2023-01-03 17:54: log dir: /home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010317542889826654013
2023-01-03 17:54: Experiment log path in: /home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010317542889826654013
2023-01-03 17:54: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=8, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010317542889826654013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=2, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=64, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-03 17:54: Argument batch_size: 256
2023-01-03 17:54: Argument clc: 'vec'
2023-01-03 17:54: Argument cuda: True
2023-01-03 17:54: Argument dataset: '2020'
2023-01-03 17:54: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-03 17:54: Argument debug: False
2023-01-03 17:54: Argument default_graph: True
2023-01-03 17:54: Argument device: 'cpu'
2023-01-03 17:54: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-03 17:54: Argument early_stop: True
2023-01-03 17:54: Argument early_stop_patience: 8
2023-01-03 17:54: Argument embed_dim: 8
2023-01-03 17:54: Argument epochs: 30
2023-01-03 17:54: Argument grad_norm: False
2023-01-03 17:54: Argument horizon: 1
2023-01-03 17:54: Argument input_dim: 25
2023-01-03 17:54: Argument lag: 10
2023-01-03 17:54: Argument link_len: 2
2023-01-03 17:54: Argument log_dir: '/home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010317542889826654013'
2023-01-03 17:54: Argument log_step: 1
2023-01-03 17:54: Argument loss_func: 'nllloss'
2023-01-03 17:54: Argument lr_decay: True
2023-01-03 17:54: Argument lr_decay_rate: 0.1
2023-01-03 17:54: Argument lr_decay_step: '15'
2023-01-03 17:54: Argument lr_init: 0.0001
2023-01-03 17:54: Argument max_grad_norm: 5
2023-01-03 17:54: Argument minbatch_size: 64
2023-01-03 17:54: Argument mode: 'train'
2023-01-03 17:54: Argument model: 'fire_GCN'
2023-01-03 17:54: Argument nan_fill: -1.0
2023-01-03 17:54: Argument num_layers: 2
2023-01-03 17:54: Argument num_nodes: 625
2023-01-03 17:54: Argument num_workers: 12
2023-01-03 17:54: Argument output_dim: 2
2023-01-03 17:54: Argument patch_height: 25
2023-01-03 17:54: Argument patch_width: 25
2023-01-03 17:54: Argument persistent_workers: True
2023-01-03 17:54: Argument pin_memory: True
2023-01-03 17:54: Argument plot: False
2023-01-03 17:54: Argument positive_weight: 0.5
2023-01-03 17:54: Argument prefetch_factor: 2
2023-01-03 17:54: Argument real_value: True
2023-01-03 17:54: Argument rnn_units: 64
2023-01-03 17:54: Argument seed: 10000
2023-01-03 17:54: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-03 17:54: Argument teacher_forcing: False
2023-01-03 17:54: Argument weight_decay: 0.0
2023-01-03 17:54: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 8]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([8, 2, 89, 64]) True
encoder.cell_list.0.gate.weights_window torch.Size([8, 1, 64]) True
encoder.cell_list.0.gate.bias_pool torch.Size([8, 128]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([8, 2, 89, 32]) True
encoder.cell_list.0.update.weights_window torch.Size([8, 1, 32]) True
encoder.cell_list.0.update.bias_pool torch.Size([8, 64]) True
encoder.cell_list.0.update.T torch.Size([10]) True
encoder.cell_list.1.gate.weights_pool torch.Size([8, 2, 128, 64]) True
encoder.cell_list.1.gate.weights_window torch.Size([8, 64, 64]) True
encoder.cell_list.1.gate.bias_pool torch.Size([8, 128]) True
encoder.cell_list.1.gate.T torch.Size([10]) True
encoder.cell_list.1.update.weights_pool torch.Size([8, 2, 128, 32]) True
encoder.cell_list.1.update.weights_window torch.Size([8, 64, 32]) True
encoder.cell_list.1.update.bias_pool torch.Size([8, 64]) True
encoder.cell_list.1.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 40000]) True
fc1.bias torch.Size([2]) True
Total params num: 471396
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010317542889826654013/run.log
2023-01-03 17:55: Train Epoch 1: 3/634 Loss: 0.504086
2023-01-03 17:56: Train Epoch 1: 7/634 Loss: 0.781081
2023-01-03 17:56: Train Epoch 1: 11/634 Loss: 0.530753
2023-01-03 17:57: Train Epoch 1: 15/634 Loss: 0.408211
2023-01-03 17:58: Train Epoch 1: 19/634 Loss: 0.425072
2023-01-03 17:59: Train Epoch 1: 23/634 Loss: 0.378773
2023-01-03 18:00: Train Epoch 1: 27/634 Loss: 0.259297
2023-01-03 18:01: Train Epoch 1: 31/634 Loss: 0.240782
2023-01-03 18:01: Train Epoch 1: 35/634 Loss: 0.395591
2023-01-03 18:02: Train Epoch 1: 39/634 Loss: 0.357833
2023-01-03 18:03: Train Epoch 1: 43/634 Loss: 0.312468
2023-01-03 18:04: Train Epoch 1: 47/634 Loss: 0.254238
2023-01-03 18:05: Train Epoch 1: 51/634 Loss: 0.296160
2023-01-03 18:05: Train Epoch 1: 55/634 Loss: 0.258797
2023-01-03 18:06: Train Epoch 1: 59/634 Loss: 0.265604
2023-01-03 18:07: Train Epoch 1: 63/634 Loss: 0.257463
2023-01-03 18:08: Train Epoch 1: 67/634 Loss: 0.286538
2023-01-03 18:09: Train Epoch 1: 71/634 Loss: 0.266182
2023-01-03 18:10: Train Epoch 1: 75/634 Loss: 0.254947
2023-01-03 18:10: Train Epoch 1: 79/634 Loss: 0.223118
2023-01-03 18:11: Train Epoch 1: 83/634 Loss: 0.232221
2023-01-03 18:12: Train Epoch 1: 87/634 Loss: 0.247500
2023-01-03 18:13: Train Epoch 1: 91/634 Loss: 0.233935
2023-01-03 18:14: Train Epoch 1: 95/634 Loss: 0.239904
2023-01-03 18:14: Train Epoch 1: 99/634 Loss: 0.219294
2023-01-03 18:15: Train Epoch 1: 103/634 Loss: 0.228539
2023-01-03 18:16: Train Epoch 1: 107/634 Loss: 0.206567
2023-01-03 18:17: Train Epoch 1: 111/634 Loss: 0.213501
2023-01-03 18:18: Train Epoch 1: 115/634 Loss: 0.217306
2023-01-03 18:19: Train Epoch 1: 119/634 Loss: 0.213829
2023-01-03 18:19: Train Epoch 1: 123/634 Loss: 0.219704
2023-01-03 18:20: Train Epoch 1: 127/634 Loss: 0.255129
2023-01-03 18:21: Train Epoch 1: 131/634 Loss: 0.229100
2023-01-03 18:22: Train Epoch 1: 135/634 Loss: 0.232518
2023-01-03 18:23: Train Epoch 1: 139/634 Loss: 0.235610
2023-01-03 18:24: Train Epoch 1: 143/634 Loss: 0.216211
2023-01-03 18:25: Train Epoch 1: 147/634 Loss: 0.226157
2023-01-03 18:25: Train Epoch 1: 151/634 Loss: 0.206887
2023-01-03 18:26: Train Epoch 1: 155/634 Loss: 0.239808
2023-01-03 18:27: Train Epoch 1: 159/634 Loss: 0.249108
2023-01-03 18:28: Train Epoch 1: 163/634 Loss: 0.232546
2023-01-03 18:29: Train Epoch 1: 167/634 Loss: 0.240554
2023-01-03 18:30: Train Epoch 1: 171/634 Loss: 0.215504
2023-01-03 18:30: Train Epoch 1: 175/634 Loss: 0.219518
2023-01-03 18:31: Train Epoch 1: 179/634 Loss: 0.231887
2023-01-03 18:32: Train Epoch 1: 183/634 Loss: 0.284861
2023-01-03 18:33: Train Epoch 1: 187/634 Loss: 0.258045
2023-01-03 18:34: Train Epoch 1: 191/634 Loss: 0.223284
2023-01-03 18:35: Train Epoch 1: 195/634 Loss: 0.246180
2023-01-03 18:35: Train Epoch 1: 199/634 Loss: 0.217599
2023-01-03 18:36: Train Epoch 1: 203/634 Loss: 0.236257
2023-01-03 18:37: Train Epoch 1: 207/634 Loss: 0.184140
2023-01-03 18:38: Train Epoch 1: 211/634 Loss: 0.229697
2023-01-03 18:39: Train Epoch 1: 215/634 Loss: 0.217842
2023-01-03 18:39: Train Epoch 1: 219/634 Loss: 0.229187
2023-01-03 18:40: Train Epoch 1: 223/634 Loss: 0.186711
2023-01-03 18:41: Train Epoch 1: 227/634 Loss: 0.265749
2023-01-03 18:42: Train Epoch 1: 231/634 Loss: 0.270986
2023-01-03 18:43: Train Epoch 1: 235/634 Loss: 0.217341
2023-01-03 18:44: Train Epoch 1: 239/634 Loss: 0.246499
2023-01-03 18:44: Train Epoch 1: 243/634 Loss: 0.207199
2023-01-03 18:45: Train Epoch 1: 247/634 Loss: 0.200065
2023-01-03 18:46: Train Epoch 1: 251/634 Loss: 0.204896
2023-01-03 18:47: Train Epoch 1: 255/634 Loss: 0.240109
2023-01-03 18:48: Train Epoch 1: 259/634 Loss: 0.238037
2023-01-03 18:48: Train Epoch 1: 263/634 Loss: 0.185082
2023-01-03 18:49: Train Epoch 1: 267/634 Loss: 0.221444
2023-01-03 18:50: Train Epoch 1: 271/634 Loss: 0.202893
2023-01-03 18:51: Train Epoch 1: 275/634 Loss: 0.215305
2023-01-03 18:52: Train Epoch 1: 279/634 Loss: 0.206712
2023-01-03 18:53: Train Epoch 1: 283/634 Loss: 0.196555
2023-01-03 18:53: Train Epoch 1: 287/634 Loss: 0.190618
2023-01-03 18:54: Train Epoch 1: 291/634 Loss: 0.206091
2023-01-03 18:55: Train Epoch 1: 295/634 Loss: 0.211010
2023-01-03 18:56: Train Epoch 1: 299/634 Loss: 0.203562
2023-01-03 18:57: Train Epoch 1: 303/634 Loss: 0.202781
2023-01-03 18:57: Train Epoch 1: 307/634 Loss: 0.198191
2023-01-03 18:58: Train Epoch 1: 311/634 Loss: 0.221816
2023-01-03 18:59: Train Epoch 1: 315/634 Loss: 0.207241
2023-01-03 19:00: Train Epoch 1: 319/634 Loss: 0.199384
2023-01-03 19:01: Train Epoch 1: 323/634 Loss: 0.189059
2023-01-03 19:02: Train Epoch 1: 327/634 Loss: 0.219577
2023-01-03 19:02: Train Epoch 1: 331/634 Loss: 0.191497
2023-01-03 19:03: Train Epoch 1: 335/634 Loss: 0.199700
2023-01-03 19:04: Train Epoch 1: 339/634 Loss: 0.228818
2023-01-03 19:05: Train Epoch 1: 343/634 Loss: 0.203383
2023-01-03 19:06: Train Epoch 1: 347/634 Loss: 0.205394
2023-01-03 19:07: Train Epoch 1: 351/634 Loss: 0.224186
2023-01-03 19:07: Train Epoch 1: 355/634 Loss: 0.190006
2023-01-03 19:08: Train Epoch 1: 359/634 Loss: 0.224677
2023-01-03 19:09: Train Epoch 1: 363/634 Loss: 0.199666
2023-01-03 19:10: Train Epoch 1: 367/634 Loss: 0.230078
2023-01-03 19:11: Train Epoch 1: 371/634 Loss: 0.238333
2023-01-03 19:11: Train Epoch 1: 375/634 Loss: 0.191784
2023-01-03 19:12: Train Epoch 1: 379/634 Loss: 0.213297
2023-01-03 19:13: Train Epoch 1: 383/634 Loss: 0.229329
2023-01-03 19:14: Train Epoch 1: 387/634 Loss: 0.263779
2023-01-03 19:15: Train Epoch 1: 391/634 Loss: 0.182905
2023-01-03 19:16: Train Epoch 1: 395/634 Loss: 0.218988
2023-01-03 19:16: Train Epoch 1: 399/634 Loss: 0.236417
2023-01-03 19:17: Train Epoch 1: 403/634 Loss: 0.223046
2023-01-03 19:18: Train Epoch 1: 407/634 Loss: 0.208875
2023-01-03 19:19: Train Epoch 1: 411/634 Loss: 0.230938
2023-01-03 19:19: Train Epoch 1: 415/634 Loss: 0.208830
2023-01-03 19:20: Train Epoch 1: 419/634 Loss: 0.206667
2023-01-03 19:21: Train Epoch 1: 423/634 Loss: 0.213567
2023-01-03 19:22: Train Epoch 1: 427/634 Loss: 0.209856
2023-01-03 19:23: Train Epoch 1: 431/634 Loss: 0.193017
2023-01-03 19:24: Train Epoch 1: 435/634 Loss: 0.238971
2023-01-03 19:24: Train Epoch 1: 439/634 Loss: 0.212714
2023-01-03 19:25: Train Epoch 1: 443/634 Loss: 0.191384
2023-01-03 19:26: Train Epoch 1: 447/634 Loss: 0.231143
2023-01-03 19:27: Train Epoch 1: 451/634 Loss: 0.205034
2023-01-03 19:28: Train Epoch 1: 455/634 Loss: 0.227742
2023-01-03 19:28: Train Epoch 1: 459/634 Loss: 0.197129
2023-01-03 19:29: Train Epoch 1: 463/634 Loss: 0.226351
2023-01-03 19:30: Train Epoch 1: 467/634 Loss: 0.234557
2023-01-03 19:31: Train Epoch 1: 471/634 Loss: 0.207200
2023-01-03 19:32: Train Epoch 1: 475/634 Loss: 0.245421
2023-01-03 19:32: Train Epoch 1: 479/634 Loss: 0.272979
2023-01-03 19:33: Train Epoch 1: 483/634 Loss: 0.205230
2023-01-03 19:34: Train Epoch 1: 487/634 Loss: 0.203662
2023-01-03 19:35: Train Epoch 1: 491/634 Loss: 0.209156
2023-01-03 19:36: Train Epoch 1: 495/634 Loss: 0.203455
2023-01-03 19:37: Train Epoch 1: 499/634 Loss: 0.217609
2023-01-03 19:37: Train Epoch 1: 503/634 Loss: 0.204869
2023-01-03 19:38: Train Epoch 1: 507/634 Loss: 0.224021
2023-01-03 19:39: Train Epoch 1: 511/634 Loss: 0.206353
2023-01-03 19:40: Train Epoch 1: 515/634 Loss: 0.210715
2023-01-03 19:41: Train Epoch 1: 519/634 Loss: 0.191442
2023-01-03 19:41: Train Epoch 1: 523/634 Loss: 0.206850
2023-01-03 19:42: Train Epoch 1: 527/634 Loss: 0.210749
2023-01-03 19:43: Train Epoch 1: 531/634 Loss: 0.184989
2023-01-03 19:44: Train Epoch 1: 535/634 Loss: 0.185546
2023-01-03 19:45: Train Epoch 1: 539/634 Loss: 0.197187
2023-01-03 19:45: Train Epoch 1: 543/634 Loss: 0.205647
2023-01-03 19:46: Train Epoch 1: 547/634 Loss: 0.222695
2023-01-03 19:47: Train Epoch 1: 551/634 Loss: 0.228817
2023-01-03 19:48: Train Epoch 1: 555/634 Loss: 0.223477
2023-01-03 19:49: Train Epoch 1: 559/634 Loss: 0.237117
2023-01-03 19:49: Train Epoch 1: 563/634 Loss: 0.219958
2023-01-03 19:50: Train Epoch 1: 567/634 Loss: 0.202428
2023-01-03 19:51: Train Epoch 1: 571/634 Loss: 0.202603
2023-01-03 19:52: Train Epoch 1: 575/634 Loss: 0.223652
2023-01-03 19:53: Train Epoch 1: 579/634 Loss: 0.203277
2023-01-03 19:54: Train Epoch 1: 583/634 Loss: 0.200647
2023-01-03 19:54: Train Epoch 1: 587/634 Loss: 0.203335
2023-01-03 19:55: Train Epoch 1: 591/634 Loss: 0.214223
2023-01-03 19:56: Train Epoch 1: 595/634 Loss: 0.193619
2023-01-03 19:57: Train Epoch 1: 599/634 Loss: 0.186210
2023-01-03 19:58: Train Epoch 1: 603/634 Loss: 0.197730
2023-01-03 19:59: Train Epoch 1: 607/634 Loss: 0.213721
2023-01-03 19:59: Train Epoch 1: 611/634 Loss: 0.191262
2023-01-03 20:00: Train Epoch 1: 615/634 Loss: 0.235441
2023-01-03 20:01: Train Epoch 1: 619/634 Loss: 0.211056
2023-01-03 20:02: Train Epoch 1: 623/634 Loss: 0.208178
2023-01-03 20:03: Train Epoch 1: 627/634 Loss: 0.228325
2023-01-03 20:03: Train Epoch 1: 631/634 Loss: 0.211015
2023-01-03 20:04: Train Epoch 1: 633/634 Loss: 0.102112
2023-01-03 20:04: **********Train Epoch 1: averaged Loss: 0.232880 
2023-01-03 20:04: 
Epoch time elapsed: 7785.068507194519

2023-01-03 20:07: 
 metrics validation: {'precision': 0.6962220508866616, 'recall': 0.6946153846153846, 'f1-score': 0.6954177897574123, 'support': 1300, 'AUC': 0.8176221893491125, 'AUCPR': 0.7059755086847181, 'TP': 903, 'FP': 394, 'TN': 2206, 'FN': 397} 

2023-01-03 20:07: **********Val Epoch 1: average Loss: 0.243927
2023-01-03 20:07: *********************************Current best model saved!
2023-01-03 20:10: 
 Testing metrics {'precision': 0.7590673575129534, 'recall': 0.7157980456026058, 'f1-score': 0.7367979882648784, 'support': 1228, 'AUC': 0.8597587905441966, 'AUCPR': 0.7763831764252238, 'TP': 879, 'FP': 279, 'TN': 2177, 'FN': 349} 

2023-01-03 20:21: 
 Testing metrics {'precision': 0.853307560137457, 'recall': 0.9015203085999546, 'f1-score': 0.876751627496414, 'support': 4407, 'AUC': 0.9577782375739567, 'AUCPR': 0.9121832452775397, 'TP': 3973, 'FP': 683, 'TN': 8131, 'FN': 434} 

2023-01-03 20:22: Train Epoch 2: 3/634 Loss: 0.191294
2023-01-03 20:23: Train Epoch 2: 7/634 Loss: 0.219575
2023-01-03 20:24: Train Epoch 2: 11/634 Loss: 0.192309
2023-01-03 20:25: Train Epoch 2: 15/634 Loss: 0.221964
2023-01-03 20:25: Train Epoch 2: 19/634 Loss: 0.213609
2023-01-03 20:26: Train Epoch 2: 23/634 Loss: 0.203520
2023-01-03 20:27: Train Epoch 2: 27/634 Loss: 0.199352
2023-01-03 20:28: Train Epoch 2: 31/634 Loss: 0.197545
2023-01-03 20:29: Train Epoch 2: 35/634 Loss: 0.182858
2023-01-03 20:30: Train Epoch 2: 39/634 Loss: 0.189672
2023-01-03 20:31: Train Epoch 2: 43/634 Loss: 0.204671
2023-01-03 20:31: Train Epoch 2: 47/634 Loss: 0.257075
2023-01-03 20:32: Train Epoch 2: 51/634 Loss: 0.189253
2023-01-03 20:33: Train Epoch 2: 55/634 Loss: 0.219416
2023-01-03 20:34: Train Epoch 2: 59/634 Loss: 0.213986
2023-01-03 20:35: Train Epoch 2: 63/634 Loss: 0.212398
2023-01-03 20:36: Train Epoch 2: 67/634 Loss: 0.187816
2023-01-03 20:37: Train Epoch 2: 71/634 Loss: 0.212298
2023-01-03 20:38: Train Epoch 2: 75/634 Loss: 0.212353
2023-01-03 20:39: Train Epoch 2: 79/634 Loss: 0.241113
2023-01-03 20:39: Train Epoch 2: 83/634 Loss: 0.245930
2023-01-03 20:40: Train Epoch 2: 87/634 Loss: 0.225761
2023-01-03 20:41: Train Epoch 2: 91/634 Loss: 0.223492
2023-01-03 20:42: Train Epoch 2: 95/634 Loss: 0.202677
2023-01-03 20:43: Train Epoch 2: 99/634 Loss: 0.188318
2023-01-03 20:44: Train Epoch 2: 103/634 Loss: 0.221535
2023-01-03 20:45: Train Epoch 2: 107/634 Loss: 0.219187
2023-01-03 20:46: Train Epoch 2: 111/634 Loss: 0.209249
2023-01-03 20:46: Train Epoch 2: 115/634 Loss: 0.219832
2023-01-03 20:47: Train Epoch 2: 119/634 Loss: 0.195723
2023-01-03 20:48: Train Epoch 2: 123/634 Loss: 0.238882
2023-01-03 20:49: Train Epoch 2: 127/634 Loss: 0.215919
2023-01-03 20:50: Train Epoch 2: 131/634 Loss: 0.204312
2023-01-03 20:51: Train Epoch 2: 135/634 Loss: 0.197502
2023-01-03 20:52: Train Epoch 2: 139/634 Loss: 0.226532
2023-01-03 20:53: Train Epoch 2: 143/634 Loss: 0.189910
2023-01-03 20:54: Train Epoch 2: 147/634 Loss: 0.194632
2023-01-03 20:54: Train Epoch 2: 151/634 Loss: 0.184805
2023-01-03 20:55: Train Epoch 2: 155/634 Loss: 0.162942
2023-01-03 20:56: Train Epoch 2: 159/634 Loss: 0.208851
2023-01-03 20:57: Train Epoch 2: 163/634 Loss: 0.227077
2023-01-03 20:58: Train Epoch 2: 167/634 Loss: 0.200587
2023-01-03 20:59: Train Epoch 2: 171/634 Loss: 0.202204
2023-01-03 21:00: Train Epoch 2: 175/634 Loss: 0.197689
2023-01-03 21:01: Train Epoch 2: 179/634 Loss: 0.248080
2023-01-03 21:01: Train Epoch 2: 183/634 Loss: 0.189334
2023-01-03 21:02: Train Epoch 2: 187/634 Loss: 0.213377
2023-01-03 21:03: Train Epoch 2: 191/634 Loss: 0.225009
2023-01-03 21:04: Train Epoch 2: 195/634 Loss: 0.223739
2023-01-03 21:05: Train Epoch 2: 199/634 Loss: 0.194754
2023-01-03 21:06: Train Epoch 2: 203/634 Loss: 0.231335
2023-01-03 21:07: Train Epoch 2: 207/634 Loss: 0.197665
2023-01-03 21:08: Train Epoch 2: 211/634 Loss: 0.189281
2023-01-03 21:09: Train Epoch 2: 215/634 Loss: 0.252353
2023-01-03 21:09: Train Epoch 2: 219/634 Loss: 0.209209
2023-01-03 21:10: Train Epoch 2: 223/634 Loss: 0.195950
2023-01-03 21:11: Train Epoch 2: 227/634 Loss: 0.221145
2023-01-03 21:12: Train Epoch 2: 231/634 Loss: 0.176387
2023-01-03 21:13: Train Epoch 2: 235/634 Loss: 0.211221
2023-01-03 21:14: Train Epoch 2: 239/634 Loss: 0.188569
2023-01-03 21:15: Train Epoch 2: 243/634 Loss: 0.191711
2023-01-03 21:16: Train Epoch 2: 247/634 Loss: 0.196951
2023-01-03 21:17: Train Epoch 2: 251/634 Loss: 0.185223
2023-01-03 21:18: Train Epoch 2: 255/634 Loss: 0.258764
2023-01-03 21:18: Train Epoch 2: 259/634 Loss: 0.230076
2023-01-03 21:19: Train Epoch 2: 263/634 Loss: 0.214784
2023-01-03 21:20: Train Epoch 2: 267/634 Loss: 0.206935
2023-01-03 21:21: Train Epoch 2: 271/634 Loss: 0.227572
2023-01-03 21:22: Train Epoch 2: 275/634 Loss: 0.193045
2023-01-03 21:23: Train Epoch 2: 279/634 Loss: 0.243968
2023-01-03 21:24: Train Epoch 2: 283/634 Loss: 0.209779
2023-01-03 21:25: Train Epoch 2: 287/634 Loss: 0.180999
2023-01-03 21:25: Train Epoch 2: 291/634 Loss: 0.199714
2023-01-03 21:26: Train Epoch 2: 295/634 Loss: 0.185318
2023-01-03 21:27: Train Epoch 2: 299/634 Loss: 0.211227
2023-01-03 21:28: Train Epoch 2: 303/634 Loss: 0.198320
2023-01-03 21:29: Train Epoch 2: 307/634 Loss: 0.191273
2023-01-03 21:30: Train Epoch 2: 311/634 Loss: 0.215696
2023-01-03 21:31: Train Epoch 2: 315/634 Loss: 0.210326
2023-01-03 21:32: Train Epoch 2: 319/634 Loss: 0.161297
2023-01-03 21:33: Train Epoch 2: 323/634 Loss: 0.201658
2023-01-03 21:33: Train Epoch 2: 327/634 Loss: 0.210069
2023-01-03 21:34: Train Epoch 2: 331/634 Loss: 0.188440
2023-01-03 21:35: Train Epoch 2: 335/634 Loss: 0.200335
2023-01-03 21:36: Train Epoch 2: 339/634 Loss: 0.194953
2023-01-03 21:37: Train Epoch 2: 343/634 Loss: 0.204310
2023-01-03 21:38: Train Epoch 2: 347/634 Loss: 0.217016
2023-01-03 21:39: Train Epoch 2: 351/634 Loss: 0.207343
2023-01-03 21:40: Train Epoch 2: 355/634 Loss: 0.199965
2023-01-03 21:40: Train Epoch 2: 359/634 Loss: 0.207576
2023-01-03 21:41: Train Epoch 2: 363/634 Loss: 0.203022
2023-01-03 21:42: Train Epoch 2: 367/634 Loss: 0.207881
2023-01-03 21:43: Train Epoch 2: 371/634 Loss: 0.230630
2023-01-03 21:44: Train Epoch 2: 375/634 Loss: 0.242398
2023-01-03 21:45: Train Epoch 2: 379/634 Loss: 0.207787
2023-01-03 21:46: Train Epoch 2: 383/634 Loss: 0.224146
2023-01-03 21:47: Train Epoch 2: 387/634 Loss: 0.189714
2023-01-03 21:48: Train Epoch 2: 391/634 Loss: 0.223584
2023-01-03 21:48: Train Epoch 2: 395/634 Loss: 0.221365
2023-01-03 21:49: Train Epoch 2: 399/634 Loss: 0.189249
2023-01-03 21:50: Train Epoch 2: 403/634 Loss: 0.210429
2023-01-03 21:51: Train Epoch 2: 407/634 Loss: 0.208536
2023-01-03 21:52: Train Epoch 2: 411/634 Loss: 0.180346
2023-01-03 21:53: Train Epoch 2: 415/634 Loss: 0.176680
2023-01-03 21:54: Train Epoch 2: 419/634 Loss: 0.200425
2023-01-03 21:55: Train Epoch 2: 423/634 Loss: 0.184577
2023-01-03 21:55: Train Epoch 2: 427/634 Loss: 0.191304
2023-01-03 21:56: Train Epoch 2: 431/634 Loss: 0.200379
2023-01-03 21:57: Train Epoch 2: 435/634 Loss: 0.190599
2023-01-03 21:58: Train Epoch 2: 439/634 Loss: 0.176783
2023-01-03 21:59: Train Epoch 2: 443/634 Loss: 0.220349
2023-01-03 22:00: Train Epoch 2: 447/634 Loss: 0.199474
2023-01-03 22:01: Train Epoch 2: 451/634 Loss: 0.196037
2023-01-03 22:01: Train Epoch 2: 455/634 Loss: 0.186366
2023-01-03 22:02: Train Epoch 2: 459/634 Loss: 0.215550
2023-01-03 22:03: Train Epoch 2: 463/634 Loss: 0.172685
2023-01-03 22:04: Train Epoch 2: 467/634 Loss: 0.220824
2023-01-03 22:05: Train Epoch 2: 471/634 Loss: 0.190521
2023-01-03 22:06: Train Epoch 2: 475/634 Loss: 0.188378
2023-01-03 22:07: Train Epoch 2: 479/634 Loss: 0.200944
2023-01-03 22:08: Train Epoch 2: 483/634 Loss: 0.183660
2023-01-03 22:09: Train Epoch 2: 487/634 Loss: 0.195947
2023-01-03 22:09: Train Epoch 2: 491/634 Loss: 0.197959
2023-01-03 22:10: Train Epoch 2: 495/634 Loss: 0.179047
2023-01-03 22:11: Train Epoch 2: 499/634 Loss: 0.174160
2023-01-03 22:12: Train Epoch 2: 503/634 Loss: 0.177313
2023-01-03 22:13: Train Epoch 2: 507/634 Loss: 0.182624
2023-01-03 22:14: Train Epoch 2: 511/634 Loss: 0.172412
2023-01-03 22:15: Train Epoch 2: 515/634 Loss: 0.204119
2023-01-03 22:15: Train Epoch 2: 519/634 Loss: 0.186419
2023-01-03 22:16: Train Epoch 2: 523/634 Loss: 0.218872
2023-01-03 22:17: Train Epoch 2: 527/634 Loss: 0.181280
2023-01-03 22:18: Train Epoch 2: 531/634 Loss: 0.222873
2023-01-03 22:19: Train Epoch 2: 535/634 Loss: 0.200365
2023-01-03 22:19: Train Epoch 2: 539/634 Loss: 0.206482
2023-01-03 22:20: Train Epoch 2: 543/634 Loss: 0.172750
2023-01-03 22:21: Train Epoch 2: 547/634 Loss: 0.189289
2023-01-03 22:22: Train Epoch 2: 551/634 Loss: 0.187203
2023-01-03 22:23: Train Epoch 2: 555/634 Loss: 0.182449
2023-01-03 22:24: Train Epoch 2: 559/634 Loss: 0.192314
2023-01-03 22:25: Train Epoch 2: 563/634 Loss: 0.210872
2023-01-03 22:25: Train Epoch 2: 567/634 Loss: 0.216080
2023-01-03 22:26: Train Epoch 2: 571/634 Loss: 0.196044
2023-01-03 22:27: Train Epoch 2: 575/634 Loss: 0.222908
2023-01-03 22:28: Train Epoch 2: 579/634 Loss: 0.201196
2023-01-03 22:29: Train Epoch 2: 583/634 Loss: 0.228227
2023-01-03 22:30: Train Epoch 2: 587/634 Loss: 0.175917
2023-01-03 22:31: Train Epoch 2: 591/634 Loss: 0.198346
2023-01-03 22:32: Train Epoch 2: 595/634 Loss: 0.229545
2023-01-03 22:33: Train Epoch 2: 599/634 Loss: 0.223453
2023-01-03 22:33: Train Epoch 2: 603/634 Loss: 0.204311
2023-01-03 22:34: Train Epoch 2: 607/634 Loss: 0.196319
2023-01-03 22:35: Train Epoch 2: 611/634 Loss: 0.226669
2023-01-03 22:36: Train Epoch 2: 615/634 Loss: 0.186256
2023-01-03 22:37: Train Epoch 2: 619/634 Loss: 0.234166
2023-01-03 22:38: Train Epoch 2: 623/634 Loss: 0.207085
2023-01-03 22:38: Train Epoch 2: 627/634 Loss: 0.203762
2023-01-03 22:39: Train Epoch 2: 631/634 Loss: 0.193330
2023-01-03 22:40: Train Epoch 2: 633/634 Loss: 0.072540
2023-01-03 22:40: **********Train Epoch 2: averaged Loss: 0.203542 
2023-01-03 22:40: 
Epoch time elapsed: 8318.044430732727

2023-01-03 22:43: 
 metrics validation: {'precision': 0.6201413427561837, 'recall': 0.81, 'f1-score': 0.7024683122081388, 'support': 1300, 'AUC': 0.8515355029585799, 'AUCPR': 0.7410710509714148, 'TP': 1053, 'FP': 645, 'TN': 1955, 'FN': 247} 

2023-01-03 22:43: **********Val Epoch 2: average Loss: 0.236095
2023-01-03 22:43: *********************************Current best model saved!
2023-01-03 22:46: 
 Testing metrics {'precision': 0.6752021563342318, 'recall': 0.8159609120521173, 'f1-score': 0.7389380530973452, 'support': 1228, 'AUC': 0.879931086801982, 'AUCPR': 0.8012805611976932, 'TP': 1002, 'FP': 482, 'TN': 1974, 'FN': 226} 

2023-01-03 22:56: 
 Testing metrics {'precision': 0.7627872498146775, 'recall': 0.9339686861810755, 'f1-score': 0.8397429358359686, 'support': 4407, 'AUC': 0.9571711444275406, 'AUCPR': 0.9147006665061583, 'TP': 4116, 'FP': 1280, 'TN': 7534, 'FN': 291} 

2023-01-03 22:57: Train Epoch 3: 3/634 Loss: 0.267922
2023-01-03 22:58: Train Epoch 3: 7/634 Loss: 0.202275
2023-01-03 22:59: Train Epoch 3: 11/634 Loss: 0.203835
2023-01-03 22:59: Train Epoch 3: 15/634 Loss: 0.238541
2023-01-03 23:00: Train Epoch 3: 19/634 Loss: 0.202783
2023-01-03 23:01: Train Epoch 3: 23/634 Loss: 0.189243
2023-01-03 23:02: Train Epoch 3: 27/634 Loss: 0.225877
2023-01-03 23:03: Train Epoch 3: 31/634 Loss: 0.198344
2023-01-03 23:04: Train Epoch 3: 35/634 Loss: 0.192697
2023-01-03 23:04: Train Epoch 3: 39/634 Loss: 0.266286
2023-01-03 23:05: Train Epoch 3: 43/634 Loss: 0.213507
2023-01-03 23:06: Train Epoch 3: 47/634 Loss: 0.195672
2023-01-03 23:07: Train Epoch 3: 51/634 Loss: 0.203747
2023-01-03 23:08: Train Epoch 3: 55/634 Loss: 0.161596
2023-01-03 23:09: Train Epoch 3: 59/634 Loss: 0.223574
2023-01-03 23:10: Train Epoch 3: 63/634 Loss: 0.184815
2023-01-03 23:10: Train Epoch 3: 67/634 Loss: 0.231647
2023-01-03 23:11: Train Epoch 3: 71/634 Loss: 0.247403
2023-01-03 23:12: Train Epoch 3: 75/634 Loss: 0.214969
2023-01-03 23:13: Train Epoch 3: 79/634 Loss: 0.200058
2023-01-03 23:14: Train Epoch 3: 83/634 Loss: 0.209123
2023-01-03 23:15: Train Epoch 3: 87/634 Loss: 0.196086
2023-01-03 23:15: Train Epoch 3: 91/634 Loss: 0.195878
2023-01-03 23:16: Train Epoch 3: 95/634 Loss: 0.182769
2023-01-03 23:17: Train Epoch 3: 99/634 Loss: 0.172658
2023-01-03 23:18: Train Epoch 3: 103/634 Loss: 0.188320
2023-01-03 23:19: Train Epoch 3: 107/634 Loss: 0.180850
2023-01-03 23:19: Train Epoch 3: 111/634 Loss: 0.173887
2023-01-03 23:20: Train Epoch 3: 115/634 Loss: 0.188090
2023-01-03 23:21: Train Epoch 3: 119/634 Loss: 0.196819
2023-01-03 23:22: Train Epoch 3: 123/634 Loss: 0.207901
2023-01-03 23:22: Train Epoch 3: 127/634 Loss: 0.215626
2023-01-03 23:23: Train Epoch 3: 131/634 Loss: 0.166109
2023-01-03 23:24: Train Epoch 3: 135/634 Loss: 0.195108
2023-01-03 23:25: Train Epoch 3: 139/634 Loss: 0.199921
2023-01-03 23:26: Train Epoch 3: 143/634 Loss: 0.202598
2023-01-03 23:27: Train Epoch 3: 147/634 Loss: 0.210400
2023-01-03 23:27: Train Epoch 3: 151/634 Loss: 0.187330
2023-01-03 23:28: Train Epoch 3: 155/634 Loss: 0.186818
2023-01-03 23:29: Train Epoch 3: 159/634 Loss: 0.176601
2023-01-03 23:30: Train Epoch 3: 163/634 Loss: 0.169305
2023-01-03 23:31: Train Epoch 3: 167/634 Loss: 0.192971
2023-01-03 23:32: Train Epoch 3: 171/634 Loss: 0.180888
2023-01-03 23:32: Train Epoch 3: 175/634 Loss: 0.213983
2023-01-03 23:33: Train Epoch 3: 179/634 Loss: 0.170593
2023-01-03 23:34: Train Epoch 3: 183/634 Loss: 0.201220
2023-01-03 23:35: Train Epoch 3: 187/634 Loss: 0.177397
2023-01-03 23:36: Train Epoch 3: 191/634 Loss: 0.184749
2023-01-03 23:37: Train Epoch 3: 195/634 Loss: 0.224983
2023-01-03 23:37: Train Epoch 3: 199/634 Loss: 0.196290
2023-01-03 23:38: Train Epoch 3: 203/634 Loss: 0.166863
2023-01-03 23:39: Train Epoch 3: 207/634 Loss: 0.197924
2023-01-03 23:40: Train Epoch 3: 211/634 Loss: 0.234345
2023-01-03 23:41: Train Epoch 3: 215/634 Loss: 0.178700
2023-01-03 23:42: Train Epoch 3: 219/634 Loss: 0.208948
2023-01-03 23:43: Train Epoch 3: 223/634 Loss: 0.195636
2023-01-03 23:43: Train Epoch 3: 227/634 Loss: 0.180140
2023-01-03 23:44: Train Epoch 3: 231/634 Loss: 0.188394
2023-01-03 23:45: Train Epoch 3: 235/634 Loss: 0.176690
2023-01-03 23:46: Train Epoch 3: 239/634 Loss: 0.184990
2023-01-03 23:47: Train Epoch 3: 243/634 Loss: 0.194786
2023-01-03 23:48: Train Epoch 3: 247/634 Loss: 0.193775
2023-01-03 23:49: Train Epoch 3: 251/634 Loss: 0.185920
2023-01-03 23:50: Train Epoch 3: 255/634 Loss: 0.183740
2023-01-03 23:50: Train Epoch 3: 259/634 Loss: 0.182986
2023-01-03 23:51: Train Epoch 3: 263/634 Loss: 0.165471
2023-01-03 23:52: Train Epoch 3: 267/634 Loss: 0.192378
2023-01-03 23:53: Train Epoch 3: 271/634 Loss: 0.176101
2023-01-03 23:54: Train Epoch 3: 275/634 Loss: 0.188793
2023-01-03 23:55: Train Epoch 3: 279/634 Loss: 0.207252
2023-01-03 23:55: Train Epoch 3: 283/634 Loss: 0.201683
2023-01-03 23:56: Train Epoch 3: 287/634 Loss: 0.232548
2023-01-03 23:57: Train Epoch 3: 291/634 Loss: 0.180346
2023-01-03 23:58: Train Epoch 3: 295/634 Loss: 0.198381
2023-01-03 23:59: Train Epoch 3: 299/634 Loss: 0.196021
2023-01-04 00:00: Train Epoch 3: 303/634 Loss: 0.206467
2023-01-04 00:01: Train Epoch 3: 307/634 Loss: 0.206454
2023-01-04 00:02: Train Epoch 3: 311/634 Loss: 0.202906
2023-01-04 00:02: Train Epoch 3: 315/634 Loss: 0.253158
2023-01-04 00:03: Train Epoch 3: 319/634 Loss: 0.174067
2023-01-04 00:04: Train Epoch 3: 323/634 Loss: 0.206643
2023-01-04 00:05: Train Epoch 3: 327/634 Loss: 0.232000
2023-01-04 00:06: Train Epoch 3: 331/634 Loss: 0.194878
2023-01-04 00:07: Train Epoch 3: 335/634 Loss: 0.177622
2023-01-04 00:08: Train Epoch 3: 339/634 Loss: 0.190806
2023-01-04 00:09: Train Epoch 3: 343/634 Loss: 0.182879
2023-01-04 00:09: Train Epoch 3: 347/634 Loss: 0.177818
2023-01-04 00:10: Train Epoch 3: 351/634 Loss: 0.178471
2023-01-04 00:11: Train Epoch 3: 355/634 Loss: 0.181060
2023-01-04 00:12: Train Epoch 3: 359/634 Loss: 0.189938
2023-01-04 00:13: Train Epoch 3: 363/634 Loss: 0.180700
2023-01-04 00:14: Train Epoch 3: 367/634 Loss: 0.244935
2023-01-04 00:15: Train Epoch 3: 371/634 Loss: 0.182650
2023-01-04 00:15: Train Epoch 3: 375/634 Loss: 0.188687
2023-01-04 00:16: Train Epoch 3: 379/634 Loss: 0.216594
2023-01-04 00:17: Train Epoch 3: 383/634 Loss: 0.185332
2023-01-04 00:18: Train Epoch 3: 387/634 Loss: 0.200583
2023-01-04 00:19: Train Epoch 3: 391/634 Loss: 0.202193
2023-01-04 00:20: Train Epoch 3: 395/634 Loss: 0.196275
2023-01-04 00:21: Train Epoch 3: 399/634 Loss: 0.204362
2023-01-04 00:21: Train Epoch 3: 403/634 Loss: 0.196143
2023-01-04 00:22: Train Epoch 3: 407/634 Loss: 0.227372
2023-01-04 00:23: Train Epoch 3: 411/634 Loss: 0.162026
2023-01-04 00:24: Train Epoch 3: 415/634 Loss: 0.197029
2023-01-04 00:25: Train Epoch 3: 419/634 Loss: 0.209384
2023-01-04 00:26: Train Epoch 3: 423/634 Loss: 0.175458
2023-01-04 00:27: Train Epoch 3: 427/634 Loss: 0.222672
2023-01-04 00:27: Train Epoch 3: 431/634 Loss: 0.206079
2023-01-04 00:28: Train Epoch 3: 435/634 Loss: 0.213447
2023-01-04 00:29: Train Epoch 3: 439/634 Loss: 0.187259
2023-01-04 00:30: Train Epoch 3: 443/634 Loss: 0.219252
2023-01-04 00:31: Train Epoch 3: 447/634 Loss: 0.198557
2023-01-04 00:32: Train Epoch 3: 451/634 Loss: 0.178696
2023-01-04 00:33: Train Epoch 3: 455/634 Loss: 0.176854
2023-01-04 00:33: Train Epoch 3: 459/634 Loss: 0.207637
2023-01-04 00:34: Train Epoch 3: 463/634 Loss: 0.189952
2023-01-04 00:35: Train Epoch 3: 467/634 Loss: 0.205003
2023-01-04 00:36: Train Epoch 3: 471/634 Loss: 0.154668
2023-01-04 00:37: Train Epoch 3: 475/634 Loss: 0.146266
2023-01-04 00:38: Train Epoch 3: 479/634 Loss: 0.176172
2023-01-04 00:38: Train Epoch 3: 483/634 Loss: 0.191992
2023-01-04 00:39: Train Epoch 3: 487/634 Loss: 0.181269
2023-01-04 00:40: Train Epoch 3: 491/634 Loss: 0.181684
2023-01-04 00:41: Train Epoch 3: 495/634 Loss: 0.170971
2023-01-04 00:42: Train Epoch 3: 499/634 Loss: 0.176163
2023-01-04 00:43: Train Epoch 3: 503/634 Loss: 0.172688
2023-01-04 00:43: Train Epoch 3: 507/634 Loss: 0.200571
2023-01-04 00:44: Train Epoch 3: 511/634 Loss: 0.140745
2023-01-04 00:45: Train Epoch 3: 515/634 Loss: 0.172856
2023-01-04 00:46: Train Epoch 3: 519/634 Loss: 0.188464
2023-01-04 00:47: Train Epoch 3: 523/634 Loss: 0.177635
2023-01-04 00:48: Train Epoch 3: 527/634 Loss: 0.198446
2023-01-04 00:49: Train Epoch 3: 531/634 Loss: 0.183955
2023-01-04 00:50: Train Epoch 3: 535/634 Loss: 0.167165
2023-01-04 00:50: Train Epoch 3: 539/634 Loss: 0.175120
2023-01-04 00:51: Train Epoch 3: 543/634 Loss: 0.227898
2023-01-04 00:52: Train Epoch 3: 547/634 Loss: 0.191689
2023-01-04 00:53: Train Epoch 3: 551/634 Loss: 0.174785
2023-01-04 00:54: Train Epoch 3: 555/634 Loss: 0.170949
2023-01-04 00:55: Train Epoch 3: 559/634 Loss: 0.179989
2023-01-04 00:55: Train Epoch 3: 563/634 Loss: 0.189485
2023-01-04 00:56: Train Epoch 3: 567/634 Loss: 0.184122
2023-01-04 00:57: Train Epoch 3: 571/634 Loss: 0.186960
2023-01-04 00:58: Train Epoch 3: 575/634 Loss: 0.215785
2023-01-04 00:59: Train Epoch 3: 579/634 Loss: 0.185376
2023-01-04 01:00: Train Epoch 3: 583/634 Loss: 0.188367
2023-01-04 01:01: Train Epoch 3: 587/634 Loss: 0.198022
2023-01-04 01:01: Train Epoch 3: 591/634 Loss: 0.169087
2023-01-04 01:02: Train Epoch 3: 595/634 Loss: 0.192690
2023-01-04 01:03: Train Epoch 3: 599/634 Loss: 0.168261
2023-01-04 01:04: Train Epoch 3: 603/634 Loss: 0.197934
2023-01-04 01:05: Train Epoch 3: 607/634 Loss: 0.202999
2023-01-04 01:06: Train Epoch 3: 611/634 Loss: 0.164350
2023-01-04 01:07: Train Epoch 3: 615/634 Loss: 0.160987
2023-01-04 01:07: Train Epoch 3: 619/634 Loss: 0.188744
2023-01-04 01:08: Train Epoch 3: 623/634 Loss: 0.176416
2023-01-04 01:09: Train Epoch 3: 627/634 Loss: 0.196057
2023-01-04 01:10: Train Epoch 3: 631/634 Loss: 0.176578
2023-01-04 01:10: Train Epoch 3: 633/634 Loss: 0.088075
2023-01-04 01:10: **********Train Epoch 3: averaged Loss: 0.192865 
2023-01-04 01:10: 
Epoch time elapsed: 8044.809710979462

2023-01-04 01:13: 
 metrics validation: {'precision': 0.7541412380122058, 'recall': 0.6653846153846154, 'f1-score': 0.7069881487535759, 'support': 1300, 'AUC': 0.8918310650887574, 'AUCPR': 0.7788071122654536, 'TP': 865, 'FP': 282, 'TN': 2318, 'FN': 435} 

2023-01-04 01:13: **********Val Epoch 3: average Loss: 0.185901
2023-01-04 01:13: *********************************Current best model saved!
2023-01-04 01:16: 
 Testing metrics {'precision': 0.805528134254689, 'recall': 0.6644951140065146, 'f1-score': 0.7282463186077645, 'support': 1228, 'AUC': 0.9025523480355229, 'AUCPR': 0.8306377294529738, 'TP': 816, 'FP': 197, 'TN': 2259, 'FN': 412} 

2023-01-04 01:26: 
 Testing metrics {'precision': 0.8705765899529819, 'recall': 0.7982754708418425, 'f1-score': 0.8328598484848484, 'support': 4407, 'AUC': 0.959029946427309, 'AUCPR': 0.9151686753359707, 'TP': 3518, 'FP': 523, 'TN': 8291, 'FN': 889} 

2023-01-04 01:27: Train Epoch 4: 3/634 Loss: 0.158655
2023-01-04 01:28: Train Epoch 4: 7/634 Loss: 0.196405
2023-01-04 01:29: Train Epoch 4: 11/634 Loss: 0.162365
2023-01-04 01:30: Train Epoch 4: 15/634 Loss: 0.163141
2023-01-04 01:31: Train Epoch 4: 19/634 Loss: 0.187811
2023-01-04 01:31: Train Epoch 4: 23/634 Loss: 0.190657
2023-01-04 01:32: Train Epoch 4: 27/634 Loss: 0.167486
2023-01-04 01:33: Train Epoch 4: 31/634 Loss: 0.190138
2023-01-04 01:34: Train Epoch 4: 35/634 Loss: 0.188134
2023-01-04 01:35: Train Epoch 4: 39/634 Loss: 0.204557
2023-01-04 01:36: Train Epoch 4: 43/634 Loss: 0.196775
2023-01-04 01:36: Train Epoch 4: 47/634 Loss: 0.167339
2023-01-04 01:37: Train Epoch 4: 51/634 Loss: 0.181528
2023-01-04 01:38: Train Epoch 4: 55/634 Loss: 0.197408
2023-01-04 01:39: Train Epoch 4: 59/634 Loss: 0.178390
2023-01-04 01:40: Train Epoch 4: 63/634 Loss: 0.179488
2023-01-04 01:41: Train Epoch 4: 67/634 Loss: 0.175549
2023-01-04 01:42: Train Epoch 4: 71/634 Loss: 0.220398
2023-01-04 01:43: Train Epoch 4: 75/634 Loss: 0.182957
2023-01-04 01:43: Train Epoch 4: 79/634 Loss: 0.185093
2023-01-04 01:44: Train Epoch 4: 83/634 Loss: 0.164194
2023-01-04 01:45: Train Epoch 4: 87/634 Loss: 0.146890
2023-01-04 01:46: Train Epoch 4: 91/634 Loss: 0.201626
2023-01-04 01:47: Train Epoch 4: 95/634 Loss: 0.155465
2023-01-04 01:48: Train Epoch 4: 99/634 Loss: 0.161805
2023-01-04 01:49: Train Epoch 4: 103/634 Loss: 0.168533
2023-01-04 01:50: Train Epoch 4: 107/634 Loss: 0.178979
2023-01-04 01:50: Train Epoch 4: 111/634 Loss: 0.201430
2023-01-04 01:51: Train Epoch 4: 115/634 Loss: 0.194653
2023-01-04 01:52: Train Epoch 4: 119/634 Loss: 0.175940
2023-01-04 01:53: Train Epoch 4: 123/634 Loss: 0.190949
2023-01-04 01:54: Train Epoch 4: 127/634 Loss: 0.182294
2023-01-04 01:55: Train Epoch 4: 131/634 Loss: 0.181149
2023-01-04 01:56: Train Epoch 4: 135/634 Loss: 0.159879
2023-01-04 01:56: Train Epoch 4: 139/634 Loss: 0.190882
2023-01-04 01:57: Train Epoch 4: 143/634 Loss: 0.191798
2023-01-04 01:58: Train Epoch 4: 147/634 Loss: 0.197994
2023-01-04 01:59: Train Epoch 4: 151/634 Loss: 0.179766
2023-01-04 02:00: Train Epoch 4: 155/634 Loss: 0.169714
2023-01-04 02:01: Train Epoch 4: 159/634 Loss: 0.189754
2023-01-04 02:02: Train Epoch 4: 163/634 Loss: 0.174777
2023-01-04 02:03: Train Epoch 4: 167/634 Loss: 0.171811
2023-01-04 02:03: Train Epoch 4: 171/634 Loss: 0.174947
2023-01-04 02:04: Train Epoch 4: 175/634 Loss: 0.183662
2023-01-04 02:05: Train Epoch 4: 179/634 Loss: 0.206065
2023-01-04 02:06: Train Epoch 4: 183/634 Loss: 0.175695
2023-01-04 02:07: Train Epoch 4: 187/634 Loss: 0.176220
2023-01-04 02:08: Train Epoch 4: 191/634 Loss: 0.184792
2023-01-04 02:09: Train Epoch 4: 195/634 Loss: 0.150775
2023-01-04 02:10: Train Epoch 4: 199/634 Loss: 0.181733
2023-01-04 02:10: Train Epoch 4: 203/634 Loss: 0.172334
2023-01-04 02:11: Train Epoch 4: 207/634 Loss: 0.184519
2023-01-04 02:12: Train Epoch 4: 211/634 Loss: 0.141367
2023-01-04 02:13: Train Epoch 4: 215/634 Loss: 0.168845
2023-01-04 02:14: Train Epoch 4: 219/634 Loss: 0.199741
2023-01-04 02:15: Train Epoch 4: 223/634 Loss: 0.188417
2023-01-04 02:16: Train Epoch 4: 227/634 Loss: 0.158115
2023-01-04 02:16: Train Epoch 4: 231/634 Loss: 0.161937
2023-01-04 02:17: Train Epoch 4: 235/634 Loss: 0.183010
2023-01-04 02:18: Train Epoch 4: 239/634 Loss: 0.173923
2023-01-04 02:19: Train Epoch 4: 243/634 Loss: 0.173696
2023-01-04 02:20: Train Epoch 4: 247/634 Loss: 0.181738
2023-01-04 02:21: Train Epoch 4: 251/634 Loss: 0.165660
2023-01-04 02:21: Train Epoch 4: 255/634 Loss: 0.192032
2023-01-04 02:22: Train Epoch 4: 259/634 Loss: 0.175475
2023-01-04 02:23: Train Epoch 4: 263/634 Loss: 0.176355
2023-01-04 02:24: Train Epoch 4: 267/634 Loss: 0.156233
2023-01-04 02:25: Train Epoch 4: 271/634 Loss: 0.182479
2023-01-04 02:26: Train Epoch 4: 275/634 Loss: 0.226005
2023-01-04 02:27: Train Epoch 4: 279/634 Loss: 0.168144
2023-01-04 02:27: Train Epoch 4: 283/634 Loss: 0.205923
2023-01-04 02:28: Train Epoch 4: 287/634 Loss: 0.218535
2023-01-04 02:29: Train Epoch 4: 291/634 Loss: 0.183366
2023-01-04 02:30: Train Epoch 4: 295/634 Loss: 0.169213
2023-01-04 02:31: Train Epoch 4: 299/634 Loss: 0.182126
2023-01-04 02:32: Train Epoch 4: 303/634 Loss: 0.189950
2023-01-04 02:33: Train Epoch 4: 307/634 Loss: 0.195471
2023-01-04 02:33: Train Epoch 4: 311/634 Loss: 0.171696
2023-01-04 02:34: Train Epoch 4: 315/634 Loss: 0.172164
2023-01-04 02:35: Train Epoch 4: 319/634 Loss: 0.171021
2023-01-04 02:36: Train Epoch 4: 323/634 Loss: 0.186842
2023-01-04 02:37: Train Epoch 4: 327/634 Loss: 0.179908
2023-01-04 02:38: Train Epoch 4: 331/634 Loss: 0.218418
2023-01-04 02:38: Train Epoch 4: 335/634 Loss: 0.194295
2023-01-04 02:39: Train Epoch 4: 339/634 Loss: 0.173105
2023-01-04 02:40: Train Epoch 4: 343/634 Loss: 0.165826
2023-01-04 02:41: Train Epoch 4: 347/634 Loss: 0.203310
2023-01-04 02:42: Train Epoch 4: 351/634 Loss: 0.177326
2023-01-04 02:43: Train Epoch 4: 355/634 Loss: 0.174008
2023-01-04 02:44: Train Epoch 4: 359/634 Loss: 0.182599
2023-01-04 02:44: Train Epoch 4: 363/634 Loss: 0.169474
2023-01-04 02:45: Train Epoch 4: 367/634 Loss: 0.206392
2023-01-04 02:46: Train Epoch 4: 371/634 Loss: 0.213148
2023-01-04 02:47: Train Epoch 4: 375/634 Loss: 0.147515
2023-01-04 02:48: Train Epoch 4: 379/634 Loss: 0.174881
2023-01-04 02:49: Train Epoch 4: 383/634 Loss: 0.194883
2023-01-04 02:50: Train Epoch 4: 387/634 Loss: 0.183985
2023-01-04 02:50: Train Epoch 4: 391/634 Loss: 0.195156
2023-01-04 02:51: Train Epoch 4: 395/634 Loss: 0.240647
2023-01-04 02:52: Train Epoch 4: 399/634 Loss: 0.152168
2023-01-04 02:53: Train Epoch 4: 403/634 Loss: 0.188811
2023-01-04 02:54: Train Epoch 4: 407/634 Loss: 0.171613
2023-01-04 02:55: Train Epoch 4: 411/634 Loss: 0.208434
2023-01-04 02:56: Train Epoch 4: 415/634 Loss: 0.200227
2023-01-04 02:56: Train Epoch 4: 419/634 Loss: 0.198974
2023-01-04 02:57: Train Epoch 4: 423/634 Loss: 0.183080
2023-01-04 02:58: Train Epoch 4: 427/634 Loss: 0.209473
2023-01-04 02:59: Train Epoch 4: 431/634 Loss: 0.227198
2023-01-04 03:00: Train Epoch 4: 435/634 Loss: 0.201341
2023-01-04 03:01: Train Epoch 4: 439/634 Loss: 0.170776
2023-01-04 03:01: Train Epoch 4: 443/634 Loss: 0.221277
2023-01-04 03:02: Train Epoch 4: 447/634 Loss: 0.209667
2023-01-04 03:03: Train Epoch 4: 451/634 Loss: 0.204378
2023-01-04 03:04: Train Epoch 4: 455/634 Loss: 0.207188
2023-01-04 03:05: Train Epoch 4: 459/634 Loss: 0.207596
2023-01-04 03:06: Train Epoch 4: 463/634 Loss: 0.179486
2023-01-04 03:07: Train Epoch 4: 467/634 Loss: 0.158076
2023-01-04 03:07: Train Epoch 4: 471/634 Loss: 0.192828
2023-01-04 03:08: Train Epoch 4: 475/634 Loss: 0.197886
2023-01-04 03:09: Train Epoch 4: 479/634 Loss: 0.211123
2023-01-04 03:10: Train Epoch 4: 483/634 Loss: 0.203078
2023-01-04 03:11: Train Epoch 4: 487/634 Loss: 0.172916
2023-01-04 03:12: Train Epoch 4: 491/634 Loss: 0.187321
2023-01-04 03:13: Train Epoch 4: 495/634 Loss: 0.188411
2023-01-04 03:13: Train Epoch 4: 499/634 Loss: 0.185502
2023-01-04 03:14: Train Epoch 4: 503/634 Loss: 0.174052
2023-01-04 03:15: Train Epoch 4: 507/634 Loss: 0.180276
2023-01-04 03:16: Train Epoch 4: 511/634 Loss: 0.165106
2023-01-04 03:17: Train Epoch 4: 515/634 Loss: 0.167916
2023-01-04 03:18: Train Epoch 4: 519/634 Loss: 0.169155
2023-01-04 03:19: Train Epoch 4: 523/634 Loss: 0.168882
2023-01-04 03:19: Train Epoch 4: 527/634 Loss: 0.174549
2023-01-04 03:20: Train Epoch 4: 531/634 Loss: 0.194152
2023-01-04 03:21: Train Epoch 4: 535/634 Loss: 0.158715
2023-01-04 03:22: Train Epoch 4: 539/634 Loss: 0.190805
2023-01-04 03:23: Train Epoch 4: 543/634 Loss: 0.167700
2023-01-04 03:24: Train Epoch 4: 547/634 Loss: 0.176465
2023-01-04 03:25: Train Epoch 4: 551/634 Loss: 0.206305
2023-01-04 03:25: Train Epoch 4: 555/634 Loss: 0.149925
2023-01-04 03:26: Train Epoch 4: 559/634 Loss: 0.165167
2023-01-04 03:27: Train Epoch 4: 563/634 Loss: 0.180421
2023-01-04 03:28: Train Epoch 4: 567/634 Loss: 0.161608
2023-01-04 03:29: Train Epoch 4: 571/634 Loss: 0.167353
2023-01-04 03:30: Train Epoch 4: 575/634 Loss: 0.181510
2023-01-04 03:31: Train Epoch 4: 579/634 Loss: 0.159033
2023-01-04 03:32: Train Epoch 4: 583/634 Loss: 0.174558
2023-01-04 03:32: Train Epoch 4: 587/634 Loss: 0.180992
2023-01-04 03:33: Train Epoch 4: 591/634 Loss: 0.184485
2023-01-04 03:34: Train Epoch 4: 595/634 Loss: 0.181536
2023-01-04 03:35: Train Epoch 4: 599/634 Loss: 0.187700
2023-01-04 03:36: Train Epoch 4: 603/634 Loss: 0.163777
2023-01-04 03:36: Train Epoch 4: 607/634 Loss: 0.161733
2023-01-04 03:37: Train Epoch 4: 611/634 Loss: 0.219639
2023-01-04 03:38: Train Epoch 4: 615/634 Loss: 0.171946
2023-01-04 03:39: Train Epoch 4: 619/634 Loss: 0.238770
2023-01-04 03:39: Train Epoch 4: 623/634 Loss: 0.172621
2023-01-04 03:40: Train Epoch 4: 627/634 Loss: 0.213468
2023-01-04 03:41: Train Epoch 4: 631/634 Loss: 0.178214
2023-01-04 03:41: Train Epoch 4: 633/634 Loss: 0.060406
2023-01-04 03:41: **********Train Epoch 4: averaged Loss: 0.182374 
2023-01-04 03:41: 
Epoch time elapsed: 8107.049685239792

2023-01-04 03:45: 
 metrics validation: {'precision': 0.7817319098457889, 'recall': 0.5069230769230769, 'f1-score': 0.6150256649556696, 'support': 1300, 'AUC': 0.889555325443787, 'AUCPR': 0.775174625688955, 'TP': 659, 'FP': 184, 'TN': 2416, 'FN': 641} 

2023-01-04 03:45: **********Val Epoch 4: average Loss: 0.209519
2023-01-04 03:47: 
 Testing metrics {'precision': 0.805528134254689, 'recall': 0.6644951140065146, 'f1-score': 0.7282463186077645, 'support': 1228, 'AUC': 0.9025523480355229, 'AUCPR': 0.8306377294529738, 'TP': 816, 'FP': 197, 'TN': 2259, 'FN': 412} 

2023-01-04 03:58: 
 Testing metrics {'precision': 0.8705765899529819, 'recall': 0.7982754708418425, 'f1-score': 0.8328598484848484, 'support': 4407, 'AUC': 0.959029946427309, 'AUCPR': 0.9151686753359707, 'TP': 3518, 'FP': 523, 'TN': 8291, 'FN': 889} 

2023-01-04 03:59: Train Epoch 5: 3/634 Loss: 0.185985
2023-01-04 04:00: Train Epoch 5: 7/634 Loss: 0.173693
2023-01-04 04:00: Train Epoch 5: 11/634 Loss: 0.182592
2023-01-04 04:01: Train Epoch 5: 15/634 Loss: 0.189874
2023-01-04 04:02: Train Epoch 5: 19/634 Loss: 0.200280
2023-01-04 04:03: Train Epoch 5: 23/634 Loss: 0.188507
2023-01-04 04:04: Train Epoch 5: 27/634 Loss: 0.173480
2023-01-04 04:05: Train Epoch 5: 31/634 Loss: 0.191429
2023-01-04 04:05: Train Epoch 5: 35/634 Loss: 0.201403
2023-01-04 04:06: Train Epoch 5: 39/634 Loss: 0.185105
2023-01-04 04:07: Train Epoch 5: 43/634 Loss: 0.175533
2023-01-04 04:08: Train Epoch 5: 47/634 Loss: 0.193970
2023-01-04 04:09: Train Epoch 5: 51/634 Loss: 0.186481
2023-01-04 04:10: Train Epoch 5: 55/634 Loss: 0.178472
2023-01-04 04:11: Train Epoch 5: 59/634 Loss: 0.164699
2023-01-04 04:11: Train Epoch 5: 63/634 Loss: 0.182065
2023-01-04 04:12: Train Epoch 5: 67/634 Loss: 0.170703
2023-01-04 04:13: Train Epoch 5: 71/634 Loss: 0.176826
2023-01-04 04:14: Train Epoch 5: 75/634 Loss: 0.183049
2023-01-04 04:15: Train Epoch 5: 79/634 Loss: 0.215169
2023-01-04 04:16: Train Epoch 5: 83/634 Loss: 0.153067
2023-01-04 04:17: Train Epoch 5: 87/634 Loss: 0.163276
2023-01-04 04:17: Train Epoch 5: 91/634 Loss: 0.191127
2023-01-04 04:18: Train Epoch 5: 95/634 Loss: 0.174737
2023-01-04 04:19: Train Epoch 5: 99/634 Loss: 0.170664
2023-01-04 04:20: Train Epoch 5: 103/634 Loss: 0.237073
2023-01-04 04:21: Train Epoch 5: 107/634 Loss: 0.179483
2023-01-04 04:22: Train Epoch 5: 111/634 Loss: 0.179657
2023-01-04 04:23: Train Epoch 5: 115/634 Loss: 0.160961
2023-01-04 04:23: Train Epoch 5: 119/634 Loss: 0.205180
2023-01-04 04:24: Train Epoch 5: 123/634 Loss: 0.207351
2023-01-04 04:25: Train Epoch 5: 127/634 Loss: 0.174163
2023-01-04 04:26: Train Epoch 5: 131/634 Loss: 0.172254
2023-01-04 04:27: Train Epoch 5: 135/634 Loss: 0.169993
2023-01-04 04:28: Train Epoch 5: 139/634 Loss: 0.158586
2023-01-04 04:29: Train Epoch 5: 143/634 Loss: 0.190699
2023-01-04 04:29: Train Epoch 5: 147/634 Loss: 0.181529
2023-01-04 04:30: Train Epoch 5: 151/634 Loss: 0.183770
2023-01-04 04:31: Train Epoch 5: 155/634 Loss: 0.182244
2023-01-04 04:32: Train Epoch 5: 159/634 Loss: 0.150864
2023-01-04 04:33: Train Epoch 5: 163/634 Loss: 0.172814
2023-01-04 04:34: Train Epoch 5: 167/634 Loss: 0.185592
2023-01-04 04:35: Train Epoch 5: 171/634 Loss: 0.189186
2023-01-04 04:36: Train Epoch 5: 175/634 Loss: 0.165762
2023-01-04 04:36: Train Epoch 5: 179/634 Loss: 0.158560
2023-01-04 04:37: Train Epoch 5: 183/634 Loss: 0.171060
2023-01-04 04:38: Train Epoch 5: 187/634 Loss: 0.209585
2023-01-04 04:39: Train Epoch 5: 191/634 Loss: 0.190580
2023-01-04 04:40: Train Epoch 5: 195/634 Loss: 0.193865
2023-01-04 04:41: Train Epoch 5: 199/634 Loss: 0.173391
2023-01-04 04:41: Train Epoch 5: 203/634 Loss: 0.183372
2023-01-04 04:42: Train Epoch 5: 207/634 Loss: 0.184786
2023-01-04 04:43: Train Epoch 5: 211/634 Loss: 0.161971
2023-01-04 04:44: Train Epoch 5: 215/634 Loss: 0.173671
2023-01-04 04:45: Train Epoch 5: 219/634 Loss: 0.173280
2023-01-04 04:46: Train Epoch 5: 223/634 Loss: 0.188357
2023-01-04 04:47: Train Epoch 5: 227/634 Loss: 0.185288
2023-01-04 04:47: Train Epoch 5: 231/634 Loss: 0.151418
2023-01-04 04:48: Train Epoch 5: 235/634 Loss: 0.181144
2023-01-04 04:49: Train Epoch 5: 239/634 Loss: 0.171126
2023-01-04 04:50: Train Epoch 5: 243/634 Loss: 0.179553
2023-01-04 04:51: Train Epoch 5: 247/634 Loss: 0.184324
2023-01-04 04:52: Train Epoch 5: 251/634 Loss: 0.181963
2023-01-04 04:53: Train Epoch 5: 255/634 Loss: 0.178356
2023-01-04 04:53: Train Epoch 5: 259/634 Loss: 0.192075
2023-01-04 04:54: Train Epoch 5: 263/634 Loss: 0.192705
2023-01-04 04:55: Train Epoch 5: 267/634 Loss: 0.205058
2023-01-04 04:56: Train Epoch 5: 271/634 Loss: 0.148167
2023-01-04 04:57: Train Epoch 5: 275/634 Loss: 0.174769
2023-01-04 04:58: Train Epoch 5: 279/634 Loss: 0.153642
2023-01-04 04:58: Train Epoch 5: 283/634 Loss: 0.188695
2023-01-04 04:59: Train Epoch 5: 287/634 Loss: 0.181109
2023-01-04 05:00: Train Epoch 5: 291/634 Loss: 0.186684
2023-01-04 05:01: Train Epoch 5: 295/634 Loss: 0.152177
2023-01-04 05:02: Train Epoch 5: 299/634 Loss: 0.180416
2023-01-04 05:03: Train Epoch 5: 303/634 Loss: 0.171628
2023-01-04 05:04: Train Epoch 5: 307/634 Loss: 0.179847
2023-01-04 05:04: Train Epoch 5: 311/634 Loss: 0.151151
2023-01-04 05:05: Train Epoch 5: 315/634 Loss: 0.173159
2023-01-04 05:06: Train Epoch 5: 319/634 Loss: 0.181877
2023-01-04 05:07: Train Epoch 5: 323/634 Loss: 0.184099
2023-01-04 05:08: Train Epoch 5: 327/634 Loss: 0.195863
2023-01-04 05:09: Train Epoch 5: 331/634 Loss: 0.178073
2023-01-04 05:09: Train Epoch 5: 335/634 Loss: 0.181674
2023-01-04 05:10: Train Epoch 5: 339/634 Loss: 0.182688
2023-01-04 05:11: Train Epoch 5: 343/634 Loss: 0.179562
2023-01-04 05:12: Train Epoch 5: 347/634 Loss: 0.172691
2023-01-04 05:12: Train Epoch 5: 351/634 Loss: 0.186208
2023-01-04 05:13: Train Epoch 5: 355/634 Loss: 0.197657
2023-01-04 05:14: Train Epoch 5: 359/634 Loss: 0.161131
2023-01-04 05:15: Train Epoch 5: 363/634 Loss: 0.162777
2023-01-04 05:16: Train Epoch 5: 367/634 Loss: 0.160290
2023-01-04 05:16: Train Epoch 5: 371/634 Loss: 0.192795
2023-01-04 05:17: Train Epoch 5: 375/634 Loss: 0.192197
2023-01-04 05:18: Train Epoch 5: 379/634 Loss: 0.157143
2023-01-04 05:19: Train Epoch 5: 383/634 Loss: 0.167722
2023-01-04 05:20: Train Epoch 5: 387/634 Loss: 0.177175
2023-01-04 05:21: Train Epoch 5: 391/634 Loss: 0.173093
2023-01-04 05:21: Train Epoch 5: 395/634 Loss: 0.186523
2023-01-04 05:22: Train Epoch 5: 399/634 Loss: 0.162502
2023-01-04 05:23: Train Epoch 5: 403/634 Loss: 0.174081
2023-01-04 05:24: Train Epoch 5: 407/634 Loss: 0.211245
2023-01-04 05:25: Train Epoch 5: 411/634 Loss: 0.211932
2023-01-04 05:26: Train Epoch 5: 415/634 Loss: 0.174225
2023-01-04 05:26: Train Epoch 5: 419/634 Loss: 0.174134
2023-01-04 05:27: Train Epoch 5: 423/634 Loss: 0.202265
2023-01-04 05:28: Train Epoch 5: 427/634 Loss: 0.169759
2023-01-04 05:29: Train Epoch 5: 431/634 Loss: 0.175896
2023-01-04 05:30: Train Epoch 5: 435/634 Loss: 0.143300
2023-01-04 05:31: Train Epoch 5: 439/634 Loss: 0.211211
2023-01-04 05:32: Train Epoch 5: 443/634 Loss: 0.164090
2023-01-04 05:32: Train Epoch 5: 447/634 Loss: 0.171425
2023-01-04 05:33: Train Epoch 5: 451/634 Loss: 0.194810
2023-01-04 05:34: Train Epoch 5: 455/634 Loss: 0.162622
2023-01-04 05:35: Train Epoch 5: 459/634 Loss: 0.178906
2023-01-04 05:36: Train Epoch 5: 463/634 Loss: 0.159751
2023-01-04 05:37: Train Epoch 5: 467/634 Loss: 0.160476
2023-01-04 05:37: Train Epoch 5: 471/634 Loss: 0.137306
2023-01-04 05:38: Train Epoch 5: 475/634 Loss: 0.175522
2023-01-04 05:39: Train Epoch 5: 479/634 Loss: 0.207359
2023-01-04 05:40: Train Epoch 5: 483/634 Loss: 0.172149
2023-01-04 05:41: Train Epoch 5: 487/634 Loss: 0.178004
2023-01-04 05:42: Train Epoch 5: 491/634 Loss: 0.161111
2023-01-04 05:42: Train Epoch 5: 495/634 Loss: 0.170114
2023-01-04 05:43: Train Epoch 5: 499/634 Loss: 0.178925
2023-01-04 05:44: Train Epoch 5: 503/634 Loss: 0.162856
2023-01-04 05:45: Train Epoch 5: 507/634 Loss: 0.150706
2023-01-04 05:46: Train Epoch 5: 511/634 Loss: 0.192439
2023-01-04 05:47: Train Epoch 5: 515/634 Loss: 0.169114
2023-01-04 05:48: Train Epoch 5: 519/634 Loss: 0.205633
2023-01-04 05:48: Train Epoch 5: 523/634 Loss: 0.194025
2023-01-04 05:49: Train Epoch 5: 527/634 Loss: 0.190790
2023-01-04 05:50: Train Epoch 5: 531/634 Loss: 0.179932
2023-01-04 05:51: Train Epoch 5: 535/634 Loss: 0.176018
2023-01-04 05:52: Train Epoch 5: 539/634 Loss: 0.186035
2023-01-04 05:53: Train Epoch 5: 543/634 Loss: 0.184527
2023-01-04 05:53: Train Epoch 5: 547/634 Loss: 0.198036
2023-01-04 05:54: Train Epoch 5: 551/634 Loss: 0.192968
2023-01-04 05:55: Train Epoch 5: 555/634 Loss: 0.212359
2023-01-04 05:56: Train Epoch 5: 559/634 Loss: 0.153310
2023-01-04 05:57: Train Epoch 5: 563/634 Loss: 0.215348
2023-01-04 05:58: Train Epoch 5: 567/634 Loss: 0.213489
2023-01-04 05:59: Train Epoch 5: 571/634 Loss: 0.171084
2023-01-04 05:59: Train Epoch 5: 575/634 Loss: 0.144755
2023-01-04 06:00: Train Epoch 5: 579/634 Loss: 0.185523
2023-01-04 06:01: Train Epoch 5: 583/634 Loss: 0.157206
2023-01-04 06:02: Train Epoch 5: 587/634 Loss: 0.153581
2023-01-04 06:03: Train Epoch 5: 591/634 Loss: 0.159268
2023-01-04 06:04: Train Epoch 5: 595/634 Loss: 0.177917
2023-01-04 06:04: Train Epoch 5: 599/634 Loss: 0.173099
2023-01-04 06:05: Train Epoch 5: 603/634 Loss: 0.184958
2023-01-04 06:06: Train Epoch 5: 607/634 Loss: 0.178056
2023-01-04 06:07: Train Epoch 5: 611/634 Loss: 0.154807
2023-01-04 06:08: Train Epoch 5: 615/634 Loss: 0.194534
2023-01-04 06:09: Train Epoch 5: 619/634 Loss: 0.169460
2023-01-04 06:10: Train Epoch 5: 623/634 Loss: 0.153607
2023-01-04 06:11: Train Epoch 5: 627/634 Loss: 0.235950
2023-01-04 06:11: Train Epoch 5: 631/634 Loss: 0.182476
2023-01-04 06:12: Train Epoch 5: 633/634 Loss: 0.084044
2023-01-04 06:12: **********Train Epoch 5: averaged Loss: 0.178607 
2023-01-04 06:12: 
Epoch time elapsed: 8029.565058708191

2023-01-04 06:15: 
 metrics validation: {'precision': 0.6364634816035145, 'recall': 0.8915384615384615, 'f1-score': 0.742710669657161, 'support': 1300, 'AUC': 0.885401479289941, 'AUCPR': 0.778210142128615, 'TP': 1159, 'FP': 662, 'TN': 1938, 'FN': 141} 

2023-01-04 06:15: **********Val Epoch 5: average Loss: 0.220658
2023-01-04 06:18: 
 Testing metrics {'precision': 0.805528134254689, 'recall': 0.6644951140065146, 'f1-score': 0.7282463186077645, 'support': 1228, 'AUC': 0.9025523480355229, 'AUCPR': 0.8306377294529738, 'TP': 816, 'FP': 197, 'TN': 2259, 'FN': 412} 

2023-01-04 06:28: 
 Testing metrics {'precision': 0.8705765899529819, 'recall': 0.7982754708418425, 'f1-score': 0.8328598484848484, 'support': 4407, 'AUC': 0.959029946427309, 'AUCPR': 0.9151686753359707, 'TP': 3518, 'FP': 523, 'TN': 8291, 'FN': 889} 

2023-01-04 06:29: Train Epoch 6: 3/634 Loss: 0.208477
2023-01-04 06:30: Train Epoch 6: 7/634 Loss: 0.179578
2023-01-04 06:31: Train Epoch 6: 11/634 Loss: 0.212048
2023-01-04 06:32: Train Epoch 6: 15/634 Loss: 0.170156
2023-01-04 06:32: Train Epoch 6: 19/634 Loss: 0.194190
2023-01-04 06:33: Train Epoch 6: 23/634 Loss: 0.174461
2023-01-04 06:34: Train Epoch 6: 27/634 Loss: 0.199756
2023-01-04 06:35: Train Epoch 6: 31/634 Loss: 0.173526
2023-01-04 06:36: Train Epoch 6: 35/634 Loss: 0.224934
2023-01-04 06:37: Train Epoch 6: 39/634 Loss: 0.190740
2023-01-04 06:37: Train Epoch 6: 43/634 Loss: 0.148852
2023-01-04 06:38: Train Epoch 6: 47/634 Loss: 0.169109
2023-01-04 06:39: Train Epoch 6: 51/634 Loss: 0.196288
2023-01-04 06:40: Train Epoch 6: 55/634 Loss: 0.169834
2023-01-04 06:41: Train Epoch 6: 59/634 Loss: 0.180033
2023-01-04 06:42: Train Epoch 6: 63/634 Loss: 0.167390
2023-01-04 06:43: Train Epoch 6: 67/634 Loss: 0.172214
2023-01-04 06:43: Train Epoch 6: 71/634 Loss: 0.186499
2023-01-04 06:44: Train Epoch 6: 75/634 Loss: 0.155992
2023-01-04 06:45: Train Epoch 6: 79/634 Loss: 0.169939
2023-01-04 06:46: Train Epoch 6: 83/634 Loss: 0.171575
2023-01-04 06:47: Train Epoch 6: 87/634 Loss: 0.189205
2023-01-04 06:48: Train Epoch 6: 91/634 Loss: 0.191777
2023-01-04 06:48: Train Epoch 6: 95/634 Loss: 0.169856
2023-01-04 06:49: Train Epoch 6: 99/634 Loss: 0.179320
2023-01-04 06:50: Train Epoch 6: 103/634 Loss: 0.182685
2023-01-04 06:51: Train Epoch 6: 107/634 Loss: 0.164959
2023-01-04 06:52: Train Epoch 6: 111/634 Loss: 0.164222
2023-01-04 06:53: Train Epoch 6: 115/634 Loss: 0.177931
2023-01-04 06:54: Train Epoch 6: 119/634 Loss: 0.222136
2023-01-04 06:54: Train Epoch 6: 123/634 Loss: 0.154765
2023-01-04 06:55: Train Epoch 6: 127/634 Loss: 0.160144
2023-01-04 06:56: Train Epoch 6: 131/634 Loss: 0.166458
2023-01-04 06:57: Train Epoch 6: 135/634 Loss: 0.174277
2023-01-04 06:58: Train Epoch 6: 139/634 Loss: 0.173237
2023-01-04 06:59: Train Epoch 6: 143/634 Loss: 0.231878
2023-01-04 07:00: Train Epoch 6: 147/634 Loss: 0.151161
2023-01-04 07:00: Train Epoch 6: 151/634 Loss: 0.161012
2023-01-04 07:01: Train Epoch 6: 155/634 Loss: 0.168884
2023-01-04 07:02: Train Epoch 6: 159/634 Loss: 0.184114
2023-01-04 07:03: Train Epoch 6: 163/634 Loss: 0.193245
2023-01-04 07:04: Train Epoch 6: 167/634 Loss: 0.170273
2023-01-04 07:05: Train Epoch 6: 171/634 Loss: 0.218150
2023-01-04 07:06: Train Epoch 6: 175/634 Loss: 0.176858
2023-01-04 07:06: Train Epoch 6: 179/634 Loss: 0.193200
2023-01-04 07:07: Train Epoch 6: 183/634 Loss: 0.176643
2023-01-04 07:08: Train Epoch 6: 187/634 Loss: 0.151934
2023-01-04 07:09: Train Epoch 6: 191/634 Loss: 0.162325
2023-01-04 07:10: Train Epoch 6: 195/634 Loss: 0.174575
2023-01-04 07:11: Train Epoch 6: 199/634 Loss: 0.183896
2023-01-04 07:12: Train Epoch 6: 203/634 Loss: 0.182600
2023-01-04 07:12: Train Epoch 6: 207/634 Loss: 0.183237
2023-01-04 07:13: Train Epoch 6: 211/634 Loss: 0.183724
2023-01-04 07:14: Train Epoch 6: 215/634 Loss: 0.186007
2023-01-04 07:15: Train Epoch 6: 219/634 Loss: 0.139228
2023-01-04 07:16: Train Epoch 6: 223/634 Loss: 0.183877
2023-01-04 07:17: Train Epoch 6: 227/634 Loss: 0.189107
2023-01-04 07:17: Train Epoch 6: 231/634 Loss: 0.204241
2023-01-04 07:18: Train Epoch 6: 235/634 Loss: 0.164998
2023-01-04 07:19: Train Epoch 6: 239/634 Loss: 0.201804
2023-01-04 07:20: Train Epoch 6: 243/634 Loss: 0.188924
2023-01-04 07:21: Train Epoch 6: 247/634 Loss: 0.174302
2023-01-04 07:22: Train Epoch 6: 251/634 Loss: 0.178256
2023-01-04 07:23: Train Epoch 6: 255/634 Loss: 0.178508
2023-01-04 07:23: Train Epoch 6: 259/634 Loss: 0.176117
2023-01-04 07:24: Train Epoch 6: 263/634 Loss: 0.191365
2023-01-04 07:25: Train Epoch 6: 267/634 Loss: 0.170037
2023-01-04 07:26: Train Epoch 6: 271/634 Loss: 0.191879
2023-01-04 07:27: Train Epoch 6: 275/634 Loss: 0.174546
2023-01-04 07:28: Train Epoch 6: 279/634 Loss: 0.222501
2023-01-04 07:29: Train Epoch 6: 283/634 Loss: 0.188970
2023-01-04 07:30: Train Epoch 6: 287/634 Loss: 0.186515
2023-01-04 07:30: Train Epoch 6: 291/634 Loss: 0.177983
2023-01-04 07:31: Train Epoch 6: 295/634 Loss: 0.197845
2023-01-04 07:32: Train Epoch 6: 299/634 Loss: 0.175206
2023-01-04 07:33: Train Epoch 6: 303/634 Loss: 0.197220
2023-01-04 07:34: Train Epoch 6: 307/634 Loss: 0.164308
2023-01-04 07:35: Train Epoch 6: 311/634 Loss: 0.179727
2023-01-04 07:35: Train Epoch 6: 315/634 Loss: 0.183348
2023-01-04 07:36: Train Epoch 6: 319/634 Loss: 0.194613
2023-01-04 07:37: Train Epoch 6: 323/634 Loss: 0.181477
2023-01-04 07:38: Train Epoch 6: 327/634 Loss: 0.182325
2023-01-04 07:39: Train Epoch 6: 331/634 Loss: 0.196315
2023-01-04 07:40: Train Epoch 6: 335/634 Loss: 0.212139
2023-01-04 07:40: Train Epoch 6: 339/634 Loss: 0.173662
2023-01-04 07:41: Train Epoch 6: 343/634 Loss: 0.166952
2023-01-04 07:42: Train Epoch 6: 347/634 Loss: 0.194432
2023-01-04 07:43: Train Epoch 6: 351/634 Loss: 0.160994
2023-01-04 07:44: Train Epoch 6: 355/634 Loss: 0.165301
2023-01-04 07:45: Train Epoch 6: 359/634 Loss: 0.183341
2023-01-04 07:46: Train Epoch 6: 363/634 Loss: 0.173032
2023-01-04 07:46: Train Epoch 6: 367/634 Loss: 0.148713
2023-01-04 07:47: Train Epoch 6: 371/634 Loss: 0.211316
2023-01-04 07:48: Train Epoch 6: 375/634 Loss: 0.161833
2023-01-04 07:49: Train Epoch 6: 379/634 Loss: 0.163343
2023-01-04 07:50: Train Epoch 6: 383/634 Loss: 0.165954
2023-01-04 07:51: Train Epoch 6: 387/634 Loss: 0.163743
2023-01-04 07:52: Train Epoch 6: 391/634 Loss: 0.221386
2023-01-04 07:52: Train Epoch 6: 395/634 Loss: 0.171888
2023-01-04 07:53: Train Epoch 6: 399/634 Loss: 0.164392
2023-01-04 07:54: Train Epoch 6: 403/634 Loss: 0.186523
2023-01-04 07:55: Train Epoch 6: 407/634 Loss: 0.179737
2023-01-04 07:56: Train Epoch 6: 411/634 Loss: 0.170316
2023-01-04 07:57: Train Epoch 6: 415/634 Loss: 0.165901
2023-01-04 07:58: Train Epoch 6: 419/634 Loss: 0.175981
2023-01-04 07:58: Train Epoch 6: 423/634 Loss: 0.181956
2023-01-04 07:59: Train Epoch 6: 427/634 Loss: 0.212037
2023-01-04 08:00: Train Epoch 6: 431/634 Loss: 0.192697
2023-01-04 08:01: Train Epoch 6: 435/634 Loss: 0.186646
2023-01-04 08:02: Train Epoch 6: 439/634 Loss: 0.154805
2023-01-04 08:03: Train Epoch 6: 443/634 Loss: 0.201986
2023-01-04 08:03: Train Epoch 6: 447/634 Loss: 0.177002
2023-01-04 08:04: Train Epoch 6: 451/634 Loss: 0.191953
2023-01-04 08:05: Train Epoch 6: 455/634 Loss: 0.189115
2023-01-04 08:06: Train Epoch 6: 459/634 Loss: 0.150693
2023-01-04 08:07: Train Epoch 6: 463/634 Loss: 0.185767
2023-01-04 08:08: Train Epoch 6: 467/634 Loss: 0.184879
2023-01-04 08:09: Train Epoch 6: 471/634 Loss: 0.218158
2023-01-04 08:10: Train Epoch 6: 475/634 Loss: 0.158942
2023-01-04 08:10: Train Epoch 6: 479/634 Loss: 0.168698
2023-01-04 08:11: Train Epoch 6: 483/634 Loss: 0.199984
2023-01-04 08:12: Train Epoch 6: 487/634 Loss: 0.196962
2023-01-04 08:13: Train Epoch 6: 491/634 Loss: 0.182457
2023-01-04 08:14: Train Epoch 6: 495/634 Loss: 0.194340
2023-01-04 08:15: Train Epoch 6: 499/634 Loss: 0.242046
2023-01-04 08:15: Train Epoch 6: 503/634 Loss: 0.184186
2023-01-04 08:16: Train Epoch 6: 507/634 Loss: 0.177172
2023-01-04 08:17: Train Epoch 6: 511/634 Loss: 0.166398
2023-01-04 08:18: Train Epoch 6: 515/634 Loss: 0.182819
2023-01-04 08:19: Train Epoch 6: 519/634 Loss: 0.183113
2023-01-04 08:19: Train Epoch 6: 523/634 Loss: 0.182796
2023-01-04 08:20: Train Epoch 6: 527/634 Loss: 0.172982
2023-01-04 08:21: Train Epoch 6: 531/634 Loss: 0.186861
2023-01-04 08:22: Train Epoch 6: 535/634 Loss: 0.212333
2023-01-04 08:23: Train Epoch 6: 539/634 Loss: 0.164675
2023-01-04 08:24: Train Epoch 6: 543/634 Loss: 0.176639
2023-01-04 08:25: Train Epoch 6: 547/634 Loss: 0.149761
2023-01-04 08:25: Train Epoch 6: 551/634 Loss: 0.147183
2023-01-04 08:26: Train Epoch 6: 555/634 Loss: 0.188931
2023-01-04 08:27: Train Epoch 6: 559/634 Loss: 0.186285
2023-01-04 08:28: Train Epoch 6: 563/634 Loss: 0.176955
2023-01-04 08:29: Train Epoch 6: 567/634 Loss: 0.154107
2023-01-04 08:30: Train Epoch 6: 571/634 Loss: 0.196937
2023-01-04 08:30: Train Epoch 6: 575/634 Loss: 0.167049
2023-01-04 08:31: Train Epoch 6: 579/634 Loss: 0.178776
2023-01-04 08:32: Train Epoch 6: 583/634 Loss: 0.168922
2023-01-04 08:33: Train Epoch 6: 587/634 Loss: 0.182109
2023-01-04 08:34: Train Epoch 6: 591/634 Loss: 0.167678
2023-01-04 08:35: Train Epoch 6: 595/634 Loss: 0.174501
2023-01-04 08:36: Train Epoch 6: 599/634 Loss: 0.172796
2023-01-04 08:36: Train Epoch 6: 603/634 Loss: 0.177830
2023-01-04 08:37: Train Epoch 6: 607/634 Loss: 0.156445
2023-01-04 08:38: Train Epoch 6: 611/634 Loss: 0.158943
2023-01-04 08:39: Train Epoch 6: 615/634 Loss: 0.235171
2023-01-04 08:40: Train Epoch 6: 619/634 Loss: 0.188002
2023-01-04 08:40: Train Epoch 6: 623/634 Loss: 0.173350
2023-01-04 08:41: Train Epoch 6: 627/634 Loss: 0.179624
2023-01-04 08:42: Train Epoch 6: 631/634 Loss: 0.200418
2023-01-04 08:42: Train Epoch 6: 633/634 Loss: 0.076985
2023-01-04 08:42: **********Train Epoch 6: averaged Loss: 0.180230 
2023-01-04 08:42: 
Epoch time elapsed: 8046.710968732834

2023-01-04 08:45: 
 metrics validation: {'precision': 0.8585858585858586, 'recall': 0.19615384615384615, 'f1-score': 0.319348778960551, 'support': 1300, 'AUC': 0.8964207100591717, 'AUCPR': 0.7769715840348117, 'TP': 255, 'FP': 42, 'TN': 2558, 'FN': 1045} 

2023-01-04 08:45: **********Val Epoch 6: average Loss: 0.276491
2023-01-04 08:48: 
 Testing metrics {'precision': 0.805528134254689, 'recall': 0.6644951140065146, 'f1-score': 0.7282463186077645, 'support': 1228, 'AUC': 0.9025523480355229, 'AUCPR': 0.8306377294529738, 'TP': 816, 'FP': 197, 'TN': 2259, 'FN': 412} 

2023-01-04 08:59: 
 Testing metrics {'precision': 0.8705765899529819, 'recall': 0.7982754708418425, 'f1-score': 0.8328598484848484, 'support': 4407, 'AUC': 0.959029946427309, 'AUCPR': 0.9151686753359707, 'TP': 3518, 'FP': 523, 'TN': 8291, 'FN': 889} 

2023-01-04 09:00: Train Epoch 7: 3/634 Loss: 0.190519
2023-01-04 09:00: Train Epoch 7: 7/634 Loss: 0.232322
2023-01-04 09:01: Train Epoch 7: 11/634 Loss: 0.172596
2023-01-04 09:02: Train Epoch 7: 15/634 Loss: 0.196490
2023-01-04 09:03: Train Epoch 7: 19/634 Loss: 0.164662
2023-01-04 09:04: Train Epoch 7: 23/634 Loss: 0.185505
2023-01-04 09:05: Train Epoch 7: 27/634 Loss: 0.187477
2023-01-04 09:06: Train Epoch 7: 31/634 Loss: 0.171757
2023-01-04 09:06: Train Epoch 7: 35/634 Loss: 0.187776
2023-01-04 09:07: Train Epoch 7: 39/634 Loss: 0.186422
2023-01-04 09:08: Train Epoch 7: 43/634 Loss: 0.159407
2023-01-04 09:09: Train Epoch 7: 47/634 Loss: 0.208055
2023-01-04 09:10: Train Epoch 7: 51/634 Loss: 0.189138
2023-01-04 09:11: Train Epoch 7: 55/634 Loss: 0.203613
2023-01-04 09:12: Train Epoch 7: 59/634 Loss: 0.199802
2023-01-04 09:12: Train Epoch 7: 63/634 Loss: 0.168148
2023-01-04 09:13: Train Epoch 7: 67/634 Loss: 0.175315
2023-01-04 09:14: Train Epoch 7: 71/634 Loss: 0.187766
2023-01-04 09:15: Train Epoch 7: 75/634 Loss: 0.176095
2023-01-04 09:16: Train Epoch 7: 79/634 Loss: 0.159865
2023-01-04 09:17: Train Epoch 7: 83/634 Loss: 0.196557
2023-01-04 09:18: Train Epoch 7: 87/634 Loss: 0.177389
2023-01-04 09:18: Train Epoch 7: 91/634 Loss: 0.188481
2023-01-04 09:19: Train Epoch 7: 95/634 Loss: 0.197993
2023-01-04 09:20: Train Epoch 7: 99/634 Loss: 0.165626
2023-01-04 09:21: Train Epoch 7: 103/634 Loss: 0.169680
2023-01-04 09:22: Train Epoch 7: 107/634 Loss: 0.182431
2023-01-04 09:23: Train Epoch 7: 111/634 Loss: 0.150386
2023-01-04 09:24: Train Epoch 7: 115/634 Loss: 0.185371
2023-01-04 09:24: Train Epoch 7: 119/634 Loss: 0.203290
2023-01-04 09:25: Train Epoch 7: 123/634 Loss: 0.165550
2023-01-04 09:26: Train Epoch 7: 127/634 Loss: 0.184880
2023-01-04 09:27: Train Epoch 7: 131/634 Loss: 0.175890
2023-01-04 09:28: Train Epoch 7: 135/634 Loss: 0.160805
2023-01-04 09:29: Train Epoch 7: 139/634 Loss: 0.182658
2023-01-04 09:29: Train Epoch 7: 143/634 Loss: 0.212992
2023-01-04 09:30: Train Epoch 7: 147/634 Loss: 0.191183
2023-01-04 09:31: Train Epoch 7: 151/634 Loss: 0.221865
2023-01-04 09:32: Train Epoch 7: 155/634 Loss: 0.214322
2023-01-04 09:33: Train Epoch 7: 159/634 Loss: 0.174537
2023-01-04 09:34: Train Epoch 7: 163/634 Loss: 0.196584
2023-01-04 09:35: Train Epoch 7: 167/634 Loss: 0.187734
2023-01-04 09:35: Train Epoch 7: 171/634 Loss: 0.202467
2023-01-04 09:36: Train Epoch 7: 175/634 Loss: 0.176836
2023-01-04 09:37: Train Epoch 7: 179/634 Loss: 0.160412
2023-01-04 09:38: Train Epoch 7: 183/634 Loss: 0.196154
2023-01-04 09:39: Train Epoch 7: 187/634 Loss: 0.170115
2023-01-04 09:40: Train Epoch 7: 191/634 Loss: 0.169143
2023-01-04 09:41: Train Epoch 7: 195/634 Loss: 0.206745
2023-01-04 09:42: Train Epoch 7: 199/634 Loss: 0.181807
2023-01-04 09:42: Train Epoch 7: 203/634 Loss: 0.178808
2023-01-04 09:43: Train Epoch 7: 207/634 Loss: 0.190007
2023-01-04 09:44: Train Epoch 7: 211/634 Loss: 0.173547
2023-01-04 09:45: Train Epoch 7: 215/634 Loss: 0.204274
2023-01-04 09:46: Train Epoch 7: 219/634 Loss: 0.180784
2023-01-04 09:47: Train Epoch 7: 223/634 Loss: 0.198511
2023-01-04 09:47: Train Epoch 7: 227/634 Loss: 0.160209
2023-01-04 09:48: Train Epoch 7: 231/634 Loss: 0.156962
2023-01-04 09:49: Train Epoch 7: 235/634 Loss: 0.153524
2023-01-04 09:50: Train Epoch 7: 239/634 Loss: 0.204829
2023-01-04 09:51: Train Epoch 7: 243/634 Loss: 0.170908
2023-01-04 09:52: Train Epoch 7: 247/634 Loss: 0.151996
2023-01-04 09:53: Train Epoch 7: 251/634 Loss: 0.179540
2023-01-04 09:54: Train Epoch 7: 255/634 Loss: 0.181833
2023-01-04 09:54: Train Epoch 7: 259/634 Loss: 0.178989
2023-01-04 09:55: Train Epoch 7: 263/634 Loss: 0.192856
2023-01-04 09:56: Train Epoch 7: 267/634 Loss: 0.141083
2023-01-04 09:57: Train Epoch 7: 271/634 Loss: 0.164556
2023-01-04 09:58: Train Epoch 7: 275/634 Loss: 0.168390
2023-01-04 09:59: Train Epoch 7: 279/634 Loss: 0.185771
2023-01-04 10:00: Train Epoch 7: 283/634 Loss: 0.163512
2023-01-04 10:00: Train Epoch 7: 287/634 Loss: 0.175643
2023-01-04 10:01: Train Epoch 7: 291/634 Loss: 0.162474
2023-01-04 10:02: Train Epoch 7: 295/634 Loss: 0.180664
2023-01-04 10:03: Train Epoch 7: 299/634 Loss: 0.165721
2023-01-04 10:04: Train Epoch 7: 303/634 Loss: 0.166136
2023-01-04 10:05: Train Epoch 7: 307/634 Loss: 0.182735
2023-01-04 10:05: Train Epoch 7: 311/634 Loss: 0.180300
2023-01-04 10:06: Train Epoch 7: 315/634 Loss: 0.172816
2023-01-04 10:07: Train Epoch 7: 319/634 Loss: 0.157555
2023-01-04 10:08: Train Epoch 7: 323/634 Loss: 0.169108
2023-01-04 10:09: Train Epoch 7: 327/634 Loss: 0.184493
2023-01-04 10:10: Train Epoch 7: 331/634 Loss: 0.171392
2023-01-04 10:10: Train Epoch 7: 335/634 Loss: 0.177983
2023-01-04 10:11: Train Epoch 7: 339/634 Loss: 0.181766
2023-01-04 10:12: Train Epoch 7: 343/634 Loss: 0.191477
2023-01-04 10:13: Train Epoch 7: 347/634 Loss: 0.197282
2023-01-04 10:14: Train Epoch 7: 351/634 Loss: 0.180911
2023-01-04 10:15: Train Epoch 7: 355/634 Loss: 0.181551
2023-01-04 10:16: Train Epoch 7: 359/634 Loss: 0.203297
2023-01-04 10:16: Train Epoch 7: 363/634 Loss: 0.194264
2023-01-04 10:17: Train Epoch 7: 367/634 Loss: 0.164932
2023-01-04 10:18: Train Epoch 7: 371/634 Loss: 0.140976
2023-01-04 10:19: Train Epoch 7: 375/634 Loss: 0.174151
2023-01-04 10:20: Train Epoch 7: 379/634 Loss: 0.191814
2023-01-04 10:21: Train Epoch 7: 383/634 Loss: 0.168557
2023-01-04 10:22: Train Epoch 7: 387/634 Loss: 0.177597
2023-01-04 10:22: Train Epoch 7: 391/634 Loss: 0.176256
2023-01-04 10:23: Train Epoch 7: 395/634 Loss: 0.157504
2023-01-04 10:24: Train Epoch 7: 399/634 Loss: 0.187389
2023-01-04 10:25: Train Epoch 7: 403/634 Loss: 0.154896
2023-01-04 10:26: Train Epoch 7: 407/634 Loss: 0.157465
2023-01-04 10:27: Train Epoch 7: 411/634 Loss: 0.172969
2023-01-04 10:28: Train Epoch 7: 415/634 Loss: 0.182176
2023-01-04 10:28: Train Epoch 7: 419/634 Loss: 0.160347
2023-01-04 10:29: Train Epoch 7: 423/634 Loss: 0.174599
2023-01-04 10:30: Train Epoch 7: 427/634 Loss: 0.177807
2023-01-04 10:31: Train Epoch 7: 431/634 Loss: 0.199946
2023-01-04 10:32: Train Epoch 7: 435/634 Loss: 0.192738
2023-01-04 10:33: Train Epoch 7: 439/634 Loss: 0.184197
2023-01-04 10:34: Train Epoch 7: 443/634 Loss: 0.170308
2023-01-04 10:34: Train Epoch 7: 447/634 Loss: 0.196856
2023-01-04 10:35: Train Epoch 7: 451/634 Loss: 0.174168
2023-01-04 10:36: Train Epoch 7: 455/634 Loss: 0.178754
2023-01-04 10:37: Train Epoch 7: 459/634 Loss: 0.167418
2023-01-04 10:38: Train Epoch 7: 463/634 Loss: 0.148462
2023-01-04 10:39: Train Epoch 7: 467/634 Loss: 0.162994
2023-01-04 10:39: Train Epoch 7: 471/634 Loss: 0.174027
2023-01-04 10:40: Train Epoch 7: 475/634 Loss: 0.179693
2023-01-04 10:41: Train Epoch 7: 479/634 Loss: 0.179636
2023-01-04 10:42: Train Epoch 7: 483/634 Loss: 0.194059
2023-01-04 10:43: Train Epoch 7: 487/634 Loss: 0.238505
2023-01-04 10:44: Train Epoch 7: 491/634 Loss: 0.188241
2023-01-04 10:45: Train Epoch 7: 495/634 Loss: 0.199472
2023-01-04 10:45: Train Epoch 7: 499/634 Loss: 0.201323
2023-01-04 10:46: Train Epoch 7: 503/634 Loss: 0.181838
2023-01-04 10:47: Train Epoch 7: 507/634 Loss: 0.169996
2023-01-04 10:48: Train Epoch 7: 511/634 Loss: 0.173686
2023-01-04 10:49: Train Epoch 7: 515/634 Loss: 0.190434
2023-01-04 10:50: Train Epoch 7: 519/634 Loss: 0.175462
2023-01-04 10:51: Train Epoch 7: 523/634 Loss: 0.190183
2023-01-04 10:51: Train Epoch 7: 527/634 Loss: 0.189036
2023-01-04 10:52: Train Epoch 7: 531/634 Loss: 0.170197
2023-01-04 10:53: Train Epoch 7: 535/634 Loss: 0.188022
2023-01-04 10:54: Train Epoch 7: 539/634 Loss: 0.192184
2023-01-04 10:55: Train Epoch 7: 543/634 Loss: 0.192099
2023-01-04 10:56: Train Epoch 7: 547/634 Loss: 0.169527
2023-01-04 10:57: Train Epoch 7: 551/634 Loss: 0.155811
2023-01-04 10:58: Train Epoch 7: 555/634 Loss: 0.185761
2023-01-04 10:58: Train Epoch 7: 559/634 Loss: 0.159821
2023-01-04 10:59: Train Epoch 7: 563/634 Loss: 0.199298
2023-01-04 11:00: Train Epoch 7: 567/634 Loss: 0.171467
2023-01-04 11:01: Train Epoch 7: 571/634 Loss: 0.171619
2023-01-04 11:02: Train Epoch 7: 575/634 Loss: 0.171252
2023-01-04 11:03: Train Epoch 7: 579/634 Loss: 0.166436
2023-01-04 11:03: Train Epoch 7: 583/634 Loss: 0.187428
2023-01-04 11:04: Train Epoch 7: 587/634 Loss: 0.168362
2023-01-04 11:05: Train Epoch 7: 591/634 Loss: 0.210108
2023-01-04 11:06: Train Epoch 7: 595/634 Loss: 0.161790
2023-01-04 11:07: Train Epoch 7: 599/634 Loss: 0.173315
2023-01-04 11:08: Train Epoch 7: 603/634 Loss: 0.180742
2023-01-04 11:09: Train Epoch 7: 607/634 Loss: 0.157601
2023-01-04 11:09: Train Epoch 7: 611/634 Loss: 0.186087
2023-01-04 11:10: Train Epoch 7: 615/634 Loss: 0.184209
2023-01-04 11:11: Train Epoch 7: 619/634 Loss: 0.171133
2023-01-04 11:12: Train Epoch 7: 623/634 Loss: 0.187868
2023-01-04 11:13: Train Epoch 7: 627/634 Loss: 0.178239
2023-01-04 11:14: Train Epoch 7: 631/634 Loss: 0.171762
2023-01-04 11:14: Train Epoch 7: 633/634 Loss: 0.059938
2023-01-04 11:14: **********Train Epoch 7: averaged Loss: 0.179270 
2023-01-04 11:14: 
Epoch time elapsed: 8110.319520711899

2023-01-04 11:17: 
 metrics validation: {'precision': 0.7854545454545454, 'recall': 0.49846153846153846, 'f1-score': 0.6098823529411764, 'support': 1300, 'AUC': 0.891939349112426, 'AUCPR': 0.7829555667698628, 'TP': 648, 'FP': 177, 'TN': 2423, 'FN': 652} 

2023-01-04 11:17: **********Val Epoch 7: average Loss: 0.201032
2023-01-04 11:20: 
 Testing metrics {'precision': 0.805528134254689, 'recall': 0.6644951140065146, 'f1-score': 0.7282463186077645, 'support': 1228, 'AUC': 0.9025523480355229, 'AUCPR': 0.8306377294529738, 'TP': 816, 'FP': 197, 'TN': 2259, 'FN': 412} 

2023-01-04 11:30: 
 Testing metrics {'precision': 0.8705765899529819, 'recall': 0.7982754708418425, 'f1-score': 0.8328598484848484, 'support': 4407, 'AUC': 0.959029946427309, 'AUCPR': 0.9151686753359707, 'TP': 3518, 'FP': 523, 'TN': 8291, 'FN': 889} 

2023-01-04 11:31: Train Epoch 8: 3/634 Loss: 0.187150
2023-01-04 11:32: Train Epoch 8: 7/634 Loss: 0.181999
2023-01-04 11:33: Train Epoch 8: 11/634 Loss: 0.185324
2023-01-04 11:34: Train Epoch 8: 15/634 Loss: 0.177158
2023-01-04 11:35: Train Epoch 8: 19/634 Loss: 0.172972
2023-01-04 11:35: Train Epoch 8: 23/634 Loss: 0.176743
2023-01-04 11:36: Train Epoch 8: 27/634 Loss: 0.185564
2023-01-04 11:37: Train Epoch 8: 31/634 Loss: 0.188031
2023-01-04 11:38: Train Epoch 8: 35/634 Loss: 0.204889
2023-01-04 11:39: Train Epoch 8: 39/634 Loss: 0.186886
2023-01-04 11:40: Train Epoch 8: 43/634 Loss: 0.185065
2023-01-04 11:41: Train Epoch 8: 47/634 Loss: 0.215359
2023-01-04 11:41: Train Epoch 8: 51/634 Loss: 0.195281
2023-01-04 11:42: Train Epoch 8: 55/634 Loss: 0.163233
2023-01-04 11:43: Train Epoch 8: 59/634 Loss: 0.198359
2023-01-04 11:44: Train Epoch 8: 63/634 Loss: 0.197195
2023-01-04 11:45: Train Epoch 8: 67/634 Loss: 0.179533
2023-01-04 11:46: Train Epoch 8: 71/634 Loss: 0.192726
2023-01-04 11:47: Train Epoch 8: 75/634 Loss: 0.161058
2023-01-04 11:47: Train Epoch 8: 79/634 Loss: 0.171821
2023-01-04 11:48: Train Epoch 8: 83/634 Loss: 0.184954
2023-01-04 11:49: Train Epoch 8: 87/634 Loss: 0.192865
2023-01-04 11:50: Train Epoch 8: 91/634 Loss: 0.161390
2023-01-04 11:51: Train Epoch 8: 95/634 Loss: 0.183254
2023-01-04 11:52: Train Epoch 8: 99/634 Loss: 0.176048
2023-01-04 11:53: Train Epoch 8: 103/634 Loss: 0.165674
2023-01-04 11:53: Train Epoch 8: 107/634 Loss: 0.162616
2023-01-04 11:54: Train Epoch 8: 111/634 Loss: 0.161352
2023-01-04 11:55: Train Epoch 8: 115/634 Loss: 0.175892
2023-01-04 11:56: Train Epoch 8: 119/634 Loss: 0.219186
2023-01-04 11:57: Train Epoch 8: 123/634 Loss: 0.181445
2023-01-04 11:58: Train Epoch 8: 127/634 Loss: 0.183594
2023-01-04 11:58: Train Epoch 8: 131/634 Loss: 0.204603
2023-01-04 11:59: Train Epoch 8: 135/634 Loss: 0.179905
2023-01-04 12:00: Train Epoch 8: 139/634 Loss: 0.212600
2023-01-04 12:01: Train Epoch 8: 143/634 Loss: 0.179718
2023-01-04 12:02: Train Epoch 8: 147/634 Loss: 0.165819
2023-01-04 12:03: Train Epoch 8: 151/634 Loss: 0.189340
2023-01-04 12:04: Train Epoch 8: 155/634 Loss: 0.181287
2023-01-04 12:05: Train Epoch 8: 159/634 Loss: 0.192338
2023-01-04 12:05: Train Epoch 8: 163/634 Loss: 0.179387
2023-01-04 12:06: Train Epoch 8: 167/634 Loss: 0.191467
2023-01-04 12:07: Train Epoch 8: 171/634 Loss: 0.195271
2023-01-04 12:08: Train Epoch 8: 175/634 Loss: 0.168421
2023-01-04 12:09: Train Epoch 8: 179/634 Loss: 0.161377
2023-01-04 12:10: Train Epoch 8: 183/634 Loss: 0.167743
2023-01-04 12:11: Train Epoch 8: 187/634 Loss: 0.180015
2023-01-04 12:11: Train Epoch 8: 191/634 Loss: 0.173669
2023-01-04 12:12: Train Epoch 8: 195/634 Loss: 0.173825
2023-01-04 12:13: Train Epoch 8: 199/634 Loss: 0.208928
2023-01-04 12:14: Train Epoch 8: 203/634 Loss: 0.179460
2023-01-04 12:15: Train Epoch 8: 207/634 Loss: 0.191152
2023-01-04 12:16: Train Epoch 8: 211/634 Loss: 0.170417
2023-01-04 12:16: Train Epoch 8: 215/634 Loss: 0.186961
2023-01-04 12:17: Train Epoch 8: 219/634 Loss: 0.190029
2023-01-04 12:18: Train Epoch 8: 223/634 Loss: 0.176400
2023-01-04 12:19: Train Epoch 8: 227/634 Loss: 0.185423
2023-01-04 12:20: Train Epoch 8: 231/634 Loss: 0.158952
2023-01-04 12:21: Train Epoch 8: 235/634 Loss: 0.172171
2023-01-04 12:22: Train Epoch 8: 239/634 Loss: 0.213214
2023-01-04 12:22: Train Epoch 8: 243/634 Loss: 0.200210
2023-01-04 12:23: Train Epoch 8: 247/634 Loss: 0.185602
2023-01-04 12:24: Train Epoch 8: 251/634 Loss: 0.189716
2023-01-04 12:25: Train Epoch 8: 255/634 Loss: 0.181103
2023-01-04 12:26: Train Epoch 8: 259/634 Loss: 0.159790
2023-01-04 12:27: Train Epoch 8: 263/634 Loss: 0.167364
2023-01-04 12:28: Train Epoch 8: 267/634 Loss: 0.177975
2023-01-04 12:28: Train Epoch 8: 271/634 Loss: 0.221490
2023-01-04 12:29: Train Epoch 8: 275/634 Loss: 0.202154
2023-01-04 12:30: Train Epoch 8: 279/634 Loss: 0.202777
2023-01-04 12:31: Train Epoch 8: 283/634 Loss: 0.192097
2023-01-04 12:32: Train Epoch 8: 287/634 Loss: 0.164918
2023-01-04 12:33: Train Epoch 8: 291/634 Loss: 0.176325
2023-01-04 12:34: Train Epoch 8: 295/634 Loss: 0.167377
2023-01-04 12:34: Train Epoch 8: 299/634 Loss: 0.182064
2023-01-04 12:35: Train Epoch 8: 303/634 Loss: 0.163407
2023-01-04 12:36: Train Epoch 8: 307/634 Loss: 0.158833
2023-01-04 12:37: Train Epoch 8: 311/634 Loss: 0.200548
2023-01-04 12:38: Train Epoch 8: 315/634 Loss: 0.161165
2023-01-04 12:39: Train Epoch 8: 319/634 Loss: 0.157312
2023-01-04 12:40: Train Epoch 8: 323/634 Loss: 0.161790
2023-01-04 12:40: Train Epoch 8: 327/634 Loss: 0.203272
2023-01-04 12:41: Train Epoch 8: 331/634 Loss: 0.187507
2023-01-04 12:42: Train Epoch 8: 335/634 Loss: 0.197905
2023-01-04 12:43: Train Epoch 8: 339/634 Loss: 0.190037
2023-01-04 12:44: Train Epoch 8: 343/634 Loss: 0.191564
2023-01-04 12:45: Train Epoch 8: 347/634 Loss: 0.174221
2023-01-04 12:46: Train Epoch 8: 351/634 Loss: 0.175284
2023-01-04 12:46: Train Epoch 8: 355/634 Loss: 0.163432
2023-01-04 12:47: Train Epoch 8: 359/634 Loss: 0.176640
2023-01-04 12:48: Train Epoch 8: 363/634 Loss: 0.200398
2023-01-04 12:49: Train Epoch 8: 367/634 Loss: 0.212051
2023-01-04 12:50: Train Epoch 8: 371/634 Loss: 0.167234
2023-01-04 12:51: Train Epoch 8: 375/634 Loss: 0.196037
2023-01-04 12:52: Train Epoch 8: 379/634 Loss: 0.189408
2023-01-04 12:52: Train Epoch 8: 383/634 Loss: 0.173408
2023-01-04 12:53: Train Epoch 8: 387/634 Loss: 0.205848
2023-01-04 12:54: Train Epoch 8: 391/634 Loss: 0.180353
2023-01-04 12:55: Train Epoch 8: 395/634 Loss: 0.215579
2023-01-04 12:56: Train Epoch 8: 399/634 Loss: 0.153045
2023-01-04 12:57: Train Epoch 8: 403/634 Loss: 0.150759
2023-01-04 12:58: Train Epoch 8: 407/634 Loss: 0.178820
2023-01-04 12:58: Train Epoch 8: 411/634 Loss: 0.173589
2023-01-04 12:59: Train Epoch 8: 415/634 Loss: 0.165441
2023-01-04 13:00: Train Epoch 8: 419/634 Loss: 0.173258
2023-01-04 13:01: Train Epoch 8: 423/634 Loss: 0.155722
2023-01-04 13:02: Train Epoch 8: 427/634 Loss: 0.168742
2023-01-04 13:03: Train Epoch 8: 431/634 Loss: 0.172019
2023-01-04 13:03: Train Epoch 8: 435/634 Loss: 0.157802
2023-01-04 13:04: Train Epoch 8: 439/634 Loss: 0.173351
2023-01-04 13:05: Train Epoch 8: 443/634 Loss: 0.178500
2023-01-04 13:06: Train Epoch 8: 447/634 Loss: 0.172459
2023-01-04 13:07: Train Epoch 8: 451/634 Loss: 0.167547
2023-01-04 13:08: Train Epoch 8: 455/634 Loss: 0.156937
2023-01-04 13:09: Train Epoch 8: 459/634 Loss: 0.172292
2023-01-04 13:09: Train Epoch 8: 463/634 Loss: 0.176790
2023-01-04 13:10: Train Epoch 8: 467/634 Loss: 0.183706
2023-01-04 13:11: Train Epoch 8: 471/634 Loss: 0.167178
2023-01-04 13:12: Train Epoch 8: 475/634 Loss: 0.174192
2023-01-04 13:13: Train Epoch 8: 479/634 Loss: 0.195008
2023-01-04 13:14: Train Epoch 8: 483/634 Loss: 0.189918
2023-01-04 13:14: Train Epoch 8: 487/634 Loss: 0.167457
2023-01-04 13:15: Train Epoch 8: 491/634 Loss: 0.168425
2023-01-04 13:16: Train Epoch 8: 495/634 Loss: 0.170788
2023-01-04 13:17: Train Epoch 8: 499/634 Loss: 0.166538
2023-01-04 13:18: Train Epoch 8: 503/634 Loss: 0.168944
2023-01-04 13:19: Train Epoch 8: 507/634 Loss: 0.184834
2023-01-04 13:19: Train Epoch 8: 511/634 Loss: 0.172166
2023-01-04 13:20: Train Epoch 8: 515/634 Loss: 0.177778
2023-01-04 13:21: Train Epoch 8: 519/634 Loss: 0.170810
2023-01-04 13:22: Train Epoch 8: 523/634 Loss: 0.168674
2023-01-04 13:23: Train Epoch 8: 527/634 Loss: 0.170282
2023-01-04 13:24: Train Epoch 8: 531/634 Loss: 0.187344
2023-01-04 13:24: Train Epoch 8: 535/634 Loss: 0.164777
2023-01-04 13:25: Train Epoch 8: 539/634 Loss: 0.209671
2023-01-04 13:26: Train Epoch 8: 543/634 Loss: 0.192603
2023-01-04 13:27: Train Epoch 8: 547/634 Loss: 0.164710
2023-01-04 13:28: Train Epoch 8: 551/634 Loss: 0.190230
2023-01-04 13:29: Train Epoch 8: 555/634 Loss: 0.193735
2023-01-04 13:30: Train Epoch 8: 559/634 Loss: 0.179578
2023-01-04 13:31: Train Epoch 8: 563/634 Loss: 0.204802
2023-01-04 13:31: Train Epoch 8: 567/634 Loss: 0.166420
2023-01-04 13:32: Train Epoch 8: 571/634 Loss: 0.162376
2023-01-04 13:33: Train Epoch 8: 575/634 Loss: 0.170780
2023-01-04 13:34: Train Epoch 8: 579/634 Loss: 0.195908
2023-01-04 13:35: Train Epoch 8: 583/634 Loss: 0.185001
2023-01-04 13:36: Train Epoch 8: 587/634 Loss: 0.186351
2023-01-04 13:36: Train Epoch 8: 591/634 Loss: 0.186241
2023-01-04 13:37: Train Epoch 8: 595/634 Loss: 0.174596
2023-01-04 13:38: Train Epoch 8: 599/634 Loss: 0.166646
2023-01-04 13:39: Train Epoch 8: 603/634 Loss: 0.219847
2023-01-04 13:40: Train Epoch 8: 607/634 Loss: 0.206088
2023-01-04 13:41: Train Epoch 8: 611/634 Loss: 0.160489
2023-01-04 13:42: Train Epoch 8: 615/634 Loss: 0.177826
2023-01-04 13:42: Train Epoch 8: 619/634 Loss: 0.198124
2023-01-04 13:43: Train Epoch 8: 623/634 Loss: 0.193350
2023-01-04 13:44: Train Epoch 8: 627/634 Loss: 0.207908
2023-01-04 13:45: Train Epoch 8: 631/634 Loss: 0.229895
2023-01-04 13:45: Train Epoch 8: 633/634 Loss: 0.081269
2023-01-04 13:45: **********Train Epoch 8: averaged Loss: 0.180874 
2023-01-04 13:45: 
Epoch time elapsed: 8085.905559539795

2023-01-04 13:48: 
 metrics validation: {'precision': 0.8255613126079447, 'recall': 0.3676923076923077, 'f1-score': 0.5087812666311868, 'support': 1300, 'AUC': 0.8991846153846154, 'AUCPR': 0.7917651472865277, 'TP': 478, 'FP': 101, 'TN': 2499, 'FN': 822} 

2023-01-04 13:48: **********Val Epoch 8: average Loss: 0.225074
2023-01-04 13:51: 
 Testing metrics {'precision': 0.805528134254689, 'recall': 0.6644951140065146, 'f1-score': 0.7282463186077645, 'support': 1228, 'AUC': 0.9025523480355229, 'AUCPR': 0.8306377294529738, 'TP': 816, 'FP': 197, 'TN': 2259, 'FN': 412} 

2023-01-04 14:02: 
 Testing metrics {'precision': 0.8705765899529819, 'recall': 0.7982754708418425, 'f1-score': 0.8328598484848484, 'support': 4407, 'AUC': 0.959029946427309, 'AUCPR': 0.9151686753359707, 'TP': 3518, 'FP': 523, 'TN': 8291, 'FN': 889} 

2023-01-04 14:02: Train Epoch 9: 3/634 Loss: 0.192062
2023-01-04 14:03: Train Epoch 9: 7/634 Loss: 0.197426
2023-01-04 14:04: Train Epoch 9: 11/634 Loss: 0.192997
2023-01-04 14:05: Train Epoch 9: 15/634 Loss: 0.195304
2023-01-04 14:06: Train Epoch 9: 19/634 Loss: 0.203417
2023-01-04 14:07: Train Epoch 9: 23/634 Loss: 0.193372
2023-01-04 14:07: Train Epoch 9: 27/634 Loss: 0.171307
2023-01-04 14:08: Train Epoch 9: 31/634 Loss: 0.190613
2023-01-04 14:09: Train Epoch 9: 35/634 Loss: 0.185090
2023-01-04 14:10: Train Epoch 9: 39/634 Loss: 0.166964
2023-01-04 14:11: Train Epoch 9: 43/634 Loss: 0.171662
2023-01-04 14:12: Train Epoch 9: 47/634 Loss: 0.206910
2023-01-04 14:12: Train Epoch 9: 51/634 Loss: 0.180591
2023-01-04 14:13: Train Epoch 9: 55/634 Loss: 0.189372
2023-01-04 14:14: Train Epoch 9: 59/634 Loss: 0.174072
2023-01-04 14:15: Train Epoch 9: 63/634 Loss: 0.233502
2023-01-04 14:16: Train Epoch 9: 67/634 Loss: 0.191981
2023-01-04 14:17: Train Epoch 9: 71/634 Loss: 0.184297
2023-01-04 14:18: Train Epoch 9: 75/634 Loss: 0.173265
2023-01-04 14:19: Train Epoch 9: 79/634 Loss: 0.194855
2023-01-04 14:19: Train Epoch 9: 83/634 Loss: 0.188997
2023-01-04 14:20: Train Epoch 9: 87/634 Loss: 0.184615
2023-01-04 14:21: Train Epoch 9: 91/634 Loss: 0.175005
2023-01-04 14:22: Train Epoch 9: 95/634 Loss: 0.193534
2023-01-04 14:23: Train Epoch 9: 99/634 Loss: 0.186805
2023-01-04 14:23: Train Epoch 9: 103/634 Loss: 0.191043
2023-01-04 14:24: Train Epoch 9: 107/634 Loss: 0.218597
2023-01-04 14:25: Train Epoch 9: 111/634 Loss: 0.171731
2023-01-04 14:26: Train Epoch 9: 115/634 Loss: 0.185492
2023-01-04 14:27: Train Epoch 9: 119/634 Loss: 0.165092
2023-01-04 14:27: Train Epoch 9: 123/634 Loss: 0.165556
2023-01-04 14:28: Train Epoch 9: 127/634 Loss: 0.167220
2023-01-04 14:29: Train Epoch 9: 131/634 Loss: 0.165315
2023-01-04 14:30: Train Epoch 9: 135/634 Loss: 0.186557
2023-01-04 14:31: Train Epoch 9: 139/634 Loss: 0.169756
2023-01-04 14:32: Train Epoch 9: 143/634 Loss: 0.181530
2023-01-04 14:32: Train Epoch 9: 147/634 Loss: 0.186441
2023-01-04 14:33: Train Epoch 9: 151/634 Loss: 0.170293
2023-01-04 14:34: Train Epoch 9: 155/634 Loss: 0.186987
2023-01-04 14:35: Train Epoch 9: 159/634 Loss: 0.177864
2023-01-04 14:36: Train Epoch 9: 163/634 Loss: 0.196035
2023-01-04 14:37: Train Epoch 9: 167/634 Loss: 0.167466
2023-01-04 14:37: Train Epoch 9: 171/634 Loss: 0.213495
2023-01-04 14:38: Train Epoch 9: 175/634 Loss: 0.162649
2023-01-04 14:39: Train Epoch 9: 179/634 Loss: 0.195023
2023-01-04 14:40: Train Epoch 9: 183/634 Loss: 0.194129
2023-01-04 14:41: Train Epoch 9: 187/634 Loss: 0.201439
2023-01-04 14:42: Train Epoch 9: 191/634 Loss: 0.203861
2023-01-04 14:42: Train Epoch 9: 195/634 Loss: 0.213528
2023-01-04 14:43: Train Epoch 9: 199/634 Loss: 0.165706
2023-01-04 14:44: Train Epoch 9: 203/634 Loss: 0.184646
2023-01-04 14:45: Train Epoch 9: 207/634 Loss: 0.254914
2023-01-04 14:46: Train Epoch 9: 211/634 Loss: 0.211066
2023-01-04 14:47: Train Epoch 9: 215/634 Loss: 0.209280
2023-01-04 14:48: Train Epoch 9: 219/634 Loss: 0.256596
2023-01-04 14:48: Train Epoch 9: 223/634 Loss: 0.171100
2023-01-04 14:49: Train Epoch 9: 227/634 Loss: 0.194086
2023-01-04 14:50: Train Epoch 9: 231/634 Loss: 0.199777
2023-01-04 14:51: Train Epoch 9: 235/634 Loss: 0.165371
2023-01-04 14:52: Train Epoch 9: 239/634 Loss: 0.173473
2023-01-04 14:53: Train Epoch 9: 243/634 Loss: 0.175677
2023-01-04 14:53: Train Epoch 9: 247/634 Loss: 0.152407
2023-01-04 14:54: Train Epoch 9: 251/634 Loss: 0.177331
2023-01-04 14:55: Train Epoch 9: 255/634 Loss: 0.194206
2023-01-04 14:56: Train Epoch 9: 259/634 Loss: 0.182698
2023-01-04 14:57: Train Epoch 9: 263/634 Loss: 0.201428
2023-01-04 14:58: Train Epoch 9: 267/634 Loss: 0.232883
2023-01-04 14:58: Train Epoch 9: 271/634 Loss: 0.169950
2023-01-04 14:59: Train Epoch 9: 275/634 Loss: 0.169640
2023-01-04 15:00: Train Epoch 9: 279/634 Loss: 0.196859
2023-01-04 15:01: Train Epoch 9: 283/634 Loss: 0.221056
2023-01-04 15:02: Train Epoch 9: 287/634 Loss: 0.198360
2023-01-04 15:03: Train Epoch 9: 291/634 Loss: 0.182781
2023-01-04 15:03: Train Epoch 9: 295/634 Loss: 0.190601
2023-01-04 15:04: Train Epoch 9: 299/634 Loss: 0.197969
2023-01-04 15:05: Train Epoch 9: 303/634 Loss: 0.182534
2023-01-04 15:06: Train Epoch 9: 307/634 Loss: 0.226315
2023-01-04 15:07: Train Epoch 9: 311/634 Loss: 0.203005
2023-01-04 15:08: Train Epoch 9: 315/634 Loss: 0.193123
2023-01-04 15:09: Train Epoch 9: 319/634 Loss: 0.194065
2023-01-04 15:09: Train Epoch 9: 323/634 Loss: 0.215440
2023-01-04 15:10: Train Epoch 9: 327/634 Loss: 0.189309
2023-01-04 15:11: Train Epoch 9: 331/634 Loss: 0.187922
2023-01-04 15:12: Train Epoch 9: 335/634 Loss: 0.215789
2023-01-04 15:13: Train Epoch 9: 339/634 Loss: 0.196061
2023-01-04 15:14: Train Epoch 9: 343/634 Loss: 0.188692
2023-01-04 15:15: Train Epoch 9: 347/634 Loss: 0.182402
2023-01-04 15:15: Train Epoch 9: 351/634 Loss: 0.182060
2023-01-04 15:16: Train Epoch 9: 355/634 Loss: 0.173510
2023-01-04 15:17: Train Epoch 9: 359/634 Loss: 0.147396
2023-01-04 15:18: Train Epoch 9: 363/634 Loss: 0.206033
2023-01-04 15:19: Train Epoch 9: 367/634 Loss: 0.210336
2023-01-04 15:20: Train Epoch 9: 371/634 Loss: 0.189320
2023-01-04 15:20: Train Epoch 9: 375/634 Loss: 0.167039
2023-01-04 15:21: Train Epoch 9: 379/634 Loss: 0.186282
2023-01-04 15:22: Train Epoch 9: 383/634 Loss: 0.181084
2023-01-04 15:23: Train Epoch 9: 387/634 Loss: 0.182563
2023-01-04 15:24: Train Epoch 9: 391/634 Loss: 0.190222
2023-01-04 15:25: Train Epoch 9: 395/634 Loss: 0.181172
2023-01-04 15:26: Train Epoch 9: 399/634 Loss: 0.181607
2023-01-04 15:26: Train Epoch 9: 403/634 Loss: 0.172504
2023-01-04 15:27: Train Epoch 9: 407/634 Loss: 0.200878
2023-01-04 15:28: Train Epoch 9: 411/634 Loss: 0.152823
2023-01-04 15:29: Train Epoch 9: 415/634 Loss: 0.213584
2023-01-04 15:30: Train Epoch 9: 419/634 Loss: 0.179420
2023-01-04 15:31: Train Epoch 9: 423/634 Loss: 0.193241
2023-01-04 15:32: Train Epoch 9: 427/634 Loss: 0.177677
2023-01-04 15:32: Train Epoch 9: 431/634 Loss: 0.202188
2023-01-04 15:33: Train Epoch 9: 435/634 Loss: 0.175214
2023-01-04 15:34: Train Epoch 9: 439/634 Loss: 0.172684
2023-01-04 15:35: Train Epoch 9: 443/634 Loss: 0.176922
2023-01-04 15:36: Train Epoch 9: 447/634 Loss: 0.169752
2023-01-04 15:37: Train Epoch 9: 451/634 Loss: 0.156176
2023-01-04 15:38: Train Epoch 9: 455/634 Loss: 0.150554
2023-01-04 15:38: Train Epoch 9: 459/634 Loss: 0.151971
2023-01-04 15:39: Train Epoch 9: 463/634 Loss: 0.188463
2023-01-04 15:40: Train Epoch 9: 467/634 Loss: 0.187964
2023-01-04 15:41: Train Epoch 9: 471/634 Loss: 0.192254
2023-01-04 15:42: Train Epoch 9: 475/634 Loss: 0.180508
2023-01-04 15:43: Train Epoch 9: 479/634 Loss: 0.173026
2023-01-04 15:43: Train Epoch 9: 483/634 Loss: 0.212892
2023-01-04 15:44: Train Epoch 9: 487/634 Loss: 0.172432
2023-01-04 15:45: Train Epoch 9: 491/634 Loss: 0.214301
2023-01-04 15:46: Train Epoch 9: 495/634 Loss: 0.174626
2023-01-04 15:47: Train Epoch 9: 499/634 Loss: 0.206461
2023-01-04 15:48: Train Epoch 9: 503/634 Loss: 0.201684
2023-01-04 15:49: Train Epoch 9: 507/634 Loss: 0.182312
2023-01-04 15:49: Train Epoch 9: 511/634 Loss: 0.164598
2023-01-04 15:50: Train Epoch 9: 515/634 Loss: 0.225766
2023-01-04 15:51: Train Epoch 9: 519/634 Loss: 0.193735
2023-01-04 15:52: Train Epoch 9: 523/634 Loss: 0.206653
2023-01-04 15:53: Train Epoch 9: 527/634 Loss: 0.202348
2023-01-04 15:54: Train Epoch 9: 531/634 Loss: 0.171529
2023-01-04 15:55: Train Epoch 9: 535/634 Loss: 0.160631
2023-01-04 15:55: Train Epoch 9: 539/634 Loss: 0.187596
2023-01-04 15:56: Train Epoch 9: 543/634 Loss: 0.167805
2023-01-04 15:57: Train Epoch 9: 547/634 Loss: 0.189960
2023-01-04 15:58: Train Epoch 9: 551/634 Loss: 0.164241
2023-01-04 15:59: Train Epoch 9: 555/634 Loss: 0.156279
2023-01-04 16:00: Train Epoch 9: 559/634 Loss: 0.168332
2023-01-04 16:01: Train Epoch 9: 563/634 Loss: 0.169517
2023-01-04 16:01: Train Epoch 9: 567/634 Loss: 0.180479
2023-01-04 16:02: Train Epoch 9: 571/634 Loss: 0.150789
2023-01-04 16:03: Train Epoch 9: 575/634 Loss: 0.190378
2023-01-04 16:04: Train Epoch 9: 579/634 Loss: 0.163846
2023-01-04 16:05: Train Epoch 9: 583/634 Loss: 0.173620
2023-01-04 16:06: Train Epoch 9: 587/634 Loss: 0.172979
2023-01-04 16:06: Train Epoch 9: 591/634 Loss: 0.150223
2023-01-04 16:07: Train Epoch 9: 595/634 Loss: 0.161853
2023-01-04 16:08: Train Epoch 9: 599/634 Loss: 0.153227
2023-01-04 16:09: Train Epoch 9: 603/634 Loss: 0.150999
2023-01-04 16:10: Train Epoch 9: 607/634 Loss: 0.156531
2023-01-04 16:11: Train Epoch 9: 611/634 Loss: 0.165798
2023-01-04 16:11: Train Epoch 9: 615/634 Loss: 0.193037
2023-01-04 16:12: Train Epoch 9: 619/634 Loss: 0.186770
2023-01-04 16:13: Train Epoch 9: 623/634 Loss: 0.136403
2023-01-04 16:14: Train Epoch 9: 627/634 Loss: 0.164865
2023-01-04 16:15: Train Epoch 9: 631/634 Loss: 0.158846
2023-01-04 16:15: Train Epoch 9: 633/634 Loss: 0.088405
2023-01-04 16:15: **********Train Epoch 9: averaged Loss: 0.184269 
2023-01-04 16:15: 
Epoch time elapsed: 8016.857815980911

2023-01-04 16:18: 
 metrics validation: {'precision': 0.7564543889845095, 'recall': 0.6761538461538461, 'f1-score': 0.7140536149471973, 'support': 1300, 'AUC': 0.9005831360946746, 'AUCPR': 0.7970862953765978, 'TP': 879, 'FP': 283, 'TN': 2317, 'FN': 421} 

2023-01-04 16:18: **********Val Epoch 9: average Loss: 0.178240
2023-01-04 16:18: *********************************Current best model saved!
2023-01-04 16:21: 
 Testing metrics {'precision': 0.8109404990403071, 'recall': 0.6881107491856677, 'f1-score': 0.7444933920704846, 'support': 1228, 'AUC': 0.911024586467761, 'AUCPR': 0.8418089748309379, 'TP': 845, 'FP': 197, 'TN': 2259, 'FN': 383} 

2023-01-04 16:32: 
 Testing metrics {'precision': 0.8668775857872962, 'recall': 0.8082595870206489, 'f1-score': 0.8365429779239079, 'support': 4407, 'AUC': 0.9592944965692667, 'AUCPR': 0.9165759765183124, 'TP': 3562, 'FP': 547, 'TN': 8267, 'FN': 845} 

2023-01-04 16:33: Train Epoch 10: 3/634 Loss: 0.222468
2023-01-04 16:34: Train Epoch 10: 7/634 Loss: 0.160357
2023-01-04 16:34: Train Epoch 10: 11/634 Loss: 0.211712
2023-01-04 16:35: Train Epoch 10: 15/634 Loss: 0.155795
2023-01-04 16:36: Train Epoch 10: 19/634 Loss: 0.178195
2023-01-04 16:37: Train Epoch 10: 23/634 Loss: 0.161816
2023-01-04 16:38: Train Epoch 10: 27/634 Loss: 0.154654
2023-01-04 16:39: Train Epoch 10: 31/634 Loss: 0.160525
2023-01-04 16:39: Train Epoch 10: 35/634 Loss: 0.176507
2023-01-04 16:40: Train Epoch 10: 39/634 Loss: 0.185314
2023-01-04 16:41: Train Epoch 10: 43/634 Loss: 0.144754
2023-01-04 16:42: Train Epoch 10: 47/634 Loss: 0.158544
2023-01-04 16:43: Train Epoch 10: 51/634 Loss: 0.167210
2023-01-04 16:44: Train Epoch 10: 55/634 Loss: 0.206387
2023-01-04 16:45: Train Epoch 10: 59/634 Loss: 0.169730
2023-01-04 16:46: Train Epoch 10: 63/634 Loss: 0.162303
2023-01-04 16:47: Train Epoch 10: 67/634 Loss: 0.188003
2023-01-04 16:48: Train Epoch 10: 71/634 Loss: 0.158039
2023-01-04 16:48: Train Epoch 10: 75/634 Loss: 0.163293
2023-01-04 16:49: Train Epoch 10: 79/634 Loss: 0.153368
2023-01-04 16:50: Train Epoch 10: 83/634 Loss: 0.184034
2023-01-04 16:51: Train Epoch 10: 87/634 Loss: 0.167250
2023-01-04 16:52: Train Epoch 10: 91/634 Loss: 0.173815
2023-01-04 16:53: Train Epoch 10: 95/634 Loss: 0.170837
2023-01-04 16:54: Train Epoch 10: 99/634 Loss: 0.148914
2023-01-04 16:54: Train Epoch 10: 103/634 Loss: 0.169840
2023-01-04 16:55: Train Epoch 10: 107/634 Loss: 0.155025
2023-01-04 16:56: Train Epoch 10: 111/634 Loss: 0.199787
2023-01-04 16:57: Train Epoch 10: 115/634 Loss: 0.217300
2023-01-04 16:58: Train Epoch 10: 119/634 Loss: 0.156708
2023-01-04 16:58: Train Epoch 10: 123/634 Loss: 0.148195
2023-01-04 16:59: Train Epoch 10: 127/634 Loss: 0.143310
2023-01-04 17:00: Train Epoch 10: 131/634 Loss: 0.171061
2023-01-04 17:01: Train Epoch 10: 135/634 Loss: 0.193370
2023-01-04 17:02: Train Epoch 10: 139/634 Loss: 0.171862
2023-01-04 17:03: Train Epoch 10: 143/634 Loss: 0.213595
2023-01-04 17:04: Train Epoch 10: 147/634 Loss: 0.194565
2023-01-04 17:04: Train Epoch 10: 151/634 Loss: 0.149714
2023-01-04 17:05: Train Epoch 10: 155/634 Loss: 0.171764
