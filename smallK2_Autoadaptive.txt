2023-01-06 21:31: log dir: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010621311405767569386
2023-01-06 21:31: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010621311405767569386
2023-01-06 21:31: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010621311405767569386', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=48, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-06 21:31: Argument batch_size: 256
2023-01-06 21:31: Argument clc: 'vec'
2023-01-06 21:31: Argument cuda: True
2023-01-06 21:31: Argument dataset: '2020'
2023-01-06 21:31: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-06 21:31: Argument debug: False
2023-01-06 21:31: Argument default_graph: True
2023-01-06 21:31: Argument device: 'cpu'
2023-01-06 21:31: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-06 21:31: Argument early_stop: True
2023-01-06 21:31: Argument early_stop_patience: 8
2023-01-06 21:31: Argument embed_dim: 64
2023-01-06 21:31: Argument epochs: 30
2023-01-06 21:31: Argument grad_norm: False
2023-01-06 21:31: Argument horizon: 1
2023-01-06 21:31: Argument input_dim: 25
2023-01-06 21:31: Argument lag: 10
2023-01-06 21:31: Argument link_len: 2
2023-01-06 21:31: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010621311405767569386'
2023-01-06 21:31: Argument log_step: 1
2023-01-06 21:31: Argument loss_func: 'nllloss'
2023-01-06 21:31: Argument lr_decay: True
2023-01-06 21:31: Argument lr_decay_rate: 0.1
2023-01-06 21:31: Argument lr_decay_step: '20'
2023-01-06 21:31: Argument lr_init: 0.0001
2023-01-06 21:31: Argument max_grad_norm: 5
2023-01-06 21:31: Argument minbatch_size: 64
2023-01-06 21:31: Argument mode: 'train'
2023-01-06 21:31: Argument model: 'fire_GCN'
2023-01-06 21:31: Argument nan_fill: -1.0
2023-01-06 21:31: Argument num_layers: 1
2023-01-06 21:31: Argument num_nodes: 625
2023-01-06 21:31: Argument num_workers: 12
2023-01-06 21:31: Argument output_dim: 2
2023-01-06 21:31: Argument patch_height: 25
2023-01-06 21:31: Argument patch_width: 25
2023-01-06 21:31: Argument persistent_workers: True
2023-01-06 21:31: Argument pin_memory: True
2023-01-06 21:31: Argument plot: False
2023-01-06 21:31: Argument positive_weight: 0.5
2023-01-06 21:31: Argument prefetch_factor: 2
2023-01-06 21:31: Argument real_value: True
2023-01-06 21:31: Argument rnn_units: 48
2023-01-06 21:31: Argument seed: 10000
2023-01-06 21:31: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-06 21:31: Argument teacher_forcing: False
2023-01-06 21:31: Argument weight_decay: 0.0
2023-01-06 21:31: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([64, 2, 73, 48]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 48]) True
encoder.cell_list.0.gate.bias_pool torch.Size([64, 96]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([64, 2, 73, 24]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 24]) True
encoder.cell_list.0.update.bias_pool torch.Size([64, 48]) True
encoder.cell_list.0.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 30000]) True
fc1.bias torch.Size([2]) True
Total params num: 786664
*****************Finish Parameter****************
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010621311405767569386/run.log
2023-01-06 21:31: Train Epoch 1: 3/24 Loss: 0.445391
2023-01-06 21:31: Train Epoch 1: 7/24 Loss: 0.393040
2023-01-06 21:31: Train Epoch 1: 11/24 Loss: 0.330409
2023-01-06 21:32: Train Epoch 1: 15/24 Loss: 0.332452
2023-01-06 21:32: Train Epoch 1: 19/24 Loss: 0.304311
2023-01-06 21:32: Train Epoch 1: 23/24 Loss: 0.253118
2023-01-06 21:32: **********Train Epoch 1: averaged Loss: 0.343120 
2023-01-06 21:32: 
Epoch time elapsed: 75.25370788574219

2023-01-06 21:32: 
 metrics validation: {'precision': 0.4632183908045977, 'recall': 0.806, 'f1-score': 0.5883211678832118, 'support': 500, 'AUC': 0.7683420000000001, 'AUCPR': 0.6351917081127572, 'TP': 403, 'FP': 467, 'TN': 533, 'FN': 97} 

2023-01-06 21:32: **********Val Epoch 1: average Loss: 0.314375
2023-01-06 21:32: *********************************Current best model saved!
2023-01-06 21:33: 
 Testing metrics {'precision': 0.4971751412429379, 'recall': 0.88, 'f1-score': 0.6353790613718412, 'support': 500, 'AUC': 0.856588, 'AUCPR': 0.7709100632721002, 'TP': 440, 'FP': 445, 'TN': 555, 'FN': 60} 

2023-01-06 21:33: 
 Testing metrics {'precision': 0.5930087390761548, 'recall': 0.95, 'f1-score': 0.7302075326671791, 'support': 500, 'AUC': 0.9481379999999999, 'AUCPR': 0.9153034963302104, 'TP': 475, 'FP': 326, 'TN': 674, 'FN': 25} 

2023-01-06 21:33: Train Epoch 2: 3/24 Loss: 0.295436
2023-01-06 21:34: Train Epoch 2: 7/24 Loss: 0.294902
2023-01-06 21:34: Train Epoch 2: 11/24 Loss: 0.248533
2023-01-06 21:34: Train Epoch 2: 15/24 Loss: 0.247596
2023-01-06 21:34: Train Epoch 2: 19/24 Loss: 0.247234
2023-01-06 21:34: Train Epoch 2: 23/24 Loss: 0.244871
2023-01-06 21:34: **********Train Epoch 2: averaged Loss: 0.263095 
2023-01-06 21:34: 
Epoch time elapsed: 73.48620128631592

2023-01-06 21:35: 
 metrics validation: {'precision': 0.8301886792452831, 'recall': 0.088, 'f1-score': 0.15913200723327306, 'support': 500, 'AUC': 0.776106, 'AUCPR': 0.6449496411261849, 'TP': 44, 'FP': 9, 'TN': 991, 'FN': 456} 

2023-01-06 21:35: **********Val Epoch 2: average Loss: 0.288281
2023-01-06 21:35: *********************************Current best model saved!
2023-01-06 21:35: 
 Testing metrics {'precision': 0.9117647058823529, 'recall': 0.186, 'f1-score': 0.30897009966777406, 'support': 500, 'AUC': 0.8632120000000001, 'AUCPR': 0.7820296085261988, 'TP': 93, 'FP': 9, 'TN': 991, 'FN': 407} 

2023-01-06 21:35: 
 Testing metrics {'precision': 0.9759036144578314, 'recall': 0.486, 'f1-score': 0.6488651535380507, 'support': 500, 'AUC': 0.955378, 'AUCPR': 0.9295526434961342, 'TP': 243, 'FP': 6, 'TN': 994, 'FN': 257} 

2023-01-06 21:36: Train Epoch 3: 3/24 Loss: 0.279544
2023-01-06 21:36: Train Epoch 3: 7/24 Loss: 0.260498
2023-01-06 21:36: Train Epoch 3: 11/24 Loss: 0.243740
2023-01-06 21:36: Train Epoch 3: 15/24 Loss: 0.243804
2023-01-06 21:36: Train Epoch 3: 19/24 Loss: 0.260259
2023-01-06 21:37: Train Epoch 3: 23/24 Loss: 0.203580
2023-01-06 21:37: **********Train Epoch 3: averaged Loss: 0.248571 
2023-01-06 21:37: 
Epoch time elapsed: 73.52158856391907

2023-01-06 21:37: 
 metrics validation: {'precision': 0.6003787878787878, 'recall': 0.634, 'f1-score': 0.6167315175097275, 'support': 500, 'AUC': 0.78237, 'AUCPR': 0.6542896630712566, 'TP': 317, 'FP': 211, 'TN': 789, 'FN': 183} 

2023-01-06 21:37: **********Val Epoch 3: average Loss: 0.260764
2023-01-06 21:37: *********************************Current best model saved!
2023-01-06 21:37: 
 Testing metrics {'precision': 0.6790123456790124, 'recall': 0.77, 'f1-score': 0.7216494845360826, 'support': 500, 'AUC': 0.865528, 'AUCPR': 0.7881231052105279, 'TP': 385, 'FP': 182, 'TN': 818, 'FN': 115} 

2023-01-06 21:38: 
 Testing metrics {'precision': 0.7958477508650519, 'recall': 0.92, 'f1-score': 0.8534322820037105, 'support': 500, 'AUC': 0.957808, 'AUCPR': 0.9334924342365702, 'TP': 460, 'FP': 118, 'TN': 882, 'FN': 40} 

2023-01-06 21:38: Train Epoch 4: 3/24 Loss: 0.223594
2023-01-06 21:38: Train Epoch 4: 7/24 Loss: 0.223804
2023-01-06 21:38: Train Epoch 4: 11/24 Loss: 0.262168
2023-01-06 21:39: Train Epoch 4: 15/24 Loss: 0.193692
2023-01-06 21:39: Train Epoch 4: 19/24 Loss: 0.236970
2023-01-06 21:39: Train Epoch 4: 23/24 Loss: 0.197192
2023-01-06 21:39: **********Train Epoch 4: averaged Loss: 0.222903 
2023-01-06 21:39: 
Epoch time elapsed: 75.97387194633484

2023-01-06 21:39: 
 metrics validation: {'precision': 0.7151515151515152, 'recall': 0.472, 'f1-score': 0.5686746987951806, 'support': 500, 'AUC': 0.7889919999999999, 'AUCPR': 0.6647018027916305, 'TP': 236, 'FP': 94, 'TN': 906, 'FN': 264} 

2023-01-06 21:39: **********Val Epoch 4: average Loss: 0.267693
2023-01-06 21:39: Train Epoch 5: 3/24 Loss: 0.259374
2023-01-06 21:40: Train Epoch 5: 7/24 Loss: 0.215957
2023-01-06 21:40: Train Epoch 5: 11/24 Loss: 0.234948
2023-01-06 21:40: Train Epoch 5: 15/24 Loss: 0.219109
2023-01-06 21:40: Train Epoch 5: 19/24 Loss: 0.232648
2023-01-06 21:40: Train Epoch 5: 23/24 Loss: 0.190675
2023-01-06 21:40: **********Train Epoch 5: averaged Loss: 0.225452 
2023-01-06 21:40: 
Epoch time elapsed: 69.57472634315491

2023-01-06 21:41: 
 metrics validation: {'precision': 0.7375886524822695, 'recall': 0.416, 'f1-score': 0.5319693094629155, 'support': 500, 'AUC': 0.7915019999999999, 'AUCPR': 0.6685137762149123, 'TP': 208, 'FP': 74, 'TN': 926, 'FN': 292} 

2023-01-06 21:41: **********Val Epoch 5: average Loss: 0.269683
2023-01-06 21:41: Train Epoch 6: 3/24 Loss: 0.226337
2023-01-06 21:41: Train Epoch 6: 7/24 Loss: 0.246853
2023-01-06 21:41: Train Epoch 6: 11/24 Loss: 0.248899
2023-01-06 21:42: Train Epoch 6: 15/24 Loss: 0.208977
2023-01-06 21:42: Train Epoch 6: 19/24 Loss: 0.218748
2023-01-06 21:42: Train Epoch 6: 23/24 Loss: 0.191519
2023-01-06 21:42: **********Train Epoch 6: averaged Loss: 0.223555 
2023-01-06 21:42: 
Epoch time elapsed: 73.88730716705322

2023-01-06 21:42: 
 metrics validation: {'precision': 0.7246835443037974, 'recall': 0.458, 'f1-score': 0.5612745098039215, 'support': 500, 'AUC': 0.7936300000000001, 'AUCPR': 0.6707192830019165, 'TP': 229, 'FP': 87, 'TN': 913, 'FN': 271} 

2023-01-06 21:42: **********Val Epoch 6: average Loss: 0.261362
2023-01-06 21:43: Train Epoch 7: 3/24 Loss: 0.232616
2023-01-06 21:43: Train Epoch 7: 7/24 Loss: 0.235190
2023-01-06 21:43: Train Epoch 7: 11/24 Loss: 0.224114
2023-01-06 21:43: Train Epoch 7: 15/24 Loss: 0.241998
2023-01-06 21:43: Train Epoch 7: 19/24 Loss: 0.212231
2023-01-06 21:44: Train Epoch 7: 23/24 Loss: 0.165780
2023-01-06 21:44: **********Train Epoch 7: averaged Loss: 0.218655 
2023-01-06 21:44: 
Epoch time elapsed: 68.67603063583374

2023-01-06 21:44: 
 metrics validation: {'precision': 0.7147147147147147, 'recall': 0.476, 'f1-score': 0.5714285714285713, 'support': 500, 'AUC': 0.794098, 'AUCPR': 0.6713090679998592, 'TP': 238, 'FP': 95, 'TN': 905, 'FN': 262} 

2023-01-06 21:44: **********Val Epoch 7: average Loss: 0.259282
2023-01-06 21:44: *********************************Current best model saved!
2023-01-06 21:44: 
 Testing metrics {'precision': 0.837772397094431, 'recall': 0.692, 'f1-score': 0.7579408543263964, 'support': 500, 'AUC': 0.868928, 'AUCPR': 0.7942774708046578, 'TP': 346, 'FP': 67, 'TN': 933, 'FN': 154} 

2023-01-06 21:45: 
 Testing metrics {'precision': 0.8891170431211499, 'recall': 0.866, 'f1-score': 0.8774062816616007, 'support': 500, 'AUC': 0.9621500000000001, 'AUCPR': 0.940169218968428, 'TP': 433, 'FP': 54, 'TN': 946, 'FN': 67} 

2023-01-06 21:45: Train Epoch 8: 3/24 Loss: 0.233396
2023-01-06 21:45: Train Epoch 8: 7/24 Loss: 0.213215
2023-01-06 21:45: Train Epoch 8: 11/24 Loss: 0.211761
2023-01-06 21:45: Train Epoch 8: 15/24 Loss: 0.218178
2023-01-06 21:46: Train Epoch 8: 19/24 Loss: 0.212956
2023-01-06 21:46: Train Epoch 8: 23/24 Loss: 0.186186
2023-01-06 21:46: **********Train Epoch 8: averaged Loss: 0.212615 
2023-01-06 21:46: 
Epoch time elapsed: 74.34679675102234

2023-01-06 21:46: 
 metrics validation: {'precision': 0.6779324055666004, 'recall': 0.682, 'f1-score': 0.6799601196410768, 'support': 500, 'AUC': 0.803778, 'AUCPR': 0.6854905289638489, 'TP': 341, 'FP': 162, 'TN': 838, 'FN': 159} 

2023-01-06 21:46: **********Val Epoch 8: average Loss: 0.249574
2023-01-06 21:46: *********************************Current best model saved!
2023-01-06 21:46: 
 Testing metrics {'precision': 0.758130081300813, 'recall': 0.746, 'f1-score': 0.7520161290322581, 'support': 500, 'AUC': 0.8694, 'AUCPR': 0.795094187244085, 'TP': 373, 'FP': 119, 'TN': 881, 'FN': 127} 

2023-01-06 21:47: 
 Testing metrics {'precision': 0.8502772643253235, 'recall': 0.92, 'f1-score': 0.8837656099903939, 'support': 500, 'AUC': 0.963812, 'AUCPR': 0.9420608579686257, 'TP': 460, 'FP': 81, 'TN': 919, 'FN': 40} 

2023-01-06 21:47: Train Epoch 9: 3/24 Loss: 0.217290
2023-01-06 21:47: Train Epoch 9: 7/24 Loss: 0.225489
2023-01-06 21:47: Train Epoch 9: 11/24 Loss: 0.218578
2023-01-06 21:48: Train Epoch 9: 15/24 Loss: 0.197870
2023-01-06 21:48: Train Epoch 9: 19/24 Loss: 0.195778
2023-01-06 21:48: Train Epoch 9: 23/24 Loss: 0.187764
2023-01-06 21:48: **********Train Epoch 9: averaged Loss: 0.207128 
2023-01-06 21:48: 
Epoch time elapsed: 70.39088416099548

2023-01-06 21:48: 
 metrics validation: {'precision': 0.7196029776674938, 'recall': 0.58, 'f1-score': 0.6423034330011074, 'support': 500, 'AUC': 0.8088239999999999, 'AUCPR': 0.6989905353374357, 'TP': 290, 'FP': 113, 'TN': 887, 'FN': 210} 

2023-01-06 21:48: **********Val Epoch 9: average Loss: 0.249825
2023-01-06 21:49: Train Epoch 10: 3/24 Loss: 0.204381
2023-01-06 21:49: Train Epoch 10: 7/24 Loss: 0.228276
2023-01-06 21:49: Train Epoch 10: 11/24 Loss: 0.200025
2023-01-06 21:49: Train Epoch 10: 15/24 Loss: 0.223053
2023-01-06 21:49: Train Epoch 10: 19/24 Loss: 0.218017
2023-01-06 21:50: Train Epoch 10: 23/24 Loss: 0.198590
2023-01-06 21:50: **********Train Epoch 10: averaged Loss: 0.212057 
2023-01-06 21:50: 
Epoch time elapsed: 70.0628719329834

2023-01-06 21:50: 
 metrics validation: {'precision': 0.7031578947368421, 'recall': 0.668, 'f1-score': 0.6851282051282052, 'support': 500, 'AUC': 0.8058699999999999, 'AUCPR': 0.6967121909016262, 'TP': 334, 'FP': 141, 'TN': 859, 'FN': 166} 

2023-01-06 21:50: **********Val Epoch 10: average Loss: 0.250202
2023-01-06 21:50: Train Epoch 11: 3/24 Loss: 0.237206
2023-01-06 21:50: Train Epoch 11: 7/24 Loss: 0.202647
2023-01-06 21:50: Train Epoch 11: 11/24 Loss: 0.238336
2023-01-06 21:51: Train Epoch 11: 15/24 Loss: 0.227230
2023-01-06 21:51: Train Epoch 11: 19/24 Loss: 0.177371
2023-01-06 21:51: Train Epoch 11: 23/24 Loss: 0.188862
2023-01-06 21:51: **********Train Epoch 11: averaged Loss: 0.211942 
2023-01-06 21:51: 
Epoch time elapsed: 67.38361024856567

2023-01-06 21:51: 
 metrics validation: {'precision': 0.75, 'recall': 0.45, 'f1-score': 0.5625000000000001, 'support': 500, 'AUC': 0.804716, 'AUCPR': 0.6954484022858757, 'TP': 225, 'FP': 75, 'TN': 925, 'FN': 275} 

2023-01-06 21:51: **********Val Epoch 11: average Loss: 0.260703
2023-01-06 21:52: Train Epoch 12: 3/24 Loss: 0.230833
2023-01-06 21:52: Train Epoch 12: 7/24 Loss: 0.211326
2023-01-06 21:52: Train Epoch 12: 11/24 Loss: 0.196451
2023-01-06 21:52: Train Epoch 12: 15/24 Loss: 0.237805
2023-01-06 21:52: Train Epoch 12: 19/24 Loss: 0.207847
2023-01-06 21:52: Train Epoch 12: 23/24 Loss: 0.165112
2023-01-06 21:52: **********Train Epoch 12: averaged Loss: 0.208229 
2023-01-06 21:52: 
Epoch time elapsed: 67.24234390258789

2023-01-06 21:53: 
 metrics validation: {'precision': 0.6819047619047619, 'recall': 0.716, 'f1-score': 0.6985365853658536, 'support': 500, 'AUC': 0.805948, 'AUCPR': 0.6963702120732339, 'TP': 358, 'FP': 167, 'TN': 833, 'FN': 142} 

2023-01-06 21:53: **********Val Epoch 12: average Loss: 0.250174
2023-01-06 21:53: Train Epoch 13: 3/24 Loss: 0.191828
2023-01-06 21:53: Train Epoch 13: 7/24 Loss: 0.220883
2023-01-06 21:53: Train Epoch 13: 11/24 Loss: 0.234329
2023-01-06 21:54: Train Epoch 13: 15/24 Loss: 0.192304
2023-01-06 21:54: Train Epoch 13: 19/24 Loss: 0.232685
2023-01-06 21:54: Train Epoch 13: 23/24 Loss: 0.179478
2023-01-06 21:54: **********Train Epoch 13: averaged Loss: 0.208585 
2023-01-06 21:54: 
Epoch time elapsed: 71.26948618888855

2023-01-06 21:54: 
 metrics validation: {'precision': 0.706601466992665, 'recall': 0.578, 'f1-score': 0.6358635863586358, 'support': 500, 'AUC': 0.8043060000000001, 'AUCPR': 0.6949054788300194, 'TP': 289, 'FP': 120, 'TN': 880, 'FN': 211} 

2023-01-06 21:54: **********Val Epoch 13: average Loss: 0.252754
2023-01-06 21:55: Train Epoch 14: 3/24 Loss: 0.219996
2023-01-06 21:55: Train Epoch 14: 7/24 Loss: 0.214272
2023-01-06 21:55: Train Epoch 14: 11/24 Loss: 0.197969
2023-01-06 21:55: Train Epoch 14: 15/24 Loss: 0.217180
2023-01-06 21:55: Train Epoch 14: 19/24 Loss: 0.192365
2023-01-06 21:56: Train Epoch 14: 23/24 Loss: 0.170374
2023-01-06 21:56: **********Train Epoch 14: averaged Loss: 0.202026 
2023-01-06 21:56: 
Epoch time elapsed: 72.76030611991882

2023-01-06 21:56: 
 metrics validation: {'precision': 0.7223796033994334, 'recall': 0.51, 'f1-score': 0.5978898007033998, 'support': 500, 'AUC': 0.8013379999999999, 'AUCPR': 0.6915789601495582, 'TP': 255, 'FP': 98, 'TN': 902, 'FN': 245} 

2023-01-06 21:56: **********Val Epoch 14: average Loss: 0.257119
2023-01-06 21:56: Train Epoch 15: 3/24 Loss: 0.226980
2023-01-06 21:56: Train Epoch 15: 7/24 Loss: 0.224431
2023-01-06 21:57: Train Epoch 15: 11/24 Loss: 0.214561
2023-01-06 21:57: Train Epoch 15: 15/24 Loss: 0.200132
2023-01-06 21:57: Train Epoch 15: 19/24 Loss: 0.221082
2023-01-06 21:57: Train Epoch 15: 23/24 Loss: 0.186141
2023-01-06 21:57: **********Train Epoch 15: averaged Loss: 0.212221 
2023-01-06 21:57: 
Epoch time elapsed: 72.90786075592041

2023-01-06 21:57: 
 metrics validation: {'precision': 0.7360703812316716, 'recall': 0.502, 'f1-score': 0.5969084423305588, 'support': 500, 'AUC': 0.80197, 'AUCPR': 0.6921673663434986, 'TP': 251, 'FP': 90, 'TN': 910, 'FN': 249} 

2023-01-06 21:57: **********Val Epoch 15: average Loss: 0.257332
2023-01-06 21:58: Train Epoch 16: 3/24 Loss: 0.211571
2023-01-06 21:58: Train Epoch 16: 7/24 Loss: 0.198441
2023-01-06 21:58: Train Epoch 16: 11/24 Loss: 0.222888
2023-01-06 21:58: Train Epoch 16: 15/24 Loss: 0.217700
2023-01-06 21:58: Train Epoch 16: 19/24 Loss: 0.173106
2023-01-06 21:59: Train Epoch 16: 23/24 Loss: 0.176817
2023-01-06 21:59: **********Train Epoch 16: averaged Loss: 0.200087 
2023-01-06 21:59: 
Epoch time elapsed: 64.8442268371582

2023-01-06 21:59: 
 metrics validation: {'precision': 0.6956521739130435, 'recall': 0.704, 'f1-score': 0.6998011928429423, 'support': 500, 'AUC': 0.80607, 'AUCPR': 0.6958270568148562, 'TP': 352, 'FP': 154, 'TN': 846, 'FN': 148} 

2023-01-06 21:59: **********Val Epoch 16: average Loss: 0.249843
2023-01-06 21:59: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-06 21:59: Total training time: 28.1769min, best loss: 0.249574
2023-01-06 21:59: Saving current best model to /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010621311405767569386/best_model.pth
2023-01-06 21:59: 
 Testing metrics {'precision': 0.758130081300813, 'recall': 0.746, 'f1-score': 0.7520161290322581, 'support': 500, 'AUC': 0.8694, 'AUCPR': 0.795094187244085, 'TP': 373, 'FP': 119, 'TN': 881, 'FN': 127} 

2023-01-06 22:00: 
 Testing metrics {'precision': 0.8502772643253235, 'recall': 0.92, 'f1-score': 0.8837656099903939, 'support': 500, 'AUC': 0.963812, 'AUCPR': 0.9420608579686257, 'TP': 460, 'FP': 81, 'TN': 919, 'FN': 40} 

