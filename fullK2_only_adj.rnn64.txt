2023-01-07 23:44: log dir: /home/joel.chacon/tmp/Graphs/WildFire_GCN/experiments/2020/2023010723443607695754013
2023-01-07 23:44: Experiment log path in: /home/joel.chacon/tmp/Graphs/WildFire_GCN/experiments/2020/2023010723443607695754013
2023-01-07 23:44: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/Graphs/WildFire_GCN/experiments/2020/2023010723443607695754013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=64, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-07 23:44: Argument batch_size: 256
2023-01-07 23:44: Argument clc: 'vec'
2023-01-07 23:44: Argument cuda: True
2023-01-07 23:44: Argument dataset: '2020'
2023-01-07 23:44: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-07 23:44: Argument debug: False
2023-01-07 23:44: Argument default_graph: True
2023-01-07 23:44: Argument device: 'cpu'
2023-01-07 23:44: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-07 23:44: Argument early_stop: True
2023-01-07 23:44: Argument early_stop_patience: 8
2023-01-07 23:44: Argument embed_dim: 64
2023-01-07 23:44: Argument epochs: 30
2023-01-07 23:44: Argument grad_norm: False
2023-01-07 23:44: Argument horizon: 1
2023-01-07 23:44: Argument input_dim: 25
2023-01-07 23:44: Argument lag: 10
2023-01-07 23:44: Argument link_len: 2
2023-01-07 23:44: Argument log_dir: '/home/joel.chacon/tmp/Graphs/WildFire_GCN/experiments/2020/2023010723443607695754013'
2023-01-07 23:44: Argument log_step: 1
2023-01-07 23:44: Argument loss_func: 'nllloss'
2023-01-07 23:44: Argument lr_decay: True
2023-01-07 23:44: Argument lr_decay_rate: 0.1
2023-01-07 23:44: Argument lr_decay_step: '20'
2023-01-07 23:44: Argument lr_init: 0.0001
2023-01-07 23:44: Argument max_grad_norm: 5
2023-01-07 23:44: Argument minbatch_size: 64
2023-01-07 23:44: Argument mode: 'train'
2023-01-07 23:44: Argument model: 'fire_GCN'
2023-01-07 23:44: Argument nan_fill: -1.0
2023-01-07 23:44: Argument num_layers: 1
2023-01-07 23:44: Argument num_nodes: 625
2023-01-07 23:44: Argument num_workers: 12
2023-01-07 23:44: Argument output_dim: 2
2023-01-07 23:44: Argument patch_height: 25
2023-01-07 23:44: Argument patch_width: 25
2023-01-07 23:44: Argument persistent_workers: True
2023-01-07 23:44: Argument pin_memory: True
2023-01-07 23:44: Argument plot: False
2023-01-07 23:44: Argument positive_weight: 0.5
2023-01-07 23:44: Argument prefetch_factor: 2
2023-01-07 23:44: Argument real_value: True
2023-01-07 23:44: Argument rnn_units: 64
2023-01-07 23:44: Argument seed: 10000
2023-01-07 23:44: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-07 23:44: Argument teacher_forcing: False
2023-01-07 23:44: Argument weight_decay: 0.0
2023-01-07 23:44: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool_adj torch.Size([64, 2, 89, 64]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 64]) True
encoder.cell_list.0.gate.bias_pool_adj torch.Size([64, 128]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool_adj torch.Size([64, 2, 89, 32]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 32]) True
encoder.cell_list.0.update.bias_pool_adj torch.Size([64, 64]) True
encoder.cell_list.0.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 40000]) True
fc1.bias torch.Size([2]) True
Total params num: 1232136
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/Graphs/WildFire_GCN/experiments/2020/2023010723443607695754013/run.log
2023-01-07 23:44: Train Epoch 1: 3/634 Loss: 0.378288
2023-01-07 23:45: Train Epoch 1: 7/634 Loss: 0.369190
2023-01-07 23:45: Train Epoch 1: 11/634 Loss: 0.431006
2023-01-07 23:45: Train Epoch 1: 15/634 Loss: 0.323272
2023-01-07 23:45: Train Epoch 1: 19/634 Loss: 0.298933
2023-01-07 23:46: Train Epoch 1: 23/634 Loss: 0.327852
2023-01-07 23:46: Train Epoch 1: 27/634 Loss: 0.372409
2023-01-07 23:46: Train Epoch 1: 31/634 Loss: 0.286752
2023-01-07 23:46: Train Epoch 1: 35/634 Loss: 0.253219
2023-01-07 23:47: Train Epoch 1: 39/634 Loss: 0.249570
2023-01-07 23:47: Train Epoch 1: 43/634 Loss: 0.298483
2023-01-07 23:47: Train Epoch 1: 47/634 Loss: 0.319978
2023-01-07 23:47: Train Epoch 1: 51/634 Loss: 0.287438
2023-01-07 23:48: Train Epoch 1: 55/634 Loss: 0.244944
2023-01-07 23:48: Train Epoch 1: 59/634 Loss: 0.242638
2023-01-07 23:48: Train Epoch 1: 63/634 Loss: 0.250048
2023-01-07 23:49: Train Epoch 1: 67/634 Loss: 0.254133
2023-01-07 23:49: Train Epoch 1: 71/634 Loss: 0.283310
2023-01-07 23:49: Train Epoch 1: 75/634 Loss: 0.229624
2023-01-07 23:49: Train Epoch 1: 79/634 Loss: 0.233536
2023-01-07 23:50: Train Epoch 1: 83/634 Loss: 0.285904
2023-01-07 23:50: Train Epoch 1: 87/634 Loss: 0.245143
2023-01-07 23:50: Train Epoch 1: 91/634 Loss: 0.232296
2023-01-07 23:50: Train Epoch 1: 95/634 Loss: 0.216246
2023-01-07 23:51: Train Epoch 1: 99/634 Loss: 0.251915
2023-01-07 23:51: Train Epoch 1: 103/634 Loss: 0.234612
2023-01-07 23:51: Train Epoch 1: 107/634 Loss: 0.223476
2023-01-07 23:51: Train Epoch 1: 111/634 Loss: 0.243600
2023-01-07 23:52: Train Epoch 1: 115/634 Loss: 0.267131
2023-01-07 23:52: Train Epoch 1: 119/634 Loss: 0.228636
2023-01-07 23:52: Train Epoch 1: 123/634 Loss: 0.227115
2023-01-07 23:52: Train Epoch 1: 127/634 Loss: 0.239298
2023-01-07 23:53: Train Epoch 1: 131/634 Loss: 0.192981
2023-01-07 23:53: Train Epoch 1: 135/634 Loss: 0.215936
2023-01-07 23:53: Train Epoch 1: 139/634 Loss: 0.229289
2023-01-07 23:53: Train Epoch 1: 143/634 Loss: 0.215772
2023-01-07 23:54: Train Epoch 1: 147/634 Loss: 0.205350
2023-01-07 23:54: Train Epoch 1: 151/634 Loss: 0.234082
2023-01-07 23:54: Train Epoch 1: 155/634 Loss: 0.244654
2023-01-07 23:54: Train Epoch 1: 159/634 Loss: 0.206875
2023-01-07 23:55: Train Epoch 1: 163/634 Loss: 0.232000
2023-01-07 23:55: Train Epoch 1: 167/634 Loss: 0.244254
2023-01-07 23:55: Train Epoch 1: 171/634 Loss: 0.215148
2023-01-07 23:55: Train Epoch 1: 175/634 Loss: 0.203684
2023-01-07 23:56: Train Epoch 1: 179/634 Loss: 0.246765
2023-01-07 23:56: Train Epoch 1: 183/634 Loss: 0.227339
2023-01-07 23:56: Train Epoch 1: 187/634 Loss: 0.198859
2023-01-07 23:57: Train Epoch 1: 191/634 Loss: 0.201903
2023-01-07 23:57: Train Epoch 1: 195/634 Loss: 0.219530
2023-01-07 23:57: Train Epoch 1: 199/634 Loss: 0.206337
2023-01-07 23:57: Train Epoch 1: 203/634 Loss: 0.219735
2023-01-07 23:58: Train Epoch 1: 207/634 Loss: 0.241641
2023-01-07 23:58: Train Epoch 1: 211/634 Loss: 0.229465
2023-01-07 23:58: Train Epoch 1: 215/634 Loss: 0.209643
2023-01-07 23:58: Train Epoch 1: 219/634 Loss: 0.218400
2023-01-07 23:59: Train Epoch 1: 223/634 Loss: 0.191352
2023-01-07 23:59: Train Epoch 1: 227/634 Loss: 0.207698
2023-01-07 23:59: Train Epoch 1: 231/634 Loss: 0.216929
2023-01-07 23:59: Train Epoch 1: 235/634 Loss: 0.196309
2023-01-08 00:00: Train Epoch 1: 239/634 Loss: 0.225428
2023-01-08 00:00: Train Epoch 1: 243/634 Loss: 0.199025
2023-01-08 00:00: Train Epoch 1: 247/634 Loss: 0.208447
2023-01-08 00:00: Train Epoch 1: 251/634 Loss: 0.218552
2023-01-08 00:01: Train Epoch 1: 255/634 Loss: 0.216247
2023-01-08 00:01: Train Epoch 1: 259/634 Loss: 0.226602
2023-01-08 00:01: Train Epoch 1: 263/634 Loss: 0.209376
2023-01-08 00:01: Train Epoch 1: 267/634 Loss: 0.235582
2023-01-08 00:02: Train Epoch 1: 271/634 Loss: 0.207706
2023-01-08 00:02: Train Epoch 1: 275/634 Loss: 0.190561
2023-01-08 00:02: Train Epoch 1: 279/634 Loss: 0.218799
2023-01-08 00:02: Train Epoch 1: 283/634 Loss: 0.219802
2023-01-08 00:03: Train Epoch 1: 287/634 Loss: 0.245723
2023-01-08 00:03: Train Epoch 1: 291/634 Loss: 0.245671
2023-01-08 00:03: Train Epoch 1: 295/634 Loss: 0.225220
2023-01-08 00:03: Train Epoch 1: 299/634 Loss: 0.195611
2023-01-08 00:04: Train Epoch 1: 303/634 Loss: 0.202445
2023-01-08 00:04: Train Epoch 1: 307/634 Loss: 0.207638
2023-01-08 00:04: Train Epoch 1: 311/634 Loss: 0.237748
2023-01-08 00:04: Train Epoch 1: 315/634 Loss: 0.213972
2023-01-08 00:05: Train Epoch 1: 319/634 Loss: 0.203747
2023-01-08 00:05: Train Epoch 1: 323/634 Loss: 0.197164
2023-01-08 00:05: Train Epoch 1: 327/634 Loss: 0.202820
2023-01-08 00:05: Train Epoch 1: 331/634 Loss: 0.200003
2023-01-08 00:06: Train Epoch 1: 335/634 Loss: 0.190852
2023-01-08 00:06: Train Epoch 1: 339/634 Loss: 0.222056
2023-01-08 00:06: Train Epoch 1: 343/634 Loss: 0.232106
2023-01-08 00:06: Train Epoch 1: 347/634 Loss: 0.221699
2023-01-08 00:07: Train Epoch 1: 351/634 Loss: 0.237677
2023-01-08 00:07: Train Epoch 1: 355/634 Loss: 0.221648
2023-01-08 00:07: Train Epoch 1: 359/634 Loss: 0.203921
2023-01-08 00:07: Train Epoch 1: 363/634 Loss: 0.169552
2023-01-08 00:08: Train Epoch 1: 367/634 Loss: 0.217907
2023-01-08 00:08: Train Epoch 1: 371/634 Loss: 0.206870
2023-01-08 00:08: Train Epoch 1: 375/634 Loss: 0.200793
2023-01-08 00:08: Train Epoch 1: 379/634 Loss: 0.251446
2023-01-08 00:09: Train Epoch 1: 383/634 Loss: 0.223716
2023-01-08 00:09: Train Epoch 1: 387/634 Loss: 0.184018
2023-01-08 00:09: Train Epoch 1: 391/634 Loss: 0.199081
2023-01-08 00:09: Train Epoch 1: 395/634 Loss: 0.211209
2023-01-08 00:10: Train Epoch 1: 399/634 Loss: 0.232449
2023-01-08 00:10: Train Epoch 1: 403/634 Loss: 0.177372
2023-01-08 00:10: Train Epoch 1: 407/634 Loss: 0.193175
2023-01-08 00:10: Train Epoch 1: 411/634 Loss: 0.225324
2023-01-08 00:11: Train Epoch 1: 415/634 Loss: 0.204382
2023-01-08 00:11: Train Epoch 1: 419/634 Loss: 0.194109
2023-01-08 00:11: Train Epoch 1: 423/634 Loss: 0.189912
2023-01-08 00:11: Train Epoch 1: 427/634 Loss: 0.225071
2023-01-08 00:11: Train Epoch 1: 431/634 Loss: 0.216799
2023-01-08 00:12: Train Epoch 1: 435/634 Loss: 0.204705
2023-01-08 00:12: Train Epoch 1: 439/634 Loss: 0.254855
2023-01-08 00:12: Train Epoch 1: 443/634 Loss: 0.225781
2023-01-08 00:13: Train Epoch 1: 447/634 Loss: 0.214673
2023-01-08 00:13: Train Epoch 1: 451/634 Loss: 0.205119
2023-01-08 00:13: Train Epoch 1: 455/634 Loss: 0.222647
2023-01-08 00:13: Train Epoch 1: 459/634 Loss: 0.221361
2023-01-08 00:14: Train Epoch 1: 463/634 Loss: 0.230893
2023-01-08 00:14: Train Epoch 1: 467/634 Loss: 0.236321
2023-01-08 00:14: Train Epoch 1: 471/634 Loss: 0.209301
2023-01-08 00:14: Train Epoch 1: 475/634 Loss: 0.183040
2023-01-08 00:15: Train Epoch 1: 479/634 Loss: 0.185202
2023-01-08 00:15: Train Epoch 1: 483/634 Loss: 0.201169
2023-01-08 00:15: Train Epoch 1: 487/634 Loss: 0.221333
2023-01-08 00:15: Train Epoch 1: 491/634 Loss: 0.228138
2023-01-08 00:16: Train Epoch 1: 495/634 Loss: 0.229243
2023-01-08 00:16: Train Epoch 1: 499/634 Loss: 0.224636
2023-01-08 00:16: Train Epoch 1: 503/634 Loss: 0.237547
2023-01-08 00:16: Train Epoch 1: 507/634 Loss: 0.208257
2023-01-08 00:17: Train Epoch 1: 511/634 Loss: 0.203877
2023-01-08 00:17: Train Epoch 1: 515/634 Loss: 0.208914
2023-01-08 00:17: Train Epoch 1: 519/634 Loss: 0.209311
2023-01-08 00:17: Train Epoch 1: 523/634 Loss: 0.215987
2023-01-08 00:17: Train Epoch 1: 527/634 Loss: 0.205565
2023-01-08 00:18: Train Epoch 1: 531/634 Loss: 0.242641
2023-01-08 00:18: Train Epoch 1: 535/634 Loss: 0.220183
2023-01-08 00:18: Train Epoch 1: 539/634 Loss: 0.210762
2023-01-08 00:19: Train Epoch 1: 543/634 Loss: 0.230407
2023-01-08 00:19: Train Epoch 1: 547/634 Loss: 0.213546
2023-01-08 00:19: Train Epoch 1: 551/634 Loss: 0.218387
2023-01-08 00:19: Train Epoch 1: 555/634 Loss: 0.237115
2023-01-08 00:20: Train Epoch 1: 559/634 Loss: 0.199594
2023-01-08 00:20: Train Epoch 1: 563/634 Loss: 0.225367
2023-01-08 00:20: Train Epoch 1: 567/634 Loss: 0.207285
2023-01-08 00:20: Train Epoch 1: 571/634 Loss: 0.198036
2023-01-08 00:21: Train Epoch 1: 575/634 Loss: 0.211367
2023-01-08 00:21: Train Epoch 1: 579/634 Loss: 0.211707
2023-01-08 00:21: Train Epoch 1: 583/634 Loss: 0.194188
2023-01-08 00:21: Train Epoch 1: 587/634 Loss: 0.212993
2023-01-08 00:22: Train Epoch 1: 591/634 Loss: 0.211709
2023-01-08 00:22: Train Epoch 1: 595/634 Loss: 0.214327
2023-01-08 00:22: Train Epoch 1: 599/634 Loss: 0.204152
2023-01-08 00:22: Train Epoch 1: 603/634 Loss: 0.189726
2023-01-08 00:22: Train Epoch 1: 607/634 Loss: 0.200823
2023-01-08 00:23: Train Epoch 1: 611/634 Loss: 0.204247
2023-01-08 00:23: Train Epoch 1: 615/634 Loss: 0.202782
2023-01-08 00:23: Train Epoch 1: 619/634 Loss: 0.193757
2023-01-08 00:23: Train Epoch 1: 623/634 Loss: 0.225572
2023-01-08 00:24: Train Epoch 1: 627/634 Loss: 0.212827
2023-01-08 00:24: Train Epoch 1: 631/634 Loss: 0.186004
2023-01-08 00:24: Train Epoch 1: 633/634 Loss: 0.086250
2023-01-08 00:24: **********Train Epoch 1: averaged Loss: 0.225551 
2023-01-08 00:24: 
Epoch time elapsed: 2399.872388124466

2023-01-08 00:25: 
 metrics validation: {'precision': 0.6986100950987564, 'recall': 0.7346153846153847, 'f1-score': 0.7161604799400074, 'support': 1300, 'AUC': 0.8271062130177516, 'AUCPR': 0.702785588082184, 'TP': 955, 'FP': 412, 'TN': 2188, 'FN': 345} 

2023-01-08 00:25: **********Val Epoch 1: average Loss: 0.232408
2023-01-08 00:25: *********************************Current best model saved!
2023-01-08 00:26: 
 Testing metrics {'precision': 0.7429022082018928, 'recall': 0.7671009771986971, 'f1-score': 0.7548076923076924, 'support': 1228, 'AUC': 0.8634254408534838, 'AUCPR': 0.7719138925843125, 'TP': 942, 'FP': 326, 'TN': 2130, 'FN': 286} 

2023-01-08 00:31: 
 Testing metrics {'precision': 0.8279659256181175, 'recall': 0.9042432493759928, 'f1-score': 0.8644251626898047, 'support': 4407, 'AUC': 0.9636289379959446, 'AUCPR': 0.9363656362996245, 'TP': 3985, 'FP': 828, 'TN': 7986, 'FN': 422} 

2023-01-08 00:31: Train Epoch 2: 3/634 Loss: 0.197421
2023-01-08 00:31: Train Epoch 2: 7/634 Loss: 0.218001
2023-01-08 00:32: Train Epoch 2: 11/634 Loss: 0.225188
2023-01-08 00:32: Train Epoch 2: 15/634 Loss: 0.200792
2023-01-08 00:32: Train Epoch 2: 19/634 Loss: 0.207089
2023-01-08 00:32: Train Epoch 2: 23/634 Loss: 0.237753
2023-01-08 00:33: Train Epoch 2: 27/634 Loss: 0.219135
2023-01-08 00:33: Train Epoch 2: 31/634 Loss: 0.227642
2023-01-08 00:33: Train Epoch 2: 35/634 Loss: 0.196441
2023-01-08 00:33: Train Epoch 2: 39/634 Loss: 0.193512
2023-01-08 00:34: Train Epoch 2: 43/634 Loss: 0.209210
2023-01-08 00:34: Train Epoch 2: 47/634 Loss: 0.203716
2023-01-08 00:34: Train Epoch 2: 51/634 Loss: 0.196950
2023-01-08 00:34: Train Epoch 2: 55/634 Loss: 0.201993
2023-01-08 00:35: Train Epoch 2: 59/634 Loss: 0.234112
2023-01-08 00:35: Train Epoch 2: 63/634 Loss: 0.232024
2023-01-08 00:35: Train Epoch 2: 67/634 Loss: 0.207732
2023-01-08 00:35: Train Epoch 2: 71/634 Loss: 0.185843
2023-01-08 00:36: Train Epoch 2: 75/634 Loss: 0.215708
2023-01-08 00:36: Train Epoch 2: 79/634 Loss: 0.201414
2023-01-08 00:36: Train Epoch 2: 83/634 Loss: 0.237022
2023-01-08 00:37: Train Epoch 2: 87/634 Loss: 0.212051
2023-01-08 00:37: Train Epoch 2: 91/634 Loss: 0.192584
2023-01-08 00:37: Train Epoch 2: 95/634 Loss: 0.233811
2023-01-08 00:37: Train Epoch 2: 99/634 Loss: 0.215917
2023-01-08 00:38: Train Epoch 2: 103/634 Loss: 0.185506
2023-01-08 00:38: Train Epoch 2: 107/634 Loss: 0.212149
2023-01-08 00:38: Train Epoch 2: 111/634 Loss: 0.219673
2023-01-08 00:38: Train Epoch 2: 115/634 Loss: 0.201687
2023-01-08 00:39: Train Epoch 2: 119/634 Loss: 0.231159
2023-01-08 00:39: Train Epoch 2: 123/634 Loss: 0.211879
2023-01-08 00:39: Train Epoch 2: 127/634 Loss: 0.187903
2023-01-08 00:39: Train Epoch 2: 131/634 Loss: 0.219725
2023-01-08 00:40: Train Epoch 2: 135/634 Loss: 0.210370
2023-01-08 00:40: Train Epoch 2: 139/634 Loss: 0.213652
2023-01-08 00:40: Train Epoch 2: 143/634 Loss: 0.210551
2023-01-08 00:40: Train Epoch 2: 147/634 Loss: 0.219951
2023-01-08 00:41: Train Epoch 2: 151/634 Loss: 0.195892
2023-01-08 00:41: Train Epoch 2: 155/634 Loss: 0.206102
2023-01-08 00:41: Train Epoch 2: 159/634 Loss: 0.176619
2023-01-08 00:42: Train Epoch 2: 163/634 Loss: 0.217691
2023-01-08 00:42: Train Epoch 2: 167/634 Loss: 0.183201
2023-01-08 00:42: Train Epoch 2: 171/634 Loss: 0.196829
2023-01-08 00:42: Train Epoch 2: 175/634 Loss: 0.218514
2023-01-08 00:43: Train Epoch 2: 179/634 Loss: 0.227155
2023-01-08 00:43: Train Epoch 2: 183/634 Loss: 0.201653
2023-01-08 00:43: Train Epoch 2: 187/634 Loss: 0.178020
2023-01-08 00:43: Train Epoch 2: 191/634 Loss: 0.196919
2023-01-08 00:44: Train Epoch 2: 195/634 Loss: 0.193319
2023-01-08 00:44: Train Epoch 2: 199/634 Loss: 0.202358
2023-01-08 00:44: Train Epoch 2: 203/634 Loss: 0.212431
2023-01-08 00:44: Train Epoch 2: 207/634 Loss: 0.206806
2023-01-08 00:45: Train Epoch 2: 211/634 Loss: 0.208463
2023-01-08 00:45: Train Epoch 2: 215/634 Loss: 0.196061
2023-01-08 00:45: Train Epoch 2: 219/634 Loss: 0.216599
2023-01-08 00:45: Train Epoch 2: 223/634 Loss: 0.169137
2023-01-08 00:46: Train Epoch 2: 227/634 Loss: 0.236552
2023-01-08 00:46: Train Epoch 2: 231/634 Loss: 0.186274
2023-01-08 00:46: Train Epoch 2: 235/634 Loss: 0.199023
2023-01-08 00:46: Train Epoch 2: 239/634 Loss: 0.197561
2023-01-08 00:47: Train Epoch 2: 243/634 Loss: 0.188720
2023-01-08 00:47: Train Epoch 2: 247/634 Loss: 0.222405
2023-01-08 00:47: Train Epoch 2: 251/634 Loss: 0.215310
2023-01-08 00:47: Train Epoch 2: 255/634 Loss: 0.196297
2023-01-08 00:48: Train Epoch 2: 259/634 Loss: 0.196173
2023-01-08 00:48: Train Epoch 2: 263/634 Loss: 0.208495
2023-01-08 00:48: Train Epoch 2: 267/634 Loss: 0.179866
2023-01-08 00:49: Train Epoch 2: 271/634 Loss: 0.228822
2023-01-08 00:49: Train Epoch 2: 275/634 Loss: 0.194710
2023-01-08 00:49: Train Epoch 2: 279/634 Loss: 0.204304
2023-01-08 00:49: Train Epoch 2: 283/634 Loss: 0.174131
2023-01-08 00:50: Train Epoch 2: 287/634 Loss: 0.184967
2023-01-08 00:50: Train Epoch 2: 291/634 Loss: 0.221293
2023-01-08 00:50: Train Epoch 2: 295/634 Loss: 0.183913
2023-01-08 00:50: Train Epoch 2: 299/634 Loss: 0.202133
2023-01-08 00:51: Train Epoch 2: 303/634 Loss: 0.242585
2023-01-08 00:51: Train Epoch 2: 307/634 Loss: 0.193864
2023-01-08 00:51: Train Epoch 2: 311/634 Loss: 0.229548
2023-01-08 00:51: Train Epoch 2: 315/634 Loss: 0.232565
2023-01-08 00:52: Train Epoch 2: 319/634 Loss: 0.205699
2023-01-08 00:52: Train Epoch 2: 323/634 Loss: 0.232387
2023-01-08 00:52: Train Epoch 2: 327/634 Loss: 0.183662
2023-01-08 00:53: Train Epoch 2: 331/634 Loss: 0.199046
2023-01-08 00:53: Train Epoch 2: 335/634 Loss: 0.174204
2023-01-08 00:53: Train Epoch 2: 339/634 Loss: 0.197257
2023-01-08 00:53: Train Epoch 2: 343/634 Loss: 0.214411
2023-01-08 00:54: Train Epoch 2: 347/634 Loss: 0.209333
2023-01-08 00:54: Train Epoch 2: 351/634 Loss: 0.188949
2023-01-08 00:54: Train Epoch 2: 355/634 Loss: 0.193364
2023-01-08 00:54: Train Epoch 2: 359/634 Loss: 0.196451
2023-01-08 00:55: Train Epoch 2: 363/634 Loss: 0.197499
2023-01-08 00:55: Train Epoch 2: 367/634 Loss: 0.215455
2023-01-08 00:55: Train Epoch 2: 371/634 Loss: 0.183265
2023-01-08 00:56: Train Epoch 2: 375/634 Loss: 0.192228
2023-01-08 00:56: Train Epoch 2: 379/634 Loss: 0.154085
2023-01-08 00:56: Train Epoch 2: 383/634 Loss: 0.202147
2023-01-08 00:56: Train Epoch 2: 387/634 Loss: 0.234718
2023-01-08 00:57: Train Epoch 2: 391/634 Loss: 0.244155
2023-01-08 00:57: Train Epoch 2: 395/634 Loss: 0.169225
2023-01-08 00:57: Train Epoch 2: 399/634 Loss: 0.187073
2023-01-08 00:57: Train Epoch 2: 403/634 Loss: 0.191152
2023-01-08 00:58: Train Epoch 2: 407/634 Loss: 0.228330
2023-01-08 00:58: Train Epoch 2: 411/634 Loss: 0.188302
2023-01-08 00:58: Train Epoch 2: 415/634 Loss: 0.219055
2023-01-08 00:58: Train Epoch 2: 419/634 Loss: 0.200587
2023-01-08 00:59: Train Epoch 2: 423/634 Loss: 0.189623
2023-01-08 00:59: Train Epoch 2: 427/634 Loss: 0.161281
2023-01-08 00:59: Train Epoch 2: 431/634 Loss: 0.218877
2023-01-08 01:00: Train Epoch 2: 435/634 Loss: 0.228101
2023-01-08 01:00: Train Epoch 2: 439/634 Loss: 0.197530
2023-01-08 01:00: Train Epoch 2: 443/634 Loss: 0.186549
2023-01-08 01:00: Train Epoch 2: 447/634 Loss: 0.216267
2023-01-08 01:01: Train Epoch 2: 451/634 Loss: 0.190805
2023-01-08 01:01: Train Epoch 2: 455/634 Loss: 0.200558
2023-01-08 01:01: Train Epoch 2: 459/634 Loss: 0.198014
2023-01-08 01:01: Train Epoch 2: 463/634 Loss: 0.182611
2023-01-08 01:02: Train Epoch 2: 467/634 Loss: 0.170158
2023-01-08 01:02: Train Epoch 2: 471/634 Loss: 0.189964
2023-01-08 01:02: Train Epoch 2: 475/634 Loss: 0.172424
2023-01-08 01:02: Train Epoch 2: 479/634 Loss: 0.215041
2023-01-08 01:03: Train Epoch 2: 483/634 Loss: 0.215286
2023-01-08 01:03: Train Epoch 2: 487/634 Loss: 0.209204
2023-01-08 01:03: Train Epoch 2: 491/634 Loss: 0.194117
2023-01-08 01:03: Train Epoch 2: 495/634 Loss: 0.197464
2023-01-08 01:04: Train Epoch 2: 499/634 Loss: 0.195795
2023-01-08 01:04: Train Epoch 2: 503/634 Loss: 0.190104
2023-01-08 01:04: Train Epoch 2: 507/634 Loss: 0.178162
2023-01-08 01:04: Train Epoch 2: 511/634 Loss: 0.214298
2023-01-08 01:05: Train Epoch 2: 515/634 Loss: 0.186734
2023-01-08 01:05: Train Epoch 2: 519/634 Loss: 0.195943
2023-01-08 01:05: Train Epoch 2: 523/634 Loss: 0.199202
2023-01-08 01:05: Train Epoch 2: 527/634 Loss: 0.188822
2023-01-08 01:06: Train Epoch 2: 531/634 Loss: 0.176565
2023-01-08 01:06: Train Epoch 2: 535/634 Loss: 0.190131
2023-01-08 01:06: Train Epoch 2: 539/634 Loss: 0.175662
2023-01-08 01:06: Train Epoch 2: 543/634 Loss: 0.220842
2023-01-08 01:07: Train Epoch 2: 547/634 Loss: 0.190081
2023-01-08 01:07: Train Epoch 2: 551/634 Loss: 0.174299
2023-01-08 01:07: Train Epoch 2: 555/634 Loss: 0.188656
2023-01-08 01:07: Train Epoch 2: 559/634 Loss: 0.203882
2023-01-08 01:08: Train Epoch 2: 563/634 Loss: 0.180247
2023-01-08 01:08: Train Epoch 2: 567/634 Loss: 0.197171
2023-01-08 01:08: Train Epoch 2: 571/634 Loss: 0.221952
2023-01-08 01:08: Train Epoch 2: 575/634 Loss: 0.188368
2023-01-08 01:09: Train Epoch 2: 579/634 Loss: 0.182906
2023-01-08 01:09: Train Epoch 2: 583/634 Loss: 0.219144
2023-01-08 01:09: Train Epoch 2: 587/634 Loss: 0.204887
2023-01-08 01:10: Train Epoch 2: 591/634 Loss: 0.210324
2023-01-08 01:10: Train Epoch 2: 595/634 Loss: 0.217894
2023-01-08 01:10: Train Epoch 2: 599/634 Loss: 0.203005
2023-01-08 01:10: Train Epoch 2: 603/634 Loss: 0.211453
2023-01-08 01:11: Train Epoch 2: 607/634 Loss: 0.210969
2023-01-08 01:11: Train Epoch 2: 611/634 Loss: 0.209888
2023-01-08 01:11: Train Epoch 2: 615/634 Loss: 0.210056
2023-01-08 01:11: Train Epoch 2: 619/634 Loss: 0.217753
2023-01-08 01:12: Train Epoch 2: 623/634 Loss: 0.201239
2023-01-08 01:12: Train Epoch 2: 627/634 Loss: 0.170197
2023-01-08 01:12: Train Epoch 2: 631/634 Loss: 0.204342
2023-01-08 01:12: Train Epoch 2: 633/634 Loss: 0.066511
2023-01-08 01:12: **********Train Epoch 2: averaged Loss: 0.201786 
2023-01-08 01:12: 
Epoch time elapsed: 2493.941244840622

2023-01-08 01:13: 
 metrics validation: {'precision': 0.7810945273631841, 'recall': 0.6038461538461538, 'f1-score': 0.6811279826464208, 'support': 1300, 'AUC': 0.8671458579881657, 'AUCPR': 0.7538490183431095, 'TP': 785, 'FP': 220, 'TN': 2380, 'FN': 515} 

2023-01-08 01:13: **********Val Epoch 2: average Loss: 0.210750
2023-01-08 01:13: *********************************Current best model saved!
2023-01-08 01:15: 
 Testing metrics {'precision': 0.8344086021505376, 'recall': 0.6319218241042345, 'f1-score': 0.7191844300278035, 'support': 1228, 'AUC': 0.8849732490530403, 'AUCPR': 0.8119800324602527, 'TP': 776, 'FP': 154, 'TN': 2302, 'FN': 452} 

2023-01-08 01:19: 
 Testing metrics {'precision': 0.8991279754890408, 'recall': 0.865668255048786, 'f1-score': 0.8820809248554914, 'support': 4407, 'AUC': 0.9663229677356439, 'AUCPR': 0.9358953940563947, 'TP': 3815, 'FP': 428, 'TN': 8386, 'FN': 592} 

2023-01-08 01:19: Train Epoch 3: 3/634 Loss: 0.174129
2023-01-08 01:19: Train Epoch 3: 7/634 Loss: 0.171499
2023-01-08 01:19: Train Epoch 3: 11/634 Loss: 0.208474
2023-01-08 01:20: Train Epoch 3: 15/634 Loss: 0.199023
2023-01-08 01:20: Train Epoch 3: 19/634 Loss: 0.189402
2023-01-08 01:20: Train Epoch 3: 23/634 Loss: 0.182609
2023-01-08 01:21: Train Epoch 3: 27/634 Loss: 0.168831
2023-01-08 01:21: Train Epoch 3: 31/634 Loss: 0.189127
2023-01-08 01:21: Train Epoch 3: 35/634 Loss: 0.247357
2023-01-08 01:21: Train Epoch 3: 39/634 Loss: 0.185525
2023-01-08 01:22: Train Epoch 3: 43/634 Loss: 0.185229
2023-01-08 01:22: Train Epoch 3: 47/634 Loss: 0.186084
2023-01-08 01:22: Train Epoch 3: 51/634 Loss: 0.182701
2023-01-08 01:22: Train Epoch 3: 55/634 Loss: 0.183355
2023-01-08 01:23: Train Epoch 3: 59/634 Loss: 0.189628
2023-01-08 01:23: Train Epoch 3: 63/634 Loss: 0.207595
2023-01-08 01:23: Train Epoch 3: 67/634 Loss: 0.188780
2023-01-08 01:23: Train Epoch 3: 71/634 Loss: 0.186703
2023-01-08 01:24: Train Epoch 3: 75/634 Loss: 0.181341
2023-01-08 01:24: Train Epoch 3: 79/634 Loss: 0.211421
2023-01-08 01:24: Train Epoch 3: 83/634 Loss: 0.210609
2023-01-08 01:24: Train Epoch 3: 87/634 Loss: 0.193739
2023-01-08 01:25: Train Epoch 3: 91/634 Loss: 0.194211
2023-01-08 01:25: Train Epoch 3: 95/634 Loss: 0.184376
2023-01-08 01:25: Train Epoch 3: 99/634 Loss: 0.170440
2023-01-08 01:26: Train Epoch 3: 103/634 Loss: 0.198753
2023-01-08 01:26: Train Epoch 3: 107/634 Loss: 0.188797
2023-01-08 01:26: Train Epoch 3: 111/634 Loss: 0.188847
2023-01-08 01:26: Train Epoch 3: 115/634 Loss: 0.195645
2023-01-08 01:27: Train Epoch 3: 119/634 Loss: 0.210051
2023-01-08 01:27: Train Epoch 3: 123/634 Loss: 0.204958
2023-01-08 01:27: Train Epoch 3: 127/634 Loss: 0.173444
2023-01-08 01:27: Train Epoch 3: 131/634 Loss: 0.152936
2023-01-08 01:28: Train Epoch 3: 135/634 Loss: 0.235516
2023-01-08 01:28: Train Epoch 3: 139/634 Loss: 0.249759
2023-01-08 01:28: Train Epoch 3: 143/634 Loss: 0.192415
2023-01-08 01:28: Train Epoch 3: 147/634 Loss: 0.177356
2023-01-08 01:29: Train Epoch 3: 151/634 Loss: 0.215267
2023-01-08 01:29: Train Epoch 3: 155/634 Loss: 0.170516
2023-01-08 01:29: Train Epoch 3: 159/634 Loss: 0.192711
2023-01-08 01:30: Train Epoch 3: 163/634 Loss: 0.193168
2023-01-08 01:30: Train Epoch 3: 167/634 Loss: 0.224277
2023-01-08 01:30: Train Epoch 3: 171/634 Loss: 0.205385
2023-01-08 01:30: Train Epoch 3: 175/634 Loss: 0.217369
2023-01-08 01:31: Train Epoch 3: 179/634 Loss: 0.191619
2023-01-08 01:31: Train Epoch 3: 183/634 Loss: 0.207837
2023-01-08 01:31: Train Epoch 3: 187/634 Loss: 0.198932
2023-01-08 01:31: Train Epoch 3: 191/634 Loss: 0.227153
2023-01-08 01:32: Train Epoch 3: 195/634 Loss: 0.178726
2023-01-08 01:32: Train Epoch 3: 199/634 Loss: 0.224468
2023-01-08 01:32: Train Epoch 3: 203/634 Loss: 0.157881
2023-01-08 01:33: Train Epoch 3: 207/634 Loss: 0.255524
2023-01-08 01:33: Train Epoch 3: 211/634 Loss: 0.214324
2023-01-08 01:33: Train Epoch 3: 215/634 Loss: 0.202083
2023-01-08 01:33: Train Epoch 3: 219/634 Loss: 0.210836
2023-01-08 01:34: Train Epoch 3: 223/634 Loss: 0.193297
2023-01-08 01:34: Train Epoch 3: 227/634 Loss: 0.165216
2023-01-08 01:34: Train Epoch 3: 231/634 Loss: 0.206731
2023-01-08 01:34: Train Epoch 3: 235/634 Loss: 0.224008
2023-01-08 01:35: Train Epoch 3: 239/634 Loss: 0.176667
2023-01-08 01:35: Train Epoch 3: 243/634 Loss: 0.206700
2023-01-08 01:35: Train Epoch 3: 247/634 Loss: 0.195235
2023-01-08 01:36: Train Epoch 3: 251/634 Loss: 0.206186
2023-01-08 01:36: Train Epoch 3: 255/634 Loss: 0.186775
2023-01-08 01:36: Train Epoch 3: 259/634 Loss: 0.195233
2023-01-08 01:36: Train Epoch 3: 263/634 Loss: 0.168351
2023-01-08 01:37: Train Epoch 3: 267/634 Loss: 0.202318
2023-01-08 01:37: Train Epoch 3: 271/634 Loss: 0.198434
2023-01-08 01:37: Train Epoch 3: 275/634 Loss: 0.172863
2023-01-08 01:37: Train Epoch 3: 279/634 Loss: 0.232566
2023-01-08 01:38: Train Epoch 3: 283/634 Loss: 0.151768
2023-01-08 01:38: Train Epoch 3: 287/634 Loss: 0.176038
2023-01-08 01:38: Train Epoch 3: 291/634 Loss: 0.168669
2023-01-08 01:38: Train Epoch 3: 295/634 Loss: 0.187091
2023-01-08 01:39: Train Epoch 3: 299/634 Loss: 0.183470
2023-01-08 01:39: Train Epoch 3: 303/634 Loss: 0.179261
2023-01-08 01:39: Train Epoch 3: 307/634 Loss: 0.201032
2023-01-08 01:39: Train Epoch 3: 311/634 Loss: 0.191572
2023-01-08 01:40: Train Epoch 3: 315/634 Loss: 0.179828
2023-01-08 01:40: Train Epoch 3: 319/634 Loss: 0.182210
2023-01-08 01:40: Train Epoch 3: 323/634 Loss: 0.190051
2023-01-08 01:40: Train Epoch 3: 327/634 Loss: 0.183447
2023-01-08 01:41: Train Epoch 3: 331/634 Loss: 0.208886
2023-01-08 01:41: Train Epoch 3: 335/634 Loss: 0.187815
2023-01-08 01:41: Train Epoch 3: 339/634 Loss: 0.198030
2023-01-08 01:41: Train Epoch 3: 343/634 Loss: 0.194478
2023-01-08 01:42: Train Epoch 3: 347/634 Loss: 0.154233
2023-01-08 01:42: Train Epoch 3: 351/634 Loss: 0.181450
2023-01-08 01:42: Train Epoch 3: 355/634 Loss: 0.176345
2023-01-08 01:42: Train Epoch 3: 359/634 Loss: 0.161659
2023-01-08 01:43: Train Epoch 3: 363/634 Loss: 0.180755
2023-01-08 01:43: Train Epoch 3: 367/634 Loss: 0.193854
2023-01-08 01:43: Train Epoch 3: 371/634 Loss: 0.196269
2023-01-08 01:43: Train Epoch 3: 375/634 Loss: 0.206938
2023-01-08 01:44: Train Epoch 3: 379/634 Loss: 0.182036
2023-01-08 01:44: Train Epoch 3: 383/634 Loss: 0.230997
2023-01-08 01:44: Train Epoch 3: 387/634 Loss: 0.160445
2023-01-08 01:45: Train Epoch 3: 391/634 Loss: 0.195124
2023-01-08 01:45: Train Epoch 3: 395/634 Loss: 0.196224
2023-01-08 01:45: Train Epoch 3: 399/634 Loss: 0.201829
2023-01-08 01:45: Train Epoch 3: 403/634 Loss: 0.174752
2023-01-08 01:46: Train Epoch 3: 407/634 Loss: 0.202145
2023-01-08 01:46: Train Epoch 3: 411/634 Loss: 0.172194
2023-01-08 01:46: Train Epoch 3: 415/634 Loss: 0.219367
2023-01-08 01:46: Train Epoch 3: 419/634 Loss: 0.210881
2023-01-08 01:47: Train Epoch 3: 423/634 Loss: 0.184776
2023-01-08 01:47: Train Epoch 3: 427/634 Loss: 0.196407
2023-01-08 01:47: Train Epoch 3: 431/634 Loss: 0.188223
2023-01-08 01:48: Train Epoch 3: 435/634 Loss: 0.204089
2023-01-08 01:48: Train Epoch 3: 439/634 Loss: 0.168162
2023-01-08 01:48: Train Epoch 3: 443/634 Loss: 0.180869
2023-01-08 01:48: Train Epoch 3: 447/634 Loss: 0.203766
2023-01-08 01:49: Train Epoch 3: 451/634 Loss: 0.191404
2023-01-08 01:49: Train Epoch 3: 455/634 Loss: 0.197768
2023-01-08 01:49: Train Epoch 3: 459/634 Loss: 0.193446
2023-01-08 01:49: Train Epoch 3: 463/634 Loss: 0.195589
2023-01-08 01:50: Train Epoch 3: 467/634 Loss: 0.193729
2023-01-08 01:50: Train Epoch 3: 471/634 Loss: 0.211415
2023-01-08 01:50: Train Epoch 3: 475/634 Loss: 0.155378
2023-01-08 01:50: Train Epoch 3: 479/634 Loss: 0.217022
2023-01-08 01:51: Train Epoch 3: 483/634 Loss: 0.177245
2023-01-08 01:51: Train Epoch 3: 487/634 Loss: 0.211167
2023-01-08 01:51: Train Epoch 3: 491/634 Loss: 0.190347
2023-01-08 01:52: Train Epoch 3: 495/634 Loss: 0.180795
2023-01-08 01:52: Train Epoch 3: 499/634 Loss: 0.201301
2023-01-08 01:52: Train Epoch 3: 503/634 Loss: 0.191754
2023-01-08 01:52: Train Epoch 3: 507/634 Loss: 0.197363
2023-01-08 01:53: Train Epoch 3: 511/634 Loss: 0.178280
2023-01-08 01:53: Train Epoch 3: 515/634 Loss: 0.168634
2023-01-08 01:53: Train Epoch 3: 519/634 Loss: 0.158534
2023-01-08 01:53: Train Epoch 3: 523/634 Loss: 0.181849
2023-01-08 01:54: Train Epoch 3: 527/634 Loss: 0.216466
2023-01-08 01:54: Train Epoch 3: 531/634 Loss: 0.188913
2023-01-08 01:54: Train Epoch 3: 535/634 Loss: 0.186280
2023-01-08 01:54: Train Epoch 3: 539/634 Loss: 0.192656
2023-01-08 01:55: Train Epoch 3: 543/634 Loss: 0.158560
2023-01-08 01:55: Train Epoch 3: 547/634 Loss: 0.188812
2023-01-08 01:55: Train Epoch 3: 551/634 Loss: 0.179049
2023-01-08 01:55: Train Epoch 3: 555/634 Loss: 0.193841
2023-01-08 01:56: Train Epoch 3: 559/634 Loss: 0.184201
2023-01-08 01:56: Train Epoch 3: 563/634 Loss: 0.171282
2023-01-08 01:56: Train Epoch 3: 567/634 Loss: 0.189616
2023-01-08 01:57: Train Epoch 3: 571/634 Loss: 0.180814
2023-01-08 01:57: Train Epoch 3: 575/634 Loss: 0.204668
2023-01-08 01:57: Train Epoch 3: 579/634 Loss: 0.185738
2023-01-08 01:57: Train Epoch 3: 583/634 Loss: 0.175785
2023-01-08 01:58: Train Epoch 3: 587/634 Loss: 0.160048
2023-01-08 01:58: Train Epoch 3: 591/634 Loss: 0.198721
2023-01-08 01:58: Train Epoch 3: 595/634 Loss: 0.199818
2023-01-08 01:58: Train Epoch 3: 599/634 Loss: 0.175909
2023-01-08 01:59: Train Epoch 3: 603/634 Loss: 0.198813
2023-01-08 01:59: Train Epoch 3: 607/634 Loss: 0.198274
2023-01-08 01:59: Train Epoch 3: 611/634 Loss: 0.149647
2023-01-08 01:59: Train Epoch 3: 615/634 Loss: 0.228043
2023-01-08 02:00: Train Epoch 3: 619/634 Loss: 0.197194
2023-01-08 02:00: Train Epoch 3: 623/634 Loss: 0.180089
2023-01-08 02:00: Train Epoch 3: 627/634 Loss: 0.166153
2023-01-08 02:00: Train Epoch 3: 631/634 Loss: 0.181010
2023-01-08 02:01: Train Epoch 3: 633/634 Loss: 0.102819
2023-01-08 02:01: **********Train Epoch 3: averaged Loss: 0.191025 
2023-01-08 02:01: 
Epoch time elapsed: 2513.038985013962

2023-01-08 02:02: 
 metrics validation: {'precision': 0.7719155844155844, 'recall': 0.7315384615384616, 'f1-score': 0.7511848341232228, 'support': 1300, 'AUC': 0.881573076923077, 'AUCPR': 0.7926275805340682, 'TP': 951, 'FP': 281, 'TN': 2319, 'FN': 349} 

2023-01-08 02:02: **********Val Epoch 3: average Loss: 0.196010
2023-01-08 02:02: *********************************Current best model saved!
2023-01-08 02:03: 
 Testing metrics {'precision': 0.8152573529411765, 'recall': 0.7223127035830619, 'f1-score': 0.7659758203799656, 'support': 1228, 'AUC': 0.8993576854926841, 'AUCPR': 0.83808668993007, 'TP': 887, 'FP': 201, 'TN': 2255, 'FN': 341} 

2023-01-08 02:07: 
 Testing metrics {'precision': 0.8857648882001329, 'recall': 0.9078738370773769, 'f1-score': 0.8966831017480951, 'support': 4407, 'AUC': 0.972450356815737, 'AUCPR': 0.9471354334705093, 'TP': 4001, 'FP': 516, 'TN': 8298, 'FN': 406} 

2023-01-08 02:07: Train Epoch 4: 3/634 Loss: 0.219900
2023-01-08 02:07: Train Epoch 4: 7/634 Loss: 0.155637
2023-01-08 02:08: Train Epoch 4: 11/634 Loss: 0.197110
2023-01-08 02:08: Train Epoch 4: 15/634 Loss: 0.176116
2023-01-08 02:08: Train Epoch 4: 19/634 Loss: 0.160772
2023-01-08 02:09: Train Epoch 4: 23/634 Loss: 0.171847
2023-01-08 02:09: Train Epoch 4: 27/634 Loss: 0.195681
2023-01-08 02:09: Train Epoch 4: 31/634 Loss: 0.193802
2023-01-08 02:09: Train Epoch 4: 35/634 Loss: 0.175858
2023-01-08 02:10: Train Epoch 4: 39/634 Loss: 0.186734
2023-01-08 02:10: Train Epoch 4: 43/634 Loss: 0.222724
2023-01-08 02:10: Train Epoch 4: 47/634 Loss: 0.172199
2023-01-08 02:10: Train Epoch 4: 51/634 Loss: 0.214854
2023-01-08 02:11: Train Epoch 4: 55/634 Loss: 0.183929
2023-01-08 02:11: Train Epoch 4: 59/634 Loss: 0.192631
2023-01-08 02:11: Train Epoch 4: 63/634 Loss: 0.204730
2023-01-08 02:11: Train Epoch 4: 67/634 Loss: 0.149010
2023-01-08 02:12: Train Epoch 4: 71/634 Loss: 0.164604
2023-01-08 02:12: Train Epoch 4: 75/634 Loss: 0.181653
2023-01-08 02:12: Train Epoch 4: 79/634 Loss: 0.190955
2023-01-08 02:12: Train Epoch 4: 83/634 Loss: 0.163106
2023-01-08 02:13: Train Epoch 4: 87/634 Loss: 0.173275
2023-01-08 02:13: Train Epoch 4: 91/634 Loss: 0.224152
2023-01-08 02:13: Train Epoch 4: 95/634 Loss: 0.223475
2023-01-08 02:13: Train Epoch 4: 99/634 Loss: 0.181479
2023-01-08 02:14: Train Epoch 4: 103/634 Loss: 0.189255
2023-01-08 02:14: Train Epoch 4: 107/634 Loss: 0.200653
2023-01-08 02:14: Train Epoch 4: 111/634 Loss: 0.217764
2023-01-08 02:15: Train Epoch 4: 115/634 Loss: 0.197826
2023-01-08 02:15: Train Epoch 4: 119/634 Loss: 0.173780
2023-01-08 02:15: Train Epoch 4: 123/634 Loss: 0.198121
2023-01-08 02:15: Train Epoch 4: 127/634 Loss: 0.191752
2023-01-08 02:15: Train Epoch 4: 131/634 Loss: 0.170073
2023-01-08 02:16: Train Epoch 4: 135/634 Loss: 0.173086
2023-01-08 02:16: Train Epoch 4: 139/634 Loss: 0.208410
2023-01-08 02:16: Train Epoch 4: 143/634 Loss: 0.180667
2023-01-08 02:16: Train Epoch 4: 147/634 Loss: 0.144276
2023-01-08 02:17: Train Epoch 4: 151/634 Loss: 0.213185
2023-01-08 02:17: Train Epoch 4: 155/634 Loss: 0.184818
2023-01-08 02:17: Train Epoch 4: 159/634 Loss: 0.171423
2023-01-08 02:17: Train Epoch 4: 163/634 Loss: 0.183522
2023-01-08 02:18: Train Epoch 4: 167/634 Loss: 0.175698
2023-01-08 02:18: Train Epoch 4: 171/634 Loss: 0.188358
2023-01-08 02:18: Train Epoch 4: 175/634 Loss: 0.182808
2023-01-08 02:18: Train Epoch 4: 179/634 Loss: 0.177986
2023-01-08 02:19: Train Epoch 4: 183/634 Loss: 0.184063
2023-01-08 02:19: Train Epoch 4: 187/634 Loss: 0.181944
2023-01-08 02:19: Train Epoch 4: 191/634 Loss: 0.166692
2023-01-08 02:19: Train Epoch 4: 195/634 Loss: 0.166503
2023-01-08 02:20: Train Epoch 4: 199/634 Loss: 0.180396
2023-01-08 02:20: Train Epoch 4: 203/634 Loss: 0.195985
2023-01-08 02:20: Train Epoch 4: 207/634 Loss: 0.187466
2023-01-08 02:21: Train Epoch 4: 211/634 Loss: 0.160273
2023-01-08 02:21: Train Epoch 4: 215/634 Loss: 0.175746
2023-01-08 02:21: Train Epoch 4: 219/634 Loss: 0.211846
2023-01-08 02:21: Train Epoch 4: 223/634 Loss: 0.206572
2023-01-08 02:21: Train Epoch 4: 227/634 Loss: 0.188339
2023-01-08 02:22: Train Epoch 4: 231/634 Loss: 0.224574
2023-01-08 02:22: Train Epoch 4: 235/634 Loss: 0.180955
2023-01-08 02:22: Train Epoch 4: 239/634 Loss: 0.161538
2023-01-08 02:23: Train Epoch 4: 243/634 Loss: 0.173681
2023-01-08 02:23: Train Epoch 4: 247/634 Loss: 0.178944
2023-01-08 02:23: Train Epoch 4: 251/634 Loss: 0.160843
2023-01-08 02:23: Train Epoch 4: 255/634 Loss: 0.203002
2023-01-08 02:24: Train Epoch 4: 259/634 Loss: 0.172098
2023-01-08 02:24: Train Epoch 4: 263/634 Loss: 0.197020
2023-01-08 02:24: Train Epoch 4: 267/634 Loss: 0.184175
2023-01-08 02:24: Train Epoch 4: 271/634 Loss: 0.151401
2023-01-08 02:24: Train Epoch 4: 275/634 Loss: 0.181082
2023-01-08 02:25: Train Epoch 4: 279/634 Loss: 0.168726
2023-01-08 02:25: Train Epoch 4: 283/634 Loss: 0.164156
2023-01-08 02:25: Train Epoch 4: 287/634 Loss: 0.190403
2023-01-08 02:25: Train Epoch 4: 291/634 Loss: 0.180262
2023-01-08 02:26: Train Epoch 4: 295/634 Loss: 0.198291
2023-01-08 02:26: Train Epoch 4: 299/634 Loss: 0.167620
2023-01-08 02:26: Train Epoch 4: 303/634 Loss: 0.183713
2023-01-08 02:26: Train Epoch 4: 307/634 Loss: 0.183261
2023-01-08 02:27: Train Epoch 4: 311/634 Loss: 0.167937
2023-01-08 02:27: Train Epoch 4: 315/634 Loss: 0.209683
2023-01-08 02:27: Train Epoch 4: 319/634 Loss: 0.183678
2023-01-08 02:27: Train Epoch 4: 323/634 Loss: 0.166700
2023-01-08 02:28: Train Epoch 4: 327/634 Loss: 0.171090
2023-01-08 02:28: Train Epoch 4: 331/634 Loss: 0.172699
2023-01-08 02:28: Train Epoch 4: 335/634 Loss: 0.178793
2023-01-08 02:28: Train Epoch 4: 339/634 Loss: 0.182968
2023-01-08 02:29: Train Epoch 4: 343/634 Loss: 0.191272
2023-01-08 02:29: Train Epoch 4: 347/634 Loss: 0.187576
2023-01-08 02:29: Train Epoch 4: 351/634 Loss: 0.168026
2023-01-08 02:29: Train Epoch 4: 355/634 Loss: 0.217917
2023-01-08 02:30: Train Epoch 4: 359/634 Loss: 0.206073
2023-01-08 02:30: Train Epoch 4: 363/634 Loss: 0.202992
2023-01-08 02:30: Train Epoch 4: 367/634 Loss: 0.192918
2023-01-08 02:30: Train Epoch 4: 371/634 Loss: 0.192502
2023-01-08 02:31: Train Epoch 4: 375/634 Loss: 0.167341
2023-01-08 02:31: Train Epoch 4: 379/634 Loss: 0.202023
2023-01-08 02:31: Train Epoch 4: 383/634 Loss: 0.184102
2023-01-08 02:31: Train Epoch 4: 387/634 Loss: 0.166253
2023-01-08 02:32: Train Epoch 4: 391/634 Loss: 0.167172
2023-01-08 02:32: Train Epoch 4: 395/634 Loss: 0.219189
2023-01-08 02:32: Train Epoch 4: 399/634 Loss: 0.222519
2023-01-08 02:32: Train Epoch 4: 403/634 Loss: 0.161584
2023-01-08 02:33: Train Epoch 4: 407/634 Loss: 0.259544
2023-01-08 02:33: Train Epoch 4: 411/634 Loss: 0.237174
2023-01-08 02:33: Train Epoch 4: 415/634 Loss: 0.178577
2023-01-08 02:33: Train Epoch 4: 419/634 Loss: 0.186080
2023-01-08 02:34: Train Epoch 4: 423/634 Loss: 0.220900
2023-01-08 02:34: Train Epoch 4: 427/634 Loss: 0.239445
2023-01-08 02:34: Train Epoch 4: 431/634 Loss: 0.204745
2023-01-08 02:34: Train Epoch 4: 435/634 Loss: 0.169195
2023-01-08 02:35: Train Epoch 4: 439/634 Loss: 0.216639
2023-01-08 02:35: Train Epoch 4: 443/634 Loss: 0.179430
2023-01-08 02:35: Train Epoch 4: 447/634 Loss: 0.220069
2023-01-08 02:35: Train Epoch 4: 451/634 Loss: 0.194064
2023-01-08 02:36: Train Epoch 4: 455/634 Loss: 0.207866
2023-01-08 02:36: Train Epoch 4: 459/634 Loss: 0.200201
2023-01-08 02:36: Train Epoch 4: 463/634 Loss: 0.199998
2023-01-08 02:36: Train Epoch 4: 467/634 Loss: 0.193096
2023-01-08 02:37: Train Epoch 4: 471/634 Loss: 0.192448
2023-01-08 02:37: Train Epoch 4: 475/634 Loss: 0.202207
2023-01-08 02:37: Train Epoch 4: 479/634 Loss: 0.169863
2023-01-08 02:37: Train Epoch 4: 483/634 Loss: 0.171028
2023-01-08 02:38: Train Epoch 4: 487/634 Loss: 0.198188
2023-01-08 02:38: Train Epoch 4: 491/634 Loss: 0.182444
2023-01-08 02:38: Train Epoch 4: 495/634 Loss: 0.196292
2023-01-08 02:38: Train Epoch 4: 499/634 Loss: 0.186541
2023-01-08 02:39: Train Epoch 4: 503/634 Loss: 0.182112
2023-01-08 02:39: Train Epoch 4: 507/634 Loss: 0.233152
2023-01-08 02:39: Train Epoch 4: 511/634 Loss: 0.184308
2023-01-08 02:39: Train Epoch 4: 515/634 Loss: 0.173657
2023-01-08 02:40: Train Epoch 4: 519/634 Loss: 0.178580
2023-01-08 02:40: Train Epoch 4: 523/634 Loss: 0.174920
2023-01-08 02:40: Train Epoch 4: 527/634 Loss: 0.178719
2023-01-08 02:40: Train Epoch 4: 531/634 Loss: 0.177558
2023-01-08 02:41: Train Epoch 4: 535/634 Loss: 0.191110
2023-01-08 02:41: Train Epoch 4: 539/634 Loss: 0.182234
2023-01-08 02:41: Train Epoch 4: 543/634 Loss: 0.186679
2023-01-08 02:41: Train Epoch 4: 547/634 Loss: 0.186331
2023-01-08 02:42: Train Epoch 4: 551/634 Loss: 0.160062
2023-01-08 02:42: Train Epoch 4: 555/634 Loss: 0.204334
2023-01-08 02:42: Train Epoch 4: 559/634 Loss: 0.185375
2023-01-08 02:42: Train Epoch 4: 563/634 Loss: 0.173824
2023-01-08 02:42: Train Epoch 4: 567/634 Loss: 0.155201
2023-01-08 02:43: Train Epoch 4: 571/634 Loss: 0.195053
2023-01-08 02:43: Train Epoch 4: 575/634 Loss: 0.146894
2023-01-08 02:43: Train Epoch 4: 579/634 Loss: 0.184687
2023-01-08 02:43: Train Epoch 4: 583/634 Loss: 0.166949
2023-01-08 02:44: Train Epoch 4: 587/634 Loss: 0.168291
2023-01-08 02:44: Train Epoch 4: 591/634 Loss: 0.185276
2023-01-08 02:44: Train Epoch 4: 595/634 Loss: 0.144276
2023-01-08 02:44: Train Epoch 4: 599/634 Loss: 0.171834
2023-01-08 02:45: Train Epoch 4: 603/634 Loss: 0.175579
2023-01-08 02:45: Train Epoch 4: 607/634 Loss: 0.167729
2023-01-08 02:45: Train Epoch 4: 611/634 Loss: 0.165302
2023-01-08 02:45: Train Epoch 4: 615/634 Loss: 0.173904
2023-01-08 02:46: Train Epoch 4: 619/634 Loss: 0.188475
2023-01-08 02:46: Train Epoch 4: 623/634 Loss: 0.186562
2023-01-08 02:46: Train Epoch 4: 627/634 Loss: 0.185575
2023-01-08 02:46: Train Epoch 4: 631/634 Loss: 0.145812
2023-01-08 02:47: Train Epoch 4: 633/634 Loss: 0.089569
2023-01-08 02:47: **********Train Epoch 4: averaged Loss: 0.185222 
2023-01-08 02:47: 
Epoch time elapsed: 2374.885092020035

2023-01-08 02:48: 
 metrics validation: {'precision': 0.7832345469940728, 'recall': 0.7115384615384616, 'f1-score': 0.7456670697299476, 'support': 1300, 'AUC': 0.8966171597633136, 'AUCPR': 0.8191091831951611, 'TP': 925, 'FP': 256, 'TN': 2344, 'FN': 375} 

2023-01-08 02:48: **********Val Epoch 4: average Loss: 0.187197
2023-01-08 02:48: *********************************Current best model saved!
2023-01-08 02:49: 
 Testing metrics {'precision': 0.829971181556196, 'recall': 0.7035830618892508, 'f1-score': 0.76156897311591, 'support': 1228, 'AUC': 0.9135246129932414, 'AUCPR': 0.8616052568699109, 'TP': 864, 'FP': 177, 'TN': 2279, 'FN': 364} 

2023-01-08 02:53: 
 Testing metrics {'precision': 0.8988536749831423, 'recall': 0.9074200136147039, 'f1-score': 0.9031165311653115, 'support': 4407, 'AUC': 0.9729633668078339, 'AUCPR': 0.9461382111394306, 'TP': 3999, 'FP': 450, 'TN': 8364, 'FN': 408} 

2023-01-08 02:53: Train Epoch 5: 3/634 Loss: 0.199985
2023-01-08 02:53: Train Epoch 5: 7/634 Loss: 0.196188
2023-01-08 02:54: Train Epoch 5: 11/634 Loss: 0.181798
2023-01-08 02:54: Train Epoch 5: 15/634 Loss: 0.178437
2023-01-08 02:54: Train Epoch 5: 19/634 Loss: 0.163747
2023-01-08 02:54: Train Epoch 5: 23/634 Loss: 0.205413
2023-01-08 02:55: Train Epoch 5: 27/634 Loss: 0.172351
2023-01-08 02:55: Train Epoch 5: 31/634 Loss: 0.190073
2023-01-08 02:55: Train Epoch 5: 35/634 Loss: 0.149369
2023-01-08 02:55: Train Epoch 5: 39/634 Loss: 0.196566
2023-01-08 02:56: Train Epoch 5: 43/634 Loss: 0.156921
2023-01-08 02:56: Train Epoch 5: 47/634 Loss: 0.181074
2023-01-08 02:56: Train Epoch 5: 51/634 Loss: 0.154560
2023-01-08 02:56: Train Epoch 5: 55/634 Loss: 0.196108
2023-01-08 02:57: Train Epoch 5: 59/634 Loss: 0.151571
2023-01-08 02:57: Train Epoch 5: 63/634 Loss: 0.199549
2023-01-08 02:57: Train Epoch 5: 67/634 Loss: 0.171874
2023-01-08 02:57: Train Epoch 5: 71/634 Loss: 0.175533
2023-01-08 02:58: Train Epoch 5: 75/634 Loss: 0.187223
2023-01-08 02:58: Train Epoch 5: 79/634 Loss: 0.174936
2023-01-08 02:58: Train Epoch 5: 83/634 Loss: 0.197670
2023-01-08 02:58: Train Epoch 5: 87/634 Loss: 0.203543
2023-01-08 02:59: Train Epoch 5: 91/634 Loss: 0.163244
2023-01-08 02:59: Train Epoch 5: 95/634 Loss: 0.194826
2023-01-08 02:59: Train Epoch 5: 99/634 Loss: 0.155785
2023-01-08 02:59: Train Epoch 5: 103/634 Loss: 0.191643
2023-01-08 03:00: Train Epoch 5: 107/634 Loss: 0.194365
2023-01-08 03:00: Train Epoch 5: 111/634 Loss: 0.161439
2023-01-08 03:00: Train Epoch 5: 115/634 Loss: 0.179009
2023-01-08 03:00: Train Epoch 5: 119/634 Loss: 0.189543
2023-01-08 03:01: Train Epoch 5: 123/634 Loss: 0.166523
2023-01-08 03:01: Train Epoch 5: 127/634 Loss: 0.179370
2023-01-08 03:01: Train Epoch 5: 131/634 Loss: 0.205850
2023-01-08 03:01: Train Epoch 5: 135/634 Loss: 0.163962
2023-01-08 03:02: Train Epoch 5: 139/634 Loss: 0.188804
2023-01-08 03:02: Train Epoch 5: 143/634 Loss: 0.162350
2023-01-08 03:02: Train Epoch 5: 147/634 Loss: 0.244243
2023-01-08 03:02: Train Epoch 5: 151/634 Loss: 0.187435
2023-01-08 03:03: Train Epoch 5: 155/634 Loss: 0.190930
2023-01-08 03:03: Train Epoch 5: 159/634 Loss: 0.190703
2023-01-08 03:03: Train Epoch 5: 163/634 Loss: 0.186285
2023-01-08 03:03: Train Epoch 5: 167/634 Loss: 0.164347
2023-01-08 03:04: Train Epoch 5: 171/634 Loss: 0.184204
2023-01-08 03:04: Train Epoch 5: 175/634 Loss: 0.176094
2023-01-08 03:04: Train Epoch 5: 179/634 Loss: 0.174748
2023-01-08 03:04: Train Epoch 5: 183/634 Loss: 0.198194
2023-01-08 03:05: Train Epoch 5: 187/634 Loss: 0.152292
2023-01-08 03:05: Train Epoch 5: 191/634 Loss: 0.201824
2023-01-08 03:05: Train Epoch 5: 195/634 Loss: 0.195706
2023-01-08 03:05: Train Epoch 5: 199/634 Loss: 0.178970
2023-01-08 03:06: Train Epoch 5: 203/634 Loss: 0.157130
2023-01-08 03:06: Train Epoch 5: 207/634 Loss: 0.193264
2023-01-08 03:06: Train Epoch 5: 211/634 Loss: 0.148334
2023-01-08 03:06: Train Epoch 5: 215/634 Loss: 0.179470
2023-01-08 03:07: Train Epoch 5: 219/634 Loss: 0.201131
2023-01-08 03:07: Train Epoch 5: 223/634 Loss: 0.194215
2023-01-08 03:07: Train Epoch 5: 227/634 Loss: 0.173365
2023-01-08 03:07: Train Epoch 5: 231/634 Loss: 0.181430
2023-01-08 03:08: Train Epoch 5: 235/634 Loss: 0.228151
2023-01-08 03:08: Train Epoch 5: 239/634 Loss: 0.172383
2023-01-08 03:08: Train Epoch 5: 243/634 Loss: 0.169353
2023-01-08 03:08: Train Epoch 5: 247/634 Loss: 0.166296
2023-01-08 03:09: Train Epoch 5: 251/634 Loss: 0.205917
2023-01-08 03:09: Train Epoch 5: 255/634 Loss: 0.179651
2023-01-08 03:09: Train Epoch 5: 259/634 Loss: 0.155148
2023-01-08 03:09: Train Epoch 5: 263/634 Loss: 0.175603
2023-01-08 03:10: Train Epoch 5: 267/634 Loss: 0.231172
2023-01-08 03:10: Train Epoch 5: 271/634 Loss: 0.176824
2023-01-08 03:10: Train Epoch 5: 275/634 Loss: 0.173206
2023-01-08 03:10: Train Epoch 5: 279/634 Loss: 0.175512
2023-01-08 03:11: Train Epoch 5: 283/634 Loss: 0.189775
2023-01-08 03:11: Train Epoch 5: 287/634 Loss: 0.168695
2023-01-08 03:11: Train Epoch 5: 291/634 Loss: 0.192693
2023-01-08 03:11: Train Epoch 5: 295/634 Loss: 0.188294
2023-01-08 03:12: Train Epoch 5: 299/634 Loss: 0.204299
2023-01-08 03:12: Train Epoch 5: 303/634 Loss: 0.173343
2023-01-08 03:12: Train Epoch 5: 307/634 Loss: 0.159648
2023-01-08 03:12: Train Epoch 5: 311/634 Loss: 0.160771
2023-01-08 03:13: Train Epoch 5: 315/634 Loss: 0.179007
2023-01-08 03:13: Train Epoch 5: 319/634 Loss: 0.163325
2023-01-08 03:13: Train Epoch 5: 323/634 Loss: 0.189397
2023-01-08 03:13: Train Epoch 5: 327/634 Loss: 0.195684
2023-01-08 03:14: Train Epoch 5: 331/634 Loss: 0.181291
2023-01-08 03:14: Train Epoch 5: 335/634 Loss: 0.176881
2023-01-08 03:14: Train Epoch 5: 339/634 Loss: 0.221254
2023-01-08 03:14: Train Epoch 5: 343/634 Loss: 0.157679
2023-01-08 03:15: Train Epoch 5: 347/634 Loss: 0.174578
2023-01-08 03:15: Train Epoch 5: 351/634 Loss: 0.191128
2023-01-08 03:15: Train Epoch 5: 355/634 Loss: 0.167477
2023-01-08 03:15: Train Epoch 5: 359/634 Loss: 0.168961
2023-01-08 03:16: Train Epoch 5: 363/634 Loss: 0.181011
2023-01-08 03:16: Train Epoch 5: 367/634 Loss: 0.181254
2023-01-08 03:16: Train Epoch 5: 371/634 Loss: 0.202838
2023-01-08 03:16: Train Epoch 5: 375/634 Loss: 0.162311
2023-01-08 03:17: Train Epoch 5: 379/634 Loss: 0.181590
2023-01-08 03:17: Train Epoch 5: 383/634 Loss: 0.173011
2023-01-08 03:17: Train Epoch 5: 387/634 Loss: 0.191331
2023-01-08 03:17: Train Epoch 5: 391/634 Loss: 0.189363
2023-01-08 03:18: Train Epoch 5: 395/634 Loss: 0.182881
2023-01-08 03:18: Train Epoch 5: 399/634 Loss: 0.168172
2023-01-08 03:18: Train Epoch 5: 403/634 Loss: 0.218230
2023-01-08 03:18: Train Epoch 5: 407/634 Loss: 0.178060
2023-01-08 03:19: Train Epoch 5: 411/634 Loss: 0.193474
2023-01-08 03:19: Train Epoch 5: 415/634 Loss: 0.208007
2023-01-08 03:19: Train Epoch 5: 419/634 Loss: 0.232185
2023-01-08 03:19: Train Epoch 5: 423/634 Loss: 0.182444
2023-01-08 03:19: Train Epoch 5: 427/634 Loss: 0.203006
2023-01-08 03:20: Train Epoch 5: 431/634 Loss: 0.181414
2023-01-08 03:20: Train Epoch 5: 435/634 Loss: 0.166927
2023-01-08 03:20: Train Epoch 5: 439/634 Loss: 0.201100
2023-01-08 03:20: Train Epoch 5: 443/634 Loss: 0.188739
2023-01-08 03:21: Train Epoch 5: 447/634 Loss: 0.210995
2023-01-08 03:21: Train Epoch 5: 451/634 Loss: 0.179607
2023-01-08 03:21: Train Epoch 5: 455/634 Loss: 0.210148
2023-01-08 03:21: Train Epoch 5: 459/634 Loss: 0.187176
2023-01-08 03:22: Train Epoch 5: 463/634 Loss: 0.210644
2023-01-08 03:22: Train Epoch 5: 467/634 Loss: 0.226556
2023-01-08 03:22: Train Epoch 5: 471/634 Loss: 0.157352
2023-01-08 03:22: Train Epoch 5: 475/634 Loss: 0.181244
2023-01-08 03:23: Train Epoch 5: 479/634 Loss: 0.162317
2023-01-08 03:23: Train Epoch 5: 483/634 Loss: 0.172700
2023-01-08 03:23: Train Epoch 5: 487/634 Loss: 0.200487
2023-01-08 03:24: Train Epoch 5: 491/634 Loss: 0.176978
2023-01-08 03:24: Train Epoch 5: 495/634 Loss: 0.195427
2023-01-08 03:24: Train Epoch 5: 499/634 Loss: 0.251253
2023-01-08 03:24: Train Epoch 5: 503/634 Loss: 0.209128
2023-01-08 03:25: Train Epoch 5: 507/634 Loss: 0.174940
2023-01-08 03:25: Train Epoch 5: 511/634 Loss: 0.197480
2023-01-08 03:25: Train Epoch 5: 515/634 Loss: 0.191632
2023-01-08 03:25: Train Epoch 5: 519/634 Loss: 0.182955
2023-01-08 03:26: Train Epoch 5: 523/634 Loss: 0.191952
2023-01-08 03:26: Train Epoch 5: 527/634 Loss: 0.204243
2023-01-08 03:26: Train Epoch 5: 531/634 Loss: 0.190991
2023-01-08 03:26: Train Epoch 5: 535/634 Loss: 0.184614
2023-01-08 03:27: Train Epoch 5: 539/634 Loss: 0.187046
2023-01-08 03:27: Train Epoch 5: 543/634 Loss: 0.169966
2023-01-08 03:27: Train Epoch 5: 547/634 Loss: 0.172602
2023-01-08 03:27: Train Epoch 5: 551/634 Loss: 0.167948
2023-01-08 03:28: Train Epoch 5: 555/634 Loss: 0.143310
2023-01-08 03:28: Train Epoch 5: 559/634 Loss: 0.189748
2023-01-08 03:28: Train Epoch 5: 563/634 Loss: 0.163841
2023-01-08 03:28: Train Epoch 5: 567/634 Loss: 0.179215
2023-01-08 03:29: Train Epoch 5: 571/634 Loss: 0.178389
2023-01-08 03:29: Train Epoch 5: 575/634 Loss: 0.191069
2023-01-08 03:29: Train Epoch 5: 579/634 Loss: 0.150765
2023-01-08 03:29: Train Epoch 5: 583/634 Loss: 0.172413
2023-01-08 03:30: Train Epoch 5: 587/634 Loss: 0.171234
2023-01-08 03:30: Train Epoch 5: 591/634 Loss: 0.175907
2023-01-08 03:30: Train Epoch 5: 595/634 Loss: 0.167808
2023-01-08 03:30: Train Epoch 5: 599/634 Loss: 0.173013
2023-01-08 03:31: Train Epoch 5: 603/634 Loss: 0.191018
2023-01-08 03:31: Train Epoch 5: 607/634 Loss: 0.157387
2023-01-08 03:31: Train Epoch 5: 611/634 Loss: 0.177908
2023-01-08 03:31: Train Epoch 5: 615/634 Loss: 0.178888
2023-01-08 03:32: Train Epoch 5: 619/634 Loss: 0.164040
2023-01-08 03:32: Train Epoch 5: 623/634 Loss: 0.176129
2023-01-08 03:32: Train Epoch 5: 627/634 Loss: 0.143801
2023-01-08 03:32: Train Epoch 5: 631/634 Loss: 0.164509
2023-01-08 03:32: Train Epoch 5: 633/634 Loss: 0.074163
2023-01-08 03:32: **********Train Epoch 5: averaged Loss: 0.182070 
2023-01-08 03:32: 
Epoch time elapsed: 2369.977131843567

2023-01-08 03:34: 
 metrics validation: {'precision': 0.8652561247216035, 'recall': 0.5976923076923077, 'f1-score': 0.7070063694267517, 'support': 1300, 'AUC': 0.9190896449704142, 'AUCPR': 0.8510234490339045, 'TP': 777, 'FP': 121, 'TN': 2479, 'FN': 523} 

2023-01-08 03:34: **********Val Epoch 5: average Loss: 0.180562
2023-01-08 03:34: *********************************Current best model saved!
2023-01-08 03:35: 
 Testing metrics {'precision': 0.9103030303030303, 'recall': 0.6115635179153095, 'f1-score': 0.7316122747199221, 'support': 1228, 'AUC': 0.9163343245021166, 'AUCPR': 0.8602857534537149, 'TP': 751, 'FP': 74, 'TN': 2382, 'FN': 477} 

2023-01-08 03:39: 
 Testing metrics {'precision': 0.9468757905388313, 'recall': 0.8493306103925573, 'f1-score': 0.8954545454545454, 'support': 4407, 'AUC': 0.97372550600621, 'AUCPR': 0.9442497179497636, 'TP': 3743, 'FP': 210, 'TN': 8604, 'FN': 664} 

2023-01-08 03:39: Train Epoch 6: 3/634 Loss: 0.174158
2023-01-08 03:39: Train Epoch 6: 7/634 Loss: 0.145790
2023-01-08 03:40: Train Epoch 6: 11/634 Loss: 0.161512
2023-01-08 03:40: Train Epoch 6: 15/634 Loss: 0.174331
2023-01-08 03:40: Train Epoch 6: 19/634 Loss: 0.185474
2023-01-08 03:40: Train Epoch 6: 23/634 Loss: 0.186733
2023-01-08 03:41: Train Epoch 6: 27/634 Loss: 0.148783
2023-01-08 03:41: Train Epoch 6: 31/634 Loss: 0.152532
2023-01-08 03:41: Train Epoch 6: 35/634 Loss: 0.154382
2023-01-08 03:41: Train Epoch 6: 39/634 Loss: 0.178692
2023-01-08 03:42: Train Epoch 6: 43/634 Loss: 0.182799
2023-01-08 03:42: Train Epoch 6: 47/634 Loss: 0.189633
2023-01-08 03:42: Train Epoch 6: 51/634 Loss: 0.186924
2023-01-08 03:42: Train Epoch 6: 55/634 Loss: 0.180152
2023-01-08 03:43: Train Epoch 6: 59/634 Loss: 0.197431
2023-01-08 03:43: Train Epoch 6: 63/634 Loss: 0.188010
2023-01-08 03:43: Train Epoch 6: 67/634 Loss: 0.192155
2023-01-08 03:43: Train Epoch 6: 71/634 Loss: 0.167805
2023-01-08 03:44: Train Epoch 6: 75/634 Loss: 0.174227
2023-01-08 03:44: Train Epoch 6: 79/634 Loss: 0.157145
2023-01-08 03:44: Train Epoch 6: 83/634 Loss: 0.192515
2023-01-08 03:44: Train Epoch 6: 87/634 Loss: 0.156907
2023-01-08 03:45: Train Epoch 6: 91/634 Loss: 0.151437
2023-01-08 03:45: Train Epoch 6: 95/634 Loss: 0.185674
2023-01-08 03:45: Train Epoch 6: 99/634 Loss: 0.196545
2023-01-08 03:45: Train Epoch 6: 103/634 Loss: 0.186428
2023-01-08 03:46: Train Epoch 6: 107/634 Loss: 0.184012
2023-01-08 03:46: Train Epoch 6: 111/634 Loss: 0.217159
2023-01-08 03:46: Train Epoch 6: 115/634 Loss: 0.176260
2023-01-08 03:46: Train Epoch 6: 119/634 Loss: 0.202176
2023-01-08 03:47: Train Epoch 6: 123/634 Loss: 0.167889
2023-01-08 03:47: Train Epoch 6: 127/634 Loss: 0.169593
2023-01-08 03:47: Train Epoch 6: 131/634 Loss: 0.192612
2023-01-08 03:47: Train Epoch 6: 135/634 Loss: 0.147200
2023-01-08 03:48: Train Epoch 6: 139/634 Loss: 0.189036
2023-01-08 03:48: Train Epoch 6: 143/634 Loss: 0.161654
2023-01-08 03:48: Train Epoch 6: 147/634 Loss: 0.166144
2023-01-08 03:48: Train Epoch 6: 151/634 Loss: 0.165483
2023-01-08 03:49: Train Epoch 6: 155/634 Loss: 0.177061
2023-01-08 03:49: Train Epoch 6: 159/634 Loss: 0.190577
2023-01-08 03:49: Train Epoch 6: 163/634 Loss: 0.175419
2023-01-08 03:49: Train Epoch 6: 167/634 Loss: 0.161825
2023-01-08 03:50: Train Epoch 6: 171/634 Loss: 0.168941
2023-01-08 03:50: Train Epoch 6: 175/634 Loss: 0.184986
2023-01-08 03:50: Train Epoch 6: 179/634 Loss: 0.206255
2023-01-08 03:50: Train Epoch 6: 183/634 Loss: 0.174894
2023-01-08 03:51: Train Epoch 6: 187/634 Loss: 0.177597
2023-01-08 03:51: Train Epoch 6: 191/634 Loss: 0.166049
2023-01-08 03:51: Train Epoch 6: 195/634 Loss: 0.186150
2023-01-08 03:51: Train Epoch 6: 199/634 Loss: 0.161556
2023-01-08 03:51: Train Epoch 6: 203/634 Loss: 0.202536
2023-01-08 03:52: Train Epoch 6: 207/634 Loss: 0.177253
2023-01-08 03:52: Train Epoch 6: 211/634 Loss: 0.185515
2023-01-08 03:52: Train Epoch 6: 215/634 Loss: 0.170422
2023-01-08 03:52: Train Epoch 6: 219/634 Loss: 0.155856
2023-01-08 03:53: Train Epoch 6: 223/634 Loss: 0.152884
2023-01-08 03:53: Train Epoch 6: 227/634 Loss: 0.192396
2023-01-08 03:53: Train Epoch 6: 231/634 Loss: 0.190348
2023-01-08 03:53: Train Epoch 6: 235/634 Loss: 0.164302
2023-01-08 03:54: Train Epoch 6: 239/634 Loss: 0.181900
2023-01-08 03:54: Train Epoch 6: 243/634 Loss: 0.183503
2023-01-08 03:54: Train Epoch 6: 247/634 Loss: 0.227696
2023-01-08 03:54: Train Epoch 6: 251/634 Loss: 0.196183
2023-01-08 03:55: Train Epoch 6: 255/634 Loss: 0.194323
2023-01-08 03:55: Train Epoch 6: 259/634 Loss: 0.175769
2023-01-08 03:55: Train Epoch 6: 263/634 Loss: 0.184873
2023-01-08 03:55: Train Epoch 6: 267/634 Loss: 0.214762
2023-01-08 03:56: Train Epoch 6: 271/634 Loss: 0.175644
2023-01-08 03:56: Train Epoch 6: 275/634 Loss: 0.203831
2023-01-08 03:56: Train Epoch 6: 279/634 Loss: 0.184198
2023-01-08 03:56: Train Epoch 6: 283/634 Loss: 0.169600
2023-01-08 03:57: Train Epoch 6: 287/634 Loss: 0.213703
2023-01-08 03:57: Train Epoch 6: 291/634 Loss: 0.167938
2023-01-08 03:57: Train Epoch 6: 295/634 Loss: 0.224701
2023-01-08 03:57: Train Epoch 6: 299/634 Loss: 0.147300
2023-01-08 03:58: Train Epoch 6: 303/634 Loss: 0.170359
2023-01-08 03:58: Train Epoch 6: 307/634 Loss: 0.208934
2023-01-08 03:58: Train Epoch 6: 311/634 Loss: 0.177286
2023-01-08 03:58: Train Epoch 6: 315/634 Loss: 0.164619
2023-01-08 03:59: Train Epoch 6: 319/634 Loss: 0.160049
2023-01-08 03:59: Train Epoch 6: 323/634 Loss: 0.185955
2023-01-08 03:59: Train Epoch 6: 327/634 Loss: 0.170933
2023-01-08 03:59: Train Epoch 6: 331/634 Loss: 0.199843
2023-01-08 04:00: Train Epoch 6: 335/634 Loss: 0.166228
2023-01-08 04:00: Train Epoch 6: 339/634 Loss: 0.193934
2023-01-08 04:00: Train Epoch 6: 343/634 Loss: 0.195835
2023-01-08 04:00: Train Epoch 6: 347/634 Loss: 0.145267
2023-01-08 04:01: Train Epoch 6: 351/634 Loss: 0.188058
2023-01-08 04:01: Train Epoch 6: 355/634 Loss: 0.181516
2023-01-08 04:01: Train Epoch 6: 359/634 Loss: 0.193371
2023-01-08 04:01: Train Epoch 6: 363/634 Loss: 0.176365
2023-01-08 04:01: Train Epoch 6: 367/634 Loss: 0.181544
2023-01-08 04:02: Train Epoch 6: 371/634 Loss: 0.178429
2023-01-08 04:02: Train Epoch 6: 375/634 Loss: 0.193769
2023-01-08 04:02: Train Epoch 6: 379/634 Loss: 0.199536
2023-01-08 04:02: Train Epoch 6: 383/634 Loss: 0.197480
2023-01-08 04:03: Train Epoch 6: 387/634 Loss: 0.188039
2023-01-08 04:03: Train Epoch 6: 391/634 Loss: 0.192349
2023-01-08 04:03: Train Epoch 6: 395/634 Loss: 0.174518
2023-01-08 04:03: Train Epoch 6: 399/634 Loss: 0.158894
2023-01-08 04:04: Train Epoch 6: 403/634 Loss: 0.176575
2023-01-08 04:04: Train Epoch 6: 407/634 Loss: 0.195697
2023-01-08 04:04: Train Epoch 6: 411/634 Loss: 0.174656
2023-01-08 04:04: Train Epoch 6: 415/634 Loss: 0.176732
2023-01-08 04:05: Train Epoch 6: 419/634 Loss: 0.193863
2023-01-08 04:05: Train Epoch 6: 423/634 Loss: 0.161406
2023-01-08 04:05: Train Epoch 6: 427/634 Loss: 0.153339
2023-01-08 04:05: Train Epoch 6: 431/634 Loss: 0.159196
2023-01-08 04:06: Train Epoch 6: 435/634 Loss: 0.211857
2023-01-08 04:06: Train Epoch 6: 439/634 Loss: 0.171689
2023-01-08 04:06: Train Epoch 6: 443/634 Loss: 0.158284
2023-01-08 04:06: Train Epoch 6: 447/634 Loss: 0.127537
2023-01-08 04:07: Train Epoch 6: 451/634 Loss: 0.167476
2023-01-08 04:07: Train Epoch 6: 455/634 Loss: 0.165679
2023-01-08 04:07: Train Epoch 6: 459/634 Loss: 0.155706
2023-01-08 04:07: Train Epoch 6: 463/634 Loss: 0.167500
2023-01-08 04:08: Train Epoch 6: 467/634 Loss: 0.145931
2023-01-08 04:08: Train Epoch 6: 471/634 Loss: 0.188887
2023-01-08 04:08: Train Epoch 6: 475/634 Loss: 0.165478
2023-01-08 04:08: Train Epoch 6: 479/634 Loss: 0.163180
2023-01-08 04:08: Train Epoch 6: 483/634 Loss: 0.197867
2023-01-08 04:09: Train Epoch 6: 487/634 Loss: 0.176603
2023-01-08 04:09: Train Epoch 6: 491/634 Loss: 0.204562
2023-01-08 04:09: Train Epoch 6: 495/634 Loss: 0.148996
2023-01-08 04:09: Train Epoch 6: 499/634 Loss: 0.215160
2023-01-08 04:10: Train Epoch 6: 503/634 Loss: 0.160866
2023-01-08 04:10: Train Epoch 6: 507/634 Loss: 0.169949
2023-01-08 04:10: Train Epoch 6: 511/634 Loss: 0.182007
2023-01-08 04:11: Train Epoch 6: 515/634 Loss: 0.174648
2023-01-08 04:11: Train Epoch 6: 519/634 Loss: 0.157443
2023-01-08 04:11: Train Epoch 6: 523/634 Loss: 0.153907
2023-01-08 04:11: Train Epoch 6: 527/634 Loss: 0.173774
2023-01-08 04:11: Train Epoch 6: 531/634 Loss: 0.184490
2023-01-08 04:12: Train Epoch 6: 535/634 Loss: 0.139365
2023-01-08 04:12: Train Epoch 6: 539/634 Loss: 0.162105
2023-01-08 04:12: Train Epoch 6: 543/634 Loss: 0.151432
2023-01-08 04:12: Train Epoch 6: 547/634 Loss: 0.158407
2023-01-08 04:13: Train Epoch 6: 551/634 Loss: 0.181852
2023-01-08 04:13: Train Epoch 6: 555/634 Loss: 0.188176
2023-01-08 04:13: Train Epoch 6: 559/634 Loss: 0.160607
2023-01-08 04:14: Train Epoch 6: 563/634 Loss: 0.183358
2023-01-08 04:14: Train Epoch 6: 567/634 Loss: 0.156291
2023-01-08 04:14: Train Epoch 6: 571/634 Loss: 0.169462
2023-01-08 04:14: Train Epoch 6: 575/634 Loss: 0.149206
2023-01-08 04:14: Train Epoch 6: 579/634 Loss: 0.176585
2023-01-08 04:15: Train Epoch 6: 583/634 Loss: 0.173556
2023-01-08 04:15: Train Epoch 6: 587/634 Loss: 0.156387
2023-01-08 04:15: Train Epoch 6: 591/634 Loss: 0.171251
2023-01-08 04:15: Train Epoch 6: 595/634 Loss: 0.175038
2023-01-08 04:16: Train Epoch 6: 599/634 Loss: 0.154682
2023-01-08 04:16: Train Epoch 6: 603/634 Loss: 0.209696
2023-01-08 04:16: Train Epoch 6: 607/634 Loss: 0.175199
2023-01-08 04:16: Train Epoch 6: 611/634 Loss: 0.170881
2023-01-08 04:17: Train Epoch 6: 615/634 Loss: 0.175713
2023-01-08 04:17: Train Epoch 6: 619/634 Loss: 0.182946
2023-01-08 04:17: Train Epoch 6: 623/634 Loss: 0.148161
2023-01-08 04:17: Train Epoch 6: 627/634 Loss: 0.163223
2023-01-08 04:18: Train Epoch 6: 631/634 Loss: 0.149632
2023-01-08 04:18: Train Epoch 6: 633/634 Loss: 0.062742
2023-01-08 04:18: **********Train Epoch 6: averaged Loss: 0.175636 
2023-01-08 04:18: 
Epoch time elapsed: 2341.7533740997314

2023-01-08 04:19: 
 metrics validation: {'precision': 0.8100456621004566, 'recall': 0.6823076923076923, 'f1-score': 0.7407098121085595, 'support': 1300, 'AUC': 0.9105269230769231, 'AUCPR': 0.8279637395009669, 'TP': 887, 'FP': 208, 'TN': 2392, 'FN': 413} 

2023-01-08 04:19: **********Val Epoch 6: average Loss: 0.177722
2023-01-08 04:19: *********************************Current best model saved!
2023-01-08 04:20: 
 Testing metrics {'precision': 0.8725490196078431, 'recall': 0.6522801302931596, 'f1-score': 0.7465051258154707, 'support': 1228, 'AUC': 0.9206228315419792, 'AUCPR': 0.867614475035118, 'TP': 801, 'FP': 117, 'TN': 2339, 'FN': 427} 

2023-01-08 04:24: 
 Testing metrics {'precision': 0.9179156098685728, 'recall': 0.9033356024506467, 'f1-score': 0.9105672461116194, 'support': 4407, 'AUC': 0.9731992504858883, 'AUCPR': 0.9396807130073705, 'TP': 3981, 'FP': 356, 'TN': 8458, 'FN': 426} 

2023-01-08 04:25: Train Epoch 7: 3/634 Loss: 0.183079
2023-01-08 04:25: Train Epoch 7: 7/634 Loss: 0.197365
2023-01-08 04:25: Train Epoch 7: 11/634 Loss: 0.164985
2023-01-08 04:25: Train Epoch 7: 15/634 Loss: 0.168471
2023-01-08 04:25: Train Epoch 7: 19/634 Loss: 0.210587
2023-01-08 04:26: Train Epoch 7: 23/634 Loss: 0.177885
2023-01-08 04:26: Train Epoch 7: 27/634 Loss: 0.184313
2023-01-08 04:26: Train Epoch 7: 31/634 Loss: 0.173655
2023-01-08 04:26: Train Epoch 7: 35/634 Loss: 0.146521
2023-01-08 04:27: Train Epoch 7: 39/634 Loss: 0.173998
2023-01-08 04:27: Train Epoch 7: 43/634 Loss: 0.141303
2023-01-08 04:27: Train Epoch 7: 47/634 Loss: 0.173097
2023-01-08 04:27: Train Epoch 7: 51/634 Loss: 0.166879
2023-01-08 04:28: Train Epoch 7: 55/634 Loss: 0.166325
2023-01-08 04:28: Train Epoch 7: 59/634 Loss: 0.216638
2023-01-08 04:28: Train Epoch 7: 63/634 Loss: 0.166214
2023-01-08 04:28: Train Epoch 7: 67/634 Loss: 0.146127
2023-01-08 04:29: Train Epoch 7: 71/634 Loss: 0.187131
2023-01-08 04:29: Train Epoch 7: 75/634 Loss: 0.145705
2023-01-08 04:29: Train Epoch 7: 79/634 Loss: 0.177889
2023-01-08 04:29: Train Epoch 7: 83/634 Loss: 0.172998
2023-01-08 04:30: Train Epoch 7: 87/634 Loss: 0.152016
2023-01-08 04:30: Train Epoch 7: 91/634 Loss: 0.183782
2023-01-08 04:30: Train Epoch 7: 95/634 Loss: 0.159209
2023-01-08 04:30: Train Epoch 7: 99/634 Loss: 0.156997
2023-01-08 04:31: Train Epoch 7: 103/634 Loss: 0.195388
2023-01-08 04:31: Train Epoch 7: 107/634 Loss: 0.176774
2023-01-08 04:31: Train Epoch 7: 111/634 Loss: 0.147250
2023-01-08 04:31: Train Epoch 7: 115/634 Loss: 0.198376
2023-01-08 04:32: Train Epoch 7: 119/634 Loss: 0.152109
2023-01-08 04:32: Train Epoch 7: 123/634 Loss: 0.164153
2023-01-08 04:32: Train Epoch 7: 127/634 Loss: 0.176040
2023-01-08 04:32: Train Epoch 7: 131/634 Loss: 0.180201
2023-01-08 04:33: Train Epoch 7: 135/634 Loss: 0.178480
2023-01-08 04:33: Train Epoch 7: 139/634 Loss: 0.178876
2023-01-08 04:33: Train Epoch 7: 143/634 Loss: 0.200218
2023-01-08 04:33: Train Epoch 7: 147/634 Loss: 0.166070
2023-01-08 04:34: Train Epoch 7: 151/634 Loss: 0.192546
2023-01-08 04:34: Train Epoch 7: 155/634 Loss: 0.171080
2023-01-08 04:34: Train Epoch 7: 159/634 Loss: 0.208631
2023-01-08 04:34: Train Epoch 7: 163/634 Loss: 0.204711
2023-01-08 04:35: Train Epoch 7: 167/634 Loss: 0.178799
2023-01-08 04:35: Train Epoch 7: 171/634 Loss: 0.143768
2023-01-08 04:35: Train Epoch 7: 175/634 Loss: 0.195742
2023-01-08 04:35: Train Epoch 7: 179/634 Loss: 0.171448
2023-01-08 04:36: Train Epoch 7: 183/634 Loss: 0.180295
2023-01-08 04:36: Train Epoch 7: 187/634 Loss: 0.144869
2023-01-08 04:36: Train Epoch 7: 191/634 Loss: 0.198789
2023-01-08 04:36: Train Epoch 7: 195/634 Loss: 0.176605
2023-01-08 04:37: Train Epoch 7: 199/634 Loss: 0.175145
2023-01-08 04:37: Train Epoch 7: 203/634 Loss: 0.166904
2023-01-08 04:37: Train Epoch 7: 207/634 Loss: 0.189802
2023-01-08 04:37: Train Epoch 7: 211/634 Loss: 0.142496
2023-01-08 04:38: Train Epoch 7: 215/634 Loss: 0.170409
2023-01-08 04:38: Train Epoch 7: 219/634 Loss: 0.163032
2023-01-08 04:38: Train Epoch 7: 223/634 Loss: 0.198313
2023-01-08 04:38: Train Epoch 7: 227/634 Loss: 0.167820
2023-01-08 04:39: Train Epoch 7: 231/634 Loss: 0.151437
2023-01-08 04:39: Train Epoch 7: 235/634 Loss: 0.172631
2023-01-08 04:39: Train Epoch 7: 239/634 Loss: 0.173423
2023-01-08 04:39: Train Epoch 7: 243/634 Loss: 0.171942
2023-01-08 04:40: Train Epoch 7: 247/634 Loss: 0.167172
2023-01-08 04:40: Train Epoch 7: 251/634 Loss: 0.217432
2023-01-08 04:40: Train Epoch 7: 255/634 Loss: 0.166824
2023-01-08 04:40: Train Epoch 7: 259/634 Loss: 0.173532
2023-01-08 04:41: Train Epoch 7: 263/634 Loss: 0.146254
2023-01-08 04:41: Train Epoch 7: 267/634 Loss: 0.182553
2023-01-08 04:41: Train Epoch 7: 271/634 Loss: 0.164354
2023-01-08 04:41: Train Epoch 7: 275/634 Loss: 0.192999
2023-01-08 04:41: Train Epoch 7: 279/634 Loss: 0.196371
2023-01-08 04:42: Train Epoch 7: 283/634 Loss: 0.158149
2023-01-08 04:42: Train Epoch 7: 287/634 Loss: 0.153836
2023-01-08 04:42: Train Epoch 7: 291/634 Loss: 0.175617
2023-01-08 04:42: Train Epoch 7: 295/634 Loss: 0.162524
2023-01-08 04:43: Train Epoch 7: 299/634 Loss: 0.190040
2023-01-08 04:43: Train Epoch 7: 303/634 Loss: 0.187234
2023-01-08 04:43: Train Epoch 7: 307/634 Loss: 0.177325
2023-01-08 04:43: Train Epoch 7: 311/634 Loss: 0.176083
2023-01-08 04:44: Train Epoch 7: 315/634 Loss: 0.175332
2023-01-08 04:44: Train Epoch 7: 319/634 Loss: 0.169868
2023-01-08 04:44: Train Epoch 7: 323/634 Loss: 0.178042
2023-01-08 04:44: Train Epoch 7: 327/634 Loss: 0.139096
2023-01-08 04:45: Train Epoch 7: 331/634 Loss: 0.149216
2023-01-08 04:45: Train Epoch 7: 335/634 Loss: 0.211456
2023-01-08 04:45: Train Epoch 7: 339/634 Loss: 0.158446
2023-01-08 04:45: Train Epoch 7: 343/634 Loss: 0.180791
2023-01-08 04:46: Train Epoch 7: 347/634 Loss: 0.177056
2023-01-08 04:46: Train Epoch 7: 351/634 Loss: 0.164790
2023-01-08 04:46: Train Epoch 7: 355/634 Loss: 0.179304
2023-01-08 04:46: Train Epoch 7: 359/634 Loss: 0.211985
2023-01-08 04:47: Train Epoch 7: 363/634 Loss: 0.168822
2023-01-08 04:47: Train Epoch 7: 367/634 Loss: 0.152748
2023-01-08 04:47: Train Epoch 7: 371/634 Loss: 0.187633
2023-01-08 04:47: Train Epoch 7: 375/634 Loss: 0.133323
2023-01-08 04:48: Train Epoch 7: 379/634 Loss: 0.158357
2023-01-08 04:48: Train Epoch 7: 383/634 Loss: 0.171212
2023-01-08 04:48: Train Epoch 7: 387/634 Loss: 0.173044
2023-01-08 04:48: Train Epoch 7: 391/634 Loss: 0.145122
2023-01-08 04:49: Train Epoch 7: 395/634 Loss: 0.169764
2023-01-08 04:49: Train Epoch 7: 399/634 Loss: 0.166383
2023-01-08 04:49: Train Epoch 7: 403/634 Loss: 0.170699
2023-01-08 04:49: Train Epoch 7: 407/634 Loss: 0.166600
2023-01-08 04:50: Train Epoch 7: 411/634 Loss: 0.171644
2023-01-08 04:50: Train Epoch 7: 415/634 Loss: 0.189351
2023-01-08 04:50: Train Epoch 7: 419/634 Loss: 0.149515
2023-01-08 04:50: Train Epoch 7: 423/634 Loss: 0.159525
2023-01-08 04:51: Train Epoch 7: 427/634 Loss: 0.180088
2023-01-08 04:51: Train Epoch 7: 431/634 Loss: 0.201234
2023-01-08 04:51: Train Epoch 7: 435/634 Loss: 0.161183
2023-01-08 04:51: Train Epoch 7: 439/634 Loss: 0.154467
2023-01-08 04:52: Train Epoch 7: 443/634 Loss: 0.135583
2023-01-08 04:52: Train Epoch 7: 447/634 Loss: 0.178136
2023-01-08 04:52: Train Epoch 7: 451/634 Loss: 0.162571
2023-01-08 04:52: Train Epoch 7: 455/634 Loss: 0.158677
2023-01-08 04:53: Train Epoch 7: 459/634 Loss: 0.163565
2023-01-08 04:53: Train Epoch 7: 463/634 Loss: 0.149471
2023-01-08 04:53: Train Epoch 7: 467/634 Loss: 0.166802
2023-01-08 04:53: Train Epoch 7: 471/634 Loss: 0.176079
2023-01-08 04:54: Train Epoch 7: 475/634 Loss: 0.172797
2023-01-08 04:54: Train Epoch 7: 479/634 Loss: 0.181924
2023-01-08 04:54: Train Epoch 7: 483/634 Loss: 0.138050
2023-01-08 04:54: Train Epoch 7: 487/634 Loss: 0.168773
2023-01-08 04:55: Train Epoch 7: 491/634 Loss: 0.155624
2023-01-08 04:55: Train Epoch 7: 495/634 Loss: 0.195596
2023-01-08 04:55: Train Epoch 7: 499/634 Loss: 0.149712
2023-01-08 04:55: Train Epoch 7: 503/634 Loss: 0.186624
2023-01-08 04:56: Train Epoch 7: 507/634 Loss: 0.186686
2023-01-08 04:56: Train Epoch 7: 511/634 Loss: 0.194287
2023-01-08 04:56: Train Epoch 7: 515/634 Loss: 0.126694
2023-01-08 04:56: Train Epoch 7: 519/634 Loss: 0.144860
2023-01-08 04:57: Train Epoch 7: 523/634 Loss: 0.145023
2023-01-08 04:57: Train Epoch 7: 527/634 Loss: 0.168971
2023-01-08 04:57: Train Epoch 7: 531/634 Loss: 0.156628
2023-01-08 04:57: Train Epoch 7: 535/634 Loss: 0.182459
2023-01-08 04:58: Train Epoch 7: 539/634 Loss: 0.175876
2023-01-08 04:58: Train Epoch 7: 543/634 Loss: 0.160981
2023-01-08 04:58: Train Epoch 7: 547/634 Loss: 0.165655
2023-01-08 04:58: Train Epoch 7: 551/634 Loss: 0.154354
2023-01-08 04:59: Train Epoch 7: 555/634 Loss: 0.171970
2023-01-08 04:59: Train Epoch 7: 559/634 Loss: 0.204435
2023-01-08 04:59: Train Epoch 7: 563/634 Loss: 0.180793
2023-01-08 04:59: Train Epoch 7: 567/634 Loss: 0.180068
2023-01-08 05:00: Train Epoch 7: 571/634 Loss: 0.182781
2023-01-08 05:00: Train Epoch 7: 575/634 Loss: 0.153100
2023-01-08 05:00: Train Epoch 7: 579/634 Loss: 0.182962
2023-01-08 05:00: Train Epoch 7: 583/634 Loss: 0.176943
2023-01-08 05:01: Train Epoch 7: 587/634 Loss: 0.158013
2023-01-08 05:01: Train Epoch 7: 591/634 Loss: 0.157579
2023-01-08 05:01: Train Epoch 7: 595/634 Loss: 0.192664
2023-01-08 05:01: Train Epoch 7: 599/634 Loss: 0.165983
2023-01-08 05:02: Train Epoch 7: 603/634 Loss: 0.158391
2023-01-08 05:02: Train Epoch 7: 607/634 Loss: 0.189984
2023-01-08 05:02: Train Epoch 7: 611/634 Loss: 0.151247
2023-01-08 05:02: Train Epoch 7: 615/634 Loss: 0.183332
2023-01-08 05:03: Train Epoch 7: 619/634 Loss: 0.156945
2023-01-08 05:03: Train Epoch 7: 623/634 Loss: 0.160765
2023-01-08 05:03: Train Epoch 7: 627/634 Loss: 0.202051
2023-01-08 05:03: Train Epoch 7: 631/634 Loss: 0.166531
2023-01-08 05:03: Train Epoch 7: 633/634 Loss: 0.061153
2023-01-08 05:03: **********Train Epoch 7: averaged Loss: 0.170895 
2023-01-08 05:03: 
Epoch time elapsed: 2347.0998725891113

2023-01-08 05:05: 
 metrics validation: {'precision': 0.8498942917547568, 'recall': 0.6184615384615385, 'f1-score': 0.715939447907391, 'support': 1300, 'AUC': 0.9205880177514794, 'AUCPR': 0.8509902026738153, 'TP': 804, 'FP': 142, 'TN': 2458, 'FN': 496} 

2023-01-08 05:05: **********Val Epoch 7: average Loss: 0.176511
2023-01-08 05:05: *********************************Current best model saved!
2023-01-08 05:06: 
 Testing metrics {'precision': 0.9035591274397244, 'recall': 0.6408794788273615, 'f1-score': 0.7498808956646023, 'support': 1228, 'AUC': 0.9285241090091141, 'AUCPR': 0.8802134811026263, 'TP': 787, 'FP': 84, 'TN': 2372, 'FN': 441} 

2023-01-08 05:10: 
 Testing metrics {'precision': 0.9442018437651626, 'recall': 0.8831404583616973, 'f1-score': 0.9126509555633722, 'support': 4407, 'AUC': 0.9774541801265175, 'AUCPR': 0.9525218961126537, 'TP': 3892, 'FP': 230, 'TN': 8584, 'FN': 515} 

2023-01-08 05:10: Train Epoch 8: 3/634 Loss: 0.180178
2023-01-08 05:10: Train Epoch 8: 7/634 Loss: 0.152968
2023-01-08 05:11: Train Epoch 8: 11/634 Loss: 0.175385
2023-01-08 05:11: Train Epoch 8: 15/634 Loss: 0.176153
2023-01-08 05:11: Train Epoch 8: 19/634 Loss: 0.180963
2023-01-08 05:11: Train Epoch 8: 23/634 Loss: 0.188425
2023-01-08 05:12: Train Epoch 8: 27/634 Loss: 0.167699
2023-01-08 05:12: Train Epoch 8: 31/634 Loss: 0.193084
2023-01-08 05:12: Train Epoch 8: 35/634 Loss: 0.191946
2023-01-08 05:12: Train Epoch 8: 39/634 Loss: 0.145591
2023-01-08 05:13: Train Epoch 8: 43/634 Loss: 0.176592
2023-01-08 05:13: Train Epoch 8: 47/634 Loss: 0.149027
2023-01-08 05:13: Train Epoch 8: 51/634 Loss: 0.180298
2023-01-08 05:13: Train Epoch 8: 55/634 Loss: 0.126545
2023-01-08 05:14: Train Epoch 8: 59/634 Loss: 0.159520
2023-01-08 05:14: Train Epoch 8: 63/634 Loss: 0.175055
2023-01-08 05:14: Train Epoch 8: 67/634 Loss: 0.164543
2023-01-08 05:14: Train Epoch 8: 71/634 Loss: 0.175030
2023-01-08 05:15: Train Epoch 8: 75/634 Loss: 0.154684
2023-01-08 05:15: Train Epoch 8: 79/634 Loss: 0.158012
2023-01-08 05:15: Train Epoch 8: 83/634 Loss: 0.178438
2023-01-08 05:15: Train Epoch 8: 87/634 Loss: 0.148725
2023-01-08 05:16: Train Epoch 8: 91/634 Loss: 0.206398
2023-01-08 05:16: Train Epoch 8: 95/634 Loss: 0.258737
2023-01-08 05:16: Train Epoch 8: 99/634 Loss: 0.163889
2023-01-08 05:16: Train Epoch 8: 103/634 Loss: 0.191016
2023-01-08 05:16: Train Epoch 8: 107/634 Loss: 0.180652
2023-01-08 05:17: Train Epoch 8: 111/634 Loss: 0.181927
2023-01-08 05:17: Train Epoch 8: 115/634 Loss: 0.161760
2023-01-08 05:17: Train Epoch 8: 119/634 Loss: 0.172132
2023-01-08 05:17: Train Epoch 8: 123/634 Loss: 0.161489
2023-01-08 05:18: Train Epoch 8: 127/634 Loss: 0.165760
2023-01-08 05:18: Train Epoch 8: 131/634 Loss: 0.171076
2023-01-08 05:18: Train Epoch 8: 135/634 Loss: 0.224987
2023-01-08 05:18: Train Epoch 8: 139/634 Loss: 0.199818
2023-01-08 05:19: Train Epoch 8: 143/634 Loss: 0.154844
2023-01-08 05:19: Train Epoch 8: 147/634 Loss: 0.188382
2023-01-08 05:19: Train Epoch 8: 151/634 Loss: 0.189420
2023-01-08 05:19: Train Epoch 8: 155/634 Loss: 0.187249
2023-01-08 05:20: Train Epoch 8: 159/634 Loss: 0.179814
2023-01-08 05:20: Train Epoch 8: 163/634 Loss: 0.214317
2023-01-08 05:20: Train Epoch 8: 167/634 Loss: 0.148314
2023-01-08 05:20: Train Epoch 8: 171/634 Loss: 0.139394
2023-01-08 05:21: Train Epoch 8: 175/634 Loss: 0.160115
2023-01-08 05:21: Train Epoch 8: 179/634 Loss: 0.192295
2023-01-08 05:21: Train Epoch 8: 183/634 Loss: 0.185475
2023-01-08 05:21: Train Epoch 8: 187/634 Loss: 0.174440
2023-01-08 05:22: Train Epoch 8: 191/634 Loss: 0.196401
2023-01-08 05:22: Train Epoch 8: 195/634 Loss: 0.153426
2023-01-08 05:22: Train Epoch 8: 199/634 Loss: 0.165796
2023-01-08 05:22: Train Epoch 8: 203/634 Loss: 0.198620
2023-01-08 05:23: Train Epoch 8: 207/634 Loss: 0.164269
2023-01-08 05:23: Train Epoch 8: 211/634 Loss: 0.150050
2023-01-08 05:23: Train Epoch 8: 215/634 Loss: 0.177203
2023-01-08 05:23: Train Epoch 8: 219/634 Loss: 0.193940
2023-01-08 05:23: Train Epoch 8: 223/634 Loss: 0.190860
2023-01-08 05:24: Train Epoch 8: 227/634 Loss: 0.167484
2023-01-08 05:24: Train Epoch 8: 231/634 Loss: 0.153186
2023-01-08 05:24: Train Epoch 8: 235/634 Loss: 0.167988
2023-01-08 05:24: Train Epoch 8: 239/634 Loss: 0.198116
2023-01-08 05:25: Train Epoch 8: 243/634 Loss: 0.164732
2023-01-08 05:25: Train Epoch 8: 247/634 Loss: 0.180637
2023-01-08 05:25: Train Epoch 8: 251/634 Loss: 0.195579
2023-01-08 05:25: Train Epoch 8: 255/634 Loss: 0.177696
2023-01-08 05:26: Train Epoch 8: 259/634 Loss: 0.192869
2023-01-08 05:26: Train Epoch 8: 263/634 Loss: 0.163676
2023-01-08 05:26: Train Epoch 8: 267/634 Loss: 0.142742
2023-01-08 05:26: Train Epoch 8: 271/634 Loss: 0.140618
2023-01-08 05:27: Train Epoch 8: 275/634 Loss: 0.162704
2023-01-08 05:27: Train Epoch 8: 279/634 Loss: 0.177323
2023-01-08 05:27: Train Epoch 8: 283/634 Loss: 0.127837
2023-01-08 05:27: Train Epoch 8: 287/634 Loss: 0.176014
2023-01-08 05:28: Train Epoch 8: 291/634 Loss: 0.171171
2023-01-08 05:28: Train Epoch 8: 295/634 Loss: 0.173028
2023-01-08 05:28: Train Epoch 8: 299/634 Loss: 0.156461
2023-01-08 05:28: Train Epoch 8: 303/634 Loss: 0.142059
2023-01-08 05:29: Train Epoch 8: 307/634 Loss: 0.185419
2023-01-08 05:29: Train Epoch 8: 311/634 Loss: 0.172387
2023-01-08 05:29: Train Epoch 8: 315/634 Loss: 0.159518
2023-01-08 05:29: Train Epoch 8: 319/634 Loss: 0.177006
2023-01-08 05:30: Train Epoch 8: 323/634 Loss: 0.173148
2023-01-08 05:30: Train Epoch 8: 327/634 Loss: 0.183165
2023-01-08 05:30: Train Epoch 8: 331/634 Loss: 0.200431
2023-01-08 05:30: Train Epoch 8: 335/634 Loss: 0.151379
2023-01-08 05:31: Train Epoch 8: 339/634 Loss: 0.157056
2023-01-08 05:31: Train Epoch 8: 343/634 Loss: 0.150519
2023-01-08 05:31: Train Epoch 8: 347/634 Loss: 0.146837
2023-01-08 05:31: Train Epoch 8: 351/634 Loss: 0.183163
2023-01-08 05:32: Train Epoch 8: 355/634 Loss: 0.173639
2023-01-08 05:32: Train Epoch 8: 359/634 Loss: 0.168114
2023-01-08 05:32: Train Epoch 8: 363/634 Loss: 0.190519
2023-01-08 05:32: Train Epoch 8: 367/634 Loss: 0.195575
2023-01-08 05:33: Train Epoch 8: 371/634 Loss: 0.189604
2023-01-08 05:33: Train Epoch 8: 375/634 Loss: 0.157147
2023-01-08 05:33: Train Epoch 8: 379/634 Loss: 0.173236
2023-01-08 05:33: Train Epoch 8: 383/634 Loss: 0.152552
2023-01-08 05:34: Train Epoch 8: 387/634 Loss: 0.174570
2023-01-08 05:34: Train Epoch 8: 391/634 Loss: 0.178501
2023-01-08 05:34: Train Epoch 8: 395/634 Loss: 0.155747
2023-01-08 05:34: Train Epoch 8: 399/634 Loss: 0.170103
2023-01-08 05:34: Train Epoch 8: 403/634 Loss: 0.200801
2023-01-08 05:35: Train Epoch 8: 407/634 Loss: 0.157508
2023-01-08 05:35: Train Epoch 8: 411/634 Loss: 0.178916
2023-01-08 05:35: Train Epoch 8: 415/634 Loss: 0.158235
2023-01-08 05:35: Train Epoch 8: 419/634 Loss: 0.177845
2023-01-08 05:36: Train Epoch 8: 423/634 Loss: 0.189232
2023-01-08 05:36: Train Epoch 8: 427/634 Loss: 0.184129
2023-01-08 05:36: Train Epoch 8: 431/634 Loss: 0.173868
2023-01-08 05:36: Train Epoch 8: 435/634 Loss: 0.176643
2023-01-08 05:37: Train Epoch 8: 439/634 Loss: 0.157988
2023-01-08 05:37: Train Epoch 8: 443/634 Loss: 0.178847
2023-01-08 05:37: Train Epoch 8: 447/634 Loss: 0.182012
2023-01-08 05:37: Train Epoch 8: 451/634 Loss: 0.175366
2023-01-08 05:38: Train Epoch 8: 455/634 Loss: 0.176544
2023-01-08 05:38: Train Epoch 8: 459/634 Loss: 0.178253
2023-01-08 05:38: Train Epoch 8: 463/634 Loss: 0.185747
2023-01-08 05:38: Train Epoch 8: 467/634 Loss: 0.167488
2023-01-08 05:39: Train Epoch 8: 471/634 Loss: 0.141510
2023-01-08 05:39: Train Epoch 8: 475/634 Loss: 0.177907
2023-01-08 05:39: Train Epoch 8: 479/634 Loss: 0.175214
2023-01-08 05:39: Train Epoch 8: 483/634 Loss: 0.174896
2023-01-08 05:40: Train Epoch 8: 487/634 Loss: 0.178558
2023-01-08 05:40: Train Epoch 8: 491/634 Loss: 0.159741
2023-01-08 05:40: Train Epoch 8: 495/634 Loss: 0.173904
2023-01-08 05:40: Train Epoch 8: 499/634 Loss: 0.190094
2023-01-08 05:41: Train Epoch 8: 503/634 Loss: 0.201093
2023-01-08 05:41: Train Epoch 8: 507/634 Loss: 0.153105
2023-01-08 05:41: Train Epoch 8: 511/634 Loss: 0.190284
2023-01-08 05:41: Train Epoch 8: 515/634 Loss: 0.168794
2023-01-08 05:42: Train Epoch 8: 519/634 Loss: 0.195876
2023-01-08 05:42: Train Epoch 8: 523/634 Loss: 0.160920
2023-01-08 05:42: Train Epoch 8: 527/634 Loss: 0.173639
2023-01-08 05:42: Train Epoch 8: 531/634 Loss: 0.147463
2023-01-08 05:43: Train Epoch 8: 535/634 Loss: 0.150781
2023-01-08 05:43: Train Epoch 8: 539/634 Loss: 0.183276
2023-01-08 05:43: Train Epoch 8: 543/634 Loss: 0.170979
2023-01-08 05:43: Train Epoch 8: 547/634 Loss: 0.187717
2023-01-08 05:44: Train Epoch 8: 551/634 Loss: 0.182257
2023-01-08 05:44: Train Epoch 8: 555/634 Loss: 0.154826
2023-01-08 05:44: Train Epoch 8: 559/634 Loss: 0.145849
2023-01-08 05:44: Train Epoch 8: 563/634 Loss: 0.143115
2023-01-08 05:44: Train Epoch 8: 567/634 Loss: 0.188560
2023-01-08 05:45: Train Epoch 8: 571/634 Loss: 0.181977
2023-01-08 05:45: Train Epoch 8: 575/634 Loss: 0.161435
2023-01-08 05:45: Train Epoch 8: 579/634 Loss: 0.160181
2023-01-08 05:45: Train Epoch 8: 583/634 Loss: 0.159803
2023-01-08 05:46: Train Epoch 8: 587/634 Loss: 0.158322
2023-01-08 05:46: Train Epoch 8: 591/634 Loss: 0.168234
2023-01-08 05:46: Train Epoch 8: 595/634 Loss: 0.205379
2023-01-08 05:47: Train Epoch 8: 599/634 Loss: 0.174397
2023-01-08 05:47: Train Epoch 8: 603/634 Loss: 0.172846
2023-01-08 05:47: Train Epoch 8: 607/634 Loss: 0.152691
2023-01-08 05:47: Train Epoch 8: 611/634 Loss: 0.147390
2023-01-08 05:47: Train Epoch 8: 615/634 Loss: 0.157836
2023-01-08 05:48: Train Epoch 8: 619/634 Loss: 0.145908
2023-01-08 05:48: Train Epoch 8: 623/634 Loss: 0.172410
2023-01-08 05:48: Train Epoch 8: 627/634 Loss: 0.135318
2023-01-08 05:48: Train Epoch 8: 631/634 Loss: 0.164058
2023-01-08 05:49: Train Epoch 8: 633/634 Loss: 0.086545
2023-01-08 05:49: **********Train Epoch 8: averaged Loss: 0.171502 
2023-01-08 05:49: 
Epoch time elapsed: 2318.50670671463

2023-01-08 05:50: 
 metrics validation: {'precision': 0.8196428571428571, 'recall': 0.7061538461538461, 'f1-score': 0.7586776859504132, 'support': 1300, 'AUC': 0.9306624260355029, 'AUCPR': 0.8643658467912471, 'TP': 918, 'FP': 202, 'TN': 2398, 'FN': 382} 

2023-01-08 05:50: **********Val Epoch 8: average Loss: 0.152977
2023-01-08 05:50: *********************************Current best model saved!
2023-01-08 05:51: 
 Testing metrics {'precision': 0.8554729011689692, 'recall': 0.6555374592833876, 'f1-score': 0.7422775472568004, 'support': 1228, 'AUC': 0.9273082473023586, 'AUCPR': 0.8762869647794839, 'TP': 805, 'FP': 136, 'TN': 2320, 'FN': 423} 

2023-01-08 05:55: 
 Testing metrics {'precision': 0.9152930402930403, 'recall': 0.9071931018833673, 'f1-score': 0.9112250712250712, 'support': 4407, 'AUC': 0.978818521022597, 'AUCPR': 0.9602996066645514, 'TP': 3998, 'FP': 370, 'TN': 8444, 'FN': 409} 

2023-01-08 05:55: Train Epoch 9: 3/634 Loss: 0.185222
2023-01-08 05:55: Train Epoch 9: 7/634 Loss: 0.192750
2023-01-08 05:56: Train Epoch 9: 11/634 Loss: 0.144791
2023-01-08 05:56: Train Epoch 9: 15/634 Loss: 0.161541
2023-01-08 05:56: Train Epoch 9: 19/634 Loss: 0.136807
2023-01-08 05:56: Train Epoch 9: 23/634 Loss: 0.142512
2023-01-08 05:57: Train Epoch 9: 27/634 Loss: 0.141150
2023-01-08 05:57: Train Epoch 9: 31/634 Loss: 0.151383
2023-01-08 05:57: Train Epoch 9: 35/634 Loss: 0.165153
2023-01-08 05:57: Train Epoch 9: 39/634 Loss: 0.143515
2023-01-08 05:58: Train Epoch 9: 43/634 Loss: 0.137500
2023-01-08 05:58: Train Epoch 9: 47/634 Loss: 0.158646
2023-01-08 05:58: Train Epoch 9: 51/634 Loss: 0.202383
2023-01-08 05:58: Train Epoch 9: 55/634 Loss: 0.185201
2023-01-08 05:59: Train Epoch 9: 59/634 Loss: 0.149588
2023-01-08 05:59: Train Epoch 9: 63/634 Loss: 0.165482
2023-01-08 05:59: Train Epoch 9: 67/634 Loss: 0.177804
2023-01-08 05:59: Train Epoch 9: 71/634 Loss: 0.157860
2023-01-08 05:59: Train Epoch 9: 75/634 Loss: 0.151792
2023-01-08 06:00: Train Epoch 9: 79/634 Loss: 0.186727
2023-01-08 06:00: Train Epoch 9: 83/634 Loss: 0.159969
2023-01-08 06:00: Train Epoch 9: 87/634 Loss: 0.174465
2023-01-08 06:00: Train Epoch 9: 91/634 Loss: 0.152568
2023-01-08 06:01: Train Epoch 9: 95/634 Loss: 0.175485
2023-01-08 06:01: Train Epoch 9: 99/634 Loss: 0.170953
2023-01-08 06:01: Train Epoch 9: 103/634 Loss: 0.181250
2023-01-08 06:01: Train Epoch 9: 107/634 Loss: 0.178593
2023-01-08 06:02: Train Epoch 9: 111/634 Loss: 0.162748
2023-01-08 06:02: Train Epoch 9: 115/634 Loss: 0.164551
2023-01-08 06:02: Train Epoch 9: 119/634 Loss: 0.200790
2023-01-08 06:02: Train Epoch 9: 123/634 Loss: 0.181902
2023-01-08 06:03: Train Epoch 9: 127/634 Loss: 0.176445
2023-01-08 06:03: Train Epoch 9: 131/634 Loss: 0.161357
2023-01-08 06:03: Train Epoch 9: 135/634 Loss: 0.165482
2023-01-08 06:03: Train Epoch 9: 139/634 Loss: 0.172079
2023-01-08 06:04: Train Epoch 9: 143/634 Loss: 0.167463
2023-01-08 06:04: Train Epoch 9: 147/634 Loss: 0.157947
2023-01-08 06:04: Train Epoch 9: 151/634 Loss: 0.154321
2023-01-08 06:04: Train Epoch 9: 155/634 Loss: 0.165221
2023-01-08 06:05: Train Epoch 9: 159/634 Loss: 0.174937
2023-01-08 06:05: Train Epoch 9: 163/634 Loss: 0.150305
2023-01-08 06:05: Train Epoch 9: 167/634 Loss: 0.180281
2023-01-08 06:05: Train Epoch 9: 171/634 Loss: 0.175941
2023-01-08 06:06: Train Epoch 9: 175/634 Loss: 0.189746
2023-01-08 06:06: Train Epoch 9: 179/634 Loss: 0.167716
2023-01-08 06:06: Train Epoch 9: 183/634 Loss: 0.174353
2023-01-08 06:06: Train Epoch 9: 187/634 Loss: 0.151001
2023-01-08 06:07: Train Epoch 9: 191/634 Loss: 0.154608
2023-01-08 06:07: Train Epoch 9: 195/634 Loss: 0.152098
2023-01-08 06:07: Train Epoch 9: 199/634 Loss: 0.169534
2023-01-08 06:07: Train Epoch 9: 203/634 Loss: 0.159271
2023-01-08 06:08: Train Epoch 9: 207/634 Loss: 0.162518
2023-01-08 06:08: Train Epoch 9: 211/634 Loss: 0.159484
2023-01-08 06:08: Train Epoch 9: 215/634 Loss: 0.142362
2023-01-08 06:08: Train Epoch 9: 219/634 Loss: 0.142228
2023-01-08 06:09: Train Epoch 9: 223/634 Loss: 0.133291
2023-01-08 06:09: Train Epoch 9: 227/634 Loss: 0.162671
2023-01-08 06:09: Train Epoch 9: 231/634 Loss: 0.148117
2023-01-08 06:09: Train Epoch 9: 235/634 Loss: 0.179755
2023-01-08 06:10: Train Epoch 9: 239/634 Loss: 0.186987
2023-01-08 06:10: Train Epoch 9: 243/634 Loss: 0.151922
2023-01-08 06:10: Train Epoch 9: 247/634 Loss: 0.167166
2023-01-08 06:10: Train Epoch 9: 251/634 Loss: 0.152849
2023-01-08 06:11: Train Epoch 9: 255/634 Loss: 0.171211
2023-01-08 06:11: Train Epoch 9: 259/634 Loss: 0.180588
2023-01-08 06:11: Train Epoch 9: 263/634 Loss: 0.148066
2023-01-08 06:11: Train Epoch 9: 267/634 Loss: 0.155835
2023-01-08 06:12: Train Epoch 9: 271/634 Loss: 0.168354
2023-01-08 06:12: Train Epoch 9: 275/634 Loss: 0.156715
2023-01-08 06:12: Train Epoch 9: 279/634 Loss: 0.153942
2023-01-08 06:12: Train Epoch 9: 283/634 Loss: 0.162896
2023-01-08 06:13: Train Epoch 9: 287/634 Loss: 0.144538
2023-01-08 06:13: Train Epoch 9: 291/634 Loss: 0.189383
2023-01-08 06:13: Train Epoch 9: 295/634 Loss: 0.169585
2023-01-08 06:13: Train Epoch 9: 299/634 Loss: 0.151158
2023-01-08 06:13: Train Epoch 9: 303/634 Loss: 0.140997
2023-01-08 06:14: Train Epoch 9: 307/634 Loss: 0.177615
2023-01-08 06:14: Train Epoch 9: 311/634 Loss: 0.181180
2023-01-08 06:14: Train Epoch 9: 315/634 Loss: 0.151984
2023-01-08 06:14: Train Epoch 9: 319/634 Loss: 0.170630
2023-01-08 06:15: Train Epoch 9: 323/634 Loss: 0.153908
2023-01-08 06:15: Train Epoch 9: 327/634 Loss: 0.177195
2023-01-08 06:15: Train Epoch 9: 331/634 Loss: 0.149843
2023-01-08 06:16: Train Epoch 9: 335/634 Loss: 0.170905
2023-01-08 06:16: Train Epoch 9: 339/634 Loss: 0.150059
2023-01-08 06:16: Train Epoch 9: 343/634 Loss: 0.160008
2023-01-08 06:16: Train Epoch 9: 347/634 Loss: 0.139445
2023-01-08 06:17: Train Epoch 9: 351/634 Loss: 0.180559
2023-01-08 06:17: Train Epoch 9: 355/634 Loss: 0.136739
2023-01-08 06:17: Train Epoch 9: 359/634 Loss: 0.152096
2023-01-08 06:17: Train Epoch 9: 363/634 Loss: 0.153914
2023-01-08 06:17: Train Epoch 9: 367/634 Loss: 0.152035
2023-01-08 06:18: Train Epoch 9: 371/634 Loss: 0.155272
2023-01-08 06:18: Train Epoch 9: 375/634 Loss: 0.194301
2023-01-08 06:18: Train Epoch 9: 379/634 Loss: 0.191918
2023-01-08 06:19: Train Epoch 9: 383/634 Loss: 0.187722
2023-01-08 06:19: Train Epoch 9: 387/634 Loss: 0.142491
2023-01-08 06:19: Train Epoch 9: 391/634 Loss: 0.169246
2023-01-08 06:19: Train Epoch 9: 395/634 Loss: 0.165156
2023-01-08 06:19: Train Epoch 9: 399/634 Loss: 0.156467
2023-01-08 06:20: Train Epoch 9: 403/634 Loss: 0.178286
2023-01-08 06:20: Train Epoch 9: 407/634 Loss: 0.180223
2023-01-08 06:20: Train Epoch 9: 411/634 Loss: 0.137866
2023-01-08 06:21: Train Epoch 9: 415/634 Loss: 0.160510
2023-01-08 06:21: Train Epoch 9: 419/634 Loss: 0.156673
2023-01-08 06:21: Train Epoch 9: 423/634 Loss: 0.157170
2023-01-08 06:21: Train Epoch 9: 427/634 Loss: 0.172676
2023-01-08 06:22: Train Epoch 9: 431/634 Loss: 0.198045
2023-01-08 06:22: Train Epoch 9: 435/634 Loss: 0.184274
2023-01-08 06:22: Train Epoch 9: 439/634 Loss: 0.166392
2023-01-08 06:22: Train Epoch 9: 443/634 Loss: 0.200023
2023-01-08 06:23: Train Epoch 9: 447/634 Loss: 0.195863
2023-01-08 06:23: Train Epoch 9: 451/634 Loss: 0.133471
2023-01-08 06:23: Train Epoch 9: 455/634 Loss: 0.164148
2023-01-08 06:23: Train Epoch 9: 459/634 Loss: 0.167566
2023-01-08 06:24: Train Epoch 9: 463/634 Loss: 0.155305
2023-01-08 06:24: Train Epoch 9: 467/634 Loss: 0.144024
2023-01-08 06:24: Train Epoch 9: 471/634 Loss: 0.181119
2023-01-08 06:25: Train Epoch 9: 475/634 Loss: 0.173732
2023-01-08 06:25: Train Epoch 9: 479/634 Loss: 0.165264
2023-01-08 06:25: Train Epoch 9: 483/634 Loss: 0.187862
2023-01-08 06:25: Train Epoch 9: 487/634 Loss: 0.173240
2023-01-08 06:26: Train Epoch 9: 491/634 Loss: 0.177517
2023-01-08 06:26: Train Epoch 9: 495/634 Loss: 0.147316
2023-01-08 06:26: Train Epoch 9: 499/634 Loss: 0.135222
2023-01-08 06:26: Train Epoch 9: 503/634 Loss: 0.160535
2023-01-08 06:27: Train Epoch 9: 507/634 Loss: 0.138583
2023-01-08 06:27: Train Epoch 9: 511/634 Loss: 0.161081
2023-01-08 06:27: Train Epoch 9: 515/634 Loss: 0.159585
2023-01-08 06:27: Train Epoch 9: 519/634 Loss: 0.155136
2023-01-08 06:28: Train Epoch 9: 523/634 Loss: 0.168711
2023-01-08 06:28: Train Epoch 9: 527/634 Loss: 0.193168
2023-01-08 06:28: Train Epoch 9: 531/634 Loss: 0.169052
2023-01-08 06:28: Train Epoch 9: 535/634 Loss: 0.172532
2023-01-08 06:29: Train Epoch 9: 539/634 Loss: 0.170990
2023-01-08 06:29: Train Epoch 9: 543/634 Loss: 0.143316
2023-01-08 06:29: Train Epoch 9: 547/634 Loss: 0.151793
2023-01-08 06:29: Train Epoch 9: 551/634 Loss: 0.125173
2023-01-08 06:30: Train Epoch 9: 555/634 Loss: 0.156955
2023-01-08 06:30: Train Epoch 9: 559/634 Loss: 0.169395
2023-01-08 06:30: Train Epoch 9: 563/634 Loss: 0.152102
2023-01-08 06:30: Train Epoch 9: 567/634 Loss: 0.199449
2023-01-08 06:31: Train Epoch 9: 571/634 Loss: 0.150110
2023-01-08 06:31: Train Epoch 9: 575/634 Loss: 0.156537
2023-01-08 06:31: Train Epoch 9: 579/634 Loss: 0.141894
2023-01-08 06:31: Train Epoch 9: 583/634 Loss: 0.142926
2023-01-08 06:32: Train Epoch 9: 587/634 Loss: 0.191973
2023-01-08 06:32: Train Epoch 9: 591/634 Loss: 0.190434
2023-01-08 06:32: Train Epoch 9: 595/634 Loss: 0.150618
2023-01-08 06:32: Train Epoch 9: 599/634 Loss: 0.158841
2023-01-08 06:32: Train Epoch 9: 603/634 Loss: 0.144063
2023-01-08 06:33: Train Epoch 9: 607/634 Loss: 0.187201
2023-01-08 06:33: Train Epoch 9: 611/634 Loss: 0.164762
2023-01-08 06:33: Train Epoch 9: 615/634 Loss: 0.167654
2023-01-08 06:33: Train Epoch 9: 619/634 Loss: 0.161240
2023-01-08 06:34: Train Epoch 9: 623/634 Loss: 0.154588
2023-01-08 06:34: Train Epoch 9: 627/634 Loss: 0.159199
2023-01-08 06:34: Train Epoch 9: 631/634 Loss: 0.216889
2023-01-08 06:34: Train Epoch 9: 633/634 Loss: 0.065356
2023-01-08 06:34: **********Train Epoch 9: averaged Loss: 0.163586 
2023-01-08 06:34: 
Epoch time elapsed: 2363.1585183143616

2023-01-08 06:36: 
 metrics validation: {'precision': 0.9041570438799076, 'recall': 0.6023076923076923, 'f1-score': 0.7229916897506924, 'support': 1300, 'AUC': 0.9376457100591716, 'AUCPR': 0.8816065142776898, 'TP': 783, 'FP': 83, 'TN': 2517, 'FN': 517} 

2023-01-08 06:36: **********Val Epoch 9: average Loss: 0.172620
2023-01-08 06:36: Train Epoch 10: 3/634 Loss: 0.141354
2023-01-08 06:36: Train Epoch 10: 7/634 Loss: 0.131129
2023-01-08 06:36: Train Epoch 10: 11/634 Loss: 0.187938
2023-01-08 06:37: Train Epoch 10: 15/634 Loss: 0.154982
2023-01-08 06:37: Train Epoch 10: 19/634 Loss: 0.153958
2023-01-08 06:37: Train Epoch 10: 23/634 Loss: 0.153721
2023-01-08 06:37: Train Epoch 10: 27/634 Loss: 0.183248
2023-01-08 06:38: Train Epoch 10: 31/634 Loss: 0.153954
2023-01-08 06:38: Train Epoch 10: 35/634 Loss: 0.135326
2023-01-08 06:38: Train Epoch 10: 39/634 Loss: 0.150034
2023-01-08 06:38: Train Epoch 10: 43/634 Loss: 0.181694
2023-01-08 06:39: Train Epoch 10: 47/634 Loss: 0.181463
2023-01-08 06:39: Train Epoch 10: 51/634 Loss: 0.170072
2023-01-08 06:39: Train Epoch 10: 55/634 Loss: 0.187976
2023-01-08 06:40: Train Epoch 10: 59/634 Loss: 0.176210
2023-01-08 06:40: Train Epoch 10: 63/634 Loss: 0.148969
2023-01-08 06:40: Train Epoch 10: 67/634 Loss: 0.156160
2023-01-08 06:41: Train Epoch 10: 71/634 Loss: 0.166799
2023-01-08 06:41: Train Epoch 10: 75/634 Loss: 0.170712
2023-01-08 06:41: Train Epoch 10: 79/634 Loss: 0.156610
2023-01-08 06:41: Train Epoch 10: 83/634 Loss: 0.159616
2023-01-08 06:42: Train Epoch 10: 87/634 Loss: 0.165919
2023-01-08 06:42: Train Epoch 10: 91/634 Loss: 0.181816
2023-01-08 06:42: Train Epoch 10: 95/634 Loss: 0.143030
2023-01-08 06:42: Train Epoch 10: 99/634 Loss: 0.144423
2023-01-08 06:43: Train Epoch 10: 103/634 Loss: 0.188855
2023-01-08 06:43: Train Epoch 10: 107/634 Loss: 0.156339
2023-01-08 06:43: Train Epoch 10: 111/634 Loss: 0.179800
2023-01-08 06:43: Train Epoch 10: 115/634 Loss: 0.122708
2023-01-08 06:44: Train Epoch 10: 119/634 Loss: 0.172537
2023-01-08 06:44: Train Epoch 10: 123/634 Loss: 0.159103
2023-01-08 06:44: Train Epoch 10: 127/634 Loss: 0.160685
2023-01-08 06:44: Train Epoch 10: 131/634 Loss: 0.170705
2023-01-08 06:45: Train Epoch 10: 135/634 Loss: 0.162695
2023-01-08 06:45: Train Epoch 10: 139/634 Loss: 0.196872
2023-01-08 06:45: Train Epoch 10: 143/634 Loss: 0.185291
2023-01-08 06:45: Train Epoch 10: 147/634 Loss: 0.155602
2023-01-08 06:46: Train Epoch 10: 151/634 Loss: 0.188589
2023-01-08 06:46: Train Epoch 10: 155/634 Loss: 0.152445
2023-01-08 06:46: Train Epoch 10: 159/634 Loss: 0.128439
2023-01-08 06:46: Train Epoch 10: 163/634 Loss: 0.163289
2023-01-08 06:46: Train Epoch 10: 167/634 Loss: 0.161903
2023-01-08 06:47: Train Epoch 10: 171/634 Loss: 0.153722
2023-01-08 06:47: Train Epoch 10: 175/634 Loss: 0.173441
2023-01-08 06:47: Train Epoch 10: 179/634 Loss: 0.187100
2023-01-08 06:47: Train Epoch 10: 183/634 Loss: 0.156165
2023-01-08 06:48: Train Epoch 10: 187/634 Loss: 0.146064
2023-01-08 06:48: Train Epoch 10: 191/634 Loss: 0.155319
2023-01-08 06:48: Train Epoch 10: 195/634 Loss: 0.153930
2023-01-08 06:48: Train Epoch 10: 199/634 Loss: 0.158805
2023-01-08 06:49: Train Epoch 10: 203/634 Loss: 0.159906
2023-01-08 06:49: Train Epoch 10: 207/634 Loss: 0.133117
2023-01-08 06:49: Train Epoch 10: 211/634 Loss: 0.160637
2023-01-08 06:49: Train Epoch 10: 215/634 Loss: 0.163682
2023-01-08 06:50: Train Epoch 10: 219/634 Loss: 0.176693
2023-01-08 06:50: Train Epoch 10: 223/634 Loss: 0.166058
2023-01-08 06:50: Train Epoch 10: 227/634 Loss: 0.162486
2023-01-08 06:50: Train Epoch 10: 231/634 Loss: 0.144541
2023-01-08 06:51: Train Epoch 10: 235/634 Loss: 0.150033
2023-01-08 06:51: Train Epoch 10: 239/634 Loss: 0.195217
2023-01-08 06:51: Train Epoch 10: 243/634 Loss: 0.149952
2023-01-08 06:51: Train Epoch 10: 247/634 Loss: 0.173615
2023-01-08 06:52: Train Epoch 10: 251/634 Loss: 0.179756
2023-01-08 06:52: Train Epoch 10: 255/634 Loss: 0.197096
2023-01-08 06:52: Train Epoch 10: 259/634 Loss: 0.171261
2023-01-08 06:52: Train Epoch 10: 263/634 Loss: 0.187126
2023-01-08 06:53: Train Epoch 10: 267/634 Loss: 0.164168
2023-01-08 06:53: Train Epoch 10: 271/634 Loss: 0.158376
2023-01-08 06:53: Train Epoch 10: 275/634 Loss: 0.174725
2023-01-08 06:53: Train Epoch 10: 279/634 Loss: 0.216978
2023-01-08 06:54: Train Epoch 10: 283/634 Loss: 0.182481
2023-01-08 06:54: Train Epoch 10: 287/634 Loss: 0.171709
2023-01-08 06:54: Train Epoch 10: 291/634 Loss: 0.212191
2023-01-08 06:54: Train Epoch 10: 295/634 Loss: 0.178239
2023-01-08 06:54: Train Epoch 10: 299/634 Loss: 0.153022
2023-01-08 06:55: Train Epoch 10: 303/634 Loss: 0.156866
2023-01-08 06:55: Train Epoch 10: 307/634 Loss: 0.224717
2023-01-08 06:55: Train Epoch 10: 311/634 Loss: 0.165734
2023-01-08 06:55: Train Epoch 10: 315/634 Loss: 0.199577
2023-01-08 06:56: Train Epoch 10: 319/634 Loss: 0.184210
2023-01-08 06:56: Train Epoch 10: 323/634 Loss: 0.165274
2023-01-08 06:56: Train Epoch 10: 327/634 Loss: 0.180877
2023-01-08 06:56: Train Epoch 10: 331/634 Loss: 0.174300
2023-01-08 06:57: Train Epoch 10: 335/634 Loss: 0.161689
2023-01-08 06:57: Train Epoch 10: 339/634 Loss: 0.178382
2023-01-08 06:57: Train Epoch 10: 343/634 Loss: 0.167563
2023-01-08 06:57: Train Epoch 10: 347/634 Loss: 0.150821
2023-01-08 06:58: Train Epoch 10: 351/634 Loss: 0.169418
2023-01-08 06:58: Train Epoch 10: 355/634 Loss: 0.162490
2023-01-08 06:58: Train Epoch 10: 359/634 Loss: 0.157609
2023-01-08 06:58: Train Epoch 10: 363/634 Loss: 0.165736
2023-01-08 06:58: Train Epoch 10: 367/634 Loss: 0.156425
2023-01-08 06:59: Train Epoch 10: 371/634 Loss: 0.154026
2023-01-08 06:59: Train Epoch 10: 375/634 Loss: 0.153978
2023-01-08 06:59: Train Epoch 10: 379/634 Loss: 0.167767
2023-01-08 06:59: Train Epoch 10: 383/634 Loss: 0.152695
2023-01-08 07:00: Train Epoch 10: 387/634 Loss: 0.172713
2023-01-08 07:00: Train Epoch 10: 391/634 Loss: 0.144822
2023-01-08 07:00: Train Epoch 10: 395/634 Loss: 0.195446
2023-01-08 07:00: Train Epoch 10: 399/634 Loss: 0.176357
2023-01-08 07:01: Train Epoch 10: 403/634 Loss: 0.160648
2023-01-08 07:01: Train Epoch 10: 407/634 Loss: 0.187206
2023-01-08 07:01: Train Epoch 10: 411/634 Loss: 0.169205
2023-01-08 07:01: Train Epoch 10: 415/634 Loss: 0.150816
2023-01-08 07:02: Train Epoch 10: 419/634 Loss: 0.180294
2023-01-08 07:02: Train Epoch 10: 423/634 Loss: 0.172454
2023-01-08 07:02: Train Epoch 10: 427/634 Loss: 0.159815
2023-01-08 07:02: Train Epoch 10: 431/634 Loss: 0.140874
2023-01-08 07:03: Train Epoch 10: 435/634 Loss: 0.162722
2023-01-08 07:03: Train Epoch 10: 439/634 Loss: 0.174347
2023-01-08 07:03: Train Epoch 10: 443/634 Loss: 0.147313
2023-01-08 07:03: Train Epoch 10: 447/634 Loss: 0.168878
2023-01-08 07:04: Train Epoch 10: 451/634 Loss: 0.169096
2023-01-08 07:04: Train Epoch 10: 455/634 Loss: 0.155761
2023-01-08 07:04: Train Epoch 10: 459/634 Loss: 0.171350
2023-01-08 07:04: Train Epoch 10: 463/634 Loss: 0.172652
2023-01-08 07:05: Train Epoch 10: 467/634 Loss: 0.164354
2023-01-08 07:05: Train Epoch 10: 471/634 Loss: 0.208251
2023-01-08 07:05: Train Epoch 10: 475/634 Loss: 0.154356
2023-01-08 07:05: Train Epoch 10: 479/634 Loss: 0.167953
2023-01-08 07:06: Train Epoch 10: 483/634 Loss: 0.179495
2023-01-08 07:06: Train Epoch 10: 487/634 Loss: 0.146863
2023-01-08 07:06: Train Epoch 10: 491/634 Loss: 0.169983
2023-01-08 07:06: Train Epoch 10: 495/634 Loss: 0.187874
2023-01-08 07:07: Train Epoch 10: 499/634 Loss: 0.159218
2023-01-08 07:07: Train Epoch 10: 503/634 Loss: 0.151303
2023-01-08 07:07: Train Epoch 10: 507/634 Loss: 0.148059
2023-01-08 07:07: Train Epoch 10: 511/634 Loss: 0.187433
2023-01-08 07:07: Train Epoch 10: 515/634 Loss: 0.178110
2023-01-08 07:08: Train Epoch 10: 519/634 Loss: 0.163107
2023-01-08 07:08: Train Epoch 10: 523/634 Loss: 0.189639
2023-01-08 07:08: Train Epoch 10: 527/634 Loss: 0.163552
2023-01-08 07:08: Train Epoch 10: 531/634 Loss: 0.147436
2023-01-08 07:09: Train Epoch 10: 535/634 Loss: 0.156705
2023-01-08 07:09: Train Epoch 10: 539/634 Loss: 0.152458
2023-01-08 07:09: Train Epoch 10: 543/634 Loss: 0.151196
2023-01-08 07:09: Train Epoch 10: 547/634 Loss: 0.167859
2023-01-08 07:10: Train Epoch 10: 551/634 Loss: 0.176685
2023-01-08 07:10: Train Epoch 10: 555/634 Loss: 0.158810
2023-01-08 07:10: Train Epoch 10: 559/634 Loss: 0.154898
2023-01-08 07:10: Train Epoch 10: 563/634 Loss: 0.179364
2023-01-08 07:11: Train Epoch 10: 567/634 Loss: 0.174332
2023-01-08 07:11: Train Epoch 10: 571/634 Loss: 0.161941
2023-01-08 07:11: Train Epoch 10: 575/634 Loss: 0.150419
2023-01-08 07:11: Train Epoch 10: 579/634 Loss: 0.146093
2023-01-08 07:12: Train Epoch 10: 583/634 Loss: 0.158784
2023-01-08 07:12: Train Epoch 10: 587/634 Loss: 0.187264
2023-01-08 07:12: Train Epoch 10: 591/634 Loss: 0.165751
2023-01-08 07:12: Train Epoch 10: 595/634 Loss: 0.182918
2023-01-08 07:12: Train Epoch 10: 599/634 Loss: 0.166989
2023-01-08 07:13: Train Epoch 10: 603/634 Loss: 0.165565
2023-01-08 07:13: Train Epoch 10: 607/634 Loss: 0.176182
2023-01-08 07:13: Train Epoch 10: 611/634 Loss: 0.182834
2023-01-08 07:13: Train Epoch 10: 615/634 Loss: 0.176819
2023-01-08 07:14: Train Epoch 10: 619/634 Loss: 0.142305
2023-01-08 07:14: Train Epoch 10: 623/634 Loss: 0.175621
2023-01-08 07:14: Train Epoch 10: 627/634 Loss: 0.187898
2023-01-08 07:14: Train Epoch 10: 631/634 Loss: 0.167993
2023-01-08 07:15: Train Epoch 10: 633/634 Loss: 0.079375
2023-01-08 07:15: **********Train Epoch 10: averaged Loss: 0.166085 
2023-01-08 07:15: 
Epoch time elapsed: 2336.7088482379913

2023-01-08 07:16: 
 metrics validation: {'precision': 0.8731343283582089, 'recall': 0.63, 'f1-score': 0.7319034852546917, 'support': 1300, 'AUC': 0.9193766272189349, 'AUCPR': 0.8532853198009984, 'TP': 819, 'FP': 119, 'TN': 2481, 'FN': 481} 

2023-01-08 07:16: **********Val Epoch 10: average Loss: 0.182077
2023-01-08 07:16: Train Epoch 11: 3/634 Loss: 0.158302
2023-01-08 07:16: Train Epoch 11: 7/634 Loss: 0.130080
2023-01-08 07:16: Train Epoch 11: 11/634 Loss: 0.213436
2023-01-08 07:17: Train Epoch 11: 15/634 Loss: 0.150689
2023-01-08 07:17: Train Epoch 11: 19/634 Loss: 0.177204
2023-01-08 07:17: Train Epoch 11: 23/634 Loss: 0.172543
2023-01-08 07:17: Train Epoch 11: 27/634 Loss: 0.178127
2023-01-08 07:18: Train Epoch 11: 31/634 Loss: 0.156170
2023-01-08 07:18: Train Epoch 11: 35/634 Loss: 0.140634
2023-01-08 07:18: Train Epoch 11: 39/634 Loss: 0.158619
2023-01-08 07:18: Train Epoch 11: 43/634 Loss: 0.164678
2023-01-08 07:19: Train Epoch 11: 47/634 Loss: 0.185190
2023-01-08 07:19: Train Epoch 11: 51/634 Loss: 0.163962
2023-01-08 07:19: Train Epoch 11: 55/634 Loss: 0.191317
2023-01-08 07:19: Train Epoch 11: 59/634 Loss: 0.159430
2023-01-08 07:20: Train Epoch 11: 63/634 Loss: 0.171885
2023-01-08 07:20: Train Epoch 11: 67/634 Loss: 0.193101
2023-01-08 07:20: Train Epoch 11: 71/634 Loss: 0.163800
2023-01-08 07:20: Train Epoch 11: 75/634 Loss: 0.181235
2023-01-08 07:21: Train Epoch 11: 79/634 Loss: 0.148987
2023-01-08 07:21: Train Epoch 11: 83/634 Loss: 0.169449
2023-01-08 07:21: Train Epoch 11: 87/634 Loss: 0.176275
2023-01-08 07:21: Train Epoch 11: 91/634 Loss: 0.160967
2023-01-08 07:22: Train Epoch 11: 95/634 Loss: 0.140295
2023-01-08 07:22: Train Epoch 11: 99/634 Loss: 0.177195
2023-01-08 07:22: Train Epoch 11: 103/634 Loss: 0.185762
2023-01-08 07:22: Train Epoch 11: 107/634 Loss: 0.161720
2023-01-08 07:23: Train Epoch 11: 111/634 Loss: 0.156810
2023-01-08 07:23: Train Epoch 11: 115/634 Loss: 0.164122
2023-01-08 07:23: Train Epoch 11: 119/634 Loss: 0.179323
2023-01-08 07:23: Train Epoch 11: 123/634 Loss: 0.159132
2023-01-08 07:23: Train Epoch 11: 127/634 Loss: 0.166081
2023-01-08 07:24: Train Epoch 11: 131/634 Loss: 0.161612
2023-01-08 07:24: Train Epoch 11: 135/634 Loss: 0.165860
2023-01-08 07:24: Train Epoch 11: 139/634 Loss: 0.163430
2023-01-08 07:24: Train Epoch 11: 143/634 Loss: 0.150006
2023-01-08 07:25: Train Epoch 11: 147/634 Loss: 0.167840
2023-01-08 07:25: Train Epoch 11: 151/634 Loss: 0.191311
2023-01-08 07:25: Train Epoch 11: 155/634 Loss: 0.169910
2023-01-08 07:25: Train Epoch 11: 159/634 Loss: 0.147852
2023-01-08 07:26: Train Epoch 11: 163/634 Loss: 0.228141
2023-01-08 07:26: Train Epoch 11: 167/634 Loss: 0.162098
2023-01-08 07:26: Train Epoch 11: 171/634 Loss: 0.143808
2023-01-08 07:26: Train Epoch 11: 175/634 Loss: 0.132343
2023-01-08 07:27: Train Epoch 11: 179/634 Loss: 0.168934
2023-01-08 07:27: Train Epoch 11: 183/634 Loss: 0.188674
2023-01-08 07:27: Train Epoch 11: 187/634 Loss: 0.139045
2023-01-08 07:27: Train Epoch 11: 191/634 Loss: 0.160524
2023-01-08 07:28: Train Epoch 11: 195/634 Loss: 0.156410
2023-01-08 07:28: Train Epoch 11: 199/634 Loss: 0.208039
2023-01-08 07:28: Train Epoch 11: 203/634 Loss: 0.197323
2023-01-08 07:28: Train Epoch 11: 207/634 Loss: 0.152033
2023-01-08 07:29: Train Epoch 11: 211/634 Loss: 0.158463
2023-01-08 07:29: Train Epoch 11: 215/634 Loss: 0.167189
2023-01-08 07:29: Train Epoch 11: 219/634 Loss: 0.175893
2023-01-08 07:29: Train Epoch 11: 223/634 Loss: 0.141230
2023-01-08 07:30: Train Epoch 11: 227/634 Loss: 0.166258
2023-01-08 07:30: Train Epoch 11: 231/634 Loss: 0.198579
2023-01-08 07:30: Train Epoch 11: 235/634 Loss: 0.155095
2023-01-08 07:30: Train Epoch 11: 239/634 Loss: 0.174539
2023-01-08 07:31: Train Epoch 11: 243/634 Loss: 0.170688
2023-01-08 07:31: Train Epoch 11: 247/634 Loss: 0.163000
2023-01-08 07:31: Train Epoch 11: 251/634 Loss: 0.188924
2023-01-08 07:31: Train Epoch 11: 255/634 Loss: 0.164640
2023-01-08 07:32: Train Epoch 11: 259/634 Loss: 0.206500
2023-01-08 07:32: Train Epoch 11: 263/634 Loss: 0.138423
2023-01-08 07:32: Train Epoch 11: 267/634 Loss: 0.184743
2023-01-08 07:32: Train Epoch 11: 271/634 Loss: 0.166542
2023-01-08 07:32: Train Epoch 11: 275/634 Loss: 0.146300
2023-01-08 07:33: Train Epoch 11: 279/634 Loss: 0.160720
2023-01-08 07:33: Train Epoch 11: 283/634 Loss: 0.136957
2023-01-08 07:33: Train Epoch 11: 287/634 Loss: 0.167665
2023-01-08 07:33: Train Epoch 11: 291/634 Loss: 0.167643
2023-01-08 07:34: Train Epoch 11: 295/634 Loss: 0.152741
2023-01-08 07:34: Train Epoch 11: 299/634 Loss: 0.151211
2023-01-08 07:34: Train Epoch 11: 303/634 Loss: 0.204991
2023-01-08 07:34: Train Epoch 11: 307/634 Loss: 0.151407
2023-01-08 07:35: Train Epoch 11: 311/634 Loss: 0.167984
2023-01-08 07:35: Train Epoch 11: 315/634 Loss: 0.194242
2023-01-08 07:35: Train Epoch 11: 319/634 Loss: 0.160110
2023-01-08 07:35: Train Epoch 11: 323/634 Loss: 0.159821
2023-01-08 07:36: Train Epoch 11: 327/634 Loss: 0.151422
2023-01-08 07:36: Train Epoch 11: 331/634 Loss: 0.167598
2023-01-08 07:36: Train Epoch 11: 335/634 Loss: 0.163292
2023-01-08 07:36: Train Epoch 11: 339/634 Loss: 0.148066
2023-01-08 07:37: Train Epoch 11: 343/634 Loss: 0.204524
2023-01-08 07:37: Train Epoch 11: 347/634 Loss: 0.189641
2023-01-08 07:37: Train Epoch 11: 351/634 Loss: 0.149268
2023-01-08 07:37: Train Epoch 11: 355/634 Loss: 0.175153
2023-01-08 07:38: Train Epoch 11: 359/634 Loss: 0.181987
2023-01-08 07:38: Train Epoch 11: 363/634 Loss: 0.203377
2023-01-08 07:38: Train Epoch 11: 367/634 Loss: 0.147645
2023-01-08 07:38: Train Epoch 11: 371/634 Loss: 0.198267
2023-01-08 07:39: Train Epoch 11: 375/634 Loss: 0.187456
2023-01-08 07:39: Train Epoch 11: 379/634 Loss: 0.157224
2023-01-08 07:39: Train Epoch 11: 383/634 Loss: 0.156501
2023-01-08 07:39: Train Epoch 11: 387/634 Loss: 0.169115
2023-01-08 07:39: Train Epoch 11: 391/634 Loss: 0.178875
2023-01-08 07:40: Train Epoch 11: 395/634 Loss: 0.159141
2023-01-08 07:40: Train Epoch 11: 399/634 Loss: 0.173098
2023-01-08 07:40: Train Epoch 11: 403/634 Loss: 0.173376
2023-01-08 07:41: Train Epoch 11: 407/634 Loss: 0.194411
2023-01-08 07:41: Train Epoch 11: 411/634 Loss: 0.170632
2023-01-08 07:41: Train Epoch 11: 415/634 Loss: 0.165916
2023-01-08 07:41: Train Epoch 11: 419/634 Loss: 0.136459
2023-01-08 07:41: Train Epoch 11: 423/634 Loss: 0.173130
2023-01-08 07:42: Train Epoch 11: 427/634 Loss: 0.175472
2023-01-08 07:42: Train Epoch 11: 431/634 Loss: 0.169846
2023-01-08 07:42: Train Epoch 11: 435/634 Loss: 0.182628
2023-01-08 07:42: Train Epoch 11: 439/634 Loss: 0.153438
2023-01-08 07:43: Train Epoch 11: 443/634 Loss: 0.163538
2023-01-08 07:43: Train Epoch 11: 447/634 Loss: 0.141097
2023-01-08 07:43: Train Epoch 11: 451/634 Loss: 0.160425
2023-01-08 07:43: Train Epoch 11: 455/634 Loss: 0.166907
2023-01-08 07:44: Train Epoch 11: 459/634 Loss: 0.141920
2023-01-08 07:44: Train Epoch 11: 463/634 Loss: 0.141190
2023-01-08 07:44: Train Epoch 11: 467/634 Loss: 0.171752
2023-01-08 07:44: Train Epoch 11: 471/634 Loss: 0.153577
2023-01-08 07:45: Train Epoch 11: 475/634 Loss: 0.168013
2023-01-08 07:45: Train Epoch 11: 479/634 Loss: 0.189904
2023-01-08 07:45: Train Epoch 11: 483/634 Loss: 0.190173
2023-01-08 07:45: Train Epoch 11: 487/634 Loss: 0.168584
2023-01-08 07:46: Train Epoch 11: 491/634 Loss: 0.190843
2023-01-08 07:46: Train Epoch 11: 495/634 Loss: 0.146738
2023-01-08 07:46: Train Epoch 11: 499/634 Loss: 0.168947
2023-01-08 07:46: Train Epoch 11: 503/634 Loss: 0.157144
2023-01-08 07:47: Train Epoch 11: 507/634 Loss: 0.183029
2023-01-08 07:47: Train Epoch 11: 511/634 Loss: 0.148267
2023-01-08 07:47: Train Epoch 11: 515/634 Loss: 0.166641
2023-01-08 07:47: Train Epoch 11: 519/634 Loss: 0.152220
2023-01-08 07:48: Train Epoch 11: 523/634 Loss: 0.145598
2023-01-08 07:48: Train Epoch 11: 527/634 Loss: 0.182109
2023-01-08 07:48: Train Epoch 11: 531/634 Loss: 0.186257
2023-01-08 07:48: Train Epoch 11: 535/634 Loss: 0.155203
2023-01-08 07:49: Train Epoch 11: 539/634 Loss: 0.136559
2023-01-08 07:49: Train Epoch 11: 543/634 Loss: 0.200839
2023-01-08 07:49: Train Epoch 11: 547/634 Loss: 0.147659
2023-01-08 07:49: Train Epoch 11: 551/634 Loss: 0.139287
2023-01-08 07:49: Train Epoch 11: 555/634 Loss: 0.163967
2023-01-08 07:50: Train Epoch 11: 559/634 Loss: 0.168695
2023-01-08 07:50: Train Epoch 11: 563/634 Loss: 0.182236
2023-01-08 07:50: Train Epoch 11: 567/634 Loss: 0.205039
2023-01-08 07:50: Train Epoch 11: 571/634 Loss: 0.149031
2023-01-08 07:51: Train Epoch 11: 575/634 Loss: 0.148771
2023-01-08 07:51: Train Epoch 11: 579/634 Loss: 0.167633
2023-01-08 07:51: Train Epoch 11: 583/634 Loss: 0.183959
2023-01-08 07:51: Train Epoch 11: 587/634 Loss: 0.137895
2023-01-08 07:52: Train Epoch 11: 591/634 Loss: 0.123381
2023-01-08 07:52: Train Epoch 11: 595/634 Loss: 0.161564
2023-01-08 07:52: Train Epoch 11: 599/634 Loss: 0.163782
2023-01-08 07:52: Train Epoch 11: 603/634 Loss: 0.169872
2023-01-08 07:53: Train Epoch 11: 607/634 Loss: 0.174283
2023-01-08 07:53: Train Epoch 11: 611/634 Loss: 0.156370
2023-01-08 07:53: Train Epoch 11: 615/634 Loss: 0.193907
2023-01-08 07:53: Train Epoch 11: 619/634 Loss: 0.150039
2023-01-08 07:54: Train Epoch 11: 623/634 Loss: 0.157759
2023-01-08 07:54: Train Epoch 11: 627/634 Loss: 0.158274
2023-01-08 07:54: Train Epoch 11: 631/634 Loss: 0.151125
2023-01-08 07:54: Train Epoch 11: 633/634 Loss: 0.072487
2023-01-08 07:54: **********Train Epoch 11: averaged Loss: 0.166136 
2023-01-08 07:54: 
Epoch time elapsed: 2309.1906735897064

2023-01-08 07:55: 
 metrics validation: {'precision': 0.8772874058127018, 'recall': 0.6269230769230769, 'f1-score': 0.731269627635711, 'support': 1300, 'AUC': 0.9347825443786981, 'AUCPR': 0.8822626204293202, 'TP': 815, 'FP': 114, 'TN': 2486, 'FN': 485} 

2023-01-08 07:55: **********Val Epoch 11: average Loss: 0.159243
2023-01-08 07:56: Train Epoch 12: 3/634 Loss: 0.144454
2023-01-08 07:56: Train Epoch 12: 7/634 Loss: 0.140989
2023-01-08 07:56: Train Epoch 12: 11/634 Loss: 0.162686
2023-01-08 07:56: Train Epoch 12: 15/634 Loss: 0.165234
2023-01-08 07:57: Train Epoch 12: 19/634 Loss: 0.172235
2023-01-08 07:57: Train Epoch 12: 23/634 Loss: 0.185326
2023-01-08 07:57: Train Epoch 12: 27/634 Loss: 0.185448
2023-01-08 07:57: Train Epoch 12: 31/634 Loss: 0.167461
2023-01-08 07:58: Train Epoch 12: 35/634 Loss: 0.122471
2023-01-08 07:58: Train Epoch 12: 39/634 Loss: 0.146760
2023-01-08 07:58: Train Epoch 12: 43/634 Loss: 0.153945
2023-01-08 07:58: Train Epoch 12: 47/634 Loss: 0.198688
2023-01-08 07:58: Train Epoch 12: 51/634 Loss: 0.181398
2023-01-08 07:59: Train Epoch 12: 55/634 Loss: 0.187071
2023-01-08 07:59: Train Epoch 12: 59/634 Loss: 0.159336
2023-01-08 07:59: Train Epoch 12: 63/634 Loss: 0.161659
2023-01-08 07:59: Train Epoch 12: 67/634 Loss: 0.178283
2023-01-08 08:00: Train Epoch 12: 71/634 Loss: 0.160334
2023-01-08 08:00: Train Epoch 12: 75/634 Loss: 0.145418
2023-01-08 08:00: Train Epoch 12: 79/634 Loss: 0.157386
2023-01-08 08:00: Train Epoch 12: 83/634 Loss: 0.163531
2023-01-08 08:01: Train Epoch 12: 87/634 Loss: 0.167091
2023-01-08 08:01: Train Epoch 12: 91/634 Loss: 0.162697
2023-01-08 08:01: Train Epoch 12: 95/634 Loss: 0.137636
2023-01-08 08:01: Train Epoch 12: 99/634 Loss: 0.162857
2023-01-08 08:02: Train Epoch 12: 103/634 Loss: 0.174260
2023-01-08 08:02: Train Epoch 12: 107/634 Loss: 0.165271
2023-01-08 08:02: Train Epoch 12: 111/634 Loss: 0.193182
2023-01-08 08:02: Train Epoch 12: 115/634 Loss: 0.201144
2023-01-08 08:03: Train Epoch 12: 119/634 Loss: 0.155492
2023-01-08 08:03: Train Epoch 12: 123/634 Loss: 0.170938
2023-01-08 08:03: Train Epoch 12: 127/634 Loss: 0.136884
2023-01-08 08:03: Train Epoch 12: 131/634 Loss: 0.171064
2023-01-08 08:04: Train Epoch 12: 135/634 Loss: 0.160652
2023-01-08 08:04: Train Epoch 12: 139/634 Loss: 0.151089
2023-01-08 08:04: Train Epoch 12: 143/634 Loss: 0.169904
2023-01-08 08:04: Train Epoch 12: 147/634 Loss: 0.167634
2023-01-08 08:04: Train Epoch 12: 151/634 Loss: 0.171759
2023-01-08 08:05: Train Epoch 12: 155/634 Loss: 0.171724
2023-01-08 08:05: Train Epoch 12: 159/634 Loss: 0.169705
2023-01-08 08:05: Train Epoch 12: 163/634 Loss: 0.172778
2023-01-08 08:05: Train Epoch 12: 167/634 Loss: 0.150957
2023-01-08 08:06: Train Epoch 12: 171/634 Loss: 0.160207
2023-01-08 08:06: Train Epoch 12: 175/634 Loss: 0.168398
2023-01-08 08:06: Train Epoch 12: 179/634 Loss: 0.177966
2023-01-08 08:06: Train Epoch 12: 183/634 Loss: 0.173298
2023-01-08 08:07: Train Epoch 12: 187/634 Loss: 0.127526
2023-01-08 08:07: Train Epoch 12: 191/634 Loss: 0.181907
2023-01-08 08:07: Train Epoch 12: 195/634 Loss: 0.156436
2023-01-08 08:07: Train Epoch 12: 199/634 Loss: 0.180452
2023-01-08 08:08: Train Epoch 12: 203/634 Loss: 0.157411
2023-01-08 08:08: Train Epoch 12: 207/634 Loss: 0.169722
2023-01-08 08:08: Train Epoch 12: 211/634 Loss: 0.152712
2023-01-08 08:08: Train Epoch 12: 215/634 Loss: 0.187960
2023-01-08 08:09: Train Epoch 12: 219/634 Loss: 0.156258
2023-01-08 08:09: Train Epoch 12: 223/634 Loss: 0.168141
2023-01-08 08:09: Train Epoch 12: 227/634 Loss: 0.177699
2023-01-08 08:09: Train Epoch 12: 231/634 Loss: 0.139775
2023-01-08 08:10: Train Epoch 12: 235/634 Loss: 0.192720
2023-01-08 08:10: Train Epoch 12: 239/634 Loss: 0.184267
2023-01-08 08:10: Train Epoch 12: 243/634 Loss: 0.185811
2023-01-08 08:10: Train Epoch 12: 247/634 Loss: 0.152248
2023-01-08 08:11: Train Epoch 12: 251/634 Loss: 0.175954
2023-01-08 08:11: Train Epoch 12: 255/634 Loss: 0.151545
2023-01-08 08:11: Train Epoch 12: 259/634 Loss: 0.157890
2023-01-08 08:11: Train Epoch 12: 263/634 Loss: 0.168019
2023-01-08 08:12: Train Epoch 12: 267/634 Loss: 0.175972
2023-01-08 08:12: Train Epoch 12: 271/634 Loss: 0.199332
2023-01-08 08:12: Train Epoch 12: 275/634 Loss: 0.157121
2023-01-08 08:12: Train Epoch 12: 279/634 Loss: 0.168110
2023-01-08 08:12: Train Epoch 12: 283/634 Loss: 0.167625
2023-01-08 08:13: Train Epoch 12: 287/634 Loss: 0.170557
2023-01-08 08:13: Train Epoch 12: 291/634 Loss: 0.148750
2023-01-08 08:13: Train Epoch 12: 295/634 Loss: 0.174241
2023-01-08 08:13: Train Epoch 12: 299/634 Loss: 0.179873
2023-01-08 08:14: Train Epoch 12: 303/634 Loss: 0.152366
2023-01-08 08:14: Train Epoch 12: 307/634 Loss: 0.184826
2023-01-08 08:14: Train Epoch 12: 311/634 Loss: 0.167354
2023-01-08 08:14: Train Epoch 12: 315/634 Loss: 0.156215
2023-01-08 08:15: Train Epoch 12: 319/634 Loss: 0.172602
2023-01-08 08:15: Train Epoch 12: 323/634 Loss: 0.129325
2023-01-08 08:15: Train Epoch 12: 327/634 Loss: 0.174344
2023-01-08 08:15: Train Epoch 12: 331/634 Loss: 0.153527
2023-01-08 08:16: Train Epoch 12: 335/634 Loss: 0.142005
2023-01-08 08:16: Train Epoch 12: 339/634 Loss: 0.143305
2023-01-08 08:16: Train Epoch 12: 343/634 Loss: 0.152664
2023-01-08 08:16: Train Epoch 12: 347/634 Loss: 0.166279
2023-01-08 08:17: Train Epoch 12: 351/634 Loss: 0.160876
2023-01-08 08:17: Train Epoch 12: 355/634 Loss: 0.158019
2023-01-08 08:17: Train Epoch 12: 359/634 Loss: 0.146219
2023-01-08 08:17: Train Epoch 12: 363/634 Loss: 0.177864
2023-01-08 08:18: Train Epoch 12: 367/634 Loss: 0.160667
2023-01-08 08:18: Train Epoch 12: 371/634 Loss: 0.187650
2023-01-08 08:18: Train Epoch 12: 375/634 Loss: 0.162668
2023-01-08 08:18: Train Epoch 12: 379/634 Loss: 0.171474
2023-01-08 08:18: Train Epoch 12: 383/634 Loss: 0.161424
2023-01-08 08:19: Train Epoch 12: 387/634 Loss: 0.161012
2023-01-08 08:19: Train Epoch 12: 391/634 Loss: 0.183008
2023-01-08 08:19: Train Epoch 12: 395/634 Loss: 0.153904
2023-01-08 08:19: Train Epoch 12: 399/634 Loss: 0.162656
2023-01-08 08:20: Train Epoch 12: 403/634 Loss: 0.174269
2023-01-08 08:20: Train Epoch 12: 407/634 Loss: 0.165088
2023-01-08 08:20: Train Epoch 12: 411/634 Loss: 0.152177
2023-01-08 08:20: Train Epoch 12: 415/634 Loss: 0.158363
2023-01-08 08:21: Train Epoch 12: 419/634 Loss: 0.183737
2023-01-08 08:21: Train Epoch 12: 423/634 Loss: 0.149053
2023-01-08 08:21: Train Epoch 12: 427/634 Loss: 0.146165
2023-01-08 08:21: Train Epoch 12: 431/634 Loss: 0.181608
2023-01-08 08:22: Train Epoch 12: 435/634 Loss: 0.154281
2023-01-08 08:22: Train Epoch 12: 439/634 Loss: 0.173707
2023-01-08 08:22: Train Epoch 12: 443/634 Loss: 0.142911
2023-01-08 08:22: Train Epoch 12: 447/634 Loss: 0.149545
2023-01-08 08:23: Train Epoch 12: 451/634 Loss: 0.133454
2023-01-08 08:23: Train Epoch 12: 455/634 Loss: 0.154631
2023-01-08 08:23: Train Epoch 12: 459/634 Loss: 0.188770
2023-01-08 08:23: Train Epoch 12: 463/634 Loss: 0.170855
2023-01-08 08:24: Train Epoch 12: 467/634 Loss: 0.165584
2023-01-08 08:24: Train Epoch 12: 471/634 Loss: 0.171166
2023-01-08 08:24: Train Epoch 12: 475/634 Loss: 0.160304
2023-01-08 08:24: Train Epoch 12: 479/634 Loss: 0.140999
2023-01-08 08:25: Train Epoch 12: 483/634 Loss: 0.140609
2023-01-08 08:25: Train Epoch 12: 487/634 Loss: 0.128533
2023-01-08 08:25: Train Epoch 12: 491/634 Loss: 0.187176
2023-01-08 08:25: Train Epoch 12: 495/634 Loss: 0.200401
2023-01-08 08:25: Train Epoch 12: 499/634 Loss: 0.174744
2023-01-08 08:26: Train Epoch 12: 503/634 Loss: 0.178723
2023-01-08 08:26: Train Epoch 12: 507/634 Loss: 0.165856
2023-01-08 08:26: Train Epoch 12: 511/634 Loss: 0.182224
2023-01-08 08:26: Train Epoch 12: 515/634 Loss: 0.163684
2023-01-08 08:27: Train Epoch 12: 519/634 Loss: 0.155522
2023-01-08 08:27: Train Epoch 12: 523/634 Loss: 0.163406
2023-01-08 08:27: Train Epoch 12: 527/634 Loss: 0.150825
2023-01-08 08:27: Train Epoch 12: 531/634 Loss: 0.168588
2023-01-08 08:28: Train Epoch 12: 535/634 Loss: 0.163813
2023-01-08 08:28: Train Epoch 12: 539/634 Loss: 0.186991
2023-01-08 08:28: Train Epoch 12: 543/634 Loss: 0.147733
2023-01-08 08:28: Train Epoch 12: 547/634 Loss: 0.184239
2023-01-08 08:29: Train Epoch 12: 551/634 Loss: 0.168647
2023-01-08 08:29: Train Epoch 12: 555/634 Loss: 0.166877
2023-01-08 08:29: Train Epoch 12: 559/634 Loss: 0.171467
2023-01-08 08:29: Train Epoch 12: 563/634 Loss: 0.176986
2023-01-08 08:30: Train Epoch 12: 567/634 Loss: 0.154319
2023-01-08 08:30: Train Epoch 12: 571/634 Loss: 0.170981
2023-01-08 08:30: Train Epoch 12: 575/634 Loss: 0.177507
2023-01-08 08:30: Train Epoch 12: 579/634 Loss: 0.171937
2023-01-08 08:31: Train Epoch 12: 583/634 Loss: 0.158018
2023-01-08 08:31: Train Epoch 12: 587/634 Loss: 0.163061
2023-01-08 08:31: Train Epoch 12: 591/634 Loss: 0.181367
2023-01-08 08:31: Train Epoch 12: 595/634 Loss: 0.178935
2023-01-08 08:32: Train Epoch 12: 599/634 Loss: 0.185417
2023-01-08 08:32: Train Epoch 12: 603/634 Loss: 0.133354
2023-01-08 08:32: Train Epoch 12: 607/634 Loss: 0.167818
2023-01-08 08:32: Train Epoch 12: 611/634 Loss: 0.205022
2023-01-08 08:33: Train Epoch 12: 615/634 Loss: 0.149134
2023-01-08 08:33: Train Epoch 12: 619/634 Loss: 0.163540
2023-01-08 08:33: Train Epoch 12: 623/634 Loss: 0.163480
2023-01-08 08:33: Train Epoch 12: 627/634 Loss: 0.160625
2023-01-08 08:34: Train Epoch 12: 631/634 Loss: 0.184936
2023-01-08 08:34: Train Epoch 12: 633/634 Loss: 0.076310
2023-01-08 08:34: **********Train Epoch 12: averaged Loss: 0.164795 
2023-01-08 08:34: 
Epoch time elapsed: 2300.0005939006805

2023-01-08 08:35: 
 metrics validation: {'precision': 0.8074817518248175, 'recall': 0.6807692307692308, 'f1-score': 0.7387312186978299, 'support': 1300, 'AUC': 0.9081289940828403, 'AUCPR': 0.8265042019072969, 'TP': 885, 'FP': 211, 'TN': 2389, 'FN': 415} 

2023-01-08 08:35: **********Val Epoch 12: average Loss: 0.183129
2023-01-08 08:35: Train Epoch 13: 3/634 Loss: 0.163227
2023-01-08 08:35: Train Epoch 13: 7/634 Loss: 0.167762
2023-01-08 08:36: Train Epoch 13: 11/634 Loss: 0.140605
2023-01-08 08:36: Train Epoch 13: 15/634 Loss: 0.142865
2023-01-08 08:36: Train Epoch 13: 19/634 Loss: 0.189884
2023-01-08 08:36: Train Epoch 13: 23/634 Loss: 0.153718
2023-01-08 08:37: Train Epoch 13: 27/634 Loss: 0.202215
2023-01-08 08:37: Train Epoch 13: 31/634 Loss: 0.155918
2023-01-08 08:37: Train Epoch 13: 35/634 Loss: 0.173905
2023-01-08 08:37: Train Epoch 13: 39/634 Loss: 0.158256
2023-01-08 08:37: Train Epoch 13: 43/634 Loss: 0.168734
2023-01-08 08:38: Train Epoch 13: 47/634 Loss: 0.180196
2023-01-08 08:38: Train Epoch 13: 51/634 Loss: 0.162661
2023-01-08 08:38: Train Epoch 13: 55/634 Loss: 0.153166
2023-01-08 08:38: Train Epoch 13: 59/634 Loss: 0.150081
2023-01-08 08:39: Train Epoch 13: 63/634 Loss: 0.208930
2023-01-08 08:39: Train Epoch 13: 67/634 Loss: 0.187866
2023-01-08 08:39: Train Epoch 13: 71/634 Loss: 0.158676
2023-01-08 08:39: Train Epoch 13: 75/634 Loss: 0.154414
2023-01-08 08:40: Train Epoch 13: 79/634 Loss: 0.138371
2023-01-08 08:40: Train Epoch 13: 83/634 Loss: 0.155697
2023-01-08 08:40: Train Epoch 13: 87/634 Loss: 0.151600
2023-01-08 08:40: Train Epoch 13: 91/634 Loss: 0.180636
2023-01-08 08:41: Train Epoch 13: 95/634 Loss: 0.169693
2023-01-08 08:41: Train Epoch 13: 99/634 Loss: 0.180672
2023-01-08 08:41: Train Epoch 13: 103/634 Loss: 0.182211
2023-01-08 08:41: Train Epoch 13: 107/634 Loss: 0.156829
2023-01-08 08:42: Train Epoch 13: 111/634 Loss: 0.184389
2023-01-08 08:42: Train Epoch 13: 115/634 Loss: 0.161055
2023-01-08 08:42: Train Epoch 13: 119/634 Loss: 0.179209
2023-01-08 08:42: Train Epoch 13: 123/634 Loss: 0.156762
2023-01-08 08:43: Train Epoch 13: 127/634 Loss: 0.178508
2023-01-08 08:43: Train Epoch 13: 131/634 Loss: 0.180475
2023-01-08 08:43: Train Epoch 13: 135/634 Loss: 0.154281
2023-01-08 08:43: Train Epoch 13: 139/634 Loss: 0.164536
2023-01-08 08:44: Train Epoch 13: 143/634 Loss: 0.141997
2023-01-08 08:44: Train Epoch 13: 147/634 Loss: 0.182771
2023-01-08 08:44: Train Epoch 13: 151/634 Loss: 0.144624
2023-01-08 08:44: Train Epoch 13: 155/634 Loss: 0.155162
2023-01-08 08:45: Train Epoch 13: 159/634 Loss: 0.182601
2023-01-08 08:45: Train Epoch 13: 163/634 Loss: 0.154972
2023-01-08 08:45: Train Epoch 13: 167/634 Loss: 0.159710
2023-01-08 08:45: Train Epoch 13: 171/634 Loss: 0.168696
2023-01-08 08:46: Train Epoch 13: 175/634 Loss: 0.169167
2023-01-08 08:46: Train Epoch 13: 179/634 Loss: 0.145716
2023-01-08 08:46: Train Epoch 13: 183/634 Loss: 0.181948
2023-01-08 08:46: Train Epoch 13: 187/634 Loss: 0.176518
2023-01-08 08:47: Train Epoch 13: 191/634 Loss: 0.173156
2023-01-08 08:47: Train Epoch 13: 195/634 Loss: 0.176002
2023-01-08 08:47: Train Epoch 13: 199/634 Loss: 0.148101
2023-01-08 08:47: Train Epoch 13: 203/634 Loss: 0.165888
2023-01-08 08:48: Train Epoch 13: 207/634 Loss: 0.155992
2023-01-08 08:48: Train Epoch 13: 211/634 Loss: 0.156179
2023-01-08 08:48: Train Epoch 13: 215/634 Loss: 0.130050
2023-01-08 08:48: Train Epoch 13: 219/634 Loss: 0.137208
2023-01-08 08:48: Train Epoch 13: 223/634 Loss: 0.179843
2023-01-08 08:49: Train Epoch 13: 227/634 Loss: 0.179040
2023-01-08 08:49: Train Epoch 13: 231/634 Loss: 0.181694
2023-01-08 08:49: Train Epoch 13: 235/634 Loss: 0.156174
2023-01-08 08:49: Train Epoch 13: 239/634 Loss: 0.148203
2023-01-08 08:50: Train Epoch 13: 243/634 Loss: 0.150626
2023-01-08 08:50: Train Epoch 13: 247/634 Loss: 0.159490
2023-01-08 08:50: Train Epoch 13: 251/634 Loss: 0.169077
2023-01-08 08:50: Train Epoch 13: 255/634 Loss: 0.164248
2023-01-08 08:51: Train Epoch 13: 259/634 Loss: 0.140270
2023-01-08 08:51: Train Epoch 13: 263/634 Loss: 0.140908
2023-01-08 08:51: Train Epoch 13: 267/634 Loss: 0.177605
2023-01-08 08:51: Train Epoch 13: 271/634 Loss: 0.164388
2023-01-08 08:52: Train Epoch 13: 275/634 Loss: 0.159759
2023-01-08 08:52: Train Epoch 13: 279/634 Loss: 0.172703
2023-01-08 08:52: Train Epoch 13: 283/634 Loss: 0.180814
2023-01-08 08:52: Train Epoch 13: 287/634 Loss: 0.159457
2023-01-08 08:53: Train Epoch 13: 291/634 Loss: 0.169938
2023-01-08 08:53: Train Epoch 13: 295/634 Loss: 0.163965
2023-01-08 08:53: Train Epoch 13: 299/634 Loss: 0.169419
2023-01-08 08:53: Train Epoch 13: 303/634 Loss: 0.159824
2023-01-08 08:54: Train Epoch 13: 307/634 Loss: 0.165706
2023-01-08 08:54: Train Epoch 13: 311/634 Loss: 0.157255
2023-01-08 08:54: Train Epoch 13: 315/634 Loss: 0.188313
2023-01-08 08:54: Train Epoch 13: 319/634 Loss: 0.152016
2023-01-08 08:55: Train Epoch 13: 323/634 Loss: 0.188890
2023-01-08 08:55: Train Epoch 13: 327/634 Loss: 0.173511
2023-01-08 08:55: Train Epoch 13: 331/634 Loss: 0.158720
2023-01-08 08:55: Train Epoch 13: 335/634 Loss: 0.141084
2023-01-08 08:56: Train Epoch 13: 339/634 Loss: 0.178673
2023-01-08 08:56: Train Epoch 13: 343/634 Loss: 0.168292
2023-01-08 08:56: Train Epoch 13: 347/634 Loss: 0.157698
2023-01-08 08:56: Train Epoch 13: 351/634 Loss: 0.226498
2023-01-08 08:57: Train Epoch 13: 355/634 Loss: 0.165283
2023-01-08 08:57: Train Epoch 13: 359/634 Loss: 0.164774
2023-01-08 08:57: Train Epoch 13: 363/634 Loss: 0.186584
2023-01-08 08:57: Train Epoch 13: 367/634 Loss: 0.163803
2023-01-08 08:58: Train Epoch 13: 371/634 Loss: 0.183870
2023-01-08 08:58: Train Epoch 13: 375/634 Loss: 0.157157
2023-01-08 08:58: Train Epoch 13: 379/634 Loss: 0.174867
2023-01-08 08:58: Train Epoch 13: 383/634 Loss: 0.175797
2023-01-08 08:59: Train Epoch 13: 387/634 Loss: 0.163621
2023-01-08 08:59: Train Epoch 13: 391/634 Loss: 0.145481
2023-01-08 08:59: Train Epoch 13: 395/634 Loss: 0.193065
2023-01-08 08:59: Train Epoch 13: 399/634 Loss: 0.157075
2023-01-08 08:59: Train Epoch 13: 403/634 Loss: 0.154074
2023-01-08 09:00: Train Epoch 13: 407/634 Loss: 0.172218
2023-01-08 09:00: Train Epoch 13: 411/634 Loss: 0.189689
2023-01-08 09:00: Train Epoch 13: 415/634 Loss: 0.154349
2023-01-08 09:00: Train Epoch 13: 419/634 Loss: 0.157315
2023-01-08 09:01: Train Epoch 13: 423/634 Loss: 0.164380
2023-01-08 09:01: Train Epoch 13: 427/634 Loss: 0.162305
2023-01-08 09:01: Train Epoch 13: 431/634 Loss: 0.170435
2023-01-08 09:01: Train Epoch 13: 435/634 Loss: 0.208666
2023-01-08 09:02: Train Epoch 13: 439/634 Loss: 0.223713
2023-01-08 09:02: Train Epoch 13: 443/634 Loss: 0.148382
2023-01-08 09:02: Train Epoch 13: 447/634 Loss: 0.145584
2023-01-08 09:02: Train Epoch 13: 451/634 Loss: 0.154222
2023-01-08 09:03: Train Epoch 13: 455/634 Loss: 0.167765
2023-01-08 09:03: Train Epoch 13: 459/634 Loss: 0.155665
2023-01-08 09:03: Train Epoch 13: 463/634 Loss: 0.183119
2023-01-08 09:03: Train Epoch 13: 467/634 Loss: 0.143233
2023-01-08 09:04: Train Epoch 13: 471/634 Loss: 0.148715
2023-01-08 09:04: Train Epoch 13: 475/634 Loss: 0.145133
2023-01-08 09:04: Train Epoch 13: 479/634 Loss: 0.147999
2023-01-08 09:04: Train Epoch 13: 483/634 Loss: 0.158339
2023-01-08 09:05: Train Epoch 13: 487/634 Loss: 0.169533
2023-01-08 09:05: Train Epoch 13: 491/634 Loss: 0.160744
2023-01-08 09:05: Train Epoch 13: 495/634 Loss: 0.147604
2023-01-08 09:05: Train Epoch 13: 499/634 Loss: 0.183711
2023-01-08 09:05: Train Epoch 13: 503/634 Loss: 0.169071
2023-01-08 09:06: Train Epoch 13: 507/634 Loss: 0.177713
2023-01-08 09:06: Train Epoch 13: 511/634 Loss: 0.173420
2023-01-08 09:06: Train Epoch 13: 515/634 Loss: 0.185847
2023-01-08 09:06: Train Epoch 13: 519/634 Loss: 0.179710
2023-01-08 09:07: Train Epoch 13: 523/634 Loss: 0.159459
2023-01-08 09:07: Train Epoch 13: 527/634 Loss: 0.169120
2023-01-08 09:07: Train Epoch 13: 531/634 Loss: 0.151347
2023-01-08 09:07: Train Epoch 13: 535/634 Loss: 0.175423
2023-01-08 09:08: Train Epoch 13: 539/634 Loss: 0.193470
2023-01-08 09:08: Train Epoch 13: 543/634 Loss: 0.134317
2023-01-08 09:08: Train Epoch 13: 547/634 Loss: 0.196420
2023-01-08 09:08: Train Epoch 13: 551/634 Loss: 0.179422
2023-01-08 09:09: Train Epoch 13: 555/634 Loss: 0.154882
2023-01-08 09:09: Train Epoch 13: 559/634 Loss: 0.156727
2023-01-08 09:09: Train Epoch 13: 563/634 Loss: 0.156364
2023-01-08 09:09: Train Epoch 13: 567/634 Loss: 0.186706
2023-01-08 09:10: Train Epoch 13: 571/634 Loss: 0.174297
2023-01-08 09:10: Train Epoch 13: 575/634 Loss: 0.191578
2023-01-08 09:10: Train Epoch 13: 579/634 Loss: 0.159525
2023-01-08 09:10: Train Epoch 13: 583/634 Loss: 0.138272
2023-01-08 09:11: Train Epoch 13: 587/634 Loss: 0.141553
2023-01-08 09:11: Train Epoch 13: 591/634 Loss: 0.161045
2023-01-08 09:11: Train Epoch 13: 595/634 Loss: 0.160099
2023-01-08 09:11: Train Epoch 13: 599/634 Loss: 0.163431
2023-01-08 09:12: Train Epoch 13: 603/634 Loss: 0.155753
2023-01-08 09:12: Train Epoch 13: 607/634 Loss: 0.147982
2023-01-08 09:12: Train Epoch 13: 611/634 Loss: 0.180841
2023-01-08 09:12: Train Epoch 13: 615/634 Loss: 0.147113
2023-01-08 09:12: Train Epoch 13: 619/634 Loss: 0.154420
2023-01-08 09:13: Train Epoch 13: 623/634 Loss: 0.169298
2023-01-08 09:13: Train Epoch 13: 627/634 Loss: 0.180594
2023-01-08 09:13: Train Epoch 13: 631/634 Loss: 0.186714
2023-01-08 09:13: Train Epoch 13: 633/634 Loss: 0.062901
2023-01-08 09:13: **********Train Epoch 13: averaged Loss: 0.165293 
2023-01-08 09:13: 
Epoch time elapsed: 2306.3671712875366

2023-01-08 09:14: 
 metrics validation: {'precision': 0.7948717948717948, 'recall': 0.6915384615384615, 'f1-score': 0.739613327848622, 'support': 1300, 'AUC': 0.9257923076923077, 'AUCPR': 0.8637676083793839, 'TP': 899, 'FP': 232, 'TN': 2368, 'FN': 401} 

2023-01-08 09:14: **********Val Epoch 13: average Loss: 0.159151
2023-01-08 09:15: Train Epoch 14: 3/634 Loss: 0.165547
2023-01-08 09:15: Train Epoch 14: 7/634 Loss: 0.142624
2023-01-08 09:15: Train Epoch 14: 11/634 Loss: 0.170752
2023-01-08 09:15: Train Epoch 14: 15/634 Loss: 0.177327
2023-01-08 09:16: Train Epoch 14: 19/634 Loss: 0.196629
2023-01-08 09:16: Train Epoch 14: 23/634 Loss: 0.174518
2023-01-08 09:16: Train Epoch 14: 27/634 Loss: 0.174944
2023-01-08 09:16: Train Epoch 14: 31/634 Loss: 0.160685
2023-01-08 09:17: Train Epoch 14: 35/634 Loss: 0.175660
2023-01-08 09:17: Train Epoch 14: 39/634 Loss: 0.195670
2023-01-08 09:17: Train Epoch 14: 43/634 Loss: 0.181845
2023-01-08 09:17: Train Epoch 14: 47/634 Loss: 0.173800
2023-01-08 09:18: Train Epoch 14: 51/634 Loss: 0.150879
2023-01-08 09:18: Train Epoch 14: 55/634 Loss: 0.187044
2023-01-08 09:18: Train Epoch 14: 59/634 Loss: 0.170365
2023-01-08 09:18: Train Epoch 14: 63/634 Loss: 0.159307
2023-01-08 09:19: Train Epoch 14: 67/634 Loss: 0.168001
2023-01-08 09:19: Train Epoch 14: 71/634 Loss: 0.178288
2023-01-08 09:19: Train Epoch 14: 75/634 Loss: 0.179889
2023-01-08 09:19: Train Epoch 14: 79/634 Loss: 0.173324
2023-01-08 09:19: Train Epoch 14: 83/634 Loss: 0.163227
2023-01-08 09:20: Train Epoch 14: 87/634 Loss: 0.163189
2023-01-08 09:20: Train Epoch 14: 91/634 Loss: 0.169998
2023-01-08 09:20: Train Epoch 14: 95/634 Loss: 0.154575
2023-01-08 09:20: Train Epoch 14: 99/634 Loss: 0.167588
2023-01-08 09:21: Train Epoch 14: 103/634 Loss: 0.163526
2023-01-08 09:21: Train Epoch 14: 107/634 Loss: 0.149028
2023-01-08 09:21: Train Epoch 14: 111/634 Loss: 0.169734
2023-01-08 09:21: Train Epoch 14: 115/634 Loss: 0.136856
2023-01-08 09:22: Train Epoch 14: 119/634 Loss: 0.158055
2023-01-08 09:22: Train Epoch 14: 123/634 Loss: 0.175813
2023-01-08 09:22: Train Epoch 14: 127/634 Loss: 0.170080
2023-01-08 09:22: Train Epoch 14: 131/634 Loss: 0.165025
2023-01-08 09:23: Train Epoch 14: 135/634 Loss: 0.186343
2023-01-08 09:23: Train Epoch 14: 139/634 Loss: 0.166947
2023-01-08 09:23: Train Epoch 14: 143/634 Loss: 0.174762
2023-01-08 09:23: Train Epoch 14: 147/634 Loss: 0.173306
2023-01-08 09:24: Train Epoch 14: 151/634 Loss: 0.173002
2023-01-08 09:24: Train Epoch 14: 155/634 Loss: 0.178598
2023-01-08 09:24: Train Epoch 14: 159/634 Loss: 0.196568
2023-01-08 09:24: Train Epoch 14: 163/634 Loss: 0.169070
2023-01-08 09:25: Train Epoch 14: 167/634 Loss: 0.149812
2023-01-08 09:25: Train Epoch 14: 171/634 Loss: 0.174575
2023-01-08 09:25: Train Epoch 14: 175/634 Loss: 0.169931
2023-01-08 09:25: Train Epoch 14: 179/634 Loss: 0.152366
2023-01-08 09:26: Train Epoch 14: 183/634 Loss: 0.177689
2023-01-08 09:26: Train Epoch 14: 187/634 Loss: 0.149777
2023-01-08 09:26: Train Epoch 14: 191/634 Loss: 0.175016
2023-01-08 09:26: Train Epoch 14: 195/634 Loss: 0.193946
2023-01-08 09:26: Train Epoch 14: 199/634 Loss: 0.193093
2023-01-08 09:27: Train Epoch 14: 203/634 Loss: 0.212115
2023-01-08 09:27: Train Epoch 14: 207/634 Loss: 0.160767
2023-01-08 09:27: Train Epoch 14: 211/634 Loss: 0.169034
2023-01-08 09:27: Train Epoch 14: 215/634 Loss: 0.136705
2023-01-08 09:28: Train Epoch 14: 219/634 Loss: 0.202384
2023-01-08 09:28: Train Epoch 14: 223/634 Loss: 0.155868
2023-01-08 09:28: Train Epoch 14: 227/634 Loss: 0.168382
2023-01-08 09:28: Train Epoch 14: 231/634 Loss: 0.141701
2023-01-08 09:29: Train Epoch 14: 235/634 Loss: 0.159738
2023-01-08 09:29: Train Epoch 14: 239/634 Loss: 0.165162
2023-01-08 09:29: Train Epoch 14: 243/634 Loss: 0.179476
2023-01-08 09:29: Train Epoch 14: 247/634 Loss: 0.179305
2023-01-08 09:29: Train Epoch 14: 251/634 Loss: 0.198458
2023-01-08 09:30: Train Epoch 14: 255/634 Loss: 0.163436
2023-01-08 09:30: Train Epoch 14: 259/634 Loss: 0.165331
2023-01-08 09:30: Train Epoch 14: 263/634 Loss: 0.159293
2023-01-08 09:30: Train Epoch 14: 267/634 Loss: 0.152953
2023-01-08 09:31: Train Epoch 14: 271/634 Loss: 0.164938
2023-01-08 09:31: Train Epoch 14: 275/634 Loss: 0.154772
2023-01-08 09:31: Train Epoch 14: 279/634 Loss: 0.144445
2023-01-08 09:31: Train Epoch 14: 283/634 Loss: 0.194309
2023-01-08 09:32: Train Epoch 14: 287/634 Loss: 0.150266
2023-01-08 09:32: Train Epoch 14: 291/634 Loss: 0.182054
2023-01-08 09:32: Train Epoch 14: 295/634 Loss: 0.147969
2023-01-08 09:32: Train Epoch 14: 299/634 Loss: 0.163702
2023-01-08 09:33: Train Epoch 14: 303/634 Loss: 0.156983
2023-01-08 09:33: Train Epoch 14: 307/634 Loss: 0.175294
2023-01-08 09:33: Train Epoch 14: 311/634 Loss: 0.153236
2023-01-08 09:33: Train Epoch 14: 315/634 Loss: 0.162913
2023-01-08 09:34: Train Epoch 14: 319/634 Loss: 0.163311
2023-01-08 09:34: Train Epoch 14: 323/634 Loss: 0.184995
2023-01-08 09:34: Train Epoch 14: 327/634 Loss: 0.163327
2023-01-08 09:34: Train Epoch 14: 331/634 Loss: 0.197467
2023-01-08 09:35: Train Epoch 14: 335/634 Loss: 0.172734
2023-01-08 09:35: Train Epoch 14: 339/634 Loss: 0.160266
2023-01-08 09:35: Train Epoch 14: 343/634 Loss: 0.181039
2023-01-08 09:35: Train Epoch 14: 347/634 Loss: 0.167694
2023-01-08 09:36: Train Epoch 14: 351/634 Loss: 0.171205
2023-01-08 09:36: Train Epoch 14: 355/634 Loss: 0.154556
2023-01-08 09:36: Train Epoch 14: 359/634 Loss: 0.151550
2023-01-08 09:36: Train Epoch 14: 363/634 Loss: 0.151193
2023-01-08 09:37: Train Epoch 14: 367/634 Loss: 0.194544
2023-01-08 09:37: Train Epoch 14: 371/634 Loss: 0.152236
2023-01-08 09:37: Train Epoch 14: 375/634 Loss: 0.184227
2023-01-08 09:37: Train Epoch 14: 379/634 Loss: 0.131206
2023-01-08 09:38: Train Epoch 14: 383/634 Loss: 0.180301
2023-01-08 09:38: Train Epoch 14: 387/634 Loss: 0.176848
2023-01-08 09:38: Train Epoch 14: 391/634 Loss: 0.170374
2023-01-08 09:38: Train Epoch 14: 395/634 Loss: 0.164209
2023-01-08 09:39: Train Epoch 14: 399/634 Loss: 0.154144
2023-01-08 09:39: Train Epoch 14: 403/634 Loss: 0.181717
2023-01-08 09:39: Train Epoch 14: 407/634 Loss: 0.169813
2023-01-08 09:39: Train Epoch 14: 411/634 Loss: 0.165856
2023-01-08 09:39: Train Epoch 14: 415/634 Loss: 0.164189
2023-01-08 09:40: Train Epoch 14: 419/634 Loss: 0.182469
2023-01-08 09:40: Train Epoch 14: 423/634 Loss: 0.159905
2023-01-08 09:40: Train Epoch 14: 427/634 Loss: 0.185924
2023-01-08 09:40: Train Epoch 14: 431/634 Loss: 0.159380
2023-01-08 09:41: Train Epoch 14: 435/634 Loss: 0.179813
2023-01-08 09:41: Train Epoch 14: 439/634 Loss: 0.156366
2023-01-08 09:41: Train Epoch 14: 443/634 Loss: 0.174981
2023-01-08 09:41: Train Epoch 14: 447/634 Loss: 0.148015
2023-01-08 09:42: Train Epoch 14: 451/634 Loss: 0.143154
2023-01-08 09:42: Train Epoch 14: 455/634 Loss: 0.195324
2023-01-08 09:42: Train Epoch 14: 459/634 Loss: 0.158068
2023-01-08 09:42: Train Epoch 14: 463/634 Loss: 0.157131
2023-01-08 09:43: Train Epoch 14: 467/634 Loss: 0.157681
2023-01-08 09:43: Train Epoch 14: 471/634 Loss: 0.141344
2023-01-08 09:43: Train Epoch 14: 475/634 Loss: 0.148645
2023-01-08 09:43: Train Epoch 14: 479/634 Loss: 0.152814
2023-01-08 09:44: Train Epoch 14: 483/634 Loss: 0.144240
2023-01-08 09:44: Train Epoch 14: 487/634 Loss: 0.159053
2023-01-08 09:44: Train Epoch 14: 491/634 Loss: 0.154676
2023-01-08 09:44: Train Epoch 14: 495/634 Loss: 0.172536
2023-01-08 09:44: Train Epoch 14: 499/634 Loss: 0.160998
2023-01-08 09:45: Train Epoch 14: 503/634 Loss: 0.149876
2023-01-08 09:45: Train Epoch 14: 507/634 Loss: 0.183155
2023-01-08 09:45: Train Epoch 14: 511/634 Loss: 0.153505
2023-01-08 09:45: Train Epoch 14: 515/634 Loss: 0.133433
2023-01-08 09:46: Train Epoch 14: 519/634 Loss: 0.171510
2023-01-08 09:46: Train Epoch 14: 523/634 Loss: 0.165834
2023-01-08 09:46: Train Epoch 14: 527/634 Loss: 0.163206
2023-01-08 09:46: Train Epoch 14: 531/634 Loss: 0.164629
2023-01-08 09:47: Train Epoch 14: 535/634 Loss: 0.137607
2023-01-08 09:47: Train Epoch 14: 539/634 Loss: 0.153384
2023-01-08 09:47: Train Epoch 14: 543/634 Loss: 0.157940
2023-01-08 09:47: Train Epoch 14: 547/634 Loss: 0.148033
2023-01-08 09:48: Train Epoch 14: 551/634 Loss: 0.186290
2023-01-08 09:48: Train Epoch 14: 555/634 Loss: 0.168406
2023-01-08 09:48: Train Epoch 14: 559/634 Loss: 0.155677
2023-01-08 09:48: Train Epoch 14: 563/634 Loss: 0.181175
2023-01-08 09:48: Train Epoch 14: 567/634 Loss: 0.189652
2023-01-08 09:49: Train Epoch 14: 571/634 Loss: 0.180765
2023-01-08 09:49: Train Epoch 14: 575/634 Loss: 0.180678
2023-01-08 09:49: Train Epoch 14: 579/634 Loss: 0.161024
2023-01-08 09:49: Train Epoch 14: 583/634 Loss: 0.168346
2023-01-08 09:50: Train Epoch 14: 587/634 Loss: 0.154104
2023-01-08 09:50: Train Epoch 14: 591/634 Loss: 0.177625
2023-01-08 09:50: Train Epoch 14: 595/634 Loss: 0.159845
2023-01-08 09:50: Train Epoch 14: 599/634 Loss: 0.130583
2023-01-08 09:51: Train Epoch 14: 603/634 Loss: 0.200459
2023-01-08 09:51: Train Epoch 14: 607/634 Loss: 0.175281
2023-01-08 09:51: Train Epoch 14: 611/634 Loss: 0.131228
2023-01-08 09:51: Train Epoch 14: 615/634 Loss: 0.210462
2023-01-08 09:52: Train Epoch 14: 619/634 Loss: 0.169836
2023-01-08 09:52: Train Epoch 14: 623/634 Loss: 0.150438
2023-01-08 09:52: Train Epoch 14: 627/634 Loss: 0.149138
2023-01-08 09:52: Train Epoch 14: 631/634 Loss: 0.180022
2023-01-08 09:52: Train Epoch 14: 633/634 Loss: 0.066939
2023-01-08 09:52: **********Train Epoch 14: averaged Loss: 0.166360 
2023-01-08 09:52: 
Epoch time elapsed: 2274.8834416866302

2023-01-08 09:54: 
 metrics validation: {'precision': 0.802990325417766, 'recall': 0.7023076923076923, 'f1-score': 0.7492819039803037, 'support': 1300, 'AUC': 0.9228736686390533, 'AUCPR': 0.86056374064702, 'TP': 913, 'FP': 224, 'TN': 2376, 'FN': 387} 

2023-01-08 09:54: **********Val Epoch 14: average Loss: 0.160268
2023-01-08 09:54: Train Epoch 15: 3/634 Loss: 0.150257
2023-01-08 09:54: Train Epoch 15: 7/634 Loss: 0.181630
2023-01-08 09:54: Train Epoch 15: 11/634 Loss: 0.143990
2023-01-08 09:54: Train Epoch 15: 15/634 Loss: 0.173660
2023-01-08 09:55: Train Epoch 15: 19/634 Loss: 0.162434
2023-01-08 09:55: Train Epoch 15: 23/634 Loss: 0.162381
2023-01-08 09:55: Train Epoch 15: 27/634 Loss: 0.170801
2023-01-08 09:55: Train Epoch 15: 31/634 Loss: 0.208394
2023-01-08 09:56: Train Epoch 15: 35/634 Loss: 0.168783
2023-01-08 09:56: Train Epoch 15: 39/634 Loss: 0.162388
2023-01-08 09:56: Train Epoch 15: 43/634 Loss: 0.174933
2023-01-08 09:56: Train Epoch 15: 47/634 Loss: 0.161135
2023-01-08 09:57: Train Epoch 15: 51/634 Loss: 0.171431
2023-01-08 09:57: Train Epoch 15: 55/634 Loss: 0.141840
2023-01-08 09:57: Train Epoch 15: 59/634 Loss: 0.204234
2023-01-08 09:57: Train Epoch 15: 63/634 Loss: 0.183775
2023-01-08 09:58: Train Epoch 15: 67/634 Loss: 0.181548
2023-01-08 09:58: Train Epoch 15: 71/634 Loss: 0.160740
2023-01-08 09:58: Train Epoch 15: 75/634 Loss: 0.217422
2023-01-08 09:58: Train Epoch 15: 79/634 Loss: 0.152116
2023-01-08 09:59: Train Epoch 15: 83/634 Loss: 0.162531
2023-01-08 09:59: Train Epoch 15: 87/634 Loss: 0.163005
2023-01-08 09:59: Train Epoch 15: 91/634 Loss: 0.186969
2023-01-08 09:59: Train Epoch 15: 95/634 Loss: 0.167639
2023-01-08 10:00: Train Epoch 15: 99/634 Loss: 0.158762
2023-01-08 10:00: Train Epoch 15: 103/634 Loss: 0.170097
2023-01-08 10:00: Train Epoch 15: 107/634 Loss: 0.176003
2023-01-08 10:00: Train Epoch 15: 111/634 Loss: 0.173044
2023-01-08 10:01: Train Epoch 15: 115/634 Loss: 0.223871
2023-01-08 10:01: Train Epoch 15: 119/634 Loss: 0.163241
2023-01-08 10:01: Train Epoch 15: 123/634 Loss: 0.137449
2023-01-08 10:01: Train Epoch 15: 127/634 Loss: 0.158298
2023-01-08 10:02: Train Epoch 15: 131/634 Loss: 0.153558
2023-01-08 10:02: Train Epoch 15: 135/634 Loss: 0.211842
2023-01-08 10:02: Train Epoch 15: 139/634 Loss: 0.170602
2023-01-08 10:02: Train Epoch 15: 143/634 Loss: 0.165460
2023-01-08 10:02: Train Epoch 15: 147/634 Loss: 0.149871
2023-01-08 10:03: Train Epoch 15: 151/634 Loss: 0.170432
2023-01-08 10:03: Train Epoch 15: 155/634 Loss: 0.155484
2023-01-08 10:03: Train Epoch 15: 159/634 Loss: 0.143443
2023-01-08 10:03: Train Epoch 15: 163/634 Loss: 0.165114
2023-01-08 10:04: Train Epoch 15: 167/634 Loss: 0.162196
2023-01-08 10:04: Train Epoch 15: 171/634 Loss: 0.148540
2023-01-08 10:04: Train Epoch 15: 175/634 Loss: 0.158555
2023-01-08 10:04: Train Epoch 15: 179/634 Loss: 0.154387
2023-01-08 10:05: Train Epoch 15: 183/634 Loss: 0.191967
2023-01-08 10:05: Train Epoch 15: 187/634 Loss: 0.154824
2023-01-08 10:05: Train Epoch 15: 191/634 Loss: 0.175261
2023-01-08 10:05: Train Epoch 15: 195/634 Loss: 0.159098
2023-01-08 10:06: Train Epoch 15: 199/634 Loss: 0.134485
2023-01-08 10:06: Train Epoch 15: 203/634 Loss: 0.162157
2023-01-08 10:06: Train Epoch 15: 207/634 Loss: 0.157313
2023-01-08 10:06: Train Epoch 15: 211/634 Loss: 0.148245
2023-01-08 10:07: Train Epoch 15: 215/634 Loss: 0.177574
2023-01-08 10:07: Train Epoch 15: 219/634 Loss: 0.148115
2023-01-08 10:07: Train Epoch 15: 223/634 Loss: 0.200904
2023-01-08 10:07: Train Epoch 15: 227/634 Loss: 0.176327
2023-01-08 10:08: Train Epoch 15: 231/634 Loss: 0.163531
2023-01-08 10:08: Train Epoch 15: 235/634 Loss: 0.161478
2023-01-08 10:08: Train Epoch 15: 239/634 Loss: 0.141184
2023-01-08 10:08: Train Epoch 15: 243/634 Loss: 0.163778
2023-01-08 10:09: Train Epoch 15: 247/634 Loss: 0.151453
2023-01-08 10:09: Train Epoch 15: 251/634 Loss: 0.151500
2023-01-08 10:09: Train Epoch 15: 255/634 Loss: 0.177088
2023-01-08 10:09: Train Epoch 15: 259/634 Loss: 0.165909
2023-01-08 10:10: Train Epoch 15: 263/634 Loss: 0.178796
2023-01-08 10:10: Train Epoch 15: 267/634 Loss: 0.174058
2023-01-08 10:10: Train Epoch 15: 271/634 Loss: 0.157826
2023-01-08 10:10: Train Epoch 15: 275/634 Loss: 0.165267
2023-01-08 10:11: Train Epoch 15: 279/634 Loss: 0.189927
2023-01-08 10:11: Train Epoch 15: 283/634 Loss: 0.156099
2023-01-08 10:11: Train Epoch 15: 287/634 Loss: 0.146182
2023-01-08 10:11: Train Epoch 15: 291/634 Loss: 0.135691
2023-01-08 10:12: Train Epoch 15: 295/634 Loss: 0.182369
2023-01-08 10:12: Train Epoch 15: 299/634 Loss: 0.155422
2023-01-08 10:12: Train Epoch 15: 303/634 Loss: 0.139600
2023-01-08 10:12: Train Epoch 15: 307/634 Loss: 0.161474
2023-01-08 10:13: Train Epoch 15: 311/634 Loss: 0.171553
2023-01-08 10:13: Train Epoch 15: 315/634 Loss: 0.182115
2023-01-08 10:13: Train Epoch 15: 319/634 Loss: 0.160307
2023-01-08 10:13: Train Epoch 15: 323/634 Loss: 0.159246
2023-01-08 10:14: Train Epoch 15: 327/634 Loss: 0.161968
2023-01-08 10:14: Train Epoch 15: 331/634 Loss: 0.165350
2023-01-08 10:14: Train Epoch 15: 335/634 Loss: 0.147889
2023-01-08 10:14: Train Epoch 15: 339/634 Loss: 0.176924
2023-01-08 10:14: Train Epoch 15: 343/634 Loss: 0.160169
2023-01-08 10:15: Train Epoch 15: 347/634 Loss: 0.166506
2023-01-08 10:15: Train Epoch 15: 351/634 Loss: 0.179052
2023-01-08 10:15: Train Epoch 15: 355/634 Loss: 0.163899
2023-01-08 10:15: Train Epoch 15: 359/634 Loss: 0.172006
2023-01-08 10:16: Train Epoch 15: 363/634 Loss: 0.158133
2023-01-08 10:16: Train Epoch 15: 367/634 Loss: 0.148692
2023-01-08 10:16: Train Epoch 15: 371/634 Loss: 0.177106
2023-01-08 10:16: Train Epoch 15: 375/634 Loss: 0.135619
2023-01-08 10:17: Train Epoch 15: 379/634 Loss: 0.184608
2023-01-08 10:17: Train Epoch 15: 383/634 Loss: 0.144645
2023-01-08 10:17: Train Epoch 15: 387/634 Loss: 0.153458
2023-01-08 10:17: Train Epoch 15: 391/634 Loss: 0.162913
2023-01-08 10:18: Train Epoch 15: 395/634 Loss: 0.186599
2023-01-08 10:18: Train Epoch 15: 399/634 Loss: 0.158832
2023-01-08 10:18: Train Epoch 15: 403/634 Loss: 0.158154
2023-01-08 10:18: Train Epoch 15: 407/634 Loss: 0.171998
2023-01-08 10:19: Train Epoch 15: 411/634 Loss: 0.183158
2023-01-08 10:19: Train Epoch 15: 415/634 Loss: 0.160002
2023-01-08 10:19: Train Epoch 15: 419/634 Loss: 0.157720
2023-01-08 10:19: Train Epoch 15: 423/634 Loss: 0.149899
2023-01-08 10:20: Train Epoch 15: 427/634 Loss: 0.166682
2023-01-08 10:20: Train Epoch 15: 431/634 Loss: 0.154090
2023-01-08 10:20: Train Epoch 15: 435/634 Loss: 0.183619
2023-01-08 10:20: Train Epoch 15: 439/634 Loss: 0.189083
2023-01-08 10:21: Train Epoch 15: 443/634 Loss: 0.162799
2023-01-08 10:21: Train Epoch 15: 447/634 Loss: 0.164130
2023-01-08 10:21: Train Epoch 15: 451/634 Loss: 0.196665
2023-01-08 10:21: Train Epoch 15: 455/634 Loss: 0.166226
2023-01-08 10:22: Train Epoch 15: 459/634 Loss: 0.134720
2023-01-08 10:22: Train Epoch 15: 463/634 Loss: 0.143471
2023-01-08 10:22: Train Epoch 15: 467/634 Loss: 0.195217
2023-01-08 10:22: Train Epoch 15: 471/634 Loss: 0.205616
2023-01-08 10:22: Train Epoch 15: 475/634 Loss: 0.161777
2023-01-08 10:23: Train Epoch 15: 479/634 Loss: 0.141110
2023-01-08 10:23: Train Epoch 15: 483/634 Loss: 0.165001
2023-01-08 10:23: Train Epoch 15: 487/634 Loss: 0.177620
2023-01-08 10:23: Train Epoch 15: 491/634 Loss: 0.159806
2023-01-08 10:24: Train Epoch 15: 495/634 Loss: 0.179245
2023-01-08 10:24: Train Epoch 15: 499/634 Loss: 0.235735
2023-01-08 10:24: Train Epoch 15: 503/634 Loss: 0.177364
2023-01-08 10:24: Train Epoch 15: 507/634 Loss: 0.184179
2023-01-08 10:25: Train Epoch 15: 511/634 Loss: 0.161951
2023-01-08 10:25: Train Epoch 15: 515/634 Loss: 0.165664
2023-01-08 10:25: Train Epoch 15: 519/634 Loss: 0.158031
2023-01-08 10:25: Train Epoch 15: 523/634 Loss: 0.151721
2023-01-08 10:26: Train Epoch 15: 527/634 Loss: 0.164184
2023-01-08 10:26: Train Epoch 15: 531/634 Loss: 0.167912
2023-01-08 10:26: Train Epoch 15: 535/634 Loss: 0.170079
2023-01-08 10:26: Train Epoch 15: 539/634 Loss: 0.158210
2023-01-08 10:27: Train Epoch 15: 543/634 Loss: 0.168593
2023-01-08 10:27: Train Epoch 15: 547/634 Loss: 0.184057
2023-01-08 10:27: Train Epoch 15: 551/634 Loss: 0.157321
2023-01-08 10:27: Train Epoch 15: 555/634 Loss: 0.146527
2023-01-08 10:28: Train Epoch 15: 559/634 Loss: 0.207104
2023-01-08 10:28: Train Epoch 15: 563/634 Loss: 0.219269
2023-01-08 10:28: Train Epoch 15: 567/634 Loss: 0.139619
2023-01-08 10:28: Train Epoch 15: 571/634 Loss: 0.182858
2023-01-08 10:28: Train Epoch 15: 575/634 Loss: 0.172968
2023-01-08 10:29: Train Epoch 15: 579/634 Loss: 0.181392
2023-01-08 10:29: Train Epoch 15: 583/634 Loss: 0.171430
2023-01-08 10:29: Train Epoch 15: 587/634 Loss: 0.192012
2023-01-08 10:29: Train Epoch 15: 591/634 Loss: 0.187856
2023-01-08 10:30: Train Epoch 15: 595/634 Loss: 0.153900
2023-01-08 10:30: Train Epoch 15: 599/634 Loss: 0.176225
2023-01-08 10:30: Train Epoch 15: 603/634 Loss: 0.186392
2023-01-08 10:30: Train Epoch 15: 607/634 Loss: 0.177404
2023-01-08 10:31: Train Epoch 15: 611/634 Loss: 0.198451
2023-01-08 10:31: Train Epoch 15: 615/634 Loss: 0.191245
2023-01-08 10:31: Train Epoch 15: 619/634 Loss: 0.195698
2023-01-08 10:31: Train Epoch 15: 623/634 Loss: 0.183587
2023-01-08 10:32: Train Epoch 15: 627/634 Loss: 0.177468
2023-01-08 10:32: Train Epoch 15: 631/634 Loss: 0.165806
2023-01-08 10:32: Train Epoch 15: 633/634 Loss: 0.081351
2023-01-08 10:32: **********Train Epoch 15: averaged Loss: 0.167850 
2023-01-08 10:32: 
Epoch time elapsed: 2302.0071861743927

2023-01-08 10:33: 
 metrics validation: {'precision': 0.8457760314341847, 'recall': 0.6623076923076923, 'f1-score': 0.7428817946505608, 'support': 1300, 'AUC': 0.925221597633136, 'AUCPR': 0.8608519211755989, 'TP': 861, 'FP': 157, 'TN': 2443, 'FN': 439} 

2023-01-08 10:33: **********Val Epoch 15: average Loss: 0.163243
2023-01-08 10:33: Train Epoch 16: 3/634 Loss: 0.167438
2023-01-08 10:34: Train Epoch 16: 7/634 Loss: 0.173538
2023-01-08 10:34: Train Epoch 16: 11/634 Loss: 0.167897
2023-01-08 10:34: Train Epoch 16: 15/634 Loss: 0.132246
2023-01-08 10:34: Train Epoch 16: 19/634 Loss: 0.189473
2023-01-08 10:35: Train Epoch 16: 23/634 Loss: 0.200340
2023-01-08 10:35: Train Epoch 16: 27/634 Loss: 0.187946
2023-01-08 10:35: Train Epoch 16: 31/634 Loss: 0.148301
2023-01-08 10:35: Train Epoch 16: 35/634 Loss: 0.191274
2023-01-08 10:36: Train Epoch 16: 39/634 Loss: 0.163116
2023-01-08 10:36: Train Epoch 16: 43/634 Loss: 0.146060
2023-01-08 10:36: Train Epoch 16: 47/634 Loss: 0.152808
2023-01-08 10:36: Train Epoch 16: 51/634 Loss: 0.168318
2023-01-08 10:37: Train Epoch 16: 55/634 Loss: 0.171917
2023-01-08 10:37: Train Epoch 16: 59/634 Loss: 0.170192
2023-01-08 10:37: Train Epoch 16: 63/634 Loss: 0.184882
2023-01-08 10:37: Train Epoch 16: 67/634 Loss: 0.138276
2023-01-08 10:38: Train Epoch 16: 71/634 Loss: 0.179592
2023-01-08 10:38: Train Epoch 16: 75/634 Loss: 0.189097
2023-01-08 10:38: Train Epoch 16: 79/634 Loss: 0.180999
2023-01-08 10:38: Train Epoch 16: 83/634 Loss: 0.172703
2023-01-08 10:39: Train Epoch 16: 87/634 Loss: 0.201421
2023-01-08 10:39: Train Epoch 16: 91/634 Loss: 0.181512
2023-01-08 10:39: Train Epoch 16: 95/634 Loss: 0.137353
2023-01-08 10:39: Train Epoch 16: 99/634 Loss: 0.179466
2023-01-08 10:39: Train Epoch 16: 103/634 Loss: 0.208027
2023-01-08 10:40: Train Epoch 16: 107/634 Loss: 0.158597
2023-01-08 10:40: Train Epoch 16: 111/634 Loss: 0.173699
2023-01-08 10:40: Train Epoch 16: 115/634 Loss: 0.206709
2023-01-08 10:40: Train Epoch 16: 119/634 Loss: 0.177678
2023-01-08 10:41: Train Epoch 16: 123/634 Loss: 0.173593
2023-01-08 10:41: Train Epoch 16: 127/634 Loss: 0.198186
2023-01-08 10:41: Train Epoch 16: 131/634 Loss: 0.196527
2023-01-08 10:41: Train Epoch 16: 135/634 Loss: 0.194968
2023-01-08 10:42: Train Epoch 16: 139/634 Loss: 0.199014
2023-01-08 10:42: Train Epoch 16: 143/634 Loss: 0.175167
2023-01-08 10:42: Train Epoch 16: 147/634 Loss: 0.215379
2023-01-08 10:42: Train Epoch 16: 151/634 Loss: 0.155034
2023-01-08 10:43: Train Epoch 16: 155/634 Loss: 0.159502
2023-01-08 10:43: Train Epoch 16: 159/634 Loss: 0.179573
2023-01-08 10:43: Train Epoch 16: 163/634 Loss: 0.206013
2023-01-08 10:43: Train Epoch 16: 167/634 Loss: 0.165691
2023-01-08 10:44: Train Epoch 16: 171/634 Loss: 0.167964
2023-01-08 10:44: Train Epoch 16: 175/634 Loss: 0.162448
2023-01-08 10:44: Train Epoch 16: 179/634 Loss: 0.201807
2023-01-08 10:44: Train Epoch 16: 183/634 Loss: 0.166058
2023-01-08 10:45: Train Epoch 16: 187/634 Loss: 0.138887
2023-01-08 10:45: Train Epoch 16: 191/634 Loss: 0.171425
2023-01-08 10:45: Train Epoch 16: 195/634 Loss: 0.152137
2023-01-08 10:45: Train Epoch 16: 199/634 Loss: 0.183803
2023-01-08 10:45: Train Epoch 16: 203/634 Loss: 0.152539
2023-01-08 10:46: Train Epoch 16: 207/634 Loss: 0.146095
2023-01-08 10:46: Train Epoch 16: 211/634 Loss: 0.167037
2023-01-08 10:46: Train Epoch 16: 215/634 Loss: 0.169793
2023-01-08 10:46: Train Epoch 16: 219/634 Loss: 0.164910
2023-01-08 10:47: Train Epoch 16: 223/634 Loss: 0.193419
2023-01-08 10:47: Train Epoch 16: 227/634 Loss: 0.177346
2023-01-08 10:47: Train Epoch 16: 231/634 Loss: 0.166591
2023-01-08 10:47: Train Epoch 16: 235/634 Loss: 0.153706
2023-01-08 10:48: Train Epoch 16: 239/634 Loss: 0.148245
2023-01-08 10:48: Train Epoch 16: 243/634 Loss: 0.162382
2023-01-08 10:48: Train Epoch 16: 247/634 Loss: 0.178990
2023-01-08 10:48: Train Epoch 16: 251/634 Loss: 0.168675
2023-01-08 10:49: Train Epoch 16: 255/634 Loss: 0.145102
2023-01-08 10:49: Train Epoch 16: 259/634 Loss: 0.159218
2023-01-08 10:49: Train Epoch 16: 263/634 Loss: 0.155093
2023-01-08 10:49: Train Epoch 16: 267/634 Loss: 0.160775
2023-01-08 10:50: Train Epoch 16: 271/634 Loss: 0.155471
2023-01-08 10:50: Train Epoch 16: 275/634 Loss: 0.185371
2023-01-08 10:50: Train Epoch 16: 279/634 Loss: 0.144236
2023-01-08 10:50: Train Epoch 16: 283/634 Loss: 0.178002
2023-01-08 10:51: Train Epoch 16: 287/634 Loss: 0.156668
2023-01-08 10:51: Train Epoch 16: 291/634 Loss: 0.154290
2023-01-08 10:51: Train Epoch 16: 295/634 Loss: 0.151542
2023-01-08 10:51: Train Epoch 16: 299/634 Loss: 0.146581
2023-01-08 10:52: Train Epoch 16: 303/634 Loss: 0.196562
2023-01-08 10:52: Train Epoch 16: 307/634 Loss: 0.179428
2023-01-08 10:52: Train Epoch 16: 311/634 Loss: 0.162552
2023-01-08 10:52: Train Epoch 16: 315/634 Loss: 0.163083
2023-01-08 10:53: Train Epoch 16: 319/634 Loss: 0.147710
2023-01-08 10:53: Train Epoch 16: 323/634 Loss: 0.154144
2023-01-08 10:53: Train Epoch 16: 327/634 Loss: 0.189197
2023-01-08 10:53: Train Epoch 16: 331/634 Loss: 0.178173
2023-01-08 10:53: Train Epoch 16: 335/634 Loss: 0.167838
2023-01-08 10:54: Train Epoch 16: 339/634 Loss: 0.149430
2023-01-08 10:54: Train Epoch 16: 343/634 Loss: 0.177656
2023-01-08 10:54: Train Epoch 16: 347/634 Loss: 0.147550
2023-01-08 10:54: Train Epoch 16: 351/634 Loss: 0.179340
2023-01-08 10:55: Train Epoch 16: 355/634 Loss: 0.153569
2023-01-08 10:55: Train Epoch 16: 359/634 Loss: 0.181281
2023-01-08 10:55: Train Epoch 16: 363/634 Loss: 0.163584
2023-01-08 10:55: Train Epoch 16: 367/634 Loss: 0.179161
2023-01-08 10:56: Train Epoch 16: 371/634 Loss: 0.180702
2023-01-08 10:56: Train Epoch 16: 375/634 Loss: 0.184188
2023-01-08 10:56: Train Epoch 16: 379/634 Loss: 0.166557
2023-01-08 10:56: Train Epoch 16: 383/634 Loss: 0.158886
2023-01-08 10:57: Train Epoch 16: 387/634 Loss: 0.145780
2023-01-08 10:57: Train Epoch 16: 391/634 Loss: 0.164373
2023-01-08 10:57: Train Epoch 16: 395/634 Loss: 0.162819
2023-01-08 10:57: Train Epoch 16: 399/634 Loss: 0.176722
2023-01-08 10:58: Train Epoch 16: 403/634 Loss: 0.170369
2023-01-08 10:58: Train Epoch 16: 407/634 Loss: 0.138262
2023-01-08 10:58: Train Epoch 16: 411/634 Loss: 0.174836
2023-01-08 10:58: Train Epoch 16: 415/634 Loss: 0.174726
2023-01-08 10:59: Train Epoch 16: 419/634 Loss: 0.154694
2023-01-08 10:59: Train Epoch 16: 423/634 Loss: 0.151599
2023-01-08 10:59: Train Epoch 16: 427/634 Loss: 0.157250
2023-01-08 10:59: Train Epoch 16: 431/634 Loss: 0.178800
2023-01-08 10:59: Train Epoch 16: 435/634 Loss: 0.149345
2023-01-08 11:00: Train Epoch 16: 439/634 Loss: 0.167147
2023-01-08 11:00: Train Epoch 16: 443/634 Loss: 0.175744
2023-01-08 11:00: Train Epoch 16: 447/634 Loss: 0.178382
2023-01-08 11:00: Train Epoch 16: 451/634 Loss: 0.139722
2023-01-08 11:01: Train Epoch 16: 455/634 Loss: 0.135004
2023-01-08 11:01: Train Epoch 16: 459/634 Loss: 0.156985
2023-01-08 11:01: Train Epoch 16: 463/634 Loss: 0.157440
2023-01-08 11:01: Train Epoch 16: 467/634 Loss: 0.190123
2023-01-08 11:02: Train Epoch 16: 471/634 Loss: 0.162304
2023-01-08 11:02: Train Epoch 16: 475/634 Loss: 0.163043
2023-01-08 11:02: Train Epoch 16: 479/634 Loss: 0.167731
2023-01-08 11:02: Train Epoch 16: 483/634 Loss: 0.152381
2023-01-08 11:03: Train Epoch 16: 487/634 Loss: 0.152355
2023-01-08 11:03: Train Epoch 16: 491/634 Loss: 0.181442
2023-01-08 11:03: Train Epoch 16: 495/634 Loss: 0.205765
2023-01-08 11:03: Train Epoch 16: 499/634 Loss: 0.166493
2023-01-08 11:04: Train Epoch 16: 503/634 Loss: 0.146510
2023-01-08 11:04: Train Epoch 16: 507/634 Loss: 0.223719
2023-01-08 11:04: Train Epoch 16: 511/634 Loss: 0.178563
2023-01-08 11:04: Train Epoch 16: 515/634 Loss: 0.174076
2023-01-08 11:05: Train Epoch 16: 519/634 Loss: 0.172139
2023-01-08 11:05: Train Epoch 16: 523/634 Loss: 0.159945
2023-01-08 11:05: Train Epoch 16: 527/634 Loss: 0.165603
2023-01-08 11:05: Train Epoch 16: 531/634 Loss: 0.190507
2023-01-08 11:06: Train Epoch 16: 535/634 Loss: 0.185627
2023-01-08 11:06: Train Epoch 16: 539/634 Loss: 0.185868
2023-01-08 11:06: Train Epoch 16: 543/634 Loss: 0.145949
2023-01-08 11:06: Train Epoch 16: 547/634 Loss: 0.166521
2023-01-08 11:07: Train Epoch 16: 551/634 Loss: 0.174564
2023-01-08 11:07: Train Epoch 16: 555/634 Loss: 0.173882
2023-01-08 11:07: Train Epoch 16: 559/634 Loss: 0.152612
2023-01-08 11:07: Train Epoch 16: 563/634 Loss: 0.196453
2023-01-08 11:08: Train Epoch 16: 567/634 Loss: 0.148822
2023-01-08 11:08: Train Epoch 16: 571/634 Loss: 0.165265
2023-01-08 11:08: Train Epoch 16: 575/634 Loss: 0.179317
2023-01-08 11:08: Train Epoch 16: 579/634 Loss: 0.153158
2023-01-08 11:09: Train Epoch 16: 583/634 Loss: 0.151655
2023-01-08 11:09: Train Epoch 16: 587/634 Loss: 0.179799
2023-01-08 11:09: Train Epoch 16: 591/634 Loss: 0.172628
2023-01-08 11:09: Train Epoch 16: 595/634 Loss: 0.163111
2023-01-08 11:09: Train Epoch 16: 599/634 Loss: 0.169493
2023-01-08 11:10: Train Epoch 16: 603/634 Loss: 0.195216
2023-01-08 11:10: Train Epoch 16: 607/634 Loss: 0.182839
2023-01-08 11:10: Train Epoch 16: 611/634 Loss: 0.170110
2023-01-08 11:10: Train Epoch 16: 615/634 Loss: 0.166988
2023-01-08 11:11: Train Epoch 16: 619/634 Loss: 0.148263
2023-01-08 11:11: Train Epoch 16: 623/634 Loss: 0.155627
2023-01-08 11:11: Train Epoch 16: 627/634 Loss: 0.168780
2023-01-08 11:11: Train Epoch 16: 631/634 Loss: 0.156094
2023-01-08 11:11: Train Epoch 16: 633/634 Loss: 0.071041
2023-01-08 11:11: **********Train Epoch 16: averaged Loss: 0.168611 
2023-01-08 11:11: 
Epoch time elapsed: 2301.7300872802734

2023-01-08 11:13: 
 metrics validation: {'precision': 0.9446870451237264, 'recall': 0.49923076923076926, 'f1-score': 0.6532460996477101, 'support': 1300, 'AUC': 0.9345718934911241, 'AUCPR': 0.8806181748170681, 'TP': 649, 'FP': 38, 'TN': 2562, 'FN': 651} 

2023-01-08 11:13: **********Val Epoch 16: average Loss: 0.206339
2023-01-08 11:13: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-08 11:13: Total training time: 688.5026min, best loss: 0.152977
2023-01-08 11:13: Saving current best model to /home/joel.chacon/tmp/Graphs/WildFire_GCN/experiments/2020/2023010723443607695754013/best_model.pth
2023-01-08 11:14: 
 Testing metrics {'precision': 0.8554729011689692, 'recall': 0.6555374592833876, 'f1-score': 0.7422775472568004, 'support': 1228, 'AUC': 0.9273082473023586, 'AUCPR': 0.8762869647794839, 'TP': 805, 'FP': 136, 'TN': 2320, 'FN': 423} 

2023-01-08 11:18: 
 Testing metrics {'precision': 0.9152930402930403, 'recall': 0.9071931018833673, 'f1-score': 0.9112250712250712, 'support': 4407, 'AUC': 0.978818521022597, 'AUCPR': 0.9602996066645514, 'TP': 3998, 'FP': 370, 'TN': 8444, 'FN': 409} 

