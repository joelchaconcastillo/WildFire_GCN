/home/joel.chacon/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
2022-12-18 16:31: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221218163151
2022-12-18 16:31: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221218163151
2022-12-18 16:31: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=50, epochs=30, gamma=1.0, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221218163151', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.3, lr_decay_step='10, 15, 20, 25', lr_init=0.003, mae_thresh=None, mape_thresh=0.0, max_grad_norm=5, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=64, seed=1992, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, test_ratio=0.2, val_ratio=0.2, weight_decay=0.01, window_len=10)
2022-12-18 16:31: Argument batch_size: 256
2022-12-18 16:31: Argument clc: 'vec'
2022-12-18 16:31: Argument cuda: True
2022-12-18 16:31: Argument dataset: '2020'
2022-12-18 16:31: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-18 16:31: Argument debug: False
2022-12-18 16:31: Argument default_graph: True
2022-12-18 16:31: Argument device: 'cpu'
2022-12-18 16:31: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-18 16:31: Argument early_stop: True
2022-12-18 16:31: Argument early_stop_patience: 8
2022-12-18 16:31: Argument embed_dim: 50
2022-12-18 16:31: Argument epochs: 30
2022-12-18 16:31: Argument gamma: 1.0
2022-12-18 16:31: Argument grad_norm: False
2022-12-18 16:31: Argument horizon: 1
2022-12-18 16:31: Argument input_dim: 25
2022-12-18 16:31: Argument lag: 10
2022-12-18 16:31: Argument link_len: 2
2022-12-18 16:31: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221218163151'
2022-12-18 16:31: Argument log_step: 1
2022-12-18 16:31: Argument loss_func: 'nllloss'
2022-12-18 16:31: Argument lr_decay: True
2022-12-18 16:31: Argument lr_decay_rate: 0.3
2022-12-18 16:31: Argument lr_decay_step: '10, 15, 20, 25'
2022-12-18 16:31: Argument lr_init: 0.003
2022-12-18 16:31: Argument mae_thresh: None
2022-12-18 16:31: Argument mape_thresh: 0.0
2022-12-18 16:31: Argument max_grad_norm: 5
2022-12-18 16:31: Argument mode: 'train'
2022-12-18 16:31: Argument model: 'fire_GCN'
2022-12-18 16:31: Argument nan_fill: 0.5
2022-12-18 16:31: Argument num_layers: 1
2022-12-18 16:31: Argument num_nodes: 625
2022-12-18 16:31: Argument num_workers: 12
2022-12-18 16:31: Argument output_dim: 2
2022-12-18 16:31: Argument patch_height: 25
2022-12-18 16:31: Argument patch_width: 25
2022-12-18 16:31: Argument persistent_workers: True
2022-12-18 16:31: Argument pin_memory: True
2022-12-18 16:31: Argument plot: False
2022-12-18 16:31: Argument positive_weight: 0.5
2022-12-18 16:31: Argument prefetch_factor: 2
2022-12-18 16:31: Argument real_value: True
2022-12-18 16:31: Argument rnn_units: 64
2022-12-18 16:31: Argument seed: 1992
2022-12-18 16:31: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-18 16:31: Argument teacher_forcing: False
2022-12-18 16:31: Argument test_ratio: 0.2
2022-12-18 16:31: Argument val_ratio: 0.2
2022-12-18 16:31: Argument weight_decay: 0.01
2022-12-18 16:31: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 50]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([50, 2, 89, 64]) True
encoder.cell_list.0.gate.weights_window torch.Size([50, 1, 64]) True
encoder.cell_list.0.gate.bias_pool torch.Size([50, 128]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.gate.cnn.features.0.weight torch.Size([8, 1, 3, 3]) True
encoder.cell_list.0.gate.cnn.features.0.bias torch.Size([8]) True
encoder.cell_list.0.gate.cnn.features.3.weight torch.Size([64, 8, 3, 3]) True
encoder.cell_list.0.gate.cnn.features.3.bias torch.Size([64]) True
encoder.cell_list.0.update.weights_pool torch.Size([50, 2, 89, 32]) True
encoder.cell_list.0.update.weights_window torch.Size([50, 1, 32]) True
encoder.cell_list.0.update.bias_pool torch.Size([50, 64]) True
encoder.cell_list.0.update.T torch.Size([10]) True
encoder.cell_list.0.update.cnn.features.0.weight torch.Size([8, 1, 3, 3]) True
encoder.cell_list.0.update.cnn.features.0.bias torch.Size([8]) True
encoder.cell_list.0.update.cnn.features.3.weight torch.Size([32, 8, 3, 3]) True
encoder.cell_list.0.update.cnn.features.3.bias torch.Size([32]) True
end_conv.weight torch.Size([2, 1, 625, 64]) True
end_conv.bias torch.Size([2]) True
Total params num: 987290
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221218163151/run.log
2022-12-18 16:32: Train Epoch 1: 0/159 Loss: 0.749898
2022-12-18 16:38: Train Epoch 1: 1/159 Loss: 25.942617
2022-12-18 16:38: Train Epoch 1: 2/159 Loss: 16.293940
2022-12-18 16:39: Train Epoch 1: 3/159 Loss: 1.080029
2022-12-18 16:40: Train Epoch 1: 4/159 Loss: 28.929909
2022-12-18 16:40: Train Epoch 1: 5/159 Loss: 21.632919
2022-12-18 16:41: Train Epoch 1: 6/159 Loss: 9.085131
2022-12-18 16:41: Train Epoch 1: 7/159 Loss: 4.416453
2022-12-18 16:42: Train Epoch 1: 8/159 Loss: 8.558764
2022-12-18 16:42: Train Epoch 1: 9/159 Loss: 9.957477
2022-12-18 16:43: Train Epoch 1: 10/159 Loss: 9.327469
2022-12-18 16:43: Train Epoch 1: 11/159 Loss: 6.219172
2022-12-18 16:44: Train Epoch 1: 12/159 Loss: 1.566095
2022-12-18 16:44: Train Epoch 1: 13/159 Loss: 6.587301
2022-12-18 16:44: Train Epoch 1: 14/159 Loss: 9.190121
2022-12-18 16:45: Train Epoch 1: 15/159 Loss: 6.859452
2022-12-18 16:45: Train Epoch 1: 16/159 Loss: 1.587290
2022-12-18 16:46: Train Epoch 1: 17/159 Loss: 1.971039
2022-12-18 16:46: Train Epoch 1: 18/159 Loss: 3.522469
2022-12-18 16:46: Train Epoch 1: 19/159 Loss: 4.219979
2022-12-18 16:47: Train Epoch 1: 20/159 Loss: 4.116140
2022-12-18 16:47: Train Epoch 1: 21/159 Loss: 3.275733
2022-12-18 16:47: Train Epoch 1: 22/159 Loss: 2.923275
2022-12-18 16:48: Train Epoch 1: 23/159 Loss: 1.864082
2022-12-18 16:48: Train Epoch 1: 24/159 Loss: 0.568228
2022-12-18 16:49: Train Epoch 1: 25/159 Loss: 2.525731
2022-12-18 16:49: Train Epoch 1: 26/159 Loss: 2.879741
2022-12-18 16:49: Train Epoch 1: 27/159 Loss: 2.076191
2022-12-18 16:50: Train Epoch 1: 28/159 Loss: 0.695349
2022-12-18 16:50: Train Epoch 1: 29/159 Loss: 0.616116
2022-12-18 16:51: Train Epoch 1: 30/159 Loss: 1.141611
2022-12-18 16:51: Train Epoch 1: 31/159 Loss: 1.318483
2022-12-18 16:51: Train Epoch 1: 32/159 Loss: 1.182115
2022-12-18 16:52: Train Epoch 1: 33/159 Loss: 1.184145
2022-12-18 16:52: Train Epoch 1: 34/159 Loss: 0.815152
2022-12-18 16:53: Train Epoch 1: 35/159 Loss: 0.566517
2022-12-18 16:53: Train Epoch 1: 36/159 Loss: 0.455890
2022-12-18 16:53: Train Epoch 1: 37/159 Loss: 0.622925
2022-12-18 16:54: Train Epoch 1: 38/159 Loss: 0.889968
2022-12-18 16:54: Train Epoch 1: 39/159 Loss: 0.791222
2022-12-18 16:54: Train Epoch 1: 40/159 Loss: 0.677098
2022-12-18 16:55: Train Epoch 1: 41/159 Loss: 0.470059
2022-12-18 16:55: Train Epoch 1: 42/159 Loss: 0.418478
2022-12-18 16:56: Train Epoch 1: 43/159 Loss: 0.528695
2022-12-18 16:56: Train Epoch 1: 44/159 Loss: 0.587043
2022-12-18 16:56: Train Epoch 1: 45/159 Loss: 0.518414
2022-12-18 16:57: Train Epoch 1: 46/159 Loss: 0.520193
2022-12-18 16:57: Train Epoch 1: 47/159 Loss: 0.576544
2022-12-18 16:58: Train Epoch 1: 48/159 Loss: 0.394616
2022-12-18 16:58: Train Epoch 1: 49/159 Loss: 0.407131
2022-12-18 16:58: Train Epoch 1: 50/159 Loss: 0.358670
2022-12-18 16:59: Train Epoch 1: 51/159 Loss: 0.418141
2022-12-18 16:59: Train Epoch 1: 52/159 Loss: 0.391145
2022-12-18 17:00: Train Epoch 1: 53/159 Loss: 0.414572
2022-12-18 17:00: Train Epoch 1: 54/159 Loss: 0.456575
2022-12-18 17:00: Train Epoch 1: 55/159 Loss: 0.435245
2022-12-18 17:01: Train Epoch 1: 56/159 Loss: 0.352196
2022-12-18 17:01: Train Epoch 1: 57/159 Loss: 0.302674
2022-12-18 17:02: Train Epoch 1: 58/159 Loss: 0.353723
2022-12-18 17:02: Train Epoch 1: 59/159 Loss: 0.374021
2022-12-18 17:02: Train Epoch 1: 60/159 Loss: 0.359105
2022-12-18 17:03: Train Epoch 1: 61/159 Loss: 0.364627
2022-12-18 17:03: Train Epoch 1: 62/159 Loss: 0.418798
2022-12-18 17:04: Train Epoch 1: 63/159 Loss: 0.365175
2022-12-18 17:04: Train Epoch 1: 64/159 Loss: 0.432059
2022-12-18 17:04: Train Epoch 1: 65/159 Loss: 0.355225
2022-12-18 17:05: Train Epoch 1: 66/159 Loss: 0.382559
2022-12-18 17:05: Train Epoch 1: 67/159 Loss: 0.334851
2022-12-18 17:05: Train Epoch 1: 68/159 Loss: 0.354297
2022-12-18 17:06: Train Epoch 1: 69/159 Loss: 0.353190
2022-12-18 17:06: Train Epoch 1: 70/159 Loss: 0.346179
2022-12-18 17:07: Train Epoch 1: 71/159 Loss: 0.319927
2022-12-18 17:07: Train Epoch 1: 72/159 Loss: 0.357846
2022-12-18 17:07: Train Epoch 1: 73/159 Loss: 0.349898
2022-12-18 17:08: Train Epoch 1: 74/159 Loss: 0.327139
2022-12-18 17:08: Train Epoch 1: 75/159 Loss: 0.360658
2022-12-18 17:09: Train Epoch 1: 76/159 Loss: 0.388856
2022-12-18 17:09: Train Epoch 1: 77/159 Loss: 0.330537
2022-12-18 17:09: Train Epoch 1: 78/159 Loss: 0.335642
2022-12-18 17:10: Train Epoch 1: 79/159 Loss: 0.342677
2022-12-18 17:10: Train Epoch 1: 80/159 Loss: 0.294963
2022-12-18 17:11: Train Epoch 1: 81/159 Loss: 0.377933
2022-12-18 17:11: Train Epoch 1: 82/159 Loss: 0.317961
2022-12-18 17:11: Train Epoch 1: 83/159 Loss: 0.275443
2022-12-18 17:12: Train Epoch 1: 84/159 Loss: 0.392436
2022-12-18 17:12: Train Epoch 1: 85/159 Loss: 0.379517
2022-12-18 17:12: Train Epoch 1: 86/159 Loss: 0.310658
2022-12-18 17:13: Train Epoch 1: 87/159 Loss: 0.297485
2022-12-18 17:13: Train Epoch 1: 88/159 Loss: 0.391398
2022-12-18 17:14: Train Epoch 1: 89/159 Loss: 0.306144
2022-12-18 17:14: Train Epoch 1: 90/159 Loss: 0.296512
2022-12-18 17:14: Train Epoch 1: 91/159 Loss: 0.275263
2022-12-18 17:15: Train Epoch 1: 92/159 Loss: 0.341294
2022-12-18 17:15: Train Epoch 1: 93/159 Loss: 0.327931
2022-12-18 17:16: Train Epoch 1: 94/159 Loss: 0.315261
2022-12-18 17:16: Train Epoch 1: 95/159 Loss: 0.280359
2022-12-18 17:16: Train Epoch 1: 96/159 Loss: 0.258263
2022-12-18 17:17: Train Epoch 1: 97/159 Loss: 0.309268
2022-12-18 17:17: Train Epoch 1: 98/159 Loss: 0.304673
2022-12-18 17:18: Train Epoch 1: 99/159 Loss: 0.271997
2022-12-18 17:18: Train Epoch 1: 100/159 Loss: 0.302603
2022-12-18 17:18: Train Epoch 1: 101/159 Loss: 0.328400
2022-12-18 17:19: Train Epoch 1: 102/159 Loss: 0.329246
2022-12-18 17:19: Train Epoch 1: 103/159 Loss: 0.296861
2022-12-18 17:19: Train Epoch 1: 104/159 Loss: 0.287916
2022-12-18 17:20: Train Epoch 1: 105/159 Loss: 0.278990
2022-12-18 17:20: Train Epoch 1: 106/159 Loss: 0.335797
2022-12-18 17:21: Train Epoch 1: 107/159 Loss: 0.306546
2022-12-18 17:21: Train Epoch 1: 108/159 Loss: 0.324933
2022-12-18 17:21: Train Epoch 1: 109/159 Loss: 0.255513
2022-12-18 17:22: Train Epoch 1: 110/159 Loss: 0.295619
2022-12-18 17:22: Train Epoch 1: 111/159 Loss: 0.290852
2022-12-18 17:23: Train Epoch 1: 112/159 Loss: 0.309051
2022-12-18 17:23: Train Epoch 1: 113/159 Loss: 0.307270
2022-12-18 17:23: Train Epoch 1: 114/159 Loss: 0.220227
2022-12-18 17:24: Train Epoch 1: 115/159 Loss: 0.247702
2022-12-18 17:24: Train Epoch 1: 116/159 Loss: 0.333786
2022-12-18 17:24: Train Epoch 1: 117/159 Loss: 0.362533
2022-12-18 17:25: Train Epoch 1: 118/159 Loss: 0.270579
2022-12-18 17:25: Train Epoch 1: 119/159 Loss: 0.291064
2022-12-18 17:26: Train Epoch 1: 120/159 Loss: 0.337977
2022-12-18 17:26: Train Epoch 1: 121/159 Loss: 0.411778
2022-12-18 17:27: Train Epoch 1: 122/159 Loss: 0.310783
2022-12-18 17:27: Train Epoch 1: 123/159 Loss: 0.400242
2022-12-18 17:27: Train Epoch 1: 124/159 Loss: 0.278295
2022-12-18 17:28: Train Epoch 1: 125/159 Loss: 0.263811
2022-12-18 17:28: Train Epoch 1: 126/159 Loss: 0.244415
2022-12-18 17:29: Train Epoch 1: 127/159 Loss: 0.358105
2022-12-18 17:29: Train Epoch 1: 128/159 Loss: 0.297781
2022-12-18 17:29: Train Epoch 1: 129/159 Loss: 0.261603
2022-12-18 17:30: Train Epoch 1: 130/159 Loss: 0.264200
2022-12-18 17:30: Train Epoch 1: 131/159 Loss: 0.369173
2022-12-18 17:31: Train Epoch 1: 132/159 Loss: 0.329683
2022-12-18 17:31: Train Epoch 1: 133/159 Loss: 0.310005
2022-12-18 17:31: Train Epoch 1: 134/159 Loss: 0.274805
2022-12-18 17:32: Train Epoch 1: 135/159 Loss: 0.251843
2022-12-18 17:32: Train Epoch 1: 136/159 Loss: 0.270106
2022-12-18 17:32: Train Epoch 1: 137/159 Loss: 0.309975
2022-12-18 17:33: Train Epoch 1: 138/159 Loss: 0.326097
2022-12-18 17:33: Train Epoch 1: 139/159 Loss: 0.320807
2022-12-18 17:34: Train Epoch 1: 140/159 Loss: 0.237599
2022-12-18 17:34: Train Epoch 1: 141/159 Loss: 0.321470
2022-12-18 17:34: Train Epoch 1: 142/159 Loss: 0.229752
2022-12-18 17:35: Train Epoch 1: 143/159 Loss: 0.280230
2022-12-18 17:35: Train Epoch 1: 144/159 Loss: 0.314643
2022-12-18 17:35: Train Epoch 1: 145/159 Loss: 0.315666
2022-12-18 17:36: Train Epoch 1: 146/159 Loss: 0.324299
2022-12-18 17:36: Train Epoch 1: 147/159 Loss: 0.297022
2022-12-18 17:37: Train Epoch 1: 148/159 Loss: 0.310550
2022-12-18 17:37: Train Epoch 1: 149/159 Loss: 0.334046
2022-12-18 17:37: Train Epoch 1: 150/159 Loss: 0.308626
2022-12-18 17:38: Train Epoch 1: 151/159 Loss: 0.275135
2022-12-18 17:38: Train Epoch 1: 152/159 Loss: 0.311879
2022-12-18 17:39: Train Epoch 1: 153/159 Loss: 0.313926
2022-12-18 17:39: Train Epoch 1: 154/159 Loss: 0.336351
2022-12-18 17:39: Train Epoch 1: 155/159 Loss: 0.326698
2022-12-18 17:40: Train Epoch 1: 156/159 Loss: 0.335264
2022-12-18 17:40: Train Epoch 1: 157/159 Loss: 0.354499
2022-12-18 17:40: Train Epoch 1: 158/159 Loss: 0.217260
2022-12-18 17:40: **********Train Epoch 1: averaged Loss: 1.563379 
2022-12-18 17:40: 
Epoch time elapsed: 4140.079160451889

2022-12-18 17:42: 
 metrics validation: {'precision': 0.7914893617021277, 'recall': 0.5723076923076923, 'f1-score': 0.6642857142857141, 'support': 1300, 'AUC': 0.8275147928994083, 'AUCPR': 0.7410993389217684, 'TP': 744, 'FP': 196, 'TN': 2404, 'FN': 556} 

2022-12-18 17:42: **********Val Epoch 1: average Loss: 0.559661
2022-12-18 17:42: *********************************Current best model saved!
2022-12-18 17:42: Train Epoch 2: 0/159 Loss: 0.337762
2022-12-18 17:43: Train Epoch 2: 1/159 Loss: 0.279070
2022-12-18 17:43: Train Epoch 2: 2/159 Loss: 0.314266
2022-12-18 17:43: Train Epoch 2: 3/159 Loss: 0.357144
2022-12-18 17:44: Train Epoch 2: 4/159 Loss: 0.317779
2022-12-18 17:44: Train Epoch 2: 5/159 Loss: 0.267841
2022-12-18 17:44: Train Epoch 2: 6/159 Loss: 0.270881
2022-12-18 17:45: Train Epoch 2: 7/159 Loss: 0.280031
2022-12-18 17:45: Train Epoch 2: 8/159 Loss: 0.315898
2022-12-18 17:46: Train Epoch 2: 9/159 Loss: 0.314523
2022-12-18 17:46: Train Epoch 2: 10/159 Loss: 0.308873
2022-12-18 17:46: Train Epoch 2: 11/159 Loss: 0.341728
2022-12-18 17:47: Train Epoch 2: 12/159 Loss: 0.294703
2022-12-18 17:47: Train Epoch 2: 13/159 Loss: 0.338819
2022-12-18 17:47: Train Epoch 2: 14/159 Loss: 0.290262
2022-12-18 17:48: Train Epoch 2: 15/159 Loss: 0.259565
2022-12-18 17:48: Train Epoch 2: 16/159 Loss: 0.259020
2022-12-18 17:49: Train Epoch 2: 17/159 Loss: 0.397670
2022-12-18 17:49: Train Epoch 2: 18/159 Loss: 0.246985
2022-12-18 17:49: Train Epoch 2: 19/159 Loss: 0.311336
2022-12-18 17:50: Train Epoch 2: 20/159 Loss: 0.305061
2022-12-18 17:50: Train Epoch 2: 21/159 Loss: 0.350969
2022-12-18 17:50: Train Epoch 2: 22/159 Loss: 0.273165
2022-12-18 17:51: Train Epoch 2: 23/159 Loss: 0.323875
2022-12-18 17:51: Train Epoch 2: 24/159 Loss: 0.384417
2022-12-18 17:52: Train Epoch 2: 25/159 Loss: 0.269812
2022-12-18 17:52: Train Epoch 2: 26/159 Loss: 0.282175
2022-12-18 17:52: Train Epoch 2: 27/159 Loss: 0.308772
2022-12-18 17:53: Train Epoch 2: 28/159 Loss: 0.332872
2022-12-18 17:53: Train Epoch 2: 29/159 Loss: 0.286827
2022-12-18 17:53: Train Epoch 2: 30/159 Loss: 0.288744
2022-12-18 17:54: Train Epoch 2: 31/159 Loss: 0.275213
2022-12-18 17:54: Train Epoch 2: 32/159 Loss: 0.278650
2022-12-18 17:55: Train Epoch 2: 33/159 Loss: 0.300382
2022-12-18 17:55: Train Epoch 2: 34/159 Loss: 0.228990
2022-12-18 17:55: Train Epoch 2: 35/159 Loss: 0.321412
2022-12-18 17:56: Train Epoch 2: 36/159 Loss: 0.313057
2022-12-18 17:56: Train Epoch 2: 37/159 Loss: 0.267243
2022-12-18 17:56: Train Epoch 2: 38/159 Loss: 0.296324
2022-12-18 17:57: Train Epoch 2: 39/159 Loss: 0.283958
2022-12-18 17:57: Train Epoch 2: 40/159 Loss: 0.255858
2022-12-18 17:58: Train Epoch 2: 41/159 Loss: 0.290836
2022-12-18 17:58: Train Epoch 2: 42/159 Loss: 0.273825
2022-12-18 17:58: Train Epoch 2: 43/159 Loss: 0.320570
2022-12-18 17:59: Train Epoch 2: 44/159 Loss: 0.330381
2022-12-18 17:59: Train Epoch 2: 45/159 Loss: 0.224425
2022-12-18 17:59: Train Epoch 2: 46/159 Loss: 0.319900
2022-12-18 18:00: Train Epoch 2: 47/159 Loss: 0.289380
2022-12-18 18:00: Train Epoch 2: 48/159 Loss: 0.270015
2022-12-18 18:01: Train Epoch 2: 49/159 Loss: 0.339417
2022-12-18 18:01: Train Epoch 2: 50/159 Loss: 0.326108
2022-12-18 18:01: Train Epoch 2: 51/159 Loss: 0.306775
2022-12-18 18:02: Train Epoch 2: 52/159 Loss: 0.310096
2022-12-18 18:02: Train Epoch 2: 53/159 Loss: 0.283729
2022-12-18 18:02: Train Epoch 2: 54/159 Loss: 0.358334
2022-12-18 18:03: Train Epoch 2: 55/159 Loss: 0.271034
2022-12-18 18:03: Train Epoch 2: 56/159 Loss: 0.270397
2022-12-18 18:04: Train Epoch 2: 57/159 Loss: 0.295067
2022-12-18 18:04: Train Epoch 2: 58/159 Loss: 0.329274
2022-12-18 18:04: Train Epoch 2: 59/159 Loss: 0.316329
2022-12-18 18:05: Train Epoch 2: 60/159 Loss: 0.333307
2022-12-18 18:05: Train Epoch 2: 61/159 Loss: 0.341179
2022-12-18 18:05: Train Epoch 2: 62/159 Loss: 0.301592
2022-12-18 18:06: Train Epoch 2: 63/159 Loss: 0.325935
2022-12-18 18:06: Train Epoch 2: 64/159 Loss: 0.368237
2022-12-18 18:07: Train Epoch 2: 65/159 Loss: 0.269826
2022-12-18 18:07: Train Epoch 2: 66/159 Loss: 0.280617
2022-12-18 18:07: Train Epoch 2: 67/159 Loss: 0.297125
2022-12-18 18:08: Train Epoch 2: 68/159 Loss: 0.291876
2022-12-18 18:08: Train Epoch 2: 69/159 Loss: 0.288520
2022-12-18 18:08: Train Epoch 2: 70/159 Loss: 0.316435
2022-12-18 18:09: Train Epoch 2: 71/159 Loss: 0.283216
2022-12-18 18:09: Train Epoch 2: 72/159 Loss: 0.306066
2022-12-18 18:10: Train Epoch 2: 73/159 Loss: 0.310729
2022-12-18 18:10: Train Epoch 2: 74/159 Loss: 0.301589
2022-12-18 18:10: Train Epoch 2: 75/159 Loss: 0.309979
2022-12-18 18:11: Train Epoch 2: 76/159 Loss: 0.285693
2022-12-18 18:11: Train Epoch 2: 77/159 Loss: 0.284876
2022-12-18 18:12: Train Epoch 2: 78/159 Loss: 0.280589
2022-12-18 18:12: Train Epoch 2: 79/159 Loss: 0.312194
2022-12-18 18:12: Train Epoch 2: 80/159 Loss: 0.317267
2022-12-18 18:13: Train Epoch 2: 81/159 Loss: 0.252470
2022-12-18 18:13: Train Epoch 2: 82/159 Loss: 0.346210
2022-12-18 18:13: Train Epoch 2: 83/159 Loss: 0.285211
2022-12-18 18:14: Train Epoch 2: 84/159 Loss: 0.289937
2022-12-18 18:14: Train Epoch 2: 85/159 Loss: 0.290611
2022-12-18 18:14: Train Epoch 2: 86/159 Loss: 0.273099
2022-12-18 18:15: Train Epoch 2: 87/159 Loss: 0.327985
2022-12-18 18:15: Train Epoch 2: 88/159 Loss: 0.353226
2022-12-18 18:16: Train Epoch 2: 89/159 Loss: 0.364026
2022-12-18 18:16: Train Epoch 2: 90/159 Loss: 0.283742
2022-12-18 18:16: Train Epoch 2: 91/159 Loss: 0.282310
2022-12-18 18:17: Train Epoch 2: 92/159 Loss: 0.289904
2022-12-18 18:17: Train Epoch 2: 93/159 Loss: 0.334335
2022-12-18 18:18: Train Epoch 2: 94/159 Loss: 0.246875
2022-12-18 18:18: Train Epoch 2: 95/159 Loss: 0.325274
2022-12-18 18:18: Train Epoch 2: 96/159 Loss: 0.245879
2022-12-18 18:19: Train Epoch 2: 97/159 Loss: 0.291092
2022-12-18 18:19: Train Epoch 2: 98/159 Loss: 0.301002
2022-12-18 18:19: Train Epoch 2: 99/159 Loss: 0.297834
2022-12-18 18:20: Train Epoch 2: 100/159 Loss: 0.255608
2022-12-18 18:20: Train Epoch 2: 101/159 Loss: 0.350485
2022-12-18 18:21: Train Epoch 2: 102/159 Loss: 0.254097
2022-12-18 18:21: Train Epoch 2: 103/159 Loss: 0.262347
2022-12-18 18:21: Train Epoch 2: 104/159 Loss: 0.341331
2022-12-18 18:22: Train Epoch 2: 105/159 Loss: 0.303096
2022-12-18 18:22: Train Epoch 2: 106/159 Loss: 0.332733
2022-12-18 18:22: Train Epoch 2: 107/159 Loss: 0.338047
2022-12-18 18:23: Train Epoch 2: 108/159 Loss: 0.263150
2022-12-18 18:23: Train Epoch 2: 109/159 Loss: 0.256103
2022-12-18 18:24: Train Epoch 2: 110/159 Loss: 0.264124
2022-12-18 18:24: Train Epoch 2: 111/159 Loss: 0.341061
2022-12-18 18:24: Train Epoch 2: 112/159 Loss: 0.285195
2022-12-18 18:25: Train Epoch 2: 113/159 Loss: 0.315537
2022-12-18 18:25: Train Epoch 2: 114/159 Loss: 0.261437
2022-12-18 18:25: Train Epoch 2: 115/159 Loss: 0.303477
2022-12-18 18:26: Train Epoch 2: 116/159 Loss: 0.298410
2022-12-18 18:26: Train Epoch 2: 117/159 Loss: 0.293813
2022-12-18 18:27: Train Epoch 2: 118/159 Loss: 0.327572
2022-12-18 18:27: Train Epoch 2: 119/159 Loss: 0.346770
2022-12-18 18:27: Train Epoch 2: 120/159 Loss: 0.256487
2022-12-18 18:28: Train Epoch 2: 121/159 Loss: 0.256573
2022-12-18 18:28: Train Epoch 2: 122/159 Loss: 0.278805
2022-12-18 18:28: Train Epoch 2: 123/159 Loss: 0.310596
2022-12-18 18:29: Train Epoch 2: 124/159 Loss: 0.308261
2022-12-18 18:29: Train Epoch 2: 125/159 Loss: 0.343493
2022-12-18 18:30: Train Epoch 2: 126/159 Loss: 0.298272
2022-12-18 18:30: Train Epoch 2: 127/159 Loss: 0.300276
2022-12-18 18:30: Train Epoch 2: 128/159 Loss: 0.340157
2022-12-18 18:31: Train Epoch 2: 129/159 Loss: 0.260299
2022-12-18 18:31: Train Epoch 2: 130/159 Loss: 0.295088
2022-12-18 18:31: Train Epoch 2: 131/159 Loss: 0.269443
2022-12-18 18:32: Train Epoch 2: 132/159 Loss: 0.300236
2022-12-18 18:32: Train Epoch 2: 133/159 Loss: 0.287241
2022-12-18 18:33: Train Epoch 2: 134/159 Loss: 0.295198
2022-12-18 18:33: Train Epoch 2: 135/159 Loss: 0.319668
2022-12-18 18:33: Train Epoch 2: 136/159 Loss: 0.341228
2022-12-18 18:34: Train Epoch 2: 137/159 Loss: 0.350062
2022-12-18 18:34: Train Epoch 2: 138/159 Loss: 0.338415
2022-12-18 18:34: Train Epoch 2: 139/159 Loss: 0.334408
2022-12-18 18:35: Train Epoch 2: 140/159 Loss: 0.297748
2022-12-18 18:35: Train Epoch 2: 141/159 Loss: 0.334316
2022-12-18 18:35: Train Epoch 2: 142/159 Loss: 0.286623
2022-12-18 18:36: Train Epoch 2: 143/159 Loss: 0.323388
2022-12-18 18:36: Train Epoch 2: 144/159 Loss: 0.306826
2022-12-18 18:37: Train Epoch 2: 145/159 Loss: 0.312505
2022-12-18 18:37: Train Epoch 2: 146/159 Loss: 0.292022
2022-12-18 18:37: Train Epoch 2: 147/159 Loss: 0.292675
2022-12-18 18:38: Train Epoch 2: 148/159 Loss: 0.286938
2022-12-18 18:38: Train Epoch 2: 149/159 Loss: 0.289612
2022-12-18 18:38: Train Epoch 2: 150/159 Loss: 0.305987
2022-12-18 18:39: Train Epoch 2: 151/159 Loss: 0.348063
2022-12-18 18:39: Train Epoch 2: 152/159 Loss: 0.282690
2022-12-18 18:40: Train Epoch 2: 153/159 Loss: 0.319331
2022-12-18 18:40: Train Epoch 2: 154/159 Loss: 0.249024
2022-12-18 18:40: Train Epoch 2: 155/159 Loss: 0.281571
2022-12-18 18:41: Train Epoch 2: 156/159 Loss: 0.301737
2022-12-18 18:41: Train Epoch 2: 157/159 Loss: 0.251413
2022-12-18 18:41: Train Epoch 2: 158/159 Loss: 0.365994
2022-12-18 18:41: **********Train Epoch 2: averaged Loss: 0.301590 
2022-12-18 18:41: 
Epoch time elapsed: 3568.046643972397

2022-12-18 18:43: 
 metrics validation: {'precision': 0.7781818181818182, 'recall': 0.6584615384615384, 'f1-score': 0.7133333333333334, 'support': 1300, 'AUC': 0.8359440828402368, 'AUCPR': 0.7556359627332837, 'TP': 856, 'FP': 244, 'TN': 2356, 'FN': 444} 

2022-12-18 18:43: **********Val Epoch 2: average Loss: 0.519327
2022-12-18 18:43: *********************************Current best model saved!
2022-12-18 18:43: Train Epoch 3: 0/159 Loss: 0.312499
2022-12-18 18:43: Train Epoch 3: 1/159 Loss: 0.256370
2022-12-18 18:44: Train Epoch 3: 2/159 Loss: 0.348540
2022-12-18 18:44: Train Epoch 3: 3/159 Loss: 0.260934
2022-12-18 18:45: Train Epoch 3: 4/159 Loss: 0.250864
2022-12-18 18:45: Train Epoch 3: 5/159 Loss: 0.242087
2022-12-18 18:45: Train Epoch 3: 6/159 Loss: 0.299593
2022-12-18 18:46: Train Epoch 3: 7/159 Loss: 0.283711
2022-12-18 18:46: Train Epoch 3: 8/159 Loss: 0.304892
2022-12-18 18:46: Train Epoch 3: 9/159 Loss: 0.246652
2022-12-18 18:47: Train Epoch 3: 10/159 Loss: 0.262613
2022-12-18 18:47: Train Epoch 3: 11/159 Loss: 0.314836
2022-12-18 18:47: Train Epoch 3: 12/159 Loss: 0.271077
2022-12-18 18:48: Train Epoch 3: 13/159 Loss: 0.301086
2022-12-18 18:48: Train Epoch 3: 14/159 Loss: 0.270736
2022-12-18 18:49: Train Epoch 3: 15/159 Loss: 0.358973
2022-12-18 18:49: Train Epoch 3: 16/159 Loss: 0.321161
2022-12-18 18:49: Train Epoch 3: 17/159 Loss: 0.321158
2022-12-18 18:50: Train Epoch 3: 18/159 Loss: 0.365063
2022-12-18 18:50: Train Epoch 3: 19/159 Loss: 0.360870
2022-12-18 18:50: Train Epoch 3: 20/159 Loss: 0.299162
2022-12-18 18:51: Train Epoch 3: 21/159 Loss: 0.299245
2022-12-18 18:51: Train Epoch 3: 22/159 Loss: 0.314689
2022-12-18 18:52: Train Epoch 3: 23/159 Loss: 0.300465
2022-12-18 18:52: Train Epoch 3: 24/159 Loss: 0.277020
2022-12-18 18:52: Train Epoch 3: 25/159 Loss: 0.315551
2022-12-18 18:53: Train Epoch 3: 26/159 Loss: 0.272450
2022-12-18 18:53: Train Epoch 3: 27/159 Loss: 0.333052
2022-12-18 18:53: Train Epoch 3: 28/159 Loss: 0.342364
2022-12-18 18:54: Train Epoch 3: 29/159 Loss: 0.239102
2022-12-18 18:54: Train Epoch 3: 30/159 Loss: 0.298459
2022-12-18 18:55: Train Epoch 3: 31/159 Loss: 0.300354
2022-12-18 18:55: Train Epoch 3: 32/159 Loss: 0.274862
2022-12-18 18:55: Train Epoch 3: 33/159 Loss: 0.350306
2022-12-18 18:56: Train Epoch 3: 34/159 Loss: 0.331370
2022-12-18 18:56: Train Epoch 3: 35/159 Loss: 0.259753
2022-12-18 18:56: Train Epoch 3: 36/159 Loss: 0.329251
2022-12-18 18:57: Train Epoch 3: 37/159 Loss: 0.325538
2022-12-18 18:57: Train Epoch 3: 38/159 Loss: 0.293657
2022-12-18 18:58: Train Epoch 3: 39/159 Loss: 0.258403
2022-12-18 18:58: Train Epoch 3: 40/159 Loss: 0.292346
2022-12-18 18:58: Train Epoch 3: 41/159 Loss: 0.398448
2022-12-18 18:59: Train Epoch 3: 42/159 Loss: 0.267376
2022-12-18 18:59: Train Epoch 3: 43/159 Loss: 0.323072
2022-12-18 18:59: Train Epoch 3: 44/159 Loss: 0.272124
2022-12-18 19:00: Train Epoch 3: 45/159 Loss: 0.306472
2022-12-18 19:00: Train Epoch 3: 46/159 Loss: 0.328255
2022-12-18 19:01: Train Epoch 3: 47/159 Loss: 0.299811
2022-12-18 19:01: Train Epoch 3: 48/159 Loss: 0.271656
2022-12-18 19:01: Train Epoch 3: 49/159 Loss: 0.305342
2022-12-18 19:02: Train Epoch 3: 50/159 Loss: 0.366240
2022-12-18 19:02: Train Epoch 3: 51/159 Loss: 0.272943
2022-12-18 19:02: Train Epoch 3: 52/159 Loss: 0.267584
2022-12-18 19:03: Train Epoch 3: 53/159 Loss: 0.326786
2022-12-18 19:03: Train Epoch 3: 54/159 Loss: 0.261644
2022-12-18 19:04: Train Epoch 3: 55/159 Loss: 0.301690
2022-12-18 19:04: Train Epoch 3: 56/159 Loss: 0.263263
2022-12-18 19:04: Train Epoch 3: 57/159 Loss: 0.308460
2022-12-18 19:05: Train Epoch 3: 58/159 Loss: 0.301457
2022-12-18 19:05: Train Epoch 3: 59/159 Loss: 0.277920
2022-12-18 19:05: Train Epoch 3: 60/159 Loss: 0.288764
2022-12-18 19:06: Train Epoch 3: 61/159 Loss: 0.318153
2022-12-18 19:06: Train Epoch 3: 62/159 Loss: 0.300256
2022-12-18 19:07: Train Epoch 3: 63/159 Loss: 0.235359
2022-12-18 19:07: Train Epoch 3: 64/159 Loss: 0.297296
2022-12-18 19:07: Train Epoch 3: 65/159 Loss: 0.278301
2022-12-18 19:08: Train Epoch 3: 66/159 Loss: 0.268458
2022-12-18 19:08: Train Epoch 3: 67/159 Loss: 0.284229
2022-12-18 19:08: Train Epoch 3: 68/159 Loss: 0.297359
2022-12-18 19:09: Train Epoch 3: 69/159 Loss: 0.366045
2022-12-18 19:09: Train Epoch 3: 70/159 Loss: 0.277465
2022-12-18 19:10: Train Epoch 3: 71/159 Loss: 0.222239
2022-12-18 19:10: Train Epoch 3: 72/159 Loss: 0.286202
2022-12-18 19:10: Train Epoch 3: 73/159 Loss: 0.253786
2022-12-18 19:11: Train Epoch 3: 74/159 Loss: 0.297008
2022-12-18 19:11: Train Epoch 3: 75/159 Loss: 0.265435
2022-12-18 19:11: Train Epoch 3: 76/159 Loss: 0.285538
2022-12-18 19:12: Train Epoch 3: 77/159 Loss: 0.335605
2022-12-18 19:12: Train Epoch 3: 78/159 Loss: 0.313730
2022-12-18 19:13: Train Epoch 3: 79/159 Loss: 0.258405
2022-12-18 19:13: Train Epoch 3: 80/159 Loss: 0.279524
2022-12-18 19:13: Train Epoch 3: 81/159 Loss: 0.357170
2022-12-18 19:14: Train Epoch 3: 82/159 Loss: 0.269273
2022-12-18 19:14: Train Epoch 3: 83/159 Loss: 0.270317
2022-12-18 19:14: Train Epoch 3: 84/159 Loss: 0.292641
2022-12-18 19:15: Train Epoch 3: 85/159 Loss: 0.282770
2022-12-18 19:15: Train Epoch 3: 86/159 Loss: 0.306660
2022-12-18 19:16: Train Epoch 3: 87/159 Loss: 0.272428
2022-12-18 19:16: Train Epoch 3: 88/159 Loss: 0.340924
2022-12-18 19:16: Train Epoch 3: 89/159 Loss: 0.269645
2022-12-18 19:17: Train Epoch 3: 90/159 Loss: 0.331929
2022-12-18 19:17: Train Epoch 3: 91/159 Loss: 0.279596
2022-12-18 19:17: Train Epoch 3: 92/159 Loss: 0.345913
2022-12-18 19:18: Train Epoch 3: 93/159 Loss: 0.247771
2022-12-18 19:18: Train Epoch 3: 94/159 Loss: 0.325510
2022-12-18 19:19: Train Epoch 3: 95/159 Loss: 0.303207
2022-12-18 19:19: Train Epoch 3: 96/159 Loss: 0.293265
2022-12-18 19:19: Train Epoch 3: 97/159 Loss: 0.300503
2022-12-18 19:20: Train Epoch 3: 98/159 Loss: 0.250954
2022-12-18 19:20: Train Epoch 3: 99/159 Loss: 0.363515
2022-12-18 19:20: Train Epoch 3: 100/159 Loss: 0.317414
2022-12-18 19:21: Train Epoch 3: 101/159 Loss: 0.230825
2022-12-18 19:21: Train Epoch 3: 102/159 Loss: 0.326859
2022-12-18 19:22: Train Epoch 3: 103/159 Loss: 0.288258
2022-12-18 19:22: Train Epoch 3: 104/159 Loss: 0.324439
2022-12-18 19:22: Train Epoch 3: 105/159 Loss: 0.316781
2022-12-18 19:23: Train Epoch 3: 106/159 Loss: 0.308279
2022-12-18 19:23: Train Epoch 3: 107/159 Loss: 0.291316
2022-12-18 19:23: Train Epoch 3: 108/159 Loss: 0.255967
2022-12-18 19:24: Train Epoch 3: 109/159 Loss: 0.332349
2022-12-18 19:24: Train Epoch 3: 110/159 Loss: 0.325831
2022-12-18 19:25: Train Epoch 3: 111/159 Loss: 0.344632
2022-12-18 19:25: Train Epoch 3: 112/159 Loss: 0.237494
2022-12-18 19:25: Train Epoch 3: 113/159 Loss: 0.276985
2022-12-18 19:26: Train Epoch 3: 114/159 Loss: 0.243176
2022-12-18 19:26: Train Epoch 3: 115/159 Loss: 0.295660
2022-12-18 19:26: Train Epoch 3: 116/159 Loss: 0.329948
2022-12-18 19:27: Train Epoch 3: 117/159 Loss: 0.276448
2022-12-18 19:27: Train Epoch 3: 118/159 Loss: 0.279239
2022-12-18 19:28: Train Epoch 3: 119/159 Loss: 0.301456
2022-12-18 19:28: Train Epoch 3: 120/159 Loss: 0.302522
2022-12-18 19:28: Train Epoch 3: 121/159 Loss: 0.301418
2022-12-18 19:29: Train Epoch 3: 122/159 Loss: 0.323002
2022-12-18 19:29: Train Epoch 3: 123/159 Loss: 0.287548
2022-12-18 19:29: Train Epoch 3: 124/159 Loss: 0.320198
2022-12-18 19:30: Train Epoch 3: 125/159 Loss: 0.324348
2022-12-18 19:30: Train Epoch 3: 126/159 Loss: 0.309552
2022-12-18 19:31: Train Epoch 3: 127/159 Loss: 0.265201
2022-12-18 19:31: Train Epoch 3: 128/159 Loss: 0.341262
2022-12-18 19:31: Train Epoch 3: 129/159 Loss: 0.329337
2022-12-18 19:32: Train Epoch 3: 130/159 Loss: 0.343949
2022-12-18 19:32: Train Epoch 3: 131/159 Loss: 0.301756
2022-12-18 19:32: Train Epoch 3: 132/159 Loss: 0.273094
2022-12-18 19:33: Train Epoch 3: 133/159 Loss: 0.331402
2022-12-18 19:33: Train Epoch 3: 134/159 Loss: 0.256485
2022-12-18 19:34: Train Epoch 3: 135/159 Loss: 0.269684
2022-12-18 19:34: Train Epoch 3: 136/159 Loss: 0.301967
2022-12-18 19:34: Train Epoch 3: 137/159 Loss: 0.249931
2022-12-18 19:35: Train Epoch 3: 138/159 Loss: 0.257400
2022-12-18 19:35: Train Epoch 3: 139/159 Loss: 0.300248
2022-12-18 19:35: Train Epoch 3: 140/159 Loss: 0.278753
2022-12-18 19:36: Train Epoch 3: 141/159 Loss: 0.324264
2022-12-18 19:36: Train Epoch 3: 142/159 Loss: 0.321084
2022-12-18 19:37: Train Epoch 3: 143/159 Loss: 0.325378
2022-12-18 19:37: Train Epoch 3: 144/159 Loss: 0.314679
2022-12-18 19:37: Train Epoch 3: 145/159 Loss: 0.280015
2022-12-18 19:38: Train Epoch 3: 146/159 Loss: 0.296136
2022-12-18 19:38: Train Epoch 3: 147/159 Loss: 0.264958
2022-12-18 19:38: Train Epoch 3: 148/159 Loss: 0.337697
2022-12-18 19:39: Train Epoch 3: 149/159 Loss: 0.288330
2022-12-18 19:39: Train Epoch 3: 150/159 Loss: 0.331855
2022-12-18 19:40: Train Epoch 3: 151/159 Loss: 0.275736
2022-12-18 19:40: Train Epoch 3: 152/159 Loss: 0.269413
2022-12-18 19:40: Train Epoch 3: 153/159 Loss: 0.305579
2022-12-18 19:41: Train Epoch 3: 154/159 Loss: 0.267006
2022-12-18 19:41: Train Epoch 3: 155/159 Loss: 0.290547
2022-12-18 19:41: Train Epoch 3: 156/159 Loss: 0.295668
2022-12-18 19:42: Train Epoch 3: 157/159 Loss: 0.313610
2022-12-18 19:42: Train Epoch 3: 158/159 Loss: 0.359268
2022-12-18 19:42: **********Train Epoch 3: averaged Loss: 0.297663 
2022-12-18 19:42: 
Epoch time elapsed: 3558.140162706375

2022-12-18 19:43: 
 metrics validation: {'precision': 0.8121890547263682, 'recall': 0.5023076923076923, 'f1-score': 0.620722433460076, 'support': 1300, 'AUC': 0.8281547337278107, 'AUCPR': 0.7513504527247008, 'TP': 653, 'FP': 151, 'TN': 2449, 'FN': 647} 

2022-12-18 19:43: **********Val Epoch 3: average Loss: 0.585296
2022-12-18 19:44: Train Epoch 4: 0/159 Loss: 0.315843
2022-12-18 19:44: Train Epoch 4: 1/159 Loss: 0.324624
2022-12-18 19:45: Train Epoch 4: 2/159 Loss: 0.376890
2022-12-18 19:45: Train Epoch 4: 3/159 Loss: 0.318112
2022-12-18 19:45: Train Epoch 4: 4/159 Loss: 0.302228
2022-12-18 19:46: Train Epoch 4: 5/159 Loss: 0.312519
2022-12-18 19:46: Train Epoch 4: 6/159 Loss: 0.304759
2022-12-18 19:47: Train Epoch 4: 7/159 Loss: 0.324468
2022-12-18 19:47: Train Epoch 4: 8/159 Loss: 0.266517
2022-12-18 19:47: Train Epoch 4: 9/159 Loss: 0.361047
2022-12-18 19:48: Train Epoch 4: 10/159 Loss: 0.356422
2022-12-18 19:48: Train Epoch 4: 11/159 Loss: 0.322607
2022-12-18 19:48: Train Epoch 4: 12/159 Loss: 0.276970
2022-12-18 19:49: Train Epoch 4: 13/159 Loss: 0.345035
2022-12-18 19:49: Train Epoch 4: 14/159 Loss: 0.277669
2022-12-18 19:50: Train Epoch 4: 15/159 Loss: 0.304710
2022-12-18 19:50: Train Epoch 4: 16/159 Loss: 0.373944
2022-12-18 19:50: Train Epoch 4: 17/159 Loss: 0.293887
2022-12-18 19:51: Train Epoch 4: 18/159 Loss: 0.350399
2022-12-18 19:51: Train Epoch 4: 19/159 Loss: 0.337484
2022-12-18 19:51: Train Epoch 4: 20/159 Loss: 0.294143
2022-12-18 19:52: Train Epoch 4: 21/159 Loss: 0.278511
2022-12-18 19:52: Train Epoch 4: 22/159 Loss: 0.316445
2022-12-18 19:53: Train Epoch 4: 23/159 Loss: 0.312836
2022-12-18 19:53: Train Epoch 4: 24/159 Loss: 0.288437
2022-12-18 19:53: Train Epoch 4: 25/159 Loss: 0.230077
2022-12-18 19:54: Train Epoch 4: 26/159 Loss: 0.251841
2022-12-18 19:54: Train Epoch 4: 27/159 Loss: 0.313036
2022-12-18 19:54: Train Epoch 4: 28/159 Loss: 0.275982
2022-12-18 19:55: Train Epoch 4: 29/159 Loss: 0.274299
2022-12-18 19:55: Train Epoch 4: 30/159 Loss: 0.239582
2022-12-18 19:56: Train Epoch 4: 31/159 Loss: 0.281662
2022-12-18 19:56: Train Epoch 4: 32/159 Loss: 0.288595
2022-12-18 19:56: Train Epoch 4: 33/159 Loss: 0.306978
2022-12-18 19:57: Train Epoch 4: 34/159 Loss: 0.271985
2022-12-18 19:57: Train Epoch 4: 35/159 Loss: 0.314922
2022-12-18 19:57: Train Epoch 4: 36/159 Loss: 0.294818
2022-12-18 19:58: Train Epoch 4: 37/159 Loss: 0.316672
2022-12-18 19:58: Train Epoch 4: 38/159 Loss: 0.303561
2022-12-18 19:59: Train Epoch 4: 39/159 Loss: 0.264118
2022-12-18 19:59: Train Epoch 4: 40/159 Loss: 0.289076
2022-12-18 19:59: Train Epoch 4: 41/159 Loss: 0.357005
2022-12-18 20:00: Train Epoch 4: 42/159 Loss: 0.289959
2022-12-18 20:00: Train Epoch 4: 43/159 Loss: 0.326581
2022-12-18 20:00: Train Epoch 4: 44/159 Loss: 0.288157
2022-12-18 20:01: Train Epoch 4: 45/159 Loss: 0.258018
2022-12-18 20:01: Train Epoch 4: 46/159 Loss: 0.285797
2022-12-18 20:02: Train Epoch 4: 47/159 Loss: 0.270775
2022-12-18 20:02: Train Epoch 4: 48/159 Loss: 0.279608
2022-12-18 20:02: Train Epoch 4: 49/159 Loss: 0.271124
2022-12-18 20:03: Train Epoch 4: 50/159 Loss: 0.290479
2022-12-18 20:03: Train Epoch 4: 51/159 Loss: 0.316749
2022-12-18 20:03: Train Epoch 4: 52/159 Loss: 0.298039
2022-12-18 20:04: Train Epoch 4: 53/159 Loss: 0.317196
2022-12-18 20:04: Train Epoch 4: 54/159 Loss: 0.292298
2022-12-18 20:05: Train Epoch 4: 55/159 Loss: 0.318679
2022-12-18 20:05: Train Epoch 4: 56/159 Loss: 0.321178
2022-12-18 20:05: Train Epoch 4: 57/159 Loss: 0.272236
2022-12-18 20:06: Train Epoch 4: 58/159 Loss: 0.297585
2022-12-18 20:06: Train Epoch 4: 59/159 Loss: 0.301285
2022-12-18 20:06: Train Epoch 4: 60/159 Loss: 0.276054
2022-12-18 20:07: Train Epoch 4: 61/159 Loss: 0.262282
2022-12-18 20:07: Train Epoch 4: 62/159 Loss: 0.284764
2022-12-18 20:08: Train Epoch 4: 63/159 Loss: 0.283418
2022-12-18 20:08: Train Epoch 4: 64/159 Loss: 0.251553
2022-12-18 20:08: Train Epoch 4: 65/159 Loss: 0.297213
2022-12-18 20:09: Train Epoch 4: 66/159 Loss: 0.260173
2022-12-18 20:09: Train Epoch 4: 67/159 Loss: 0.349412
2022-12-18 20:09: Train Epoch 4: 68/159 Loss: 0.279941
2022-12-18 20:10: Train Epoch 4: 69/159 Loss: 0.284029
2022-12-18 20:10: Train Epoch 4: 70/159 Loss: 0.253618
2022-12-18 20:11: Train Epoch 4: 71/159 Loss: 0.333370
2022-12-18 20:11: Train Epoch 4: 72/159 Loss: 0.302555
2022-12-18 20:11: Train Epoch 4: 73/159 Loss: 0.317126
2022-12-18 20:12: Train Epoch 4: 74/159 Loss: 0.326670
2022-12-18 20:12: Train Epoch 4: 75/159 Loss: 0.327387
2022-12-18 20:12: Train Epoch 4: 76/159 Loss: 0.374004
2022-12-18 20:13: Train Epoch 4: 77/159 Loss: 0.327275
2022-12-18 20:13: Train Epoch 4: 78/159 Loss: 0.258356
2022-12-18 20:14: Train Epoch 4: 79/159 Loss: 0.304341
2022-12-18 20:14: Train Epoch 4: 80/159 Loss: 0.264456
2022-12-18 20:14: Train Epoch 4: 81/159 Loss: 0.279041
2022-12-18 20:15: Train Epoch 4: 82/159 Loss: 0.270528
2022-12-18 20:15: Train Epoch 4: 83/159 Loss: 0.291373
2022-12-18 20:15: Train Epoch 4: 84/159 Loss: 0.276989
2022-12-18 20:16: Train Epoch 4: 85/159 Loss: 0.266892
2022-12-18 20:16: Train Epoch 4: 86/159 Loss: 0.315161
2022-12-18 20:17: Train Epoch 4: 87/159 Loss: 0.267528
2022-12-18 20:17: Train Epoch 4: 88/159 Loss: 0.306535
2022-12-18 20:17: Train Epoch 4: 89/159 Loss: 0.281740
2022-12-18 20:18: Train Epoch 4: 90/159 Loss: 0.297389
2022-12-18 20:18: Train Epoch 4: 91/159 Loss: 0.329715
2022-12-18 20:18: Train Epoch 4: 92/159 Loss: 0.280790
2022-12-18 20:19: Train Epoch 4: 93/159 Loss: 0.371387
2022-12-18 20:19: Train Epoch 4: 94/159 Loss: 0.301051
2022-12-18 20:20: Train Epoch 4: 95/159 Loss: 0.282234
2022-12-18 20:20: Train Epoch 4: 96/159 Loss: 0.285011
2022-12-18 20:20: Train Epoch 4: 97/159 Loss: 0.309321
2022-12-18 20:21: Train Epoch 4: 98/159 Loss: 0.273693
2022-12-18 20:21: Train Epoch 4: 99/159 Loss: 0.309015
2022-12-18 20:21: Train Epoch 4: 100/159 Loss: 0.305492
2022-12-18 20:22: Train Epoch 4: 101/159 Loss: 0.265119
2022-12-18 20:22: Train Epoch 4: 102/159 Loss: 0.286513
2022-12-18 20:23: Train Epoch 4: 103/159 Loss: 0.363904
2022-12-18 20:23: Train Epoch 4: 104/159 Loss: 0.303825
2022-12-18 20:23: Train Epoch 4: 105/159 Loss: 0.272910
2022-12-18 20:24: Train Epoch 4: 106/159 Loss: 0.355640
2022-12-18 20:24: Train Epoch 4: 107/159 Loss: 0.317884
2022-12-18 20:24: Train Epoch 4: 108/159 Loss: 0.246433
2022-12-18 20:25: Train Epoch 4: 109/159 Loss: 0.267260
2022-12-18 20:25: Train Epoch 4: 110/159 Loss: 0.327429
2022-12-18 20:26: Train Epoch 4: 111/159 Loss: 0.344508
2022-12-18 20:26: Train Epoch 4: 112/159 Loss: 0.314658
2022-12-18 20:26: Train Epoch 4: 113/159 Loss: 0.300557
2022-12-18 20:27: Train Epoch 4: 114/159 Loss: 0.313176
2022-12-18 20:27: Train Epoch 4: 115/159 Loss: 0.311252
2022-12-18 20:27: Train Epoch 4: 116/159 Loss: 0.317080
2022-12-18 20:28: Train Epoch 4: 117/159 Loss: 0.341534
2022-12-18 20:28: Train Epoch 4: 118/159 Loss: 0.277146
2022-12-18 20:29: Train Epoch 4: 119/159 Loss: 0.303796
2022-12-18 20:29: Train Epoch 4: 120/159 Loss: 0.313588
2022-12-18 20:29: Train Epoch 4: 121/159 Loss: 0.248472
2022-12-18 20:30: Train Epoch 4: 122/159 Loss: 0.311954
2022-12-18 20:30: Train Epoch 4: 123/159 Loss: 0.278493
2022-12-18 20:31: Train Epoch 4: 124/159 Loss: 0.306253
2022-12-18 20:31: Train Epoch 4: 125/159 Loss: 0.333876
2022-12-18 20:31: Train Epoch 4: 126/159 Loss: 0.342901
2022-12-18 20:32: Train Epoch 4: 127/159 Loss: 0.313320
2022-12-18 20:32: Train Epoch 4: 128/159 Loss: 0.270567
2022-12-18 20:32: Train Epoch 4: 129/159 Loss: 0.289252
2022-12-18 20:33: Train Epoch 4: 130/159 Loss: 0.298630
2022-12-18 20:33: Train Epoch 4: 131/159 Loss: 0.260846
2022-12-18 20:34: Train Epoch 4: 132/159 Loss: 0.346111
2022-12-18 20:34: Train Epoch 4: 133/159 Loss: 0.235101
2022-12-18 20:34: Train Epoch 4: 134/159 Loss: 0.281778
2022-12-18 20:35: Train Epoch 4: 135/159 Loss: 0.300659
2022-12-18 20:35: Train Epoch 4: 136/159 Loss: 0.291838
2022-12-18 20:35: Train Epoch 4: 137/159 Loss: 0.305153
2022-12-18 20:36: Train Epoch 4: 138/159 Loss: 0.275683
2022-12-18 20:36: Train Epoch 4: 139/159 Loss: 0.276651
2022-12-18 20:36: Train Epoch 4: 140/159 Loss: 0.268976
2022-12-18 20:37: Train Epoch 4: 141/159 Loss: 0.328548
2022-12-18 20:37: Train Epoch 4: 142/159 Loss: 0.250518
2022-12-18 20:38: Train Epoch 4: 143/159 Loss: 0.284437
2022-12-18 20:38: Train Epoch 4: 144/159 Loss: 0.257706
2022-12-18 20:38: Train Epoch 4: 145/159 Loss: 0.278105
2022-12-18 20:39: Train Epoch 4: 146/159 Loss: 0.383481
2022-12-18 20:39: Train Epoch 4: 147/159 Loss: 0.281963
2022-12-18 20:39: Train Epoch 4: 148/159 Loss: 0.251952
2022-12-18 20:40: Train Epoch 4: 149/159 Loss: 0.391819
2022-12-18 20:40: Train Epoch 4: 150/159 Loss: 0.294079
2022-12-18 20:41: Train Epoch 4: 151/159 Loss: 0.278444
2022-12-18 20:41: Train Epoch 4: 152/159 Loss: 0.309326
2022-12-18 20:41: Train Epoch 4: 153/159 Loss: 0.335769
2022-12-18 20:42: Train Epoch 4: 154/159 Loss: 0.289059
2022-12-18 20:42: Train Epoch 4: 155/159 Loss: 0.331983
2022-12-18 20:42: Train Epoch 4: 156/159 Loss: 0.333327
2022-12-18 20:43: Train Epoch 4: 157/159 Loss: 0.271994
2022-12-18 20:43: Train Epoch 4: 158/159 Loss: 0.287354
2022-12-18 20:43: **********Train Epoch 4: averaged Loss: 0.299660 
2022-12-18 20:43: 
Epoch time elapsed: 3575.540184736252

2022-12-18 20:45: 
 metrics validation: {'precision': 0.85997171145686, 'recall': 0.4676923076923077, 'f1-score': 0.6058794220229198, 'support': 1300, 'AUC': 0.8340680473372781, 'AUCPR': 0.7598926520135307, 'TP': 608, 'FP': 99, 'TN': 2501, 'FN': 692} 

2022-12-18 20:45: **********Val Epoch 4: average Loss: 0.599983
2022-12-18 20:45: Train Epoch 5: 0/159 Loss: 0.265532
2022-12-18 20:45: Train Epoch 5: 1/159 Loss: 0.356524
2022-12-18 20:46: Train Epoch 5: 2/159 Loss: 0.237311
2022-12-18 20:46: Train Epoch 5: 3/159 Loss: 0.247158
2022-12-18 20:46: Train Epoch 5: 4/159 Loss: 0.303314
2022-12-18 20:47: Train Epoch 5: 5/159 Loss: 0.290704
2022-12-18 20:47: Train Epoch 5: 6/159 Loss: 0.317682
2022-12-18 20:48: Train Epoch 5: 7/159 Loss: 0.272716
2022-12-18 20:48: Train Epoch 5: 8/159 Loss: 0.294388
2022-12-18 20:48: Train Epoch 5: 9/159 Loss: 0.263017
2022-12-18 20:49: Train Epoch 5: 10/159 Loss: 0.305063
2022-12-18 20:49: Train Epoch 5: 11/159 Loss: 0.248049
2022-12-18 20:50: Train Epoch 5: 12/159 Loss: 0.340683
2022-12-18 20:50: Train Epoch 5: 13/159 Loss: 0.328139
2022-12-18 20:51: Train Epoch 5: 14/159 Loss: 0.291447
2022-12-18 20:51: Train Epoch 5: 15/159 Loss: 0.313308
2022-12-18 20:52: Train Epoch 5: 16/159 Loss: 0.324556
2022-12-18 20:52: Train Epoch 5: 17/159 Loss: 0.295902
2022-12-18 20:53: Train Epoch 5: 18/159 Loss: 0.239444
2022-12-18 20:53: Train Epoch 5: 19/159 Loss: 0.275781
2022-12-18 20:54: Train Epoch 5: 20/159 Loss: 0.268411
2022-12-18 20:54: Train Epoch 5: 21/159 Loss: 0.291554
2022-12-18 20:55: Train Epoch 5: 22/159 Loss: 0.315731
2022-12-18 20:56: Train Epoch 5: 23/159 Loss: 0.370475
2022-12-18 20:56: Train Epoch 5: 24/159 Loss: 0.296278
2022-12-18 20:57: Train Epoch 5: 25/159 Loss: 0.362404
2022-12-18 20:57: Train Epoch 5: 26/159 Loss: 0.276462
2022-12-18 20:58: Train Epoch 5: 27/159 Loss: 0.348262
2022-12-18 20:58: Train Epoch 5: 28/159 Loss: 0.293113
2022-12-18 20:59: Train Epoch 5: 29/159 Loss: 0.332659
2022-12-18 20:59: Train Epoch 5: 30/159 Loss: 0.346658
2022-12-18 21:00: Train Epoch 5: 31/159 Loss: 0.298010
2022-12-18 21:00: Train Epoch 5: 32/159 Loss: 0.411683
2022-12-18 21:01: Train Epoch 5: 33/159 Loss: 0.326969
2022-12-18 21:01: Train Epoch 5: 34/159 Loss: 0.290969
2022-12-18 21:02: Train Epoch 5: 35/159 Loss: 0.274929
2022-12-18 21:03: Train Epoch 5: 36/159 Loss: 0.315986
2022-12-18 21:03: Train Epoch 5: 37/159 Loss: 0.310782
2022-12-18 21:04: Train Epoch 5: 38/159 Loss: 0.289231
2022-12-18 21:04: Train Epoch 5: 39/159 Loss: 0.339445
2022-12-18 21:05: Train Epoch 5: 40/159 Loss: 0.303407
2022-12-18 21:05: Train Epoch 5: 41/159 Loss: 0.253869
2022-12-18 21:06: Train Epoch 5: 42/159 Loss: 0.344067
2022-12-18 21:06: Train Epoch 5: 43/159 Loss: 0.255389
2022-12-18 21:07: Train Epoch 5: 44/159 Loss: 0.307997
2022-12-18 21:07: Train Epoch 5: 45/159 Loss: 0.306376
2022-12-18 21:08: Train Epoch 5: 46/159 Loss: 0.293266
2022-12-18 21:09: Train Epoch 5: 47/159 Loss: 0.319866
2022-12-18 21:09: Train Epoch 5: 48/159 Loss: 0.307358
2022-12-18 21:10: Train Epoch 5: 49/159 Loss: 0.295206
2022-12-18 21:10: Train Epoch 5: 50/159 Loss: 0.288849
2022-12-18 21:11: Train Epoch 5: 51/159 Loss: 0.331547
2022-12-18 21:11: Train Epoch 5: 52/159 Loss: 0.269489
2022-12-18 21:12: Train Epoch 5: 53/159 Loss: 0.351053
2022-12-18 21:12: Train Epoch 5: 54/159 Loss: 0.374579
2022-12-18 21:13: Train Epoch 5: 55/159 Loss: 0.309762
2022-12-18 21:13: Train Epoch 5: 56/159 Loss: 0.301700
2022-12-18 21:14: Train Epoch 5: 57/159 Loss: 0.314781
2022-12-18 21:14: Train Epoch 5: 58/159 Loss: 0.300036
2022-12-18 21:15: Train Epoch 5: 59/159 Loss: 0.269662
2022-12-18 21:16: Train Epoch 5: 60/159 Loss: 0.266900
2022-12-18 21:16: Train Epoch 5: 61/159 Loss: 0.256777
2022-12-18 21:17: Train Epoch 5: 62/159 Loss: 0.315819
2022-12-18 21:17: Train Epoch 5: 63/159 Loss: 0.327156
2022-12-18 21:18: Train Epoch 5: 64/159 Loss: 0.324542
2022-12-18 21:18: Train Epoch 5: 65/159 Loss: 0.301627
2022-12-18 21:19: Train Epoch 5: 66/159 Loss: 0.320230
2022-12-18 21:19: Train Epoch 5: 67/159 Loss: 0.312173
2022-12-18 21:20: Train Epoch 5: 68/159 Loss: 0.313487
2022-12-18 21:20: Train Epoch 5: 69/159 Loss: 0.239027
2022-12-18 21:21: Train Epoch 5: 70/159 Loss: 0.342239
2022-12-18 21:22: Train Epoch 5: 71/159 Loss: 0.298073
2022-12-18 21:22: Train Epoch 5: 72/159 Loss: 0.311852
2022-12-18 21:23: Train Epoch 5: 73/159 Loss: 0.262423
2022-12-18 21:23: Train Epoch 5: 74/159 Loss: 0.273596
2022-12-18 21:24: Train Epoch 5: 75/159 Loss: 0.297124
2022-12-18 21:24: Train Epoch 5: 76/159 Loss: 0.219343
2022-12-18 21:25: Train Epoch 5: 77/159 Loss: 0.357671
2022-12-18 21:25: Train Epoch 5: 78/159 Loss: 0.267399
2022-12-18 21:26: Train Epoch 5: 79/159 Loss: 0.310836
2022-12-18 21:27: Train Epoch 5: 80/159 Loss: 0.314305
2022-12-18 21:27: Train Epoch 5: 81/159 Loss: 0.303451
2022-12-18 21:28: Train Epoch 5: 82/159 Loss: 0.263522
2022-12-18 21:28: Train Epoch 5: 83/159 Loss: 0.246941
2022-12-18 21:29: Train Epoch 5: 84/159 Loss: 0.254247
2022-12-18 21:29: Train Epoch 5: 85/159 Loss: 0.305178
2022-12-18 21:30: Train Epoch 5: 86/159 Loss: 0.279042
2022-12-18 21:30: Train Epoch 5: 87/159 Loss: 0.291947
2022-12-18 21:31: Train Epoch 5: 88/159 Loss: 0.324153
2022-12-18 21:31: Train Epoch 5: 89/159 Loss: 0.320101
2022-12-18 21:32: Train Epoch 5: 90/159 Loss: 0.339240
2022-12-18 21:33: Train Epoch 5: 91/159 Loss: 0.303788
2022-12-18 21:33: Train Epoch 5: 92/159 Loss: 0.338257
2022-12-18 21:34: Train Epoch 5: 93/159 Loss: 0.277334
2022-12-18 21:34: Train Epoch 5: 94/159 Loss: 0.305346
2022-12-18 21:35: Train Epoch 5: 95/159 Loss: 0.335537
2022-12-18 21:35: Train Epoch 5: 96/159 Loss: 0.361702
2022-12-18 21:36: Train Epoch 5: 97/159 Loss: 0.357431
2022-12-18 21:36: Train Epoch 5: 98/159 Loss: 0.273251
2022-12-18 21:37: Train Epoch 5: 99/159 Loss: 0.334183
2022-12-18 21:38: Train Epoch 5: 100/159 Loss: 0.259232
2022-12-18 21:38: Train Epoch 5: 101/159 Loss: 0.276549
2022-12-18 21:39: Train Epoch 5: 102/159 Loss: 0.284712
2022-12-18 21:39: Train Epoch 5: 103/159 Loss: 0.292209
2022-12-18 21:40: Train Epoch 5: 104/159 Loss: 0.292832
2022-12-18 21:40: Train Epoch 5: 105/159 Loss: 0.303248
2022-12-18 21:41: Train Epoch 5: 106/159 Loss: 0.310686
2022-12-18 21:41: Train Epoch 5: 107/159 Loss: 0.308939
2022-12-18 21:42: Train Epoch 5: 108/159 Loss: 0.310274
2022-12-18 21:43: Train Epoch 5: 109/159 Loss: 0.353721
2022-12-18 21:43: Train Epoch 5: 110/159 Loss: 0.295387
2022-12-18 21:44: Train Epoch 5: 111/159 Loss: 0.299230
2022-12-18 21:44: Train Epoch 5: 112/159 Loss: 0.307635
2022-12-18 21:45: Train Epoch 5: 113/159 Loss: 0.260153
2022-12-18 21:45: Train Epoch 5: 114/159 Loss: 0.272911
2022-12-18 21:46: Train Epoch 5: 115/159 Loss: 0.297737
2022-12-18 21:46: Train Epoch 5: 116/159 Loss: 0.319780
2022-12-18 21:47: Train Epoch 5: 117/159 Loss: 0.317500
Traceback (most recent call last):
  File "Run_Model.py", line 201, in <module>
    trainer.train()
  File "/home/joel.chacon/tmp/WildFire_GCN/Trainer.py", line 117, in train
    train_epoch_loss = self.train_epoch(epoch)
  File "/home/joel.chacon/tmp/WildFire_GCN/Trainer.py", line 88, in train_epoch
    loss.backward()
  File "/home/joel.chacon/.local/lib/python3.8/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/joel.chacon/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
