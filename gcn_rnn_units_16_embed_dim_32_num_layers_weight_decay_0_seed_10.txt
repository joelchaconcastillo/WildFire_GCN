/home/joel.chacon/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2022-12-28 00:10: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103455046927062
2022-12-28 00:10: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103455046927062
2022-12-28 00:10: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=32, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103455046927062', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0005, max_grad_norm=5, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=10, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-28 00:10: Argument batch_size: 256
2022-12-28 00:10: Argument clc: 'vec'
2022-12-28 00:10: Argument cuda: True
2022-12-28 00:10: Argument dataset: '2020'
2022-12-28 00:10: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-28 00:10: Argument debug: False
2022-12-28 00:10: Argument default_graph: True
2022-12-28 00:10: Argument device: 'cpu'
2022-12-28 00:10: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-28 00:10: Argument early_stop: True
2022-12-28 00:10: Argument early_stop_patience: 8
2022-12-28 00:10: Argument embed_dim: 32
2022-12-28 00:10: Argument epochs: 30
2022-12-28 00:10: Argument grad_norm: False
2022-12-28 00:10: Argument horizon: 1
2022-12-28 00:10: Argument input_dim: 25
2022-12-28 00:10: Argument lag: 10
2022-12-28 00:10: Argument link_len: 2
2022-12-28 00:10: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103455046927062'
2022-12-28 00:10: Argument log_step: 1
2022-12-28 00:10: Argument loss_func: 'nllloss'
2022-12-28 00:10: Argument lr_decay: True
2022-12-28 00:10: Argument lr_decay_rate: 0.1
2022-12-28 00:10: Argument lr_decay_step: '15, 20'
2022-12-28 00:10: Argument lr_init: 0.0005
2022-12-28 00:10: Argument max_grad_norm: 5
2022-12-28 00:10: Argument mode: 'train'
2022-12-28 00:10: Argument model: 'fire_GCN'
2022-12-28 00:10: Argument nan_fill: 0.5
2022-12-28 00:10: Argument num_layers: 1
2022-12-28 00:10: Argument num_nodes: 625
2022-12-28 00:10: Argument num_workers: 20
2022-12-28 00:10: Argument output_dim: 2
2022-12-28 00:10: Argument patch_height: 25
2022-12-28 00:10: Argument patch_width: 25
2022-12-28 00:10: Argument persistent_workers: True
2022-12-28 00:10: Argument pin_memory: True
2022-12-28 00:10: Argument plot: False
2022-12-28 00:10: Argument positive_weight: 0.5
2022-12-28 00:10: Argument prefetch_factor: 2
2022-12-28 00:10: Argument real_value: True
2022-12-28 00:10: Argument rnn_units: 16
2022-12-28 00:10: Argument seed: 10
2022-12-28 00:10: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-28 00:10: Argument teacher_forcing: False
2022-12-28 00:10: Argument weight_decay: 0.0
2022-12-28 00:10: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 32]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([32, 2, 41, 16]) True
encoder.cell_list.0.gate.weights_window torch.Size([32, 1, 16]) True
encoder.cell_list.0.gate.bias_pool torch.Size([32, 32]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([32, 2, 41, 8]) True
encoder.cell_list.0.update.weights_window torch.Size([32, 1, 8]) True
encoder.cell_list.0.update.bias_pool torch.Size([32, 16]) True
encoder.cell_list.0.update.T torch.Size([10]) True
end_conv.weight torch.Size([2, 1, 625, 16]) True
end_conv.bias torch.Size([2]) True
Total params num: 105352
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103455046927062/run.log
2022-12-28 00:11: Train Epoch 1: 0/159 Loss: 0.756111
2022-12-28 00:12: Train Epoch 1: 1/159 Loss: 1.303115
2022-12-28 00:13: Train Epoch 1: 2/159 Loss: 1.149974
2022-12-28 00:14: Train Epoch 1: 3/159 Loss: 0.675584
2022-12-28 00:15: Train Epoch 1: 4/159 Loss: 0.981417
2022-12-28 00:16: Train Epoch 1: 5/159 Loss: 0.980992
2022-12-28 00:17: Train Epoch 1: 6/159 Loss: 0.685571
2022-12-28 00:17: Train Epoch 1: 7/159 Loss: 0.709942
2022-12-28 00:18: Train Epoch 1: 8/159 Loss: 0.860636
2022-12-28 00:19: Train Epoch 1: 9/159 Loss: 0.832660
2022-12-28 00:20: Train Epoch 1: 10/159 Loss: 0.687269
2022-12-28 00:21: Train Epoch 1: 11/159 Loss: 0.653082
2022-12-28 00:22: Train Epoch 1: 12/159 Loss: 0.706653
2022-12-28 00:23: Train Epoch 1: 13/159 Loss: 0.784677
2022-12-28 00:24: Train Epoch 1: 14/159 Loss: 0.739022
2022-12-28 00:24: Train Epoch 1: 15/159 Loss: 0.605192
2022-12-28 00:25: Train Epoch 1: 16/159 Loss: 0.707792
2022-12-28 00:26: Train Epoch 1: 17/159 Loss: 0.701655
2022-12-28 00:27: Train Epoch 1: 18/159 Loss: 0.751305
2022-12-28 00:28: Train Epoch 1: 19/159 Loss: 0.655701
2022-12-28 00:29: Train Epoch 1: 20/159 Loss: 0.613475
2022-12-28 00:30: Train Epoch 1: 21/159 Loss: 0.637307
2022-12-28 00:30: Train Epoch 1: 22/159 Loss: 0.680177
2022-12-28 00:31: Train Epoch 1: 23/159 Loss: 0.647776
2022-12-28 00:32: Train Epoch 1: 24/159 Loss: 0.605454
2022-12-28 00:33: Train Epoch 1: 25/159 Loss: 0.593283
2022-12-28 00:34: Train Epoch 1: 26/159 Loss: 0.646254
2022-12-28 00:35: Train Epoch 1: 27/159 Loss: 0.641166
2022-12-28 00:36: Train Epoch 1: 28/159 Loss: 0.630538
2022-12-28 00:37: Train Epoch 1: 29/159 Loss: 0.587532
2022-12-28 00:37: Train Epoch 1: 30/159 Loss: 0.609413
2022-12-28 00:38: Train Epoch 1: 31/159 Loss: 0.623079
2022-12-28 00:39: Train Epoch 1: 32/159 Loss: 0.626527
2022-12-28 00:40: Train Epoch 1: 33/159 Loss: 0.593940
2022-12-28 00:41: Train Epoch 1: 34/159 Loss: 0.568836
2022-12-28 00:42: Train Epoch 1: 35/159 Loss: 0.617472
2022-12-28 00:43: Train Epoch 1: 36/159 Loss: 0.594069
2022-12-28 00:43: Train Epoch 1: 37/159 Loss: 0.588191
2022-12-28 00:44: Train Epoch 1: 38/159 Loss: 0.595555
2022-12-28 00:45: Train Epoch 1: 39/159 Loss: 0.575780
2022-12-28 00:46: Train Epoch 1: 40/159 Loss: 0.565726
2022-12-28 00:47: Train Epoch 1: 41/159 Loss: 0.561046
2022-12-28 00:48: Train Epoch 1: 42/159 Loss: 0.552344
2022-12-28 00:49: Train Epoch 1: 43/159 Loss: 0.612522
2022-12-28 00:50: Train Epoch 1: 44/159 Loss: 0.605843
2022-12-28 00:50: Train Epoch 1: 45/159 Loss: 0.537948
2022-12-28 00:51: Train Epoch 1: 46/159 Loss: 0.584172
2022-12-28 00:52: Train Epoch 1: 47/159 Loss: 0.573598
2022-12-28 00:53: Train Epoch 1: 48/159 Loss: 0.559464
2022-12-28 00:54: Train Epoch 1: 49/159 Loss: 0.511693
2022-12-28 00:55: Train Epoch 1: 50/159 Loss: 0.636047
2022-12-28 00:56: Train Epoch 1: 51/159 Loss: 0.546085
2022-12-28 00:56: Train Epoch 1: 52/159 Loss: 0.534130
2022-12-28 00:57: Train Epoch 1: 53/159 Loss: 0.535870
2022-12-28 00:58: Train Epoch 1: 54/159 Loss: 0.548781
2022-12-28 00:59: Train Epoch 1: 55/159 Loss: 0.538224
2022-12-28 01:00: Train Epoch 1: 56/159 Loss: 0.512729
2022-12-28 01:01: Train Epoch 1: 57/159 Loss: 0.547769
2022-12-28 01:02: Train Epoch 1: 58/159 Loss: 0.540569
2022-12-28 01:03: Train Epoch 1: 59/159 Loss: 0.490610
2022-12-28 01:03: Train Epoch 1: 60/159 Loss: 0.486436
2022-12-28 01:04: Train Epoch 1: 61/159 Loss: 0.508896
2022-12-28 01:05: Train Epoch 1: 62/159 Loss: 0.513306
2022-12-28 01:06: Train Epoch 1: 63/159 Loss: 0.505098
2022-12-28 01:07: Train Epoch 1: 64/159 Loss: 0.461734
2022-12-28 01:08: Train Epoch 1: 65/159 Loss: 0.483942
2022-12-28 01:09: Train Epoch 1: 66/159 Loss: 0.525042
2022-12-28 01:10: Train Epoch 1: 67/159 Loss: 0.439548
2022-12-28 01:10: Train Epoch 1: 68/159 Loss: 0.488459
2022-12-28 01:11: Train Epoch 1: 69/159 Loss: 0.471582
2022-12-28 01:12: Train Epoch 1: 70/159 Loss: 0.447869
2022-12-28 01:13: Train Epoch 1: 71/159 Loss: 0.444916
2022-12-28 01:14: Train Epoch 1: 72/159 Loss: 0.431484
2022-12-28 01:15: Train Epoch 1: 73/159 Loss: 0.452601
2022-12-28 01:16: Train Epoch 1: 74/159 Loss: 0.461604
2022-12-28 01:17: Train Epoch 1: 75/159 Loss: 0.443952
2022-12-28 01:17: Train Epoch 1: 76/159 Loss: 0.431067
2022-12-28 01:18: Train Epoch 1: 77/159 Loss: 0.451024
2022-12-28 01:19: Train Epoch 1: 78/159 Loss: 0.451708
2022-12-28 01:20: Train Epoch 1: 79/159 Loss: 0.433125
2022-12-28 01:21: Train Epoch 1: 80/159 Loss: 0.429861
2022-12-28 01:22: Train Epoch 1: 81/159 Loss: 0.418014
2022-12-28 01:23: Train Epoch 1: 82/159 Loss: 0.391825
2022-12-28 01:24: Train Epoch 1: 83/159 Loss: 0.368097
2022-12-28 01:24: Train Epoch 1: 84/159 Loss: 0.445128
2022-12-28 01:25: Train Epoch 1: 85/159 Loss: 0.400031
2022-12-28 01:26: Train Epoch 1: 86/159 Loss: 0.375344
2022-12-28 01:27: Train Epoch 1: 87/159 Loss: 0.380674
2022-12-28 01:28: Train Epoch 1: 88/159 Loss: 0.402238
2022-12-28 01:29: Train Epoch 1: 89/159 Loss: 0.407826
2022-12-28 01:30: Train Epoch 1: 90/159 Loss: 0.367578
2022-12-28 01:31: Train Epoch 1: 91/159 Loss: 0.417236
2022-12-28 01:31: Train Epoch 1: 92/159 Loss: 0.361008
2022-12-28 01:32: Train Epoch 1: 93/159 Loss: 0.365617
2022-12-28 01:33: Train Epoch 1: 94/159 Loss: 0.356354
2022-12-28 01:34: Train Epoch 1: 95/159 Loss: 0.318301
2022-12-28 01:35: Train Epoch 1: 96/159 Loss: 0.360419
2022-12-28 01:36: Train Epoch 1: 97/159 Loss: 0.349552
2022-12-28 01:37: Train Epoch 1: 98/159 Loss: 0.403256
2022-12-28 01:37: Train Epoch 1: 99/159 Loss: 0.428623
2022-12-28 01:38: Train Epoch 1: 100/159 Loss: 0.347480
2022-12-28 01:39: Train Epoch 1: 101/159 Loss: 0.413663
2022-12-28 01:40: Train Epoch 1: 102/159 Loss: 0.339257
2022-12-28 01:41: Train Epoch 1: 103/159 Loss: 0.325314
2022-12-28 01:42: Train Epoch 1: 104/159 Loss: 0.348292
2022-12-28 01:43: Train Epoch 1: 105/159 Loss: 0.317009
2022-12-28 01:44: Train Epoch 1: 106/159 Loss: 0.323280
2022-12-28 01:44: Train Epoch 1: 107/159 Loss: 0.328542
2022-12-28 01:45: Train Epoch 1: 108/159 Loss: 0.403356
2022-12-28 01:46: Train Epoch 1: 109/159 Loss: 0.395309
2022-12-28 01:47: Train Epoch 1: 110/159 Loss: 0.346415
2022-12-28 01:48: Train Epoch 1: 111/159 Loss: 0.359733
2022-12-28 01:49: Train Epoch 1: 112/159 Loss: 0.341185
2022-12-28 01:50: Train Epoch 1: 113/159 Loss: 0.389980
2022-12-28 01:51: Train Epoch 1: 114/159 Loss: 0.324126
2022-12-28 01:51: Train Epoch 1: 115/159 Loss: 0.312581
2022-12-28 01:52: Train Epoch 1: 116/159 Loss: 0.371882
2022-12-28 01:53: Train Epoch 1: 117/159 Loss: 0.307423
2022-12-28 01:54: Train Epoch 1: 118/159 Loss: 0.368391
2022-12-28 01:55: Train Epoch 1: 119/159 Loss: 0.383397
2022-12-28 01:56: Train Epoch 1: 120/159 Loss: 0.315900
2022-12-28 01:57: Train Epoch 1: 121/159 Loss: 0.337014
2022-12-28 01:58: Train Epoch 1: 122/159 Loss: 0.404212
2022-12-28 01:58: Train Epoch 1: 123/159 Loss: 0.327566
2022-12-28 01:59: Train Epoch 1: 124/159 Loss: 0.349154
2022-12-28 02:00: Train Epoch 1: 125/159 Loss: 0.380664
2022-12-28 02:01: Train Epoch 1: 126/159 Loss: 0.366084
2022-12-28 02:02: Train Epoch 1: 127/159 Loss: 0.334532
2022-12-28 02:03: Train Epoch 1: 128/159 Loss: 0.330089
2022-12-28 02:04: Train Epoch 1: 129/159 Loss: 0.399242
2022-12-28 02:04: Train Epoch 1: 130/159 Loss: 0.308017
2022-12-28 02:05: Train Epoch 1: 131/159 Loss: 0.298935
2022-12-28 02:06: Train Epoch 1: 132/159 Loss: 0.392400
2022-12-28 02:07: Train Epoch 1: 133/159 Loss: 0.338596
2022-12-28 02:08: Train Epoch 1: 134/159 Loss: 0.288280
2022-12-28 02:09: Train Epoch 1: 135/159 Loss: 0.338038
2022-12-28 02:10: Train Epoch 1: 136/159 Loss: 0.375042
2022-12-28 02:11: Train Epoch 1: 137/159 Loss: 0.304285
2022-12-28 02:11: Train Epoch 1: 138/159 Loss: 0.319733
2022-12-28 02:12: Train Epoch 1: 139/159 Loss: 0.349747
2022-12-28 02:13: Train Epoch 1: 140/159 Loss: 0.303716
2022-12-28 02:14: Train Epoch 1: 141/159 Loss: 0.324055
2022-12-28 02:15: Train Epoch 1: 142/159 Loss: 0.340633
2022-12-28 02:16: Train Epoch 1: 143/159 Loss: 0.353652
2022-12-28 02:17: Train Epoch 1: 144/159 Loss: 0.338327
2022-12-28 02:17: Train Epoch 1: 145/159 Loss: 0.326995
2022-12-28 02:18: Train Epoch 1: 146/159 Loss: 0.269364
2022-12-28 02:19: Train Epoch 1: 147/159 Loss: 0.297257
2022-12-28 02:20: Train Epoch 1: 148/159 Loss: 0.303029
2022-12-28 02:21: Train Epoch 1: 149/159 Loss: 0.267026
2022-12-28 02:22: Train Epoch 1: 150/159 Loss: 0.344493
2022-12-28 02:23: Train Epoch 1: 151/159 Loss: 0.322996
2022-12-28 02:23: Train Epoch 1: 152/159 Loss: 0.325860
2022-12-28 02:24: Train Epoch 1: 153/159 Loss: 0.289834
2022-12-28 02:25: Train Epoch 1: 154/159 Loss: 0.263210
2022-12-28 02:26: Train Epoch 1: 155/159 Loss: 0.288050
2022-12-28 02:27: Train Epoch 1: 156/159 Loss: 0.309200
2022-12-28 02:28: Train Epoch 1: 157/159 Loss: 0.310217
2022-12-28 02:28: Train Epoch 1: 158/159 Loss: 0.312808
2022-12-28 02:28: **********Train Epoch 1: averaged Loss: 0.479085 
2022-12-28 02:28: 
Epoch time elapsed: 8273.185506105423

2022-12-28 02:32: 
 metrics validation: {'precision': 0.7216589861751153, 'recall': 0.6023076923076923, 'f1-score': 0.6566037735849056, 'support': 1300, 'AUC': 0.8062849112426036, 'AUCPR': 0.7081913371777776, 'TP': 783, 'FP': 302, 'TN': 2298, 'FN': 517} 

2022-12-28 02:32: **********Val Epoch 1: average Loss: 0.570930
2022-12-28 02:32: *********************************Current best model saved!
/home/joel.chacon/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2022-12-28 02:36: 
 Testing metrics {'precision': 0.7980582524271844, 'recall': 0.6693811074918566, 'f1-score': 0.7280779450841454, 'support': 1228, 'AUC': 0.8585532074610872, 'AUCPR': 0.775715064473973, 'TP': 822, 'FP': 208, 'TN': 2248, 'FN': 406} 

2022-12-28 02:37: Train Epoch 2: 0/159 Loss: 0.227528
2022-12-28 02:38: Train Epoch 2: 1/159 Loss: 0.308003
2022-12-28 02:39: Train Epoch 2: 2/159 Loss: 0.305156
2022-12-28 02:40: Train Epoch 2: 3/159 Loss: 0.359757
2022-12-28 02:41: Train Epoch 2: 4/159 Loss: 0.326288
2022-12-28 02:42: Train Epoch 2: 5/159 Loss: 0.304403
2022-12-28 02:43: Train Epoch 2: 6/159 Loss: 0.344963
2022-12-28 02:44: Train Epoch 2: 7/159 Loss: 0.333295
2022-12-28 02:45: Train Epoch 2: 8/159 Loss: 0.343390
2022-12-28 02:46: Train Epoch 2: 9/159 Loss: 0.248844
2022-12-28 02:47: Train Epoch 2: 10/159 Loss: 0.328936
2022-12-28 02:47: Train Epoch 2: 11/159 Loss: 0.305387
2022-12-28 02:48: Train Epoch 2: 12/159 Loss: 0.319596
2022-12-28 02:49: Train Epoch 2: 13/159 Loss: 0.305943
2022-12-28 02:50: Train Epoch 2: 14/159 Loss: 0.288334
2022-12-28 02:51: Train Epoch 2: 15/159 Loss: 0.268570
2022-12-28 02:52: Train Epoch 2: 16/159 Loss: 0.345894
2022-12-28 02:53: Train Epoch 2: 17/159 Loss: 0.324924
2022-12-28 02:54: Train Epoch 2: 18/159 Loss: 0.288738
2022-12-28 02:55: Train Epoch 2: 19/159 Loss: 0.300997
2022-12-28 02:55: Train Epoch 2: 20/159 Loss: 0.308077
2022-12-28 02:56: Train Epoch 2: 21/159 Loss: 0.349522
2022-12-28 02:57: Train Epoch 2: 22/159 Loss: 0.243091
2022-12-28 02:58: Train Epoch 2: 23/159 Loss: 0.376891
2022-12-28 02:59: Train Epoch 2: 24/159 Loss: 0.307077
2022-12-28 03:00: Train Epoch 2: 25/159 Loss: 0.288063
2022-12-28 03:01: Train Epoch 2: 26/159 Loss: 0.287986
2022-12-28 03:02: Train Epoch 2: 27/159 Loss: 0.348569
2022-12-28 03:02: Train Epoch 2: 28/159 Loss: 0.302380
2022-12-28 03:03: Train Epoch 2: 29/159 Loss: 0.231368
2022-12-28 03:04: Train Epoch 2: 30/159 Loss: 0.344876
2022-12-28 03:05: Train Epoch 2: 31/159 Loss: 0.321730
2022-12-28 03:06: Train Epoch 2: 32/159 Loss: 0.361305
2022-12-28 03:07: Train Epoch 2: 33/159 Loss: 0.254291
2022-12-28 03:08: Train Epoch 2: 34/159 Loss: 0.281760
2022-12-28 03:09: Train Epoch 2: 35/159 Loss: 0.326724
2022-12-28 03:10: Train Epoch 2: 36/159 Loss: 0.287021
2022-12-28 03:10: Train Epoch 2: 37/159 Loss: 0.344597
2022-12-28 03:11: Train Epoch 2: 38/159 Loss: 0.295994
2022-12-28 03:12: Train Epoch 2: 39/159 Loss: 0.287327
2022-12-28 03:13: Train Epoch 2: 40/159 Loss: 0.261330
2022-12-28 03:14: Train Epoch 2: 41/159 Loss: 0.365167
2022-12-28 03:15: Train Epoch 2: 42/159 Loss: 0.267791
2022-12-28 03:16: Train Epoch 2: 43/159 Loss: 0.363651
2022-12-28 03:17: Train Epoch 2: 44/159 Loss: 0.251597
2022-12-28 03:17: Train Epoch 2: 45/159 Loss: 0.315993
2022-12-28 03:18: Train Epoch 2: 46/159 Loss: 0.280980
2022-12-28 03:19: Train Epoch 2: 47/159 Loss: 0.280663
2022-12-28 03:20: Train Epoch 2: 48/159 Loss: 0.320911
2022-12-28 03:21: Train Epoch 2: 49/159 Loss: 0.261492
2022-12-28 03:22: Train Epoch 2: 50/159 Loss: 0.235265
2022-12-28 03:23: Train Epoch 2: 51/159 Loss: 0.296690
2022-12-28 03:24: Train Epoch 2: 52/159 Loss: 0.304175
2022-12-28 03:25: Train Epoch 2: 53/159 Loss: 0.322302
2022-12-28 03:25: Train Epoch 2: 54/159 Loss: 0.315121
2022-12-28 03:26: Train Epoch 2: 55/159 Loss: 0.291804
2022-12-28 03:27: Train Epoch 2: 56/159 Loss: 0.337497
2022-12-28 03:28: Train Epoch 2: 57/159 Loss: 0.283979
2022-12-28 03:29: Train Epoch 2: 58/159 Loss: 0.282842
2022-12-28 03:30: Train Epoch 2: 59/159 Loss: 0.278059
2022-12-28 03:31: Train Epoch 2: 60/159 Loss: 0.350823
2022-12-28 03:32: Train Epoch 2: 61/159 Loss: 0.298142
2022-12-28 03:32: Train Epoch 2: 62/159 Loss: 0.303015
2022-12-28 03:33: Train Epoch 2: 63/159 Loss: 0.272047
2022-12-28 03:34: Train Epoch 2: 64/159 Loss: 0.257438
2022-12-28 03:35: Train Epoch 2: 65/159 Loss: 0.332614
2022-12-28 03:36: Train Epoch 2: 66/159 Loss: 0.369424
2022-12-28 03:37: Train Epoch 2: 67/159 Loss: 0.310985
2022-12-28 03:38: Train Epoch 2: 68/159 Loss: 0.262967
2022-12-28 03:39: Train Epoch 2: 69/159 Loss: 0.321837
2022-12-28 03:39: Train Epoch 2: 70/159 Loss: 0.258490
2022-12-28 03:40: Train Epoch 2: 71/159 Loss: 0.234118
2022-12-28 03:41: Train Epoch 2: 72/159 Loss: 0.303966
2022-12-28 03:42: Train Epoch 2: 73/159 Loss: 0.253492
2022-12-28 03:43: Train Epoch 2: 74/159 Loss: 0.280215
2022-12-28 03:44: Train Epoch 2: 75/159 Loss: 0.280741
2022-12-28 03:45: Train Epoch 2: 76/159 Loss: 0.281427
2022-12-28 03:46: Train Epoch 2: 77/159 Loss: 0.278956
2022-12-28 03:47: Train Epoch 2: 78/159 Loss: 0.290249
2022-12-28 03:47: Train Epoch 2: 79/159 Loss: 0.283422
2022-12-28 03:48: Train Epoch 2: 80/159 Loss: 0.234933
2022-12-28 03:49: Train Epoch 2: 81/159 Loss: 0.274476
2022-12-28 03:50: Train Epoch 2: 82/159 Loss: 0.290759
2022-12-28 03:51: Train Epoch 2: 83/159 Loss: 0.371951
2022-12-28 03:52: Train Epoch 2: 84/159 Loss: 0.301294
2022-12-28 03:53: Train Epoch 2: 85/159 Loss: 0.269889
2022-12-28 03:54: Train Epoch 2: 86/159 Loss: 0.264752
2022-12-28 03:54: Train Epoch 2: 87/159 Loss: 0.315116
2022-12-28 03:55: Train Epoch 2: 88/159 Loss: 0.218963
2022-12-28 03:56: Train Epoch 2: 89/159 Loss: 0.308598
2022-12-28 03:57: Train Epoch 2: 90/159 Loss: 0.311445
2022-12-28 03:58: Train Epoch 2: 91/159 Loss: 0.279722
2022-12-28 03:59: Train Epoch 2: 92/159 Loss: 0.295254
2022-12-28 04:00: Train Epoch 2: 93/159 Loss: 0.278638
2022-12-28 04:01: Train Epoch 2: 94/159 Loss: 0.230445
2022-12-28 04:02: Train Epoch 2: 95/159 Loss: 0.248635
2022-12-28 04:03: Train Epoch 2: 96/159 Loss: 0.301406
2022-12-28 04:03: Train Epoch 2: 97/159 Loss: 0.280233
2022-12-28 04:04: Train Epoch 2: 98/159 Loss: 0.313557
2022-12-28 04:05: Train Epoch 2: 99/159 Loss: 0.284173
2022-12-28 04:06: Train Epoch 2: 100/159 Loss: 0.266485
2022-12-28 04:07: Train Epoch 2: 101/159 Loss: 0.225923
2022-12-28 04:08: Train Epoch 2: 102/159 Loss: 0.300545
2022-12-28 04:09: Train Epoch 2: 103/159 Loss: 0.277182
2022-12-28 04:10: Train Epoch 2: 104/159 Loss: 0.250893
2022-12-28 04:11: Train Epoch 2: 105/159 Loss: 0.249283
2022-12-28 04:11: Train Epoch 2: 106/159 Loss: 0.213626
2022-12-28 04:12: Train Epoch 2: 107/159 Loss: 0.271379
2022-12-28 04:13: Train Epoch 2: 108/159 Loss: 0.339159
2022-12-28 04:14: Train Epoch 2: 109/159 Loss: 0.292755
2022-12-28 04:15: Train Epoch 2: 110/159 Loss: 0.280825
2022-12-28 04:16: Train Epoch 2: 111/159 Loss: 0.286737
2022-12-28 04:17: Train Epoch 2: 112/159 Loss: 0.278538
2022-12-28 04:18: Train Epoch 2: 113/159 Loss: 0.407954
2022-12-28 04:18: Train Epoch 2: 114/159 Loss: 0.282287
2022-12-28 04:19: Train Epoch 2: 115/159 Loss: 0.287210
2022-12-28 04:20: Train Epoch 2: 116/159 Loss: 0.268215
2022-12-28 04:21: Train Epoch 2: 117/159 Loss: 0.321429
2022-12-28 04:22: Train Epoch 2: 118/159 Loss: 0.320000
2022-12-28 04:23: Train Epoch 2: 119/159 Loss: 0.312664
2022-12-28 04:24: Train Epoch 2: 120/159 Loss: 0.344806
2022-12-28 04:25: Train Epoch 2: 121/159 Loss: 0.284812
2022-12-28 04:25: Train Epoch 2: 122/159 Loss: 0.266646
2022-12-28 04:26: Train Epoch 2: 123/159 Loss: 0.330441
2022-12-28 04:27: Train Epoch 2: 124/159 Loss: 0.291755
2022-12-28 04:28: Train Epoch 2: 125/159 Loss: 0.256812
2022-12-28 04:29: Train Epoch 2: 126/159 Loss: 0.257950
2022-12-28 04:30: Train Epoch 2: 127/159 Loss: 0.347365
2022-12-28 04:31: Train Epoch 2: 128/159 Loss: 0.188648
2022-12-28 04:32: Train Epoch 2: 129/159 Loss: 0.284569
2022-12-28 04:32: Train Epoch 2: 130/159 Loss: 0.338226
2022-12-28 04:33: Train Epoch 2: 131/159 Loss: 0.269088
2022-12-28 04:34: Train Epoch 2: 132/159 Loss: 0.345827
2022-12-28 04:35: Train Epoch 2: 133/159 Loss: 0.301396
2022-12-28 04:36: Train Epoch 2: 134/159 Loss: 0.357970
2022-12-28 04:37: Train Epoch 2: 135/159 Loss: 0.269725
2022-12-28 04:38: Train Epoch 2: 136/159 Loss: 0.257058
2022-12-28 04:39: Train Epoch 2: 137/159 Loss: 0.234639
2022-12-28 04:39: Train Epoch 2: 138/159 Loss: 0.304908
2022-12-28 04:40: Train Epoch 2: 139/159 Loss: 0.337150
2022-12-28 04:41: Train Epoch 2: 140/159 Loss: 0.311877
2022-12-28 04:42: Train Epoch 2: 141/159 Loss: 0.297696
2022-12-28 04:43: Train Epoch 2: 142/159 Loss: 0.241989
2022-12-28 04:44: Train Epoch 2: 143/159 Loss: 0.244806
2022-12-28 04:45: Train Epoch 2: 144/159 Loss: 0.276612
2022-12-28 04:46: Train Epoch 2: 145/159 Loss: 0.345212
2022-12-28 04:47: Train Epoch 2: 146/159 Loss: 0.272150
2022-12-28 04:47: Train Epoch 2: 147/159 Loss: 0.245127
2022-12-28 04:48: Train Epoch 2: 148/159 Loss: 0.298747
2022-12-28 04:49: Train Epoch 2: 149/159 Loss: 0.282350
2022-12-28 04:50: Train Epoch 2: 150/159 Loss: 0.321717
2022-12-28 04:51: Train Epoch 2: 151/159 Loss: 0.288967
2022-12-28 04:52: Train Epoch 2: 152/159 Loss: 0.280649
2022-12-28 04:53: Train Epoch 2: 153/159 Loss: 0.313494
2022-12-28 04:54: Train Epoch 2: 154/159 Loss: 0.227587
2022-12-28 04:54: Train Epoch 2: 155/159 Loss: 0.200846
2022-12-28 04:55: Train Epoch 2: 156/159 Loss: 0.280055
2022-12-28 04:56: Train Epoch 2: 157/159 Loss: 0.281308
2022-12-28 04:57: Train Epoch 2: 158/159 Loss: 0.385417
2022-12-28 04:57: **********Train Epoch 2: averaged Loss: 0.293981 
2022-12-28 04:57: 
Epoch time elapsed: 8413.493119716644

2022-12-28 05:00: 
 metrics validation: {'precision': 0.7315834038950042, 'recall': 0.6646153846153846, 'f1-score': 0.6964933494558646, 'support': 1300, 'AUC': 0.8337701183431953, 'AUCPR': 0.7467558168253656, 'TP': 864, 'FP': 317, 'TN': 2283, 'FN': 436} 

2022-12-28 05:00: **********Val Epoch 2: average Loss: 0.555594
2022-12-28 05:00: *********************************Current best model saved!
2022-12-28 05:04: 
 Testing metrics {'precision': 0.8102981029810298, 'recall': 0.7304560260586319, 'f1-score': 0.7683083511777301, 'support': 1228, 'AUC': 0.8691017278697917, 'AUCPR': 0.8032519101034807, 'TP': 897, 'FP': 210, 'TN': 2246, 'FN': 331} 

2022-12-28 05:05: Train Epoch 3: 0/159 Loss: 0.418651
2022-12-28 05:06: Train Epoch 3: 1/159 Loss: 0.318517
2022-12-28 05:07: Train Epoch 3: 2/159 Loss: 0.345997
2022-12-28 05:08: Train Epoch 3: 3/159 Loss: 0.255064
2022-12-28 05:09: Train Epoch 3: 4/159 Loss: 0.245071
2022-12-28 05:10: Train Epoch 3: 5/159 Loss: 0.348572
2022-12-28 05:11: Train Epoch 3: 6/159 Loss: 0.293419
2022-12-28 05:12: Train Epoch 3: 7/159 Loss: 0.277018
2022-12-28 05:12: Train Epoch 3: 8/159 Loss: 0.273996
2022-12-28 05:13: Train Epoch 3: 9/159 Loss: 0.218217
2022-12-28 05:14: Train Epoch 3: 10/159 Loss: 0.236019
2022-12-28 05:15: Train Epoch 3: 11/159 Loss: 0.288678
2022-12-28 05:16: Train Epoch 3: 12/159 Loss: 0.275558
2022-12-28 05:17: Train Epoch 3: 13/159 Loss: 0.277710
2022-12-28 05:18: Train Epoch 3: 14/159 Loss: 0.245302
2022-12-28 05:19: Train Epoch 3: 15/159 Loss: 0.271993
2022-12-28 05:19: Train Epoch 3: 16/159 Loss: 0.252830
2022-12-28 05:20: Train Epoch 3: 17/159 Loss: 0.293775
2022-12-28 05:21: Train Epoch 3: 18/159 Loss: 0.301549
2022-12-28 05:22: Train Epoch 3: 19/159 Loss: 0.267578
2022-12-28 05:23: Train Epoch 3: 20/159 Loss: 0.239850
2022-12-28 05:24: Train Epoch 3: 21/159 Loss: 0.316437
2022-12-28 05:25: Train Epoch 3: 22/159 Loss: 0.244442
2022-12-28 05:26: Train Epoch 3: 23/159 Loss: 0.271313
2022-12-28 05:27: Train Epoch 3: 24/159 Loss: 0.237896
2022-12-28 05:27: Train Epoch 3: 25/159 Loss: 0.296201
2022-12-28 05:28: Train Epoch 3: 26/159 Loss: 0.253942
2022-12-28 05:29: Train Epoch 3: 27/159 Loss: 0.242287
2022-12-28 05:30: Train Epoch 3: 28/159 Loss: 0.276632
2022-12-28 05:31: Train Epoch 3: 29/159 Loss: 0.309048
2022-12-28 05:32: Train Epoch 3: 30/159 Loss: 0.315984
2022-12-28 05:33: Train Epoch 3: 31/159 Loss: 0.232136
2022-12-28 05:33: Train Epoch 3: 32/159 Loss: 0.287044
2022-12-28 05:34: Train Epoch 3: 33/159 Loss: 0.317017
2022-12-28 05:35: Train Epoch 3: 34/159 Loss: 0.416807
2022-12-28 05:36: Train Epoch 3: 35/159 Loss: 0.265825
2022-12-28 05:37: Train Epoch 3: 36/159 Loss: 0.308720
2022-12-28 05:38: Train Epoch 3: 37/159 Loss: 0.289845
2022-12-28 05:39: Train Epoch 3: 38/159 Loss: 0.237372
2022-12-28 05:40: Train Epoch 3: 39/159 Loss: 0.264965
2022-12-28 05:41: Train Epoch 3: 40/159 Loss: 0.281397
2022-12-28 05:41: Train Epoch 3: 41/159 Loss: 0.267497
2022-12-28 05:42: Train Epoch 3: 42/159 Loss: 0.268609
2022-12-28 05:43: Train Epoch 3: 43/159 Loss: 0.289573
2022-12-28 05:44: Train Epoch 3: 44/159 Loss: 0.290492
2022-12-28 05:45: Train Epoch 3: 45/159 Loss: 0.286199
2022-12-28 05:46: Train Epoch 3: 46/159 Loss: 0.346962
2022-12-28 05:47: Train Epoch 3: 47/159 Loss: 0.299749
2022-12-28 05:48: Train Epoch 3: 48/159 Loss: 0.266154
2022-12-28 05:48: Train Epoch 3: 49/159 Loss: 0.222754
2022-12-28 05:49: Train Epoch 3: 50/159 Loss: 0.275279
2022-12-28 05:50: Train Epoch 3: 51/159 Loss: 0.226666
2022-12-28 05:51: Train Epoch 3: 52/159 Loss: 0.350246
2022-12-28 05:52: Train Epoch 3: 53/159 Loss: 0.259831
2022-12-28 05:53: Train Epoch 3: 54/159 Loss: 0.294648
2022-12-28 05:54: Train Epoch 3: 55/159 Loss: 0.337795
2022-12-28 05:55: Train Epoch 3: 56/159 Loss: 0.269900
2022-12-28 05:56: Train Epoch 3: 57/159 Loss: 0.336361
2022-12-28 05:56: Train Epoch 3: 58/159 Loss: 0.355059
2022-12-28 05:57: Train Epoch 3: 59/159 Loss: 0.296418
2022-12-28 05:58: Train Epoch 3: 60/159 Loss: 0.220852
2022-12-28 05:59: Train Epoch 3: 61/159 Loss: 0.281986
2022-12-28 06:00: Train Epoch 3: 62/159 Loss: 0.286212
2022-12-28 06:01: Train Epoch 3: 63/159 Loss: 0.241582
2022-12-28 06:02: Train Epoch 3: 64/159 Loss: 0.314522
2022-12-28 06:03: Train Epoch 3: 65/159 Loss: 0.217491
2022-12-28 06:03: Train Epoch 3: 66/159 Loss: 0.278361
2022-12-28 06:04: Train Epoch 3: 67/159 Loss: 0.322551
2022-12-28 06:05: Train Epoch 3: 68/159 Loss: 0.275323
2022-12-28 06:06: Train Epoch 3: 69/159 Loss: 0.263623
2022-12-28 06:07: Train Epoch 3: 70/159 Loss: 0.274569
2022-12-28 06:08: Train Epoch 3: 71/159 Loss: 0.283738
2022-12-28 06:09: Train Epoch 3: 72/159 Loss: 0.250263
2022-12-28 06:10: Train Epoch 3: 73/159 Loss: 0.314048
2022-12-28 06:11: Train Epoch 3: 74/159 Loss: 0.315825
2022-12-28 06:11: Train Epoch 3: 75/159 Loss: 0.319023
2022-12-28 06:12: Train Epoch 3: 76/159 Loss: 0.271690
2022-12-28 06:13: Train Epoch 3: 77/159 Loss: 0.284046
2022-12-28 06:14: Train Epoch 3: 78/159 Loss: 0.289382
2022-12-28 06:15: Train Epoch 3: 79/159 Loss: 0.238214
2022-12-28 06:16: Train Epoch 3: 80/159 Loss: 0.263681
2022-12-28 06:17: Train Epoch 3: 81/159 Loss: 0.224159
2022-12-28 06:18: Train Epoch 3: 82/159 Loss: 0.279786
2022-12-28 06:19: Train Epoch 3: 83/159 Loss: 0.336818
2022-12-28 06:19: Train Epoch 3: 84/159 Loss: 0.236361
2022-12-28 06:20: Train Epoch 3: 85/159 Loss: 0.239531
2022-12-28 06:21: Train Epoch 3: 86/159 Loss: 0.302913
2022-12-28 06:22: Train Epoch 3: 87/159 Loss: 0.295320
2022-12-28 06:23: Train Epoch 3: 88/159 Loss: 0.328925
2022-12-28 06:24: Train Epoch 3: 89/159 Loss: 0.247679
2022-12-28 06:25: Train Epoch 3: 90/159 Loss: 0.305050
2022-12-28 06:26: Train Epoch 3: 91/159 Loss: 0.299925
2022-12-28 06:27: Train Epoch 3: 92/159 Loss: 0.235414
2022-12-28 06:27: Train Epoch 3: 93/159 Loss: 0.297238
2022-12-28 06:28: Train Epoch 3: 94/159 Loss: 0.251938
2022-12-28 06:29: Train Epoch 3: 95/159 Loss: 0.245943
2022-12-28 06:30: Train Epoch 3: 96/159 Loss: 0.212340
2022-12-28 06:31: Train Epoch 3: 97/159 Loss: 0.309106
2022-12-28 06:32: Train Epoch 3: 98/159 Loss: 0.353146
2022-12-28 06:33: Train Epoch 3: 99/159 Loss: 0.369271
2022-12-28 06:34: Train Epoch 3: 100/159 Loss: 0.329820
2022-12-28 06:35: Train Epoch 3: 101/159 Loss: 0.225102
2022-12-28 06:35: Train Epoch 3: 102/159 Loss: 0.222957
2022-12-28 06:36: Train Epoch 3: 103/159 Loss: 0.349719
2022-12-28 06:37: Train Epoch 3: 104/159 Loss: 0.294318
2022-12-28 06:38: Train Epoch 3: 105/159 Loss: 0.231924
2022-12-28 06:39: Train Epoch 3: 106/159 Loss: 0.303796
2022-12-28 06:40: Train Epoch 3: 107/159 Loss: 0.225407
2022-12-28 06:41: Train Epoch 3: 108/159 Loss: 0.278217
2022-12-28 06:42: Train Epoch 3: 109/159 Loss: 0.242328
2022-12-28 06:43: Train Epoch 3: 110/159 Loss: 0.292823
2022-12-28 06:43: Train Epoch 3: 111/159 Loss: 0.291824
2022-12-28 06:44: Train Epoch 3: 112/159 Loss: 0.228126
2022-12-28 06:45: Train Epoch 3: 113/159 Loss: 0.222922
2022-12-28 06:46: Train Epoch 3: 114/159 Loss: 0.265995
2022-12-28 06:47: Train Epoch 3: 115/159 Loss: 0.321204
2022-12-28 06:48: Train Epoch 3: 116/159 Loss: 0.233555
2022-12-28 06:49: Train Epoch 3: 117/159 Loss: 0.284032
2022-12-28 06:50: Train Epoch 3: 118/159 Loss: 0.216406
2022-12-28 06:51: Train Epoch 3: 119/159 Loss: 0.237723
2022-12-28 06:52: Train Epoch 3: 120/159 Loss: 0.273478
2022-12-28 06:52: Train Epoch 3: 121/159 Loss: 0.266553
2022-12-28 06:53: Train Epoch 3: 122/159 Loss: 0.247230
2022-12-28 06:54: Train Epoch 3: 123/159 Loss: 0.275901
2022-12-28 06:55: Train Epoch 3: 124/159 Loss: 0.381958
2022-12-28 06:56: Train Epoch 3: 125/159 Loss: 0.268629
2022-12-28 06:57: Train Epoch 3: 126/159 Loss: 0.240307
2022-12-28 06:58: Train Epoch 3: 127/159 Loss: 0.225111
2022-12-28 06:59: Train Epoch 3: 128/159 Loss: 0.296155
2022-12-28 07:00: Train Epoch 3: 129/159 Loss: 0.242907
2022-12-28 07:01: Train Epoch 3: 130/159 Loss: 0.266148
2022-12-28 07:01: Train Epoch 3: 131/159 Loss: 0.266679
2022-12-28 07:02: Train Epoch 3: 132/159 Loss: 0.248354
2022-12-28 07:03: Train Epoch 3: 133/159 Loss: 0.213462
2022-12-28 07:04: Train Epoch 3: 134/159 Loss: 0.228793
2022-12-28 07:05: Train Epoch 3: 135/159 Loss: 0.344762
2022-12-28 07:06: Train Epoch 3: 136/159 Loss: 0.320704
2022-12-28 07:07: Train Epoch 3: 137/159 Loss: 0.325284
2022-12-28 07:08: Train Epoch 3: 138/159 Loss: 0.230936
2022-12-28 07:08: Train Epoch 3: 139/159 Loss: 0.216068
2022-12-28 07:09: Train Epoch 3: 140/159 Loss: 0.299671
2022-12-28 07:10: Train Epoch 3: 141/159 Loss: 0.254317
2022-12-28 07:11: Train Epoch 3: 142/159 Loss: 0.250250
2022-12-28 07:12: Train Epoch 3: 143/159 Loss: 0.272695
2022-12-28 07:13: Train Epoch 3: 144/159 Loss: 0.213844
2022-12-28 07:14: Train Epoch 3: 145/159 Loss: 0.262273
2022-12-28 07:15: Train Epoch 3: 146/159 Loss: 0.314045
2022-12-28 07:16: Train Epoch 3: 147/159 Loss: 0.254275
2022-12-28 07:17: Train Epoch 3: 148/159 Loss: 0.233240
2022-12-28 07:17: Train Epoch 3: 149/159 Loss: 0.304281
2022-12-28 07:18: Train Epoch 3: 150/159 Loss: 0.269845
2022-12-28 07:19: Train Epoch 3: 151/159 Loss: 0.288124
2022-12-28 07:20: Train Epoch 3: 152/159 Loss: 0.255319
2022-12-28 07:21: Train Epoch 3: 153/159 Loss: 0.240001
2022-12-28 07:22: Train Epoch 3: 154/159 Loss: 0.262076
2022-12-28 07:23: Train Epoch 3: 155/159 Loss: 0.248917
2022-12-28 07:24: Train Epoch 3: 156/159 Loss: 0.281572
2022-12-28 07:25: Train Epoch 3: 157/159 Loss: 0.247166
2022-12-28 07:25: Train Epoch 3: 158/159 Loss: 0.247668
2022-12-28 07:25: **********Train Epoch 3: averaged Loss: 0.276767 
2022-12-28 07:25: 
Epoch time elapsed: 8434.547787427902

2022-12-28 07:29: 
 metrics validation: {'precision': 0.7371575342465754, 'recall': 0.6623076923076923, 'f1-score': 0.6977309562398704, 'support': 1300, 'AUC': 0.8469523668639054, 'AUCPR': 0.769873304767063, 'TP': 861, 'FP': 307, 'TN': 2293, 'FN': 439} 

2022-12-28 07:29: **********Val Epoch 3: average Loss: 0.534132
2022-12-28 07:29: *********************************Current best model saved!
2022-12-28 07:33: 
 Testing metrics {'precision': 0.8144424131627057, 'recall': 0.7255700325732899, 'f1-score': 0.7674418604651163, 'support': 1228, 'AUC': 0.8738610621863361, 'AUCPR': 0.8133754715129284, 'TP': 891, 'FP': 203, 'TN': 2253, 'FN': 337} 

2022-12-28 07:34: Train Epoch 4: 0/159 Loss: 0.227567
2022-12-28 07:35: Train Epoch 4: 1/159 Loss: 0.276779
2022-12-28 07:36: Train Epoch 4: 2/159 Loss: 0.297408
2022-12-28 07:36: Train Epoch 4: 3/159 Loss: 0.230786
2022-12-28 07:37: Train Epoch 4: 4/159 Loss: 0.235636
2022-12-28 07:38: Train Epoch 4: 5/159 Loss: 0.301233
2022-12-28 07:39: Train Epoch 4: 6/159 Loss: 0.297330
2022-12-28 07:40: Train Epoch 4: 7/159 Loss: 0.256399
2022-12-28 07:41: Train Epoch 4: 8/159 Loss: 0.252945
2022-12-28 07:42: Train Epoch 4: 9/159 Loss: 0.247229
2022-12-28 07:43: Train Epoch 4: 10/159 Loss: 0.279671
2022-12-28 07:43: Train Epoch 4: 11/159 Loss: 0.246957
2022-12-28 07:44: Train Epoch 4: 12/159 Loss: 0.209274
2022-12-28 07:45: Train Epoch 4: 13/159 Loss: 0.281221
2022-12-28 07:46: Train Epoch 4: 14/159 Loss: 0.328831
2022-12-28 07:47: Train Epoch 4: 15/159 Loss: 0.215715
2022-12-28 07:48: Train Epoch 4: 16/159 Loss: 0.273338
2022-12-28 07:49: Train Epoch 4: 17/159 Loss: 0.193891
2022-12-28 07:50: Train Epoch 4: 18/159 Loss: 0.286812
2022-12-28 07:51: Train Epoch 4: 19/159 Loss: 0.238981
2022-12-28 07:51: Train Epoch 4: 20/159 Loss: 0.236275
2022-12-28 07:52: Train Epoch 4: 21/159 Loss: 0.272908
2022-12-28 07:53: Train Epoch 4: 22/159 Loss: 0.232664
2022-12-28 07:54: Train Epoch 4: 23/159 Loss: 0.242117
2022-12-28 07:55: Train Epoch 4: 24/159 Loss: 0.242751
2022-12-28 07:56: Train Epoch 4: 25/159 Loss: 0.339184
2022-12-28 07:57: Train Epoch 4: 26/159 Loss: 0.322479
2022-12-28 07:58: Train Epoch 4: 27/159 Loss: 0.264775
2022-12-28 07:59: Train Epoch 4: 28/159 Loss: 0.213150
2022-12-28 08:00: Train Epoch 4: 29/159 Loss: 0.211294
2022-12-28 08:00: Train Epoch 4: 30/159 Loss: 0.217248
2022-12-28 08:01: Train Epoch 4: 31/159 Loss: 0.202774
2022-12-28 08:02: Train Epoch 4: 32/159 Loss: 0.277747
2022-12-28 08:03: Train Epoch 4: 33/159 Loss: 0.273408
2022-12-28 08:04: Train Epoch 4: 34/159 Loss: 0.258771
2022-12-28 08:05: Train Epoch 4: 35/159 Loss: 0.250229
2022-12-28 08:06: Train Epoch 4: 36/159 Loss: 0.262535
2022-12-28 08:07: Train Epoch 4: 37/159 Loss: 0.322984
2022-12-28 08:08: Train Epoch 4: 38/159 Loss: 0.295112
2022-12-28 08:08: Train Epoch 4: 39/159 Loss: 0.313639
2022-12-28 08:09: Train Epoch 4: 40/159 Loss: 0.292577
2022-12-28 08:10: Train Epoch 4: 41/159 Loss: 0.214478
2022-12-28 08:11: Train Epoch 4: 42/159 Loss: 0.270836
2022-12-28 08:12: Train Epoch 4: 43/159 Loss: 0.296483
2022-12-28 08:13: Train Epoch 4: 44/159 Loss: 0.242961
2022-12-28 08:14: Train Epoch 4: 45/159 Loss: 0.299708
2022-12-28 08:15: Train Epoch 4: 46/159 Loss: 0.244222
2022-12-28 08:16: Train Epoch 4: 47/159 Loss: 0.293370
2022-12-28 08:16: Train Epoch 4: 48/159 Loss: 0.315704
2022-12-28 08:17: Train Epoch 4: 49/159 Loss: 0.224854
2022-12-28 08:18: Train Epoch 4: 50/159 Loss: 0.254456
2022-12-28 08:19: Train Epoch 4: 51/159 Loss: 0.231271
2022-12-28 08:20: Train Epoch 4: 52/159 Loss: 0.309721
2022-12-28 08:21: Train Epoch 4: 53/159 Loss: 0.231940
2022-12-28 08:22: Train Epoch 4: 54/159 Loss: 0.278319
2022-12-28 08:23: Train Epoch 4: 55/159 Loss: 0.284056
2022-12-28 08:24: Train Epoch 4: 56/159 Loss: 0.259330
2022-12-28 08:24: Train Epoch 4: 57/159 Loss: 0.296075
2022-12-28 08:25: Train Epoch 4: 58/159 Loss: 0.242381
2022-12-28 08:26: Train Epoch 4: 59/159 Loss: 0.280300
2022-12-28 08:27: Train Epoch 4: 60/159 Loss: 0.333410
2022-12-28 08:28: Train Epoch 4: 61/159 Loss: 0.252424
2022-12-28 08:29: Train Epoch 4: 62/159 Loss: 0.283626
2022-12-28 08:30: Train Epoch 4: 63/159 Loss: 0.249361
2022-12-28 08:31: Train Epoch 4: 64/159 Loss: 0.243526
2022-12-28 08:32: Train Epoch 4: 65/159 Loss: 0.277415
2022-12-28 08:32: Train Epoch 4: 66/159 Loss: 0.264755
2022-12-28 08:33: Train Epoch 4: 67/159 Loss: 0.308653
2022-12-28 08:34: Train Epoch 4: 68/159 Loss: 0.291047
2022-12-28 08:35: Train Epoch 4: 69/159 Loss: 0.220391
2022-12-28 08:36: Train Epoch 4: 70/159 Loss: 0.232939
2022-12-28 08:37: Train Epoch 4: 71/159 Loss: 0.252798
2022-12-28 08:38: Train Epoch 4: 72/159 Loss: 0.303874
2022-12-28 08:39: Train Epoch 4: 73/159 Loss: 0.296645
2022-12-28 08:40: Train Epoch 4: 74/159 Loss: 0.259505
2022-12-28 08:40: Train Epoch 4: 75/159 Loss: 0.281342
2022-12-28 08:41: Train Epoch 4: 76/159 Loss: 0.289779
2022-12-28 08:42: Train Epoch 4: 77/159 Loss: 0.228466
2022-12-28 08:43: Train Epoch 4: 78/159 Loss: 0.261316
2022-12-28 08:44: Train Epoch 4: 79/159 Loss: 0.283987
2022-12-28 08:45: Train Epoch 4: 80/159 Loss: 0.197985
2022-12-28 08:46: Train Epoch 4: 81/159 Loss: 0.292369
2022-12-28 08:47: Train Epoch 4: 82/159 Loss: 0.297962
2022-12-28 08:48: Train Epoch 4: 83/159 Loss: 0.259998
2022-12-28 08:48: Train Epoch 4: 84/159 Loss: 0.219490
2022-12-28 08:49: Train Epoch 4: 85/159 Loss: 0.265727
2022-12-28 08:50: Train Epoch 4: 86/159 Loss: 0.285227
2022-12-28 08:51: Train Epoch 4: 87/159 Loss: 0.265033
2022-12-28 08:52: Train Epoch 4: 88/159 Loss: 0.301202
2022-12-28 08:53: Train Epoch 4: 89/159 Loss: 0.348597
2022-12-28 08:54: Train Epoch 4: 90/159 Loss: 0.278149
2022-12-28 08:55: Train Epoch 4: 91/159 Loss: 0.271497
2022-12-28 08:56: Train Epoch 4: 92/159 Loss: 0.360599
2022-12-28 08:56: Train Epoch 4: 93/159 Loss: 0.320574
2022-12-28 08:57: Train Epoch 4: 94/159 Loss: 0.251936
2022-12-28 08:58: Train Epoch 4: 95/159 Loss: 0.312776
2022-12-28 08:59: Train Epoch 4: 96/159 Loss: 0.257947
2022-12-28 09:00: Train Epoch 4: 97/159 Loss: 0.273199
2022-12-28 09:01: Train Epoch 4: 98/159 Loss: 0.225043
2022-12-28 09:02: Train Epoch 4: 99/159 Loss: 0.277382
2022-12-28 09:03: Train Epoch 4: 100/159 Loss: 0.259351
2022-12-28 09:04: Train Epoch 4: 101/159 Loss: 0.279344
2022-12-28 09:04: Train Epoch 4: 102/159 Loss: 0.291016
2022-12-28 09:05: Train Epoch 4: 103/159 Loss: 0.233544
2022-12-28 09:06: Train Epoch 4: 104/159 Loss: 0.280242
2022-12-28 09:07: Train Epoch 4: 105/159 Loss: 0.234018
2022-12-28 09:08: Train Epoch 4: 106/159 Loss: 0.322004
2022-12-28 09:09: Train Epoch 4: 107/159 Loss: 0.254709
2022-12-28 09:10: Train Epoch 4: 108/159 Loss: 0.269729
2022-12-28 09:11: Train Epoch 4: 109/159 Loss: 0.216599
2022-12-28 09:12: Train Epoch 4: 110/159 Loss: 0.294316
2022-12-28 09:12: Train Epoch 4: 111/159 Loss: 0.261874
2022-12-28 09:13: Train Epoch 4: 112/159 Loss: 0.218998
2022-12-28 09:14: Train Epoch 4: 113/159 Loss: 0.187253
2022-12-28 09:15: Train Epoch 4: 114/159 Loss: 0.231742
2022-12-28 09:16: Train Epoch 4: 115/159 Loss: 0.268456
2022-12-28 09:17: Train Epoch 4: 116/159 Loss: 0.254118
2022-12-28 09:18: Train Epoch 4: 117/159 Loss: 0.315374
2022-12-28 09:19: Train Epoch 4: 118/159 Loss: 0.216164
2022-12-28 09:20: Train Epoch 4: 119/159 Loss: 0.254718
2022-12-28 09:20: Train Epoch 4: 120/159 Loss: 0.252903
2022-12-28 09:21: Train Epoch 4: 121/159 Loss: 0.286889
2022-12-28 09:22: Train Epoch 4: 122/159 Loss: 0.228549
2022-12-28 09:23: Train Epoch 4: 123/159 Loss: 0.266809
2022-12-28 09:24: Train Epoch 4: 124/159 Loss: 0.263304
2022-12-28 09:25: Train Epoch 4: 125/159 Loss: 0.262629
2022-12-28 09:26: Train Epoch 4: 126/159 Loss: 0.315344
2022-12-28 09:27: Train Epoch 4: 127/159 Loss: 0.239342
2022-12-28 09:27: Train Epoch 4: 128/159 Loss: 0.297554
2022-12-28 09:28: Train Epoch 4: 129/159 Loss: 0.282102
2022-12-28 09:29: Train Epoch 4: 130/159 Loss: 0.260518
2022-12-28 09:30: Train Epoch 4: 131/159 Loss: 0.228169
2022-12-28 09:31: Train Epoch 4: 132/159 Loss: 0.243001
2022-12-28 09:32: Train Epoch 4: 133/159 Loss: 0.259034
2022-12-28 09:33: Train Epoch 4: 134/159 Loss: 0.303035
2022-12-28 09:34: Train Epoch 4: 135/159 Loss: 0.203396
2022-12-28 09:35: Train Epoch 4: 136/159 Loss: 0.237461
2022-12-28 09:35: Train Epoch 4: 137/159 Loss: 0.284951
2022-12-28 09:36: Train Epoch 4: 138/159 Loss: 0.235830
2022-12-28 09:37: Train Epoch 4: 139/159 Loss: 0.302994
2022-12-28 09:38: Train Epoch 4: 140/159 Loss: 0.331003
2022-12-28 09:39: Train Epoch 4: 141/159 Loss: 0.245435
2022-12-28 09:40: Train Epoch 4: 142/159 Loss: 0.265012
2022-12-28 09:41: Train Epoch 4: 143/159 Loss: 0.250660
2022-12-28 09:42: Train Epoch 4: 144/159 Loss: 0.202083
2022-12-28 09:43: Train Epoch 4: 145/159 Loss: 0.296144
2022-12-28 09:43: Train Epoch 4: 146/159 Loss: 0.289645
2022-12-28 09:44: Train Epoch 4: 147/159 Loss: 0.258463
2022-12-28 09:45: Train Epoch 4: 148/159 Loss: 0.255185
2022-12-28 09:46: Train Epoch 4: 149/159 Loss: 0.231687
2022-12-28 09:47: Train Epoch 4: 150/159 Loss: 0.293411
2022-12-28 09:48: Train Epoch 4: 151/159 Loss: 0.250625
2022-12-28 09:49: Train Epoch 4: 152/159 Loss: 0.299613
2022-12-28 09:50: Train Epoch 4: 153/159 Loss: 0.262037
2022-12-28 09:50: Train Epoch 4: 154/159 Loss: 0.270953
2022-12-28 09:51: Train Epoch 4: 155/159 Loss: 0.245676
2022-12-28 09:52: Train Epoch 4: 156/159 Loss: 0.296024
2022-12-28 09:53: Train Epoch 4: 157/159 Loss: 0.334231
2022-12-28 09:53: Train Epoch 4: 158/159 Loss: 0.258862
2022-12-28 09:53: **********Train Epoch 4: averaged Loss: 0.266070 
2022-12-28 09:53: 
Epoch time elapsed: 8445.10093665123

2022-12-28 09:57: 
 metrics validation: {'precision': 0.7987866531850354, 'recall': 0.6076923076923076, 'f1-score': 0.690257754477938, 'support': 1300, 'AUC': 0.8567210059171597, 'AUCPR': 0.7843056991794801, 'TP': 790, 'FP': 199, 'TN': 2401, 'FN': 510} 

2022-12-28 09:57: **********Val Epoch 4: average Loss: 0.533340
2022-12-28 09:57: *********************************Current best model saved!
2022-12-28 10:01: 
 Testing metrics {'precision': 0.850187265917603, 'recall': 0.5545602605863192, 'f1-score': 0.6712666338097585, 'support': 1228, 'AUC': 0.87712021480334, 'AUCPR': 0.819564262645715, 'TP': 681, 'FP': 120, 'TN': 2336, 'FN': 547} 

2022-12-28 10:02: Train Epoch 5: 0/159 Loss: 0.250022
2022-12-28 10:03: Train Epoch 5: 1/159 Loss: 0.285769
2022-12-28 10:04: Train Epoch 5: 2/159 Loss: 0.271289
2022-12-28 10:05: Train Epoch 5: 3/159 Loss: 0.276090
2022-12-28 10:06: Train Epoch 5: 4/159 Loss: 0.291898
2022-12-28 10:07: Train Epoch 5: 5/159 Loss: 0.223777
2022-12-28 10:08: Train Epoch 5: 6/159 Loss: 0.256074
2022-12-28 10:08: Train Epoch 5: 7/159 Loss: 0.316118
2022-12-28 10:09: Train Epoch 5: 8/159 Loss: 0.208846
2022-12-28 10:10: Train Epoch 5: 9/159 Loss: 0.270700
2022-12-28 10:11: Train Epoch 5: 10/159 Loss: 0.285550
2022-12-28 10:12: Train Epoch 5: 11/159 Loss: 0.267912
2022-12-28 10:13: Train Epoch 5: 12/159 Loss: 0.281808
2022-12-28 10:14: Train Epoch 5: 13/159 Loss: 0.217262
2022-12-28 10:15: Train Epoch 5: 14/159 Loss: 0.239204
2022-12-28 10:15: Train Epoch 5: 15/159 Loss: 0.271756
2022-12-28 10:16: Train Epoch 5: 16/159 Loss: 0.313481
2022-12-28 10:17: Train Epoch 5: 17/159 Loss: 0.268391
2022-12-28 10:18: Train Epoch 5: 18/159 Loss: 0.299269
2022-12-28 10:19: Train Epoch 5: 19/159 Loss: 0.318702
2022-12-28 10:20: Train Epoch 5: 20/159 Loss: 0.226170
2022-12-28 10:21: Train Epoch 5: 21/159 Loss: 0.307796
2022-12-28 10:22: Train Epoch 5: 22/159 Loss: 0.232113
2022-12-28 10:23: Train Epoch 5: 23/159 Loss: 0.229542
2022-12-28 10:23: Train Epoch 5: 24/159 Loss: 0.248015
2022-12-28 10:24: Train Epoch 5: 25/159 Loss: 0.199266
2022-12-28 10:25: Train Epoch 5: 26/159 Loss: 0.254893
2022-12-28 10:26: Train Epoch 5: 27/159 Loss: 0.272756
2022-12-28 10:27: Train Epoch 5: 28/159 Loss: 0.223396
2022-12-28 10:28: Train Epoch 5: 29/159 Loss: 0.240477
2022-12-28 10:29: Train Epoch 5: 30/159 Loss: 0.344026
2022-12-28 10:30: Train Epoch 5: 31/159 Loss: 0.223429
2022-12-28 10:31: Train Epoch 5: 32/159 Loss: 0.284258
2022-12-28 10:31: Train Epoch 5: 33/159 Loss: 0.217850
2022-12-28 10:32: Train Epoch 5: 34/159 Loss: 0.245349
2022-12-28 10:33: Train Epoch 5: 35/159 Loss: 0.231267
2022-12-28 10:34: Train Epoch 5: 36/159 Loss: 0.284999
2022-12-28 10:35: Train Epoch 5: 37/159 Loss: 0.318763
2022-12-28 10:36: Train Epoch 5: 38/159 Loss: 0.236185
2022-12-28 10:37: Train Epoch 5: 39/159 Loss: 0.180191
2022-12-28 10:38: Train Epoch 5: 40/159 Loss: 0.292186
2022-12-28 10:38: Train Epoch 5: 41/159 Loss: 0.249645
2022-12-28 10:39: Train Epoch 5: 42/159 Loss: 0.240787
2022-12-28 10:40: Train Epoch 5: 43/159 Loss: 0.304791
2022-12-28 10:41: Train Epoch 5: 44/159 Loss: 0.209472
2022-12-28 10:42: Train Epoch 5: 45/159 Loss: 0.304896
2022-12-28 10:43: Train Epoch 5: 46/159 Loss: 0.298856
2022-12-28 10:44: Train Epoch 5: 47/159 Loss: 0.241639
2022-12-28 10:45: Train Epoch 5: 48/159 Loss: 0.295620
2022-12-28 10:46: Train Epoch 5: 49/159 Loss: 0.312785
2022-12-28 10:46: Train Epoch 5: 50/159 Loss: 0.274531
2022-12-28 10:47: Train Epoch 5: 51/159 Loss: 0.333824
2022-12-28 10:48: Train Epoch 5: 52/159 Loss: 0.295279
2022-12-28 10:49: Train Epoch 5: 53/159 Loss: 0.308796
2022-12-28 10:50: Train Epoch 5: 54/159 Loss: 0.235781
2022-12-28 10:51: Train Epoch 5: 55/159 Loss: 0.219905
2022-12-28 10:52: Train Epoch 5: 56/159 Loss: 0.248898
2022-12-28 10:53: Train Epoch 5: 57/159 Loss: 0.257142
2022-12-28 10:54: Train Epoch 5: 58/159 Loss: 0.224867
2022-12-28 10:54: Train Epoch 5: 59/159 Loss: 0.276143
2022-12-28 10:55: Train Epoch 5: 60/159 Loss: 0.317436
2022-12-28 10:56: Train Epoch 5: 61/159 Loss: 0.323892
2022-12-28 10:57: Train Epoch 5: 62/159 Loss: 0.253211
2022-12-28 10:58: Train Epoch 5: 63/159 Loss: 0.265795
2022-12-28 10:59: Train Epoch 5: 64/159 Loss: 0.289437
2022-12-28 11:00: Train Epoch 5: 65/159 Loss: 0.246560
2022-12-28 11:01: Train Epoch 5: 66/159 Loss: 0.269236
2022-12-28 11:01: Train Epoch 5: 67/159 Loss: 0.212767
2022-12-28 11:02: Train Epoch 5: 68/159 Loss: 0.221704
2022-12-28 11:03: Train Epoch 5: 69/159 Loss: 0.289751
2022-12-28 11:04: Train Epoch 5: 70/159 Loss: 0.224337
2022-12-28 11:05: Train Epoch 5: 71/159 Loss: 0.227729
2022-12-28 11:06: Train Epoch 5: 72/159 Loss: 0.262796
2022-12-28 11:07: Train Epoch 5: 73/159 Loss: 0.236170
2022-12-28 11:08: Train Epoch 5: 74/159 Loss: 0.411318
2022-12-28 11:09: Train Epoch 5: 75/159 Loss: 0.272227
2022-12-28 11:09: Train Epoch 5: 76/159 Loss: 0.276174
2022-12-28 11:10: Train Epoch 5: 77/159 Loss: 0.271360
2022-12-28 11:11: Train Epoch 5: 78/159 Loss: 0.246185
2022-12-28 11:12: Train Epoch 5: 79/159 Loss: 0.224648
2022-12-28 11:13: Train Epoch 5: 80/159 Loss: 0.248157
2022-12-28 11:14: Train Epoch 5: 81/159 Loss: 0.300760
2022-12-28 11:15: Train Epoch 5: 82/159 Loss: 0.272671
2022-12-28 11:16: Train Epoch 5: 83/159 Loss: 0.253189
2022-12-28 11:16: Train Epoch 5: 84/159 Loss: 0.224159
2022-12-28 11:17: Train Epoch 5: 85/159 Loss: 0.308448
2022-12-28 11:18: Train Epoch 5: 86/159 Loss: 0.200819
2022-12-28 11:19: Train Epoch 5: 87/159 Loss: 0.219019
2022-12-28 11:20: Train Epoch 5: 88/159 Loss: 0.276737
2022-12-28 11:21: Train Epoch 5: 89/159 Loss: 0.240524
2022-12-28 11:22: Train Epoch 5: 90/159 Loss: 0.346798
2022-12-28 11:23: Train Epoch 5: 91/159 Loss: 0.217853
2022-12-28 11:23: Train Epoch 5: 92/159 Loss: 0.290658
2022-12-28 11:24: Train Epoch 5: 93/159 Loss: 0.213932
2022-12-28 11:25: Train Epoch 5: 94/159 Loss: 0.230273
2022-12-28 11:26: Train Epoch 5: 95/159 Loss: 0.255559
2022-12-28 11:27: Train Epoch 5: 96/159 Loss: 0.294449
2022-12-28 11:28: Train Epoch 5: 97/159 Loss: 0.246624
2022-12-28 11:29: Train Epoch 5: 98/159 Loss: 0.213154
2022-12-28 11:30: Train Epoch 5: 99/159 Loss: 0.172532
2022-12-28 11:31: Train Epoch 5: 100/159 Loss: 0.244720
2022-12-28 11:31: Train Epoch 5: 101/159 Loss: 0.252855
2022-12-28 11:32: Train Epoch 5: 102/159 Loss: 0.231876
2022-12-28 11:33: Train Epoch 5: 103/159 Loss: 0.217897
2022-12-28 11:34: Train Epoch 5: 104/159 Loss: 0.281684
2022-12-28 11:35: Train Epoch 5: 105/159 Loss: 0.293003
2022-12-28 11:36: Train Epoch 5: 106/159 Loss: 0.246809
2022-12-28 11:37: Train Epoch 5: 107/159 Loss: 0.230783
2022-12-28 11:38: Train Epoch 5: 108/159 Loss: 0.297396
2022-12-28 11:39: Train Epoch 5: 109/159 Loss: 0.221806
2022-12-28 11:39: Train Epoch 5: 110/159 Loss: 0.335702
2022-12-28 11:40: Train Epoch 5: 111/159 Loss: 0.237929
2022-12-28 11:41: Train Epoch 5: 112/159 Loss: 0.212729
2022-12-28 11:42: Train Epoch 5: 113/159 Loss: 0.309370
2022-12-28 11:43: Train Epoch 5: 114/159 Loss: 0.246661
2022-12-28 11:44: Train Epoch 5: 115/159 Loss: 0.294906
2022-12-28 11:45: Train Epoch 5: 116/159 Loss: 0.234805
2022-12-28 11:46: Train Epoch 5: 117/159 Loss: 0.316688
2022-12-28 11:47: Train Epoch 5: 118/159 Loss: 0.287895
2022-12-28 11:47: Train Epoch 5: 119/159 Loss: 0.244986
2022-12-28 11:48: Train Epoch 5: 120/159 Loss: 0.266456
2022-12-28 11:49: Train Epoch 5: 121/159 Loss: 0.225826
2022-12-28 11:50: Train Epoch 5: 122/159 Loss: 0.291959
2022-12-28 11:51: Train Epoch 5: 123/159 Loss: 0.287448
2022-12-28 11:52: Train Epoch 5: 124/159 Loss: 0.228470
2022-12-28 11:53: Train Epoch 5: 125/159 Loss: 0.299945
2022-12-28 11:54: Train Epoch 5: 126/159 Loss: 0.221416
2022-12-28 11:55: Train Epoch 5: 127/159 Loss: 0.241762
2022-12-28 11:55: Train Epoch 5: 128/159 Loss: 0.267409
2022-12-28 11:56: Train Epoch 5: 129/159 Loss: 0.318270
2022-12-28 11:57: Train Epoch 5: 130/159 Loss: 0.251428
2022-12-28 11:58: Train Epoch 5: 131/159 Loss: 0.319058
2022-12-28 11:59: Train Epoch 5: 132/159 Loss: 0.171177
2022-12-28 12:00: Train Epoch 5: 133/159 Loss: 0.271615
2022-12-28 12:01: Train Epoch 5: 134/159 Loss: 0.271242
2022-12-28 12:02: Train Epoch 5: 135/159 Loss: 0.300790
2022-12-28 12:03: Train Epoch 5: 136/159 Loss: 0.247813
2022-12-28 12:03: Train Epoch 5: 137/159 Loss: 0.267803
2022-12-28 12:04: Train Epoch 5: 138/159 Loss: 0.209378
2022-12-28 12:05: Train Epoch 5: 139/159 Loss: 0.295280
2022-12-28 12:06: Train Epoch 5: 140/159 Loss: 0.262772
2022-12-28 12:07: Train Epoch 5: 141/159 Loss: 0.239869
2022-12-28 12:08: Train Epoch 5: 142/159 Loss: 0.284392
2022-12-28 12:09: Train Epoch 5: 143/159 Loss: 0.275284
2022-12-28 12:10: Train Epoch 5: 144/159 Loss: 0.257174
2022-12-28 12:11: Train Epoch 5: 145/159 Loss: 0.239545
2022-12-28 12:11: Train Epoch 5: 146/159 Loss: 0.285634
2022-12-28 12:12: Train Epoch 5: 147/159 Loss: 0.217102
2022-12-28 12:13: Train Epoch 5: 148/159 Loss: 0.330092
2022-12-28 12:14: Train Epoch 5: 149/159 Loss: 0.246708
2022-12-28 12:15: Train Epoch 5: 150/159 Loss: 0.249345
2022-12-28 12:16: Train Epoch 5: 151/159 Loss: 0.286854
2022-12-28 12:17: Train Epoch 5: 152/159 Loss: 0.274862
2022-12-28 12:18: Train Epoch 5: 153/159 Loss: 0.266429
2022-12-28 12:19: Train Epoch 5: 154/159 Loss: 0.237860
2022-12-28 12:19: Train Epoch 5: 155/159 Loss: 0.267183
2022-12-28 12:20: Train Epoch 5: 156/159 Loss: 0.250564
2022-12-28 12:21: Train Epoch 5: 157/159 Loss: 0.218604
2022-12-28 12:22: Train Epoch 5: 158/159 Loss: 0.178115
2022-12-28 12:22: **********Train Epoch 5: averaged Loss: 0.261465 
2022-12-28 12:22: 
Epoch time elapsed: 8430.89761042595

2022-12-28 12:25: 
 metrics validation: {'precision': 0.7931372549019607, 'recall': 0.6223076923076923, 'f1-score': 0.6974137931034483, 'support': 1300, 'AUC': 0.8582934911242603, 'AUCPR': 0.7853234763417575, 'TP': 809, 'FP': 211, 'TN': 2389, 'FN': 491} 

2022-12-28 12:25: **********Val Epoch 5: average Loss: 0.524773
2022-12-28 12:25: *********************************Current best model saved!
2022-12-28 12:29: 
 Testing metrics {'precision': 0.8500563697857948, 'recall': 0.6140065146579805, 'f1-score': 0.7130023640661939, 'support': 1228, 'AUC': 0.8816641953760783, 'AUCPR': 0.8265972431903841, 'TP': 754, 'FP': 133, 'TN': 2323, 'FN': 474} 

2022-12-28 12:30: Train Epoch 6: 0/159 Loss: 0.238605
2022-12-28 12:31: Train Epoch 6: 1/159 Loss: 0.265114
2022-12-28 12:32: Train Epoch 6: 2/159 Loss: 0.257770
2022-12-28 12:33: Train Epoch 6: 3/159 Loss: 0.302680
2022-12-28 12:34: Train Epoch 6: 4/159 Loss: 0.204980
2022-12-28 12:35: Train Epoch 6: 5/159 Loss: 0.317874
2022-12-28 12:36: Train Epoch 6: 6/159 Loss: 0.357524
2022-12-28 12:37: Train Epoch 6: 7/159 Loss: 0.284985
2022-12-28 12:37: Train Epoch 6: 8/159 Loss: 0.199785
2022-12-28 12:38: Train Epoch 6: 9/159 Loss: 0.267827
2022-12-28 12:39: Train Epoch 6: 10/159 Loss: 0.236919
2022-12-28 12:40: Train Epoch 6: 11/159 Loss: 0.234533
2022-12-28 12:41: Train Epoch 6: 12/159 Loss: 0.272970
2022-12-28 12:42: Train Epoch 6: 13/159 Loss: 0.284161
2022-12-28 12:43: Train Epoch 6: 14/159 Loss: 0.321742
2022-12-28 12:44: Train Epoch 6: 15/159 Loss: 0.215469
2022-12-28 12:45: Train Epoch 6: 16/159 Loss: 0.254888
2022-12-28 12:45: Train Epoch 6: 17/159 Loss: 0.254194
2022-12-28 12:46: Train Epoch 6: 18/159 Loss: 0.239939
2022-12-28 12:47: Train Epoch 6: 19/159 Loss: 0.247370
2022-12-28 12:48: Train Epoch 6: 20/159 Loss: 0.258502
2022-12-28 12:49: Train Epoch 6: 21/159 Loss: 0.242150
2022-12-28 12:50: Train Epoch 6: 22/159 Loss: 0.262724
2022-12-28 12:51: Train Epoch 6: 23/159 Loss: 0.226367
2022-12-28 12:52: Train Epoch 6: 24/159 Loss: 0.233393
2022-12-28 12:53: Train Epoch 6: 25/159 Loss: 0.253034
2022-12-28 12:53: Train Epoch 6: 26/159 Loss: 0.181622
2022-12-28 12:54: Train Epoch 6: 27/159 Loss: 0.286346
2022-12-28 12:55: Train Epoch 6: 28/159 Loss: 0.234489
2022-12-28 12:56: Train Epoch 6: 29/159 Loss: 0.266187
2022-12-28 12:57: Train Epoch 6: 30/159 Loss: 0.265272
2022-12-28 12:58: Train Epoch 6: 31/159 Loss: 0.208589
2022-12-28 12:59: Train Epoch 6: 32/159 Loss: 0.310049
2022-12-28 13:00: Train Epoch 6: 33/159 Loss: 0.287516
2022-12-28 13:01: Train Epoch 6: 34/159 Loss: 0.252903
2022-12-28 13:01: Train Epoch 6: 35/159 Loss: 0.249462
2022-12-28 13:02: Train Epoch 6: 36/159 Loss: 0.228937
2022-12-28 13:03: Train Epoch 6: 37/159 Loss: 0.260718
2022-12-28 13:04: Train Epoch 6: 38/159 Loss: 0.269268
2022-12-28 13:05: Train Epoch 6: 39/159 Loss: 0.242430
2022-12-28 13:06: Train Epoch 6: 40/159 Loss: 0.289251
2022-12-28 13:07: Train Epoch 6: 41/159 Loss: 0.275203
2022-12-28 13:08: Train Epoch 6: 42/159 Loss: 0.234055
2022-12-28 13:09: Train Epoch 6: 43/159 Loss: 0.282017
2022-12-28 13:09: Train Epoch 6: 44/159 Loss: 0.293024
2022-12-28 13:10: Train Epoch 6: 45/159 Loss: 0.211239
2022-12-28 13:11: Train Epoch 6: 46/159 Loss: 0.270028
2022-12-28 13:12: Train Epoch 6: 47/159 Loss: 0.226243
2022-12-28 13:13: Train Epoch 6: 48/159 Loss: 0.255939
2022-12-28 13:14: Train Epoch 6: 49/159 Loss: 0.249525
2022-12-28 13:15: Train Epoch 6: 50/159 Loss: 0.219041
2022-12-28 13:16: Train Epoch 6: 51/159 Loss: 0.325844
2022-12-28 13:16: Train Epoch 6: 52/159 Loss: 0.264198
2022-12-28 13:17: Train Epoch 6: 53/159 Loss: 0.269862
2022-12-28 13:18: Train Epoch 6: 54/159 Loss: 0.300563
2022-12-28 13:19: Train Epoch 6: 55/159 Loss: 0.238979
2022-12-28 13:20: Train Epoch 6: 56/159 Loss: 0.265828
2022-12-28 13:21: Train Epoch 6: 57/159 Loss: 0.232870
2022-12-28 13:22: Train Epoch 6: 58/159 Loss: 0.266533
2022-12-28 13:23: Train Epoch 6: 59/159 Loss: 0.241984
2022-12-28 13:24: Train Epoch 6: 60/159 Loss: 0.250485
2022-12-28 13:24: Train Epoch 6: 61/159 Loss: 0.288041
2022-12-28 13:25: Train Epoch 6: 62/159 Loss: 0.216141
2022-12-28 13:26: Train Epoch 6: 63/159 Loss: 0.270135
2022-12-28 13:27: Train Epoch 6: 64/159 Loss: 0.274792
2022-12-28 13:28: Train Epoch 6: 65/159 Loss: 0.252674
2022-12-28 13:29: Train Epoch 6: 66/159 Loss: 0.235298
2022-12-28 13:30: Train Epoch 6: 67/159 Loss: 0.284941
2022-12-28 13:31: Train Epoch 6: 68/159 Loss: 0.227275
2022-12-28 13:31: Train Epoch 6: 69/159 Loss: 0.269609
2022-12-28 13:32: Train Epoch 6: 70/159 Loss: 0.266821
2022-12-28 13:33: Train Epoch 6: 71/159 Loss: 0.245646
2022-12-28 13:34: Train Epoch 6: 72/159 Loss: 0.305263
2022-12-28 13:35: Train Epoch 6: 73/159 Loss: 0.215550
2022-12-28 13:36: Train Epoch 6: 74/159 Loss: 0.304896
2022-12-28 13:37: Train Epoch 6: 75/159 Loss: 0.232133
2022-12-28 13:38: Train Epoch 6: 76/159 Loss: 0.216739
2022-12-28 13:39: Train Epoch 6: 77/159 Loss: 0.235030
2022-12-28 13:39: Train Epoch 6: 78/159 Loss: 0.336895
2022-12-28 13:40: Train Epoch 6: 79/159 Loss: 0.304806
2022-12-28 13:41: Train Epoch 6: 80/159 Loss: 0.249959
2022-12-28 13:42: Train Epoch 6: 81/159 Loss: 0.280179
2022-12-28 13:43: Train Epoch 6: 82/159 Loss: 0.285303
2022-12-28 13:44: Train Epoch 6: 83/159 Loss: 0.241015
2022-12-28 13:45: Train Epoch 6: 84/159 Loss: 0.208348
2022-12-28 13:46: Train Epoch 6: 85/159 Loss: 0.217677
2022-12-28 13:46: Train Epoch 6: 86/159 Loss: 0.247248
2022-12-28 13:47: Train Epoch 6: 87/159 Loss: 0.224625
2022-12-28 13:48: Train Epoch 6: 88/159 Loss: 0.214746
2022-12-28 13:49: Train Epoch 6: 89/159 Loss: 0.216167
2022-12-28 13:50: Train Epoch 6: 90/159 Loss: 0.255406
2022-12-28 13:51: Train Epoch 6: 91/159 Loss: 0.257144
2022-12-28 13:52: Train Epoch 6: 92/159 Loss: 0.267337
2022-12-28 13:53: Train Epoch 6: 93/159 Loss: 0.232670
2022-12-28 13:53: Train Epoch 6: 94/159 Loss: 0.241426
2022-12-28 13:54: Train Epoch 6: 95/159 Loss: 0.249447
2022-12-28 13:55: Train Epoch 6: 96/159 Loss: 0.238696
2022-12-28 13:56: Train Epoch 6: 97/159 Loss: 0.267756
2022-12-28 13:57: Train Epoch 6: 98/159 Loss: 0.347753
2022-12-28 13:58: Train Epoch 6: 99/159 Loss: 0.277734
2022-12-28 13:59: Train Epoch 6: 100/159 Loss: 0.226527
2022-12-28 14:00: Train Epoch 6: 101/159 Loss: 0.259546
2022-12-28 14:01: Train Epoch 6: 102/159 Loss: 0.170584
2022-12-28 14:01: Train Epoch 6: 103/159 Loss: 0.273231
2022-12-28 14:02: Train Epoch 6: 104/159 Loss: 0.210102
2022-12-28 14:03: Train Epoch 6: 105/159 Loss: 0.195516
2022-12-28 14:04: Train Epoch 6: 106/159 Loss: 0.283110
2022-12-28 14:05: Train Epoch 6: 107/159 Loss: 0.190585
2022-12-28 14:06: Train Epoch 6: 108/159 Loss: 0.166117
2022-12-28 14:07: Train Epoch 6: 109/159 Loss: 0.242588
2022-12-28 14:08: Train Epoch 6: 110/159 Loss: 0.271148
2022-12-28 14:09: Train Epoch 6: 111/159 Loss: 0.266470
2022-12-28 14:09: Train Epoch 6: 112/159 Loss: 0.242438
2022-12-28 14:10: Train Epoch 6: 113/159 Loss: 0.247868
2022-12-28 14:11: Train Epoch 6: 114/159 Loss: 0.271724
2022-12-28 14:12: Train Epoch 6: 115/159 Loss: 0.230477
2022-12-28 14:13: Train Epoch 6: 116/159 Loss: 0.279647
2022-12-28 14:14: Train Epoch 6: 117/159 Loss: 0.273190
2022-12-28 14:15: Train Epoch 6: 118/159 Loss: 0.280900
2022-12-28 14:16: Train Epoch 6: 119/159 Loss: 0.288004
2022-12-28 14:17: Train Epoch 6: 120/159 Loss: 0.282572
2022-12-28 14:17: Train Epoch 6: 121/159 Loss: 0.261243
2022-12-28 14:18: Train Epoch 6: 122/159 Loss: 0.254545
2022-12-28 14:19: Train Epoch 6: 123/159 Loss: 0.264797
2022-12-28 14:20: Train Epoch 6: 124/159 Loss: 0.256728
2022-12-28 14:21: Train Epoch 6: 125/159 Loss: 0.240402
2022-12-28 14:22: Train Epoch 6: 126/159 Loss: 0.261120
2022-12-28 14:23: Train Epoch 6: 127/159 Loss: 0.209999
2022-12-28 14:24: Train Epoch 6: 128/159 Loss: 0.242311
2022-12-28 14:24: Train Epoch 6: 129/159 Loss: 0.221446
2022-12-28 14:25: Train Epoch 6: 130/159 Loss: 0.227543
2022-12-28 14:26: Train Epoch 6: 131/159 Loss: 0.232006
2022-12-28 14:27: Train Epoch 6: 132/159 Loss: 0.225355
2022-12-28 14:28: Train Epoch 6: 133/159 Loss: 0.269820
2022-12-28 14:29: Train Epoch 6: 134/159 Loss: 0.239420
2022-12-28 14:30: Train Epoch 6: 135/159 Loss: 0.244439
2022-12-28 14:31: Train Epoch 6: 136/159 Loss: 0.255756
2022-12-28 14:32: Train Epoch 6: 137/159 Loss: 0.255086
2022-12-28 14:32: Train Epoch 6: 138/159 Loss: 0.239201
2022-12-28 14:33: Train Epoch 6: 139/159 Loss: 0.188495
2022-12-28 14:34: Train Epoch 6: 140/159 Loss: 0.235881
2022-12-28 14:35: Train Epoch 6: 141/159 Loss: 0.284990
2022-12-28 14:36: Train Epoch 6: 142/159 Loss: 0.241323
2022-12-28 14:37: Train Epoch 6: 143/159 Loss: 0.224861
2022-12-28 14:38: Train Epoch 6: 144/159 Loss: 0.220117
2022-12-28 14:39: Train Epoch 6: 145/159 Loss: 0.239376
2022-12-28 14:39: Train Epoch 6: 146/159 Loss: 0.247661
2022-12-28 14:40: Train Epoch 6: 147/159 Loss: 0.280656
2022-12-28 14:41: Train Epoch 6: 148/159 Loss: 0.208522
2022-12-28 14:42: Train Epoch 6: 149/159 Loss: 0.376732
2022-12-28 14:43: Train Epoch 6: 150/159 Loss: 0.253639
2022-12-28 14:44: Train Epoch 6: 151/159 Loss: 0.256255
2022-12-28 14:45: Train Epoch 6: 152/159 Loss: 0.310281
2022-12-28 14:46: Train Epoch 6: 153/159 Loss: 0.246592
2022-12-28 14:46: Train Epoch 6: 154/159 Loss: 0.213919
2022-12-28 14:47: Train Epoch 6: 155/159 Loss: 0.262735
2022-12-28 14:48: Train Epoch 6: 156/159 Loss: 0.262046
2022-12-28 14:49: Train Epoch 6: 157/159 Loss: 0.264271
2022-12-28 14:49: Train Epoch 6: 158/159 Loss: 0.198037
2022-12-28 14:49: **********Train Epoch 6: averaged Loss: 0.253555 
2022-12-28 14:49: 
Epoch time elapsed: 8407.956323862076

2022-12-28 14:53: 
 metrics validation: {'precision': 0.7949640287769785, 'recall': 0.68, 'f1-score': 0.7330016583747927, 'support': 1300, 'AUC': 0.8649917159763313, 'AUCPR': 0.796640781045956, 'TP': 884, 'FP': 228, 'TN': 2372, 'FN': 416} 

2022-12-28 14:53: **********Val Epoch 6: average Loss: 0.504722
2022-12-28 14:53: *********************************Current best model saved!
