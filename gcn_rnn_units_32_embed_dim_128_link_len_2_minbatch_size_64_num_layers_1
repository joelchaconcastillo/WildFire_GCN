2022-12-31 16:47: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123116475666372054013
2022-12-31 16:47: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123116475666372054013
2022-12-31 16:47: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=128, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123116475666372054013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=32, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-31 16:47: Argument batch_size: 256
2022-12-31 16:47: Argument clc: 'vec'
2022-12-31 16:47: Argument cuda: True
2022-12-31 16:47: Argument dataset: '2020'
2022-12-31 16:47: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-31 16:47: Argument debug: False
2022-12-31 16:47: Argument default_graph: True
2022-12-31 16:47: Argument device: 'cpu'
2022-12-31 16:47: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-31 16:47: Argument early_stop: True
2022-12-31 16:47: Argument early_stop_patience: 8
2022-12-31 16:47: Argument embed_dim: 128
2022-12-31 16:47: Argument epochs: 30
2022-12-31 16:47: Argument grad_norm: False
2022-12-31 16:47: Argument horizon: 1
2022-12-31 16:47: Argument input_dim: 25
2022-12-31 16:47: Argument lag: 10
2022-12-31 16:47: Argument link_len: 2
2022-12-31 16:47: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123116475666372054013'
2022-12-31 16:47: Argument log_step: 1
2022-12-31 16:47: Argument loss_func: 'nllloss'
2022-12-31 16:47: Argument lr_decay: True
2022-12-31 16:47: Argument lr_decay_rate: 0.1
2022-12-31 16:47: Argument lr_decay_step: '15, 20'
2022-12-31 16:47: Argument lr_init: 0.0001
2022-12-31 16:47: Argument max_grad_norm: 5
2022-12-31 16:47: Argument minbatch_size: 64
2022-12-31 16:47: Argument mode: 'train'
2022-12-31 16:47: Argument model: 'fire_GCN'
2022-12-31 16:47: Argument nan_fill: -1.0
2022-12-31 16:47: Argument num_layers: 1
2022-12-31 16:47: Argument num_nodes: 625
2022-12-31 16:47: Argument num_workers: 12
2022-12-31 16:47: Argument output_dim: 2
2022-12-31 16:47: Argument patch_height: 25
2022-12-31 16:47: Argument patch_width: 25
2022-12-31 16:47: Argument persistent_workers: True
2022-12-31 16:47: Argument pin_memory: True
2022-12-31 16:47: Argument plot: False
2022-12-31 16:47: Argument positive_weight: 0.5
2022-12-31 16:47: Argument prefetch_factor: 2
2022-12-31 16:47: Argument real_value: True
2022-12-31 16:47: Argument rnn_units: 32
2022-12-31 16:47: Argument seed: 10000
2022-12-31 16:47: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-31 16:47: Argument teacher_forcing: False
2022-12-31 16:47: Argument weight_decay: 0.0
2022-12-31 16:47: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 128]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([128, 2, 57, 32]) True
encoder.cell_list.0.gate.weights_window torch.Size([128, 1, 32]) True
encoder.cell_list.0.gate.bias_pool torch.Size([128, 64]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([128, 2, 57, 16]) True
encoder.cell_list.0.update.weights_window torch.Size([128, 1, 16]) True
encoder.cell_list.0.update.bias_pool torch.Size([128, 32]) True
encoder.cell_list.0.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 20000]) True
fc1.bias torch.Size([2]) True
Total params num: 838920
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123116475666372054013/run.log
2022-12-31 16:48: Train Epoch 1: 3/634 Loss: 0.530994
2022-12-31 16:48: Train Epoch 1: 7/634 Loss: 0.824885
2022-12-31 16:48: Train Epoch 1: 11/634 Loss: 0.562329
2022-12-31 16:49: Train Epoch 1: 15/634 Loss: 0.612547
2022-12-31 16:49: Train Epoch 1: 19/634 Loss: 0.419495
2022-12-31 16:49: Train Epoch 1: 23/634 Loss: 0.275884
2022-12-31 16:49: Train Epoch 1: 27/634 Loss: 0.291413
2022-12-31 16:50: Train Epoch 1: 31/634 Loss: 0.384949
2022-12-31 16:50: Train Epoch 1: 35/634 Loss: 0.378122
2022-12-31 16:50: Train Epoch 1: 39/634 Loss: 0.394988
2022-12-31 16:51: Train Epoch 1: 43/634 Loss: 0.288581
2022-12-31 16:51: Train Epoch 1: 47/634 Loss: 0.266335
2022-12-31 16:51: Train Epoch 1: 51/634 Loss: 0.275725
2022-12-31 16:51: Train Epoch 1: 55/634 Loss: 0.241929
2022-12-31 16:52: Train Epoch 1: 59/634 Loss: 0.271477
2022-12-31 16:52: Train Epoch 1: 63/634 Loss: 0.349029
2022-12-31 16:52: Train Epoch 1: 67/634 Loss: 0.281434
2022-12-31 16:52: Train Epoch 1: 71/634 Loss: 0.267481
2022-12-31 16:53: Train Epoch 1: 75/634 Loss: 0.250486
2022-12-31 16:53: Train Epoch 1: 79/634 Loss: 0.230668
2022-12-31 16:53: Train Epoch 1: 83/634 Loss: 0.247030
2022-12-31 16:54: Train Epoch 1: 87/634 Loss: 0.268270
2022-12-31 16:54: Train Epoch 1: 91/634 Loss: 0.266600
2022-12-31 16:54: Train Epoch 1: 95/634 Loss: 0.286725
2022-12-31 16:54: Train Epoch 1: 99/634 Loss: 0.227674
2022-12-31 16:55: Train Epoch 1: 103/634 Loss: 0.259565
2022-12-31 16:55: Train Epoch 1: 107/634 Loss: 0.219937
2022-12-31 16:55: Train Epoch 1: 111/634 Loss: 0.234346
2022-12-31 16:55: Train Epoch 1: 115/634 Loss: 0.192062
2022-12-31 16:56: Train Epoch 1: 119/634 Loss: 0.230404
2022-12-31 16:56: Train Epoch 1: 123/634 Loss: 0.254487
2022-12-31 16:56: Train Epoch 1: 127/634 Loss: 0.213532
2022-12-31 16:57: Train Epoch 1: 131/634 Loss: 0.225646
2022-12-31 16:57: Train Epoch 1: 135/634 Loss: 0.210722
2022-12-31 16:57: Train Epoch 1: 139/634 Loss: 0.220480
2022-12-31 16:57: Train Epoch 1: 143/634 Loss: 0.207955
2022-12-31 16:58: Train Epoch 1: 147/634 Loss: 0.229355
2022-12-31 16:58: Train Epoch 1: 151/634 Loss: 0.213936
2022-12-31 16:58: Train Epoch 1: 155/634 Loss: 0.210451
2022-12-31 16:58: Train Epoch 1: 159/634 Loss: 0.228663
2022-12-31 16:59: Train Epoch 1: 163/634 Loss: 0.264788
2022-12-31 16:59: Train Epoch 1: 167/634 Loss: 0.230798
2022-12-31 16:59: Train Epoch 1: 171/634 Loss: 0.209955
2022-12-31 17:00: Train Epoch 1: 175/634 Loss: 0.235144
2022-12-31 17:00: Train Epoch 1: 179/634 Loss: 0.218491
2022-12-31 17:00: Train Epoch 1: 183/634 Loss: 0.206996
2022-12-31 17:00: Train Epoch 1: 187/634 Loss: 0.248737
2022-12-31 17:01: Train Epoch 1: 191/634 Loss: 0.216119
2022-12-31 17:01: Train Epoch 1: 195/634 Loss: 0.237329
2022-12-31 17:01: Train Epoch 1: 199/634 Loss: 0.176617
2022-12-31 17:01: Train Epoch 1: 203/634 Loss: 0.200360
2022-12-31 17:02: Train Epoch 1: 207/634 Loss: 0.204066
2022-12-31 17:02: Train Epoch 1: 211/634 Loss: 0.209639
2022-12-31 17:02: Train Epoch 1: 215/634 Loss: 0.226614
2022-12-31 17:02: Train Epoch 1: 219/634 Loss: 0.200569
2022-12-31 17:03: Train Epoch 1: 223/634 Loss: 0.207463
2022-12-31 17:03: Train Epoch 1: 227/634 Loss: 0.218025
2022-12-31 17:03: Train Epoch 1: 231/634 Loss: 0.249008
2022-12-31 17:03: Train Epoch 1: 235/634 Loss: 0.193255
2022-12-31 17:04: Train Epoch 1: 239/634 Loss: 0.212083
2022-12-31 17:04: Train Epoch 1: 243/634 Loss: 0.195507
2022-12-31 17:04: Train Epoch 1: 247/634 Loss: 0.186806
2022-12-31 17:04: Train Epoch 1: 251/634 Loss: 0.203659
2022-12-31 17:05: Train Epoch 1: 255/634 Loss: 0.204542
2022-12-31 17:05: Train Epoch 1: 259/634 Loss: 0.221358
2022-12-31 17:05: Train Epoch 1: 263/634 Loss: 0.215053
2022-12-31 17:06: Train Epoch 1: 267/634 Loss: 0.217843
2022-12-31 17:06: Train Epoch 1: 271/634 Loss: 0.216269
2022-12-31 17:06: Train Epoch 1: 275/634 Loss: 0.198729
2022-12-31 17:06: Train Epoch 1: 279/634 Loss: 0.186128
2022-12-31 17:07: Train Epoch 1: 283/634 Loss: 0.199747
2022-12-31 17:07: Train Epoch 1: 287/634 Loss: 0.228357
2022-12-31 17:07: Train Epoch 1: 291/634 Loss: 0.189241
2022-12-31 17:07: Train Epoch 1: 295/634 Loss: 0.207428
2022-12-31 17:08: Train Epoch 1: 299/634 Loss: 0.205823
2022-12-31 17:08: Train Epoch 1: 303/634 Loss: 0.219987
2022-12-31 17:08: Train Epoch 1: 307/634 Loss: 0.199621
2022-12-31 17:09: Train Epoch 1: 311/634 Loss: 0.195676
2022-12-31 17:09: Train Epoch 1: 315/634 Loss: 0.205263
2022-12-31 17:09: Train Epoch 1: 319/634 Loss: 0.189870
2022-12-31 17:09: Train Epoch 1: 323/634 Loss: 0.218230
2022-12-31 17:10: Train Epoch 1: 327/634 Loss: 0.210600
2022-12-31 17:10: Train Epoch 1: 331/634 Loss: 0.222973
2022-12-31 17:10: Train Epoch 1: 335/634 Loss: 0.186065
2022-12-31 17:10: Train Epoch 1: 339/634 Loss: 0.179502
2022-12-31 17:11: Train Epoch 1: 343/634 Loss: 0.202835
2022-12-31 17:11: Train Epoch 1: 347/634 Loss: 0.204374
2022-12-31 17:11: Train Epoch 1: 351/634 Loss: 0.226312
2022-12-31 17:11: Train Epoch 1: 355/634 Loss: 0.192416
2022-12-31 17:12: Train Epoch 1: 359/634 Loss: 0.186835
2022-12-31 17:12: Train Epoch 1: 363/634 Loss: 0.206518
2022-12-31 17:12: Train Epoch 1: 367/634 Loss: 0.224226
2022-12-31 17:12: Train Epoch 1: 371/634 Loss: 0.230767
2022-12-31 17:13: Train Epoch 1: 375/634 Loss: 0.209026
2022-12-31 17:13: Train Epoch 1: 379/634 Loss: 0.179244
2022-12-31 17:13: Train Epoch 1: 383/634 Loss: 0.192734
2022-12-31 17:14: Train Epoch 1: 387/634 Loss: 0.184795
2022-12-31 17:14: Train Epoch 1: 391/634 Loss: 0.207877
2022-12-31 17:14: Train Epoch 1: 395/634 Loss: 0.193985
2022-12-31 17:14: Train Epoch 1: 399/634 Loss: 0.192754
2022-12-31 17:15: Train Epoch 1: 403/634 Loss: 0.200528
2022-12-31 17:15: Train Epoch 1: 407/634 Loss: 0.193597
2022-12-31 17:15: Train Epoch 1: 411/634 Loss: 0.181140
2022-12-31 17:15: Train Epoch 1: 415/634 Loss: 0.216480
2022-12-31 17:16: Train Epoch 1: 419/634 Loss: 0.237735
2022-12-31 17:16: Train Epoch 1: 423/634 Loss: 0.166489
2022-12-31 17:16: Train Epoch 1: 427/634 Loss: 0.212014
2022-12-31 17:16: Train Epoch 1: 431/634 Loss: 0.210680
2022-12-31 17:17: Train Epoch 1: 435/634 Loss: 0.177543
2022-12-31 17:17: Train Epoch 1: 439/634 Loss: 0.178405
2022-12-31 17:17: Train Epoch 1: 443/634 Loss: 0.211957
2022-12-31 17:17: Train Epoch 1: 447/634 Loss: 0.184667
2022-12-31 17:18: Train Epoch 1: 451/634 Loss: 0.185688
2022-12-31 17:18: Train Epoch 1: 455/634 Loss: 0.185787
2022-12-31 17:18: Train Epoch 1: 459/634 Loss: 0.235439
2022-12-31 17:19: Train Epoch 1: 463/634 Loss: 0.209233
2022-12-31 17:19: Train Epoch 1: 467/634 Loss: 0.188205
2022-12-31 17:19: Train Epoch 1: 471/634 Loss: 0.197706
2022-12-31 17:19: Train Epoch 1: 475/634 Loss: 0.219800
2022-12-31 17:20: Train Epoch 1: 479/634 Loss: 0.243357
2022-12-31 17:20: Train Epoch 1: 483/634 Loss: 0.175938
2022-12-31 17:20: Train Epoch 1: 487/634 Loss: 0.207785
2022-12-31 17:20: Train Epoch 1: 491/634 Loss: 0.230191
2022-12-31 17:21: Train Epoch 1: 495/634 Loss: 0.211432
2022-12-31 17:21: Train Epoch 1: 499/634 Loss: 0.225327
2022-12-31 17:21: Train Epoch 1: 503/634 Loss: 0.195367
2022-12-31 17:22: Train Epoch 1: 507/634 Loss: 0.206506
2022-12-31 17:22: Train Epoch 1: 511/634 Loss: 0.238561
2022-12-31 17:22: Train Epoch 1: 515/634 Loss: 0.212199
2022-12-31 17:22: Train Epoch 1: 519/634 Loss: 0.201022
2022-12-31 17:23: Train Epoch 1: 523/634 Loss: 0.187974
2022-12-31 17:23: Train Epoch 1: 527/634 Loss: 0.205575
2022-12-31 17:23: Train Epoch 1: 531/634 Loss: 0.178172
2022-12-31 17:23: Train Epoch 1: 535/634 Loss: 0.224001
2022-12-31 17:24: Train Epoch 1: 539/634 Loss: 0.199914
2022-12-31 17:24: Train Epoch 1: 543/634 Loss: 0.184522
2022-12-31 17:24: Train Epoch 1: 547/634 Loss: 0.187841
2022-12-31 17:24: Train Epoch 1: 551/634 Loss: 0.220568
2022-12-31 17:25: Train Epoch 1: 555/634 Loss: 0.203118
2022-12-31 17:25: Train Epoch 1: 559/634 Loss: 0.198675
2022-12-31 17:25: Train Epoch 1: 563/634 Loss: 0.234395
2022-12-31 17:26: Train Epoch 1: 567/634 Loss: 0.237302
2022-12-31 17:26: Train Epoch 1: 571/634 Loss: 0.198618
2022-12-31 17:26: Train Epoch 1: 575/634 Loss: 0.228986
2022-12-31 17:26: Train Epoch 1: 579/634 Loss: 0.194688
2022-12-31 17:27: Train Epoch 1: 583/634 Loss: 0.222340
2022-12-31 17:27: Train Epoch 1: 587/634 Loss: 0.197419
2022-12-31 17:27: Train Epoch 1: 591/634 Loss: 0.192200
2022-12-31 17:27: Train Epoch 1: 595/634 Loss: 0.212177
2022-12-31 17:28: Train Epoch 1: 599/634 Loss: 0.222502
2022-12-31 17:28: Train Epoch 1: 603/634 Loss: 0.197519
2022-12-31 17:28: Train Epoch 1: 607/634 Loss: 0.183677
2022-12-31 17:28: Train Epoch 1: 611/634 Loss: 0.193468
2022-12-31 17:29: Train Epoch 1: 615/634 Loss: 0.211978
2022-12-31 17:29: Train Epoch 1: 619/634 Loss: 0.190088
2022-12-31 17:29: Train Epoch 1: 623/634 Loss: 0.169382
2022-12-31 17:30: Train Epoch 1: 627/634 Loss: 0.191878
2022-12-31 17:30: Train Epoch 1: 631/634 Loss: 0.204482
2022-12-31 17:30: Train Epoch 1: 633/634 Loss: 0.069792
2022-12-31 17:30: **********Train Epoch 1: averaged Loss: 0.229155 
2022-12-31 17:30: 
Epoch time elapsed: 2545.7128393650055

2022-12-31 17:31: 
 metrics validation: {'precision': 0.7792329279700655, 'recall': 0.6407692307692308, 'f1-score': 0.7032503165892782, 'support': 1300, 'AUC': 0.8502440828402368, 'AUCPR': 0.7550791809699919, 'TP': 833, 'FP': 236, 'TN': 2364, 'FN': 467} 

2022-12-31 17:31: **********Val Epoch 1: average Loss: 0.222118
2022-12-31 17:31: *********************************Current best model saved!
2022-12-31 17:32: 
 Testing metrics {'precision': 0.8265412748171369, 'recall': 0.6441368078175895, 'f1-score': 0.7240274599542333, 'support': 1228, 'AUC': 0.8798677572175831, 'AUCPR': 0.8190270706616953, 'TP': 791, 'FP': 166, 'TN': 2290, 'FN': 437} 

2022-12-31 17:37: 
 Testing metrics {'precision': 0.8882086167800454, 'recall': 0.88881325164511, 'f1-score': 0.8885108313485313, 'support': 4407, 'AUC': 0.9700049928819126, 'AUCPR': 0.9462872486047246, 'TP': 3917, 'FP': 493, 'TN': 8321, 'FN': 490} 

2022-12-31 17:37: Train Epoch 2: 3/634 Loss: 0.183815
2022-12-31 17:37: Train Epoch 2: 7/634 Loss: 0.193345
2022-12-31 17:38: Train Epoch 2: 11/634 Loss: 0.188889
2022-12-31 17:38: Train Epoch 2: 15/634 Loss: 0.200181
2022-12-31 17:38: Train Epoch 2: 19/634 Loss: 0.183325
2022-12-31 17:39: Train Epoch 2: 23/634 Loss: 0.194015
2022-12-31 17:39: Train Epoch 2: 27/634 Loss: 0.186432
2022-12-31 17:39: Train Epoch 2: 31/634 Loss: 0.203850
2022-12-31 17:39: Train Epoch 2: 35/634 Loss: 0.189928
2022-12-31 17:40: Train Epoch 2: 39/634 Loss: 0.184738
2022-12-31 17:40: Train Epoch 2: 43/634 Loss: 0.182082
2022-12-31 17:40: Train Epoch 2: 47/634 Loss: 0.189715
2022-12-31 17:41: Train Epoch 2: 51/634 Loss: 0.193027
2022-12-31 17:41: Train Epoch 2: 55/634 Loss: 0.164656
2022-12-31 17:41: Train Epoch 2: 59/634 Loss: 0.190339
2022-12-31 17:41: Train Epoch 2: 63/634 Loss: 0.239765
2022-12-31 17:42: Train Epoch 2: 67/634 Loss: 0.193705
2022-12-31 17:42: Train Epoch 2: 71/634 Loss: 0.198678
2022-12-31 17:42: Train Epoch 2: 75/634 Loss: 0.186296
2022-12-31 17:42: Train Epoch 2: 79/634 Loss: 0.176580
2022-12-31 17:43: Train Epoch 2: 83/634 Loss: 0.202722
2022-12-31 17:43: Train Epoch 2: 87/634 Loss: 0.179991
2022-12-31 17:43: Train Epoch 2: 91/634 Loss: 0.185090
2022-12-31 17:44: Train Epoch 2: 95/634 Loss: 0.196044
2022-12-31 17:44: Train Epoch 2: 99/634 Loss: 0.171033
2022-12-31 17:44: Train Epoch 2: 103/634 Loss: 0.212810
2022-12-31 17:44: Train Epoch 2: 107/634 Loss: 0.174549
2022-12-31 17:45: Train Epoch 2: 111/634 Loss: 0.198908
2022-12-31 17:45: Train Epoch 2: 115/634 Loss: 0.212621
2022-12-31 17:45: Train Epoch 2: 119/634 Loss: 0.191440
2022-12-31 17:46: Train Epoch 2: 123/634 Loss: 0.189234
2022-12-31 17:46: Train Epoch 2: 127/634 Loss: 0.240367
2022-12-31 17:46: Train Epoch 2: 131/634 Loss: 0.193826
2022-12-31 17:46: Train Epoch 2: 135/634 Loss: 0.202621
2022-12-31 17:47: Train Epoch 2: 139/634 Loss: 0.206024
2022-12-31 17:47: Train Epoch 2: 143/634 Loss: 0.179322
2022-12-31 17:47: Train Epoch 2: 147/634 Loss: 0.194618
2022-12-31 17:48: Train Epoch 2: 151/634 Loss: 0.220891
2022-12-31 17:48: Train Epoch 2: 155/634 Loss: 0.196333
2022-12-31 17:48: Train Epoch 2: 159/634 Loss: 0.227590
2022-12-31 17:48: Train Epoch 2: 163/634 Loss: 0.202638
2022-12-31 17:49: Train Epoch 2: 167/634 Loss: 0.197640
2022-12-31 17:49: Train Epoch 2: 171/634 Loss: 0.225272
2022-12-31 17:49: Train Epoch 2: 175/634 Loss: 0.175026
2022-12-31 17:50: Train Epoch 2: 179/634 Loss: 0.212087
2022-12-31 17:50: Train Epoch 2: 183/634 Loss: 0.239697
2022-12-31 17:50: Train Epoch 2: 187/634 Loss: 0.209903
2022-12-31 17:50: Train Epoch 2: 191/634 Loss: 0.199647
2022-12-31 17:51: Train Epoch 2: 195/634 Loss: 0.206548
2022-12-31 17:51: Train Epoch 2: 199/634 Loss: 0.204673
2022-12-31 17:51: Train Epoch 2: 203/634 Loss: 0.204880
2022-12-31 17:52: Train Epoch 2: 207/634 Loss: 0.192185
2022-12-31 17:52: Train Epoch 2: 211/634 Loss: 0.195342
2022-12-31 17:52: Train Epoch 2: 215/634 Loss: 0.248088
2022-12-31 17:52: Train Epoch 2: 219/634 Loss: 0.166742
2022-12-31 17:53: Train Epoch 2: 223/634 Loss: 0.190342
2022-12-31 17:53: Train Epoch 2: 227/634 Loss: 0.210577
2022-12-31 17:53: Train Epoch 2: 231/634 Loss: 0.187369
2022-12-31 17:54: Train Epoch 2: 235/634 Loss: 0.208365
2022-12-31 17:54: Train Epoch 2: 239/634 Loss: 0.199906
2022-12-31 17:54: Train Epoch 2: 243/634 Loss: 0.210169
2022-12-31 17:54: Train Epoch 2: 247/634 Loss: 0.196314
2022-12-31 17:55: Train Epoch 2: 251/634 Loss: 0.185867
2022-12-31 17:55: Train Epoch 2: 255/634 Loss: 0.175130
2022-12-31 17:55: Train Epoch 2: 259/634 Loss: 0.157633
2022-12-31 17:56: Train Epoch 2: 263/634 Loss: 0.178910
2022-12-31 17:56: Train Epoch 2: 267/634 Loss: 0.182855
2022-12-31 17:56: Train Epoch 2: 271/634 Loss: 0.195185
2022-12-31 17:56: Train Epoch 2: 275/634 Loss: 0.171296
2022-12-31 17:57: Train Epoch 2: 279/634 Loss: 0.182601
2022-12-31 17:57: Train Epoch 2: 283/634 Loss: 0.203753
2022-12-31 17:57: Train Epoch 2: 287/634 Loss: 0.173568
2022-12-31 17:57: Train Epoch 2: 291/634 Loss: 0.177363
2022-12-31 17:58: Train Epoch 2: 295/634 Loss: 0.184636
2022-12-31 17:58: Train Epoch 2: 299/634 Loss: 0.178887
2022-12-31 17:58: Train Epoch 2: 303/634 Loss: 0.195975
2022-12-31 17:59: Train Epoch 2: 307/634 Loss: 0.203882
2022-12-31 17:59: Train Epoch 2: 311/634 Loss: 0.203069
2022-12-31 17:59: Train Epoch 2: 315/634 Loss: 0.188238
2022-12-31 17:59: Train Epoch 2: 319/634 Loss: 0.201800
2022-12-31 18:00: Train Epoch 2: 323/634 Loss: 0.216842
2022-12-31 18:00: Train Epoch 2: 327/634 Loss: 0.188758
2022-12-31 18:00: Train Epoch 2: 331/634 Loss: 0.180504
2022-12-31 18:00: Train Epoch 2: 335/634 Loss: 0.180401
2022-12-31 18:01: Train Epoch 2: 339/634 Loss: 0.189542
2022-12-31 18:01: Train Epoch 2: 343/634 Loss: 0.166089
2022-12-31 18:01: Train Epoch 2: 347/634 Loss: 0.169182
2022-12-31 18:02: Train Epoch 2: 351/634 Loss: 0.208876
2022-12-31 18:02: Train Epoch 2: 355/634 Loss: 0.169263
2022-12-31 18:02: Train Epoch 2: 359/634 Loss: 0.197401
2022-12-31 18:02: Train Epoch 2: 363/634 Loss: 0.238711
2022-12-31 18:03: Train Epoch 2: 367/634 Loss: 0.184457
2022-12-31 18:03: Train Epoch 2: 371/634 Loss: 0.196826
2022-12-31 18:03: Train Epoch 2: 375/634 Loss: 0.176582
2022-12-31 18:03: Train Epoch 2: 379/634 Loss: 0.176370
2022-12-31 18:04: Train Epoch 2: 383/634 Loss: 0.174303
2022-12-31 18:04: Train Epoch 2: 387/634 Loss: 0.175958
2022-12-31 18:04: Train Epoch 2: 391/634 Loss: 0.164342
2022-12-31 18:04: Train Epoch 2: 395/634 Loss: 0.190793
2022-12-31 18:05: Train Epoch 2: 399/634 Loss: 0.180270
2022-12-31 18:05: Train Epoch 2: 403/634 Loss: 0.190329
2022-12-31 18:05: Train Epoch 2: 407/634 Loss: 0.206547
2022-12-31 18:05: Train Epoch 2: 411/634 Loss: 0.202304
2022-12-31 18:06: Train Epoch 2: 415/634 Loss: 0.166010
2022-12-31 18:06: Train Epoch 2: 419/634 Loss: 0.195205
2022-12-31 18:06: Train Epoch 2: 423/634 Loss: 0.168113
2022-12-31 18:06: Train Epoch 2: 427/634 Loss: 0.180844
2022-12-31 18:07: Train Epoch 2: 431/634 Loss: 0.195064
2022-12-31 18:07: Train Epoch 2: 435/634 Loss: 0.175620
2022-12-31 18:07: Train Epoch 2: 439/634 Loss: 0.178387
2022-12-31 18:08: Train Epoch 2: 443/634 Loss: 0.160870
2022-12-31 18:08: Train Epoch 2: 447/634 Loss: 0.211822
2022-12-31 18:08: Train Epoch 2: 451/634 Loss: 0.207478
2022-12-31 18:08: Train Epoch 2: 455/634 Loss: 0.197130
2022-12-31 18:09: Train Epoch 2: 459/634 Loss: 0.187880
2022-12-31 18:09: Train Epoch 2: 463/634 Loss: 0.173106
2022-12-31 18:09: Train Epoch 2: 467/634 Loss: 0.196632
2022-12-31 18:09: Train Epoch 2: 471/634 Loss: 0.182162
2022-12-31 18:10: Train Epoch 2: 475/634 Loss: 0.221585
2022-12-31 18:10: Train Epoch 2: 479/634 Loss: 0.182259
2022-12-31 18:10: Train Epoch 2: 483/634 Loss: 0.194813
2022-12-31 18:10: Train Epoch 2: 487/634 Loss: 0.186411
2022-12-31 18:11: Train Epoch 2: 491/634 Loss: 0.176398
2022-12-31 18:11: Train Epoch 2: 495/634 Loss: 0.199550
2022-12-31 18:11: Train Epoch 2: 499/634 Loss: 0.199782
2022-12-31 18:11: Train Epoch 2: 503/634 Loss: 0.190920
2022-12-31 18:12: Train Epoch 2: 507/634 Loss: 0.156605
2022-12-31 18:12: Train Epoch 2: 511/634 Loss: 0.166900
2022-12-31 18:12: Train Epoch 2: 515/634 Loss: 0.204059
2022-12-31 18:12: Train Epoch 2: 519/634 Loss: 0.174076
2022-12-31 18:13: Train Epoch 2: 523/634 Loss: 0.219191
2022-12-31 18:13: Train Epoch 2: 527/634 Loss: 0.178564
2022-12-31 18:13: Train Epoch 2: 531/634 Loss: 0.178218
2022-12-31 18:13: Train Epoch 2: 535/634 Loss: 0.186314
2022-12-31 18:14: Train Epoch 2: 539/634 Loss: 0.181880
2022-12-31 18:14: Train Epoch 2: 543/634 Loss: 0.173438
2022-12-31 18:14: Train Epoch 2: 547/634 Loss: 0.203617
2022-12-31 18:15: Train Epoch 2: 551/634 Loss: 0.198182
2022-12-31 18:15: Train Epoch 2: 555/634 Loss: 0.194285
2022-12-31 18:15: Train Epoch 2: 559/634 Loss: 0.189177
2022-12-31 18:15: Train Epoch 2: 563/634 Loss: 0.194481
2022-12-31 18:16: Train Epoch 2: 567/634 Loss: 0.182465
2022-12-31 18:16: Train Epoch 2: 571/634 Loss: 0.184736
2022-12-31 18:16: Train Epoch 2: 575/634 Loss: 0.173213
2022-12-31 18:17: Train Epoch 2: 579/634 Loss: 0.197415
2022-12-31 18:17: Train Epoch 2: 583/634 Loss: 0.178292
2022-12-31 18:17: Train Epoch 2: 587/634 Loss: 0.173618
2022-12-31 18:17: Train Epoch 2: 591/634 Loss: 0.150515
2022-12-31 18:18: Train Epoch 2: 595/634 Loss: 0.169542
2022-12-31 18:18: Train Epoch 2: 599/634 Loss: 0.177446
2022-12-31 18:18: Train Epoch 2: 603/634 Loss: 0.205204
2022-12-31 18:19: Train Epoch 2: 607/634 Loss: 0.212059
2022-12-31 18:19: Train Epoch 2: 611/634 Loss: 0.170525
2022-12-31 18:19: Train Epoch 2: 615/634 Loss: 0.208851
2022-12-31 18:19: Train Epoch 2: 619/634 Loss: 0.188540
2022-12-31 18:20: Train Epoch 2: 623/634 Loss: 0.217850
2022-12-31 18:20: Train Epoch 2: 627/634 Loss: 0.220656
2022-12-31 18:20: Train Epoch 2: 631/634 Loss: 0.181249
2022-12-31 18:20: Train Epoch 2: 633/634 Loss: 0.097986
2022-12-31 18:20: **********Train Epoch 2: averaged Loss: 0.190977 
2022-12-31 18:20: 
Epoch time elapsed: 2615.7611181735992

2022-12-31 18:22: 
 metrics validation: {'precision': 0.9053627760252366, 'recall': 0.22076923076923077, 'f1-score': 0.354978354978355, 'support': 1300, 'AUC': 0.8964461538461538, 'AUCPR': 0.8138525568459535, 'TP': 287, 'FP': 30, 'TN': 2570, 'FN': 1013} 

2022-12-31 18:22: **********Val Epoch 2: average Loss: 0.259076
2022-12-31 18:23: 
 Testing metrics {'precision': 0.8265412748171369, 'recall': 0.6441368078175895, 'f1-score': 0.7240274599542333, 'support': 1228, 'AUC': 0.8798677572175831, 'AUCPR': 0.8190270706616953, 'TP': 791, 'FP': 166, 'TN': 2290, 'FN': 437} 

2022-12-31 18:27: 
 Testing metrics {'precision': 0.8882086167800454, 'recall': 0.88881325164511, 'f1-score': 0.8885108313485313, 'support': 4407, 'AUC': 0.9700049928819126, 'AUCPR': 0.9462872486047246, 'TP': 3917, 'FP': 493, 'TN': 8321, 'FN': 490} 

2022-12-31 18:28: Train Epoch 3: 3/634 Loss: 0.197566
2022-12-31 18:28: Train Epoch 3: 7/634 Loss: 0.202971
2022-12-31 18:28: Train Epoch 3: 11/634 Loss: 0.209115
2022-12-31 18:28: Train Epoch 3: 15/634 Loss: 0.212456
2022-12-31 18:29: Train Epoch 3: 19/634 Loss: 0.162274
2022-12-31 18:29: Train Epoch 3: 23/634 Loss: 0.195277
2022-12-31 18:29: Train Epoch 3: 27/634 Loss: 0.213673
2022-12-31 18:29: Train Epoch 3: 31/634 Loss: 0.193279
2022-12-31 18:30: Train Epoch 3: 35/634 Loss: 0.218890
2022-12-31 18:30: Train Epoch 3: 39/634 Loss: 0.184126
2022-12-31 18:30: Train Epoch 3: 43/634 Loss: 0.188419
2022-12-31 18:31: Train Epoch 3: 47/634 Loss: 0.221966
2022-12-31 18:31: Train Epoch 3: 51/634 Loss: 0.162893
2022-12-31 18:31: Train Epoch 3: 55/634 Loss: 0.197703
2022-12-31 18:31: Train Epoch 3: 59/634 Loss: 0.214122
2022-12-31 18:32: Train Epoch 3: 63/634 Loss: 0.193212
2022-12-31 18:32: Train Epoch 3: 67/634 Loss: 0.183315
2022-12-31 18:32: Train Epoch 3: 71/634 Loss: 0.165715
2022-12-31 18:32: Train Epoch 3: 75/634 Loss: 0.207213
2022-12-31 18:33: Train Epoch 3: 79/634 Loss: 0.196581
2022-12-31 18:33: Train Epoch 3: 83/634 Loss: 0.213962
2022-12-31 18:33: Train Epoch 3: 87/634 Loss: 0.188035
2022-12-31 18:33: Train Epoch 3: 91/634 Loss: 0.179548
2022-12-31 18:34: Train Epoch 3: 95/634 Loss: 0.169062
2022-12-31 18:34: Train Epoch 3: 99/634 Loss: 0.202253
2022-12-31 18:34: Train Epoch 3: 103/634 Loss: 0.234783
2022-12-31 18:34: Train Epoch 3: 107/634 Loss: 0.200042
2022-12-31 18:35: Train Epoch 3: 111/634 Loss: 0.188865
2022-12-31 18:35: Train Epoch 3: 115/634 Loss: 0.203577
2022-12-31 18:35: Train Epoch 3: 119/634 Loss: 0.206168
2022-12-31 18:35: Train Epoch 3: 123/634 Loss: 0.191599
2022-12-31 18:36: Train Epoch 3: 127/634 Loss: 0.193530
2022-12-31 18:36: Train Epoch 3: 131/634 Loss: 0.196735
2022-12-31 18:36: Train Epoch 3: 135/634 Loss: 0.171315
2022-12-31 18:36: Train Epoch 3: 139/634 Loss: 0.205157
2022-12-31 18:37: Train Epoch 3: 143/634 Loss: 0.200117
2022-12-31 18:37: Train Epoch 3: 147/634 Loss: 0.170532
2022-12-31 18:37: Train Epoch 3: 151/634 Loss: 0.164207
2022-12-31 18:38: Train Epoch 3: 155/634 Loss: 0.183279
2022-12-31 18:38: Train Epoch 3: 159/634 Loss: 0.190666
2022-12-31 18:38: Train Epoch 3: 163/634 Loss: 0.178857
2022-12-31 18:38: Train Epoch 3: 167/634 Loss: 0.162247
2022-12-31 18:39: Train Epoch 3: 171/634 Loss: 0.186754
2022-12-31 18:39: Train Epoch 3: 175/634 Loss: 0.226217
2022-12-31 18:39: Train Epoch 3: 179/634 Loss: 0.204904
2022-12-31 18:39: Train Epoch 3: 183/634 Loss: 0.213808
2022-12-31 18:40: Train Epoch 3: 187/634 Loss: 0.241528
2022-12-31 18:40: Train Epoch 3: 191/634 Loss: 0.210927
2022-12-31 18:40: Train Epoch 3: 195/634 Loss: 0.191683
2022-12-31 18:40: Train Epoch 3: 199/634 Loss: 0.162632
2022-12-31 18:41: Train Epoch 3: 203/634 Loss: 0.186069
2022-12-31 18:41: Train Epoch 3: 207/634 Loss: 0.194647
2022-12-31 18:41: Train Epoch 3: 211/634 Loss: 0.195017
2022-12-31 18:41: Train Epoch 3: 215/634 Loss: 0.154185
2022-12-31 18:42: Train Epoch 3: 219/634 Loss: 0.187729
2022-12-31 18:42: Train Epoch 3: 223/634 Loss: 0.183105
2022-12-31 18:42: Train Epoch 3: 227/634 Loss: 0.187515
2022-12-31 18:42: Train Epoch 3: 231/634 Loss: 0.220436
2022-12-31 18:43: Train Epoch 3: 235/634 Loss: 0.199206
2022-12-31 18:43: Train Epoch 3: 239/634 Loss: 0.158523
2022-12-31 18:43: Train Epoch 3: 243/634 Loss: 0.182798
2022-12-31 18:43: Train Epoch 3: 247/634 Loss: 0.214435
2022-12-31 18:44: Train Epoch 3: 251/634 Loss: 0.180158
2022-12-31 18:44: Train Epoch 3: 255/634 Loss: 0.193711
2022-12-31 18:44: Train Epoch 3: 259/634 Loss: 0.180113
2022-12-31 18:44: Train Epoch 3: 263/634 Loss: 0.196639
2022-12-31 18:45: Train Epoch 3: 267/634 Loss: 0.183253
2022-12-31 18:45: Train Epoch 3: 271/634 Loss: 0.238018
2022-12-31 18:45: Train Epoch 3: 275/634 Loss: 0.200307
2022-12-31 18:46: Train Epoch 3: 279/634 Loss: 0.202664
2022-12-31 18:46: Train Epoch 3: 283/634 Loss: 0.190687
2022-12-31 18:46: Train Epoch 3: 287/634 Loss: 0.184856
2022-12-31 18:46: Train Epoch 3: 291/634 Loss: 0.221475
2022-12-31 18:47: Train Epoch 3: 295/634 Loss: 0.202028
2022-12-31 18:47: Train Epoch 3: 299/634 Loss: 0.192373
2022-12-31 18:47: Train Epoch 3: 303/634 Loss: 0.185474
2022-12-31 18:47: Train Epoch 3: 307/634 Loss: 0.188340
2022-12-31 18:48: Train Epoch 3: 311/634 Loss: 0.208372
2022-12-31 18:48: Train Epoch 3: 315/634 Loss: 0.228741
2022-12-31 18:48: Train Epoch 3: 319/634 Loss: 0.166219
2022-12-31 18:48: Train Epoch 3: 323/634 Loss: 0.198110
2022-12-31 18:49: Train Epoch 3: 327/634 Loss: 0.209738
2022-12-31 18:49: Train Epoch 3: 331/634 Loss: 0.179168
2022-12-31 18:49: Train Epoch 3: 335/634 Loss: 0.175284
2022-12-31 18:49: Train Epoch 3: 339/634 Loss: 0.177194
2022-12-31 18:50: Train Epoch 3: 343/634 Loss: 0.182155
2022-12-31 18:50: Train Epoch 3: 347/634 Loss: 0.187377
2022-12-31 18:50: Train Epoch 3: 351/634 Loss: 0.195921
2022-12-31 18:50: Train Epoch 3: 355/634 Loss: 0.196211
2022-12-31 18:51: Train Epoch 3: 359/634 Loss: 0.196968
2022-12-31 18:51: Train Epoch 3: 363/634 Loss: 0.161024
2022-12-31 18:51: Train Epoch 3: 367/634 Loss: 0.206991
2022-12-31 18:51: Train Epoch 3: 371/634 Loss: 0.190771
2022-12-31 18:52: Train Epoch 3: 375/634 Loss: 0.178563
2022-12-31 18:52: Train Epoch 3: 379/634 Loss: 0.170759
2022-12-31 18:52: Train Epoch 3: 383/634 Loss: 0.181937
2022-12-31 18:52: Train Epoch 3: 387/634 Loss: 0.161585
2022-12-31 18:53: Train Epoch 3: 391/634 Loss: 0.175144
2022-12-31 18:53: Train Epoch 3: 395/634 Loss: 0.179323
2022-12-31 18:53: Train Epoch 3: 399/634 Loss: 0.166363
2022-12-31 18:53: Train Epoch 3: 403/634 Loss: 0.167469
2022-12-31 18:54: Train Epoch 3: 407/634 Loss: 0.195074
2022-12-31 18:54: Train Epoch 3: 411/634 Loss: 0.170430
2022-12-31 18:54: Train Epoch 3: 415/634 Loss: 0.194786
2022-12-31 18:54: Train Epoch 3: 419/634 Loss: 0.166228
2022-12-31 18:55: Train Epoch 3: 423/634 Loss: 0.185979
2022-12-31 18:55: Train Epoch 3: 427/634 Loss: 0.168056
2022-12-31 18:55: Train Epoch 3: 431/634 Loss: 0.168226
2022-12-31 18:56: Train Epoch 3: 435/634 Loss: 0.199833
2022-12-31 18:56: Train Epoch 3: 439/634 Loss: 0.199108
2022-12-31 18:56: Train Epoch 3: 443/634 Loss: 0.190826
2022-12-31 18:56: Train Epoch 3: 447/634 Loss: 0.198215
2022-12-31 18:57: Train Epoch 3: 451/634 Loss: 0.205417
2022-12-31 18:57: Train Epoch 3: 455/634 Loss: 0.168827
2022-12-31 18:57: Train Epoch 3: 459/634 Loss: 0.189026
2022-12-31 18:57: Train Epoch 3: 463/634 Loss: 0.160422
2022-12-31 18:58: Train Epoch 3: 467/634 Loss: 0.187644
2022-12-31 18:58: Train Epoch 3: 471/634 Loss: 0.182582
2022-12-31 18:58: Train Epoch 3: 475/634 Loss: 0.174273
2022-12-31 18:58: Train Epoch 3: 479/634 Loss: 0.213194
2022-12-31 18:59: Train Epoch 3: 483/634 Loss: 0.167714
2022-12-31 18:59: Train Epoch 3: 487/634 Loss: 0.167106
2022-12-31 18:59: Train Epoch 3: 491/634 Loss: 0.176831
2022-12-31 18:59: Train Epoch 3: 495/634 Loss: 0.151019
2022-12-31 19:00: Train Epoch 3: 499/634 Loss: 0.186411
2022-12-31 19:00: Train Epoch 3: 503/634 Loss: 0.203338
2022-12-31 19:00: Train Epoch 3: 507/634 Loss: 0.179606
2022-12-31 19:00: Train Epoch 3: 511/634 Loss: 0.191211
2022-12-31 19:01: Train Epoch 3: 515/634 Loss: 0.168479
2022-12-31 19:01: Train Epoch 3: 519/634 Loss: 0.180379
2022-12-31 19:01: Train Epoch 3: 523/634 Loss: 0.198184
2022-12-31 19:01: Train Epoch 3: 527/634 Loss: 0.193479
2022-12-31 19:02: Train Epoch 3: 531/634 Loss: 0.226576
2022-12-31 19:02: Train Epoch 3: 535/634 Loss: 0.151255
2022-12-31 19:02: Train Epoch 3: 539/634 Loss: 0.178418
2022-12-31 19:02: Train Epoch 3: 543/634 Loss: 0.182478
2022-12-31 19:03: Train Epoch 3: 547/634 Loss: 0.184280
2022-12-31 19:03: Train Epoch 3: 551/634 Loss: 0.188885
2022-12-31 19:03: Train Epoch 3: 555/634 Loss: 0.186845
2022-12-31 19:03: Train Epoch 3: 559/634 Loss: 0.180218
2022-12-31 19:04: Train Epoch 3: 563/634 Loss: 0.187485
2022-12-31 19:04: Train Epoch 3: 567/634 Loss: 0.201796
2022-12-31 19:04: Train Epoch 3: 571/634 Loss: 0.247116
2022-12-31 19:05: Train Epoch 3: 575/634 Loss: 0.167660
2022-12-31 19:05: Train Epoch 3: 579/634 Loss: 0.175421
2022-12-31 19:05: Train Epoch 3: 583/634 Loss: 0.156323
2022-12-31 19:05: Train Epoch 3: 587/634 Loss: 0.163501
2022-12-31 19:06: Train Epoch 3: 591/634 Loss: 0.174448
2022-12-31 19:06: Train Epoch 3: 595/634 Loss: 0.233536
2022-12-31 19:06: Train Epoch 3: 599/634 Loss: 0.151861
2022-12-31 19:06: Train Epoch 3: 603/634 Loss: 0.204459
2022-12-31 19:07: Train Epoch 3: 607/634 Loss: 0.231699
2022-12-31 19:07: Train Epoch 3: 611/634 Loss: 0.178923
2022-12-31 19:07: Train Epoch 3: 615/634 Loss: 0.196868
2022-12-31 19:07: Train Epoch 3: 619/634 Loss: 0.168955
2022-12-31 19:08: Train Epoch 3: 623/634 Loss: 0.207730
2022-12-31 19:08: Train Epoch 3: 627/634 Loss: 0.160806
2022-12-31 19:08: Train Epoch 3: 631/634 Loss: 0.203237
2022-12-31 19:08: Train Epoch 3: 633/634 Loss: 0.080914
2022-12-31 19:08: **********Train Epoch 3: averaged Loss: 0.189009 
2022-12-31 19:08: 
Epoch time elapsed: 2462.546258687973

2022-12-31 19:10: 
 metrics validation: {'precision': 0.8586171310629515, 'recall': 0.64, 'f1-score': 0.7333627148523579, 'support': 1300, 'AUC': 0.9061434911242604, 'AUCPR': 0.8365359006462871, 'TP': 832, 'FP': 137, 'TN': 2463, 'FN': 468} 

2022-12-31 19:10: **********Val Epoch 3: average Loss: 0.184834
2022-12-31 19:10: *********************************Current best model saved!
2022-12-31 19:11: 
 Testing metrics {'precision': 0.8789731051344744, 'recall': 0.5855048859934854, 'f1-score': 0.7028347996089932, 'support': 1228, 'AUC': 0.8977767668622479, 'AUCPR': 0.8423923139216242, 'TP': 719, 'FP': 99, 'TN': 2357, 'FN': 509} 

2022-12-31 19:15: 
 Testing metrics {'precision': 0.9201108870967742, 'recall': 0.8284547311095983, 'f1-score': 0.8718805970149254, 'support': 4407, 'AUC': 0.9731469763458294, 'AUCPR': 0.951499048654623, 'TP': 3651, 'FP': 317, 'TN': 8497, 'FN': 756} 

2022-12-31 19:15: Train Epoch 4: 3/634 Loss: 0.198155
2022-12-31 19:16: Train Epoch 4: 7/634 Loss: 0.157192
2022-12-31 19:16: Train Epoch 4: 11/634 Loss: 0.182811
2022-12-31 19:16: Train Epoch 4: 15/634 Loss: 0.188944
2022-12-31 19:16: Train Epoch 4: 19/634 Loss: 0.205409
2022-12-31 19:17: Train Epoch 4: 23/634 Loss: 0.204424
2022-12-31 19:17: Train Epoch 4: 27/634 Loss: 0.168868
2022-12-31 19:17: Train Epoch 4: 31/634 Loss: 0.187823
2022-12-31 19:17: Train Epoch 4: 35/634 Loss: 0.206066
2022-12-31 19:18: Train Epoch 4: 39/634 Loss: 0.182560
2022-12-31 19:18: Train Epoch 4: 43/634 Loss: 0.209196
2022-12-31 19:18: Train Epoch 4: 47/634 Loss: 0.195384
2022-12-31 19:19: Train Epoch 4: 51/634 Loss: 0.192071
2022-12-31 19:19: Train Epoch 4: 55/634 Loss: 0.219889
2022-12-31 19:19: Train Epoch 4: 59/634 Loss: 0.163496
2022-12-31 19:19: Train Epoch 4: 63/634 Loss: 0.193611
2022-12-31 19:20: Train Epoch 4: 67/634 Loss: 0.175960
2022-12-31 19:20: Train Epoch 4: 71/634 Loss: 0.177340
2022-12-31 19:20: Train Epoch 4: 75/634 Loss: 0.196205
2022-12-31 19:20: Train Epoch 4: 79/634 Loss: 0.195665
2022-12-31 19:21: Train Epoch 4: 83/634 Loss: 0.182038
2022-12-31 19:21: Train Epoch 4: 87/634 Loss: 0.164299
2022-12-31 19:21: Train Epoch 4: 91/634 Loss: 0.189889
2022-12-31 19:21: Train Epoch 4: 95/634 Loss: 0.183693
2022-12-31 19:22: Train Epoch 4: 99/634 Loss: 0.170791
2022-12-31 19:22: Train Epoch 4: 103/634 Loss: 0.179639
2022-12-31 19:22: Train Epoch 4: 107/634 Loss: 0.197001
2022-12-31 19:23: Train Epoch 4: 111/634 Loss: 0.159907
2022-12-31 19:23: Train Epoch 4: 115/634 Loss: 0.213284
2022-12-31 19:23: Train Epoch 4: 119/634 Loss: 0.162050
2022-12-31 19:23: Train Epoch 4: 123/634 Loss: 0.158114
2022-12-31 19:24: Train Epoch 4: 127/634 Loss: 0.200519
2022-12-31 19:24: Train Epoch 4: 131/634 Loss: 0.180785
2022-12-31 19:24: Train Epoch 4: 135/634 Loss: 0.167165
2022-12-31 19:24: Train Epoch 4: 139/634 Loss: 0.171332
2022-12-31 19:25: Train Epoch 4: 143/634 Loss: 0.165058
2022-12-31 19:25: Train Epoch 4: 147/634 Loss: 0.184348
2022-12-31 19:25: Train Epoch 4: 151/634 Loss: 0.215105
2022-12-31 19:25: Train Epoch 4: 155/634 Loss: 0.191324
2022-12-31 19:26: Train Epoch 4: 159/634 Loss: 0.177094
2022-12-31 19:26: Train Epoch 4: 163/634 Loss: 0.179897
2022-12-31 19:26: Train Epoch 4: 167/634 Loss: 0.192289
2022-12-31 19:26: Train Epoch 4: 171/634 Loss: 0.192778
2022-12-31 19:27: Train Epoch 4: 175/634 Loss: 0.158606
2022-12-31 19:27: Train Epoch 4: 179/634 Loss: 0.157824
2022-12-31 19:27: Train Epoch 4: 183/634 Loss: 0.170232
2022-12-31 19:27: Train Epoch 4: 187/634 Loss: 0.207848
2022-12-31 19:28: Train Epoch 4: 191/634 Loss: 0.186263
2022-12-31 19:28: Train Epoch 4: 195/634 Loss: 0.180896
2022-12-31 19:28: Train Epoch 4: 199/634 Loss: 0.202326
2022-12-31 19:28: Train Epoch 4: 203/634 Loss: 0.175260
2022-12-31 19:29: Train Epoch 4: 207/634 Loss: 0.202529
2022-12-31 19:29: Train Epoch 4: 211/634 Loss: 0.179316
2022-12-31 19:29: Train Epoch 4: 215/634 Loss: 0.175713
2022-12-31 19:29: Train Epoch 4: 219/634 Loss: 0.189895
2022-12-31 19:30: Train Epoch 4: 223/634 Loss: 0.160225
2022-12-31 19:30: Train Epoch 4: 227/634 Loss: 0.161211
2022-12-31 19:30: Train Epoch 4: 231/634 Loss: 0.198639
2022-12-31 19:30: Train Epoch 4: 235/634 Loss: 0.184801
2022-12-31 19:31: Train Epoch 4: 239/634 Loss: 0.199520
2022-12-31 19:31: Train Epoch 4: 243/634 Loss: 0.153850
2022-12-31 19:31: Train Epoch 4: 247/634 Loss: 0.160401
2022-12-31 19:31: Train Epoch 4: 251/634 Loss: 0.230379
2022-12-31 19:32: Train Epoch 4: 255/634 Loss: 0.160999
2022-12-31 19:32: Train Epoch 4: 259/634 Loss: 0.183928
2022-12-31 19:32: Train Epoch 4: 263/634 Loss: 0.173911
2022-12-31 19:33: Train Epoch 4: 267/634 Loss: 0.189503
2022-12-31 19:33: Train Epoch 4: 271/634 Loss: 0.176364
2022-12-31 19:33: Train Epoch 4: 275/634 Loss: 0.193779
2022-12-31 19:33: Train Epoch 4: 279/634 Loss: 0.172207
2022-12-31 19:34: Train Epoch 4: 283/634 Loss: 0.162021
2022-12-31 19:34: Train Epoch 4: 287/634 Loss: 0.169824
2022-12-31 19:34: Train Epoch 4: 291/634 Loss: 0.182985
2022-12-31 19:34: Train Epoch 4: 295/634 Loss: 0.165222
2022-12-31 19:35: Train Epoch 4: 299/634 Loss: 0.172624
2022-12-31 19:35: Train Epoch 4: 303/634 Loss: 0.161295
2022-12-31 19:35: Train Epoch 4: 307/634 Loss: 0.179297
2022-12-31 19:35: Train Epoch 4: 311/634 Loss: 0.193767
2022-12-31 19:36: Train Epoch 4: 315/634 Loss: 0.188355
2022-12-31 19:36: Train Epoch 4: 319/634 Loss: 0.167081
2022-12-31 19:36: Train Epoch 4: 323/634 Loss: 0.189927
2022-12-31 19:37: Train Epoch 4: 327/634 Loss: 0.172352
2022-12-31 19:37: Train Epoch 4: 331/634 Loss: 0.236606
2022-12-31 19:37: Train Epoch 4: 335/634 Loss: 0.186778
2022-12-31 19:37: Train Epoch 4: 339/634 Loss: 0.159118
2022-12-31 19:38: Train Epoch 4: 343/634 Loss: 0.208023
2022-12-31 19:38: Train Epoch 4: 347/634 Loss: 0.173331
2022-12-31 19:38: Train Epoch 4: 351/634 Loss: 0.160749
2022-12-31 19:38: Train Epoch 4: 355/634 Loss: 0.163089
2022-12-31 19:39: Train Epoch 4: 359/634 Loss: 0.181990
2022-12-31 19:39: Train Epoch 4: 363/634 Loss: 0.198485
2022-12-31 19:39: Train Epoch 4: 367/634 Loss: 0.197659
2022-12-31 19:39: Train Epoch 4: 371/634 Loss: 0.201524
2022-12-31 19:40: Train Epoch 4: 375/634 Loss: 0.168475
2022-12-31 19:40: Train Epoch 4: 379/634 Loss: 0.171390
2022-12-31 19:40: Train Epoch 4: 383/634 Loss: 0.182360
2022-12-31 19:40: Train Epoch 4: 387/634 Loss: 0.156211
2022-12-31 19:41: Train Epoch 4: 391/634 Loss: 0.183830
2022-12-31 19:41: Train Epoch 4: 395/634 Loss: 0.162982
2022-12-31 19:41: Train Epoch 4: 399/634 Loss: 0.214738
2022-12-31 19:41: Train Epoch 4: 403/634 Loss: 0.185089
2022-12-31 19:42: Train Epoch 4: 407/634 Loss: 0.144538
2022-12-31 19:42: Train Epoch 4: 411/634 Loss: 0.223685
2022-12-31 19:42: Train Epoch 4: 415/634 Loss: 0.180973
2022-12-31 19:42: Train Epoch 4: 419/634 Loss: 0.205557
2022-12-31 19:43: Train Epoch 4: 423/634 Loss: 0.221733
2022-12-31 19:43: Train Epoch 4: 427/634 Loss: 0.194671
2022-12-31 19:43: Train Epoch 4: 431/634 Loss: 0.215216
2022-12-31 19:43: Train Epoch 4: 435/634 Loss: 0.177736
2022-12-31 19:44: Train Epoch 4: 439/634 Loss: 0.177151
2022-12-31 19:44: Train Epoch 4: 443/634 Loss: 0.186242
2022-12-31 19:44: Train Epoch 4: 447/634 Loss: 0.184257
2022-12-31 19:44: Train Epoch 4: 451/634 Loss: 0.163191
2022-12-31 19:45: Train Epoch 4: 455/634 Loss: 0.168515
2022-12-31 19:45: Train Epoch 4: 459/634 Loss: 0.176294
2022-12-31 19:45: Train Epoch 4: 463/634 Loss: 0.177203
2022-12-31 19:45: Train Epoch 4: 467/634 Loss: 0.168055
2022-12-31 19:46: Train Epoch 4: 471/634 Loss: 0.171841
2022-12-31 19:46: Train Epoch 4: 475/634 Loss: 0.151145
2022-12-31 19:46: Train Epoch 4: 479/634 Loss: 0.167588
2022-12-31 19:46: Train Epoch 4: 483/634 Loss: 0.207353
2022-12-31 19:47: Train Epoch 4: 487/634 Loss: 0.172197
2022-12-31 19:47: Train Epoch 4: 491/634 Loss: 0.189064
2022-12-31 19:47: Train Epoch 4: 495/634 Loss: 0.185037
2022-12-31 19:47: Train Epoch 4: 499/634 Loss: 0.153711
2022-12-31 19:48: Train Epoch 4: 503/634 Loss: 0.202823
2022-12-31 19:48: Train Epoch 4: 507/634 Loss: 0.172734
2022-12-31 19:48: Train Epoch 4: 511/634 Loss: 0.186323
2022-12-31 19:48: Train Epoch 4: 515/634 Loss: 0.204184
2022-12-31 19:49: Train Epoch 4: 519/634 Loss: 0.176582
2022-12-31 19:49: Train Epoch 4: 523/634 Loss: 0.189271
2022-12-31 19:49: Train Epoch 4: 527/634 Loss: 0.195788
2022-12-31 19:49: Train Epoch 4: 531/634 Loss: 0.215640
2022-12-31 19:50: Train Epoch 4: 535/634 Loss: 0.212979
2022-12-31 19:50: Train Epoch 4: 539/634 Loss: 0.181103
2022-12-31 19:50: Train Epoch 4: 543/634 Loss: 0.176002
2022-12-31 19:51: Train Epoch 4: 547/634 Loss: 0.166093
2022-12-31 19:51: Train Epoch 4: 551/634 Loss: 0.166917
2022-12-31 19:51: Train Epoch 4: 555/634 Loss: 0.171087
2022-12-31 19:51: Train Epoch 4: 559/634 Loss: 0.168597
2022-12-31 19:52: Train Epoch 4: 563/634 Loss: 0.166170
2022-12-31 19:52: Train Epoch 4: 567/634 Loss: 0.186668
2022-12-31 19:52: Train Epoch 4: 571/634 Loss: 0.174361
2022-12-31 19:52: Train Epoch 4: 575/634 Loss: 0.171496
2022-12-31 19:53: Train Epoch 4: 579/634 Loss: 0.183060
2022-12-31 19:53: Train Epoch 4: 583/634 Loss: 0.189040
2022-12-31 19:53: Train Epoch 4: 587/634 Loss: 0.206538
2022-12-31 19:53: Train Epoch 4: 591/634 Loss: 0.149047
2022-12-31 19:54: Train Epoch 4: 595/634 Loss: 0.169271
2022-12-31 19:54: Train Epoch 4: 599/634 Loss: 0.194667
2022-12-31 19:54: Train Epoch 4: 603/634 Loss: 0.151044
2022-12-31 19:54: Train Epoch 4: 607/634 Loss: 0.172613
2022-12-31 19:54: Train Epoch 4: 611/634 Loss: 0.194583
2022-12-31 19:55: Train Epoch 4: 615/634 Loss: 0.159200
2022-12-31 19:55: Train Epoch 4: 619/634 Loss: 0.193073
2022-12-31 19:55: Train Epoch 4: 623/634 Loss: 0.174369
2022-12-31 19:55: Train Epoch 4: 627/634 Loss: 0.176421
2022-12-31 19:56: Train Epoch 4: 631/634 Loss: 0.165938
2022-12-31 19:56: Train Epoch 4: 633/634 Loss: 0.087181
2022-12-31 19:56: **********Train Epoch 4: averaged Loss: 0.181616 
2022-12-31 19:56: 
Epoch time elapsed: 2448.2181265354156

2022-12-31 19:57: 
 metrics validation: {'precision': 0.855327468230694, 'recall': 0.6730769230769231, 'f1-score': 0.7533362031855361, 'support': 1300, 'AUC': 0.9265440828402367, 'AUCPR': 0.8616423070742324, 'TP': 875, 'FP': 148, 'TN': 2452, 'FN': 425} 

2022-12-31 19:57: **********Val Epoch 4: average Loss: 0.162635
2022-12-31 19:57: *********************************Current best model saved!
2022-12-31 19:58: 
 Testing metrics {'precision': 0.8815489749430524, 'recall': 0.6302931596091205, 'f1-score': 0.7350427350427351, 'support': 1228, 'AUC': 0.9164586626913813, 'AUCPR': 0.8690731913096343, 'TP': 774, 'FP': 104, 'TN': 2352, 'FN': 454} 

2022-12-31 20:03: 
 Testing metrics {'precision': 0.9247755399174957, 'recall': 0.86476060812344, 'f1-score': 0.8937617260787993, 'support': 4407, 'AUC': 0.9777061154796898, 'AUCPR': 0.959472513001184, 'TP': 3811, 'FP': 310, 'TN': 8504, 'FN': 596} 

2022-12-31 20:03: Train Epoch 5: 3/634 Loss: 0.142135
2022-12-31 20:03: Train Epoch 5: 7/634 Loss: 0.195786
2022-12-31 20:03: Train Epoch 5: 11/634 Loss: 0.177453
2022-12-31 20:04: Train Epoch 5: 15/634 Loss: 0.166197
2022-12-31 20:04: Train Epoch 5: 19/634 Loss: 0.180622
2022-12-31 20:04: Train Epoch 5: 23/634 Loss: 0.210606
2022-12-31 20:05: Train Epoch 5: 27/634 Loss: 0.193625
2022-12-31 20:05: Train Epoch 5: 31/634 Loss: 0.194454
2022-12-31 20:05: Train Epoch 5: 35/634 Loss: 0.186426
2022-12-31 20:05: Train Epoch 5: 39/634 Loss: 0.176322
2022-12-31 20:06: Train Epoch 5: 43/634 Loss: 0.165589
2022-12-31 20:06: Train Epoch 5: 47/634 Loss: 0.147039
2022-12-31 20:06: Train Epoch 5: 51/634 Loss: 0.174889
2022-12-31 20:07: Train Epoch 5: 55/634 Loss: 0.196989
2022-12-31 20:07: Train Epoch 5: 59/634 Loss: 0.174418
2022-12-31 20:07: Train Epoch 5: 63/634 Loss: 0.177545
2022-12-31 20:07: Train Epoch 5: 67/634 Loss: 0.197524
2022-12-31 20:08: Train Epoch 5: 71/634 Loss: 0.137810
2022-12-31 20:08: Train Epoch 5: 75/634 Loss: 0.179795
2022-12-31 20:08: Train Epoch 5: 79/634 Loss: 0.169011
2022-12-31 20:09: Train Epoch 5: 83/634 Loss: 0.172368
2022-12-31 20:09: Train Epoch 5: 87/634 Loss: 0.156273
2022-12-31 20:09: Train Epoch 5: 91/634 Loss: 0.169883
2022-12-31 20:09: Train Epoch 5: 95/634 Loss: 0.181759
2022-12-31 20:09: Train Epoch 5: 99/634 Loss: 0.187840
2022-12-31 20:10: Train Epoch 5: 103/634 Loss: 0.212249
2022-12-31 20:10: Train Epoch 5: 107/634 Loss: 0.147492
2022-12-31 20:10: Train Epoch 5: 111/634 Loss: 0.157133
2022-12-31 20:11: Train Epoch 5: 115/634 Loss: 0.174186
2022-12-31 20:11: Train Epoch 5: 119/634 Loss: 0.143325
2022-12-31 20:11: Train Epoch 5: 123/634 Loss: 0.177800
2022-12-31 20:11: Train Epoch 5: 127/634 Loss: 0.174065
2022-12-31 20:12: Train Epoch 5: 131/634 Loss: 0.191739
2022-12-31 20:12: Train Epoch 5: 135/634 Loss: 0.182921
2022-12-31 20:12: Train Epoch 5: 139/634 Loss: 0.202004
2022-12-31 20:12: Train Epoch 5: 143/634 Loss: 0.186822
2022-12-31 20:13: Train Epoch 5: 147/634 Loss: 0.159014
2022-12-31 20:13: Train Epoch 5: 151/634 Loss: 0.172181
2022-12-31 20:13: Train Epoch 5: 155/634 Loss: 0.168966
2022-12-31 20:13: Train Epoch 5: 159/634 Loss: 0.195262
2022-12-31 20:14: Train Epoch 5: 163/634 Loss: 0.194978
2022-12-31 20:14: Train Epoch 5: 167/634 Loss: 0.200004
2022-12-31 20:14: Train Epoch 5: 171/634 Loss: 0.189980
2022-12-31 20:14: Train Epoch 5: 175/634 Loss: 0.177007
2022-12-31 20:15: Train Epoch 5: 179/634 Loss: 0.227603
2022-12-31 20:15: Train Epoch 5: 183/634 Loss: 0.176203
2022-12-31 20:15: Train Epoch 5: 187/634 Loss: 0.153472
2022-12-31 20:15: Train Epoch 5: 191/634 Loss: 0.184543
2022-12-31 20:16: Train Epoch 5: 195/634 Loss: 0.201078
2022-12-31 20:16: Train Epoch 5: 199/634 Loss: 0.198075
2022-12-31 20:16: Train Epoch 5: 203/634 Loss: 0.190582
2022-12-31 20:16: Train Epoch 5: 207/634 Loss: 0.150094
2022-12-31 20:17: Train Epoch 5: 211/634 Loss: 0.161163
2022-12-31 20:17: Train Epoch 5: 215/634 Loss: 0.187823
2022-12-31 20:17: Train Epoch 5: 219/634 Loss: 0.197998
2022-12-31 20:17: Train Epoch 5: 223/634 Loss: 0.172433
2022-12-31 20:18: Train Epoch 5: 227/634 Loss: 0.189641
2022-12-31 20:18: Train Epoch 5: 231/634 Loss: 0.181977
2022-12-31 20:18: Train Epoch 5: 235/634 Loss: 0.185171
2022-12-31 20:18: Train Epoch 5: 239/634 Loss: 0.172910
2022-12-31 20:19: Train Epoch 5: 243/634 Loss: 0.180828
2022-12-31 20:19: Train Epoch 5: 247/634 Loss: 0.173923
2022-12-31 20:19: Train Epoch 5: 251/634 Loss: 0.159434
2022-12-31 20:19: Train Epoch 5: 255/634 Loss: 0.171989
2022-12-31 20:20: Train Epoch 5: 259/634 Loss: 0.156440
2022-12-31 20:20: Train Epoch 5: 263/634 Loss: 0.142993
2022-12-31 20:20: Train Epoch 5: 267/634 Loss: 0.164226
2022-12-31 20:20: Train Epoch 5: 271/634 Loss: 0.190091
2022-12-31 20:21: Train Epoch 5: 275/634 Loss: 0.157979
2022-12-31 20:21: Train Epoch 5: 279/634 Loss: 0.158857
2022-12-31 20:21: Train Epoch 5: 283/634 Loss: 0.220108
2022-12-31 20:21: Train Epoch 5: 287/634 Loss: 0.160525
2022-12-31 20:22: Train Epoch 5: 291/634 Loss: 0.187294
2022-12-31 20:22: Train Epoch 5: 295/634 Loss: 0.185805
2022-12-31 20:22: Train Epoch 5: 299/634 Loss: 0.174459
2022-12-31 20:22: Train Epoch 5: 303/634 Loss: 0.170719
2022-12-31 20:22: Train Epoch 5: 307/634 Loss: 0.170897
2022-12-31 20:23: Train Epoch 5: 311/634 Loss: 0.161211
2022-12-31 20:23: Train Epoch 5: 315/634 Loss: 0.159702
2022-12-31 20:23: Train Epoch 5: 319/634 Loss: 0.193861
2022-12-31 20:23: Train Epoch 5: 323/634 Loss: 0.173474
2022-12-31 20:24: Train Epoch 5: 327/634 Loss: 0.161022
2022-12-31 20:24: Train Epoch 5: 331/634 Loss: 0.180931
2022-12-31 20:24: Train Epoch 5: 335/634 Loss: 0.184168
2022-12-31 20:24: Train Epoch 5: 339/634 Loss: 0.183402
2022-12-31 20:25: Train Epoch 5: 343/634 Loss: 0.191140
2022-12-31 20:25: Train Epoch 5: 347/634 Loss: 0.173876
2022-12-31 20:25: Train Epoch 5: 351/634 Loss: 0.176791
2022-12-31 20:26: Train Epoch 5: 355/634 Loss: 0.161241
2022-12-31 20:26: Train Epoch 5: 359/634 Loss: 0.176320
2022-12-31 20:26: Train Epoch 5: 363/634 Loss: 0.174354
2022-12-31 20:26: Train Epoch 5: 367/634 Loss: 0.171847
2022-12-31 20:27: Train Epoch 5: 371/634 Loss: 0.192067
2022-12-31 20:27: Train Epoch 5: 375/634 Loss: 0.163555
2022-12-31 20:27: Train Epoch 5: 379/634 Loss: 0.169855
2022-12-31 20:27: Train Epoch 5: 383/634 Loss: 0.162906
2022-12-31 20:28: Train Epoch 5: 387/634 Loss: 0.164288
2022-12-31 20:28: Train Epoch 5: 391/634 Loss: 0.142550
2022-12-31 20:28: Train Epoch 5: 395/634 Loss: 0.154178
2022-12-31 20:28: Train Epoch 5: 399/634 Loss: 0.183685
2022-12-31 20:29: Train Epoch 5: 403/634 Loss: 0.131169
2022-12-31 20:29: Train Epoch 5: 407/634 Loss: 0.153013
2022-12-31 20:29: Train Epoch 5: 411/634 Loss: 0.177331
2022-12-31 20:30: Train Epoch 5: 415/634 Loss: 0.172701
2022-12-31 20:30: Train Epoch 5: 419/634 Loss: 0.160934
2022-12-31 20:30: Train Epoch 5: 423/634 Loss: 0.181259
2022-12-31 20:30: Train Epoch 5: 427/634 Loss: 0.181322
2022-12-31 20:31: Train Epoch 5: 431/634 Loss: 0.175362
2022-12-31 20:31: Train Epoch 5: 435/634 Loss: 0.160358
2022-12-31 20:31: Train Epoch 5: 439/634 Loss: 0.173951
2022-12-31 20:31: Train Epoch 5: 443/634 Loss: 0.156162
2022-12-31 20:32: Train Epoch 5: 447/634 Loss: 0.179651
2022-12-31 20:32: Train Epoch 5: 451/634 Loss: 0.166072
2022-12-31 20:32: Train Epoch 5: 455/634 Loss: 0.201061
2022-12-31 20:32: Train Epoch 5: 459/634 Loss: 0.178851
2022-12-31 20:33: Train Epoch 5: 463/634 Loss: 0.180782
2022-12-31 20:33: Train Epoch 5: 467/634 Loss: 0.201561
2022-12-31 20:33: Train Epoch 5: 471/634 Loss: 0.165648
2022-12-31 20:33: Train Epoch 5: 475/634 Loss: 0.185761
2022-12-31 20:34: Train Epoch 5: 479/634 Loss: 0.193263
2022-12-31 20:34: Train Epoch 5: 483/634 Loss: 0.163773
2022-12-31 20:34: Train Epoch 5: 487/634 Loss: 0.176392
2022-12-31 20:34: Train Epoch 5: 491/634 Loss: 0.198550
2022-12-31 20:35: Train Epoch 5: 495/634 Loss: 0.165754
2022-12-31 20:35: Train Epoch 5: 499/634 Loss: 0.204029
2022-12-31 20:35: Train Epoch 5: 503/634 Loss: 0.202178
2022-12-31 20:36: Train Epoch 5: 507/634 Loss: 0.179253
2022-12-31 20:36: Train Epoch 5: 511/634 Loss: 0.213753
2022-12-31 20:36: Train Epoch 5: 515/634 Loss: 0.156577
2022-12-31 20:36: Train Epoch 5: 519/634 Loss: 0.157241
2022-12-31 20:37: Train Epoch 5: 523/634 Loss: 0.179702
2022-12-31 20:37: Train Epoch 5: 527/634 Loss: 0.167995
2022-12-31 20:37: Train Epoch 5: 531/634 Loss: 0.187520
2022-12-31 20:37: Train Epoch 5: 535/634 Loss: 0.166254
2022-12-31 20:38: Train Epoch 5: 539/634 Loss: 0.190866
2022-12-31 20:38: Train Epoch 5: 543/634 Loss: 0.154125
2022-12-31 20:38: Train Epoch 5: 547/634 Loss: 0.188527
2022-12-31 20:38: Train Epoch 5: 551/634 Loss: 0.194850
2022-12-31 20:39: Train Epoch 5: 555/634 Loss: 0.168727
2022-12-31 20:39: Train Epoch 5: 559/634 Loss: 0.157311
2022-12-31 20:39: Train Epoch 5: 563/634 Loss: 0.184251
2022-12-31 20:39: Train Epoch 5: 567/634 Loss: 0.153465
2022-12-31 20:40: Train Epoch 5: 571/634 Loss: 0.174321
2022-12-31 20:40: Train Epoch 5: 575/634 Loss: 0.151029
2022-12-31 20:40: Train Epoch 5: 579/634 Loss: 0.178906
2022-12-31 20:40: Train Epoch 5: 583/634 Loss: 0.213991
2022-12-31 20:41: Train Epoch 5: 587/634 Loss: 0.172298
2022-12-31 20:41: Train Epoch 5: 591/634 Loss: 0.155480
2022-12-31 20:41: Train Epoch 5: 595/634 Loss: 0.155877
2022-12-31 20:41: Train Epoch 5: 599/634 Loss: 0.177234
2022-12-31 20:42: Train Epoch 5: 603/634 Loss: 0.188041
2022-12-31 20:42: Train Epoch 5: 607/634 Loss: 0.185141
2022-12-31 20:42: Train Epoch 5: 611/634 Loss: 0.147320
2022-12-31 20:42: Train Epoch 5: 615/634 Loss: 0.175737
2022-12-31 20:43: Train Epoch 5: 619/634 Loss: 0.177552
2022-12-31 20:43: Train Epoch 5: 623/634 Loss: 0.162004
2022-12-31 20:43: Train Epoch 5: 627/634 Loss: 0.207196
2022-12-31 20:44: Train Epoch 5: 631/634 Loss: 0.132212
2022-12-31 20:44: Train Epoch 5: 633/634 Loss: 0.080310
2022-12-31 20:44: **********Train Epoch 5: averaged Loss: 0.175190 
2022-12-31 20:44: 
Epoch time elapsed: 2463.1850373744965

2022-12-31 20:45: 
 metrics validation: {'precision': 0.8941605839416058, 'recall': 0.5653846153846154, 'f1-score': 0.6927426955702168, 'support': 1300, 'AUC': 0.9324745562130179, 'AUCPR': 0.8731498733241044, 'TP': 735, 'FP': 87, 'TN': 2513, 'FN': 565} 

2022-12-31 20:45: **********Val Epoch 5: average Loss: 0.170105
2022-12-31 20:46: 
 Testing metrics {'precision': 0.8815489749430524, 'recall': 0.6302931596091205, 'f1-score': 0.7350427350427351, 'support': 1228, 'AUC': 0.9164586626913813, 'AUCPR': 0.8690731913096343, 'TP': 774, 'FP': 104, 'TN': 2352, 'FN': 454} 

2022-12-31 20:50: 
 Testing metrics {'precision': 0.9247755399174957, 'recall': 0.86476060812344, 'f1-score': 0.8937617260787993, 'support': 4407, 'AUC': 0.9777061154796898, 'AUCPR': 0.959472513001184, 'TP': 3811, 'FP': 310, 'TN': 8504, 'FN': 596} 

2022-12-31 20:51: Train Epoch 6: 3/634 Loss: 0.151321
2022-12-31 20:51: Train Epoch 6: 7/634 Loss: 0.159546
2022-12-31 20:51: Train Epoch 6: 11/634 Loss: 0.171715
2022-12-31 20:51: Train Epoch 6: 15/634 Loss: 0.177851
2022-12-31 20:52: Train Epoch 6: 19/634 Loss: 0.164005
2022-12-31 20:52: Train Epoch 6: 23/634 Loss: 0.146180
2022-12-31 20:52: Train Epoch 6: 27/634 Loss: 0.192735
2022-12-31 20:53: Train Epoch 6: 31/634 Loss: 0.162396
2022-12-31 20:53: Train Epoch 6: 35/634 Loss: 0.149567
2022-12-31 20:53: Train Epoch 6: 39/634 Loss: 0.159610
2022-12-31 20:53: Train Epoch 6: 43/634 Loss: 0.186204
2022-12-31 20:54: Train Epoch 6: 47/634 Loss: 0.168817
2022-12-31 20:54: Train Epoch 6: 51/634 Loss: 0.169721
2022-12-31 20:54: Train Epoch 6: 55/634 Loss: 0.150863
2022-12-31 20:55: Train Epoch 6: 59/634 Loss: 0.161267
2022-12-31 20:55: Train Epoch 6: 63/634 Loss: 0.183567
2022-12-31 20:55: Train Epoch 6: 67/634 Loss: 0.205712
2022-12-31 20:55: Train Epoch 6: 71/634 Loss: 0.186143
2022-12-31 20:56: Train Epoch 6: 75/634 Loss: 0.173284
2022-12-31 20:56: Train Epoch 6: 79/634 Loss: 0.153255
2022-12-31 20:56: Train Epoch 6: 83/634 Loss: 0.187616
2022-12-31 20:56: Train Epoch 6: 87/634 Loss: 0.181157
2022-12-31 20:57: Train Epoch 6: 91/634 Loss: 0.175149
2022-12-31 20:57: Train Epoch 6: 95/634 Loss: 0.174687
2022-12-31 20:57: Train Epoch 6: 99/634 Loss: 0.165709
2022-12-31 20:57: Train Epoch 6: 103/634 Loss: 0.166310
2022-12-31 20:58: Train Epoch 6: 107/634 Loss: 0.177777
2022-12-31 20:58: Train Epoch 6: 111/634 Loss: 0.164629
2022-12-31 20:58: Train Epoch 6: 115/634 Loss: 0.175096
2022-12-31 20:58: Train Epoch 6: 119/634 Loss: 0.208970
2022-12-31 20:59: Train Epoch 6: 123/634 Loss: 0.166117
2022-12-31 20:59: Train Epoch 6: 127/634 Loss: 0.165926
2022-12-31 20:59: Train Epoch 6: 131/634 Loss: 0.189009
2022-12-31 20:59: Train Epoch 6: 135/634 Loss: 0.151096
2022-12-31 21:00: Train Epoch 6: 139/634 Loss: 0.164627
2022-12-31 21:00: Train Epoch 6: 143/634 Loss: 0.186509
2022-12-31 21:00: Train Epoch 6: 147/634 Loss: 0.170228
2022-12-31 21:00: Train Epoch 6: 151/634 Loss: 0.186137
2022-12-31 21:01: Train Epoch 6: 155/634 Loss: 0.203321
2022-12-31 21:01: Train Epoch 6: 159/634 Loss: 0.174967
2022-12-31 21:01: Train Epoch 6: 163/634 Loss: 0.212305
2022-12-31 21:01: Train Epoch 6: 167/634 Loss: 0.193999
2022-12-31 21:02: Train Epoch 6: 171/634 Loss: 0.171835
2022-12-31 21:02: Train Epoch 6: 175/634 Loss: 0.156700
2022-12-31 21:02: Train Epoch 6: 179/634 Loss: 0.196715
2022-12-31 21:02: Train Epoch 6: 183/634 Loss: 0.161912
2022-12-31 21:03: Train Epoch 6: 187/634 Loss: 0.192262
2022-12-31 21:03: Train Epoch 6: 191/634 Loss: 0.169945
2022-12-31 21:03: Train Epoch 6: 195/634 Loss: 0.205144
2022-12-31 21:03: Train Epoch 6: 199/634 Loss: 0.190017
2022-12-31 21:04: Train Epoch 6: 203/634 Loss: 0.178774
2022-12-31 21:04: Train Epoch 6: 207/634 Loss: 0.164056
2022-12-31 21:04: Train Epoch 6: 211/634 Loss: 0.164709
2022-12-31 21:04: Train Epoch 6: 215/634 Loss: 0.148085
2022-12-31 21:05: Train Epoch 6: 219/634 Loss: 0.200889
2022-12-31 21:05: Train Epoch 6: 223/634 Loss: 0.174914
2022-12-31 21:05: Train Epoch 6: 227/634 Loss: 0.176904
2022-12-31 21:05: Train Epoch 6: 231/634 Loss: 0.191767
2022-12-31 21:06: Train Epoch 6: 235/634 Loss: 0.171413
2022-12-31 21:06: Train Epoch 6: 239/634 Loss: 0.167812
2022-12-31 21:06: Train Epoch 6: 243/634 Loss: 0.170460
2022-12-31 21:06: Train Epoch 6: 247/634 Loss: 0.151317
2022-12-31 21:07: Train Epoch 6: 251/634 Loss: 0.188456
2022-12-31 21:07: Train Epoch 6: 255/634 Loss: 0.211285
2022-12-31 21:07: Train Epoch 6: 259/634 Loss: 0.164797
2022-12-31 21:08: Train Epoch 6: 263/634 Loss: 0.172301
2022-12-31 21:08: Train Epoch 6: 267/634 Loss: 0.205012
2022-12-31 21:08: Train Epoch 6: 271/634 Loss: 0.181106
2022-12-31 21:08: Train Epoch 6: 275/634 Loss: 0.169389
2022-12-31 21:09: Train Epoch 6: 279/634 Loss: 0.184095
2022-12-31 21:09: Train Epoch 6: 283/634 Loss: 0.177363
2022-12-31 21:09: Train Epoch 6: 287/634 Loss: 0.178837
2022-12-31 21:09: Train Epoch 6: 291/634 Loss: 0.184906
2022-12-31 21:10: Train Epoch 6: 295/634 Loss: 0.194776
2022-12-31 21:10: Train Epoch 6: 299/634 Loss: 0.163667
2022-12-31 21:10: Train Epoch 6: 303/634 Loss: 0.178678
2022-12-31 21:10: Train Epoch 6: 307/634 Loss: 0.179161
2022-12-31 21:11: Train Epoch 6: 311/634 Loss: 0.177750
2022-12-31 21:11: Train Epoch 6: 315/634 Loss: 0.165699
2022-12-31 21:11: Train Epoch 6: 319/634 Loss: 0.188745
2022-12-31 21:11: Train Epoch 6: 323/634 Loss: 0.150374
2022-12-31 21:12: Train Epoch 6: 327/634 Loss: 0.157164
2022-12-31 21:12: Train Epoch 6: 331/634 Loss: 0.180409
2022-12-31 21:12: Train Epoch 6: 335/634 Loss: 0.181801
2022-12-31 21:13: Train Epoch 6: 339/634 Loss: 0.153298
2022-12-31 21:13: Train Epoch 6: 343/634 Loss: 0.195638
2022-12-31 21:13: Train Epoch 6: 347/634 Loss: 0.179334
2022-12-31 21:13: Train Epoch 6: 351/634 Loss: 0.211562
2022-12-31 21:14: Train Epoch 6: 355/634 Loss: 0.138144
2022-12-31 21:14: Train Epoch 6: 359/634 Loss: 0.182574
2022-12-31 21:14: Train Epoch 6: 363/634 Loss: 0.190069
2022-12-31 21:14: Train Epoch 6: 367/634 Loss: 0.227162
2022-12-31 21:15: Train Epoch 6: 371/634 Loss: 0.207955
2022-12-31 21:15: Train Epoch 6: 375/634 Loss: 0.169976
2022-12-31 21:15: Train Epoch 6: 379/634 Loss: 0.169988
2022-12-31 21:15: Train Epoch 6: 383/634 Loss: 0.192719
2022-12-31 21:16: Train Epoch 6: 387/634 Loss: 0.170699
2022-12-31 21:16: Train Epoch 6: 391/634 Loss: 0.160049
2022-12-31 21:16: Train Epoch 6: 395/634 Loss: 0.177112
2022-12-31 21:16: Train Epoch 6: 399/634 Loss: 0.179655
2022-12-31 21:17: Train Epoch 6: 403/634 Loss: 0.190005
2022-12-31 21:17: Train Epoch 6: 407/634 Loss: 0.176680
2022-12-31 21:17: Train Epoch 6: 411/634 Loss: 0.145750
2022-12-31 21:17: Train Epoch 6: 415/634 Loss: 0.179581
2022-12-31 21:18: Train Epoch 6: 419/634 Loss: 0.186410
2022-12-31 21:18: Train Epoch 6: 423/634 Loss: 0.167843
2022-12-31 21:18: Train Epoch 6: 427/634 Loss: 0.155864
2022-12-31 21:18: Train Epoch 6: 431/634 Loss: 0.167708
2022-12-31 21:19: Train Epoch 6: 435/634 Loss: 0.148189
2022-12-31 21:19: Train Epoch 6: 439/634 Loss: 0.173988
2022-12-31 21:19: Train Epoch 6: 443/634 Loss: 0.179537
2022-12-31 21:19: Train Epoch 6: 447/634 Loss: 0.173054
2022-12-31 21:20: Train Epoch 6: 451/634 Loss: 0.166700
2022-12-31 21:20: Train Epoch 6: 455/634 Loss: 0.165736
2022-12-31 21:20: Train Epoch 6: 459/634 Loss: 0.156292
2022-12-31 21:21: Train Epoch 6: 463/634 Loss: 0.179226
2022-12-31 21:21: Train Epoch 6: 467/634 Loss: 0.192699
2022-12-31 21:21: Train Epoch 6: 471/634 Loss: 0.171778
2022-12-31 21:21: Train Epoch 6: 475/634 Loss: 0.187081
2022-12-31 21:22: Train Epoch 6: 479/634 Loss: 0.178384
2022-12-31 21:22: Train Epoch 6: 483/634 Loss: 0.157818
2022-12-31 21:22: Train Epoch 6: 487/634 Loss: 0.180042
2022-12-31 21:22: Train Epoch 6: 491/634 Loss: 0.167728
2022-12-31 21:23: Train Epoch 6: 495/634 Loss: 0.176642
2022-12-31 21:23: Train Epoch 6: 499/634 Loss: 0.177042
2022-12-31 21:23: Train Epoch 6: 503/634 Loss: 0.173227
2022-12-31 21:23: Train Epoch 6: 507/634 Loss: 0.177413
2022-12-31 21:24: Train Epoch 6: 511/634 Loss: 0.194699
2022-12-31 21:24: Train Epoch 6: 515/634 Loss: 0.168655
2022-12-31 21:24: Train Epoch 6: 519/634 Loss: 0.162901
2022-12-31 21:24: Train Epoch 6: 523/634 Loss: 0.165173
2022-12-31 21:25: Train Epoch 6: 527/634 Loss: 0.158569
2022-12-31 21:25: Train Epoch 6: 531/634 Loss: 0.138710
2022-12-31 21:25: Train Epoch 6: 535/634 Loss: 0.161612
2022-12-31 21:25: Train Epoch 6: 539/634 Loss: 0.166327
2022-12-31 21:26: Train Epoch 6: 543/634 Loss: 0.159635
2022-12-31 21:26: Train Epoch 6: 547/634 Loss: 0.227179
2022-12-31 21:26: Train Epoch 6: 551/634 Loss: 0.147845
2022-12-31 21:26: Train Epoch 6: 555/634 Loss: 0.175961
2022-12-31 21:27: Train Epoch 6: 559/634 Loss: 0.175305
2022-12-31 21:27: Train Epoch 6: 563/634 Loss: 0.154758
2022-12-31 21:27: Train Epoch 6: 567/634 Loss: 0.206105
2022-12-31 21:27: Train Epoch 6: 571/634 Loss: 0.157029
2022-12-31 21:28: Train Epoch 6: 575/634 Loss: 0.177118
2022-12-31 21:28: Train Epoch 6: 579/634 Loss: 0.235257
2022-12-31 21:28: Train Epoch 6: 583/634 Loss: 0.153321
2022-12-31 21:28: Train Epoch 6: 587/634 Loss: 0.170297
2022-12-31 21:29: Train Epoch 6: 591/634 Loss: 0.198812
2022-12-31 21:29: Train Epoch 6: 595/634 Loss: 0.183453
2022-12-31 21:29: Train Epoch 6: 599/634 Loss: 0.178378
2022-12-31 21:29: Train Epoch 6: 603/634 Loss: 0.173522
2022-12-31 21:30: Train Epoch 6: 607/634 Loss: 0.169751
2022-12-31 21:30: Train Epoch 6: 611/634 Loss: 0.191318
2022-12-31 21:30: Train Epoch 6: 615/634 Loss: 0.194303
2022-12-31 21:30: Train Epoch 6: 619/634 Loss: 0.154878
2022-12-31 21:31: Train Epoch 6: 623/634 Loss: 0.178556
2022-12-31 21:31: Train Epoch 6: 627/634 Loss: 0.186953
2022-12-31 21:31: Train Epoch 6: 631/634 Loss: 0.149927
2022-12-31 21:31: Train Epoch 6: 633/634 Loss: 0.065935
2022-12-31 21:31: **********Train Epoch 6: averaged Loss: 0.174824 
2022-12-31 21:31: 
Epoch time elapsed: 2463.727739095688

2022-12-31 21:33: 
 metrics validation: {'precision': 0.7531857813547954, 'recall': 0.8638461538461538, 'f1-score': 0.8047294876388391, 'support': 1300, 'AUC': 0.9356181952662722, 'AUCPR': 0.8768019563472726, 'TP': 1123, 'FP': 368, 'TN': 2232, 'FN': 177} 

2022-12-31 21:33: **********Val Epoch 6: average Loss: 0.151100
2022-12-31 21:33: *********************************Current best model saved!
2022-12-31 21:34: 
 Testing metrics {'precision': 0.7714968152866242, 'recall': 0.7890879478827362, 'f1-score': 0.7801932367149759, 'support': 1228, 'AUC': 0.9193903914099884, 'AUCPR': 0.8735667119458774, 'TP': 969, 'FP': 287, 'TN': 2169, 'FN': 259} 

2022-12-31 21:38: 
 Testing metrics {'precision': 0.8400081317340923, 'recall': 0.9375992738824597, 'f1-score': 0.8861248123525627, 'support': 4407, 'AUC': 0.9781639293347336, 'AUCPR': 0.9600428075957826, 'TP': 4132, 'FP': 787, 'TN': 8027, 'FN': 275} 

2022-12-31 21:38: Train Epoch 7: 3/634 Loss: 0.178381
2022-12-31 21:39: Train Epoch 7: 7/634 Loss: 0.153139
2022-12-31 21:39: Train Epoch 7: 11/634 Loss: 0.179400
2022-12-31 21:39: Train Epoch 7: 15/634 Loss: 0.181046
2022-12-31 21:40: Train Epoch 7: 19/634 Loss: 0.169703
2022-12-31 21:40: Train Epoch 7: 23/634 Loss: 0.167023
2022-12-31 21:40: Train Epoch 7: 27/634 Loss: 0.170964
2022-12-31 21:40: Train Epoch 7: 31/634 Loss: 0.195100
2022-12-31 21:41: Train Epoch 7: 35/634 Loss: 0.218998
2022-12-31 21:41: Train Epoch 7: 39/634 Loss: 0.154999
2022-12-31 21:41: Train Epoch 7: 43/634 Loss: 0.136460
2022-12-31 21:41: Train Epoch 7: 47/634 Loss: 0.191309
2022-12-31 21:42: Train Epoch 7: 51/634 Loss: 0.151163
2022-12-31 21:42: Train Epoch 7: 55/634 Loss: 0.198951
2022-12-31 21:42: Train Epoch 7: 59/634 Loss: 0.181818
2022-12-31 21:42: Train Epoch 7: 63/634 Loss: 0.143419
2022-12-31 21:43: Train Epoch 7: 67/634 Loss: 0.163925
2022-12-31 21:43: Train Epoch 7: 71/634 Loss: 0.136752
2022-12-31 21:43: Train Epoch 7: 75/634 Loss: 0.189767
2022-12-31 21:43: Train Epoch 7: 79/634 Loss: 0.205097
2022-12-31 21:44: Train Epoch 7: 83/634 Loss: 0.174133
2022-12-31 21:44: Train Epoch 7: 87/634 Loss: 0.167098
2022-12-31 21:44: Train Epoch 7: 91/634 Loss: 0.168653
2022-12-31 21:44: Train Epoch 7: 95/634 Loss: 0.203204
2022-12-31 21:45: Train Epoch 7: 99/634 Loss: 0.175507
2022-12-31 21:45: Train Epoch 7: 103/634 Loss: 0.196308
2022-12-31 21:45: Train Epoch 7: 107/634 Loss: 0.182588
2022-12-31 21:46: Train Epoch 7: 111/634 Loss: 0.166268
2022-12-31 21:46: Train Epoch 7: 115/634 Loss: 0.169038
2022-12-31 21:46: Train Epoch 7: 119/634 Loss: 0.147244
2022-12-31 21:46: Train Epoch 7: 123/634 Loss: 0.162176
2022-12-31 21:47: Train Epoch 7: 127/634 Loss: 0.135707
2022-12-31 21:47: Train Epoch 7: 131/634 Loss: 0.143527
2022-12-31 21:47: Train Epoch 7: 135/634 Loss: 0.150085
2022-12-31 21:47: Train Epoch 7: 139/634 Loss: 0.166243
2022-12-31 21:48: Train Epoch 7: 143/634 Loss: 0.183065
2022-12-31 21:48: Train Epoch 7: 147/634 Loss: 0.157847
2022-12-31 21:48: Train Epoch 7: 151/634 Loss: 0.141648
2022-12-31 21:48: Train Epoch 7: 155/634 Loss: 0.160447
2022-12-31 21:49: Train Epoch 7: 159/634 Loss: 0.175571
2022-12-31 21:49: Train Epoch 7: 163/634 Loss: 0.180803
2022-12-31 21:49: Train Epoch 7: 167/634 Loss: 0.178198
2022-12-31 21:49: Train Epoch 7: 171/634 Loss: 0.179608
2022-12-31 21:50: Train Epoch 7: 175/634 Loss: 0.160487
2022-12-31 21:50: Train Epoch 7: 179/634 Loss: 0.139189
2022-12-31 21:50: Train Epoch 7: 183/634 Loss: 0.154555
2022-12-31 21:51: Train Epoch 7: 187/634 Loss: 0.192982
2022-12-31 21:51: Train Epoch 7: 191/634 Loss: 0.161238
2022-12-31 21:51: Train Epoch 7: 195/634 Loss: 0.155088
2022-12-31 21:51: Train Epoch 7: 199/634 Loss: 0.137977
2022-12-31 21:52: Train Epoch 7: 203/634 Loss: 0.167505
2022-12-31 21:52: Train Epoch 7: 207/634 Loss: 0.166169
2022-12-31 21:52: Train Epoch 7: 211/634 Loss: 0.177041
2022-12-31 21:52: Train Epoch 7: 215/634 Loss: 0.153152
2022-12-31 21:53: Train Epoch 7: 219/634 Loss: 0.162558
2022-12-31 21:53: Train Epoch 7: 223/634 Loss: 0.186018
2022-12-31 21:53: Train Epoch 7: 227/634 Loss: 0.138775
2022-12-31 21:53: Train Epoch 7: 231/634 Loss: 0.162973
2022-12-31 21:54: Train Epoch 7: 235/634 Loss: 0.162853
2022-12-31 21:54: Train Epoch 7: 239/634 Loss: 0.185373
2022-12-31 21:54: Train Epoch 7: 243/634 Loss: 0.190412
2022-12-31 21:55: Train Epoch 7: 247/634 Loss: 0.159195
2022-12-31 21:55: Train Epoch 7: 251/634 Loss: 0.161935
2022-12-31 21:55: Train Epoch 7: 255/634 Loss: 0.158143
2022-12-31 21:55: Train Epoch 7: 259/634 Loss: 0.171565
2022-12-31 21:56: Train Epoch 7: 263/634 Loss: 0.144146
2022-12-31 21:56: Train Epoch 7: 267/634 Loss: 0.150051
2022-12-31 21:56: Train Epoch 7: 271/634 Loss: 0.206323
2022-12-31 21:56: Train Epoch 7: 275/634 Loss: 0.160758
2022-12-31 21:57: Train Epoch 7: 279/634 Loss: 0.180143
2022-12-31 21:57: Train Epoch 7: 283/634 Loss: 0.170610
2022-12-31 21:57: Train Epoch 7: 287/634 Loss: 0.178648
2022-12-31 21:57: Train Epoch 7: 291/634 Loss: 0.145524
2022-12-31 21:58: Train Epoch 7: 295/634 Loss: 0.191613
2022-12-31 21:58: Train Epoch 7: 299/634 Loss: 0.158557
2022-12-31 21:58: Train Epoch 7: 303/634 Loss: 0.174791
2022-12-31 21:58: Train Epoch 7: 307/634 Loss: 0.169938
2022-12-31 21:59: Train Epoch 7: 311/634 Loss: 0.160282
2022-12-31 21:59: Train Epoch 7: 315/634 Loss: 0.184141
2022-12-31 21:59: Train Epoch 7: 319/634 Loss: 0.160111
2022-12-31 22:00: Train Epoch 7: 323/634 Loss: 0.144972
2022-12-31 22:00: Train Epoch 7: 327/634 Loss: 0.152666
2022-12-31 22:00: Train Epoch 7: 331/634 Loss: 0.151419
2022-12-31 22:00: Train Epoch 7: 335/634 Loss: 0.118325
2022-12-31 22:01: Train Epoch 7: 339/634 Loss: 0.184699
2022-12-31 22:01: Train Epoch 7: 343/634 Loss: 0.173871
2022-12-31 22:01: Train Epoch 7: 347/634 Loss: 0.150875
2022-12-31 22:01: Train Epoch 7: 351/634 Loss: 0.150969
2022-12-31 22:02: Train Epoch 7: 355/634 Loss: 0.158883
2022-12-31 22:02: Train Epoch 7: 359/634 Loss: 0.166179
2022-12-31 22:02: Train Epoch 7: 363/634 Loss: 0.159651
2022-12-31 22:02: Train Epoch 7: 367/634 Loss: 0.150754
2022-12-31 22:03: Train Epoch 7: 371/634 Loss: 0.158364
2022-12-31 22:03: Train Epoch 7: 375/634 Loss: 0.151976
2022-12-31 22:03: Train Epoch 7: 379/634 Loss: 0.160016
2022-12-31 22:03: Train Epoch 7: 383/634 Loss: 0.163209
2022-12-31 22:04: Train Epoch 7: 387/634 Loss: 0.166558
2022-12-31 22:04: Train Epoch 7: 391/634 Loss: 0.181115
2022-12-31 22:04: Train Epoch 7: 395/634 Loss: 0.164668
2022-12-31 22:04: Train Epoch 7: 399/634 Loss: 0.143233
2022-12-31 22:05: Train Epoch 7: 403/634 Loss: 0.182656
2022-12-31 22:05: Train Epoch 7: 407/634 Loss: 0.179787
2022-12-31 22:05: Train Epoch 7: 411/634 Loss: 0.160816
2022-12-31 22:05: Train Epoch 7: 415/634 Loss: 0.201045
2022-12-31 22:06: Train Epoch 7: 419/634 Loss: 0.157546
2022-12-31 22:06: Train Epoch 7: 423/634 Loss: 0.160746
2022-12-31 22:06: Train Epoch 7: 427/634 Loss: 0.152207
2022-12-31 22:06: Train Epoch 7: 431/634 Loss: 0.153436
2022-12-31 22:07: Train Epoch 7: 435/634 Loss: 0.142780
2022-12-31 22:07: Train Epoch 7: 439/634 Loss: 0.186884
2022-12-31 22:07: Train Epoch 7: 443/634 Loss: 0.172888
2022-12-31 22:07: Train Epoch 7: 447/634 Loss: 0.173617
2022-12-31 22:08: Train Epoch 7: 451/634 Loss: 0.186333
2022-12-31 22:08: Train Epoch 7: 455/634 Loss: 0.211935
2022-12-31 22:08: Train Epoch 7: 459/634 Loss: 0.161210
2022-12-31 22:08: Train Epoch 7: 463/634 Loss: 0.163908
2022-12-31 22:09: Train Epoch 7: 467/634 Loss: 0.154722
2022-12-31 22:09: Train Epoch 7: 471/634 Loss: 0.165075
2022-12-31 22:09: Train Epoch 7: 475/634 Loss: 0.200517
2022-12-31 22:09: Train Epoch 7: 479/634 Loss: 0.171934
2022-12-31 22:10: Train Epoch 7: 483/634 Loss: 0.143031
2022-12-31 22:10: Train Epoch 7: 487/634 Loss: 0.171071
2022-12-31 22:10: Train Epoch 7: 491/634 Loss: 0.157811
2022-12-31 22:10: Train Epoch 7: 495/634 Loss: 0.142070
2022-12-31 22:11: Train Epoch 7: 499/634 Loss: 0.137443
2022-12-31 22:11: Train Epoch 7: 503/634 Loss: 0.168556
2022-12-31 22:11: Train Epoch 7: 507/634 Loss: 0.195228
2022-12-31 22:12: Train Epoch 7: 511/634 Loss: 0.189984
2022-12-31 22:12: Train Epoch 7: 515/634 Loss: 0.160379
2022-12-31 22:12: Train Epoch 7: 519/634 Loss: 0.184984
2022-12-31 22:12: Train Epoch 7: 523/634 Loss: 0.194278
2022-12-31 22:13: Train Epoch 7: 527/634 Loss: 0.156655
2022-12-31 22:13: Train Epoch 7: 531/634 Loss: 0.185903
2022-12-31 22:13: Train Epoch 7: 535/634 Loss: 0.181512
2022-12-31 22:13: Train Epoch 7: 539/634 Loss: 0.174969
2022-12-31 22:14: Train Epoch 7: 543/634 Loss: 0.155802
2022-12-31 22:14: Train Epoch 7: 547/634 Loss: 0.173772
2022-12-31 22:14: Train Epoch 7: 551/634 Loss: 0.174029
2022-12-31 22:14: Train Epoch 7: 555/634 Loss: 0.152120
2022-12-31 22:15: Train Epoch 7: 559/634 Loss: 0.196075
2022-12-31 22:15: Train Epoch 7: 563/634 Loss: 0.176309
2022-12-31 22:15: Train Epoch 7: 567/634 Loss: 0.157314
2022-12-31 22:15: Train Epoch 7: 571/634 Loss: 0.172708
2022-12-31 22:16: Train Epoch 7: 575/634 Loss: 0.176674
2022-12-31 22:16: Train Epoch 7: 579/634 Loss: 0.156988
2022-12-31 22:16: Train Epoch 7: 583/634 Loss: 0.194546
2022-12-31 22:16: Train Epoch 7: 587/634 Loss: 0.164214
2022-12-31 22:17: Train Epoch 7: 591/634 Loss: 0.156502
2022-12-31 22:17: Train Epoch 7: 595/634 Loss: 0.140711
2022-12-31 22:17: Train Epoch 7: 599/634 Loss: 0.180991
2022-12-31 22:18: Train Epoch 7: 603/634 Loss: 0.163404
2022-12-31 22:18: Train Epoch 7: 607/634 Loss: 0.157722
2022-12-31 22:18: Train Epoch 7: 611/634 Loss: 0.173796
2022-12-31 22:18: Train Epoch 7: 615/634 Loss: 0.133403
2022-12-31 22:19: Train Epoch 7: 619/634 Loss: 0.162389
2022-12-31 22:19: Train Epoch 7: 623/634 Loss: 0.170297
2022-12-31 22:19: Train Epoch 7: 627/634 Loss: 0.146519
2022-12-31 22:19: Train Epoch 7: 631/634 Loss: 0.134107
2022-12-31 22:19: Train Epoch 7: 633/634 Loss: 0.076332
2022-12-31 22:19: **********Train Epoch 7: averaged Loss: 0.166391 
2022-12-31 22:19: 
Epoch time elapsed: 2484.6444330215454

2022-12-31 22:21: 
 metrics validation: {'precision': 0.839765100671141, 'recall': 0.77, 'f1-score': 0.8033707865168539, 'support': 1300, 'AUC': 0.9353491124260354, 'AUCPR': 0.8781065109795902, 'TP': 1001, 'FP': 191, 'TN': 2409, 'FN': 299} 

2022-12-31 22:21: **********Val Epoch 7: average Loss: 0.146788
2022-12-31 22:21: *********************************Current best model saved!
2022-12-31 22:22: 
 Testing metrics {'precision': 0.8536335721596725, 'recall': 0.6791530944625407, 'f1-score': 0.7564625850340136, 'support': 1228, 'AUC': 0.9249173068149263, 'AUCPR': 0.8803130745009232, 'TP': 834, 'FP': 143, 'TN': 2313, 'FN': 394} 

2022-12-31 22:26: 
 Testing metrics {'precision': 0.9100938967136151, 'recall': 0.8797367823916497, 'f1-score': 0.8946578977731625, 'support': 4407, 'AUC': 0.9773343653775227, 'AUCPR': 0.9560084359577133, 'TP': 3877, 'FP': 383, 'TN': 8431, 'FN': 530} 

2022-12-31 22:27: Train Epoch 8: 3/634 Loss: 0.154613
2022-12-31 22:27: Train Epoch 8: 7/634 Loss: 0.173605
2022-12-31 22:27: Train Epoch 8: 11/634 Loss: 0.166142
2022-12-31 22:28: Train Epoch 8: 15/634 Loss: 0.189154
2022-12-31 22:28: Train Epoch 8: 19/634 Loss: 0.148157
2022-12-31 22:28: Train Epoch 8: 23/634 Loss: 0.156214
2022-12-31 22:28: Train Epoch 8: 27/634 Loss: 0.140424
2022-12-31 22:29: Train Epoch 8: 31/634 Loss: 0.185607
2022-12-31 22:29: Train Epoch 8: 35/634 Loss: 0.150628
2022-12-31 22:29: Train Epoch 8: 39/634 Loss: 0.161043
2022-12-31 22:29: Train Epoch 8: 43/634 Loss: 0.163105
2022-12-31 22:30: Train Epoch 8: 47/634 Loss: 0.166976
2022-12-31 22:30: Train Epoch 8: 51/634 Loss: 0.164430
2022-12-31 22:30: Train Epoch 8: 55/634 Loss: 0.181103
2022-12-31 22:30: Train Epoch 8: 59/634 Loss: 0.171624
2022-12-31 22:31: Train Epoch 8: 63/634 Loss: 0.176056
2022-12-31 22:31: Train Epoch 8: 67/634 Loss: 0.169797
2022-12-31 22:31: Train Epoch 8: 71/634 Loss: 0.164370
2022-12-31 22:32: Train Epoch 8: 75/634 Loss: 0.187312
2022-12-31 22:32: Train Epoch 8: 79/634 Loss: 0.184246
2022-12-31 22:32: Train Epoch 8: 83/634 Loss: 0.159728
2022-12-31 22:32: Train Epoch 8: 87/634 Loss: 0.168316
2022-12-31 22:32: Train Epoch 8: 91/634 Loss: 0.150161
2022-12-31 22:33: Train Epoch 8: 95/634 Loss: 0.178854
2022-12-31 22:33: Train Epoch 8: 99/634 Loss: 0.156951
2022-12-31 22:33: Train Epoch 8: 103/634 Loss: 0.149343
2022-12-31 22:34: Train Epoch 8: 107/634 Loss: 0.155555
2022-12-31 22:34: Train Epoch 8: 111/634 Loss: 0.147628
2022-12-31 22:34: Train Epoch 8: 115/634 Loss: 0.164020
2022-12-31 22:34: Train Epoch 8: 119/634 Loss: 0.157469
2022-12-31 22:35: Train Epoch 8: 123/634 Loss: 0.188907
2022-12-31 22:35: Train Epoch 8: 127/634 Loss: 0.168522
2022-12-31 22:35: Train Epoch 8: 131/634 Loss: 0.176081
2022-12-31 22:35: Train Epoch 8: 135/634 Loss: 0.159300
2022-12-31 22:36: Train Epoch 8: 139/634 Loss: 0.182346
2022-12-31 22:36: Train Epoch 8: 143/634 Loss: 0.171767
2022-12-31 22:36: Train Epoch 8: 147/634 Loss: 0.147186
2022-12-31 22:36: Train Epoch 8: 151/634 Loss: 0.183895
2022-12-31 22:37: Train Epoch 8: 155/634 Loss: 0.192787
2022-12-31 22:37: Train Epoch 8: 159/634 Loss: 0.193332
2022-12-31 22:37: Train Epoch 8: 163/634 Loss: 0.190123
2022-12-31 22:37: Train Epoch 8: 167/634 Loss: 0.194410
2022-12-31 22:38: Train Epoch 8: 171/634 Loss: 0.152439
2022-12-31 22:38: Train Epoch 8: 175/634 Loss: 0.164531
2022-12-31 22:38: Train Epoch 8: 179/634 Loss: 0.143439
2022-12-31 22:38: Train Epoch 8: 183/634 Loss: 0.136007
2022-12-31 22:39: Train Epoch 8: 187/634 Loss: 0.168630
2022-12-31 22:39: Train Epoch 8: 191/634 Loss: 0.182863
2022-12-31 22:39: Train Epoch 8: 195/634 Loss: 0.156507
2022-12-31 22:39: Train Epoch 8: 199/634 Loss: 0.160732
2022-12-31 22:40: Train Epoch 8: 203/634 Loss: 0.165850
2022-12-31 22:40: Train Epoch 8: 207/634 Loss: 0.140778
2022-12-31 22:40: Train Epoch 8: 211/634 Loss: 0.137767
2022-12-31 22:40: Train Epoch 8: 215/634 Loss: 0.187076
2022-12-31 22:41: Train Epoch 8: 219/634 Loss: 0.158443
2022-12-31 22:41: Train Epoch 8: 223/634 Loss: 0.171782
2022-12-31 22:41: Train Epoch 8: 227/634 Loss: 0.169280
2022-12-31 22:41: Train Epoch 8: 231/634 Loss: 0.184951
2022-12-31 22:42: Train Epoch 8: 235/634 Loss: 0.155656
2022-12-31 22:42: Train Epoch 8: 239/634 Loss: 0.166193
2022-12-31 22:42: Train Epoch 8: 243/634 Loss: 0.157896
2022-12-31 22:42: Train Epoch 8: 247/634 Loss: 0.192683
2022-12-31 22:43: Train Epoch 8: 251/634 Loss: 0.164456
2022-12-31 22:43: Train Epoch 8: 255/634 Loss: 0.161583
2022-12-31 22:43: Train Epoch 8: 259/634 Loss: 0.153696
2022-12-31 22:43: Train Epoch 8: 263/634 Loss: 0.185463
2022-12-31 22:44: Train Epoch 8: 267/634 Loss: 0.157013
2022-12-31 22:44: Train Epoch 8: 271/634 Loss: 0.185912
2022-12-31 22:44: Train Epoch 8: 275/634 Loss: 0.141380
2022-12-31 22:44: Train Epoch 8: 279/634 Loss: 0.203304
2022-12-31 22:45: Train Epoch 8: 283/634 Loss: 0.176518
2022-12-31 22:45: Train Epoch 8: 287/634 Loss: 0.139941
2022-12-31 22:45: Train Epoch 8: 291/634 Loss: 0.167646
2022-12-31 22:45: Train Epoch 8: 295/634 Loss: 0.161709
2022-12-31 22:46: Train Epoch 8: 299/634 Loss: 0.151156
2022-12-31 22:46: Train Epoch 8: 303/634 Loss: 0.152856
2022-12-31 22:46: Train Epoch 8: 307/634 Loss: 0.132259
2022-12-31 22:46: Train Epoch 8: 311/634 Loss: 0.156903
2022-12-31 22:47: Train Epoch 8: 315/634 Loss: 0.160754
2022-12-31 22:47: Train Epoch 8: 319/634 Loss: 0.143353
2022-12-31 22:47: Train Epoch 8: 323/634 Loss: 0.138428
2022-12-31 22:47: Train Epoch 8: 327/634 Loss: 0.172019
2022-12-31 22:48: Train Epoch 8: 331/634 Loss: 0.175409
2022-12-31 22:48: Train Epoch 8: 335/634 Loss: 0.185475
2022-12-31 22:48: Train Epoch 8: 339/634 Loss: 0.139051
2022-12-31 22:48: Train Epoch 8: 343/634 Loss: 0.158153
2022-12-31 22:49: Train Epoch 8: 347/634 Loss: 0.183599
2022-12-31 22:49: Train Epoch 8: 351/634 Loss: 0.181994
2022-12-31 22:49: Train Epoch 8: 355/634 Loss: 0.169860
2022-12-31 22:49: Train Epoch 8: 359/634 Loss: 0.164318
2022-12-31 22:50: Train Epoch 8: 363/634 Loss: 0.153452
2022-12-31 22:50: Train Epoch 8: 367/634 Loss: 0.155430
2022-12-31 22:50: Train Epoch 8: 371/634 Loss: 0.167594
2022-12-31 22:50: Train Epoch 8: 375/634 Loss: 0.184640
2022-12-31 22:51: Train Epoch 8: 379/634 Loss: 0.155029
2022-12-31 22:51: Train Epoch 8: 383/634 Loss: 0.200946
2022-12-31 22:51: Train Epoch 8: 387/634 Loss: 0.160467
2022-12-31 22:51: Train Epoch 8: 391/634 Loss: 0.164922
2022-12-31 22:52: Train Epoch 8: 395/634 Loss: 0.156998
2022-12-31 22:52: Train Epoch 8: 399/634 Loss: 0.185867
2022-12-31 22:52: Train Epoch 8: 403/634 Loss: 0.152486
2022-12-31 22:52: Train Epoch 8: 407/634 Loss: 0.165969
2022-12-31 22:53: Train Epoch 8: 411/634 Loss: 0.158114
2022-12-31 22:53: Train Epoch 8: 415/634 Loss: 0.159686
2022-12-31 22:53: Train Epoch 8: 419/634 Loss: 0.157760
2022-12-31 22:54: Train Epoch 8: 423/634 Loss: 0.171376
2022-12-31 22:54: Train Epoch 8: 427/634 Loss: 0.156644
2022-12-31 22:54: Train Epoch 8: 431/634 Loss: 0.179015
2022-12-31 22:54: Train Epoch 8: 435/634 Loss: 0.161546
2022-12-31 22:55: Train Epoch 8: 439/634 Loss: 0.192866
2022-12-31 22:55: Train Epoch 8: 443/634 Loss: 0.176414
2022-12-31 22:55: Train Epoch 8: 447/634 Loss: 0.147489
2022-12-31 22:55: Train Epoch 8: 451/634 Loss: 0.158902
2022-12-31 22:56: Train Epoch 8: 455/634 Loss: 0.195077
2022-12-31 22:56: Train Epoch 8: 459/634 Loss: 0.139429
2022-12-31 22:56: Train Epoch 8: 463/634 Loss: 0.146081
2022-12-31 22:56: Train Epoch 8: 467/634 Loss: 0.175093
2022-12-31 22:57: Train Epoch 8: 471/634 Loss: 0.171664
2022-12-31 22:57: Train Epoch 8: 475/634 Loss: 0.160682
2022-12-31 22:57: Train Epoch 8: 479/634 Loss: 0.152293
2022-12-31 22:57: Train Epoch 8: 483/634 Loss: 0.182664
2022-12-31 22:58: Train Epoch 8: 487/634 Loss: 0.181568
2022-12-31 22:58: Train Epoch 8: 491/634 Loss: 0.144790
2022-12-31 22:58: Train Epoch 8: 495/634 Loss: 0.153016
2022-12-31 22:59: Train Epoch 8: 499/634 Loss: 0.152447
2022-12-31 22:59: Train Epoch 8: 503/634 Loss: 0.145084
2022-12-31 22:59: Train Epoch 8: 507/634 Loss: 0.161737
2022-12-31 22:59: Train Epoch 8: 511/634 Loss: 0.176644
2022-12-31 23:00: Train Epoch 8: 515/634 Loss: 0.159263
2022-12-31 23:00: Train Epoch 8: 519/634 Loss: 0.171153
2022-12-31 23:00: Train Epoch 8: 523/634 Loss: 0.192717
2022-12-31 23:00: Train Epoch 8: 527/634 Loss: 0.143791
2022-12-31 23:01: Train Epoch 8: 531/634 Loss: 0.149920
2022-12-31 23:01: Train Epoch 8: 535/634 Loss: 0.154987
2022-12-31 23:01: Train Epoch 8: 539/634 Loss: 0.166848
2022-12-31 23:02: Train Epoch 8: 543/634 Loss: 0.133849
2022-12-31 23:02: Train Epoch 8: 547/634 Loss: 0.163932
2022-12-31 23:02: Train Epoch 8: 551/634 Loss: 0.150355
2022-12-31 23:02: Train Epoch 8: 555/634 Loss: 0.174913
2022-12-31 23:03: Train Epoch 8: 559/634 Loss: 0.148964
2022-12-31 23:03: Train Epoch 8: 563/634 Loss: 0.160938
2022-12-31 23:03: Train Epoch 8: 567/634 Loss: 0.144922
2022-12-31 23:03: Train Epoch 8: 571/634 Loss: 0.146623
2022-12-31 23:04: Train Epoch 8: 575/634 Loss: 0.170950
2022-12-31 23:04: Train Epoch 8: 579/634 Loss: 0.135043
2022-12-31 23:04: Train Epoch 8: 583/634 Loss: 0.173430
2022-12-31 23:05: Train Epoch 8: 587/634 Loss: 0.185394
2022-12-31 23:05: Train Epoch 8: 591/634 Loss: 0.164410
2022-12-31 23:05: Train Epoch 8: 595/634 Loss: 0.181406
2022-12-31 23:05: Train Epoch 8: 599/634 Loss: 0.154989
2022-12-31 23:06: Train Epoch 8: 603/634 Loss: 0.165288
2022-12-31 23:06: Train Epoch 8: 607/634 Loss: 0.192983
2022-12-31 23:06: Train Epoch 8: 611/634 Loss: 0.180824
2022-12-31 23:06: Train Epoch 8: 615/634 Loss: 0.150054
2022-12-31 23:07: Train Epoch 8: 619/634 Loss: 0.190576
2022-12-31 23:07: Train Epoch 8: 623/634 Loss: 0.184531
2022-12-31 23:07: Train Epoch 8: 627/634 Loss: 0.144801
2022-12-31 23:07: Train Epoch 8: 631/634 Loss: 0.185622
2022-12-31 23:07: Train Epoch 8: 633/634 Loss: 0.099920
2022-12-31 23:07: **********Train Epoch 8: averaged Loss: 0.164744 
2022-12-31 23:07: 
Epoch time elapsed: 2465.547943353653

2022-12-31 23:09: 
 metrics validation: {'precision': 0.794074074074074, 'recall': 0.8246153846153846, 'f1-score': 0.8090566037735849, 'support': 1300, 'AUC': 0.9352680473372781, 'AUCPR': 0.8757341936435852, 'TP': 1072, 'FP': 278, 'TN': 2322, 'FN': 228} 

2022-12-31 23:09: **********Val Epoch 8: average Loss: 0.144922
2022-12-31 23:09: *********************************Current best model saved!
2022-12-31 23:10: 
 Testing metrics {'precision': 0.8113744075829384, 'recall': 0.6970684039087948, 'f1-score': 0.7498904949627684, 'support': 1228, 'AUC': 0.9184268533353138, 'AUCPR': 0.8673183172702172, 'TP': 856, 'FP': 199, 'TN': 2257, 'FN': 372} 

2022-12-31 23:14: 
 Testing metrics {'precision': 0.871998187584957, 'recall': 0.8733832539142273, 'f1-score': 0.8726901711824055, 'support': 4407, 'AUC': 0.9721789586455817, 'AUCPR': 0.9449833298592358, 'TP': 3849, 'FP': 565, 'TN': 8249, 'FN': 558} 

2022-12-31 23:14: Train Epoch 9: 3/634 Loss: 0.183715
2022-12-31 23:15: Train Epoch 9: 7/634 Loss: 0.182666
2022-12-31 23:15: Train Epoch 9: 11/634 Loss: 0.207517
2022-12-31 23:15: Train Epoch 9: 15/634 Loss: 0.173031
2022-12-31 23:15: Train Epoch 9: 19/634 Loss: 0.132394
2022-12-31 23:16: Train Epoch 9: 23/634 Loss: 0.187458
2022-12-31 23:16: Train Epoch 9: 27/634 Loss: 0.175765
2022-12-31 23:16: Train Epoch 9: 31/634 Loss: 0.136272
2022-12-31 23:17: Train Epoch 9: 35/634 Loss: 0.175482
2022-12-31 23:17: Train Epoch 9: 39/634 Loss: 0.183524
2022-12-31 23:17: Train Epoch 9: 43/634 Loss: 0.151893
2022-12-31 23:17: Train Epoch 9: 47/634 Loss: 0.150509
2022-12-31 23:18: Train Epoch 9: 51/634 Loss: 0.144326
2022-12-31 23:18: Train Epoch 9: 55/634 Loss: 0.152692
2022-12-31 23:18: Train Epoch 9: 59/634 Loss: 0.173553
2022-12-31 23:18: Train Epoch 9: 63/634 Loss: 0.156998
2022-12-31 23:19: Train Epoch 9: 67/634 Loss: 0.169009
2022-12-31 23:19: Train Epoch 9: 71/634 Loss: 0.164301
2022-12-31 23:19: Train Epoch 9: 75/634 Loss: 0.152143
2022-12-31 23:19: Train Epoch 9: 79/634 Loss: 0.166795
2022-12-31 23:20: Train Epoch 9: 83/634 Loss: 0.163344
2022-12-31 23:20: Train Epoch 9: 87/634 Loss: 0.145165
2022-12-31 23:20: Train Epoch 9: 91/634 Loss: 0.154421
2022-12-31 23:20: Train Epoch 9: 95/634 Loss: 0.172657
2022-12-31 23:21: Train Epoch 9: 99/634 Loss: 0.134661
2022-12-31 23:21: Train Epoch 9: 103/634 Loss: 0.153508
2022-12-31 23:21: Train Epoch 9: 107/634 Loss: 0.150905
2022-12-31 23:21: Train Epoch 9: 111/634 Loss: 0.145362
2022-12-31 23:22: Train Epoch 9: 115/634 Loss: 0.147619
2022-12-31 23:22: Train Epoch 9: 119/634 Loss: 0.173022
2022-12-31 23:22: Train Epoch 9: 123/634 Loss: 0.147793
2022-12-31 23:22: Train Epoch 9: 127/634 Loss: 0.151328
2022-12-31 23:23: Train Epoch 9: 131/634 Loss: 0.158403
2022-12-31 23:23: Train Epoch 9: 135/634 Loss: 0.161699
2022-12-31 23:23: Train Epoch 9: 139/634 Loss: 0.161526
2022-12-31 23:23: Train Epoch 9: 143/634 Loss: 0.146040
2022-12-31 23:23: Train Epoch 9: 147/634 Loss: 0.130027
2022-12-31 23:24: Train Epoch 9: 151/634 Loss: 0.184384
2022-12-31 23:24: Train Epoch 9: 155/634 Loss: 0.154266
2022-12-31 23:24: Train Epoch 9: 159/634 Loss: 0.183039
2022-12-31 23:25: Train Epoch 9: 163/634 Loss: 0.181751
2022-12-31 23:25: Train Epoch 9: 167/634 Loss: 0.176651
2022-12-31 23:25: Train Epoch 9: 171/634 Loss: 0.145486
2022-12-31 23:25: Train Epoch 9: 175/634 Loss: 0.220726
2022-12-31 23:26: Train Epoch 9: 179/634 Loss: 0.178316
2022-12-31 23:26: Train Epoch 9: 183/634 Loss: 0.153409
2022-12-31 23:26: Train Epoch 9: 187/634 Loss: 0.203548
2022-12-31 23:26: Train Epoch 9: 191/634 Loss: 0.192728
2022-12-31 23:27: Train Epoch 9: 195/634 Loss: 0.154692
2022-12-31 23:27: Train Epoch 9: 199/634 Loss: 0.187112
2022-12-31 23:27: Train Epoch 9: 203/634 Loss: 0.160830
2022-12-31 23:27: Train Epoch 9: 207/634 Loss: 0.185951
2022-12-31 23:27: Train Epoch 9: 211/634 Loss: 0.149547
2022-12-31 23:28: Train Epoch 9: 215/634 Loss: 0.161363
2022-12-31 23:28: Train Epoch 9: 219/634 Loss: 0.176812
2022-12-31 23:28: Train Epoch 9: 223/634 Loss: 0.204727
2022-12-31 23:28: Train Epoch 9: 227/634 Loss: 0.143258
2022-12-31 23:29: Train Epoch 9: 231/634 Loss: 0.230094
2022-12-31 23:29: Train Epoch 9: 235/634 Loss: 0.183669
2022-12-31 23:29: Train Epoch 9: 239/634 Loss: 0.185811
2022-12-31 23:29: Train Epoch 9: 243/634 Loss: 0.185652
2022-12-31 23:30: Train Epoch 9: 247/634 Loss: 0.153875
2022-12-31 23:30: Train Epoch 9: 251/634 Loss: 0.163503
2022-12-31 23:30: Train Epoch 9: 255/634 Loss: 0.177456
2022-12-31 23:30: Train Epoch 9: 259/634 Loss: 0.169191
2022-12-31 23:31: Train Epoch 9: 263/634 Loss: 0.158523
2022-12-31 23:31: Train Epoch 9: 267/634 Loss: 0.196113
2022-12-31 23:31: Train Epoch 9: 271/634 Loss: 0.200826
2022-12-31 23:31: Train Epoch 9: 275/634 Loss: 0.156337
2022-12-31 23:32: Train Epoch 9: 279/634 Loss: 0.151519
2022-12-31 23:32: Train Epoch 9: 283/634 Loss: 0.169374
2022-12-31 23:32: Train Epoch 9: 287/634 Loss: 0.179762
2022-12-31 23:32: Train Epoch 9: 291/634 Loss: 0.155554
2022-12-31 23:33: Train Epoch 9: 295/634 Loss: 0.142362
2022-12-31 23:33: Train Epoch 9: 299/634 Loss: 0.154124
2022-12-31 23:33: Train Epoch 9: 303/634 Loss: 0.175824
2022-12-31 23:33: Train Epoch 9: 307/634 Loss: 0.173384
2022-12-31 23:34: Train Epoch 9: 311/634 Loss: 0.158841
2022-12-31 23:34: Train Epoch 9: 315/634 Loss: 0.185976
2022-12-31 23:34: Train Epoch 9: 319/634 Loss: 0.126902
2022-12-31 23:34: Train Epoch 9: 323/634 Loss: 0.148540
2022-12-31 23:35: Train Epoch 9: 327/634 Loss: 0.176856
2022-12-31 23:35: Train Epoch 9: 331/634 Loss: 0.158828
2022-12-31 23:35: Train Epoch 9: 335/634 Loss: 0.144813
2022-12-31 23:36: Train Epoch 9: 339/634 Loss: 0.138249
2022-12-31 23:36: Train Epoch 9: 343/634 Loss: 0.206185
2022-12-31 23:36: Train Epoch 9: 347/634 Loss: 0.141644
2022-12-31 23:36: Train Epoch 9: 351/634 Loss: 0.173408
2022-12-31 23:37: Train Epoch 9: 355/634 Loss: 0.177426
2022-12-31 23:37: Train Epoch 9: 359/634 Loss: 0.142904
2022-12-31 23:37: Train Epoch 9: 363/634 Loss: 0.192686
2022-12-31 23:37: Train Epoch 9: 367/634 Loss: 0.182268
2022-12-31 23:38: Train Epoch 9: 371/634 Loss: 0.146097
2022-12-31 23:38: Train Epoch 9: 375/634 Loss: 0.183924
2022-12-31 23:38: Train Epoch 9: 379/634 Loss: 0.156945
2022-12-31 23:38: Train Epoch 9: 383/634 Loss: 0.173224
2022-12-31 23:39: Train Epoch 9: 387/634 Loss: 0.146235
2022-12-31 23:39: Train Epoch 9: 391/634 Loss: 0.170611
2022-12-31 23:39: Train Epoch 9: 395/634 Loss: 0.155730
2022-12-31 23:39: Train Epoch 9: 399/634 Loss: 0.166151
2022-12-31 23:40: Train Epoch 9: 403/634 Loss: 0.161126
2022-12-31 23:40: Train Epoch 9: 407/634 Loss: 0.175985
2022-12-31 23:40: Train Epoch 9: 411/634 Loss: 0.142452
2022-12-31 23:40: Train Epoch 9: 415/634 Loss: 0.148485
2022-12-31 23:41: Train Epoch 9: 419/634 Loss: 0.148625
2022-12-31 23:41: Train Epoch 9: 423/634 Loss: 0.177947
2022-12-31 23:41: Train Epoch 9: 427/634 Loss: 0.138967
2022-12-31 23:41: Train Epoch 9: 431/634 Loss: 0.163826
2022-12-31 23:42: Train Epoch 9: 435/634 Loss: 0.156947
2022-12-31 23:42: Train Epoch 9: 439/634 Loss: 0.151212
2022-12-31 23:42: Train Epoch 9: 443/634 Loss: 0.167514
2022-12-31 23:43: Train Epoch 9: 447/634 Loss: 0.148086
2022-12-31 23:43: Train Epoch 9: 451/634 Loss: 0.137493
2022-12-31 23:43: Train Epoch 9: 455/634 Loss: 0.174948
2022-12-31 23:43: Train Epoch 9: 459/634 Loss: 0.164314
2022-12-31 23:44: Train Epoch 9: 463/634 Loss: 0.130074
2022-12-31 23:44: Train Epoch 9: 467/634 Loss: 0.160572
2022-12-31 23:44: Train Epoch 9: 471/634 Loss: 0.140044
2022-12-31 23:44: Train Epoch 9: 475/634 Loss: 0.146823
2022-12-31 23:45: Train Epoch 9: 479/634 Loss: 0.163898
2022-12-31 23:45: Train Epoch 9: 483/634 Loss: 0.192784
2022-12-31 23:45: Train Epoch 9: 487/634 Loss: 0.162610
2022-12-31 23:45: Train Epoch 9: 491/634 Loss: 0.193962
2022-12-31 23:46: Train Epoch 9: 495/634 Loss: 0.158712
2022-12-31 23:46: Train Epoch 9: 499/634 Loss: 0.166074
2022-12-31 23:46: Train Epoch 9: 503/634 Loss: 0.156821
2022-12-31 23:46: Train Epoch 9: 507/634 Loss: 0.165109
2022-12-31 23:47: Train Epoch 9: 511/634 Loss: 0.143827
2022-12-31 23:47: Train Epoch 9: 515/634 Loss: 0.135962
2022-12-31 23:47: Train Epoch 9: 519/634 Loss: 0.168219
2022-12-31 23:47: Train Epoch 9: 523/634 Loss: 0.146393
2022-12-31 23:48: Train Epoch 9: 527/634 Loss: 0.149185
2022-12-31 23:48: Train Epoch 9: 531/634 Loss: 0.147880
2022-12-31 23:48: Train Epoch 9: 535/634 Loss: 0.154127
2022-12-31 23:48: Train Epoch 9: 539/634 Loss: 0.154433
2022-12-31 23:49: Train Epoch 9: 543/634 Loss: 0.143378
2022-12-31 23:49: Train Epoch 9: 547/634 Loss: 0.192283
2022-12-31 23:49: Train Epoch 9: 551/634 Loss: 0.162958
2022-12-31 23:50: Train Epoch 9: 555/634 Loss: 0.173302
2022-12-31 23:50: Train Epoch 9: 559/634 Loss: 0.177588
2022-12-31 23:50: Train Epoch 9: 563/634 Loss: 0.168044
2022-12-31 23:50: Train Epoch 9: 567/634 Loss: 0.166697
2022-12-31 23:51: Train Epoch 9: 571/634 Loss: 0.178317
2022-12-31 23:51: Train Epoch 9: 575/634 Loss: 0.133468
2022-12-31 23:51: Train Epoch 9: 579/634 Loss: 0.155059
2022-12-31 23:51: Train Epoch 9: 583/634 Loss: 0.149921
2022-12-31 23:52: Train Epoch 9: 587/634 Loss: 0.139474
2022-12-31 23:52: Train Epoch 9: 591/634 Loss: 0.146891
2022-12-31 23:52: Train Epoch 9: 595/634 Loss: 0.141675
2022-12-31 23:52: Train Epoch 9: 599/634 Loss: 0.172115
2022-12-31 23:53: Train Epoch 9: 603/634 Loss: 0.136561
2022-12-31 23:53: Train Epoch 9: 607/634 Loss: 0.146236
2022-12-31 23:53: Train Epoch 9: 611/634 Loss: 0.138012
2022-12-31 23:53: Train Epoch 9: 615/634 Loss: 0.161492
2022-12-31 23:54: Train Epoch 9: 619/634 Loss: 0.163310
2022-12-31 23:54: Train Epoch 9: 623/634 Loss: 0.200829
2022-12-31 23:54: Train Epoch 9: 627/634 Loss: 0.149275
2022-12-31 23:55: Train Epoch 9: 631/634 Loss: 0.174169
2022-12-31 23:55: Train Epoch 9: 633/634 Loss: 0.071242
2022-12-31 23:55: **********Train Epoch 9: averaged Loss: 0.162712 
2022-12-31 23:55: 
Epoch time elapsed: 2426.4917075634003

2022-12-31 23:56: 
 metrics validation: {'precision': 0.8105891126025354, 'recall': 0.8361538461538461, 'f1-score': 0.8231730405149565, 'support': 1300, 'AUC': 0.9454304733727811, 'AUCPR': 0.8957499642676416, 'TP': 1087, 'FP': 254, 'TN': 2346, 'FN': 213} 

2022-12-31 23:56: **********Val Epoch 9: average Loss: 0.133880
2022-12-31 23:56: *********************************Current best model saved!
2022-12-31 23:57: 
 Testing metrics {'precision': 0.8269230769230769, 'recall': 0.7353420195439739, 'f1-score': 0.778448275862069, 'support': 1228, 'AUC': 0.9259564425086739, 'AUCPR': 0.8821838707655952, 'TP': 903, 'FP': 189, 'TN': 2267, 'FN': 325} 

2023-01-01 00:01: 
 Testing metrics {'precision': 0.8794449262792715, 'recall': 0.9203539823008849, 'f1-score': 0.8994345271094356, 'support': 4407, 'AUC': 0.9798750610723115, 'AUCPR': 0.9619710816950665, 'TP': 4056, 'FP': 556, 'TN': 8258, 'FN': 351} 

2023-01-01 00:02: Train Epoch 10: 3/634 Loss: 0.160452
2023-01-01 00:02: Train Epoch 10: 7/634 Loss: 0.148401
2023-01-01 00:02: Train Epoch 10: 11/634 Loss: 0.145210
2023-01-01 00:03: Train Epoch 10: 15/634 Loss: 0.180314
2023-01-01 00:03: Train Epoch 10: 19/634 Loss: 0.165842
2023-01-01 00:03: Train Epoch 10: 23/634 Loss: 0.154500
2023-01-01 00:03: Train Epoch 10: 27/634 Loss: 0.141846
2023-01-01 00:04: Train Epoch 10: 31/634 Loss: 0.172783
2023-01-01 00:04: Train Epoch 10: 35/634 Loss: 0.156096
2023-01-01 00:04: Train Epoch 10: 39/634 Loss: 0.166086
2023-01-01 00:04: Train Epoch 10: 43/634 Loss: 0.147682
2023-01-01 00:05: Train Epoch 10: 47/634 Loss: 0.151184
2023-01-01 00:05: Train Epoch 10: 51/634 Loss: 0.153393
2023-01-01 00:05: Train Epoch 10: 55/634 Loss: 0.162827
2023-01-01 00:05: Train Epoch 10: 59/634 Loss: 0.159505
2023-01-01 00:06: Train Epoch 10: 63/634 Loss: 0.137970
2023-01-01 00:06: Train Epoch 10: 67/634 Loss: 0.172563
2023-01-01 00:06: Train Epoch 10: 71/634 Loss: 0.142449
2023-01-01 00:06: Train Epoch 10: 75/634 Loss: 0.140431
2023-01-01 00:07: Train Epoch 10: 79/634 Loss: 0.151948
2023-01-01 00:07: Train Epoch 10: 83/634 Loss: 0.154395
2023-01-01 00:07: Train Epoch 10: 87/634 Loss: 0.143015
2023-01-01 00:07: Train Epoch 10: 91/634 Loss: 0.145680
2023-01-01 00:08: Train Epoch 10: 95/634 Loss: 0.175570
2023-01-01 00:08: Train Epoch 10: 99/634 Loss: 0.143256
2023-01-01 00:08: Train Epoch 10: 103/634 Loss: 0.158716
2023-01-01 00:08: Train Epoch 10: 107/634 Loss: 0.202820
2023-01-01 00:09: Train Epoch 10: 111/634 Loss: 0.153989
2023-01-01 00:09: Train Epoch 10: 115/634 Loss: 0.171617
2023-01-01 00:09: Train Epoch 10: 119/634 Loss: 0.149034
2023-01-01 00:09: Train Epoch 10: 123/634 Loss: 0.128864
2023-01-01 00:10: Train Epoch 10: 127/634 Loss: 0.134125
2023-01-01 00:10: Train Epoch 10: 131/634 Loss: 0.168937
2023-01-01 00:10: Train Epoch 10: 135/634 Loss: 0.157826
2023-01-01 00:11: Train Epoch 10: 139/634 Loss: 0.157625
2023-01-01 00:11: Train Epoch 10: 143/634 Loss: 0.132302
2023-01-01 00:11: Train Epoch 10: 147/634 Loss: 0.156727
2023-01-01 00:11: Train Epoch 10: 151/634 Loss: 0.132913
2023-01-01 00:11: Train Epoch 10: 155/634 Loss: 0.151864
2023-01-01 00:12: Train Epoch 10: 159/634 Loss: 0.139757
2023-01-01 00:12: Train Epoch 10: 163/634 Loss: 0.158551
2023-01-01 00:12: Train Epoch 10: 167/634 Loss: 0.145908
2023-01-01 00:13: Train Epoch 10: 171/634 Loss: 0.155376
2023-01-01 00:13: Train Epoch 10: 175/634 Loss: 0.158717
2023-01-01 00:13: Train Epoch 10: 179/634 Loss: 0.144025
2023-01-01 00:13: Train Epoch 10: 183/634 Loss: 0.138068
2023-01-01 00:14: Train Epoch 10: 187/634 Loss: 0.148255
2023-01-01 00:14: Train Epoch 10: 191/634 Loss: 0.157214
2023-01-01 00:14: Train Epoch 10: 195/634 Loss: 0.147401
2023-01-01 00:14: Train Epoch 10: 199/634 Loss: 0.145478
2023-01-01 00:15: Train Epoch 10: 203/634 Loss: 0.175416
2023-01-01 00:15: Train Epoch 10: 207/634 Loss: 0.151084
2023-01-01 00:15: Train Epoch 10: 211/634 Loss: 0.165538
2023-01-01 00:15: Train Epoch 10: 215/634 Loss: 0.152019
2023-01-01 00:16: Train Epoch 10: 219/634 Loss: 0.192054
2023-01-01 00:16: Train Epoch 10: 223/634 Loss: 0.153540
2023-01-01 00:16: Train Epoch 10: 227/634 Loss: 0.149417
2023-01-01 00:17: Train Epoch 10: 231/634 Loss: 0.177477
2023-01-01 00:17: Train Epoch 10: 235/634 Loss: 0.166318
2023-01-01 00:17: Train Epoch 10: 239/634 Loss: 0.140448
2023-01-01 00:17: Train Epoch 10: 243/634 Loss: 0.171839
2023-01-01 00:18: Train Epoch 10: 247/634 Loss: 0.162015
2023-01-01 00:18: Train Epoch 10: 251/634 Loss: 0.137844
2023-01-01 00:18: Train Epoch 10: 255/634 Loss: 0.163511
2023-01-01 00:18: Train Epoch 10: 259/634 Loss: 0.134180
2023-01-01 00:19: Train Epoch 10: 263/634 Loss: 0.162309
2023-01-01 00:19: Train Epoch 10: 267/634 Loss: 0.155282
2023-01-01 00:19: Train Epoch 10: 271/634 Loss: 0.154594
2023-01-01 00:19: Train Epoch 10: 275/634 Loss: 0.157780
2023-01-01 00:20: Train Epoch 10: 279/634 Loss: 0.132701
2023-01-01 00:20: Train Epoch 10: 283/634 Loss: 0.168056
2023-01-01 00:20: Train Epoch 10: 287/634 Loss: 0.172318
2023-01-01 00:20: Train Epoch 10: 291/634 Loss: 0.145342
2023-01-01 00:21: Train Epoch 10: 295/634 Loss: 0.158472
2023-01-01 00:21: Train Epoch 10: 299/634 Loss: 0.173524
2023-01-01 00:21: Train Epoch 10: 303/634 Loss: 0.143179
2023-01-01 00:21: Train Epoch 10: 307/634 Loss: 0.169933
2023-01-01 00:22: Train Epoch 10: 311/634 Loss: 0.159941
2023-01-01 00:22: Train Epoch 10: 315/634 Loss: 0.184658
2023-01-01 00:22: Train Epoch 10: 319/634 Loss: 0.169277
2023-01-01 00:22: Train Epoch 10: 323/634 Loss: 0.191858
2023-01-01 00:23: Train Epoch 10: 327/634 Loss: 0.157404
2023-01-01 00:23: Train Epoch 10: 331/634 Loss: 0.146048
2023-01-01 00:23: Train Epoch 10: 335/634 Loss: 0.152136
2023-01-01 00:23: Train Epoch 10: 339/634 Loss: 0.152122
2023-01-01 00:24: Train Epoch 10: 343/634 Loss: 0.169124
2023-01-01 00:24: Train Epoch 10: 347/634 Loss: 0.181485
2023-01-01 00:24: Train Epoch 10: 351/634 Loss: 0.136453
2023-01-01 00:24: Train Epoch 10: 355/634 Loss: 0.127890
2023-01-01 00:25: Train Epoch 10: 359/634 Loss: 0.141116
2023-01-01 00:25: Train Epoch 10: 363/634 Loss: 0.171113
2023-01-01 00:25: Train Epoch 10: 367/634 Loss: 0.148475
2023-01-01 00:25: Train Epoch 10: 371/634 Loss: 0.123453
2023-01-01 00:26: Train Epoch 10: 375/634 Loss: 0.182454
2023-01-01 00:26: Train Epoch 10: 379/634 Loss: 0.203757
2023-01-01 00:26: Train Epoch 10: 383/634 Loss: 0.146740
2023-01-01 00:26: Train Epoch 10: 387/634 Loss: 0.163928
2023-01-01 00:27: Train Epoch 10: 391/634 Loss: 0.146857
2023-01-01 00:27: Train Epoch 10: 395/634 Loss: 0.146216
2023-01-01 00:27: Train Epoch 10: 399/634 Loss: 0.168641
2023-01-01 00:27: Train Epoch 10: 403/634 Loss: 0.138295
2023-01-01 00:28: Train Epoch 10: 407/634 Loss: 0.137390
2023-01-01 00:28: Train Epoch 10: 411/634 Loss: 0.177936
2023-01-01 00:28: Train Epoch 10: 415/634 Loss: 0.166640
2023-01-01 00:29: Train Epoch 10: 419/634 Loss: 0.156285
2023-01-01 00:29: Train Epoch 10: 423/634 Loss: 0.149615
2023-01-01 00:29: Train Epoch 10: 427/634 Loss: 0.162452
2023-01-01 00:29: Train Epoch 10: 431/634 Loss: 0.153593
2023-01-01 00:30: Train Epoch 10: 435/634 Loss: 0.131399
2023-01-01 00:30: Train Epoch 10: 439/634 Loss: 0.137959
2023-01-01 00:30: Train Epoch 10: 443/634 Loss: 0.164320
2023-01-01 00:30: Train Epoch 10: 447/634 Loss: 0.133524
2023-01-01 00:31: Train Epoch 10: 451/634 Loss: 0.133168
2023-01-01 00:31: Train Epoch 10: 455/634 Loss: 0.159047
2023-01-01 00:31: Train Epoch 10: 459/634 Loss: 0.137652
2023-01-01 00:31: Train Epoch 10: 463/634 Loss: 0.162272
2023-01-01 00:32: Train Epoch 10: 467/634 Loss: 0.147362
2023-01-01 00:32: Train Epoch 10: 471/634 Loss: 0.146827
2023-01-01 00:32: Train Epoch 10: 475/634 Loss: 0.155244
2023-01-01 00:32: Train Epoch 10: 479/634 Loss: 0.132262
2023-01-01 00:33: Train Epoch 10: 483/634 Loss: 0.155919
2023-01-01 00:33: Train Epoch 10: 487/634 Loss: 0.154908
2023-01-01 00:33: Train Epoch 10: 491/634 Loss: 0.170611
2023-01-01 00:33: Train Epoch 10: 495/634 Loss: 0.184220
2023-01-01 00:33: Train Epoch 10: 499/634 Loss: 0.147079
2023-01-01 00:34: Train Epoch 10: 503/634 Loss: 0.157502
2023-01-01 00:34: Train Epoch 10: 507/634 Loss: 0.154815
2023-01-01 00:34: Train Epoch 10: 511/634 Loss: 0.141346
2023-01-01 00:34: Train Epoch 10: 515/634 Loss: 0.158063
2023-01-01 00:35: Train Epoch 10: 519/634 Loss: 0.169041
2023-01-01 00:35: Train Epoch 10: 523/634 Loss: 0.138765
2023-01-01 00:35: Train Epoch 10: 527/634 Loss: 0.145748
2023-01-01 00:35: Train Epoch 10: 531/634 Loss: 0.142938
2023-01-01 00:36: Train Epoch 10: 535/634 Loss: 0.160404
2023-01-01 00:36: Train Epoch 10: 539/634 Loss: 0.155218
2023-01-01 00:36: Train Epoch 10: 543/634 Loss: 0.161960
2023-01-01 00:36: Train Epoch 10: 547/634 Loss: 0.200324
2023-01-01 00:37: Train Epoch 10: 551/634 Loss: 0.170950
2023-01-01 00:37: Train Epoch 10: 555/634 Loss: 0.167848
2023-01-01 00:37: Train Epoch 10: 559/634 Loss: 0.196379
2023-01-01 00:37: Train Epoch 10: 563/634 Loss: 0.150758
2023-01-01 00:38: Train Epoch 10: 567/634 Loss: 0.175950
2023-01-01 00:38: Train Epoch 10: 571/634 Loss: 0.157131
2023-01-01 00:38: Train Epoch 10: 575/634 Loss: 0.151156
2023-01-01 00:39: Train Epoch 10: 579/634 Loss: 0.160669
2023-01-01 00:39: Train Epoch 10: 583/634 Loss: 0.180819
2023-01-01 00:39: Train Epoch 10: 587/634 Loss: 0.164224
2023-01-01 00:39: Train Epoch 10: 591/634 Loss: 0.140837
2023-01-01 00:40: Train Epoch 10: 595/634 Loss: 0.163658
2023-01-01 00:40: Train Epoch 10: 599/634 Loss: 0.141533
2023-01-01 00:40: Train Epoch 10: 603/634 Loss: 0.149887
2023-01-01 00:40: Train Epoch 10: 607/634 Loss: 0.165755
2023-01-01 00:41: Train Epoch 10: 611/634 Loss: 0.161752
2023-01-01 00:41: Train Epoch 10: 615/634 Loss: 0.151346
2023-01-01 00:41: Train Epoch 10: 619/634 Loss: 0.144624
2023-01-01 00:41: Train Epoch 10: 623/634 Loss: 0.163968
2023-01-01 00:42: Train Epoch 10: 627/634 Loss: 0.165079
2023-01-01 00:42: Train Epoch 10: 631/634 Loss: 0.199212
2023-01-01 00:42: Train Epoch 10: 633/634 Loss: 0.064281
2023-01-01 00:42: **********Train Epoch 10: averaged Loss: 0.155954 
2023-01-01 00:42: 
Epoch time elapsed: 2434.9492461681366

2023-01-01 00:43: 
 metrics validation: {'precision': 0.8864097363083164, 'recall': 0.6723076923076923, 'f1-score': 0.7646544181977253, 'support': 1300, 'AUC': 0.9362360946745563, 'AUCPR': 0.8841066705136761, 'TP': 874, 'FP': 112, 'TN': 2488, 'FN': 426} 

2023-01-01 00:43: **********Val Epoch 10: average Loss: 0.157856
2023-01-01 00:45: 
 Testing metrics {'precision': 0.8269230769230769, 'recall': 0.7353420195439739, 'f1-score': 0.778448275862069, 'support': 1228, 'AUC': 0.9259564425086739, 'AUCPR': 0.8821838707655952, 'TP': 903, 'FP': 189, 'TN': 2267, 'FN': 325} 

2023-01-01 00:49: 
 Testing metrics {'precision': 0.8794449262792715, 'recall': 0.9203539823008849, 'f1-score': 0.8994345271094356, 'support': 4407, 'AUC': 0.9798750610723115, 'AUCPR': 0.9619710816950665, 'TP': 4056, 'FP': 556, 'TN': 8258, 'FN': 351} 

2023-01-01 00:49: Train Epoch 11: 3/634 Loss: 0.176015
2023-01-01 00:49: Train Epoch 11: 7/634 Loss: 0.155117
2023-01-01 00:50: Train Epoch 11: 11/634 Loss: 0.161163
2023-01-01 00:50: Train Epoch 11: 15/634 Loss: 0.146630
2023-01-01 00:50: Train Epoch 11: 19/634 Loss: 0.150103
2023-01-01 00:50: Train Epoch 11: 23/634 Loss: 0.116833
2023-01-01 00:51: Train Epoch 11: 27/634 Loss: 0.158930
2023-01-01 00:51: Train Epoch 11: 31/634 Loss: 0.157597
2023-01-01 00:51: Train Epoch 11: 35/634 Loss: 0.156695
2023-01-01 00:51: Train Epoch 11: 39/634 Loss: 0.151427
2023-01-01 00:52: Train Epoch 11: 43/634 Loss: 0.151406
2023-01-01 00:52: Train Epoch 11: 47/634 Loss: 0.157411
2023-01-01 00:52: Train Epoch 11: 51/634 Loss: 0.196891
2023-01-01 00:52: Train Epoch 11: 55/634 Loss: 0.145736
2023-01-01 00:53: Train Epoch 11: 59/634 Loss: 0.149443
2023-01-01 00:53: Train Epoch 11: 63/634 Loss: 0.163713
2023-01-01 00:53: Train Epoch 11: 67/634 Loss: 0.134466
2023-01-01 00:53: Train Epoch 11: 71/634 Loss: 0.153681
2023-01-01 00:54: Train Epoch 11: 75/634 Loss: 0.166619
2023-01-01 00:54: Train Epoch 11: 79/634 Loss: 0.160883
2023-01-01 00:54: Train Epoch 11: 83/634 Loss: 0.140743
2023-01-01 00:54: Train Epoch 11: 87/634 Loss: 0.151198
2023-01-01 00:55: Train Epoch 11: 91/634 Loss: 0.174908
2023-01-01 00:55: Train Epoch 11: 95/634 Loss: 0.154185
2023-01-01 00:55: Train Epoch 11: 99/634 Loss: 0.162554
2023-01-01 00:55: Train Epoch 11: 103/634 Loss: 0.155854
2023-01-01 00:56: Train Epoch 11: 107/634 Loss: 0.175567
2023-01-01 00:56: Train Epoch 11: 111/634 Loss: 0.166616
2023-01-01 00:56: Train Epoch 11: 115/634 Loss: 0.163161
2023-01-01 00:56: Train Epoch 11: 119/634 Loss: 0.158023
2023-01-01 00:57: Train Epoch 11: 123/634 Loss: 0.159315
2023-01-01 00:57: Train Epoch 11: 127/634 Loss: 0.148954
2023-01-01 00:57: Train Epoch 11: 131/634 Loss: 0.156723
2023-01-01 00:57: Train Epoch 11: 135/634 Loss: 0.158054
2023-01-01 00:58: Train Epoch 11: 139/634 Loss: 0.167102
2023-01-01 00:58: Train Epoch 11: 143/634 Loss: 0.140530
2023-01-01 00:58: Train Epoch 11: 147/634 Loss: 0.141353
2023-01-01 00:58: Train Epoch 11: 151/634 Loss: 0.168167
2023-01-01 00:59: Train Epoch 11: 155/634 Loss: 0.145067
2023-01-01 00:59: Train Epoch 11: 159/634 Loss: 0.142954
2023-01-01 00:59: Train Epoch 11: 163/634 Loss: 0.146130
2023-01-01 00:59: Train Epoch 11: 167/634 Loss: 0.168095
2023-01-01 01:00: Train Epoch 11: 171/634 Loss: 0.178084
2023-01-01 01:00: Train Epoch 11: 175/634 Loss: 0.161511
2023-01-01 01:00: Train Epoch 11: 179/634 Loss: 0.159436
2023-01-01 01:00: Train Epoch 11: 183/634 Loss: 0.126601
2023-01-01 01:01: Train Epoch 11: 187/634 Loss: 0.162350
2023-01-01 01:01: Train Epoch 11: 191/634 Loss: 0.132637
2023-01-01 01:01: Train Epoch 11: 195/634 Loss: 0.154990
2023-01-01 01:01: Train Epoch 11: 199/634 Loss: 0.149763
2023-01-01 01:02: Train Epoch 11: 203/634 Loss: 0.137401
2023-01-01 01:02: Train Epoch 11: 207/634 Loss: 0.149963
2023-01-01 01:02: Train Epoch 11: 211/634 Loss: 0.142364
2023-01-01 01:02: Train Epoch 11: 215/634 Loss: 0.135141
2023-01-01 01:03: Train Epoch 11: 219/634 Loss: 0.153951
2023-01-01 01:03: Train Epoch 11: 223/634 Loss: 0.163854
2023-01-01 01:03: Train Epoch 11: 227/634 Loss: 0.143833
2023-01-01 01:03: Train Epoch 11: 231/634 Loss: 0.153438
2023-01-01 01:04: Train Epoch 11: 235/634 Loss: 0.149515
2023-01-01 01:04: Train Epoch 11: 239/634 Loss: 0.188277
2023-01-01 01:04: Train Epoch 11: 243/634 Loss: 0.160184
2023-01-01 01:04: Train Epoch 11: 247/634 Loss: 0.149446
2023-01-01 01:05: Train Epoch 11: 251/634 Loss: 0.170219
2023-01-01 01:05: Train Epoch 11: 255/634 Loss: 0.139407
2023-01-01 01:05: Train Epoch 11: 259/634 Loss: 0.153171
2023-01-01 01:05: Train Epoch 11: 263/634 Loss: 0.170608
2023-01-01 01:06: Train Epoch 11: 267/634 Loss: 0.145814
2023-01-01 01:06: Train Epoch 11: 271/634 Loss: 0.178693
2023-01-01 01:06: Train Epoch 11: 275/634 Loss: 0.163129
2023-01-01 01:07: Train Epoch 11: 279/634 Loss: 0.147319
2023-01-01 01:07: Train Epoch 11: 283/634 Loss: 0.155505
2023-01-01 01:07: Train Epoch 11: 287/634 Loss: 0.158302
2023-01-01 01:07: Train Epoch 11: 291/634 Loss: 0.166459
2023-01-01 01:08: Train Epoch 11: 295/634 Loss: 0.142887
2023-01-01 01:08: Train Epoch 11: 299/634 Loss: 0.157483
2023-01-01 01:08: Train Epoch 11: 303/634 Loss: 0.128832
2023-01-01 01:08: Train Epoch 11: 307/634 Loss: 0.161332
2023-01-01 01:09: Train Epoch 11: 311/634 Loss: 0.157485
2023-01-01 01:09: Train Epoch 11: 315/634 Loss: 0.149086
2023-01-01 01:09: Train Epoch 11: 319/634 Loss: 0.148357
2023-01-01 01:09: Train Epoch 11: 323/634 Loss: 0.163078
2023-01-01 01:10: Train Epoch 11: 327/634 Loss: 0.139612
2023-01-01 01:10: Train Epoch 11: 331/634 Loss: 0.192732
2023-01-01 01:10: Train Epoch 11: 335/634 Loss: 0.144901
2023-01-01 01:10: Train Epoch 11: 339/634 Loss: 0.169228
2023-01-01 01:11: Train Epoch 11: 343/634 Loss: 0.128539
2023-01-01 01:11: Train Epoch 11: 347/634 Loss: 0.163582
2023-01-01 01:11: Train Epoch 11: 351/634 Loss: 0.151370
2023-01-01 01:11: Train Epoch 11: 355/634 Loss: 0.178277
2023-01-01 01:12: Train Epoch 11: 359/634 Loss: 0.164187
2023-01-01 01:12: Train Epoch 11: 363/634 Loss: 0.159679
2023-01-01 01:12: Train Epoch 11: 367/634 Loss: 0.141156
2023-01-01 01:12: Train Epoch 11: 371/634 Loss: 0.142513
2023-01-01 01:13: Train Epoch 11: 375/634 Loss: 0.188221
2023-01-01 01:13: Train Epoch 11: 379/634 Loss: 0.194210
2023-01-01 01:13: Train Epoch 11: 383/634 Loss: 0.138968
2023-01-01 01:13: Train Epoch 11: 387/634 Loss: 0.179005
2023-01-01 01:14: Train Epoch 11: 391/634 Loss: 0.186054
2023-01-01 01:14: Train Epoch 11: 395/634 Loss: 0.163382
2023-01-01 01:14: Train Epoch 11: 399/634 Loss: 0.214013
2023-01-01 01:15: Train Epoch 11: 403/634 Loss: 0.150752
2023-01-01 01:15: Train Epoch 11: 407/634 Loss: 0.138748
2023-01-01 01:15: Train Epoch 11: 411/634 Loss: 0.149894
2023-01-01 01:15: Train Epoch 11: 415/634 Loss: 0.142907
2023-01-01 01:16: Train Epoch 11: 419/634 Loss: 0.158089
2023-01-01 01:16: Train Epoch 11: 423/634 Loss: 0.183617
2023-01-01 01:16: Train Epoch 11: 427/634 Loss: 0.145127
2023-01-01 01:16: Train Epoch 11: 431/634 Loss: 0.170022
2023-01-01 01:17: Train Epoch 11: 435/634 Loss: 0.150084
2023-01-01 01:17: Train Epoch 11: 439/634 Loss: 0.158001
2023-01-01 01:17: Train Epoch 11: 443/634 Loss: 0.168536
2023-01-01 01:17: Train Epoch 11: 447/634 Loss: 0.139419
2023-01-01 01:18: Train Epoch 11: 451/634 Loss: 0.151211
2023-01-01 01:18: Train Epoch 11: 455/634 Loss: 0.152930
2023-01-01 01:18: Train Epoch 11: 459/634 Loss: 0.157010
2023-01-01 01:18: Train Epoch 11: 463/634 Loss: 0.163292
2023-01-01 01:19: Train Epoch 11: 467/634 Loss: 0.170023
2023-01-01 01:19: Train Epoch 11: 471/634 Loss: 0.137510
2023-01-01 01:19: Train Epoch 11: 475/634 Loss: 0.160423
2023-01-01 01:19: Train Epoch 11: 479/634 Loss: 0.152815
2023-01-01 01:20: Train Epoch 11: 483/634 Loss: 0.143028
2023-01-01 01:20: Train Epoch 11: 487/634 Loss: 0.158355
2023-01-01 01:20: Train Epoch 11: 491/634 Loss: 0.135085
2023-01-01 01:21: Train Epoch 11: 495/634 Loss: 0.155715
2023-01-01 01:21: Train Epoch 11: 499/634 Loss: 0.157596
2023-01-01 01:21: Train Epoch 11: 503/634 Loss: 0.150645
2023-01-01 01:21: Train Epoch 11: 507/634 Loss: 0.161784
2023-01-01 01:22: Train Epoch 11: 511/634 Loss: 0.147713
2023-01-01 01:22: Train Epoch 11: 515/634 Loss: 0.151311
2023-01-01 01:22: Train Epoch 11: 519/634 Loss: 0.181571
2023-01-01 01:22: Train Epoch 11: 523/634 Loss: 0.161430
2023-01-01 01:23: Train Epoch 11: 527/634 Loss: 0.141022
2023-01-01 01:23: Train Epoch 11: 531/634 Loss: 0.142575
2023-01-01 01:23: Train Epoch 11: 535/634 Loss: 0.141954
2023-01-01 01:23: Train Epoch 11: 539/634 Loss: 0.163497
2023-01-01 01:24: Train Epoch 11: 543/634 Loss: 0.126997
2023-01-01 01:24: Train Epoch 11: 547/634 Loss: 0.156948
2023-01-01 01:24: Train Epoch 11: 551/634 Loss: 0.160477
2023-01-01 01:24: Train Epoch 11: 555/634 Loss: 0.145045
2023-01-01 01:25: Train Epoch 11: 559/634 Loss: 0.160400
2023-01-01 01:25: Train Epoch 11: 563/634 Loss: 0.142856
2023-01-01 01:25: Train Epoch 11: 567/634 Loss: 0.149880
2023-01-01 01:25: Train Epoch 11: 571/634 Loss: 0.132346
2023-01-01 01:26: Train Epoch 11: 575/634 Loss: 0.155370
2023-01-01 01:26: Train Epoch 11: 579/634 Loss: 0.172953
2023-01-01 01:26: Train Epoch 11: 583/634 Loss: 0.155391
2023-01-01 01:26: Train Epoch 11: 587/634 Loss: 0.179824
2023-01-01 01:27: Train Epoch 11: 591/634 Loss: 0.148656
2023-01-01 01:27: Train Epoch 11: 595/634 Loss: 0.126672
2023-01-01 01:27: Train Epoch 11: 599/634 Loss: 0.128513
2023-01-01 01:27: Train Epoch 11: 603/634 Loss: 0.162069
2023-01-01 01:28: Train Epoch 11: 607/634 Loss: 0.165446
2023-01-01 01:28: Train Epoch 11: 611/634 Loss: 0.160816
2023-01-01 01:28: Train Epoch 11: 615/634 Loss: 0.157833
2023-01-01 01:28: Train Epoch 11: 619/634 Loss: 0.161216
2023-01-01 01:29: Train Epoch 11: 623/634 Loss: 0.153955
2023-01-01 01:29: Train Epoch 11: 627/634 Loss: 0.141913
2023-01-01 01:29: Train Epoch 11: 631/634 Loss: 0.172512
2023-01-01 01:29: Train Epoch 11: 633/634 Loss: 0.070779
2023-01-01 01:29: **********Train Epoch 11: averaged Loss: 0.155271 
2023-01-01 01:29: 
Epoch time elapsed: 2436.7558073997498

2023-01-01 01:31: 
 metrics validation: {'precision': 0.9206730769230769, 'recall': 0.5892307692307692, 'f1-score': 0.7185741088180113, 'support': 1300, 'AUC': 0.9506168639053254, 'AUCPR': 0.9008190282610435, 'TP': 766, 'FP': 66, 'TN': 2534, 'FN': 534} 

2023-01-01 01:31: **********Val Epoch 11: average Loss: 0.160027
2023-01-01 01:32: 
 Testing metrics {'precision': 0.8269230769230769, 'recall': 0.7353420195439739, 'f1-score': 0.778448275862069, 'support': 1228, 'AUC': 0.9259564425086739, 'AUCPR': 0.8821838707655952, 'TP': 903, 'FP': 189, 'TN': 2267, 'FN': 325} 

2023-01-01 01:36: 
 Testing metrics {'precision': 0.8794449262792715, 'recall': 0.9203539823008849, 'f1-score': 0.8994345271094356, 'support': 4407, 'AUC': 0.9798750610723115, 'AUCPR': 0.9619710816950665, 'TP': 4056, 'FP': 556, 'TN': 8258, 'FN': 351} 

2023-01-01 01:36: Train Epoch 12: 3/634 Loss: 0.148667
2023-01-01 01:37: Train Epoch 12: 7/634 Loss: 0.156241
2023-01-01 01:37: Train Epoch 12: 11/634 Loss: 0.172555
2023-01-01 01:37: Train Epoch 12: 15/634 Loss: 0.147477
2023-01-01 01:37: Train Epoch 12: 19/634 Loss: 0.165782
2023-01-01 01:38: Train Epoch 12: 23/634 Loss: 0.170168
2023-01-01 01:38: Train Epoch 12: 27/634 Loss: 0.191447
2023-01-01 01:38: Train Epoch 12: 31/634 Loss: 0.148507
2023-01-01 01:39: Train Epoch 12: 35/634 Loss: 0.173612
2023-01-01 01:39: Train Epoch 12: 39/634 Loss: 0.161113
2023-01-01 01:39: Train Epoch 12: 43/634 Loss: 0.166326
2023-01-01 01:39: Train Epoch 12: 47/634 Loss: 0.154494
2023-01-01 01:40: Train Epoch 12: 51/634 Loss: 0.186294
2023-01-01 01:40: Train Epoch 12: 55/634 Loss: 0.171594
2023-01-01 01:40: Train Epoch 12: 59/634 Loss: 0.152464
2023-01-01 01:40: Train Epoch 12: 63/634 Loss: 0.121373
2023-01-01 01:41: Train Epoch 12: 67/634 Loss: 0.154679
2023-01-01 01:41: Train Epoch 12: 71/634 Loss: 0.143442
2023-01-01 01:41: Train Epoch 12: 75/634 Loss: 0.163021
2023-01-01 01:41: Train Epoch 12: 79/634 Loss: 0.164816
2023-01-01 01:42: Train Epoch 12: 83/634 Loss: 0.168014
2023-01-01 01:42: Train Epoch 12: 87/634 Loss: 0.158563
2023-01-01 01:42: Train Epoch 12: 91/634 Loss: 0.153203
2023-01-01 01:42: Train Epoch 12: 95/634 Loss: 0.183507
2023-01-01 01:43: Train Epoch 12: 99/634 Loss: 0.160333
2023-01-01 01:43: Train Epoch 12: 103/634 Loss: 0.129896
2023-01-01 01:43: Train Epoch 12: 107/634 Loss: 0.156869
2023-01-01 01:44: Train Epoch 12: 111/634 Loss: 0.163009
2023-01-01 01:44: Train Epoch 12: 115/634 Loss: 0.152525
2023-01-01 01:44: Train Epoch 12: 119/634 Loss: 0.129297
2023-01-01 01:44: Train Epoch 12: 123/634 Loss: 0.156822
2023-01-01 01:45: Train Epoch 12: 127/634 Loss: 0.120392
2023-01-01 01:45: Train Epoch 12: 131/634 Loss: 0.148590
2023-01-01 01:45: Train Epoch 12: 135/634 Loss: 0.149314
2023-01-01 01:45: Train Epoch 12: 139/634 Loss: 0.160172
2023-01-01 01:46: Train Epoch 12: 143/634 Loss: 0.139957
2023-01-01 01:46: Train Epoch 12: 147/634 Loss: 0.166456
2023-01-01 01:46: Train Epoch 12: 151/634 Loss: 0.153093
2023-01-01 01:46: Train Epoch 12: 155/634 Loss: 0.148883
2023-01-01 01:47: Train Epoch 12: 159/634 Loss: 0.150975
2023-01-01 01:47: Train Epoch 12: 163/634 Loss: 0.152638
2023-01-01 01:47: Train Epoch 12: 167/634 Loss: 0.173674
2023-01-01 01:47: Train Epoch 12: 171/634 Loss: 0.140090
2023-01-01 01:48: Train Epoch 12: 175/634 Loss: 0.151099
2023-01-01 01:48: Train Epoch 12: 179/634 Loss: 0.153341
2023-01-01 01:48: Train Epoch 12: 183/634 Loss: 0.145788
2023-01-01 01:49: Train Epoch 12: 187/634 Loss: 0.136935
2023-01-01 01:49: Train Epoch 12: 191/634 Loss: 0.150600
2023-01-01 01:49: Train Epoch 12: 195/634 Loss: 0.135453
2023-01-01 01:49: Train Epoch 12: 199/634 Loss: 0.133184
2023-01-01 01:50: Train Epoch 12: 203/634 Loss: 0.151654
2023-01-01 01:50: Train Epoch 12: 207/634 Loss: 0.124542
2023-01-01 01:50: Train Epoch 12: 211/634 Loss: 0.140333
2023-01-01 01:50: Train Epoch 12: 215/634 Loss: 0.153006
2023-01-01 01:51: Train Epoch 12: 219/634 Loss: 0.170118
2023-01-01 01:51: Train Epoch 12: 223/634 Loss: 0.131736
2023-01-01 01:51: Train Epoch 12: 227/634 Loss: 0.161986
2023-01-01 01:51: Train Epoch 12: 231/634 Loss: 0.156664
2023-01-01 01:52: Train Epoch 12: 235/634 Loss: 0.144697
2023-01-01 01:52: Train Epoch 12: 239/634 Loss: 0.151120
2023-01-01 01:52: Train Epoch 12: 243/634 Loss: 0.147651
2023-01-01 01:52: Train Epoch 12: 247/634 Loss: 0.139746
2023-01-01 01:53: Train Epoch 12: 251/634 Loss: 0.155738
2023-01-01 01:53: Train Epoch 12: 255/634 Loss: 0.140317
2023-01-01 01:53: Train Epoch 12: 259/634 Loss: 0.169376
2023-01-01 01:54: Train Epoch 12: 263/634 Loss: 0.153047
2023-01-01 01:54: Train Epoch 12: 267/634 Loss: 0.174236
2023-01-01 01:54: Train Epoch 12: 271/634 Loss: 0.160232
2023-01-01 01:54: Train Epoch 12: 275/634 Loss: 0.147445
2023-01-01 01:55: Train Epoch 12: 279/634 Loss: 0.166734
2023-01-01 01:55: Train Epoch 12: 283/634 Loss: 0.164908
2023-01-01 01:55: Train Epoch 12: 287/634 Loss: 0.180033
2023-01-01 01:55: Train Epoch 12: 291/634 Loss: 0.151096
2023-01-01 01:56: Train Epoch 12: 295/634 Loss: 0.171783
2023-01-01 01:56: Train Epoch 12: 299/634 Loss: 0.165884
2023-01-01 01:56: Train Epoch 12: 303/634 Loss: 0.151318
2023-01-01 01:56: Train Epoch 12: 307/634 Loss: 0.157629
2023-01-01 01:57: Train Epoch 12: 311/634 Loss: 0.215751
2023-01-01 01:57: Train Epoch 12: 315/634 Loss: 0.154251
2023-01-01 01:57: Train Epoch 12: 319/634 Loss: 0.155645
2023-01-01 01:57: Train Epoch 12: 323/634 Loss: 0.189311
2023-01-01 01:58: Train Epoch 12: 327/634 Loss: 0.176246
2023-01-01 01:58: Train Epoch 12: 331/634 Loss: 0.165827
2023-01-01 01:58: Train Epoch 12: 335/634 Loss: 0.219875
2023-01-01 01:59: Train Epoch 12: 339/634 Loss: 0.147987
2023-01-01 01:59: Train Epoch 12: 343/634 Loss: 0.153357
2023-01-01 01:59: Train Epoch 12: 347/634 Loss: 0.161345
2023-01-01 01:59: Train Epoch 12: 351/634 Loss: 0.181024
2023-01-01 02:00: Train Epoch 12: 355/634 Loss: 0.163339
2023-01-01 02:00: Train Epoch 12: 359/634 Loss: 0.236138
2023-01-01 02:00: Train Epoch 12: 363/634 Loss: 0.209279
2023-01-01 02:00: Train Epoch 12: 367/634 Loss: 0.132935
2023-01-01 02:01: Train Epoch 12: 371/634 Loss: 0.158497
2023-01-01 02:01: Train Epoch 12: 375/634 Loss: 0.186684
2023-01-01 02:01: Train Epoch 12: 379/634 Loss: 0.159554
2023-01-01 02:01: Train Epoch 12: 383/634 Loss: 0.172238
2023-01-01 02:02: Train Epoch 12: 387/634 Loss: 0.138361
2023-01-01 02:02: Train Epoch 12: 391/634 Loss: 0.159756
2023-01-01 02:02: Train Epoch 12: 395/634 Loss: 0.146318
2023-01-01 02:02: Train Epoch 12: 399/634 Loss: 0.138556
2023-01-01 02:03: Train Epoch 12: 403/634 Loss: 0.130837
2023-01-01 02:03: Train Epoch 12: 407/634 Loss: 0.157317
2023-01-01 02:03: Train Epoch 12: 411/634 Loss: 0.137803
2023-01-01 02:03: Train Epoch 12: 415/634 Loss: 0.158954
2023-01-01 02:04: Train Epoch 12: 419/634 Loss: 0.168030
2023-01-01 02:04: Train Epoch 12: 423/634 Loss: 0.147329
2023-01-01 02:04: Train Epoch 12: 427/634 Loss: 0.126412
2023-01-01 02:04: Train Epoch 12: 431/634 Loss: 0.154265
2023-01-01 02:05: Train Epoch 12: 435/634 Loss: 0.181658
2023-01-01 02:05: Train Epoch 12: 439/634 Loss: 0.147838
2023-01-01 02:05: Train Epoch 12: 443/634 Loss: 0.135226
2023-01-01 02:05: Train Epoch 12: 447/634 Loss: 0.151252
2023-01-01 02:06: Train Epoch 12: 451/634 Loss: 0.139600
2023-01-01 02:06: Train Epoch 12: 455/634 Loss: 0.130420
2023-01-01 02:06: Train Epoch 12: 459/634 Loss: 0.149613
2023-01-01 02:06: Train Epoch 12: 463/634 Loss: 0.156930
2023-01-01 02:07: Train Epoch 12: 467/634 Loss: 0.150119
2023-01-01 02:07: Train Epoch 12: 471/634 Loss: 0.146975
2023-01-01 02:07: Train Epoch 12: 475/634 Loss: 0.140463
2023-01-01 02:07: Train Epoch 12: 479/634 Loss: 0.193854
2023-01-01 02:08: Train Epoch 12: 483/634 Loss: 0.173822
2023-01-01 02:08: Train Epoch 12: 487/634 Loss: 0.146320
2023-01-01 02:08: Train Epoch 12: 491/634 Loss: 0.148497
2023-01-01 02:08: Train Epoch 12: 495/634 Loss: 0.166610
2023-01-01 02:09: Train Epoch 12: 499/634 Loss: 0.144003
2023-01-01 02:09: Train Epoch 12: 503/634 Loss: 0.136499
2023-01-01 02:09: Train Epoch 12: 507/634 Loss: 0.138728
2023-01-01 02:10: Train Epoch 12: 511/634 Loss: 0.162276
2023-01-01 02:10: Train Epoch 12: 515/634 Loss: 0.145773
2023-01-01 02:10: Train Epoch 12: 519/634 Loss: 0.153519
2023-01-01 02:10: Train Epoch 12: 523/634 Loss: 0.166586
2023-01-01 02:11: Train Epoch 12: 527/634 Loss: 0.171680
2023-01-01 02:11: Train Epoch 12: 531/634 Loss: 0.172558
2023-01-01 02:11: Train Epoch 12: 535/634 Loss: 0.168353
2023-01-01 02:11: Train Epoch 12: 539/634 Loss: 0.148692
2023-01-01 02:12: Train Epoch 12: 543/634 Loss: 0.148024
2023-01-01 02:12: Train Epoch 12: 547/634 Loss: 0.170302
2023-01-01 02:12: Train Epoch 12: 551/634 Loss: 0.152505
2023-01-01 02:12: Train Epoch 12: 555/634 Loss: 0.197611
2023-01-01 02:13: Train Epoch 12: 559/634 Loss: 0.155770
2023-01-01 02:13: Train Epoch 12: 563/634 Loss: 0.143068
2023-01-01 02:13: Train Epoch 12: 567/634 Loss: 0.164852
2023-01-01 02:13: Train Epoch 12: 571/634 Loss: 0.142993
2023-01-01 02:14: Train Epoch 12: 575/634 Loss: 0.153568
2023-01-01 02:14: Train Epoch 12: 579/634 Loss: 0.165248
2023-01-01 02:14: Train Epoch 12: 583/634 Loss: 0.145028
2023-01-01 02:14: Train Epoch 12: 587/634 Loss: 0.181962
2023-01-01 02:15: Train Epoch 12: 591/634 Loss: 0.137259
2023-01-01 02:15: Train Epoch 12: 595/634 Loss: 0.150493
2023-01-01 02:15: Train Epoch 12: 599/634 Loss: 0.145187
2023-01-01 02:15: Train Epoch 12: 603/634 Loss: 0.147109
2023-01-01 02:16: Train Epoch 12: 607/634 Loss: 0.163443
2023-01-01 02:16: Train Epoch 12: 611/634 Loss: 0.150733
2023-01-01 02:16: Train Epoch 12: 615/634 Loss: 0.148625
2023-01-01 02:16: Train Epoch 12: 619/634 Loss: 0.156546
2023-01-01 02:17: Train Epoch 12: 623/634 Loss: 0.161516
2023-01-01 02:17: Train Epoch 12: 627/634 Loss: 0.143173
2023-01-01 02:17: Train Epoch 12: 631/634 Loss: 0.137164
2023-01-01 02:17: Train Epoch 12: 633/634 Loss: 0.077379
2023-01-01 02:17: **********Train Epoch 12: averaged Loss: 0.156166 
2023-01-01 02:17: 
Epoch time elapsed: 2473.981600046158

2023-01-01 02:19: 
 metrics validation: {'precision': 0.7648686030428768, 'recall': 0.8507692307692307, 'f1-score': 0.805535324107793, 'support': 1300, 'AUC': 0.9305133136094675, 'AUCPR': 0.8707977425727784, 'TP': 1106, 'FP': 340, 'TN': 2260, 'FN': 194} 

2023-01-01 02:19: **********Val Epoch 12: average Loss: 0.153854
2023-01-01 02:20: 
 Testing metrics {'precision': 0.8269230769230769, 'recall': 0.7353420195439739, 'f1-score': 0.778448275862069, 'support': 1228, 'AUC': 0.9259564425086739, 'AUCPR': 0.8821838707655952, 'TP': 903, 'FP': 189, 'TN': 2267, 'FN': 325} 

2023-01-01 02:24: 
 Testing metrics {'precision': 0.8794449262792715, 'recall': 0.9203539823008849, 'f1-score': 0.8994345271094356, 'support': 4407, 'AUC': 0.9798750610723115, 'AUCPR': 0.9619710816950665, 'TP': 4056, 'FP': 556, 'TN': 8258, 'FN': 351} 

2023-01-01 02:24: Train Epoch 13: 3/634 Loss: 0.138286
2023-01-01 02:24: Train Epoch 13: 7/634 Loss: 0.158375
2023-01-01 02:25: Train Epoch 13: 11/634 Loss: 0.151419
2023-01-01 02:25: Train Epoch 13: 15/634 Loss: 0.179588
2023-01-01 02:25: Train Epoch 13: 19/634 Loss: 0.151028
2023-01-01 02:26: Train Epoch 13: 23/634 Loss: 0.140428
2023-01-01 02:26: Train Epoch 13: 27/634 Loss: 0.173983
2023-01-01 02:26: Train Epoch 13: 31/634 Loss: 0.148381
2023-01-01 02:26: Train Epoch 13: 35/634 Loss: 0.158336
2023-01-01 02:27: Train Epoch 13: 39/634 Loss: 0.153508
2023-01-01 02:27: Train Epoch 13: 43/634 Loss: 0.145455
2023-01-01 02:27: Train Epoch 13: 47/634 Loss: 0.163929
2023-01-01 02:27: Train Epoch 13: 51/634 Loss: 0.142252
2023-01-01 02:28: Train Epoch 13: 55/634 Loss: 0.150873
2023-01-01 02:28: Train Epoch 13: 59/634 Loss: 0.160957
2023-01-01 02:28: Train Epoch 13: 63/634 Loss: 0.165262
2023-01-01 02:28: Train Epoch 13: 67/634 Loss: 0.149521
2023-01-01 02:29: Train Epoch 13: 71/634 Loss: 0.167073
2023-01-01 02:29: Train Epoch 13: 75/634 Loss: 0.145959
2023-01-01 02:29: Train Epoch 13: 79/634 Loss: 0.176589
2023-01-01 02:29: Train Epoch 13: 83/634 Loss: 0.145641
2023-01-01 02:30: Train Epoch 13: 87/634 Loss: 0.130404
2023-01-01 02:30: Train Epoch 13: 91/634 Loss: 0.149547
2023-01-01 02:30: Train Epoch 13: 95/634 Loss: 0.158111
2023-01-01 02:30: Train Epoch 13: 99/634 Loss: 0.155095
2023-01-01 02:31: Train Epoch 13: 103/634 Loss: 0.154609
2023-01-01 02:31: Train Epoch 13: 107/634 Loss: 0.164547
2023-01-01 02:31: Train Epoch 13: 111/634 Loss: 0.163295
2023-01-01 02:31: Train Epoch 13: 115/634 Loss: 0.127666
2023-01-01 02:32: Train Epoch 13: 119/634 Loss: 0.170941
2023-01-01 02:32: Train Epoch 13: 123/634 Loss: 0.157866
2023-01-01 02:32: Train Epoch 13: 127/634 Loss: 0.136047
2023-01-01 02:32: Train Epoch 13: 131/634 Loss: 0.175300
2023-01-01 02:33: Train Epoch 13: 135/634 Loss: 0.157554
2023-01-01 02:33: Train Epoch 13: 139/634 Loss: 0.154545
2023-01-01 02:33: Train Epoch 13: 143/634 Loss: 0.152471
2023-01-01 02:33: Train Epoch 13: 147/634 Loss: 0.114857
2023-01-01 02:34: Train Epoch 13: 151/634 Loss: 0.143129
2023-01-01 02:34: Train Epoch 13: 155/634 Loss: 0.164397
2023-01-01 02:34: Train Epoch 13: 159/634 Loss: 0.175222
2023-01-01 02:34: Train Epoch 13: 163/634 Loss: 0.158572
2023-01-01 02:35: Train Epoch 13: 167/634 Loss: 0.135910
2023-01-01 02:35: Train Epoch 13: 171/634 Loss: 0.141652
2023-01-01 02:35: Train Epoch 13: 175/634 Loss: 0.131145
2023-01-01 02:35: Train Epoch 13: 179/634 Loss: 0.195531
2023-01-01 02:36: Train Epoch 13: 183/634 Loss: 0.160541
2023-01-01 02:36: Train Epoch 13: 187/634 Loss: 0.154887
2023-01-01 02:36: Train Epoch 13: 191/634 Loss: 0.159328
2023-01-01 02:36: Train Epoch 13: 195/634 Loss: 0.131443
2023-01-01 02:37: Train Epoch 13: 199/634 Loss: 0.155450
2023-01-01 02:37: Train Epoch 13: 203/634 Loss: 0.157068
2023-01-01 02:37: Train Epoch 13: 207/634 Loss: 0.173303
2023-01-01 02:37: Train Epoch 13: 211/634 Loss: 0.146306
2023-01-01 02:38: Train Epoch 13: 215/634 Loss: 0.144515
2023-01-01 02:38: Train Epoch 13: 219/634 Loss: 0.145308
2023-01-01 02:38: Train Epoch 13: 223/634 Loss: 0.132661
2023-01-01 02:38: Train Epoch 13: 227/634 Loss: 0.163011
2023-01-01 02:39: Train Epoch 13: 231/634 Loss: 0.134819
2023-01-01 02:39: Train Epoch 13: 235/634 Loss: 0.177345
2023-01-01 02:39: Train Epoch 13: 239/634 Loss: 0.159600
2023-01-01 02:40: Train Epoch 13: 243/634 Loss: 0.164699
2023-01-01 02:40: Train Epoch 13: 247/634 Loss: 0.136096
2023-01-01 02:40: Train Epoch 13: 251/634 Loss: 0.160306
2023-01-01 02:40: Train Epoch 13: 255/634 Loss: 0.174301
2023-01-01 02:41: Train Epoch 13: 259/634 Loss: 0.119325
2023-01-01 02:41: Train Epoch 13: 263/634 Loss: 0.130259
2023-01-01 02:41: Train Epoch 13: 267/634 Loss: 0.164224
2023-01-01 02:41: Train Epoch 13: 271/634 Loss: 0.139986
2023-01-01 02:41: Train Epoch 13: 275/634 Loss: 0.148517
2023-01-01 02:42: Train Epoch 13: 279/634 Loss: 0.130536
2023-01-01 02:42: Train Epoch 13: 283/634 Loss: 0.167626
2023-01-01 02:42: Train Epoch 13: 287/634 Loss: 0.165702
2023-01-01 02:43: Train Epoch 13: 291/634 Loss: 0.123790
2023-01-01 02:43: Train Epoch 13: 295/634 Loss: 0.158601
2023-01-01 02:43: Train Epoch 13: 299/634 Loss: 0.148648
2023-01-01 02:43: Train Epoch 13: 303/634 Loss: 0.173670
2023-01-01 02:43: Train Epoch 13: 307/634 Loss: 0.171325
2023-01-01 02:44: Train Epoch 13: 311/634 Loss: 0.159064
2023-01-01 02:44: Train Epoch 13: 315/634 Loss: 0.161100
2023-01-01 02:44: Train Epoch 13: 319/634 Loss: 0.162273
2023-01-01 02:44: Train Epoch 13: 323/634 Loss: 0.150303
2023-01-01 02:45: Train Epoch 13: 327/634 Loss: 0.152734
2023-01-01 02:45: Train Epoch 13: 331/634 Loss: 0.147794
2023-01-01 02:45: Train Epoch 13: 335/634 Loss: 0.150277
2023-01-01 02:45: Train Epoch 13: 339/634 Loss: 0.145835
2023-01-01 02:46: Train Epoch 13: 343/634 Loss: 0.144006
2023-01-01 02:46: Train Epoch 13: 347/634 Loss: 0.167984
2023-01-01 02:46: Train Epoch 13: 351/634 Loss: 0.129222
2023-01-01 02:47: Train Epoch 13: 355/634 Loss: 0.129804
2023-01-01 02:47: Train Epoch 13: 359/634 Loss: 0.146687
2023-01-01 02:47: Train Epoch 13: 363/634 Loss: 0.133645
2023-01-01 02:47: Train Epoch 13: 367/634 Loss: 0.141818
2023-01-01 02:48: Train Epoch 13: 371/634 Loss: 0.161417
2023-01-01 02:48: Train Epoch 13: 375/634 Loss: 0.160747
2023-01-01 02:48: Train Epoch 13: 379/634 Loss: 0.142190
2023-01-01 02:48: Train Epoch 13: 383/634 Loss: 0.142470
2023-01-01 02:48: Train Epoch 13: 387/634 Loss: 0.138110
2023-01-01 02:49: Train Epoch 13: 391/634 Loss: 0.166522
2023-01-01 02:49: Train Epoch 13: 395/634 Loss: 0.131451
2023-01-01 02:49: Train Epoch 13: 399/634 Loss: 0.152417
2023-01-01 02:49: Train Epoch 13: 403/634 Loss: 0.158707
2023-01-01 02:50: Train Epoch 13: 407/634 Loss: 0.139586
2023-01-01 02:50: Train Epoch 13: 411/634 Loss: 0.143899
2023-01-01 02:50: Train Epoch 13: 415/634 Loss: 0.150876
2023-01-01 02:51: Train Epoch 13: 419/634 Loss: 0.150823
2023-01-01 02:51: Train Epoch 13: 423/634 Loss: 0.146054
2023-01-01 02:51: Train Epoch 13: 427/634 Loss: 0.165900
2023-01-01 02:51: Train Epoch 13: 431/634 Loss: 0.132610
2023-01-01 02:52: Train Epoch 13: 435/634 Loss: 0.158837
2023-01-01 02:52: Train Epoch 13: 439/634 Loss: 0.165018
2023-01-01 02:52: Train Epoch 13: 443/634 Loss: 0.160239
2023-01-01 02:52: Train Epoch 13: 447/634 Loss: 0.137944
2023-01-01 02:53: Train Epoch 13: 451/634 Loss: 0.132629
2023-01-01 02:53: Train Epoch 13: 455/634 Loss: 0.151237
2023-01-01 02:53: Train Epoch 13: 459/634 Loss: 0.175385
2023-01-01 02:53: Train Epoch 13: 463/634 Loss: 0.175545
2023-01-01 02:54: Train Epoch 13: 467/634 Loss: 0.136778
2023-01-01 02:54: Train Epoch 13: 471/634 Loss: 0.132978
2023-01-01 02:54: Train Epoch 13: 475/634 Loss: 0.160383
2023-01-01 02:54: Train Epoch 13: 479/634 Loss: 0.176842
2023-01-01 02:55: Train Epoch 13: 483/634 Loss: 0.156390
2023-01-01 02:55: Train Epoch 13: 487/634 Loss: 0.161864
2023-01-01 02:55: Train Epoch 13: 491/634 Loss: 0.166668
2023-01-01 02:55: Train Epoch 13: 495/634 Loss: 0.132861
2023-01-01 02:56: Train Epoch 13: 499/634 Loss: 0.132511
2023-01-01 02:56: Train Epoch 13: 503/634 Loss: 0.130565
2023-01-01 02:56: Train Epoch 13: 507/634 Loss: 0.164332
2023-01-01 02:56: Train Epoch 13: 511/634 Loss: 0.145035
2023-01-01 02:57: Train Epoch 13: 515/634 Loss: 0.174299
2023-01-01 02:57: Train Epoch 13: 519/634 Loss: 0.168551
2023-01-01 02:57: Train Epoch 13: 523/634 Loss: 0.179651
2023-01-01 02:57: Train Epoch 13: 527/634 Loss: 0.156392
2023-01-01 02:58: Train Epoch 13: 531/634 Loss: 0.136502
2023-01-01 02:58: Train Epoch 13: 535/634 Loss: 0.143846
2023-01-01 02:58: Train Epoch 13: 539/634 Loss: 0.149759
2023-01-01 02:58: Train Epoch 13: 543/634 Loss: 0.180429
2023-01-01 02:59: Train Epoch 13: 547/634 Loss: 0.161029
2023-01-01 02:59: Train Epoch 13: 551/634 Loss: 0.163176
2023-01-01 02:59: Train Epoch 13: 555/634 Loss: 0.149669
2023-01-01 02:59: Train Epoch 13: 559/634 Loss: 0.153782
2023-01-01 03:00: Train Epoch 13: 563/634 Loss: 0.177706
2023-01-01 03:00: Train Epoch 13: 567/634 Loss: 0.123389
2023-01-01 03:00: Train Epoch 13: 571/634 Loss: 0.147870
2023-01-01 03:01: Train Epoch 13: 575/634 Loss: 0.163070
2023-01-01 03:01: Train Epoch 13: 579/634 Loss: 0.164030
2023-01-01 03:01: Train Epoch 13: 583/634 Loss: 0.139267
2023-01-01 03:01: Train Epoch 13: 587/634 Loss: 0.145462
2023-01-01 03:02: Train Epoch 13: 591/634 Loss: 0.162073
2023-01-01 03:02: Train Epoch 13: 595/634 Loss: 0.129545
2023-01-01 03:02: Train Epoch 13: 599/634 Loss: 0.147414
2023-01-01 03:02: Train Epoch 13: 603/634 Loss: 0.135556
2023-01-01 03:03: Train Epoch 13: 607/634 Loss: 0.170139
2023-01-01 03:03: Train Epoch 13: 611/634 Loss: 0.148510
2023-01-01 03:03: Train Epoch 13: 615/634 Loss: 0.152539
2023-01-01 03:03: Train Epoch 13: 619/634 Loss: 0.163016
2023-01-01 03:04: Train Epoch 13: 623/634 Loss: 0.142495
2023-01-01 03:04: Train Epoch 13: 627/634 Loss: 0.171045
2023-01-01 03:04: Train Epoch 13: 631/634 Loss: 0.139758
2023-01-01 03:04: Train Epoch 13: 633/634 Loss: 0.075352
2023-01-01 03:04: **********Train Epoch 13: averaged Loss: 0.152101 
2023-01-01 03:04: 
Epoch time elapsed: 2415.6010167598724

2023-01-01 03:05: 
 metrics validation: {'precision': 0.8533801580333626, 'recall': 0.7476923076923077, 'f1-score': 0.7970479704797048, 'support': 1300, 'AUC': 0.9338819526627219, 'AUCPR': 0.8767085799818163, 'TP': 972, 'FP': 167, 'TN': 2433, 'FN': 328} 

2023-01-01 03:05: **********Val Epoch 13: average Loss: 0.150635
2023-01-01 03:07: 
 Testing metrics {'precision': 0.8269230769230769, 'recall': 0.7353420195439739, 'f1-score': 0.778448275862069, 'support': 1228, 'AUC': 0.9259564425086739, 'AUCPR': 0.8821838707655952, 'TP': 903, 'FP': 189, 'TN': 2267, 'FN': 325} 

2023-01-01 03:11: 
 Testing metrics {'precision': 0.8794449262792715, 'recall': 0.9203539823008849, 'f1-score': 0.8994345271094356, 'support': 4407, 'AUC': 0.9798750610723115, 'AUCPR': 0.9619710816950665, 'TP': 4056, 'FP': 556, 'TN': 8258, 'FN': 351} 

2023-01-01 03:11: Train Epoch 14: 3/634 Loss: 0.154170
2023-01-01 03:11: Train Epoch 14: 7/634 Loss: 0.135138
2023-01-01 03:12: Train Epoch 14: 11/634 Loss: 0.155371
2023-01-01 03:12: Train Epoch 14: 15/634 Loss: 0.163282
2023-01-01 03:12: Train Epoch 14: 19/634 Loss: 0.162914
2023-01-01 03:13: Train Epoch 14: 23/634 Loss: 0.179047
2023-01-01 03:13: Train Epoch 14: 27/634 Loss: 0.152568
2023-01-01 03:13: Train Epoch 14: 31/634 Loss: 0.129469
2023-01-01 03:13: Train Epoch 14: 35/634 Loss: 0.187706
2023-01-01 03:14: Train Epoch 14: 39/634 Loss: 0.152255
2023-01-01 03:14: Train Epoch 14: 43/634 Loss: 0.189681
2023-01-01 03:14: Train Epoch 14: 47/634 Loss: 0.142998
2023-01-01 03:14: Train Epoch 14: 51/634 Loss: 0.184230
2023-01-01 03:15: Train Epoch 14: 55/634 Loss: 0.162545
2023-01-01 03:15: Train Epoch 14: 59/634 Loss: 0.172686
2023-01-01 03:15: Train Epoch 14: 63/634 Loss: 0.178788
2023-01-01 03:15: Train Epoch 14: 67/634 Loss: 0.154770
2023-01-01 03:16: Train Epoch 14: 71/634 Loss: 0.148085
2023-01-01 03:16: Train Epoch 14: 75/634 Loss: 0.150514
2023-01-01 03:16: Train Epoch 14: 79/634 Loss: 0.190963
2023-01-01 03:16: Train Epoch 14: 83/634 Loss: 0.175538
2023-01-01 03:17: Train Epoch 14: 87/634 Loss: 0.175157
2023-01-01 03:17: Train Epoch 14: 91/634 Loss: 0.173628
2023-01-01 03:17: Train Epoch 14: 95/634 Loss: 0.161890
2023-01-01 03:17: Train Epoch 14: 99/634 Loss: 0.189813
2023-01-01 03:18: Train Epoch 14: 103/634 Loss: 0.199920
2023-01-01 03:18: Train Epoch 14: 107/634 Loss: 0.155776
2023-01-01 03:18: Train Epoch 14: 111/634 Loss: 0.178168
2023-01-01 03:18: Train Epoch 14: 115/634 Loss: 0.151084
2023-01-01 03:19: Train Epoch 14: 119/634 Loss: 0.180298
2023-01-01 03:19: Train Epoch 14: 123/634 Loss: 0.159078
2023-01-01 03:19: Train Epoch 14: 127/634 Loss: 0.155467
2023-01-01 03:19: Train Epoch 14: 131/634 Loss: 0.139763
2023-01-01 03:20: Train Epoch 14: 135/634 Loss: 0.149380
2023-01-01 03:20: Train Epoch 14: 139/634 Loss: 0.148097
2023-01-01 03:20: Train Epoch 14: 143/634 Loss: 0.130042
2023-01-01 03:20: Train Epoch 14: 147/634 Loss: 0.157408
2023-01-01 03:21: Train Epoch 14: 151/634 Loss: 0.157283
2023-01-01 03:21: Train Epoch 14: 155/634 Loss: 0.163712
2023-01-01 03:21: Train Epoch 14: 159/634 Loss: 0.145179
2023-01-01 03:21: Train Epoch 14: 163/634 Loss: 0.145448
2023-01-01 03:21: Train Epoch 14: 167/634 Loss: 0.157804
2023-01-01 03:22: Train Epoch 14: 171/634 Loss: 0.151789
2023-01-01 03:22: Train Epoch 14: 175/634 Loss: 0.144455
2023-01-01 03:22: Train Epoch 14: 179/634 Loss: 0.170014
2023-01-01 03:22: Train Epoch 14: 183/634 Loss: 0.125902
2023-01-01 03:23: Train Epoch 14: 187/634 Loss: 0.126519
2023-01-01 03:23: Train Epoch 14: 191/634 Loss: 0.162237
2023-01-01 03:23: Train Epoch 14: 195/634 Loss: 0.142718
2023-01-01 03:23: Train Epoch 14: 199/634 Loss: 0.152106
2023-01-01 03:24: Train Epoch 14: 203/634 Loss: 0.130859
2023-01-01 03:24: Train Epoch 14: 207/634 Loss: 0.149586
2023-01-01 03:24: Train Epoch 14: 211/634 Loss: 0.157968
2023-01-01 03:24: Train Epoch 14: 215/634 Loss: 0.156914
2023-01-01 03:25: Train Epoch 14: 219/634 Loss: 0.160167
2023-01-01 03:25: Train Epoch 14: 223/634 Loss: 0.146529
2023-01-01 03:25: Train Epoch 14: 227/634 Loss: 0.145914
2023-01-01 03:26: Train Epoch 14: 231/634 Loss: 0.171776
2023-01-01 03:26: Train Epoch 14: 235/634 Loss: 0.145806
2023-01-01 03:26: Train Epoch 14: 239/634 Loss: 0.166287
2023-01-01 03:26: Train Epoch 14: 243/634 Loss: 0.168423
2023-01-01 03:27: Train Epoch 14: 247/634 Loss: 0.154358
2023-01-01 03:27: Train Epoch 14: 251/634 Loss: 0.131496
2023-01-01 03:27: Train Epoch 14: 255/634 Loss: 0.159519
2023-01-01 03:27: Train Epoch 14: 259/634 Loss: 0.145918
2023-01-01 03:28: Train Epoch 14: 263/634 Loss: 0.157053
2023-01-01 03:28: Train Epoch 14: 267/634 Loss: 0.161005
2023-01-01 03:28: Train Epoch 14: 271/634 Loss: 0.141417
2023-01-01 03:28: Train Epoch 14: 275/634 Loss: 0.144295
2023-01-01 03:29: Train Epoch 14: 279/634 Loss: 0.173468
2023-01-01 03:29: Train Epoch 14: 283/634 Loss: 0.169044
2023-01-01 03:29: Train Epoch 14: 287/634 Loss: 0.148333
2023-01-01 03:29: Train Epoch 14: 291/634 Loss: 0.153243
2023-01-01 03:30: Train Epoch 14: 295/634 Loss: 0.136275
2023-01-01 03:30: Train Epoch 14: 299/634 Loss: 0.156455
2023-01-01 03:30: Train Epoch 14: 303/634 Loss: 0.139631
2023-01-01 03:30: Train Epoch 14: 307/634 Loss: 0.141736
2023-01-01 03:31: Train Epoch 14: 311/634 Loss: 0.150289
2023-01-01 03:31: Train Epoch 14: 315/634 Loss: 0.132758
2023-01-01 03:31: Train Epoch 14: 319/634 Loss: 0.157998
2023-01-01 03:31: Train Epoch 14: 323/634 Loss: 0.167998
2023-01-01 03:32: Train Epoch 14: 327/634 Loss: 0.140029
2023-01-01 03:32: Train Epoch 14: 331/634 Loss: 0.161474
2023-01-01 03:32: Train Epoch 14: 335/634 Loss: 0.168394
2023-01-01 03:33: Train Epoch 14: 339/634 Loss: 0.132888
2023-01-01 03:33: Train Epoch 14: 343/634 Loss: 0.190395
2023-01-01 03:33: Train Epoch 14: 347/634 Loss: 0.145808
2023-01-01 03:33: Train Epoch 14: 351/634 Loss: 0.145556
2023-01-01 03:34: Train Epoch 14: 355/634 Loss: 0.161171
2023-01-01 03:34: Train Epoch 14: 359/634 Loss: 0.133665
2023-01-01 03:34: Train Epoch 14: 363/634 Loss: 0.175293
2023-01-01 03:34: Train Epoch 14: 367/634 Loss: 0.172470
2023-01-01 03:34: Train Epoch 14: 371/634 Loss: 0.151493
2023-01-01 03:35: Train Epoch 14: 375/634 Loss: 0.146318
2023-01-01 03:35: Train Epoch 14: 379/634 Loss: 0.151933
2023-01-01 03:35: Train Epoch 14: 383/634 Loss: 0.142147
2023-01-01 03:35: Train Epoch 14: 387/634 Loss: 0.149302
2023-01-01 03:36: Train Epoch 14: 391/634 Loss: 0.162044
2023-01-01 03:36: Train Epoch 14: 395/634 Loss: 0.141385
2023-01-01 03:36: Train Epoch 14: 399/634 Loss: 0.164690
2023-01-01 03:36: Train Epoch 14: 403/634 Loss: 0.173189
2023-01-01 03:37: Train Epoch 14: 407/634 Loss: 0.138418
2023-01-01 03:37: Train Epoch 14: 411/634 Loss: 0.153955
2023-01-01 03:37: Train Epoch 14: 415/634 Loss: 0.145003
2023-01-01 03:37: Train Epoch 14: 419/634 Loss: 0.152267
2023-01-01 03:38: Train Epoch 14: 423/634 Loss: 0.151205
2023-01-01 03:38: Train Epoch 14: 427/634 Loss: 0.150304
2023-01-01 03:38: Train Epoch 14: 431/634 Loss: 0.162022
2023-01-01 03:39: Train Epoch 14: 435/634 Loss: 0.157539
2023-01-01 03:39: Train Epoch 14: 439/634 Loss: 0.146987
2023-01-01 03:39: Train Epoch 14: 443/634 Loss: 0.157569
2023-01-01 03:39: Train Epoch 14: 447/634 Loss: 0.152499
2023-01-01 03:40: Train Epoch 14: 451/634 Loss: 0.149853
2023-01-01 03:40: Train Epoch 14: 455/634 Loss: 0.152395
2023-01-01 03:40: Train Epoch 14: 459/634 Loss: 0.164576
2023-01-01 03:40: Train Epoch 14: 463/634 Loss: 0.142989
2023-01-01 03:41: Train Epoch 14: 467/634 Loss: 0.145554
2023-01-01 03:41: Train Epoch 14: 471/634 Loss: 0.169419
2023-01-01 03:41: Train Epoch 14: 475/634 Loss: 0.156534
2023-01-01 03:41: Train Epoch 14: 479/634 Loss: 0.150067
2023-01-01 03:42: Train Epoch 14: 483/634 Loss: 0.143395
2023-01-01 03:42: Train Epoch 14: 487/634 Loss: 0.168147
2023-01-01 03:42: Train Epoch 14: 491/634 Loss: 0.154488
2023-01-01 03:42: Train Epoch 14: 495/634 Loss: 0.175880
2023-01-01 03:43: Train Epoch 14: 499/634 Loss: 0.176262
2023-01-01 03:43: Train Epoch 14: 503/634 Loss: 0.134765
2023-01-01 03:43: Train Epoch 14: 507/634 Loss: 0.158613
2023-01-01 03:43: Train Epoch 14: 511/634 Loss: 0.151600
2023-01-01 03:44: Train Epoch 14: 515/634 Loss: 0.137308
2023-01-01 03:44: Train Epoch 14: 519/634 Loss: 0.143643
2023-01-01 03:44: Train Epoch 14: 523/634 Loss: 0.149424
2023-01-01 03:44: Train Epoch 14: 527/634 Loss: 0.168211
2023-01-01 03:45: Train Epoch 14: 531/634 Loss: 0.152461
2023-01-01 03:45: Train Epoch 14: 535/634 Loss: 0.168313
2023-01-01 03:45: Train Epoch 14: 539/634 Loss: 0.149888
2023-01-01 03:45: Train Epoch 14: 543/634 Loss: 0.184087
2023-01-01 03:46: Train Epoch 14: 547/634 Loss: 0.167006
2023-01-01 03:46: Train Epoch 14: 551/634 Loss: 0.163454
2023-01-01 03:46: Train Epoch 14: 555/634 Loss: 0.151184
2023-01-01 03:46: Train Epoch 14: 559/634 Loss: 0.148962
2023-01-01 03:47: Train Epoch 14: 563/634 Loss: 0.159914
2023-01-01 03:47: Train Epoch 14: 567/634 Loss: 0.162476
2023-01-01 03:47: Train Epoch 14: 571/634 Loss: 0.155876
2023-01-01 03:47: Train Epoch 14: 575/634 Loss: 0.154104
2023-01-01 03:48: Train Epoch 14: 579/634 Loss: 0.152717
2023-01-01 03:48: Train Epoch 14: 583/634 Loss: 0.161468
2023-01-01 03:48: Train Epoch 14: 587/634 Loss: 0.165172
2023-01-01 03:48: Train Epoch 14: 591/634 Loss: 0.156221
2023-01-01 03:49: Train Epoch 14: 595/634 Loss: 0.147923
2023-01-01 03:49: Train Epoch 14: 599/634 Loss: 0.134378
2023-01-01 03:49: Train Epoch 14: 603/634 Loss: 0.156975
2023-01-01 03:49: Train Epoch 14: 607/634 Loss: 0.163953
2023-01-01 03:50: Train Epoch 14: 611/634 Loss: 0.160434
2023-01-01 03:50: Train Epoch 14: 615/634 Loss: 0.198756
2023-01-01 03:50: Train Epoch 14: 619/634 Loss: 0.182908
2023-01-01 03:50: Train Epoch 14: 623/634 Loss: 0.163398
2023-01-01 03:51: Train Epoch 14: 627/634 Loss: 0.153502
2023-01-01 03:51: Train Epoch 14: 631/634 Loss: 0.144968
2023-01-01 03:51: Train Epoch 14: 633/634 Loss: 0.065947
2023-01-01 03:51: **********Train Epoch 14: averaged Loss: 0.155927 
2023-01-01 03:51: 
Epoch time elapsed: 2405.3538484573364

2023-01-01 03:52: 
 metrics validation: {'precision': 0.8630017452006981, 'recall': 0.7607692307692308, 'f1-score': 0.8086672117743253, 'support': 1300, 'AUC': 0.9434337278106509, 'AUCPR': 0.8906732359578446, 'TP': 989, 'FP': 157, 'TN': 2443, 'FN': 311} 

2023-01-01 03:52: **********Val Epoch 14: average Loss: 0.140990
2023-01-01 03:54: 
 Testing metrics {'precision': 0.8269230769230769, 'recall': 0.7353420195439739, 'f1-score': 0.778448275862069, 'support': 1228, 'AUC': 0.9259564425086739, 'AUCPR': 0.8821838707655952, 'TP': 903, 'FP': 189, 'TN': 2267, 'FN': 325} 

2023-01-01 03:58: 
 Testing metrics {'precision': 0.8794449262792715, 'recall': 0.9203539823008849, 'f1-score': 0.8994345271094356, 'support': 4407, 'AUC': 0.9798750610723115, 'AUCPR': 0.9619710816950665, 'TP': 4056, 'FP': 556, 'TN': 8258, 'FN': 351} 

2023-01-01 03:58: Train Epoch 15: 3/634 Loss: 0.152660
2023-01-01 03:58: Train Epoch 15: 7/634 Loss: 0.147483
2023-01-01 03:59: Train Epoch 15: 11/634 Loss: 0.194705
2023-01-01 03:59: Train Epoch 15: 15/634 Loss: 0.168491
2023-01-01 03:59: Train Epoch 15: 19/634 Loss: 0.151663
2023-01-01 03:59: Train Epoch 15: 23/634 Loss: 0.172909
2023-01-01 04:00: Train Epoch 15: 27/634 Loss: 0.159409
2023-01-01 04:00: Train Epoch 15: 31/634 Loss: 0.147369
2023-01-01 04:00: Train Epoch 15: 35/634 Loss: 0.122179
2023-01-01 04:00: Train Epoch 15: 39/634 Loss: 0.141054
2023-01-01 04:01: Train Epoch 15: 43/634 Loss: 0.152374
2023-01-01 04:01: Train Epoch 15: 47/634 Loss: 0.156787
2023-01-01 04:01: Train Epoch 15: 51/634 Loss: 0.168586
2023-01-01 04:02: Train Epoch 15: 55/634 Loss: 0.176232
2023-01-01 04:02: Train Epoch 15: 59/634 Loss: 0.140993
2023-01-01 04:02: Train Epoch 15: 63/634 Loss: 0.140832
2023-01-01 04:02: Train Epoch 15: 67/634 Loss: 0.150524
2023-01-01 04:03: Train Epoch 15: 71/634 Loss: 0.158247
2023-01-01 04:03: Train Epoch 15: 75/634 Loss: 0.186798
2023-01-01 04:03: Train Epoch 15: 79/634 Loss: 0.134012
2023-01-01 04:03: Train Epoch 15: 83/634 Loss: 0.153780
2023-01-01 04:04: Train Epoch 15: 87/634 Loss: 0.157086
2023-01-01 04:04: Train Epoch 15: 91/634 Loss: 0.153240
2023-01-01 04:04: Train Epoch 15: 95/634 Loss: 0.133508
2023-01-01 04:04: Train Epoch 15: 99/634 Loss: 0.165127
2023-01-01 04:05: Train Epoch 15: 103/634 Loss: 0.147875
2023-01-01 04:05: Train Epoch 15: 107/634 Loss: 0.136538
2023-01-01 04:05: Train Epoch 15: 111/634 Loss: 0.132958
2023-01-01 04:05: Train Epoch 15: 115/634 Loss: 0.150536
2023-01-01 04:06: Train Epoch 15: 119/634 Loss: 0.160908
2023-01-01 04:06: Train Epoch 15: 123/634 Loss: 0.126851
2023-01-01 04:06: Train Epoch 15: 127/634 Loss: 0.167920
2023-01-01 04:06: Train Epoch 15: 131/634 Loss: 0.136005
2023-01-01 04:07: Train Epoch 15: 135/634 Loss: 0.147700
2023-01-01 04:07: Train Epoch 15: 139/634 Loss: 0.163825
2023-01-01 04:07: Train Epoch 15: 143/634 Loss: 0.173066
2023-01-01 04:07: Train Epoch 15: 147/634 Loss: 0.167229
2023-01-01 04:08: Train Epoch 15: 151/634 Loss: 0.163725
2023-01-01 04:08: Train Epoch 15: 155/634 Loss: 0.171127
2023-01-01 04:08: Train Epoch 15: 159/634 Loss: 0.160369
2023-01-01 04:08: Train Epoch 15: 163/634 Loss: 0.173539
2023-01-01 04:09: Train Epoch 15: 167/634 Loss: 0.181977
2023-01-01 04:09: Train Epoch 15: 171/634 Loss: 0.158203
2023-01-01 04:09: Train Epoch 15: 175/634 Loss: 0.142611
2023-01-01 04:09: Train Epoch 15: 179/634 Loss: 0.189528
2023-01-01 04:10: Train Epoch 15: 183/634 Loss: 0.199125
2023-01-01 04:10: Train Epoch 15: 187/634 Loss: 0.143737
2023-01-01 04:10: Train Epoch 15: 191/634 Loss: 0.211825
2023-01-01 04:10: Train Epoch 15: 195/634 Loss: 0.146519
2023-01-01 04:11: Train Epoch 15: 199/634 Loss: 0.145343
2023-01-01 04:11: Train Epoch 15: 203/634 Loss: 0.195695
2023-01-01 04:11: Train Epoch 15: 207/634 Loss: 0.154389
2023-01-01 04:11: Train Epoch 15: 211/634 Loss: 0.161632
2023-01-01 04:12: Train Epoch 15: 215/634 Loss: 0.165425
2023-01-01 04:12: Train Epoch 15: 219/634 Loss: 0.166281
2023-01-01 04:12: Train Epoch 15: 223/634 Loss: 0.165910
2023-01-01 04:13: Train Epoch 15: 227/634 Loss: 0.147554
2023-01-01 04:13: Train Epoch 15: 231/634 Loss: 0.197156
2023-01-01 04:13: Train Epoch 15: 235/634 Loss: 0.172577
2023-01-01 04:13: Train Epoch 15: 239/634 Loss: 0.184414
2023-01-01 04:14: Train Epoch 15: 243/634 Loss: 0.145650
2023-01-01 04:14: Train Epoch 15: 247/634 Loss: 0.155551
2023-01-01 04:14: Train Epoch 15: 251/634 Loss: 0.152511
2023-01-01 04:14: Train Epoch 15: 255/634 Loss: 0.196220
2023-01-01 04:15: Train Epoch 15: 259/634 Loss: 0.175414
2023-01-01 04:15: Train Epoch 15: 263/634 Loss: 0.173727
2023-01-01 04:15: Train Epoch 15: 267/634 Loss: 0.161016
2023-01-01 04:15: Train Epoch 15: 271/634 Loss: 0.160311
2023-01-01 04:16: Train Epoch 15: 275/634 Loss: 0.160150
2023-01-01 04:16: Train Epoch 15: 279/634 Loss: 0.171523
2023-01-01 04:16: Train Epoch 15: 283/634 Loss: 0.173575
2023-01-01 04:16: Train Epoch 15: 287/634 Loss: 0.198504
2023-01-01 04:17: Train Epoch 15: 291/634 Loss: 0.149341
2023-01-01 04:17: Train Epoch 15: 295/634 Loss: 0.172572
2023-01-01 04:17: Train Epoch 15: 299/634 Loss: 0.175291
2023-01-01 04:17: Train Epoch 15: 303/634 Loss: 0.146851
2023-01-01 04:18: Train Epoch 15: 307/634 Loss: 0.168857
2023-01-01 04:18: Train Epoch 15: 311/634 Loss: 0.164447
2023-01-01 04:18: Train Epoch 15: 315/634 Loss: 0.176914
2023-01-01 04:18: Train Epoch 15: 319/634 Loss: 0.167189
2023-01-01 04:19: Train Epoch 15: 323/634 Loss: 0.183656
2023-01-01 04:19: Train Epoch 15: 327/634 Loss: 0.159443
2023-01-01 04:19: Train Epoch 15: 331/634 Loss: 0.148243
2023-01-01 04:19: Train Epoch 15: 335/634 Loss: 0.160623
2023-01-01 04:20: Train Epoch 15: 339/634 Loss: 0.169159
2023-01-01 04:20: Train Epoch 15: 343/634 Loss: 0.146135
2023-01-01 04:20: Train Epoch 15: 347/634 Loss: 0.115980
2023-01-01 04:20: Train Epoch 15: 351/634 Loss: 0.153315
2023-01-01 04:21: Train Epoch 15: 355/634 Loss: 0.150559
2023-01-01 04:21: Train Epoch 15: 359/634 Loss: 0.154444
2023-01-01 04:21: Train Epoch 15: 363/634 Loss: 0.136716
2023-01-01 04:21: Train Epoch 15: 367/634 Loss: 0.157025
2023-01-01 04:22: Train Epoch 15: 371/634 Loss: 0.158068
2023-01-01 04:22: Train Epoch 15: 375/634 Loss: 0.146747
2023-01-01 04:22: Train Epoch 15: 379/634 Loss: 0.155685
2023-01-01 04:22: Train Epoch 15: 383/634 Loss: 0.143941
2023-01-01 04:23: Train Epoch 15: 387/634 Loss: 0.170703
2023-01-01 04:23: Train Epoch 15: 391/634 Loss: 0.170197
2023-01-01 04:23: Train Epoch 15: 395/634 Loss: 0.152082
2023-01-01 04:23: Train Epoch 15: 399/634 Loss: 0.133444
2023-01-01 04:24: Train Epoch 15: 403/634 Loss: 0.161931
2023-01-01 04:24: Train Epoch 15: 407/634 Loss: 0.151937
2023-01-01 04:24: Train Epoch 15: 411/634 Loss: 0.158612
2023-01-01 04:24: Train Epoch 15: 415/634 Loss: 0.140638
2023-01-01 04:25: Train Epoch 15: 419/634 Loss: 0.141209
2023-01-01 04:25: Train Epoch 15: 423/634 Loss: 0.130552
2023-01-01 04:25: Train Epoch 15: 427/634 Loss: 0.151436
2023-01-01 04:25: Train Epoch 15: 431/634 Loss: 0.138046
2023-01-01 04:26: Train Epoch 15: 435/634 Loss: 0.159813
2023-01-01 04:26: Train Epoch 15: 439/634 Loss: 0.167380
2023-01-01 04:26: Train Epoch 15: 443/634 Loss: 0.163804
2023-01-01 04:26: Train Epoch 15: 447/634 Loss: 0.196451
2023-01-01 04:27: Train Epoch 15: 451/634 Loss: 0.176939
2023-01-01 04:27: Train Epoch 15: 455/634 Loss: 0.163755
2023-01-01 04:27: Train Epoch 15: 459/634 Loss: 0.163286
2023-01-01 04:27: Train Epoch 15: 463/634 Loss: 0.197509
2023-01-01 04:28: Train Epoch 15: 467/634 Loss: 0.158650
2023-01-01 04:28: Train Epoch 15: 471/634 Loss: 0.167508
2023-01-01 04:28: Train Epoch 15: 475/634 Loss: 0.171877
2023-01-01 04:28: Train Epoch 15: 479/634 Loss: 0.146158
2023-01-01 04:29: Train Epoch 15: 483/634 Loss: 0.204972
2023-01-01 04:29: Train Epoch 15: 487/634 Loss: 0.158607
2023-01-01 04:29: Train Epoch 15: 491/634 Loss: 0.169650
2023-01-01 04:29: Train Epoch 15: 495/634 Loss: 0.178807
2023-01-01 04:30: Train Epoch 15: 499/634 Loss: 0.139526
2023-01-01 04:30: Train Epoch 15: 503/634 Loss: 0.177577
2023-01-01 04:30: Train Epoch 15: 507/634 Loss: 0.118605
2023-01-01 04:31: Train Epoch 15: 511/634 Loss: 0.186932
2023-01-01 04:31: Train Epoch 15: 515/634 Loss: 0.157634
2023-01-01 04:31: Train Epoch 15: 519/634 Loss: 0.145034
2023-01-01 04:31: Train Epoch 15: 523/634 Loss: 0.155888
2023-01-01 04:32: Train Epoch 15: 527/634 Loss: 0.143345
2023-01-01 04:32: Train Epoch 15: 531/634 Loss: 0.157926
2023-01-01 04:32: Train Epoch 15: 535/634 Loss: 0.167496
2023-01-01 04:32: Train Epoch 15: 539/634 Loss: 0.162501
2023-01-01 04:33: Train Epoch 15: 543/634 Loss: 0.143805
2023-01-01 04:33: Train Epoch 15: 547/634 Loss: 0.147301
2023-01-01 04:33: Train Epoch 15: 551/634 Loss: 0.161931
2023-01-01 04:33: Train Epoch 15: 555/634 Loss: 0.142648
2023-01-01 04:34: Train Epoch 15: 559/634 Loss: 0.147029
2023-01-01 04:34: Train Epoch 15: 563/634 Loss: 0.157290
2023-01-01 04:34: Train Epoch 15: 567/634 Loss: 0.143705
2023-01-01 04:34: Train Epoch 15: 571/634 Loss: 0.145535
2023-01-01 04:35: Train Epoch 15: 575/634 Loss: 0.138192
2023-01-01 04:35: Train Epoch 15: 579/634 Loss: 0.155141
2023-01-01 04:35: Train Epoch 15: 583/634 Loss: 0.146765
2023-01-01 04:36: Train Epoch 15: 587/634 Loss: 0.141274
2023-01-01 04:36: Train Epoch 15: 591/634 Loss: 0.132510
2023-01-01 04:36: Train Epoch 15: 595/634 Loss: 0.160737
2023-01-01 04:36: Train Epoch 15: 599/634 Loss: 0.139056
2023-01-01 04:37: Train Epoch 15: 603/634 Loss: 0.147157
2023-01-01 04:37: Train Epoch 15: 607/634 Loss: 0.152104
2023-01-01 04:37: Train Epoch 15: 611/634 Loss: 0.169752
2023-01-01 04:37: Train Epoch 15: 615/634 Loss: 0.144828
2023-01-01 04:38: Train Epoch 15: 619/634 Loss: 0.157625
2023-01-01 04:38: Train Epoch 15: 623/634 Loss: 0.134738
2023-01-01 04:38: Train Epoch 15: 627/634 Loss: 0.140831
2023-01-01 04:38: Train Epoch 15: 631/634 Loss: 0.138110
2023-01-01 04:39: Train Epoch 15: 633/634 Loss: 0.059481
2023-01-01 04:39: **********Train Epoch 15: averaged Loss: 0.157783 
2023-01-01 04:39: 
Epoch time elapsed: 2442.47683095932

2023-01-01 04:40: 
 metrics validation: {'precision': 0.7800143781452192, 'recall': 0.8346153846153846, 'f1-score': 0.8063916759568933, 'support': 1300, 'AUC': 0.9427485207100592, 'AUCPR': 0.8917228083306099, 'TP': 1085, 'FP': 306, 'TN': 2294, 'FN': 215} 

2023-01-01 04:40: **********Val Epoch 15: average Loss: 0.138853
2023-01-01 04:41: 
 Testing metrics {'precision': 0.8269230769230769, 'recall': 0.7353420195439739, 'f1-score': 0.778448275862069, 'support': 1228, 'AUC': 0.9259564425086739, 'AUCPR': 0.8821838707655952, 'TP': 903, 'FP': 189, 'TN': 2267, 'FN': 325} 

2023-01-01 04:45: 
 Testing metrics {'precision': 0.8794449262792715, 'recall': 0.9203539823008849, 'f1-score': 0.8994345271094356, 'support': 4407, 'AUC': 0.9798750610723115, 'AUCPR': 0.9619710816950665, 'TP': 4056, 'FP': 556, 'TN': 8258, 'FN': 351} 

2023-01-01 04:45: Train Epoch 16: 3/634 Loss: 0.141352
2023-01-01 04:46: Train Epoch 16: 7/634 Loss: 0.165025
2023-01-01 04:46: Train Epoch 16: 11/634 Loss: 0.128189
2023-01-01 04:46: Train Epoch 16: 15/634 Loss: 0.169161
2023-01-01 04:46: Train Epoch 16: 19/634 Loss: 0.151392
2023-01-01 04:47: Train Epoch 16: 23/634 Loss: 0.130228
2023-01-01 04:47: Train Epoch 16: 27/634 Loss: 0.148717
2023-01-01 04:47: Train Epoch 16: 31/634 Loss: 0.148402
2023-01-01 04:47: Train Epoch 16: 35/634 Loss: 0.153160
2023-01-01 04:48: Train Epoch 16: 39/634 Loss: 0.155584
2023-01-01 04:48: Train Epoch 16: 43/634 Loss: 0.167888
2023-01-01 04:48: Train Epoch 16: 47/634 Loss: 0.137348
2023-01-01 04:48: Train Epoch 16: 51/634 Loss: 0.133196
2023-01-01 04:49: Train Epoch 16: 55/634 Loss: 0.165692
2023-01-01 04:49: Train Epoch 16: 59/634 Loss: 0.136920
2023-01-01 04:49: Train Epoch 16: 63/634 Loss: 0.144399
2023-01-01 04:49: Train Epoch 16: 67/634 Loss: 0.148225
2023-01-01 04:50: Train Epoch 16: 71/634 Loss: 0.152504
2023-01-01 04:50: Train Epoch 16: 75/634 Loss: 0.145277
2023-01-01 04:50: Train Epoch 16: 79/634 Loss: 0.142145
2023-01-01 04:51: Train Epoch 16: 83/634 Loss: 0.143266
2023-01-01 04:51: Train Epoch 16: 87/634 Loss: 0.157470
2023-01-01 04:51: Train Epoch 16: 91/634 Loss: 0.155258
2023-01-01 04:51: Train Epoch 16: 95/634 Loss: 0.141004
2023-01-01 04:52: Train Epoch 16: 99/634 Loss: 0.151837
2023-01-01 04:52: Train Epoch 16: 103/634 Loss: 0.155504
2023-01-01 04:52: Train Epoch 16: 107/634 Loss: 0.145556
2023-01-01 04:52: Train Epoch 16: 111/634 Loss: 0.148102
2023-01-01 04:53: Train Epoch 16: 115/634 Loss: 0.139878
2023-01-01 04:53: Train Epoch 16: 119/634 Loss: 0.178772
2023-01-01 04:53: Train Epoch 16: 123/634 Loss: 0.146300
2023-01-01 04:53: Train Epoch 16: 127/634 Loss: 0.147445
2023-01-01 04:54: Train Epoch 16: 131/634 Loss: 0.166622
2023-01-01 04:54: Train Epoch 16: 135/634 Loss: 0.157511
2023-01-01 04:54: Train Epoch 16: 139/634 Loss: 0.144163
2023-01-01 04:54: Train Epoch 16: 143/634 Loss: 0.166851
2023-01-01 04:55: Train Epoch 16: 147/634 Loss: 0.132737
2023-01-01 04:55: Train Epoch 16: 151/634 Loss: 0.145208
2023-01-01 04:55: Train Epoch 16: 155/634 Loss: 0.172681
2023-01-01 04:55: Train Epoch 16: 159/634 Loss: 0.149423
2023-01-01 04:56: Train Epoch 16: 163/634 Loss: 0.120858
2023-01-01 04:56: Train Epoch 16: 167/634 Loss: 0.152970
2023-01-01 04:56: Train Epoch 16: 171/634 Loss: 0.139941
2023-01-01 04:57: Train Epoch 16: 175/634 Loss: 0.112125
2023-01-01 04:57: Train Epoch 16: 179/634 Loss: 0.154683
2023-01-01 04:57: Train Epoch 16: 183/634 Loss: 0.150297
2023-01-01 04:57: Train Epoch 16: 187/634 Loss: 0.142203
2023-01-01 04:58: Train Epoch 16: 191/634 Loss: 0.146945
2023-01-01 04:58: Train Epoch 16: 195/634 Loss: 0.157804
2023-01-01 04:58: Train Epoch 16: 199/634 Loss: 0.134047
2023-01-01 04:58: Train Epoch 16: 203/634 Loss: 0.147047
2023-01-01 04:59: Train Epoch 16: 207/634 Loss: 0.173656
2023-01-01 04:59: Train Epoch 16: 211/634 Loss: 0.151831
2023-01-01 04:59: Train Epoch 16: 215/634 Loss: 0.129305
2023-01-01 04:59: Train Epoch 16: 219/634 Loss: 0.156166
2023-01-01 05:00: Train Epoch 16: 223/634 Loss: 0.143616
2023-01-01 05:00: Train Epoch 16: 227/634 Loss: 0.145529
2023-01-01 05:00: Train Epoch 16: 231/634 Loss: 0.153577
2023-01-01 05:00: Train Epoch 16: 235/634 Loss: 0.159048
2023-01-01 05:01: Train Epoch 16: 239/634 Loss: 0.133051
2023-01-01 05:01: Train Epoch 16: 243/634 Loss: 0.125077
2023-01-01 05:01: Train Epoch 16: 247/634 Loss: 0.150774
2023-01-01 05:01: Train Epoch 16: 251/634 Loss: 0.167822
2023-01-01 05:02: Train Epoch 16: 255/634 Loss: 0.140830
2023-01-01 05:02: Train Epoch 16: 259/634 Loss: 0.140431
2023-01-01 05:02: Train Epoch 16: 263/634 Loss: 0.118147
2023-01-01 05:02: Train Epoch 16: 267/634 Loss: 0.169929
2023-01-01 05:03: Train Epoch 16: 271/634 Loss: 0.141547
2023-01-01 05:03: Train Epoch 16: 275/634 Loss: 0.168651
2023-01-01 05:03: Train Epoch 16: 279/634 Loss: 0.141457
2023-01-01 05:03: Train Epoch 16: 283/634 Loss: 0.129916
2023-01-01 05:04: Train Epoch 16: 287/634 Loss: 0.147636
2023-01-01 05:04: Train Epoch 16: 291/634 Loss: 0.166531
2023-01-01 05:04: Train Epoch 16: 295/634 Loss: 0.131372
2023-01-01 05:04: Train Epoch 16: 299/634 Loss: 0.161753
2023-01-01 05:05: Train Epoch 16: 303/634 Loss: 0.168604
2023-01-01 05:05: Train Epoch 16: 307/634 Loss: 0.154560
2023-01-01 05:05: Train Epoch 16: 311/634 Loss: 0.156939
2023-01-01 05:05: Train Epoch 16: 315/634 Loss: 0.150691
2023-01-01 05:06: Train Epoch 16: 319/634 Loss: 0.147538
2023-01-01 05:06: Train Epoch 16: 323/634 Loss: 0.163141
2023-01-01 05:06: Train Epoch 16: 327/634 Loss: 0.144459
2023-01-01 05:06: Train Epoch 16: 331/634 Loss: 0.157797
2023-01-01 05:07: Train Epoch 16: 335/634 Loss: 0.144643
2023-01-01 05:07: Train Epoch 16: 339/634 Loss: 0.156582
2023-01-01 05:07: Train Epoch 16: 343/634 Loss: 0.146905
2023-01-01 05:07: Train Epoch 16: 347/634 Loss: 0.142160
2023-01-01 05:08: Train Epoch 16: 351/634 Loss: 0.148288
2023-01-01 05:08: Train Epoch 16: 355/634 Loss: 0.148181
2023-01-01 05:08: Train Epoch 16: 359/634 Loss: 0.160826
2023-01-01 05:08: Train Epoch 16: 363/634 Loss: 0.152527
2023-01-01 05:09: Train Epoch 16: 367/634 Loss: 0.148353
2023-01-01 05:09: Train Epoch 16: 371/634 Loss: 0.152847
2023-01-01 05:09: Train Epoch 16: 375/634 Loss: 0.164335
2023-01-01 05:09: Train Epoch 16: 379/634 Loss: 0.178884
2023-01-01 05:10: Train Epoch 16: 383/634 Loss: 0.159028
2023-01-01 05:10: Train Epoch 16: 387/634 Loss: 0.147815
2023-01-01 05:10: Train Epoch 16: 391/634 Loss: 0.146703
2023-01-01 05:10: Train Epoch 16: 395/634 Loss: 0.145361
2023-01-01 05:11: Train Epoch 16: 399/634 Loss: 0.159873
2023-01-01 05:11: Train Epoch 16: 403/634 Loss: 0.167217
2023-01-01 05:11: Train Epoch 16: 407/634 Loss: 0.161559
2023-01-01 05:11: Train Epoch 16: 411/634 Loss: 0.146352
2023-01-01 05:12: Train Epoch 16: 415/634 Loss: 0.138307
2023-01-01 05:12: Train Epoch 16: 419/634 Loss: 0.154921
2023-01-01 05:12: Train Epoch 16: 423/634 Loss: 0.154368
2023-01-01 05:12: Train Epoch 16: 427/634 Loss: 0.167506
2023-01-01 05:13: Train Epoch 16: 431/634 Loss: 0.147323
2023-01-01 05:13: Train Epoch 16: 435/634 Loss: 0.143563
2023-01-01 05:13: Train Epoch 16: 439/634 Loss: 0.153529
2023-01-01 05:14: Train Epoch 16: 443/634 Loss: 0.152241
2023-01-01 05:14: Train Epoch 16: 447/634 Loss: 0.161811
2023-01-01 05:14: Train Epoch 16: 451/634 Loss: 0.148179
2023-01-01 05:14: Train Epoch 16: 455/634 Loss: 0.146543
2023-01-01 05:14: Train Epoch 16: 459/634 Loss: 0.148449
2023-01-01 05:15: Train Epoch 16: 463/634 Loss: 0.162765
2023-01-01 05:15: Train Epoch 16: 467/634 Loss: 0.125557
2023-01-01 05:15: Train Epoch 16: 471/634 Loss: 0.146394
2023-01-01 05:16: Train Epoch 16: 475/634 Loss: 0.130618
2023-01-01 05:16: Train Epoch 16: 479/634 Loss: 0.130699
2023-01-01 05:16: Train Epoch 16: 483/634 Loss: 0.131148
2023-01-01 05:16: Train Epoch 16: 487/634 Loss: 0.163724
2023-01-01 05:17: Train Epoch 16: 491/634 Loss: 0.150978
2023-01-01 05:17: Train Epoch 16: 495/634 Loss: 0.155987
2023-01-01 05:17: Train Epoch 16: 499/634 Loss: 0.132680
2023-01-01 05:17: Train Epoch 16: 503/634 Loss: 0.148481
2023-01-01 05:18: Train Epoch 16: 507/634 Loss: 0.141714
2023-01-01 05:18: Train Epoch 16: 511/634 Loss: 0.136302
2023-01-01 05:18: Train Epoch 16: 515/634 Loss: 0.156176
2023-01-01 05:18: Train Epoch 16: 519/634 Loss: 0.144399
2023-01-01 05:19: Train Epoch 16: 523/634 Loss: 0.130691
2023-01-01 05:19: Train Epoch 16: 527/634 Loss: 0.143847
2023-01-01 05:19: Train Epoch 16: 531/634 Loss: 0.127930
2023-01-01 05:19: Train Epoch 16: 535/634 Loss: 0.156252
2023-01-01 05:20: Train Epoch 16: 539/634 Loss: 0.135691
2023-01-01 05:20: Train Epoch 16: 543/634 Loss: 0.124727
2023-01-01 05:20: Train Epoch 16: 547/634 Loss: 0.134031
2023-01-01 05:20: Train Epoch 16: 551/634 Loss: 0.137739
2023-01-01 05:21: Train Epoch 16: 555/634 Loss: 0.154791
2023-01-01 05:21: Train Epoch 16: 559/634 Loss: 0.157881
2023-01-01 05:21: Train Epoch 16: 563/634 Loss: 0.133678
2023-01-01 05:21: Train Epoch 16: 567/634 Loss: 0.127438
2023-01-01 05:22: Train Epoch 16: 571/634 Loss: 0.137880
2023-01-01 05:22: Train Epoch 16: 575/634 Loss: 0.133965
2023-01-01 05:22: Train Epoch 16: 579/634 Loss: 0.132772
2023-01-01 05:23: Train Epoch 16: 583/634 Loss: 0.128411
2023-01-01 05:23: Train Epoch 16: 587/634 Loss: 0.120277
2023-01-01 05:23: Train Epoch 16: 591/634 Loss: 0.164157
2023-01-01 05:23: Train Epoch 16: 595/634 Loss: 0.138497
2023-01-01 05:23: Train Epoch 16: 599/634 Loss: 0.138118
2023-01-01 05:24: Train Epoch 16: 603/634 Loss: 0.136672
2023-01-01 05:24: Train Epoch 16: 607/634 Loss: 0.133036
2023-01-01 05:24: Train Epoch 16: 611/634 Loss: 0.158417
2023-01-01 05:25: Train Epoch 16: 615/634 Loss: 0.143023
2023-01-01 05:25: Train Epoch 16: 619/634 Loss: 0.144976
2023-01-01 05:25: Train Epoch 16: 623/634 Loss: 0.153742
2023-01-01 05:25: Train Epoch 16: 627/634 Loss: 0.137348
2023-01-01 05:26: Train Epoch 16: 631/634 Loss: 0.124759
2023-01-01 05:26: Train Epoch 16: 633/634 Loss: 0.065695
2023-01-01 05:26: **********Train Epoch 16: averaged Loss: 0.146981 
2023-01-01 05:26: 
Epoch time elapsed: 2441.4677228927612

2023-01-01 05:27: 
 metrics validation: {'precision': 0.8652849740932642, 'recall': 0.7707692307692308, 'f1-score': 0.8152969894222944, 'support': 1300, 'AUC': 0.9431470414201183, 'AUCPR': 0.8903973293587691, 'TP': 1002, 'FP': 156, 'TN': 2444, 'FN': 298} 

2023-01-01 05:27: **********Val Epoch 16: average Loss: 0.140984
2023-01-01 05:28: 
 Testing metrics {'precision': 0.8269230769230769, 'recall': 0.7353420195439739, 'f1-score': 0.778448275862069, 'support': 1228, 'AUC': 0.9259564425086739, 'AUCPR': 0.8821838707655952, 'TP': 903, 'FP': 189, 'TN': 2267, 'FN': 325} 

2023-01-01 05:33: 
 Testing metrics {'precision': 0.8794449262792715, 'recall': 0.9203539823008849, 'f1-score': 0.8994345271094356, 'support': 4407, 'AUC': 0.9798750610723115, 'AUCPR': 0.9619710816950665, 'TP': 4056, 'FP': 556, 'TN': 8258, 'FN': 351} 

2023-01-01 05:33: Train Epoch 17: 3/634 Loss: 0.168515
2023-01-01 05:33: Train Epoch 17: 7/634 Loss: 0.184108
2023-01-01 05:33: Train Epoch 17: 11/634 Loss: 0.137312
2023-01-01 05:34: Train Epoch 17: 15/634 Loss: 0.163519
2023-01-01 05:34: Train Epoch 17: 19/634 Loss: 0.145902
2023-01-01 05:34: Train Epoch 17: 23/634 Loss: 0.165603
2023-01-01 05:35: Train Epoch 17: 27/634 Loss: 0.166697
2023-01-01 05:35: Train Epoch 17: 31/634 Loss: 0.181447
2023-01-01 05:35: Train Epoch 17: 35/634 Loss: 0.145162
2023-01-01 05:35: Train Epoch 17: 39/634 Loss: 0.160479
2023-01-01 05:36: Train Epoch 17: 43/634 Loss: 0.153743
2023-01-01 05:36: Train Epoch 17: 47/634 Loss: 0.162449
2023-01-01 05:36: Train Epoch 17: 51/634 Loss: 0.145260
2023-01-01 05:36: Train Epoch 17: 55/634 Loss: 0.154908
2023-01-01 05:37: Train Epoch 17: 59/634 Loss: 0.138513
2023-01-01 05:37: Train Epoch 17: 63/634 Loss: 0.108326
2023-01-01 05:37: Train Epoch 17: 67/634 Loss: 0.138190
2023-01-01 05:37: Train Epoch 17: 71/634 Loss: 0.143365
2023-01-01 05:38: Train Epoch 17: 75/634 Loss: 0.162066
2023-01-01 05:38: Train Epoch 17: 79/634 Loss: 0.135639
2023-01-01 05:38: Train Epoch 17: 83/634 Loss: 0.153086
2023-01-01 05:38: Train Epoch 17: 87/634 Loss: 0.126073
2023-01-01 05:39: Train Epoch 17: 91/634 Loss: 0.152647
2023-01-01 05:39: Train Epoch 17: 95/634 Loss: 0.145358
2023-01-01 05:39: Train Epoch 17: 99/634 Loss: 0.139285
2023-01-01 05:39: Train Epoch 17: 103/634 Loss: 0.157362
2023-01-01 05:40: Train Epoch 17: 107/634 Loss: 0.122385
2023-01-01 05:40: Train Epoch 17: 111/634 Loss: 0.147239
2023-01-01 05:40: Train Epoch 17: 115/634 Loss: 0.131763
2023-01-01 05:40: Train Epoch 17: 119/634 Loss: 0.133359
2023-01-01 05:41: Train Epoch 17: 123/634 Loss: 0.171271
2023-01-01 05:41: Train Epoch 17: 127/634 Loss: 0.160829
2023-01-01 05:41: Train Epoch 17: 131/634 Loss: 0.167580
2023-01-01 05:41: Train Epoch 17: 135/634 Loss: 0.146283
2023-01-01 05:42: Train Epoch 17: 139/634 Loss: 0.157432
2023-01-01 05:42: Train Epoch 17: 143/634 Loss: 0.146762
2023-01-01 05:42: Train Epoch 17: 147/634 Loss: 0.143065
2023-01-01 05:43: Train Epoch 17: 151/634 Loss: 0.127592
2023-01-01 05:43: Train Epoch 17: 155/634 Loss: 0.139892
2023-01-01 05:43: Train Epoch 17: 159/634 Loss: 0.146863
2023-01-01 05:43: Train Epoch 17: 163/634 Loss: 0.160701
2023-01-01 05:44: Train Epoch 17: 167/634 Loss: 0.159983
2023-01-01 05:44: Train Epoch 17: 171/634 Loss: 0.146809
2023-01-01 05:44: Train Epoch 17: 175/634 Loss: 0.148378
2023-01-01 05:44: Train Epoch 17: 179/634 Loss: 0.131084
2023-01-01 05:45: Train Epoch 17: 183/634 Loss: 0.149450
2023-01-01 05:45: Train Epoch 17: 187/634 Loss: 0.143183
2023-01-01 05:45: Train Epoch 17: 191/634 Loss: 0.148739
2023-01-01 05:45: Train Epoch 17: 195/634 Loss: 0.130788
2023-01-01 05:46: Train Epoch 17: 199/634 Loss: 0.152729
2023-01-01 05:46: Train Epoch 17: 203/634 Loss: 0.133372
2023-01-01 05:46: Train Epoch 17: 207/634 Loss: 0.156007
2023-01-01 05:46: Train Epoch 17: 211/634 Loss: 0.173085
2023-01-01 05:47: Train Epoch 17: 215/634 Loss: 0.148048
2023-01-01 05:47: Train Epoch 17: 219/634 Loss: 0.146728
2023-01-01 05:47: Train Epoch 17: 223/634 Loss: 0.139835
2023-01-01 05:47: Train Epoch 17: 227/634 Loss: 0.159714
2023-01-01 05:48: Train Epoch 17: 231/634 Loss: 0.164493
2023-01-01 05:48: Train Epoch 17: 235/634 Loss: 0.162419
2023-01-01 05:48: Train Epoch 17: 239/634 Loss: 0.143209
2023-01-01 05:48: Train Epoch 17: 243/634 Loss: 0.163109
2023-01-01 05:49: Train Epoch 17: 247/634 Loss: 0.159717
2023-01-01 05:49: Train Epoch 17: 251/634 Loss: 0.128622
2023-01-01 05:49: Train Epoch 17: 255/634 Loss: 0.157026
2023-01-01 05:49: Train Epoch 17: 259/634 Loss: 0.129057
2023-01-01 05:50: Train Epoch 17: 263/634 Loss: 0.156492
2023-01-01 05:50: Train Epoch 17: 267/634 Loss: 0.135694
2023-01-01 05:50: Train Epoch 17: 271/634 Loss: 0.150862
2023-01-01 05:50: Train Epoch 17: 275/634 Loss: 0.150511
2023-01-01 05:51: Train Epoch 17: 279/634 Loss: 0.148547
2023-01-01 05:51: Train Epoch 17: 283/634 Loss: 0.155880
2023-01-01 05:51: Train Epoch 17: 287/634 Loss: 0.153832
2023-01-01 05:52: Train Epoch 17: 291/634 Loss: 0.117973
2023-01-01 05:52: Train Epoch 17: 295/634 Loss: 0.130763
2023-01-01 05:52: Train Epoch 17: 299/634 Loss: 0.133510
2023-01-01 05:52: Train Epoch 17: 303/634 Loss: 0.130751
2023-01-01 05:53: Train Epoch 17: 307/634 Loss: 0.165725
2023-01-01 05:53: Train Epoch 17: 311/634 Loss: 0.147862
2023-01-01 05:53: Train Epoch 17: 315/634 Loss: 0.119762
2023-01-01 05:53: Train Epoch 17: 319/634 Loss: 0.134977
2023-01-01 05:54: Train Epoch 17: 323/634 Loss: 0.155352
2023-01-01 05:54: Train Epoch 17: 327/634 Loss: 0.132215
2023-01-01 05:54: Train Epoch 17: 331/634 Loss: 0.144547
2023-01-01 05:54: Train Epoch 17: 335/634 Loss: 0.135032
2023-01-01 05:55: Train Epoch 17: 339/634 Loss: 0.163327
2023-01-01 05:55: Train Epoch 17: 343/634 Loss: 0.140504
2023-01-01 05:55: Train Epoch 17: 347/634 Loss: 0.133802
2023-01-01 05:55: Train Epoch 17: 351/634 Loss: 0.138027
2023-01-01 05:56: Train Epoch 17: 355/634 Loss: 0.139174
2023-01-01 05:56: Train Epoch 17: 359/634 Loss: 0.148049
2023-01-01 05:56: Train Epoch 17: 363/634 Loss: 0.166780
2023-01-01 05:56: Train Epoch 17: 367/634 Loss: 0.149162
2023-01-01 05:57: Train Epoch 17: 371/634 Loss: 0.159100
2023-01-01 05:57: Train Epoch 17: 375/634 Loss: 0.148839
2023-01-01 05:57: Train Epoch 17: 379/634 Loss: 0.145939
2023-01-01 05:57: Train Epoch 17: 383/634 Loss: 0.137421
2023-01-01 05:58: Train Epoch 17: 387/634 Loss: 0.134055
2023-01-01 05:58: Train Epoch 17: 391/634 Loss: 0.157567
2023-01-01 05:58: Train Epoch 17: 395/634 Loss: 0.154846
2023-01-01 05:58: Train Epoch 17: 399/634 Loss: 0.141567
2023-01-01 05:59: Train Epoch 17: 403/634 Loss: 0.144435
2023-01-01 05:59: Train Epoch 17: 407/634 Loss: 0.158798
2023-01-01 05:59: Train Epoch 17: 411/634 Loss: 0.145851
2023-01-01 05:59: Train Epoch 17: 415/634 Loss: 0.138693
2023-01-01 06:00: Train Epoch 17: 419/634 Loss: 0.139361
2023-01-01 06:00: Train Epoch 17: 423/634 Loss: 0.140035
2023-01-01 06:00: Train Epoch 17: 427/634 Loss: 0.131776
2023-01-01 06:01: Train Epoch 17: 431/634 Loss: 0.150452
2023-01-01 06:01: Train Epoch 17: 435/634 Loss: 0.140521
2023-01-01 06:01: Train Epoch 17: 439/634 Loss: 0.150300
2023-01-01 06:01: Train Epoch 17: 443/634 Loss: 0.165901
2023-01-01 06:02: Train Epoch 17: 447/634 Loss: 0.122897
2023-01-01 06:02: Train Epoch 17: 451/634 Loss: 0.159133
2023-01-01 06:02: Train Epoch 17: 455/634 Loss: 0.168413
2023-01-01 06:02: Train Epoch 17: 459/634 Loss: 0.157077
2023-01-01 06:03: Train Epoch 17: 463/634 Loss: 0.130016
2023-01-01 06:03: Train Epoch 17: 467/634 Loss: 0.142911
2023-01-01 06:03: Train Epoch 17: 471/634 Loss: 0.150789
2023-01-01 06:03: Train Epoch 17: 475/634 Loss: 0.135083
2023-01-01 06:04: Train Epoch 17: 479/634 Loss: 0.149117
2023-01-01 06:04: Train Epoch 17: 483/634 Loss: 0.133143
2023-01-01 06:04: Train Epoch 17: 487/634 Loss: 0.141211
2023-01-01 06:04: Train Epoch 17: 491/634 Loss: 0.148808
2023-01-01 06:05: Train Epoch 17: 495/634 Loss: 0.171454
2023-01-01 06:05: Train Epoch 17: 499/634 Loss: 0.153104
2023-01-01 06:05: Train Epoch 17: 503/634 Loss: 0.156895
2023-01-01 06:05: Train Epoch 17: 507/634 Loss: 0.138645
2023-01-01 06:06: Train Epoch 17: 511/634 Loss: 0.138784
2023-01-01 06:06: Train Epoch 17: 515/634 Loss: 0.149876
2023-01-01 06:06: Train Epoch 17: 519/634 Loss: 0.163898
2023-01-01 06:06: Train Epoch 17: 523/634 Loss: 0.135604
2023-01-01 06:07: Train Epoch 17: 527/634 Loss: 0.133231
2023-01-01 06:07: Train Epoch 17: 531/634 Loss: 0.157975
2023-01-01 06:07: Train Epoch 17: 535/634 Loss: 0.131784
2023-01-01 06:07: Train Epoch 17: 539/634 Loss: 0.147072
2023-01-01 06:08: Train Epoch 17: 543/634 Loss: 0.145854
2023-01-01 06:08: Train Epoch 17: 547/634 Loss: 0.130217
2023-01-01 06:08: Train Epoch 17: 551/634 Loss: 0.150004
2023-01-01 06:08: Train Epoch 17: 555/634 Loss: 0.127986
2023-01-01 06:09: Train Epoch 17: 559/634 Loss: 0.134291
2023-01-01 06:09: Train Epoch 17: 563/634 Loss: 0.152356
2023-01-01 06:09: Train Epoch 17: 567/634 Loss: 0.137495
2023-01-01 06:09: Train Epoch 17: 571/634 Loss: 0.143481
2023-01-01 06:10: Train Epoch 17: 575/634 Loss: 0.154114
2023-01-01 06:10: Train Epoch 17: 579/634 Loss: 0.169861
2023-01-01 06:10: Train Epoch 17: 583/634 Loss: 0.135502
2023-01-01 06:10: Train Epoch 17: 587/634 Loss: 0.140558
2023-01-01 06:11: Train Epoch 17: 591/634 Loss: 0.121132
2023-01-01 06:11: Train Epoch 17: 595/634 Loss: 0.151036
2023-01-01 06:11: Train Epoch 17: 599/634 Loss: 0.152650
2023-01-01 06:11: Train Epoch 17: 603/634 Loss: 0.156027
2023-01-01 06:12: Train Epoch 17: 607/634 Loss: 0.146787
2023-01-01 06:12: Train Epoch 17: 611/634 Loss: 0.116403
2023-01-01 06:12: Train Epoch 17: 615/634 Loss: 0.148304
2023-01-01 06:12: Train Epoch 17: 619/634 Loss: 0.164059
2023-01-01 06:13: Train Epoch 17: 623/634 Loss: 0.162491
2023-01-01 06:13: Train Epoch 17: 627/634 Loss: 0.155526
2023-01-01 06:13: Train Epoch 17: 631/634 Loss: 0.165315
2023-01-01 06:13: Train Epoch 17: 633/634 Loss: 0.045416
2023-01-01 06:13: **********Train Epoch 17: averaged Loss: 0.146553 
2023-01-01 06:13: 
Epoch time elapsed: 2437.8923637866974

2023-01-01 06:15: 
 metrics validation: {'precision': 0.8748882931188561, 'recall': 0.7530769230769231, 'f1-score': 0.8094253823894172, 'support': 1300, 'AUC': 0.9451047337278106, 'AUCPR': 0.8940192489463646, 'TP': 979, 'FP': 140, 'TN': 2460, 'FN': 321} 

2023-01-01 06:15: **********Val Epoch 17: average Loss: 0.141553
2023-01-01 06:15: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-01 06:15: Total training time: 807.2245min, best loss: 0.133880
2023-01-01 06:15: Saving current best model to /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123116475666372054013/best_model.pth
2023-01-01 06:16: 
 Testing metrics {'precision': 0.8269230769230769, 'recall': 0.7353420195439739, 'f1-score': 0.778448275862069, 'support': 1228, 'AUC': 0.9259564425086739, 'AUCPR': 0.8821838707655952, 'TP': 903, 'FP': 189, 'TN': 2267, 'FN': 325} 

2023-01-01 06:20: 
 Testing metrics {'precision': 0.8794449262792715, 'recall': 0.9203539823008849, 'f1-score': 0.8994345271094356, 'support': 4407, 'AUC': 0.9798750610723115, 'AUCPR': 0.9619710816950665, 'TP': 4056, 'FP': 556, 'TN': 8258, 'FN': 351} 

