2022-12-31 10:14: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123110145043936554013
2022-12-31 10:14: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123110145043936554013
2022-12-31 10:14: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123110145043936554013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=128, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-31 10:14: Argument batch_size: 256
2022-12-31 10:14: Argument clc: 'vec'
2022-12-31 10:14: Argument cuda: True
2022-12-31 10:14: Argument dataset: '2020'
2022-12-31 10:14: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-31 10:14: Argument debug: False
2022-12-31 10:14: Argument default_graph: True
2022-12-31 10:14: Argument device: 'cpu'
2022-12-31 10:14: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-31 10:14: Argument early_stop: True
2022-12-31 10:14: Argument early_stop_patience: 8
2022-12-31 10:14: Argument embed_dim: 64
2022-12-31 10:14: Argument epochs: 30
2022-12-31 10:14: Argument grad_norm: False
2022-12-31 10:14: Argument horizon: 1
2022-12-31 10:14: Argument input_dim: 25
2022-12-31 10:14: Argument lag: 10
2022-12-31 10:14: Argument link_len: 2
2022-12-31 10:14: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123110145043936554013'
2022-12-31 10:14: Argument log_step: 1
2022-12-31 10:14: Argument loss_func: 'nllloss'
2022-12-31 10:14: Argument lr_decay: True
2022-12-31 10:14: Argument lr_decay_rate: 0.1
2022-12-31 10:14: Argument lr_decay_step: '15, 20'
2022-12-31 10:14: Argument lr_init: 0.0001
2022-12-31 10:14: Argument max_grad_norm: 5
2022-12-31 10:14: Argument minbatch_size: 64
2022-12-31 10:14: Argument mode: 'train'
2022-12-31 10:14: Argument model: 'fire_GCN'
2022-12-31 10:14: Argument nan_fill: -1.0
2022-12-31 10:14: Argument num_layers: 1
2022-12-31 10:14: Argument num_nodes: 625
2022-12-31 10:14: Argument num_workers: 12
2022-12-31 10:14: Argument output_dim: 2
2022-12-31 10:14: Argument patch_height: 25
2022-12-31 10:14: Argument patch_width: 25
2022-12-31 10:14: Argument persistent_workers: True
2022-12-31 10:14: Argument pin_memory: True
2022-12-31 10:14: Argument plot: False
2022-12-31 10:14: Argument positive_weight: 0.5
2022-12-31 10:14: Argument prefetch_factor: 2
2022-12-31 10:14: Argument real_value: True
2022-12-31 10:14: Argument rnn_units: 128
2022-12-31 10:14: Argument seed: 10000
2022-12-31 10:14: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-31 10:14: Argument teacher_forcing: False
2022-12-31 10:14: Argument weight_decay: 0.0
2022-12-31 10:14: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([64, 2, 153, 128]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 128]) True
encoder.cell_list.0.gate.bias_pool torch.Size([64, 256]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([64, 2, 153, 64]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 64]) True
encoder.cell_list.0.update.bias_pool torch.Size([64, 128]) True
encoder.cell_list.0.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 80000]) True
fc1.bias torch.Size([2]) True
Total params num: 3997064
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123110145043936554013/run.log
2022-12-31 10:15: Train Epoch 1: 3/634 Loss: 0.315737
2022-12-31 10:15: Train Epoch 1: 7/634 Loss: 3.934291
2022-12-31 10:16: Train Epoch 1: 11/634 Loss: 1.125355
2022-12-31 10:16: Train Epoch 1: 15/634 Loss: 1.426885
2022-12-31 10:17: Train Epoch 1: 19/634 Loss: 1.481072
2022-12-31 10:17: Train Epoch 1: 23/634 Loss: 0.617889
2022-12-31 10:18: Train Epoch 1: 27/634 Loss: 0.429067
2022-12-31 10:18: Train Epoch 1: 31/634 Loss: 0.618235
2022-12-31 10:19: Train Epoch 1: 35/634 Loss: 0.642204
2022-12-31 10:19: Train Epoch 1: 39/634 Loss: 0.298448
2022-12-31 10:20: Train Epoch 1: 43/634 Loss: 0.355207
2022-12-31 10:20: Train Epoch 1: 47/634 Loss: 0.505307
2022-12-31 10:21: Train Epoch 1: 51/634 Loss: 0.450939
2022-12-31 10:21: Train Epoch 1: 55/634 Loss: 0.354594
2022-12-31 10:22: Train Epoch 1: 59/634 Loss: 0.316406
2022-12-31 10:22: Train Epoch 1: 63/634 Loss: 0.385704
2022-12-31 10:23: Train Epoch 1: 67/634 Loss: 0.441737
2022-12-31 10:23: Train Epoch 1: 71/634 Loss: 0.361532
2022-12-31 10:24: Train Epoch 1: 75/634 Loss: 0.300926
2022-12-31 10:24: Train Epoch 1: 79/634 Loss: 0.310622
2022-12-31 10:25: Train Epoch 1: 83/634 Loss: 0.326213
2022-12-31 10:25: Train Epoch 1: 87/634 Loss: 0.326389
2022-12-31 10:26: Train Epoch 1: 91/634 Loss: 0.214496
2022-12-31 10:26: Train Epoch 1: 95/634 Loss: 0.301293
2022-12-31 10:27: Train Epoch 1: 99/634 Loss: 0.335687
2022-12-31 10:27: Train Epoch 1: 103/634 Loss: 0.314963
2022-12-31 10:28: Train Epoch 1: 107/634 Loss: 0.250781
2022-12-31 10:28: Train Epoch 1: 111/634 Loss: 0.275063
2022-12-31 10:29: Train Epoch 1: 115/634 Loss: 0.242868
2022-12-31 10:29: Train Epoch 1: 119/634 Loss: 0.274303
2022-12-31 10:30: Train Epoch 1: 123/634 Loss: 0.277879
2022-12-31 10:30: Train Epoch 1: 127/634 Loss: 0.197092
2022-12-31 10:31: Train Epoch 1: 131/634 Loss: 0.231369
2022-12-31 10:31: Train Epoch 1: 135/634 Loss: 0.242929
2022-12-31 10:32: Train Epoch 1: 139/634 Loss: 0.248341
2022-12-31 10:32: Train Epoch 1: 143/634 Loss: 0.236700
2022-12-31 10:33: Train Epoch 1: 147/634 Loss: 0.221630
2022-12-31 10:33: Train Epoch 1: 151/634 Loss: 0.233404
2022-12-31 10:34: Train Epoch 1: 155/634 Loss: 0.239680
2022-12-31 10:34: Train Epoch 1: 159/634 Loss: 0.220910
2022-12-31 10:35: Train Epoch 1: 163/634 Loss: 0.247201
2022-12-31 10:35: Train Epoch 1: 167/634 Loss: 0.240630
2022-12-31 10:36: Train Epoch 1: 171/634 Loss: 0.210105
2022-12-31 10:36: Train Epoch 1: 175/634 Loss: 0.222043
2022-12-31 10:37: Train Epoch 1: 179/634 Loss: 0.213962
2022-12-31 10:37: Train Epoch 1: 183/634 Loss: 0.215679
2022-12-31 10:38: Train Epoch 1: 187/634 Loss: 0.188807
2022-12-31 10:38: Train Epoch 1: 191/634 Loss: 0.218126
2022-12-31 10:39: Train Epoch 1: 195/634 Loss: 0.231270
2022-12-31 10:39: Train Epoch 1: 199/634 Loss: 0.234834
2022-12-31 10:40: Train Epoch 1: 203/634 Loss: 0.207665
2022-12-31 10:40: Train Epoch 1: 207/634 Loss: 0.225819
2022-12-31 10:41: Train Epoch 1: 211/634 Loss: 0.195434
2022-12-31 10:41: Train Epoch 1: 215/634 Loss: 0.199846
2022-12-31 10:42: Train Epoch 1: 219/634 Loss: 0.267301
2022-12-31 10:42: Train Epoch 1: 223/634 Loss: 0.215489
2022-12-31 10:43: Train Epoch 1: 227/634 Loss: 0.206594
2022-12-31 10:43: Train Epoch 1: 231/634 Loss: 0.220634
2022-12-31 10:44: Train Epoch 1: 235/634 Loss: 0.227837
2022-12-31 10:44: Train Epoch 1: 239/634 Loss: 0.228872
2022-12-31 10:44: Train Epoch 1: 243/634 Loss: 0.260566
2022-12-31 10:45: Train Epoch 1: 247/634 Loss: 0.231892
2022-12-31 10:46: Train Epoch 1: 251/634 Loss: 0.204640
2022-12-31 10:46: Train Epoch 1: 255/634 Loss: 0.216031
2022-12-31 10:47: Train Epoch 1: 259/634 Loss: 0.208183
2022-12-31 10:47: Train Epoch 1: 263/634 Loss: 0.213310
2022-12-31 10:48: Train Epoch 1: 267/634 Loss: 0.248477
2022-12-31 10:48: Train Epoch 1: 271/634 Loss: 0.209694
2022-12-31 10:48: Train Epoch 1: 275/634 Loss: 0.228740
2022-12-31 10:49: Train Epoch 1: 279/634 Loss: 0.204992
2022-12-31 10:49: Train Epoch 1: 283/634 Loss: 0.183004
2022-12-31 10:50: Train Epoch 1: 287/634 Loss: 0.232753
2022-12-31 10:50: Train Epoch 1: 291/634 Loss: 0.197703
2022-12-31 10:51: Train Epoch 1: 295/634 Loss: 0.254590
2022-12-31 10:51: Train Epoch 1: 299/634 Loss: 0.197703
2022-12-31 10:52: Train Epoch 1: 303/634 Loss: 0.206016
2022-12-31 10:52: Train Epoch 1: 307/634 Loss: 0.186033
2022-12-31 10:53: Train Epoch 1: 311/634 Loss: 0.207691
2022-12-31 10:53: Train Epoch 1: 315/634 Loss: 0.214972
2022-12-31 10:54: Train Epoch 1: 319/634 Loss: 0.200059
2022-12-31 10:54: Train Epoch 1: 323/634 Loss: 0.197728
2022-12-31 10:55: Train Epoch 1: 327/634 Loss: 0.202577
2022-12-31 10:55: Train Epoch 1: 331/634 Loss: 0.184446
2022-12-31 10:56: Train Epoch 1: 335/634 Loss: 0.186281
2022-12-31 10:56: Train Epoch 1: 339/634 Loss: 0.208155
2022-12-31 10:57: Train Epoch 1: 343/634 Loss: 0.166668
2022-12-31 10:57: Train Epoch 1: 347/634 Loss: 0.229723
2022-12-31 10:58: Train Epoch 1: 351/634 Loss: 0.170058
2022-12-31 10:58: Train Epoch 1: 355/634 Loss: 0.224811
2022-12-31 10:58: Train Epoch 1: 359/634 Loss: 0.250703
2022-12-31 10:59: Train Epoch 1: 363/634 Loss: 0.196816
2022-12-31 10:59: Train Epoch 1: 367/634 Loss: 0.218401
2022-12-31 11:00: Train Epoch 1: 371/634 Loss: 0.204773
2022-12-31 11:00: Train Epoch 1: 375/634 Loss: 0.206408
2022-12-31 11:01: Train Epoch 1: 379/634 Loss: 0.204010
2022-12-31 11:01: Train Epoch 1: 383/634 Loss: 0.233097
2022-12-31 11:02: Train Epoch 1: 387/634 Loss: 0.224598
2022-12-31 11:02: Train Epoch 1: 391/634 Loss: 0.211650
2022-12-31 11:03: Train Epoch 1: 395/634 Loss: 0.212684
2022-12-31 11:03: Train Epoch 1: 399/634 Loss: 0.201426
2022-12-31 11:04: Train Epoch 1: 403/634 Loss: 0.191038
2022-12-31 11:04: Train Epoch 1: 407/634 Loss: 0.219732
2022-12-31 11:05: Train Epoch 1: 411/634 Loss: 0.202206
2022-12-31 11:05: Train Epoch 1: 415/634 Loss: 0.219022
2022-12-31 11:06: Train Epoch 1: 419/634 Loss: 0.227993
2022-12-31 11:06: Train Epoch 1: 423/634 Loss: 0.196698
2022-12-31 11:07: Train Epoch 1: 427/634 Loss: 0.221073
2022-12-31 11:07: Train Epoch 1: 431/634 Loss: 0.213878
2022-12-31 11:08: Train Epoch 1: 435/634 Loss: 0.202558
2022-12-31 11:08: Train Epoch 1: 439/634 Loss: 0.203461
2022-12-31 11:09: Train Epoch 1: 443/634 Loss: 0.183008
2022-12-31 11:09: Train Epoch 1: 447/634 Loss: 0.208132
2022-12-31 11:10: Train Epoch 1: 451/634 Loss: 0.231076
2022-12-31 11:10: Train Epoch 1: 455/634 Loss: 0.211609
2022-12-31 11:11: Train Epoch 1: 459/634 Loss: 0.176938
2022-12-31 11:11: Train Epoch 1: 463/634 Loss: 0.221926
2022-12-31 11:12: Train Epoch 1: 467/634 Loss: 0.215951
2022-12-31 11:12: Train Epoch 1: 471/634 Loss: 0.198108
2022-12-31 11:13: Train Epoch 1: 475/634 Loss: 0.213566
2022-12-31 11:13: Train Epoch 1: 479/634 Loss: 0.220495
2022-12-31 11:14: Train Epoch 1: 483/634 Loss: 0.192337
2022-12-31 11:14: Train Epoch 1: 487/634 Loss: 0.218652
2022-12-31 11:15: Train Epoch 1: 491/634 Loss: 0.214092
2022-12-31 11:15: Train Epoch 1: 495/634 Loss: 0.189896
2022-12-31 11:16: Train Epoch 1: 499/634 Loss: 0.208539
2022-12-31 11:16: Train Epoch 1: 503/634 Loss: 0.208534
2022-12-31 11:17: Train Epoch 1: 507/634 Loss: 0.247632
2022-12-31 11:17: Train Epoch 1: 511/634 Loss: 0.184163
2022-12-31 11:18: Train Epoch 1: 515/634 Loss: 0.231094
2022-12-31 11:18: Train Epoch 1: 519/634 Loss: 0.189912
2022-12-31 11:19: Train Epoch 1: 523/634 Loss: 0.191454
2022-12-31 11:19: Train Epoch 1: 527/634 Loss: 0.201825
2022-12-31 11:20: Train Epoch 1: 531/634 Loss: 0.212068
2022-12-31 11:20: Train Epoch 1: 535/634 Loss: 0.225387
2022-12-31 11:21: Train Epoch 1: 539/634 Loss: 0.182441
2022-12-31 11:21: Train Epoch 1: 543/634 Loss: 0.209226
2022-12-31 11:22: Train Epoch 1: 547/634 Loss: 0.190617
2022-12-31 11:22: Train Epoch 1: 551/634 Loss: 0.178792
2022-12-31 11:23: Train Epoch 1: 555/634 Loss: 0.219789
2022-12-31 11:23: Train Epoch 1: 559/634 Loss: 0.229918
2022-12-31 11:24: Train Epoch 1: 563/634 Loss: 0.210825
2022-12-31 11:24: Train Epoch 1: 567/634 Loss: 0.210051
2022-12-31 11:25: Train Epoch 1: 571/634 Loss: 0.205150
2022-12-31 11:26: Train Epoch 1: 575/634 Loss: 0.207361
2022-12-31 11:26: Train Epoch 1: 579/634 Loss: 0.207499
2022-12-31 11:27: Train Epoch 1: 583/634 Loss: 0.180485
2022-12-31 11:27: Train Epoch 1: 587/634 Loss: 0.180858
2022-12-31 11:28: Train Epoch 1: 591/634 Loss: 0.208437
2022-12-31 11:28: Train Epoch 1: 595/634 Loss: 0.179185
2022-12-31 11:29: Train Epoch 1: 599/634 Loss: 0.175660
2022-12-31 11:29: Train Epoch 1: 603/634 Loss: 0.214398
2022-12-31 11:30: Train Epoch 1: 607/634 Loss: 0.207624
2022-12-31 11:30: Train Epoch 1: 611/634 Loss: 0.188065
2022-12-31 11:31: Train Epoch 1: 615/634 Loss: 0.181262
2022-12-31 11:31: Train Epoch 1: 619/634 Loss: 0.200259
2022-12-31 11:32: Train Epoch 1: 623/634 Loss: 0.211239
2022-12-31 11:32: Train Epoch 1: 627/634 Loss: 0.178982
2022-12-31 11:33: Train Epoch 1: 631/634 Loss: 0.207804
2022-12-31 11:33: Train Epoch 1: 633/634 Loss: 0.084451
2022-12-31 11:33: **********Train Epoch 1: averaged Loss: 0.281062 
2022-12-31 11:33: 
Epoch time elapsed: 4721.451344251633

2022-12-31 11:35: 
 metrics validation: {'precision': 0.7459605026929982, 'recall': 0.6392307692307693, 'f1-score': 0.6884838442419222, 'support': 1300, 'AUC': 0.8275559171597633, 'AUCPR': 0.7325295686715213, 'TP': 831, 'FP': 283, 'TN': 2317, 'FN': 469} 

2022-12-31 11:35: **********Val Epoch 1: average Loss: 0.241720
2022-12-31 11:35: *********************************Current best model saved!
2022-12-31 11:37: 
 Testing metrics {'precision': 0.7862281603288798, 'recall': 0.6229641693811075, 'f1-score': 0.6951385733757384, 'support': 1228, 'AUC': 0.8609414954004817, 'AUCPR': 0.7871210481262629, 'TP': 765, 'FP': 208, 'TN': 2248, 'FN': 463} 

2022-12-31 11:44: 
 Testing metrics {'precision': 0.8958711433756806, 'recall': 0.8960744270478784, 'f1-score': 0.8959727736812252, 'support': 4407, 'AUC': 0.9712932460060419, 'AUCPR': 0.9504155664933184, 'TP': 3949, 'FP': 459, 'TN': 8355, 'FN': 458} 

2022-12-31 11:45: Train Epoch 2: 3/634 Loss: 0.164963
2022-12-31 11:46: Train Epoch 2: 7/634 Loss: 0.213358
2022-12-31 11:46: Train Epoch 2: 11/634 Loss: 0.212038
2022-12-31 11:47: Train Epoch 2: 15/634 Loss: 0.194729
2022-12-31 11:48: Train Epoch 2: 19/634 Loss: 0.184672
2022-12-31 11:48: Train Epoch 2: 23/634 Loss: 0.191108
2022-12-31 11:49: Train Epoch 2: 27/634 Loss: 0.207158
2022-12-31 11:50: Train Epoch 2: 31/634 Loss: 0.178818
2022-12-31 11:50: Train Epoch 2: 35/634 Loss: 0.193178
2022-12-31 11:51: Train Epoch 2: 39/634 Loss: 0.180140
2022-12-31 11:52: Train Epoch 2: 43/634 Loss: 0.183958
2022-12-31 11:52: Train Epoch 2: 47/634 Loss: 0.229446
2022-12-31 11:53: Train Epoch 2: 51/634 Loss: 0.211689
2022-12-31 11:54: Train Epoch 2: 55/634 Loss: 0.209238
2022-12-31 11:54: Train Epoch 2: 59/634 Loss: 0.183403
2022-12-31 11:55: Train Epoch 2: 63/634 Loss: 0.181402
2022-12-31 11:56: Train Epoch 2: 67/634 Loss: 0.214504
2022-12-31 11:56: Train Epoch 2: 71/634 Loss: 0.211103
2022-12-31 11:57: Train Epoch 2: 75/634 Loss: 0.213246
2022-12-31 11:58: Train Epoch 2: 79/634 Loss: 0.243534
2022-12-31 11:58: Train Epoch 2: 83/634 Loss: 0.214683
2022-12-31 11:59: Train Epoch 2: 87/634 Loss: 0.215280
2022-12-31 12:00: Train Epoch 2: 91/634 Loss: 0.202157
2022-12-31 12:00: Train Epoch 2: 95/634 Loss: 0.168639
2022-12-31 12:01: Train Epoch 2: 99/634 Loss: 0.241100
2022-12-31 12:02: Train Epoch 2: 103/634 Loss: 0.211177
2022-12-31 12:02: Train Epoch 2: 107/634 Loss: 0.182352
2022-12-31 12:03: Train Epoch 2: 111/634 Loss: 0.225597
2022-12-31 12:04: Train Epoch 2: 115/634 Loss: 0.216986
2022-12-31 12:04: Train Epoch 2: 119/634 Loss: 0.213070
2022-12-31 12:05: Train Epoch 2: 123/634 Loss: 0.199360
2022-12-31 12:06: Train Epoch 2: 127/634 Loss: 0.219488
2022-12-31 12:06: Train Epoch 2: 131/634 Loss: 0.195041
2022-12-31 12:07: Train Epoch 2: 135/634 Loss: 0.192910
2022-12-31 12:08: Train Epoch 2: 139/634 Loss: 0.200087
2022-12-31 12:08: Train Epoch 2: 143/634 Loss: 0.242845
2022-12-31 12:09: Train Epoch 2: 147/634 Loss: 0.208168
2022-12-31 12:10: Train Epoch 2: 151/634 Loss: 0.198818
2022-12-31 12:10: Train Epoch 2: 155/634 Loss: 0.224620
2022-12-31 12:11: Train Epoch 2: 159/634 Loss: 0.202631
2022-12-31 12:12: Train Epoch 2: 163/634 Loss: 0.206455
2022-12-31 12:12: Train Epoch 2: 167/634 Loss: 0.191892
2022-12-31 12:13: Train Epoch 2: 171/634 Loss: 0.179882
2022-12-31 12:14: Train Epoch 2: 175/634 Loss: 0.212586
2022-12-31 12:14: Train Epoch 2: 179/634 Loss: 0.204842
2022-12-31 12:15: Train Epoch 2: 183/634 Loss: 0.195089
2022-12-31 12:16: Train Epoch 2: 187/634 Loss: 0.184692
2022-12-31 12:17: Train Epoch 2: 191/634 Loss: 0.175868
2022-12-31 12:17: Train Epoch 2: 195/634 Loss: 0.221618
2022-12-31 12:18: Train Epoch 2: 199/634 Loss: 0.194287
2022-12-31 12:19: Train Epoch 2: 203/634 Loss: 0.179631
2022-12-31 12:19: Train Epoch 2: 207/634 Loss: 0.182272
2022-12-31 12:20: Train Epoch 2: 211/634 Loss: 0.229348
2022-12-31 12:21: Train Epoch 2: 215/634 Loss: 0.189513
2022-12-31 12:21: Train Epoch 2: 219/634 Loss: 0.180716
2022-12-31 12:22: Train Epoch 2: 223/634 Loss: 0.211186
2022-12-31 12:23: Train Epoch 2: 227/634 Loss: 0.216055
2022-12-31 12:23: Train Epoch 2: 231/634 Loss: 0.204945
2022-12-31 12:24: Train Epoch 2: 235/634 Loss: 0.225306
2022-12-31 12:25: Train Epoch 2: 239/634 Loss: 0.174439
2022-12-31 12:25: Train Epoch 2: 243/634 Loss: 0.231681
2022-12-31 12:26: Train Epoch 2: 247/634 Loss: 0.198632
2022-12-31 12:27: Train Epoch 2: 251/634 Loss: 0.212019
2022-12-31 12:27: Train Epoch 2: 255/634 Loss: 0.219624
2022-12-31 12:28: Train Epoch 2: 259/634 Loss: 0.215334
2022-12-31 12:29: Train Epoch 2: 263/634 Loss: 0.213664
2022-12-31 12:29: Train Epoch 2: 267/634 Loss: 0.192449
2022-12-31 12:30: Train Epoch 2: 271/634 Loss: 0.193038
2022-12-31 12:31: Train Epoch 2: 275/634 Loss: 0.202857
2022-12-31 12:31: Train Epoch 2: 279/634 Loss: 0.187986
2022-12-31 12:32: Train Epoch 2: 283/634 Loss: 0.196011
2022-12-31 12:33: Train Epoch 2: 287/634 Loss: 0.210260
2022-12-31 12:33: Train Epoch 2: 291/634 Loss: 0.212307
2022-12-31 12:34: Train Epoch 2: 295/634 Loss: 0.167062
2022-12-31 12:35: Train Epoch 2: 299/634 Loss: 0.214325
2022-12-31 12:35: Train Epoch 2: 303/634 Loss: 0.201292
2022-12-31 12:36: Train Epoch 2: 307/634 Loss: 0.213140
2022-12-31 12:37: Train Epoch 2: 311/634 Loss: 0.197021
2022-12-31 12:37: Train Epoch 2: 315/634 Loss: 0.211567
2022-12-31 12:38: Train Epoch 2: 319/634 Loss: 0.185269
2022-12-31 12:39: Train Epoch 2: 323/634 Loss: 0.195620
2022-12-31 12:39: Train Epoch 2: 327/634 Loss: 0.246412
2022-12-31 12:40: Train Epoch 2: 331/634 Loss: 0.161690
2022-12-31 12:41: Train Epoch 2: 335/634 Loss: 0.239369
2022-12-31 12:41: Train Epoch 2: 339/634 Loss: 0.185133
2022-12-31 12:42: Train Epoch 2: 343/634 Loss: 0.201000
2022-12-31 12:43: Train Epoch 2: 347/634 Loss: 0.234474
2022-12-31 12:43: Train Epoch 2: 351/634 Loss: 0.210452
2022-12-31 12:44: Train Epoch 2: 355/634 Loss: 0.213792
2022-12-31 12:45: Train Epoch 2: 359/634 Loss: 0.231201
2022-12-31 12:45: Train Epoch 2: 363/634 Loss: 0.189722
2022-12-31 12:46: Train Epoch 2: 367/634 Loss: 0.308480
2022-12-31 12:47: Train Epoch 2: 371/634 Loss: 0.297453
2022-12-31 12:47: Train Epoch 2: 375/634 Loss: 0.186744
2022-12-31 12:48: Train Epoch 2: 379/634 Loss: 0.220233
2022-12-31 12:49: Train Epoch 2: 383/634 Loss: 0.178541
2022-12-31 12:49: Train Epoch 2: 387/634 Loss: 0.177000
2022-12-31 12:50: Train Epoch 2: 391/634 Loss: 0.216951
2022-12-31 12:51: Train Epoch 2: 395/634 Loss: 0.242671
2022-12-31 12:51: Train Epoch 2: 399/634 Loss: 0.182156
2022-12-31 12:52: Train Epoch 2: 403/634 Loss: 0.202779
2022-12-31 12:53: Train Epoch 2: 407/634 Loss: 0.206668
2022-12-31 12:53: Train Epoch 2: 411/634 Loss: 0.223643
2022-12-31 12:54: Train Epoch 2: 415/634 Loss: 0.177265
2022-12-31 12:55: Train Epoch 2: 419/634 Loss: 0.200724
2022-12-31 12:56: Train Epoch 2: 423/634 Loss: 0.221454
2022-12-31 12:56: Train Epoch 2: 427/634 Loss: 0.195054
2022-12-31 12:57: Train Epoch 2: 431/634 Loss: 0.200966
2022-12-31 12:58: Train Epoch 2: 435/634 Loss: 0.198531
2022-12-31 12:58: Train Epoch 2: 439/634 Loss: 0.187729
2022-12-31 12:59: Train Epoch 2: 443/634 Loss: 0.189273
2022-12-31 13:00: Train Epoch 2: 447/634 Loss: 0.184599
2022-12-31 13:01: Train Epoch 2: 451/634 Loss: 0.212929
2022-12-31 13:01: Train Epoch 2: 455/634 Loss: 0.195084
2022-12-31 13:02: Train Epoch 2: 459/634 Loss: 0.181779
2022-12-31 13:03: Train Epoch 2: 463/634 Loss: 0.187034
2022-12-31 13:03: Train Epoch 2: 467/634 Loss: 0.179423
2022-12-31 13:04: Train Epoch 2: 471/634 Loss: 0.186324
2022-12-31 13:05: Train Epoch 2: 475/634 Loss: 0.202738
2022-12-31 13:06: Train Epoch 2: 479/634 Loss: 0.206059
2022-12-31 13:06: Train Epoch 2: 483/634 Loss: 0.164187
2022-12-31 13:07: Train Epoch 2: 487/634 Loss: 0.171455
2022-12-31 13:07: Train Epoch 2: 491/634 Loss: 0.187837
2022-12-31 13:08: Train Epoch 2: 495/634 Loss: 0.213723
2022-12-31 13:08: Train Epoch 2: 499/634 Loss: 0.199302
2022-12-31 13:09: Train Epoch 2: 503/634 Loss: 0.191985
2022-12-31 13:10: Train Epoch 2: 507/634 Loss: 0.158902
2022-12-31 13:10: Train Epoch 2: 511/634 Loss: 0.200643
2022-12-31 13:11: Train Epoch 2: 515/634 Loss: 0.176565
2022-12-31 13:11: Train Epoch 2: 519/634 Loss: 0.181001
2022-12-31 13:12: Train Epoch 2: 523/634 Loss: 0.212469
2022-12-31 13:12: Train Epoch 2: 527/634 Loss: 0.194560
2022-12-31 13:13: Train Epoch 2: 531/634 Loss: 0.210027
2022-12-31 13:13: Train Epoch 2: 535/634 Loss: 0.176511
2022-12-31 13:14: Train Epoch 2: 539/634 Loss: 0.183954
2022-12-31 13:14: Train Epoch 2: 543/634 Loss: 0.195002
2022-12-31 13:15: Train Epoch 2: 547/634 Loss: 0.209756
2022-12-31 13:16: Train Epoch 2: 551/634 Loss: 0.198526
2022-12-31 13:16: Train Epoch 2: 555/634 Loss: 0.157818
2022-12-31 13:17: Train Epoch 2: 559/634 Loss: 0.185612
2022-12-31 13:17: Train Epoch 2: 563/634 Loss: 0.209314
2022-12-31 13:18: Train Epoch 2: 567/634 Loss: 0.175490
2022-12-31 13:18: Train Epoch 2: 571/634 Loss: 0.179336
2022-12-31 13:19: Train Epoch 2: 575/634 Loss: 0.165914
2022-12-31 13:19: Train Epoch 2: 579/634 Loss: 0.201932
2022-12-31 13:20: Train Epoch 2: 583/634 Loss: 0.201442
2022-12-31 13:20: Train Epoch 2: 587/634 Loss: 0.199202
2022-12-31 13:21: Train Epoch 2: 591/634 Loss: 0.211143
2022-12-31 13:22: Train Epoch 2: 595/634 Loss: 0.190412
2022-12-31 13:22: Train Epoch 2: 599/634 Loss: 0.175986
2022-12-31 13:23: Train Epoch 2: 603/634 Loss: 0.200379
2022-12-31 13:23: Train Epoch 2: 607/634 Loss: 0.193088
2022-12-31 13:24: Train Epoch 2: 611/634 Loss: 0.209783
2022-12-31 13:24: Train Epoch 2: 615/634 Loss: 0.160731
2022-12-31 13:25: Train Epoch 2: 619/634 Loss: 0.185074
2022-12-31 13:25: Train Epoch 2: 623/634 Loss: 0.184552
2022-12-31 13:26: Train Epoch 2: 627/634 Loss: 0.202695
2022-12-31 13:26: Train Epoch 2: 631/634 Loss: 0.176872
2022-12-31 13:27: Train Epoch 2: 633/634 Loss: 0.081792
2022-12-31 13:27: **********Train Epoch 2: averaged Loss: 0.199666 
2022-12-31 13:27: 
Epoch time elapsed: 6134.991898536682

2022-12-31 13:29: 
 metrics validation: {'precision': 0.735387045813586, 'recall': 0.7161538461538461, 'f1-score': 0.7256430241621201, 'support': 1300, 'AUC': 0.853365976331361, 'AUCPR': 0.7652125391112876, 'TP': 931, 'FP': 335, 'TN': 2265, 'FN': 369} 

2022-12-31 13:29: **********Val Epoch 2: average Loss: 0.216286
2022-12-31 13:29: *********************************Current best model saved!
2022-12-31 13:31: 
 Testing metrics {'precision': 0.7929203539823009, 'recall': 0.7296416938110749, 'f1-score': 0.7599660729431722, 'support': 1228, 'AUC': 0.8786489113942855, 'AUCPR': 0.81780449747824, 'TP': 896, 'FP': 234, 'TN': 2222, 'FN': 332} 

2022-12-31 13:38: 
 Testing metrics {'precision': 0.8723902854708138, 'recall': 0.9292035398230089, 'f1-score': 0.8999011097681573, 'support': 4407, 'AUC': 0.9761907189240213, 'AUCPR': 0.9620778727324664, 'TP': 4095, 'FP': 599, 'TN': 8215, 'FN': 312} 

2022-12-31 13:39: Train Epoch 3: 3/634 Loss: 0.191537
2022-12-31 13:39: Train Epoch 3: 7/634 Loss: 0.180284
2022-12-31 13:40: Train Epoch 3: 11/634 Loss: 0.155971
2022-12-31 13:40: Train Epoch 3: 15/634 Loss: 0.173577
2022-12-31 13:41: Train Epoch 3: 19/634 Loss: 0.171360
2022-12-31 13:41: Train Epoch 3: 23/634 Loss: 0.220768
2022-12-31 13:42: Train Epoch 3: 27/634 Loss: 0.198397
2022-12-31 13:42: Train Epoch 3: 31/634 Loss: 0.209555
2022-12-31 13:43: Train Epoch 3: 35/634 Loss: 0.200421
2022-12-31 13:44: Train Epoch 3: 39/634 Loss: 0.188916
2022-12-31 13:44: Train Epoch 3: 43/634 Loss: 0.200844
2022-12-31 13:45: Train Epoch 3: 47/634 Loss: 0.202497
2022-12-31 13:45: Train Epoch 3: 51/634 Loss: 0.160172
2022-12-31 13:46: Train Epoch 3: 55/634 Loss: 0.170090
2022-12-31 13:46: Train Epoch 3: 59/634 Loss: 0.172353
2022-12-31 13:47: Train Epoch 3: 63/634 Loss: 0.208935
2022-12-31 13:47: Train Epoch 3: 67/634 Loss: 0.158916
2022-12-31 13:48: Train Epoch 3: 71/634 Loss: 0.189173
2022-12-31 13:49: Train Epoch 3: 75/634 Loss: 0.177871
2022-12-31 13:49: Train Epoch 3: 79/634 Loss: 0.166700
2022-12-31 13:50: Train Epoch 3: 83/634 Loss: 0.191349
2022-12-31 13:50: Train Epoch 3: 87/634 Loss: 0.215898
2022-12-31 13:51: Train Epoch 3: 91/634 Loss: 0.199390
2022-12-31 13:51: Train Epoch 3: 95/634 Loss: 0.193469
2022-12-31 13:52: Train Epoch 3: 99/634 Loss: 0.190182
2022-12-31 13:53: Train Epoch 3: 103/634 Loss: 0.152004
2022-12-31 13:53: Train Epoch 3: 107/634 Loss: 0.190728
2022-12-31 13:54: Train Epoch 3: 111/634 Loss: 0.187740
2022-12-31 13:54: Train Epoch 3: 115/634 Loss: 0.182332
2022-12-31 13:55: Train Epoch 3: 119/634 Loss: 0.177214
2022-12-31 13:55: Train Epoch 3: 123/634 Loss: 0.208649
2022-12-31 13:56: Train Epoch 3: 127/634 Loss: 0.188900
2022-12-31 13:56: Train Epoch 3: 131/634 Loss: 0.196712
2022-12-31 13:57: Train Epoch 3: 135/634 Loss: 0.218093
2022-12-31 13:58: Train Epoch 3: 139/634 Loss: 0.188074
2022-12-31 13:58: Train Epoch 3: 143/634 Loss: 0.157662
2022-12-31 13:59: Train Epoch 3: 147/634 Loss: 0.151311
2022-12-31 13:59: Train Epoch 3: 151/634 Loss: 0.205818
2022-12-31 14:00: Train Epoch 3: 155/634 Loss: 0.192559
2022-12-31 14:00: Train Epoch 3: 159/634 Loss: 0.179878
2022-12-31 14:01: Train Epoch 3: 163/634 Loss: 0.195219
2022-12-31 14:02: Train Epoch 3: 167/634 Loss: 0.198418
2022-12-31 14:02: Train Epoch 3: 171/634 Loss: 0.169488
2022-12-31 14:03: Train Epoch 3: 175/634 Loss: 0.167450
2022-12-31 14:03: Train Epoch 3: 179/634 Loss: 0.179868
2022-12-31 14:04: Train Epoch 3: 183/634 Loss: 0.203068
2022-12-31 14:04: Train Epoch 3: 187/634 Loss: 0.208755
2022-12-31 14:05: Train Epoch 3: 191/634 Loss: 0.179910
2022-12-31 14:06: Train Epoch 3: 195/634 Loss: 0.183288
2022-12-31 14:06: Train Epoch 3: 199/634 Loss: 0.215771
2022-12-31 14:07: Train Epoch 3: 203/634 Loss: 0.181227
2022-12-31 14:07: Train Epoch 3: 207/634 Loss: 0.168121
2022-12-31 14:08: Train Epoch 3: 211/634 Loss: 0.190356
2022-12-31 14:08: Train Epoch 3: 215/634 Loss: 0.224431
2022-12-31 14:09: Train Epoch 3: 219/634 Loss: 0.167852
2022-12-31 14:10: Train Epoch 3: 223/634 Loss: 0.204085
2022-12-31 14:10: Train Epoch 3: 227/634 Loss: 0.190670
2022-12-31 14:11: Train Epoch 3: 231/634 Loss: 0.172373
2022-12-31 14:11: Train Epoch 3: 235/634 Loss: 0.179081
2022-12-31 14:12: Train Epoch 3: 239/634 Loss: 0.173005
2022-12-31 14:13: Train Epoch 3: 243/634 Loss: 0.189790
2022-12-31 14:13: Train Epoch 3: 247/634 Loss: 0.178615
2022-12-31 14:14: Train Epoch 3: 251/634 Loss: 0.188794
2022-12-31 14:14: Train Epoch 3: 255/634 Loss: 0.233835
2022-12-31 14:15: Train Epoch 3: 259/634 Loss: 0.170678
2022-12-31 14:15: Train Epoch 3: 263/634 Loss: 0.203692
2022-12-31 14:16: Train Epoch 3: 267/634 Loss: 0.193224
2022-12-31 14:17: Train Epoch 3: 271/634 Loss: 0.212101
2022-12-31 14:17: Train Epoch 3: 275/634 Loss: 0.201955
2022-12-31 14:18: Train Epoch 3: 279/634 Loss: 0.185267
2022-12-31 14:18: Train Epoch 3: 283/634 Loss: 0.216826
2022-12-31 14:19: Train Epoch 3: 287/634 Loss: 0.200592
2022-12-31 14:19: Train Epoch 3: 291/634 Loss: 0.190524
2022-12-31 14:20: Train Epoch 3: 295/634 Loss: 0.199379
2022-12-31 14:21: Train Epoch 3: 299/634 Loss: 0.183079
2022-12-31 14:21: Train Epoch 3: 303/634 Loss: 0.157680
2022-12-31 14:22: Train Epoch 3: 307/634 Loss: 0.205128
2022-12-31 14:22: Train Epoch 3: 311/634 Loss: 0.202096
2022-12-31 14:23: Train Epoch 3: 315/634 Loss: 0.182182
2022-12-31 14:23: Train Epoch 3: 319/634 Loss: 0.173466
2022-12-31 14:24: Train Epoch 3: 323/634 Loss: 0.154004
2022-12-31 14:24: Train Epoch 3: 327/634 Loss: 0.196555
2022-12-31 14:25: Train Epoch 3: 331/634 Loss: 0.208464
2022-12-31 14:26: Train Epoch 3: 335/634 Loss: 0.186844
2022-12-31 14:26: Train Epoch 3: 339/634 Loss: 0.204117
2022-12-31 14:27: Train Epoch 3: 343/634 Loss: 0.211783
2022-12-31 14:27: Train Epoch 3: 347/634 Loss: 0.165383
2022-12-31 14:28: Train Epoch 3: 351/634 Loss: 0.217511
2022-12-31 14:28: Train Epoch 3: 355/634 Loss: 0.196191
2022-12-31 14:29: Train Epoch 3: 359/634 Loss: 0.159541
2022-12-31 14:30: Train Epoch 3: 363/634 Loss: 0.205236
2022-12-31 14:30: Train Epoch 3: 367/634 Loss: 0.172090
2022-12-31 14:31: Train Epoch 3: 371/634 Loss: 0.195775
2022-12-31 14:31: Train Epoch 3: 375/634 Loss: 0.163547
2022-12-31 14:32: Train Epoch 3: 379/634 Loss: 0.203919
2022-12-31 14:32: Train Epoch 3: 383/634 Loss: 0.191716
2022-12-31 14:33: Train Epoch 3: 387/634 Loss: 0.162825
2022-12-31 14:34: Train Epoch 3: 391/634 Loss: 0.208115
2022-12-31 14:34: Train Epoch 3: 395/634 Loss: 0.203390
2022-12-31 14:35: Train Epoch 3: 399/634 Loss: 0.156845
2022-12-31 14:35: Train Epoch 3: 403/634 Loss: 0.166717
2022-12-31 14:36: Train Epoch 3: 407/634 Loss: 0.175950
2022-12-31 14:36: Train Epoch 3: 411/634 Loss: 0.163030
2022-12-31 14:37: Train Epoch 3: 415/634 Loss: 0.231717
2022-12-31 14:38: Train Epoch 3: 419/634 Loss: 0.198881
2022-12-31 14:38: Train Epoch 3: 423/634 Loss: 0.206188
2022-12-31 14:39: Train Epoch 3: 427/634 Loss: 0.216753
2022-12-31 14:39: Train Epoch 3: 431/634 Loss: 0.157347
2022-12-31 14:40: Train Epoch 3: 435/634 Loss: 0.177951
2022-12-31 14:40: Train Epoch 3: 439/634 Loss: 0.160697
2022-12-31 14:41: Train Epoch 3: 443/634 Loss: 0.188111
2022-12-31 14:42: Train Epoch 3: 447/634 Loss: 0.183522
2022-12-31 14:42: Train Epoch 3: 451/634 Loss: 0.163768
2022-12-31 14:43: Train Epoch 3: 455/634 Loss: 0.189143
2022-12-31 14:43: Train Epoch 3: 459/634 Loss: 0.167430
2022-12-31 14:44: Train Epoch 3: 463/634 Loss: 0.177829
2022-12-31 14:44: Train Epoch 3: 467/634 Loss: 0.165014
2022-12-31 14:45: Train Epoch 3: 471/634 Loss: 0.180540
2022-12-31 14:46: Train Epoch 3: 475/634 Loss: 0.177271
2022-12-31 14:46: Train Epoch 3: 479/634 Loss: 0.169143
2022-12-31 14:47: Train Epoch 3: 483/634 Loss: 0.218090
2022-12-31 14:47: Train Epoch 3: 487/634 Loss: 0.188503
2022-12-31 14:48: Train Epoch 3: 491/634 Loss: 0.175997
2022-12-31 14:48: Train Epoch 3: 495/634 Loss: 0.224515
2022-12-31 14:49: Train Epoch 3: 499/634 Loss: 0.179839
2022-12-31 14:49: Train Epoch 3: 503/634 Loss: 0.223763
2022-12-31 14:50: Train Epoch 3: 507/634 Loss: 0.185400
2022-12-31 14:51: Train Epoch 3: 511/634 Loss: 0.200588
2022-12-31 14:51: Train Epoch 3: 515/634 Loss: 0.211291
2022-12-31 14:52: Train Epoch 3: 519/634 Loss: 0.192883
2022-12-31 14:52: Train Epoch 3: 523/634 Loss: 0.193919
2022-12-31 14:53: Train Epoch 3: 527/634 Loss: 0.212804
2022-12-31 14:54: Train Epoch 3: 531/634 Loss: 0.203439
2022-12-31 14:54: Train Epoch 3: 535/634 Loss: 0.153594
2022-12-31 14:55: Train Epoch 3: 539/634 Loss: 0.220588
2022-12-31 14:55: Train Epoch 3: 543/634 Loss: 0.196371
2022-12-31 14:56: Train Epoch 3: 547/634 Loss: 0.242532
2022-12-31 14:56: Train Epoch 3: 551/634 Loss: 0.182397
2022-12-31 14:57: Train Epoch 3: 555/634 Loss: 0.177453
2022-12-31 14:58: Train Epoch 3: 559/634 Loss: 0.199227
2022-12-31 14:58: Train Epoch 3: 563/634 Loss: 0.211295
2022-12-31 14:59: Train Epoch 3: 567/634 Loss: 0.211660
2022-12-31 14:59: Train Epoch 3: 571/634 Loss: 0.176027
2022-12-31 15:00: Train Epoch 3: 575/634 Loss: 0.212485
2022-12-31 15:00: Train Epoch 3: 579/634 Loss: 0.184756
2022-12-31 15:01: Train Epoch 3: 583/634 Loss: 0.176111
2022-12-31 15:02: Train Epoch 3: 587/634 Loss: 0.206991
2022-12-31 15:02: Train Epoch 3: 591/634 Loss: 0.194103
2022-12-31 15:03: Train Epoch 3: 595/634 Loss: 0.175015
2022-12-31 15:03: Train Epoch 3: 599/634 Loss: 0.227650
2022-12-31 15:04: Train Epoch 3: 603/634 Loss: 0.198009
2022-12-31 15:04: Train Epoch 3: 607/634 Loss: 0.219750
2022-12-31 15:05: Train Epoch 3: 611/634 Loss: 0.205433
2022-12-31 15:06: Train Epoch 3: 615/634 Loss: 0.191105
2022-12-31 15:06: Train Epoch 3: 619/634 Loss: 0.180641
2022-12-31 15:07: Train Epoch 3: 623/634 Loss: 0.184093
2022-12-31 15:07: Train Epoch 3: 627/634 Loss: 0.200693
2022-12-31 15:08: Train Epoch 3: 631/634 Loss: 0.181403
2022-12-31 15:08: Train Epoch 3: 633/634 Loss: 0.074279
2022-12-31 15:08: **********Train Epoch 3: averaged Loss: 0.189077 
2022-12-31 15:08: 
Epoch time elapsed: 5397.918185710907

2022-12-31 15:10: 
 metrics validation: {'precision': 0.8120229007633588, 'recall': 0.6546153846153846, 'f1-score': 0.7248722316865417, 'support': 1300, 'AUC': 0.8845878698224852, 'AUCPR': 0.8004586484157492, 'TP': 851, 'FP': 197, 'TN': 2403, 'FN': 449} 

2022-12-31 15:10: **********Val Epoch 3: average Loss: 0.202106
2022-12-31 15:10: *********************************Current best model saved!
2022-12-31 15:12: 
 Testing metrics {'precision': 0.8568443051201672, 'recall': 0.6677524429967426, 'f1-score': 0.7505720823798626, 'support': 1228, 'AUC': 0.8995665736506487, 'AUCPR': 0.8408411188991342, 'TP': 820, 'FP': 137, 'TN': 2319, 'FN': 408} 

2022-12-31 15:20: 
 Testing metrics {'precision': 0.9255143059825017, 'recall': 0.8881325164511005, 'f1-score': 0.9064381658175081, 'support': 4407, 'AUC': 0.97773376503715, 'AUCPR': 0.9637350860944456, 'TP': 3914, 'FP': 315, 'TN': 8499, 'FN': 493} 

2022-12-31 15:21: Train Epoch 4: 3/634 Loss: 0.197842
2022-12-31 15:21: Train Epoch 4: 7/634 Loss: 0.194032
2022-12-31 15:22: Train Epoch 4: 11/634 Loss: 0.171324
2022-12-31 15:22: Train Epoch 4: 15/634 Loss: 0.198505
2022-12-31 15:23: Train Epoch 4: 19/634 Loss: 0.181982
2022-12-31 15:24: Train Epoch 4: 23/634 Loss: 0.192221
2022-12-31 15:24: Train Epoch 4: 27/634 Loss: 0.204540
2022-12-31 15:25: Train Epoch 4: 31/634 Loss: 0.176242
2022-12-31 15:25: Train Epoch 4: 35/634 Loss: 0.162515
2022-12-31 15:26: Train Epoch 4: 39/634 Loss: 0.192546
2022-12-31 15:26: Train Epoch 4: 43/634 Loss: 0.180538
2022-12-31 15:27: Train Epoch 4: 47/634 Loss: 0.179920
2022-12-31 15:28: Train Epoch 4: 51/634 Loss: 0.197557
2022-12-31 15:28: Train Epoch 4: 55/634 Loss: 0.185197
2022-12-31 15:29: Train Epoch 4: 59/634 Loss: 0.174642
2022-12-31 15:29: Train Epoch 4: 63/634 Loss: 0.164949
2022-12-31 15:30: Train Epoch 4: 67/634 Loss: 0.178242
2022-12-31 15:30: Train Epoch 4: 71/634 Loss: 0.166842
2022-12-31 15:31: Train Epoch 4: 75/634 Loss: 0.180466
2022-12-31 15:32: Train Epoch 4: 79/634 Loss: 0.171057
2022-12-31 15:32: Train Epoch 4: 83/634 Loss: 0.197667
2022-12-31 15:33: Train Epoch 4: 87/634 Loss: 0.167189
2022-12-31 15:33: Train Epoch 4: 91/634 Loss: 0.177058
2022-12-31 15:34: Train Epoch 4: 95/634 Loss: 0.167848
2022-12-31 15:34: Train Epoch 4: 99/634 Loss: 0.164764
2022-12-31 15:35: Train Epoch 4: 103/634 Loss: 0.194513
2022-12-31 15:36: Train Epoch 4: 107/634 Loss: 0.222118
2022-12-31 15:36: Train Epoch 4: 111/634 Loss: 0.163461
2022-12-31 15:37: Train Epoch 4: 115/634 Loss: 0.201140
2022-12-31 15:37: Train Epoch 4: 119/634 Loss: 0.171774
2022-12-31 15:38: Train Epoch 4: 123/634 Loss: 0.211572
2022-12-31 15:38: Train Epoch 4: 127/634 Loss: 0.207393
2022-12-31 15:39: Train Epoch 4: 131/634 Loss: 0.224574
2022-12-31 15:40: Train Epoch 4: 135/634 Loss: 0.191232
2022-12-31 15:40: Train Epoch 4: 139/634 Loss: 0.175493
2022-12-31 15:41: Train Epoch 4: 143/634 Loss: 0.158976
2022-12-31 15:41: Train Epoch 4: 147/634 Loss: 0.179578
2022-12-31 15:42: Train Epoch 4: 151/634 Loss: 0.189387
2022-12-31 15:43: Train Epoch 4: 155/634 Loss: 0.193403
2022-12-31 15:43: Train Epoch 4: 159/634 Loss: 0.186237
2022-12-31 15:44: Train Epoch 4: 163/634 Loss: 0.164341
2022-12-31 15:44: Train Epoch 4: 167/634 Loss: 0.216848
2022-12-31 15:45: Train Epoch 4: 171/634 Loss: 0.186187
2022-12-31 15:45: Train Epoch 4: 175/634 Loss: 0.192449
2022-12-31 15:46: Train Epoch 4: 179/634 Loss: 0.159645
2022-12-31 15:47: Train Epoch 4: 183/634 Loss: 0.180656
2022-12-31 15:47: Train Epoch 4: 187/634 Loss: 0.178285
2022-12-31 15:48: Train Epoch 4: 191/634 Loss: 0.186103
2022-12-31 15:48: Train Epoch 4: 195/634 Loss: 0.162650
2022-12-31 15:49: Train Epoch 4: 199/634 Loss: 0.212383
2022-12-31 15:49: Train Epoch 4: 203/634 Loss: 0.188474
2022-12-31 15:50: Train Epoch 4: 207/634 Loss: 0.201307
2022-12-31 15:51: Train Epoch 4: 211/634 Loss: 0.202895
2022-12-31 15:51: Train Epoch 4: 215/634 Loss: 0.200240
2022-12-31 15:52: Train Epoch 4: 219/634 Loss: 0.182330
2022-12-31 15:52: Train Epoch 4: 223/634 Loss: 0.170187
2022-12-31 15:53: Train Epoch 4: 227/634 Loss: 0.180568
2022-12-31 15:53: Train Epoch 4: 231/634 Loss: 0.207862
2022-12-31 15:54: Train Epoch 4: 235/634 Loss: 0.192867
2022-12-31 15:55: Train Epoch 4: 239/634 Loss: 0.217223
2022-12-31 15:55: Train Epoch 4: 243/634 Loss: 0.181999
2022-12-31 15:56: Train Epoch 4: 247/634 Loss: 0.188674
2022-12-31 15:56: Train Epoch 4: 251/634 Loss: 0.189939
2022-12-31 15:57: Train Epoch 4: 255/634 Loss: 0.183748
2022-12-31 15:57: Train Epoch 4: 259/634 Loss: 0.166959
2022-12-31 15:58: Train Epoch 4: 263/634 Loss: 0.196041
2022-12-31 15:59: Train Epoch 4: 267/634 Loss: 0.188298
2022-12-31 15:59: Train Epoch 4: 271/634 Loss: 0.184274
2022-12-31 16:00: Train Epoch 4: 275/634 Loss: 0.184468
2022-12-31 16:00: Train Epoch 4: 279/634 Loss: 0.212267
2022-12-31 16:01: Train Epoch 4: 283/634 Loss: 0.203400
2022-12-31 16:01: Train Epoch 4: 287/634 Loss: 0.155441
2022-12-31 16:02: Train Epoch 4: 291/634 Loss: 0.175090
2022-12-31 16:03: Train Epoch 4: 295/634 Loss: 0.175474
2022-12-31 16:03: Train Epoch 4: 299/634 Loss: 0.209790
2022-12-31 16:04: Train Epoch 4: 303/634 Loss: 0.197428
2022-12-31 16:04: Train Epoch 4: 307/634 Loss: 0.199945
2022-12-31 16:05: Train Epoch 4: 311/634 Loss: 0.222348
2022-12-31 16:05: Train Epoch 4: 315/634 Loss: 0.185721
2022-12-31 16:06: Train Epoch 4: 319/634 Loss: 0.215242
2022-12-31 16:07: Train Epoch 4: 323/634 Loss: 0.158323
2022-12-31 16:07: Train Epoch 4: 327/634 Loss: 0.190867
2022-12-31 16:08: Train Epoch 4: 331/634 Loss: 0.215266
2022-12-31 16:08: Train Epoch 4: 335/634 Loss: 0.215090
2022-12-31 16:09: Train Epoch 4: 339/634 Loss: 0.233741
2022-12-31 16:09: Train Epoch 4: 343/634 Loss: 0.193112
2022-12-31 16:10: Train Epoch 4: 347/634 Loss: 0.222963
2022-12-31 16:11: Train Epoch 4: 351/634 Loss: 0.151899
2022-12-31 16:11: Train Epoch 4: 355/634 Loss: 0.193756
2022-12-31 16:12: Train Epoch 4: 359/634 Loss: 0.184860
2022-12-31 16:12: Train Epoch 4: 363/634 Loss: 0.181437
2022-12-31 16:13: Train Epoch 4: 367/634 Loss: 0.153442
2022-12-31 16:13: Train Epoch 4: 371/634 Loss: 0.173130
2022-12-31 16:14: Train Epoch 4: 375/634 Loss: 0.169934
2022-12-31 16:15: Train Epoch 4: 379/634 Loss: 0.167645
2022-12-31 16:15: Train Epoch 4: 383/634 Loss: 0.170592
2022-12-31 16:16: Train Epoch 4: 387/634 Loss: 0.207337
2022-12-31 16:16: Train Epoch 4: 391/634 Loss: 0.181596
2022-12-31 16:17: Train Epoch 4: 395/634 Loss: 0.174484
2022-12-31 16:17: Train Epoch 4: 399/634 Loss: 0.174251
2022-12-31 16:18: Train Epoch 4: 403/634 Loss: 0.147757
2022-12-31 16:19: Train Epoch 4: 407/634 Loss: 0.171949
2022-12-31 16:19: Train Epoch 4: 411/634 Loss: 0.174603
2022-12-31 16:20: Train Epoch 4: 415/634 Loss: 0.202146
2022-12-31 16:20: Train Epoch 4: 419/634 Loss: 0.163755
2022-12-31 16:21: Train Epoch 4: 423/634 Loss: 0.172274
2022-12-31 16:22: Train Epoch 4: 427/634 Loss: 0.168216
2022-12-31 16:22: Train Epoch 4: 431/634 Loss: 0.186422
2022-12-31 16:23: Train Epoch 4: 435/634 Loss: 0.197440
2022-12-31 16:23: Train Epoch 4: 439/634 Loss: 0.173956
2022-12-31 16:24: Train Epoch 4: 443/634 Loss: 0.203362
2022-12-31 16:24: Train Epoch 4: 447/634 Loss: 0.172885
2022-12-31 16:25: Train Epoch 4: 451/634 Loss: 0.231980
2022-12-31 16:26: Train Epoch 4: 455/634 Loss: 0.172433
2022-12-31 16:26: Train Epoch 4: 459/634 Loss: 0.199194
2022-12-31 16:27: Train Epoch 4: 463/634 Loss: 0.225985
2022-12-31 16:27: Train Epoch 4: 467/634 Loss: 0.188017
2022-12-31 16:28: Train Epoch 4: 471/634 Loss: 0.176428
2022-12-31 16:28: Train Epoch 4: 475/634 Loss: 0.173122
2022-12-31 16:29: Train Epoch 4: 479/634 Loss: 0.152323
2022-12-31 16:30: Train Epoch 4: 483/634 Loss: 0.199259
2022-12-31 16:30: Train Epoch 4: 487/634 Loss: 0.159643
2022-12-31 16:31: Train Epoch 4: 491/634 Loss: 0.173641
2022-12-31 16:31: Train Epoch 4: 495/634 Loss: 0.174929
2022-12-31 16:32: Train Epoch 4: 499/634 Loss: 0.209506
2022-12-31 16:32: Train Epoch 4: 503/634 Loss: 0.177292
2022-12-31 16:33: Train Epoch 4: 507/634 Loss: 0.153911
2022-12-31 16:34: Train Epoch 4: 511/634 Loss: 0.189148
2022-12-31 16:34: Train Epoch 4: 515/634 Loss: 0.198842
2022-12-31 16:35: Train Epoch 4: 519/634 Loss: 0.222366
2022-12-31 16:35: Train Epoch 4: 523/634 Loss: 0.166803
2022-12-31 16:36: Train Epoch 4: 527/634 Loss: 0.181775
2022-12-31 16:36: Train Epoch 4: 531/634 Loss: 0.182700
2022-12-31 16:37: Train Epoch 4: 535/634 Loss: 0.154782
2022-12-31 16:38: Train Epoch 4: 539/634 Loss: 0.158000
2022-12-31 16:38: Train Epoch 4: 543/634 Loss: 0.160903
2022-12-31 16:39: Train Epoch 4: 547/634 Loss: 0.176271
2022-12-31 16:39: Train Epoch 4: 551/634 Loss: 0.168084
2022-12-31 16:40: Train Epoch 4: 555/634 Loss: 0.157168
2022-12-31 16:40: Train Epoch 4: 559/634 Loss: 0.187319
2022-12-31 16:41: Train Epoch 4: 563/634 Loss: 0.165086
2022-12-31 16:42: Train Epoch 4: 567/634 Loss: 0.187169
2022-12-31 16:42: Train Epoch 4: 571/634 Loss: 0.168598
2022-12-31 16:43: Train Epoch 4: 575/634 Loss: 0.193575
2022-12-31 16:43: Train Epoch 4: 579/634 Loss: 0.151492
2022-12-31 16:44: Train Epoch 4: 583/634 Loss: 0.164743
2022-12-31 16:44: Train Epoch 4: 587/634 Loss: 0.217869
2022-12-31 16:45: Train Epoch 4: 591/634 Loss: 0.166101
2022-12-31 16:46: Train Epoch 4: 595/634 Loss: 0.185449
2022-12-31 16:46: Train Epoch 4: 599/634 Loss: 0.153701
2022-12-31 16:47: Train Epoch 4: 603/634 Loss: 0.201887
2022-12-31 16:47: Train Epoch 4: 607/634 Loss: 0.178898
2022-12-31 16:48: Train Epoch 4: 611/634 Loss: 0.170544
2022-12-31 16:48: Train Epoch 4: 615/634 Loss: 0.153351
2022-12-31 16:49: Train Epoch 4: 619/634 Loss: 0.175786
2022-12-31 16:49: Train Epoch 4: 623/634 Loss: 0.169838
2022-12-31 16:50: Train Epoch 4: 627/634 Loss: 0.179893
2022-12-31 16:51: Train Epoch 4: 631/634 Loss: 0.183129
2022-12-31 16:51: Train Epoch 4: 633/634 Loss: 0.103550
2022-12-31 16:51: **********Train Epoch 4: averaged Loss: 0.183570 
2022-12-31 16:51: 
Epoch time elapsed: 5434.051996231079

2022-12-31 16:53: 
 metrics validation: {'precision': 0.7019167217448777, 'recall': 0.816923076923077, 'f1-score': 0.7550657660860292, 'support': 1300, 'AUC': 0.8917100591715977, 'AUCPR': 0.8071072458775297, 'TP': 1062, 'FP': 451, 'TN': 2149, 'FN': 238} 

2022-12-31 16:53: **********Val Epoch 4: average Loss: 0.194759
2022-12-31 16:53: *********************************Current best model saved!
2022-12-31 16:55: 
 Testing metrics {'precision': 0.7119815668202765, 'recall': 0.754885993485342, 'f1-score': 0.7328063241106719, 'support': 1228, 'AUC': 0.8987625200267377, 'AUCPR': 0.8417785410626522, 'TP': 927, 'FP': 375, 'TN': 2081, 'FN': 301} 

2022-12-31 17:02: 
 Testing metrics {'precision': 0.8123927550047665, 'recall': 0.9668708872248696, 'f1-score': 0.8829258184832159, 'support': 4407, 'AUC': 0.9741978397405905, 'AUCPR': 0.9521879490875942, 'TP': 4261, 'FP': 984, 'TN': 7830, 'FN': 146} 

2022-12-31 17:03: Train Epoch 5: 3/634 Loss: 0.224414
2022-12-31 17:03: Train Epoch 5: 7/634 Loss: 0.209624
2022-12-31 17:04: Train Epoch 5: 11/634 Loss: 0.196996
2022-12-31 17:05: Train Epoch 5: 15/634 Loss: 0.190435
2022-12-31 17:05: Train Epoch 5: 19/634 Loss: 0.171552
2022-12-31 17:06: Train Epoch 5: 23/634 Loss: 0.207738
2022-12-31 17:06: Train Epoch 5: 27/634 Loss: 0.179813
2022-12-31 17:07: Train Epoch 5: 31/634 Loss: 0.172991
2022-12-31 17:07: Train Epoch 5: 35/634 Loss: 0.210854
2022-12-31 17:08: Train Epoch 5: 39/634 Loss: 0.173383
2022-12-31 17:09: Train Epoch 5: 43/634 Loss: 0.166163
2022-12-31 17:09: Train Epoch 5: 47/634 Loss: 0.195644
2022-12-31 17:10: Train Epoch 5: 51/634 Loss: 0.214316
2022-12-31 17:10: Train Epoch 5: 55/634 Loss: 0.180486
2022-12-31 17:11: Train Epoch 5: 59/634 Loss: 0.187786
2022-12-31 17:12: Train Epoch 5: 63/634 Loss: 0.192920
2022-12-31 17:12: Train Epoch 5: 67/634 Loss: 0.199825
2022-12-31 17:13: Train Epoch 5: 71/634 Loss: 0.165180
2022-12-31 17:13: Train Epoch 5: 75/634 Loss: 0.189201
2022-12-31 17:14: Train Epoch 5: 79/634 Loss: 0.211985
2022-12-31 17:14: Train Epoch 5: 83/634 Loss: 0.183150
2022-12-31 17:15: Train Epoch 5: 87/634 Loss: 0.177541
2022-12-31 17:16: Train Epoch 5: 91/634 Loss: 0.171909
2022-12-31 17:16: Train Epoch 5: 95/634 Loss: 0.193069
2022-12-31 17:17: Train Epoch 5: 99/634 Loss: 0.181858
2022-12-31 17:17: Train Epoch 5: 103/634 Loss: 0.162548
2022-12-31 17:18: Train Epoch 5: 107/634 Loss: 0.208278
2022-12-31 17:19: Train Epoch 5: 111/634 Loss: 0.165295
2022-12-31 17:19: Train Epoch 5: 115/634 Loss: 0.163672
2022-12-31 17:20: Train Epoch 5: 119/634 Loss: 0.175621
2022-12-31 17:20: Train Epoch 5: 123/634 Loss: 0.190769
2022-12-31 17:21: Train Epoch 5: 127/634 Loss: 0.176896
2022-12-31 17:21: Train Epoch 5: 131/634 Loss: 0.180532
2022-12-31 17:22: Train Epoch 5: 135/634 Loss: 0.196100
2022-12-31 17:23: Train Epoch 5: 139/634 Loss: 0.173187
2022-12-31 17:23: Train Epoch 5: 143/634 Loss: 0.175208
2022-12-31 17:24: Train Epoch 5: 147/634 Loss: 0.167918
2022-12-31 17:24: Train Epoch 5: 151/634 Loss: 0.170746
2022-12-31 17:25: Train Epoch 5: 155/634 Loss: 0.204517
2022-12-31 17:25: Train Epoch 5: 159/634 Loss: 0.161058
2022-12-31 17:26: Train Epoch 5: 163/634 Loss: 0.152740
2022-12-31 17:27: Train Epoch 5: 167/634 Loss: 0.185415
2022-12-31 17:27: Train Epoch 5: 171/634 Loss: 0.178346
2022-12-31 17:28: Train Epoch 5: 175/634 Loss: 0.148195
2022-12-31 17:28: Train Epoch 5: 179/634 Loss: 0.171866
2022-12-31 17:29: Train Epoch 5: 183/634 Loss: 0.150477
2022-12-31 17:30: Train Epoch 5: 187/634 Loss: 0.165702
2022-12-31 17:30: Train Epoch 5: 191/634 Loss: 0.154767
2022-12-31 17:31: Train Epoch 5: 195/634 Loss: 0.171776
2022-12-31 17:31: Train Epoch 5: 199/634 Loss: 0.178600
2022-12-31 17:32: Train Epoch 5: 203/634 Loss: 0.163542
2022-12-31 17:33: Train Epoch 5: 207/634 Loss: 0.166868
2022-12-31 17:33: Train Epoch 5: 211/634 Loss: 0.162692
2022-12-31 17:34: Train Epoch 5: 215/634 Loss: 0.171569
2022-12-31 17:34: Train Epoch 5: 219/634 Loss: 0.189862
2022-12-31 17:35: Train Epoch 5: 223/634 Loss: 0.220290
2022-12-31 17:35: Train Epoch 5: 227/634 Loss: 0.158828
2022-12-31 17:36: Train Epoch 5: 231/634 Loss: 0.200058
2022-12-31 17:37: Train Epoch 5: 235/634 Loss: 0.187757
2022-12-31 17:37: Train Epoch 5: 239/634 Loss: 0.193313
2022-12-31 17:38: Train Epoch 5: 243/634 Loss: 0.227160
2022-12-31 17:38: Train Epoch 5: 247/634 Loss: 0.156424
2022-12-31 17:39: Train Epoch 5: 251/634 Loss: 0.211699
2022-12-31 17:40: Train Epoch 5: 255/634 Loss: 0.244321
2022-12-31 17:40: Train Epoch 5: 259/634 Loss: 0.148355
2022-12-31 17:41: Train Epoch 5: 263/634 Loss: 0.207607
2022-12-31 17:41: Train Epoch 5: 267/634 Loss: 0.226065
2022-12-31 17:42: Train Epoch 5: 271/634 Loss: 0.155206
2022-12-31 17:42: Train Epoch 5: 275/634 Loss: 0.268957
2022-12-31 17:43: Train Epoch 5: 279/634 Loss: 0.182326
2022-12-31 17:44: Train Epoch 5: 283/634 Loss: 0.185887
2022-12-31 17:44: Train Epoch 5: 287/634 Loss: 0.257654
2022-12-31 17:45: Train Epoch 5: 291/634 Loss: 0.138380
2022-12-31 17:45: Train Epoch 5: 295/634 Loss: 0.172682
2022-12-31 17:46: Train Epoch 5: 299/634 Loss: 0.222676
2022-12-31 17:47: Train Epoch 5: 303/634 Loss: 0.194546
2022-12-31 17:47: Train Epoch 5: 307/634 Loss: 0.208961
2022-12-31 17:48: Train Epoch 5: 311/634 Loss: 0.156261
2022-12-31 17:48: Train Epoch 5: 315/634 Loss: 0.217217
2022-12-31 17:49: Train Epoch 5: 319/634 Loss: 0.171145
2022-12-31 17:49: Train Epoch 5: 323/634 Loss: 0.229437
2022-12-31 17:50: Train Epoch 5: 327/634 Loss: 0.177062
2022-12-31 17:51: Train Epoch 5: 331/634 Loss: 0.191002
2022-12-31 17:51: Train Epoch 5: 335/634 Loss: 0.177848
2022-12-31 17:52: Train Epoch 5: 339/634 Loss: 0.191801
2022-12-31 17:52: Train Epoch 5: 343/634 Loss: 0.152148
2022-12-31 17:53: Train Epoch 5: 347/634 Loss: 0.169705
2022-12-31 17:53: Train Epoch 5: 351/634 Loss: 0.170442
2022-12-31 17:54: Train Epoch 5: 355/634 Loss: 0.166175
2022-12-31 17:55: Train Epoch 5: 359/634 Loss: 0.193569
2022-12-31 17:55: Train Epoch 5: 363/634 Loss: 0.197141
2022-12-31 17:56: Train Epoch 5: 367/634 Loss: 0.164033
2022-12-31 17:56: Train Epoch 5: 371/634 Loss: 0.158310
2022-12-31 17:57: Train Epoch 5: 375/634 Loss: 0.156297
2022-12-31 17:57: Train Epoch 5: 379/634 Loss: 0.179337
2022-12-31 17:58: Train Epoch 5: 383/634 Loss: 0.185384
2022-12-31 17:59: Train Epoch 5: 387/634 Loss: 0.161243
2022-12-31 17:59: Train Epoch 5: 391/634 Loss: 0.148005
2022-12-31 18:00: Train Epoch 5: 395/634 Loss: 0.157294
2022-12-31 18:00: Train Epoch 5: 399/634 Loss: 0.183332
2022-12-31 18:01: Train Epoch 5: 403/634 Loss: 0.183375
2022-12-31 18:02: Train Epoch 5: 407/634 Loss: 0.156843
2022-12-31 18:02: Train Epoch 5: 411/634 Loss: 0.166807
2022-12-31 18:03: Train Epoch 5: 415/634 Loss: 0.168771
2022-12-31 18:03: Train Epoch 5: 419/634 Loss: 0.196288
2022-12-31 18:04: Train Epoch 5: 423/634 Loss: 0.187220
2022-12-31 18:04: Train Epoch 5: 427/634 Loss: 0.191850
2022-12-31 18:05: Train Epoch 5: 431/634 Loss: 0.195134
2022-12-31 18:06: Train Epoch 5: 435/634 Loss: 0.205298
2022-12-31 18:06: Train Epoch 5: 439/634 Loss: 0.188034
2022-12-31 18:07: Train Epoch 5: 443/634 Loss: 0.176137
2022-12-31 18:07: Train Epoch 5: 447/634 Loss: 0.176665
2022-12-31 18:08: Train Epoch 5: 451/634 Loss: 0.182481
2022-12-31 18:08: Train Epoch 5: 455/634 Loss: 0.172757
2022-12-31 18:09: Train Epoch 5: 459/634 Loss: 0.162653
2022-12-31 18:09: Train Epoch 5: 463/634 Loss: 0.140062
2022-12-31 18:10: Train Epoch 5: 467/634 Loss: 0.154362
2022-12-31 18:11: Train Epoch 5: 471/634 Loss: 0.162972
2022-12-31 18:11: Train Epoch 5: 475/634 Loss: 0.171075
2022-12-31 18:12: Train Epoch 5: 479/634 Loss: 0.189582
2022-12-31 18:12: Train Epoch 5: 483/634 Loss: 0.166522
2022-12-31 18:13: Train Epoch 5: 487/634 Loss: 0.167930
2022-12-31 18:14: Train Epoch 5: 491/634 Loss: 0.151867
2022-12-31 18:14: Train Epoch 5: 495/634 Loss: 0.174264
2022-12-31 18:15: Train Epoch 5: 499/634 Loss: 0.187639
2022-12-31 18:15: Train Epoch 5: 503/634 Loss: 0.176534
2022-12-31 18:16: Train Epoch 5: 507/634 Loss: 0.173889
2022-12-31 18:16: Train Epoch 5: 511/634 Loss: 0.159411
2022-12-31 18:17: Train Epoch 5: 515/634 Loss: 0.153122
2022-12-31 18:18: Train Epoch 5: 519/634 Loss: 0.190183
2022-12-31 18:18: Train Epoch 5: 523/634 Loss: 0.188096
2022-12-31 18:19: Train Epoch 5: 527/634 Loss: 0.178013
2022-12-31 18:19: Train Epoch 5: 531/634 Loss: 0.157620
2022-12-31 18:20: Train Epoch 5: 535/634 Loss: 0.195501
2022-12-31 18:20: Train Epoch 5: 539/634 Loss: 0.195128
2022-12-31 18:21: Train Epoch 5: 543/634 Loss: 0.173235
2022-12-31 18:22: Train Epoch 5: 547/634 Loss: 0.202751
2022-12-31 18:22: Train Epoch 5: 551/634 Loss: 0.175306
2022-12-31 18:23: Train Epoch 5: 555/634 Loss: 0.201009
2022-12-31 18:23: Train Epoch 5: 559/634 Loss: 0.156856
2022-12-31 18:24: Train Epoch 5: 563/634 Loss: 0.186980
2022-12-31 18:24: Train Epoch 5: 567/634 Loss: 0.187088
2022-12-31 18:25: Train Epoch 5: 571/634 Loss: 0.190506
2022-12-31 18:26: Train Epoch 5: 575/634 Loss: 0.172683
2022-12-31 18:26: Train Epoch 5: 579/634 Loss: 0.161001
2022-12-31 18:27: Train Epoch 5: 583/634 Loss: 0.175886
2022-12-31 18:27: Train Epoch 5: 587/634 Loss: 0.175069
2022-12-31 18:28: Train Epoch 5: 591/634 Loss: 0.153218
2022-12-31 18:28: Train Epoch 5: 595/634 Loss: 0.208267
2022-12-31 18:29: Train Epoch 5: 599/634 Loss: 0.198936
2022-12-31 18:30: Train Epoch 5: 603/634 Loss: 0.170536
2022-12-31 18:30: Train Epoch 5: 607/634 Loss: 0.232372
2022-12-31 18:31: Train Epoch 5: 611/634 Loss: 0.207549
2022-12-31 18:31: Train Epoch 5: 615/634 Loss: 0.153618
2022-12-31 18:32: Train Epoch 5: 619/634 Loss: 0.160506
2022-12-31 18:32: Train Epoch 5: 623/634 Loss: 0.212662
2022-12-31 18:33: Train Epoch 5: 627/634 Loss: 0.172096
2022-12-31 18:34: Train Epoch 5: 631/634 Loss: 0.181647
2022-12-31 18:34: Train Epoch 5: 633/634 Loss: 0.063763
2022-12-31 18:34: **********Train Epoch 5: averaged Loss: 0.180972 
2022-12-31 18:34: 
Epoch time elapsed: 5484.362786769867

2022-12-31 18:36: 
 metrics validation: {'precision': 0.7538677918424754, 'recall': 0.8246153846153846, 'f1-score': 0.7876561351947098, 'support': 1300, 'AUC': 0.9178423076923077, 'AUCPR': 0.839121459217316, 'TP': 1072, 'FP': 350, 'TN': 2250, 'FN': 228} 

2022-12-31 18:36: **********Val Epoch 5: average Loss: 0.165117
2022-12-31 18:36: *********************************Current best model saved!
2022-12-31 18:38: 
 Testing metrics {'precision': 0.7813531353135313, 'recall': 0.7711726384364821, 'f1-score': 0.7762295081967212, 'support': 1228, 'AUC': 0.9175150399473735, 'AUCPR': 0.8657391233463283, 'TP': 947, 'FP': 265, 'TN': 2191, 'FN': 281} 

2022-12-31 18:46: 
 Testing metrics {'precision': 0.85, 'recall': 0.9412298615838439, 'f1-score': 0.8932916980725747, 'support': 4407, 'AUC': 0.9795696029724356, 'AUCPR': 0.9641886587248083, 'TP': 4148, 'FP': 732, 'TN': 8082, 'FN': 259} 

2022-12-31 18:46: Train Epoch 6: 3/634 Loss: 0.189491
2022-12-31 18:47: Train Epoch 6: 7/634 Loss: 0.180879
2022-12-31 18:47: Train Epoch 6: 11/634 Loss: 0.162685
2022-12-31 18:48: Train Epoch 6: 15/634 Loss: 0.183552
2022-12-31 18:48: Train Epoch 6: 19/634 Loss: 0.158607
2022-12-31 18:49: Train Epoch 6: 23/634 Loss: 0.165130
2022-12-31 18:50: Train Epoch 6: 27/634 Loss: 0.192293
2022-12-31 18:50: Train Epoch 6: 31/634 Loss: 0.160722
2022-12-31 18:51: Train Epoch 6: 35/634 Loss: 0.170342
2022-12-31 18:51: Train Epoch 6: 39/634 Loss: 0.132965
2022-12-31 18:52: Train Epoch 6: 43/634 Loss: 0.174985
2022-12-31 18:52: Train Epoch 6: 47/634 Loss: 0.191908
2022-12-31 18:53: Train Epoch 6: 51/634 Loss: 0.128115
2022-12-31 18:53: Train Epoch 6: 55/634 Loss: 0.193755
2022-12-31 18:54: Train Epoch 6: 59/634 Loss: 0.170111
2022-12-31 18:54: Train Epoch 6: 63/634 Loss: 0.147371
2022-12-31 18:55: Train Epoch 6: 67/634 Loss: 0.194042
2022-12-31 18:56: Train Epoch 6: 71/634 Loss: 0.173258
2022-12-31 18:56: Train Epoch 6: 75/634 Loss: 0.196225
2022-12-31 18:57: Train Epoch 6: 79/634 Loss: 0.156334
2022-12-31 18:57: Train Epoch 6: 83/634 Loss: 0.171191
2022-12-31 18:58: Train Epoch 6: 87/634 Loss: 0.186246
2022-12-31 18:58: Train Epoch 6: 91/634 Loss: 0.166708
2022-12-31 18:59: Train Epoch 6: 95/634 Loss: 0.157898
2022-12-31 19:00: Train Epoch 6: 99/634 Loss: 0.161677
2022-12-31 19:00: Train Epoch 6: 103/634 Loss: 0.168547
2022-12-31 19:01: Train Epoch 6: 107/634 Loss: 0.177914
2022-12-31 19:01: Train Epoch 6: 111/634 Loss: 0.183180
2022-12-31 19:02: Train Epoch 6: 115/634 Loss: 0.145819
2022-12-31 19:02: Train Epoch 6: 119/634 Loss: 0.176893
2022-12-31 19:03: Train Epoch 6: 123/634 Loss: 0.192771
2022-12-31 19:03: Train Epoch 6: 127/634 Loss: 0.180535
2022-12-31 19:04: Train Epoch 6: 131/634 Loss: 0.177587
2022-12-31 19:05: Train Epoch 6: 135/634 Loss: 0.159335
2022-12-31 19:05: Train Epoch 6: 139/634 Loss: 0.178918
2022-12-31 19:06: Train Epoch 6: 143/634 Loss: 0.176362
2022-12-31 19:06: Train Epoch 6: 147/634 Loss: 0.171704
2022-12-31 19:07: Train Epoch 6: 151/634 Loss: 0.157154
2022-12-31 19:07: Train Epoch 6: 155/634 Loss: 0.163199
2022-12-31 19:08: Train Epoch 6: 159/634 Loss: 0.189403
2022-12-31 19:09: Train Epoch 6: 163/634 Loss: 0.153831
2022-12-31 19:09: Train Epoch 6: 167/634 Loss: 0.213649
2022-12-31 19:10: Train Epoch 6: 171/634 Loss: 0.172721
2022-12-31 19:10: Train Epoch 6: 175/634 Loss: 0.186066
2022-12-31 19:11: Train Epoch 6: 179/634 Loss: 0.160844
2022-12-31 19:11: Train Epoch 6: 183/634 Loss: 0.160980
2022-12-31 19:12: Train Epoch 6: 187/634 Loss: 0.227005
2022-12-31 19:13: Train Epoch 6: 191/634 Loss: 0.168947
2022-12-31 19:13: Train Epoch 6: 195/634 Loss: 0.140741
2022-12-31 19:14: Train Epoch 6: 199/634 Loss: 0.175103
2022-12-31 19:14: Train Epoch 6: 203/634 Loss: 0.166456
2022-12-31 19:15: Train Epoch 6: 207/634 Loss: 0.172603
2022-12-31 19:15: Train Epoch 6: 211/634 Loss: 0.180083
2022-12-31 19:16: Train Epoch 6: 215/634 Loss: 0.235343
2022-12-31 19:16: Train Epoch 6: 219/634 Loss: 0.171289
2022-12-31 19:17: Train Epoch 6: 223/634 Loss: 0.183375
2022-12-31 19:18: Train Epoch 6: 227/634 Loss: 0.176130
2022-12-31 19:18: Train Epoch 6: 231/634 Loss: 0.155055
2022-12-31 19:19: Train Epoch 6: 235/634 Loss: 0.162887
2022-12-31 19:19: Train Epoch 6: 239/634 Loss: 0.179886
2022-12-31 19:20: Train Epoch 6: 243/634 Loss: 0.174967
2022-12-31 19:21: Train Epoch 6: 247/634 Loss: 0.181943
2022-12-31 19:21: Train Epoch 6: 251/634 Loss: 0.153379
2022-12-31 19:22: Train Epoch 6: 255/634 Loss: 0.156796
2022-12-31 19:22: Train Epoch 6: 259/634 Loss: 0.190703
2022-12-31 19:23: Train Epoch 6: 263/634 Loss: 0.185946
2022-12-31 19:23: Train Epoch 6: 267/634 Loss: 0.195623
2022-12-31 19:24: Train Epoch 6: 271/634 Loss: 0.152694
2022-12-31 19:24: Train Epoch 6: 275/634 Loss: 0.163336
2022-12-31 19:25: Train Epoch 6: 279/634 Loss: 0.181472
2022-12-31 19:26: Train Epoch 6: 283/634 Loss: 0.149153
2022-12-31 19:26: Train Epoch 6: 287/634 Loss: 0.152445
2022-12-31 19:27: Train Epoch 6: 291/634 Loss: 0.177312
2022-12-31 19:27: Train Epoch 6: 295/634 Loss: 0.151775
2022-12-31 19:28: Train Epoch 6: 299/634 Loss: 0.158336
2022-12-31 19:28: Train Epoch 6: 303/634 Loss: 0.193204
2022-12-31 19:29: Train Epoch 6: 307/634 Loss: 0.154843
2022-12-31 19:30: Train Epoch 6: 311/634 Loss: 0.192398
2022-12-31 19:30: Train Epoch 6: 315/634 Loss: 0.164531
2022-12-31 19:31: Train Epoch 6: 319/634 Loss: 0.175181
2022-12-31 19:31: Train Epoch 6: 323/634 Loss: 0.191154
2022-12-31 19:32: Train Epoch 6: 327/634 Loss: 0.149337
2022-12-31 19:32: Train Epoch 6: 331/634 Loss: 0.164102
2022-12-31 19:33: Train Epoch 6: 335/634 Loss: 0.167308
2022-12-31 19:33: Train Epoch 6: 339/634 Loss: 0.169581
2022-12-31 19:34: Train Epoch 6: 343/634 Loss: 0.139164
2022-12-31 19:35: Train Epoch 6: 347/634 Loss: 0.204583
2022-12-31 19:35: Train Epoch 6: 351/634 Loss: 0.185585
2022-12-31 19:36: Train Epoch 6: 355/634 Loss: 0.188995
2022-12-31 19:36: Train Epoch 6: 359/634 Loss: 0.230371
2022-12-31 19:37: Train Epoch 6: 363/634 Loss: 0.162499
2022-12-31 19:37: Train Epoch 6: 367/634 Loss: 0.207614
2022-12-31 19:38: Train Epoch 6: 371/634 Loss: 0.199319
2022-12-31 19:39: Train Epoch 6: 375/634 Loss: 0.189800
2022-12-31 19:39: Train Epoch 6: 379/634 Loss: 0.246217
2022-12-31 19:40: Train Epoch 6: 383/634 Loss: 0.180732
2022-12-31 19:40: Train Epoch 6: 387/634 Loss: 0.223718
2022-12-31 19:41: Train Epoch 6: 391/634 Loss: 0.157852
2022-12-31 19:41: Train Epoch 6: 395/634 Loss: 0.190736
2022-12-31 19:42: Train Epoch 6: 399/634 Loss: 0.203139
2022-12-31 19:42: Train Epoch 6: 403/634 Loss: 0.180564
2022-12-31 19:43: Train Epoch 6: 407/634 Loss: 0.188771
2022-12-31 19:44: Train Epoch 6: 411/634 Loss: 0.208647
2022-12-31 19:44: Train Epoch 6: 415/634 Loss: 0.183721
2022-12-31 19:45: Train Epoch 6: 419/634 Loss: 0.172438
2022-12-31 19:45: Train Epoch 6: 423/634 Loss: 0.245775
2022-12-31 19:46: Train Epoch 6: 427/634 Loss: 0.149285
2022-12-31 19:46: Train Epoch 6: 431/634 Loss: 0.199628
2022-12-31 19:47: Train Epoch 6: 435/634 Loss: 0.178682
2022-12-31 19:48: Train Epoch 6: 439/634 Loss: 0.173186
2022-12-31 19:48: Train Epoch 6: 443/634 Loss: 0.190029
2022-12-31 19:49: Train Epoch 6: 447/634 Loss: 0.166661
2022-12-31 19:49: Train Epoch 6: 451/634 Loss: 0.155339
2022-12-31 19:50: Train Epoch 6: 455/634 Loss: 0.188075
2022-12-31 19:50: Train Epoch 6: 459/634 Loss: 0.158306
2022-12-31 19:51: Train Epoch 6: 463/634 Loss: 0.158018
2022-12-31 19:52: Train Epoch 6: 467/634 Loss: 0.170633
2022-12-31 19:52: Train Epoch 6: 471/634 Loss: 0.195932
2022-12-31 19:53: Train Epoch 6: 475/634 Loss: 0.164812
2022-12-31 19:53: Train Epoch 6: 479/634 Loss: 0.166683
2022-12-31 19:54: Train Epoch 6: 483/634 Loss: 0.168388
2022-12-31 19:54: Train Epoch 6: 487/634 Loss: 0.135191
2022-12-31 19:55: Train Epoch 6: 491/634 Loss: 0.176031
2022-12-31 19:55: Train Epoch 6: 495/634 Loss: 0.162428
2022-12-31 19:56: Train Epoch 6: 499/634 Loss: 0.165332
2022-12-31 19:57: Train Epoch 6: 503/634 Loss: 0.159908
2022-12-31 19:57: Train Epoch 6: 507/634 Loss: 0.147296
2022-12-31 19:58: Train Epoch 6: 511/634 Loss: 0.174049
2022-12-31 19:58: Train Epoch 6: 515/634 Loss: 0.168969
2022-12-31 19:59: Train Epoch 6: 519/634 Loss: 0.152532
2022-12-31 19:59: Train Epoch 6: 523/634 Loss: 0.167645
2022-12-31 20:00: Train Epoch 6: 527/634 Loss: 0.147554
2022-12-31 20:01: Train Epoch 6: 531/634 Loss: 0.166069
2022-12-31 20:01: Train Epoch 6: 535/634 Loss: 0.182353
2022-12-31 20:02: Train Epoch 6: 539/634 Loss: 0.162243
2022-12-31 20:02: Train Epoch 6: 543/634 Loss: 0.189934
2022-12-31 20:03: Train Epoch 6: 547/634 Loss: 0.163257
2022-12-31 20:03: Train Epoch 6: 551/634 Loss: 0.162634
2022-12-31 20:04: Train Epoch 6: 555/634 Loss: 0.177656
2022-12-31 20:05: Train Epoch 6: 559/634 Loss: 0.165429
2022-12-31 20:05: Train Epoch 6: 563/634 Loss: 0.164030
2022-12-31 20:06: Train Epoch 6: 567/634 Loss: 0.170457
2022-12-31 20:06: Train Epoch 6: 571/634 Loss: 0.165823
2022-12-31 20:07: Train Epoch 6: 575/634 Loss: 0.165233
2022-12-31 20:07: Train Epoch 6: 579/634 Loss: 0.139191
2022-12-31 20:08: Train Epoch 6: 583/634 Loss: 0.181953
2022-12-31 20:09: Train Epoch 6: 587/634 Loss: 0.154674
2022-12-31 20:09: Train Epoch 6: 591/634 Loss: 0.180039
2022-12-31 20:10: Train Epoch 6: 595/634 Loss: 0.152566
2022-12-31 20:10: Train Epoch 6: 599/634 Loss: 0.141733
2022-12-31 20:11: Train Epoch 6: 603/634 Loss: 0.153326
2022-12-31 20:11: Train Epoch 6: 607/634 Loss: 0.168095
2022-12-31 20:12: Train Epoch 6: 611/634 Loss: 0.145410
2022-12-31 20:13: Train Epoch 6: 615/634 Loss: 0.183564
2022-12-31 20:13: Train Epoch 6: 619/634 Loss: 0.224958
2022-12-31 20:14: Train Epoch 6: 623/634 Loss: 0.148028
2022-12-31 20:14: Train Epoch 6: 627/634 Loss: 0.180801
2022-12-31 20:15: Train Epoch 6: 631/634 Loss: 0.172400
2022-12-31 20:15: Train Epoch 6: 633/634 Loss: 0.078398
2022-12-31 20:15: **********Train Epoch 6: averaged Loss: 0.173128 
2022-12-31 20:15: 
Epoch time elapsed: 5362.601951122284

2022-12-31 20:17: 
 metrics validation: {'precision': 0.831814415907208, 'recall': 0.7723076923076924, 'f1-score': 0.8009573195053848, 'support': 1300, 'AUC': 0.9305710059171598, 'AUCPR': 0.8663378998107988, 'TP': 1004, 'FP': 203, 'TN': 2397, 'FN': 296} 

2022-12-31 20:17: **********Val Epoch 6: average Loss: 0.151645
2022-12-31 20:17: *********************************Current best model saved!
2022-12-31 20:19: 
 Testing metrics {'precision': 0.8473138548539114, 'recall': 0.7320846905537459, 'f1-score': 0.7854958497160331, 'support': 1228, 'AUC': 0.9191848189370709, 'AUCPR': 0.8719737718674695, 'TP': 899, 'FP': 162, 'TN': 2294, 'FN': 329} 

2022-12-31 20:27: 
 Testing metrics {'precision': 0.9063348416289593, 'recall': 0.9090083957340594, 'f1-score': 0.9076696499376912, 'support': 4407, 'AUC': 0.979419692941624, 'AUCPR': 0.9624397724215709, 'TP': 4006, 'FP': 414, 'TN': 8400, 'FN': 401} 

2022-12-31 20:28: Train Epoch 7: 3/634 Loss: 0.183087
2022-12-31 20:28: Train Epoch 7: 7/634 Loss: 0.168015
2022-12-31 20:29: Train Epoch 7: 11/634 Loss: 0.166449
2022-12-31 20:29: Train Epoch 7: 15/634 Loss: 0.178604
2022-12-31 20:30: Train Epoch 7: 19/634 Loss: 0.185770
2022-12-31 20:30: Train Epoch 7: 23/634 Loss: 0.147886
2022-12-31 20:31: Train Epoch 7: 27/634 Loss: 0.211542
2022-12-31 20:32: Train Epoch 7: 31/634 Loss: 0.204607
2022-12-31 20:32: Train Epoch 7: 35/634 Loss: 0.200273
2022-12-31 20:33: Train Epoch 7: 39/634 Loss: 0.252817
2022-12-31 20:33: Train Epoch 7: 43/634 Loss: 0.155651
2022-12-31 20:34: Train Epoch 7: 47/634 Loss: 0.205117
2022-12-31 20:34: Train Epoch 7: 51/634 Loss: 0.225294
2022-12-31 20:35: Train Epoch 7: 55/634 Loss: 0.186423
2022-12-31 20:36: Train Epoch 7: 59/634 Loss: 0.197280
2022-12-31 20:36: Train Epoch 7: 63/634 Loss: 0.240482
2022-12-31 20:37: Train Epoch 7: 67/634 Loss: 0.181965
2022-12-31 20:37: Train Epoch 7: 71/634 Loss: 0.249088
2022-12-31 20:38: Train Epoch 7: 75/634 Loss: 0.201381
2022-12-31 20:39: Train Epoch 7: 79/634 Loss: 0.155864
2022-12-31 20:39: Train Epoch 7: 83/634 Loss: 0.193034
2022-12-31 20:40: Train Epoch 7: 87/634 Loss: 0.199459
2022-12-31 20:40: Train Epoch 7: 91/634 Loss: 0.179293
2022-12-31 20:41: Train Epoch 7: 95/634 Loss: 0.206479
2022-12-31 20:42: Train Epoch 7: 99/634 Loss: 0.162162
2022-12-31 20:42: Train Epoch 7: 103/634 Loss: 0.155898
2022-12-31 20:43: Train Epoch 7: 107/634 Loss: 0.212697
2022-12-31 20:43: Train Epoch 7: 111/634 Loss: 0.138152
2022-12-31 20:44: Train Epoch 7: 115/634 Loss: 0.209513
2022-12-31 20:44: Train Epoch 7: 119/634 Loss: 0.154629
2022-12-31 20:45: Train Epoch 7: 123/634 Loss: 0.162826
2022-12-31 20:45: Train Epoch 7: 127/634 Loss: 0.155316
2022-12-31 20:46: Train Epoch 7: 131/634 Loss: 0.151736
2022-12-31 20:47: Train Epoch 7: 135/634 Loss: 0.153006
2022-12-31 20:47: Train Epoch 7: 139/634 Loss: 0.137526
2022-12-31 20:48: Train Epoch 7: 143/634 Loss: 0.147923
2022-12-31 20:48: Train Epoch 7: 147/634 Loss: 0.141108
2022-12-31 20:49: Train Epoch 7: 151/634 Loss: 0.147866
2022-12-31 20:49: Train Epoch 7: 155/634 Loss: 0.161929
2022-12-31 20:50: Train Epoch 7: 159/634 Loss: 0.171704
2022-12-31 20:51: Train Epoch 7: 163/634 Loss: 0.160359
2022-12-31 20:51: Train Epoch 7: 167/634 Loss: 0.162168
2022-12-31 20:52: Train Epoch 7: 171/634 Loss: 0.150203
2022-12-31 20:52: Train Epoch 7: 175/634 Loss: 0.159477
2022-12-31 20:53: Train Epoch 7: 179/634 Loss: 0.178730
2022-12-31 20:53: Train Epoch 7: 183/634 Loss: 0.178678
2022-12-31 20:54: Train Epoch 7: 187/634 Loss: 0.162780
2022-12-31 20:54: Train Epoch 7: 191/634 Loss: 0.137695
2022-12-31 20:55: Train Epoch 7: 195/634 Loss: 0.132886
2022-12-31 20:56: Train Epoch 7: 199/634 Loss: 0.179624
2022-12-31 20:56: Train Epoch 7: 203/634 Loss: 0.154433
2022-12-31 20:57: Train Epoch 7: 207/634 Loss: 0.150403
2022-12-31 20:57: Train Epoch 7: 211/634 Loss: 0.164361
2022-12-31 20:58: Train Epoch 7: 215/634 Loss: 0.179279
2022-12-31 20:58: Train Epoch 7: 219/634 Loss: 0.166267
2022-12-31 20:59: Train Epoch 7: 223/634 Loss: 0.151732
2022-12-31 21:00: Train Epoch 7: 227/634 Loss: 0.166446
2022-12-31 21:00: Train Epoch 7: 231/634 Loss: 0.207835
2022-12-31 21:01: Train Epoch 7: 235/634 Loss: 0.162743
2022-12-31 21:01: Train Epoch 7: 239/634 Loss: 0.149185
2022-12-31 21:02: Train Epoch 7: 243/634 Loss: 0.182680
2022-12-31 21:02: Train Epoch 7: 247/634 Loss: 0.156950
2022-12-31 21:03: Train Epoch 7: 251/634 Loss: 0.149942
2022-12-31 21:04: Train Epoch 7: 255/634 Loss: 0.179349
2022-12-31 21:04: Train Epoch 7: 259/634 Loss: 0.190928
2022-12-31 21:05: Train Epoch 7: 263/634 Loss: 0.166742
2022-12-31 21:05: Train Epoch 7: 267/634 Loss: 0.156742
2022-12-31 21:06: Train Epoch 7: 271/634 Loss: 0.155798
2022-12-31 21:06: Train Epoch 7: 275/634 Loss: 0.158759
2022-12-31 21:07: Train Epoch 7: 279/634 Loss: 0.201744
2022-12-31 21:08: Train Epoch 7: 283/634 Loss: 0.156016
2022-12-31 21:08: Train Epoch 7: 287/634 Loss: 0.158370
2022-12-31 21:09: Train Epoch 7: 291/634 Loss: 0.186639
2022-12-31 21:09: Train Epoch 7: 295/634 Loss: 0.140038
2022-12-31 21:10: Train Epoch 7: 299/634 Loss: 0.147252
2022-12-31 21:10: Train Epoch 7: 303/634 Loss: 0.158388
2022-12-31 21:11: Train Epoch 7: 307/634 Loss: 0.155604
2022-12-31 21:12: Train Epoch 7: 311/634 Loss: 0.168327
2022-12-31 21:12: Train Epoch 7: 315/634 Loss: 0.162984
2022-12-31 21:13: Train Epoch 7: 319/634 Loss: 0.130954
2022-12-31 21:13: Train Epoch 7: 323/634 Loss: 0.172690
2022-12-31 21:14: Train Epoch 7: 327/634 Loss: 0.162959
2022-12-31 21:14: Train Epoch 7: 331/634 Loss: 0.181156
2022-12-31 21:15: Train Epoch 7: 335/634 Loss: 0.163421
2022-12-31 21:16: Train Epoch 7: 339/634 Loss: 0.172735
2022-12-31 21:16: Train Epoch 7: 343/634 Loss: 0.152835
2022-12-31 21:17: Train Epoch 7: 347/634 Loss: 0.170185
2022-12-31 21:17: Train Epoch 7: 351/634 Loss: 0.155046
2022-12-31 21:18: Train Epoch 7: 355/634 Loss: 0.138474
2022-12-31 21:18: Train Epoch 7: 359/634 Loss: 0.188376
2022-12-31 21:19: Train Epoch 7: 363/634 Loss: 0.148698
2022-12-31 21:20: Train Epoch 7: 367/634 Loss: 0.138832
2022-12-31 21:20: Train Epoch 7: 371/634 Loss: 0.169057
2022-12-31 21:21: Train Epoch 7: 375/634 Loss: 0.145591
2022-12-31 21:21: Train Epoch 7: 379/634 Loss: 0.177285
2022-12-31 21:22: Train Epoch 7: 383/634 Loss: 0.186791
2022-12-31 21:23: Train Epoch 7: 387/634 Loss: 0.151333
2022-12-31 21:23: Train Epoch 7: 391/634 Loss: 0.147163
2022-12-31 21:24: Train Epoch 7: 395/634 Loss: 0.162424
2022-12-31 21:24: Train Epoch 7: 399/634 Loss: 0.155371
2022-12-31 21:25: Train Epoch 7: 403/634 Loss: 0.157581
2022-12-31 21:25: Train Epoch 7: 407/634 Loss: 0.198105
2022-12-31 21:26: Train Epoch 7: 411/634 Loss: 0.170421
2022-12-31 21:27: Train Epoch 7: 415/634 Loss: 0.176349
2022-12-31 21:27: Train Epoch 7: 419/634 Loss: 0.180376
2022-12-31 21:28: Train Epoch 7: 423/634 Loss: 0.147156
2022-12-31 21:28: Train Epoch 7: 427/634 Loss: 0.177108
2022-12-31 21:29: Train Epoch 7: 431/634 Loss: 0.167024
2022-12-31 21:29: Train Epoch 7: 435/634 Loss: 0.172968
2022-12-31 21:30: Train Epoch 7: 439/634 Loss: 0.173629
2022-12-31 21:31: Train Epoch 7: 443/634 Loss: 0.141739
2022-12-31 21:31: Train Epoch 7: 447/634 Loss: 0.186706
2022-12-31 21:32: Train Epoch 7: 451/634 Loss: 0.182037
2022-12-31 21:32: Train Epoch 7: 455/634 Loss: 0.166835
2022-12-31 21:33: Train Epoch 7: 459/634 Loss: 0.167867
2022-12-31 21:33: Train Epoch 7: 463/634 Loss: 0.162576
2022-12-31 21:34: Train Epoch 7: 467/634 Loss: 0.150671
2022-12-31 21:35: Train Epoch 7: 471/634 Loss: 0.188302
2022-12-31 21:35: Train Epoch 7: 475/634 Loss: 0.156808
2022-12-31 21:36: Train Epoch 7: 479/634 Loss: 0.180290
2022-12-31 21:36: Train Epoch 7: 483/634 Loss: 0.166459
2022-12-31 21:37: Train Epoch 7: 487/634 Loss: 0.165450
2022-12-31 21:37: Train Epoch 7: 491/634 Loss: 0.137156
2022-12-31 21:38: Train Epoch 7: 495/634 Loss: 0.206759
2022-12-31 21:39: Train Epoch 7: 499/634 Loss: 0.147862
2022-12-31 21:39: Train Epoch 7: 503/634 Loss: 0.194915
2022-12-31 21:40: Train Epoch 7: 507/634 Loss: 0.141409
2022-12-31 21:40: Train Epoch 7: 511/634 Loss: 0.146203
2022-12-31 21:41: Train Epoch 7: 515/634 Loss: 0.154709
2022-12-31 21:41: Train Epoch 7: 519/634 Loss: 0.170001
2022-12-31 21:42: Train Epoch 7: 523/634 Loss: 0.150021
2022-12-31 21:43: Train Epoch 7: 527/634 Loss: 0.156329
2022-12-31 21:43: Train Epoch 7: 531/634 Loss: 0.158485
2022-12-31 21:44: Train Epoch 7: 535/634 Loss: 0.162452
2022-12-31 21:44: Train Epoch 7: 539/634 Loss: 0.156995
2022-12-31 21:45: Train Epoch 7: 543/634 Loss: 0.150842
2022-12-31 21:45: Train Epoch 7: 547/634 Loss: 0.153737
2022-12-31 21:46: Train Epoch 7: 551/634 Loss: 0.149814
2022-12-31 21:47: Train Epoch 7: 555/634 Loss: 0.148408
2022-12-31 21:47: Train Epoch 7: 559/634 Loss: 0.144327
2022-12-31 21:48: Train Epoch 7: 563/634 Loss: 0.163936
2022-12-31 21:48: Train Epoch 7: 567/634 Loss: 0.185022
2022-12-31 21:49: Train Epoch 7: 571/634 Loss: 0.149507
2022-12-31 21:49: Train Epoch 7: 575/634 Loss: 0.173223
2022-12-31 21:50: Train Epoch 7: 579/634 Loss: 0.172179
2022-12-31 21:51: Train Epoch 7: 583/634 Loss: 0.152698
2022-12-31 21:51: Train Epoch 7: 587/634 Loss: 0.146407
2022-12-31 21:52: Train Epoch 7: 591/634 Loss: 0.149811
2022-12-31 21:52: Train Epoch 7: 595/634 Loss: 0.165385
2022-12-31 21:53: Train Epoch 7: 599/634 Loss: 0.151217
2022-12-31 21:53: Train Epoch 7: 603/634 Loss: 0.141070
2022-12-31 21:54: Train Epoch 7: 607/634 Loss: 0.164422
2022-12-31 21:55: Train Epoch 7: 611/634 Loss: 0.170488
2022-12-31 21:55: Train Epoch 7: 615/634 Loss: 0.158464
2022-12-31 21:56: Train Epoch 7: 619/634 Loss: 0.219141
2022-12-31 21:56: Train Epoch 7: 623/634 Loss: 0.159028
2022-12-31 21:57: Train Epoch 7: 627/634 Loss: 0.193658
2022-12-31 21:57: Train Epoch 7: 631/634 Loss: 0.139511
2022-12-31 21:58: Train Epoch 7: 633/634 Loss: 0.057993
2022-12-31 21:58: **********Train Epoch 7: averaged Loss: 0.167169 
2022-12-31 21:58: 
Epoch time elapsed: 5435.075607061386

2022-12-31 22:00: 
 metrics validation: {'precision': 0.6453038674033149, 'recall': 0.8984615384615384, 'f1-score': 0.7511254019292605, 'support': 1300, 'AUC': 0.9182002958579882, 'AUCPR': 0.8561693147838922, 'TP': 1168, 'FP': 642, 'TN': 1958, 'FN': 132} 

2022-12-31 22:00: **********Val Epoch 7: average Loss: 0.217654
2022-12-31 22:02: 
 Testing metrics {'precision': 0.8473138548539114, 'recall': 0.7320846905537459, 'f1-score': 0.7854958497160331, 'support': 1228, 'AUC': 0.9191848189370709, 'AUCPR': 0.8719737718674695, 'TP': 899, 'FP': 162, 'TN': 2294, 'FN': 329} 

2022-12-31 22:10: 
 Testing metrics {'precision': 0.9063348416289593, 'recall': 0.9090083957340594, 'f1-score': 0.9076696499376912, 'support': 4407, 'AUC': 0.979419692941624, 'AUCPR': 0.9624397724215709, 'TP': 4006, 'FP': 414, 'TN': 8400, 'FN': 401} 

2022-12-31 22:10: Train Epoch 8: 3/634 Loss: 0.172159
2022-12-31 22:11: Train Epoch 8: 7/634 Loss: 0.133900
2022-12-31 22:11: Train Epoch 8: 11/634 Loss: 0.169100
2022-12-31 22:12: Train Epoch 8: 15/634 Loss: 0.171568
2022-12-31 22:12: Train Epoch 8: 19/634 Loss: 0.177690
2022-12-31 22:13: Train Epoch 8: 23/634 Loss: 0.176329
2022-12-31 22:13: Train Epoch 8: 27/634 Loss: 0.137010
2022-12-31 22:14: Train Epoch 8: 31/634 Loss: 0.196501
2022-12-31 22:15: Train Epoch 8: 35/634 Loss: 0.161322
2022-12-31 22:15: Train Epoch 8: 39/634 Loss: 0.161536
2022-12-31 22:16: Train Epoch 8: 43/634 Loss: 0.162128
2022-12-31 22:16: Train Epoch 8: 47/634 Loss: 0.152715
2022-12-31 22:17: Train Epoch 8: 51/634 Loss: 0.197343
2022-12-31 22:17: Train Epoch 8: 55/634 Loss: 0.173471
2022-12-31 22:18: Train Epoch 8: 59/634 Loss: 0.152080
2022-12-31 22:19: Train Epoch 8: 63/634 Loss: 0.191988
2022-12-31 22:19: Train Epoch 8: 67/634 Loss: 0.176694
2022-12-31 22:20: Train Epoch 8: 71/634 Loss: 0.125325
2022-12-31 22:20: Train Epoch 8: 75/634 Loss: 0.132120
2022-12-31 22:21: Train Epoch 8: 79/634 Loss: 0.177679
2022-12-31 22:21: Train Epoch 8: 83/634 Loss: 0.174490
2022-12-31 22:22: Train Epoch 8: 87/634 Loss: 0.149552
2022-12-31 22:23: Train Epoch 8: 91/634 Loss: 0.154397
2022-12-31 22:23: Train Epoch 8: 95/634 Loss: 0.173158
2022-12-31 22:24: Train Epoch 8: 99/634 Loss: 0.147006
2022-12-31 22:24: Train Epoch 8: 103/634 Loss: 0.142808
2022-12-31 22:25: Train Epoch 8: 107/634 Loss: 0.175209
2022-12-31 22:25: Train Epoch 8: 111/634 Loss: 0.185604
2022-12-31 22:26: Train Epoch 8: 115/634 Loss: 0.187875
2022-12-31 22:27: Train Epoch 8: 119/634 Loss: 0.160305
2022-12-31 22:27: Train Epoch 8: 123/634 Loss: 0.180598
2022-12-31 22:28: Train Epoch 8: 127/634 Loss: 0.183509
2022-12-31 22:28: Train Epoch 8: 131/634 Loss: 0.178628
2022-12-31 22:29: Train Epoch 8: 135/634 Loss: 0.142320
2022-12-31 22:29: Train Epoch 8: 139/634 Loss: 0.158385
2022-12-31 22:30: Train Epoch 8: 143/634 Loss: 0.205448
2022-12-31 22:31: Train Epoch 8: 147/634 Loss: 0.187446
2022-12-31 22:31: Train Epoch 8: 151/634 Loss: 0.121809
2022-12-31 22:32: Train Epoch 8: 155/634 Loss: 0.207996
2022-12-31 22:32: Train Epoch 8: 159/634 Loss: 0.164104
2022-12-31 22:33: Train Epoch 8: 163/634 Loss: 0.188430
2022-12-31 22:33: Train Epoch 8: 167/634 Loss: 0.184429
2022-12-31 22:34: Train Epoch 8: 171/634 Loss: 0.182098
2022-12-31 22:35: Train Epoch 8: 175/634 Loss: 0.171465
2022-12-31 22:35: Train Epoch 8: 179/634 Loss: 0.157803
2022-12-31 22:36: Train Epoch 8: 183/634 Loss: 0.179266
2022-12-31 22:36: Train Epoch 8: 187/634 Loss: 0.147330
2022-12-31 22:37: Train Epoch 8: 191/634 Loss: 0.168188
2022-12-31 22:37: Train Epoch 8: 195/634 Loss: 0.172978
2022-12-31 22:38: Train Epoch 8: 199/634 Loss: 0.165868
2022-12-31 22:39: Train Epoch 8: 203/634 Loss: 0.183139
2022-12-31 22:39: Train Epoch 8: 207/634 Loss: 0.178352
2022-12-31 22:40: Train Epoch 8: 211/634 Loss: 0.144517
2022-12-31 22:40: Train Epoch 8: 215/634 Loss: 0.174964
2022-12-31 22:41: Train Epoch 8: 219/634 Loss: 0.193166
2022-12-31 22:41: Train Epoch 8: 223/634 Loss: 0.159723
2022-12-31 22:42: Train Epoch 8: 227/634 Loss: 0.182146
2022-12-31 22:43: Train Epoch 8: 231/634 Loss: 0.159062
2022-12-31 22:43: Train Epoch 8: 235/634 Loss: 0.188823
2022-12-31 22:44: Train Epoch 8: 239/634 Loss: 0.139074
2022-12-31 22:44: Train Epoch 8: 243/634 Loss: 0.189051
2022-12-31 22:45: Train Epoch 8: 247/634 Loss: 0.169561
2022-12-31 22:45: Train Epoch 8: 251/634 Loss: 0.168093
2022-12-31 22:46: Train Epoch 8: 255/634 Loss: 0.221309
2022-12-31 22:47: Train Epoch 8: 259/634 Loss: 0.135634
2022-12-31 22:47: Train Epoch 8: 263/634 Loss: 0.219918
2022-12-31 22:48: Train Epoch 8: 267/634 Loss: 0.150788
2022-12-31 22:48: Train Epoch 8: 271/634 Loss: 0.179017
2022-12-31 22:49: Train Epoch 8: 275/634 Loss: 0.196973
2022-12-31 22:49: Train Epoch 8: 279/634 Loss: 0.193095
2022-12-31 22:50: Train Epoch 8: 283/634 Loss: 0.164437
2022-12-31 22:51: Train Epoch 8: 287/634 Loss: 0.186753
2022-12-31 22:51: Train Epoch 8: 291/634 Loss: 0.165323
2022-12-31 22:52: Train Epoch 8: 295/634 Loss: 0.181552
2022-12-31 22:52: Train Epoch 8: 299/634 Loss: 0.156430
2022-12-31 22:53: Train Epoch 8: 303/634 Loss: 0.160039
2022-12-31 22:53: Train Epoch 8: 307/634 Loss: 0.181345
2022-12-31 22:54: Train Epoch 8: 311/634 Loss: 0.138862
2022-12-31 22:55: Train Epoch 8: 315/634 Loss: 0.160196
2022-12-31 22:55: Train Epoch 8: 319/634 Loss: 0.160339
2022-12-31 22:56: Train Epoch 8: 323/634 Loss: 0.179698
2022-12-31 22:56: Train Epoch 8: 327/634 Loss: 0.182104
2022-12-31 22:57: Train Epoch 8: 331/634 Loss: 0.150375
2022-12-31 22:57: Train Epoch 8: 335/634 Loss: 0.173731
2022-12-31 22:58: Train Epoch 8: 339/634 Loss: 0.151004
2022-12-31 22:58: Train Epoch 8: 343/634 Loss: 0.176537
2022-12-31 22:59: Train Epoch 8: 347/634 Loss: 0.157725
2022-12-31 23:00: Train Epoch 8: 351/634 Loss: 0.184051
2022-12-31 23:00: Train Epoch 8: 355/634 Loss: 0.189244
2022-12-31 23:01: Train Epoch 8: 359/634 Loss: 0.176245
2022-12-31 23:01: Train Epoch 8: 363/634 Loss: 0.166325
2022-12-31 23:02: Train Epoch 8: 367/634 Loss: 0.146103
2022-12-31 23:03: Train Epoch 8: 371/634 Loss: 0.137465
2022-12-31 23:03: Train Epoch 8: 375/634 Loss: 0.162564
2022-12-31 23:04: Train Epoch 8: 379/634 Loss: 0.172263
2022-12-31 23:04: Train Epoch 8: 383/634 Loss: 0.174763
2022-12-31 23:05: Train Epoch 8: 387/634 Loss: 0.166807
2022-12-31 23:05: Train Epoch 8: 391/634 Loss: 0.160406
2022-12-31 23:06: Train Epoch 8: 395/634 Loss: 0.179035
2022-12-31 23:06: Train Epoch 8: 399/634 Loss: 0.170265
2022-12-31 23:07: Train Epoch 8: 403/634 Loss: 0.155399
2022-12-31 23:08: Train Epoch 8: 407/634 Loss: 0.169632
2022-12-31 23:08: Train Epoch 8: 411/634 Loss: 0.167886
2022-12-31 23:09: Train Epoch 8: 415/634 Loss: 0.149291
2022-12-31 23:09: Train Epoch 8: 419/634 Loss: 0.170514
2022-12-31 23:10: Train Epoch 8: 423/634 Loss: 0.153236
2022-12-31 23:11: Train Epoch 8: 427/634 Loss: 0.170317
2022-12-31 23:11: Train Epoch 8: 431/634 Loss: 0.173769
2022-12-31 23:12: Train Epoch 8: 435/634 Loss: 0.137976
2022-12-31 23:12: Train Epoch 8: 439/634 Loss: 0.143161
2022-12-31 23:13: Train Epoch 8: 443/634 Loss: 0.166450
2022-12-31 23:13: Train Epoch 8: 447/634 Loss: 0.175149
2022-12-31 23:14: Train Epoch 8: 451/634 Loss: 0.128149
2022-12-31 23:14: Train Epoch 8: 455/634 Loss: 0.146177
2022-12-31 23:15: Train Epoch 8: 459/634 Loss: 0.152013
2022-12-31 23:16: Train Epoch 8: 463/634 Loss: 0.128315
2022-12-31 23:16: Train Epoch 8: 467/634 Loss: 0.177897
2022-12-31 23:17: Train Epoch 8: 471/634 Loss: 0.163986
2022-12-31 23:17: Train Epoch 8: 475/634 Loss: 0.175835
2022-12-31 23:18: Train Epoch 8: 479/634 Loss: 0.151864
2022-12-31 23:18: Train Epoch 8: 483/634 Loss: 0.148638
2022-12-31 23:19: Train Epoch 8: 487/634 Loss: 0.172957
2022-12-31 23:20: Train Epoch 8: 491/634 Loss: 0.150813
2022-12-31 23:20: Train Epoch 8: 495/634 Loss: 0.165829
2022-12-31 23:21: Train Epoch 8: 499/634 Loss: 0.220589
2022-12-31 23:21: Train Epoch 8: 503/634 Loss: 0.140592
2022-12-31 23:22: Train Epoch 8: 507/634 Loss: 0.187824
2022-12-31 23:22: Train Epoch 8: 511/634 Loss: 0.217982
2022-12-31 23:23: Train Epoch 8: 515/634 Loss: 0.148811
2022-12-31 23:24: Train Epoch 8: 519/634 Loss: 0.222743
2022-12-31 23:24: Train Epoch 8: 523/634 Loss: 0.168209
2022-12-31 23:25: Train Epoch 8: 527/634 Loss: 0.188007
2022-12-31 23:25: Train Epoch 8: 531/634 Loss: 0.242188
2022-12-31 23:26: Train Epoch 8: 535/634 Loss: 0.155447
2022-12-31 23:26: Train Epoch 8: 539/634 Loss: 0.180185
2022-12-31 23:27: Train Epoch 8: 543/634 Loss: 0.224476
2022-12-31 23:28: Train Epoch 8: 547/634 Loss: 0.159085
2022-12-31 23:28: Train Epoch 8: 551/634 Loss: 0.186818
2022-12-31 23:29: Train Epoch 8: 555/634 Loss: 0.189631
2022-12-31 23:29: Train Epoch 8: 559/634 Loss: 0.164791
2022-12-31 23:30: Train Epoch 8: 563/634 Loss: 0.206018
2022-12-31 23:31: Train Epoch 8: 567/634 Loss: 0.148009
2022-12-31 23:31: Train Epoch 8: 571/634 Loss: 0.157829
2022-12-31 23:32: Train Epoch 8: 575/634 Loss: 0.141308
2022-12-31 23:32: Train Epoch 8: 579/634 Loss: 0.152290
2022-12-31 23:33: Train Epoch 8: 583/634 Loss: 0.152521
2022-12-31 23:33: Train Epoch 8: 587/634 Loss: 0.166670
2022-12-31 23:34: Train Epoch 8: 591/634 Loss: 0.205653
2022-12-31 23:35: Train Epoch 8: 595/634 Loss: 0.147264
2022-12-31 23:35: Train Epoch 8: 599/634 Loss: 0.168553
2022-12-31 23:36: Train Epoch 8: 603/634 Loss: 0.153381
2022-12-31 23:36: Train Epoch 8: 607/634 Loss: 0.195046
2022-12-31 23:37: Train Epoch 8: 611/634 Loss: 0.148830
2022-12-31 23:37: Train Epoch 8: 615/634 Loss: 0.189475
2022-12-31 23:38: Train Epoch 8: 619/634 Loss: 0.168153
2022-12-31 23:38: Train Epoch 8: 623/634 Loss: 0.173302
2022-12-31 23:39: Train Epoch 8: 627/634 Loss: 0.193936
2022-12-31 23:39: Train Epoch 8: 631/634 Loss: 0.141281
2022-12-31 23:40: Train Epoch 8: 633/634 Loss: 0.068733
2022-12-31 23:40: **********Train Epoch 8: averaged Loss: 0.168594 
2022-12-31 23:40: 
Epoch time elapsed: 5412.45368885994

2022-12-31 23:42: 
 metrics validation: {'precision': 0.7321428571428571, 'recall': 0.8515384615384616, 'f1-score': 0.7873399715504978, 'support': 1300, 'AUC': 0.9257464497041421, 'AUCPR': 0.8588386258607784, 'TP': 1107, 'FP': 405, 'TN': 2195, 'FN': 193} 

2022-12-31 23:42: **********Val Epoch 8: average Loss: 0.164404
2022-12-31 23:44: 
 Testing metrics {'precision': 0.8473138548539114, 'recall': 0.7320846905537459, 'f1-score': 0.7854958497160331, 'support': 1228, 'AUC': 0.9191848189370709, 'AUCPR': 0.8719737718674695, 'TP': 899, 'FP': 162, 'TN': 2294, 'FN': 329} 

2022-12-31 23:51: 
 Testing metrics {'precision': 0.9063348416289593, 'recall': 0.9090083957340594, 'f1-score': 0.9076696499376912, 'support': 4407, 'AUC': 0.979419692941624, 'AUCPR': 0.9624397724215709, 'TP': 4006, 'FP': 414, 'TN': 8400, 'FN': 401} 

2022-12-31 23:52: Train Epoch 9: 3/634 Loss: 0.165392
2022-12-31 23:53: Train Epoch 9: 7/634 Loss: 0.161250
2022-12-31 23:53: Train Epoch 9: 11/634 Loss: 0.160276
2022-12-31 23:54: Train Epoch 9: 15/634 Loss: 0.154038
2022-12-31 23:54: Train Epoch 9: 19/634 Loss: 0.157137
2022-12-31 23:55: Train Epoch 9: 23/634 Loss: 0.147027
2022-12-31 23:55: Train Epoch 9: 27/634 Loss: 0.148014
2022-12-31 23:56: Train Epoch 9: 31/634 Loss: 0.151317
2022-12-31 23:56: Train Epoch 9: 35/634 Loss: 0.157057
2022-12-31 23:57: Train Epoch 9: 39/634 Loss: 0.146960
2022-12-31 23:57: Train Epoch 9: 43/634 Loss: 0.156592
2022-12-31 23:58: Train Epoch 9: 47/634 Loss: 0.166379
2022-12-31 23:59: Train Epoch 9: 51/634 Loss: 0.216870
2022-12-31 23:59: Train Epoch 9: 55/634 Loss: 0.192379
2023-01-01 00:00: Train Epoch 9: 59/634 Loss: 0.181452
2023-01-01 00:00: Train Epoch 9: 63/634 Loss: 0.156397
2023-01-01 00:01: Train Epoch 9: 67/634 Loss: 0.166659
2023-01-01 00:02: Train Epoch 9: 71/634 Loss: 0.158924
2023-01-01 00:02: Train Epoch 9: 75/634 Loss: 0.153335
2023-01-01 00:03: Train Epoch 9: 79/634 Loss: 0.149863
2023-01-01 00:03: Train Epoch 9: 83/634 Loss: 0.149190
2023-01-01 00:04: Train Epoch 9: 87/634 Loss: 0.150206
2023-01-01 00:04: Train Epoch 9: 91/634 Loss: 0.153402
2023-01-01 00:05: Train Epoch 9: 95/634 Loss: 0.172116
2023-01-01 00:06: Train Epoch 9: 99/634 Loss: 0.183034
2023-01-01 00:06: Train Epoch 9: 103/634 Loss: 0.147043
2023-01-01 00:07: Train Epoch 9: 107/634 Loss: 0.168701
2023-01-01 00:07: Train Epoch 9: 111/634 Loss: 0.174151
2023-01-01 00:08: Train Epoch 9: 115/634 Loss: 0.156191
2023-01-01 00:08: Train Epoch 9: 119/634 Loss: 0.168420
2023-01-01 00:09: Train Epoch 9: 123/634 Loss: 0.201902
2023-01-01 00:09: Train Epoch 9: 127/634 Loss: 0.152779
2023-01-01 00:10: Train Epoch 9: 131/634 Loss: 0.158411
2023-01-01 00:11: Train Epoch 9: 135/634 Loss: 0.176455
2023-01-01 00:11: Train Epoch 9: 139/634 Loss: 0.146789
2023-01-01 00:12: Train Epoch 9: 143/634 Loss: 0.154291
2023-01-01 00:12: Train Epoch 9: 147/634 Loss: 0.167438
2023-01-01 00:13: Train Epoch 9: 151/634 Loss: 0.145850
2023-01-01 00:13: Train Epoch 9: 155/634 Loss: 0.151358
2023-01-01 00:14: Train Epoch 9: 159/634 Loss: 0.143351
2023-01-01 00:14: Train Epoch 9: 163/634 Loss: 0.163660
2023-01-01 00:15: Train Epoch 9: 167/634 Loss: 0.160544
2023-01-01 00:16: Train Epoch 9: 171/634 Loss: 0.166643
2023-01-01 00:16: Train Epoch 9: 175/634 Loss: 0.134953
2023-01-01 00:17: Train Epoch 9: 179/634 Loss: 0.137027
2023-01-01 00:17: Train Epoch 9: 183/634 Loss: 0.158330
2023-01-01 00:18: Train Epoch 9: 187/634 Loss: 0.175174
2023-01-01 00:18: Train Epoch 9: 191/634 Loss: 0.177323
2023-01-01 00:19: Train Epoch 9: 195/634 Loss: 0.150460
2023-01-01 00:19: Train Epoch 9: 199/634 Loss: 0.138599
2023-01-01 00:20: Train Epoch 9: 203/634 Loss: 0.188409
2023-01-01 00:21: Train Epoch 9: 207/634 Loss: 0.163324
2023-01-01 00:21: Train Epoch 9: 211/634 Loss: 0.165276
2023-01-01 00:22: Train Epoch 9: 215/634 Loss: 0.153390
2023-01-01 00:22: Train Epoch 9: 219/634 Loss: 0.163521
2023-01-01 00:23: Train Epoch 9: 223/634 Loss: 0.195108
2023-01-01 00:23: Train Epoch 9: 227/634 Loss: 0.154986
2023-01-01 00:24: Train Epoch 9: 231/634 Loss: 0.160380
2023-01-01 00:24: Train Epoch 9: 235/634 Loss: 0.153312
2023-01-01 00:25: Train Epoch 9: 239/634 Loss: 0.169684
2023-01-01 00:26: Train Epoch 9: 243/634 Loss: 0.128647
2023-01-01 00:26: Train Epoch 9: 247/634 Loss: 0.178874
2023-01-01 00:27: Train Epoch 9: 251/634 Loss: 0.159956
2023-01-01 00:27: Train Epoch 9: 255/634 Loss: 0.161562
2023-01-01 00:28: Train Epoch 9: 259/634 Loss: 0.179651
2023-01-01 00:28: Train Epoch 9: 263/634 Loss: 0.165559
2023-01-01 00:29: Train Epoch 9: 267/634 Loss: 0.134592
2023-01-01 00:29: Train Epoch 9: 271/634 Loss: 0.156913
2023-01-01 00:30: Train Epoch 9: 275/634 Loss: 0.163468
2023-01-01 00:31: Train Epoch 9: 279/634 Loss: 0.160818
2023-01-01 00:31: Train Epoch 9: 283/634 Loss: 0.169767
2023-01-01 00:32: Train Epoch 9: 287/634 Loss: 0.149434
2023-01-01 00:32: Train Epoch 9: 291/634 Loss: 0.165190
2023-01-01 00:33: Train Epoch 9: 295/634 Loss: 0.193932
2023-01-01 00:33: Train Epoch 9: 299/634 Loss: 0.165449
2023-01-01 00:34: Train Epoch 9: 303/634 Loss: 0.183026
2023-01-01 00:35: Train Epoch 9: 307/634 Loss: 0.192984
2023-01-01 00:35: Train Epoch 9: 311/634 Loss: 0.173155
2023-01-01 00:36: Train Epoch 9: 315/634 Loss: 0.203335
2023-01-01 00:36: Train Epoch 9: 319/634 Loss: 0.183104
2023-01-01 00:37: Train Epoch 9: 323/634 Loss: 0.174658
2023-01-01 00:37: Train Epoch 9: 327/634 Loss: 0.174300
2023-01-01 00:38: Train Epoch 9: 331/634 Loss: 0.241898
2023-01-01 00:38: Train Epoch 9: 335/634 Loss: 0.177445
2023-01-01 00:39: Train Epoch 9: 339/634 Loss: 0.187646
2023-01-01 00:40: Train Epoch 9: 343/634 Loss: 0.176077
2023-01-01 00:40: Train Epoch 9: 347/634 Loss: 0.141857
2023-01-01 00:41: Train Epoch 9: 351/634 Loss: 0.197456
2023-01-01 00:41: Train Epoch 9: 355/634 Loss: 0.161774
2023-01-01 00:42: Train Epoch 9: 359/634 Loss: 0.203496
2023-01-01 00:42: Train Epoch 9: 363/634 Loss: 0.157552
2023-01-01 00:43: Train Epoch 9: 367/634 Loss: 0.180047
2023-01-01 00:43: Train Epoch 9: 371/634 Loss: 0.172101
2023-01-01 00:44: Train Epoch 9: 375/634 Loss: 0.186703
2023-01-01 00:45: Train Epoch 9: 379/634 Loss: 0.203358
2023-01-01 00:45: Train Epoch 9: 383/634 Loss: 0.158632
2023-01-01 00:46: Train Epoch 9: 387/634 Loss: 0.164345
2023-01-01 00:46: Train Epoch 9: 391/634 Loss: 0.176435
2023-01-01 00:47: Train Epoch 9: 395/634 Loss: 0.152512
2023-01-01 00:47: Train Epoch 9: 399/634 Loss: 0.175856
2023-01-01 00:48: Train Epoch 9: 403/634 Loss: 0.182915
2023-01-01 00:48: Train Epoch 9: 407/634 Loss: 0.159393
2023-01-01 00:49: Train Epoch 9: 411/634 Loss: 0.158261
2023-01-01 00:49: Train Epoch 9: 415/634 Loss: 0.159712
2023-01-01 00:50: Train Epoch 9: 419/634 Loss: 0.161232
2023-01-01 00:51: Train Epoch 9: 423/634 Loss: 0.167409
2023-01-01 00:51: Train Epoch 9: 427/634 Loss: 0.205961
2023-01-01 00:52: Train Epoch 9: 431/634 Loss: 0.150226
2023-01-01 00:52: Train Epoch 9: 435/634 Loss: 0.188885
2023-01-01 00:53: Train Epoch 9: 439/634 Loss: 0.127147
2023-01-01 00:54: Train Epoch 9: 443/634 Loss: 0.160963
2023-01-01 00:54: Train Epoch 9: 447/634 Loss: 0.154021
2023-01-01 00:55: Train Epoch 9: 451/634 Loss: 0.169711
2023-01-01 00:55: Train Epoch 9: 455/634 Loss: 0.169973
2023-01-01 00:56: Train Epoch 9: 459/634 Loss: 0.163848
2023-01-01 00:56: Train Epoch 9: 463/634 Loss: 0.186198
2023-01-01 00:57: Train Epoch 9: 467/634 Loss: 0.164324
2023-01-01 00:57: Train Epoch 9: 471/634 Loss: 0.144535
2023-01-01 00:58: Train Epoch 9: 475/634 Loss: 0.142385
2023-01-01 00:59: Train Epoch 9: 479/634 Loss: 0.164006
2023-01-01 00:59: Train Epoch 9: 483/634 Loss: 0.151651
2023-01-01 01:00: Train Epoch 9: 487/634 Loss: 0.165934
2023-01-01 01:00: Train Epoch 9: 491/634 Loss: 0.180910
2023-01-01 01:01: Train Epoch 9: 495/634 Loss: 0.163728
2023-01-01 01:01: Train Epoch 9: 499/634 Loss: 0.126282
2023-01-01 01:02: Train Epoch 9: 503/634 Loss: 0.132946
2023-01-01 01:03: Train Epoch 9: 507/634 Loss: 0.162704
2023-01-01 01:03: Train Epoch 9: 511/634 Loss: 0.148557
2023-01-01 01:04: Train Epoch 9: 515/634 Loss: 0.175345
2023-01-01 01:04: Train Epoch 9: 519/634 Loss: 0.132788
2023-01-01 01:05: Train Epoch 9: 523/634 Loss: 0.154414
2023-01-01 01:05: Train Epoch 9: 527/634 Loss: 0.189089
2023-01-01 01:06: Train Epoch 9: 531/634 Loss: 0.149216
2023-01-01 01:06: Train Epoch 9: 535/634 Loss: 0.151042
2023-01-01 01:07: Train Epoch 9: 539/634 Loss: 0.144318
2023-01-01 01:07: Train Epoch 9: 543/634 Loss: 0.155179
2023-01-01 01:08: Train Epoch 9: 547/634 Loss: 0.164770
2023-01-01 01:09: Train Epoch 9: 551/634 Loss: 0.145949
2023-01-01 01:09: Train Epoch 9: 555/634 Loss: 0.130096
2023-01-01 01:10: Train Epoch 9: 559/634 Loss: 0.141017
2023-01-01 01:10: Train Epoch 9: 563/634 Loss: 0.142553
2023-01-01 01:11: Train Epoch 9: 567/634 Loss: 0.141147
2023-01-01 01:11: Train Epoch 9: 571/634 Loss: 0.172038
2023-01-01 01:12: Train Epoch 9: 575/634 Loss: 0.156057
2023-01-01 01:12: Train Epoch 9: 579/634 Loss: 0.201923
2023-01-01 01:13: Train Epoch 9: 583/634 Loss: 0.168871
2023-01-01 01:14: Train Epoch 9: 587/634 Loss: 0.163815
2023-01-01 01:14: Train Epoch 9: 591/634 Loss: 0.157268
2023-01-01 01:15: Train Epoch 9: 595/634 Loss: 0.156484
2023-01-01 01:15: Train Epoch 9: 599/634 Loss: 0.161529
2023-01-01 01:16: Train Epoch 9: 603/634 Loss: 0.146800
2023-01-01 01:16: Train Epoch 9: 607/634 Loss: 0.177478
2023-01-01 01:17: Train Epoch 9: 611/634 Loss: 0.157065
2023-01-01 01:17: Train Epoch 9: 615/634 Loss: 0.166860
2023-01-01 01:18: Train Epoch 9: 619/634 Loss: 0.156919
2023-01-01 01:18: Train Epoch 9: 623/634 Loss: 0.157118
2023-01-01 01:19: Train Epoch 9: 627/634 Loss: 0.187585
2023-01-01 01:20: Train Epoch 9: 631/634 Loss: 0.187056
2023-01-01 01:20: Train Epoch 9: 633/634 Loss: 0.070377
2023-01-01 01:20: **********Train Epoch 9: averaged Loss: 0.163573 
2023-01-01 01:20: 
Epoch time elapsed: 5298.718594789505

2023-01-01 01:22: 
 metrics validation: {'precision': 0.8934081346423562, 'recall': 0.49, 'f1-score': 0.6328862394436165, 'support': 1300, 'AUC': 0.9314357988165681, 'AUCPR': 0.8675790863699029, 'TP': 637, 'FP': 76, 'TN': 2524, 'FN': 663} 

2023-01-01 01:22: **********Val Epoch 9: average Loss: 0.183700
2023-01-01 01:24: 
 Testing metrics {'precision': 0.8473138548539114, 'recall': 0.7320846905537459, 'f1-score': 0.7854958497160331, 'support': 1228, 'AUC': 0.9191848189370709, 'AUCPR': 0.8719737718674695, 'TP': 899, 'FP': 162, 'TN': 2294, 'FN': 329} 

2023-01-01 01:31: 
 Testing metrics {'precision': 0.9063348416289593, 'recall': 0.9090083957340594, 'f1-score': 0.9076696499376912, 'support': 4407, 'AUC': 0.979419692941624, 'AUCPR': 0.9624397724215709, 'TP': 4006, 'FP': 414, 'TN': 8400, 'FN': 401} 

2023-01-01 01:32: Train Epoch 10: 3/634 Loss: 0.149656
2023-01-01 01:32: Train Epoch 10: 7/634 Loss: 0.141051
2023-01-01 01:33: Train Epoch 10: 11/634 Loss: 0.157860
2023-01-01 01:33: Train Epoch 10: 15/634 Loss: 0.196895
2023-01-01 01:34: Train Epoch 10: 19/634 Loss: 0.170212
2023-01-01 01:34: Train Epoch 10: 23/634 Loss: 0.174404
2023-01-01 01:35: Train Epoch 10: 27/634 Loss: 0.137573
2023-01-01 01:35: Train Epoch 10: 31/634 Loss: 0.165156
2023-01-01 01:36: Train Epoch 10: 35/634 Loss: 0.229817
2023-01-01 01:36: Train Epoch 10: 39/634 Loss: 0.167425
2023-01-01 01:37: Train Epoch 10: 43/634 Loss: 0.199162
2023-01-01 01:38: Train Epoch 10: 47/634 Loss: 0.219006
2023-01-01 01:38: Train Epoch 10: 51/634 Loss: 0.159672
2023-01-01 01:39: Train Epoch 10: 55/634 Loss: 0.204050
2023-01-01 01:39: Train Epoch 10: 59/634 Loss: 0.196163
2023-01-01 01:40: Train Epoch 10: 63/634 Loss: 0.194453
2023-01-01 01:40: Train Epoch 10: 67/634 Loss: 0.208911
2023-01-01 01:41: Train Epoch 10: 71/634 Loss: 0.175017
2023-01-01 01:41: Train Epoch 10: 75/634 Loss: 0.212627
2023-01-01 01:42: Train Epoch 10: 79/634 Loss: 0.179549
2023-01-01 01:42: Train Epoch 10: 83/634 Loss: 0.181330
2023-01-01 01:43: Train Epoch 10: 87/634 Loss: 0.153601
2023-01-01 01:44: Train Epoch 10: 91/634 Loss: 0.146278
2023-01-01 01:44: Train Epoch 10: 95/634 Loss: 0.164665
2023-01-01 01:45: Train Epoch 10: 99/634 Loss: 0.246668
2023-01-01 01:45: Train Epoch 10: 103/634 Loss: 0.162429
2023-01-01 01:46: Train Epoch 10: 107/634 Loss: 0.220205
2023-01-01 01:46: Train Epoch 10: 111/634 Loss: 0.176892
2023-01-01 01:47: Train Epoch 10: 115/634 Loss: 0.156215
2023-01-01 01:47: Train Epoch 10: 119/634 Loss: 0.170192
2023-01-01 01:48: Train Epoch 10: 123/634 Loss: 0.162065
2023-01-01 01:48: Train Epoch 10: 127/634 Loss: 0.149907
2023-01-01 01:49: Train Epoch 10: 131/634 Loss: 0.170512
2023-01-01 01:49: Train Epoch 10: 135/634 Loss: 0.141385
2023-01-01 01:50: Train Epoch 10: 139/634 Loss: 0.142915
2023-01-01 01:51: Train Epoch 10: 143/634 Loss: 0.173760
2023-01-01 01:51: Train Epoch 10: 147/634 Loss: 0.176430
2023-01-01 01:52: Train Epoch 10: 151/634 Loss: 0.165556
2023-01-01 01:52: Train Epoch 10: 155/634 Loss: 0.155218
2023-01-01 01:53: Train Epoch 10: 159/634 Loss: 0.173806
2023-01-01 01:53: Train Epoch 10: 163/634 Loss: 0.171562
2023-01-01 01:54: Train Epoch 10: 167/634 Loss: 0.153717
2023-01-01 01:54: Train Epoch 10: 171/634 Loss: 0.152926
2023-01-01 01:55: Train Epoch 10: 175/634 Loss: 0.166340
2023-01-01 01:55: Train Epoch 10: 179/634 Loss: 0.156030
2023-01-01 01:56: Train Epoch 10: 183/634 Loss: 0.151528
2023-01-01 01:57: Train Epoch 10: 187/634 Loss: 0.155543
2023-01-01 01:57: Train Epoch 10: 191/634 Loss: 0.142767
2023-01-01 01:58: Train Epoch 10: 195/634 Loss: 0.158979
2023-01-01 01:58: Train Epoch 10: 199/634 Loss: 0.202377
2023-01-01 01:59: Train Epoch 10: 203/634 Loss: 0.161437
2023-01-01 01:59: Train Epoch 10: 207/634 Loss: 0.152918
2023-01-01 02:00: Train Epoch 10: 211/634 Loss: 0.167095
2023-01-01 02:00: Train Epoch 10: 215/634 Loss: 0.175157
2023-01-01 02:01: Train Epoch 10: 219/634 Loss: 0.157146
2023-01-01 02:01: Train Epoch 10: 223/634 Loss: 0.161367
2023-01-01 02:02: Train Epoch 10: 227/634 Loss: 0.169542
2023-01-01 02:03: Train Epoch 10: 231/634 Loss: 0.148028
2023-01-01 02:03: Train Epoch 10: 235/634 Loss: 0.172770
2023-01-01 02:04: Train Epoch 10: 239/634 Loss: 0.157331
2023-01-01 02:04: Train Epoch 10: 243/634 Loss: 0.150328
2023-01-01 02:05: Train Epoch 10: 247/634 Loss: 0.168139
2023-01-01 02:05: Train Epoch 10: 251/634 Loss: 0.162538
2023-01-01 02:06: Train Epoch 10: 255/634 Loss: 0.230732
2023-01-01 02:06: Train Epoch 10: 259/634 Loss: 0.169730
2023-01-01 02:07: Train Epoch 10: 263/634 Loss: 0.165599
2023-01-01 02:07: Train Epoch 10: 267/634 Loss: 0.201770
2023-01-01 02:08: Train Epoch 10: 271/634 Loss: 0.204692
2023-01-01 02:08: Train Epoch 10: 275/634 Loss: 0.190921
2023-01-01 02:09: Train Epoch 10: 279/634 Loss: 0.130954
2023-01-01 02:10: Train Epoch 10: 283/634 Loss: 0.153909
2023-01-01 02:10: Train Epoch 10: 287/634 Loss: 0.244691
2023-01-01 02:11: Train Epoch 10: 291/634 Loss: 0.153762
2023-01-01 02:11: Train Epoch 10: 295/634 Loss: 0.173619
2023-01-01 02:12: Train Epoch 10: 299/634 Loss: 0.171201
2023-01-01 02:12: Train Epoch 10: 303/634 Loss: 0.163605
2023-01-01 02:13: Train Epoch 10: 307/634 Loss: 0.204351
2023-01-01 02:13: Train Epoch 10: 311/634 Loss: 0.150455
2023-01-01 02:14: Train Epoch 10: 315/634 Loss: 0.159465
2023-01-01 02:15: Train Epoch 10: 319/634 Loss: 0.178804
2023-01-01 02:15: Train Epoch 10: 323/634 Loss: 0.146771
2023-01-01 02:16: Train Epoch 10: 327/634 Loss: 0.166975
2023-01-01 02:16: Train Epoch 10: 331/634 Loss: 0.137701
2023-01-01 02:17: Train Epoch 10: 335/634 Loss: 0.177748
2023-01-01 02:17: Train Epoch 10: 339/634 Loss: 0.146016
2023-01-01 02:18: Train Epoch 10: 343/634 Loss: 0.166335
2023-01-01 02:18: Train Epoch 10: 347/634 Loss: 0.144520
2023-01-01 02:19: Train Epoch 10: 351/634 Loss: 0.172519
2023-01-01 02:19: Train Epoch 10: 355/634 Loss: 0.156374
2023-01-01 02:20: Train Epoch 10: 359/634 Loss: 0.126829
2023-01-01 02:21: Train Epoch 10: 363/634 Loss: 0.170181
2023-01-01 02:21: Train Epoch 10: 367/634 Loss: 0.139347
2023-01-01 02:22: Train Epoch 10: 371/634 Loss: 0.167705
2023-01-01 02:22: Train Epoch 10: 375/634 Loss: 0.179726
2023-01-01 02:23: Train Epoch 10: 379/634 Loss: 0.134767
2023-01-01 02:23: Train Epoch 10: 383/634 Loss: 0.162184
2023-01-01 02:24: Train Epoch 10: 387/634 Loss: 0.175524
2023-01-01 02:24: Train Epoch 10: 391/634 Loss: 0.138823
2023-01-01 02:25: Train Epoch 10: 395/634 Loss: 0.162649
2023-01-01 02:25: Train Epoch 10: 399/634 Loss: 0.127443
2023-01-01 02:26: Train Epoch 10: 403/634 Loss: 0.149987
2023-01-01 02:27: Train Epoch 10: 407/634 Loss: 0.168157
2023-01-01 02:27: Train Epoch 10: 411/634 Loss: 0.157745
2023-01-01 02:28: Train Epoch 10: 415/634 Loss: 0.175556
2023-01-01 02:28: Train Epoch 10: 419/634 Loss: 0.140853
2023-01-01 02:29: Train Epoch 10: 423/634 Loss: 0.161225
2023-01-01 02:29: Train Epoch 10: 427/634 Loss: 0.167420
2023-01-01 02:30: Train Epoch 10: 431/634 Loss: 0.172967
2023-01-01 02:30: Train Epoch 10: 435/634 Loss: 0.150666
2023-01-01 02:31: Train Epoch 10: 439/634 Loss: 0.152783
2023-01-01 02:31: Train Epoch 10: 443/634 Loss: 0.165910
2023-01-01 02:32: Train Epoch 10: 447/634 Loss: 0.149418
2023-01-01 02:32: Train Epoch 10: 451/634 Loss: 0.240968
2023-01-01 02:33: Train Epoch 10: 455/634 Loss: 0.174809
2023-01-01 02:34: Train Epoch 10: 459/634 Loss: 0.153521
2023-01-01 02:34: Train Epoch 10: 463/634 Loss: 0.167348
2023-01-01 02:35: Train Epoch 10: 467/634 Loss: 0.152908
2023-01-01 02:35: Train Epoch 10: 471/634 Loss: 0.164571
2023-01-01 02:36: Train Epoch 10: 475/634 Loss: 0.157067
2023-01-01 02:36: Train Epoch 10: 479/634 Loss: 0.184966
2023-01-01 02:37: Train Epoch 10: 483/634 Loss: 0.158160
2023-01-01 02:37: Train Epoch 10: 487/634 Loss: 0.159976
2023-01-01 02:38: Train Epoch 10: 491/634 Loss: 0.149406
2023-01-01 02:39: Train Epoch 10: 495/634 Loss: 0.186253
2023-01-01 02:39: Train Epoch 10: 499/634 Loss: 0.159235
2023-01-01 02:40: Train Epoch 10: 503/634 Loss: 0.190549
2023-01-01 02:40: Train Epoch 10: 507/634 Loss: 0.177635
2023-01-01 02:41: Train Epoch 10: 511/634 Loss: 0.136566
2023-01-01 02:42: Train Epoch 10: 515/634 Loss: 0.176016
2023-01-01 02:42: Train Epoch 10: 519/634 Loss: 0.177497
2023-01-01 02:43: Train Epoch 10: 523/634 Loss: 0.187345
2023-01-01 02:43: Train Epoch 10: 527/634 Loss: 0.152131
2023-01-01 02:44: Train Epoch 10: 531/634 Loss: 0.149452
2023-01-01 02:44: Train Epoch 10: 535/634 Loss: 0.151832
2023-01-01 02:45: Train Epoch 10: 539/634 Loss: 0.163927
2023-01-01 02:45: Train Epoch 10: 543/634 Loss: 0.190386
2023-01-01 02:46: Train Epoch 10: 547/634 Loss: 0.160001
2023-01-01 02:46: Train Epoch 10: 551/634 Loss: 0.153364
2023-01-01 02:47: Train Epoch 10: 555/634 Loss: 0.161199
2023-01-01 02:48: Train Epoch 10: 559/634 Loss: 0.182250
2023-01-01 02:48: Train Epoch 10: 563/634 Loss: 0.144544
2023-01-01 02:49: Train Epoch 10: 567/634 Loss: 0.164725
2023-01-01 02:49: Train Epoch 10: 571/634 Loss: 0.196320
2023-01-01 02:50: Train Epoch 10: 575/634 Loss: 0.166946
2023-01-01 02:50: Train Epoch 10: 579/634 Loss: 0.211221
2023-01-01 02:51: Train Epoch 10: 583/634 Loss: 0.207228
2023-01-01 02:51: Train Epoch 10: 587/634 Loss: 0.187239
2023-01-01 02:52: Train Epoch 10: 591/634 Loss: 0.191087
2023-01-01 02:53: Train Epoch 10: 595/634 Loss: 0.159877
2023-01-01 02:53: Train Epoch 10: 599/634 Loss: 0.171429
2023-01-01 02:54: Train Epoch 10: 603/634 Loss: 0.185109
2023-01-01 02:54: Train Epoch 10: 607/634 Loss: 0.157644
2023-01-01 02:55: Train Epoch 10: 611/634 Loss: 0.125583
2023-01-01 02:55: Train Epoch 10: 615/634 Loss: 0.188769
2023-01-01 02:56: Train Epoch 10: 619/634 Loss: 0.190686
2023-01-01 02:56: Train Epoch 10: 623/634 Loss: 0.159554
2023-01-01 02:57: Train Epoch 10: 627/634 Loss: 0.167677
2023-01-01 02:57: Train Epoch 10: 631/634 Loss: 0.151839
2023-01-01 02:58: Train Epoch 10: 633/634 Loss: 0.064187
2023-01-01 02:58: **********Train Epoch 10: averaged Loss: 0.168027 
2023-01-01 02:58: 
Epoch time elapsed: 5186.765460729599

2023-01-01 03:00: 
 metrics validation: {'precision': 0.6824838898652607, 'recall': 0.8961538461538462, 'f1-score': 0.7748586631193881, 'support': 1300, 'AUC': 0.9253127218934911, 'AUCPR': 0.8549419211253652, 'TP': 1165, 'FP': 542, 'TN': 2058, 'FN': 135} 

2023-01-01 03:00: **********Val Epoch 10: average Loss: 0.185674
2023-01-01 03:02: 
 Testing metrics {'precision': 0.8473138548539114, 'recall': 0.7320846905537459, 'f1-score': 0.7854958497160331, 'support': 1228, 'AUC': 0.9191848189370709, 'AUCPR': 0.8719737718674695, 'TP': 899, 'FP': 162, 'TN': 2294, 'FN': 329} 

2023-01-01 03:09: 
 Testing metrics {'precision': 0.9063348416289593, 'recall': 0.9090083957340594, 'f1-score': 0.9076696499376912, 'support': 4407, 'AUC': 0.979419692941624, 'AUCPR': 0.9624397724215709, 'TP': 4006, 'FP': 414, 'TN': 8400, 'FN': 401} 

2023-01-01 03:09: Train Epoch 11: 3/634 Loss: 0.176587
2023-01-01 03:10: Train Epoch 11: 7/634 Loss: 0.168421
2023-01-01 03:11: Train Epoch 11: 11/634 Loss: 0.147241
2023-01-01 03:11: Train Epoch 11: 15/634 Loss: 0.178779
2023-01-01 03:12: Train Epoch 11: 19/634 Loss: 0.148441
2023-01-01 03:12: Train Epoch 11: 23/634 Loss: 0.175639
2023-01-01 03:13: Train Epoch 11: 27/634 Loss: 0.159407
2023-01-01 03:13: Train Epoch 11: 31/634 Loss: 0.169317
2023-01-01 03:14: Train Epoch 11: 35/634 Loss: 0.159328
2023-01-01 03:14: Train Epoch 11: 39/634 Loss: 0.154670
2023-01-01 03:15: Train Epoch 11: 43/634 Loss: 0.178141
2023-01-01 03:15: Train Epoch 11: 47/634 Loss: 0.153918
2023-01-01 03:16: Train Epoch 11: 51/634 Loss: 0.155292
2023-01-01 03:16: Train Epoch 11: 55/634 Loss: 0.147148
2023-01-01 03:17: Train Epoch 11: 59/634 Loss: 0.136129
2023-01-01 03:17: Train Epoch 11: 63/634 Loss: 0.163350
2023-01-01 03:18: Train Epoch 11: 67/634 Loss: 0.183739
2023-01-01 03:18: Train Epoch 11: 71/634 Loss: 0.140195
2023-01-01 03:19: Train Epoch 11: 75/634 Loss: 0.152400
2023-01-01 03:20: Train Epoch 11: 79/634 Loss: 0.143494
2023-01-01 03:20: Train Epoch 11: 83/634 Loss: 0.160615
2023-01-01 03:21: Train Epoch 11: 87/634 Loss: 0.160253
2023-01-01 03:21: Train Epoch 11: 91/634 Loss: 0.158392
2023-01-01 03:22: Train Epoch 11: 95/634 Loss: 0.166667
2023-01-01 03:22: Train Epoch 11: 99/634 Loss: 0.173488
2023-01-01 03:23: Train Epoch 11: 103/634 Loss: 0.190341
2023-01-01 03:23: Train Epoch 11: 107/634 Loss: 0.163613
2023-01-01 03:24: Train Epoch 11: 111/634 Loss: 0.164791
2023-01-01 03:24: Train Epoch 11: 115/634 Loss: 0.163614
2023-01-01 03:25: Train Epoch 11: 119/634 Loss: 0.162876
2023-01-01 03:25: Train Epoch 11: 123/634 Loss: 0.176291
2023-01-01 03:26: Train Epoch 11: 127/634 Loss: 0.139839
2023-01-01 03:26: Train Epoch 11: 131/634 Loss: 0.150795
2023-01-01 03:27: Train Epoch 11: 135/634 Loss: 0.162714
2023-01-01 03:28: Train Epoch 11: 139/634 Loss: 0.146217
2023-01-01 03:28: Train Epoch 11: 143/634 Loss: 0.151766
2023-01-01 03:29: Train Epoch 11: 147/634 Loss: 0.172856
2023-01-01 03:29: Train Epoch 11: 151/634 Loss: 0.128873
2023-01-01 03:30: Train Epoch 11: 155/634 Loss: 0.170605
2023-01-01 03:30: Train Epoch 11: 159/634 Loss: 0.132801
2023-01-01 03:31: Train Epoch 11: 163/634 Loss: 0.164940
2023-01-01 03:31: Train Epoch 11: 167/634 Loss: 0.167847
2023-01-01 03:32: Train Epoch 11: 171/634 Loss: 0.193377
2023-01-01 03:32: Train Epoch 11: 175/634 Loss: 0.155647
2023-01-01 03:33: Train Epoch 11: 179/634 Loss: 0.170685
2023-01-01 03:34: Train Epoch 11: 183/634 Loss: 0.150677
2023-01-01 03:34: Train Epoch 11: 187/634 Loss: 0.173154
2023-01-01 03:35: Train Epoch 11: 191/634 Loss: 0.157266
2023-01-01 03:35: Train Epoch 11: 195/634 Loss: 0.164569
2023-01-01 03:36: Train Epoch 11: 199/634 Loss: 0.195284
2023-01-01 03:36: Train Epoch 11: 203/634 Loss: 0.132267
2023-01-01 03:37: Train Epoch 11: 207/634 Loss: 0.199740
2023-01-01 03:37: Train Epoch 11: 211/634 Loss: 0.160158
2023-01-01 03:38: Train Epoch 11: 215/634 Loss: 0.182688
2023-01-01 03:38: Train Epoch 11: 219/634 Loss: 0.140937
2023-01-01 03:39: Train Epoch 11: 223/634 Loss: 0.151852
2023-01-01 03:39: Train Epoch 11: 227/634 Loss: 0.161186
2023-01-01 03:40: Train Epoch 11: 231/634 Loss: 0.166038
2023-01-01 03:41: Train Epoch 11: 235/634 Loss: 0.127947
2023-01-01 03:41: Train Epoch 11: 239/634 Loss: 0.172479
2023-01-01 03:42: Train Epoch 11: 243/634 Loss: 0.157146
2023-01-01 03:42: Train Epoch 11: 247/634 Loss: 0.137390
2023-01-01 03:43: Train Epoch 11: 251/634 Loss: 0.168653
2023-01-01 03:43: Train Epoch 11: 255/634 Loss: 0.147876
2023-01-01 03:44: Train Epoch 11: 259/634 Loss: 0.143633
2023-01-01 03:44: Train Epoch 11: 263/634 Loss: 0.159127
2023-01-01 03:45: Train Epoch 11: 267/634 Loss: 0.181824
2023-01-01 03:45: Train Epoch 11: 271/634 Loss: 0.157876
2023-01-01 03:46: Train Epoch 11: 275/634 Loss: 0.198692
2023-01-01 03:46: Train Epoch 11: 279/634 Loss: 0.180403
2023-01-01 03:47: Train Epoch 11: 283/634 Loss: 0.142997
2023-01-01 03:47: Train Epoch 11: 287/634 Loss: 0.154948
2023-01-01 03:48: Train Epoch 11: 291/634 Loss: 0.154831
2023-01-01 03:48: Train Epoch 11: 295/634 Loss: 0.185258
2023-01-01 03:49: Train Epoch 11: 299/634 Loss: 0.147245
2023-01-01 03:50: Train Epoch 11: 303/634 Loss: 0.135569
2023-01-01 03:50: Train Epoch 11: 307/634 Loss: 0.155421
2023-01-01 03:51: Train Epoch 11: 311/634 Loss: 0.171639
2023-01-01 03:51: Train Epoch 11: 315/634 Loss: 0.157381
2023-01-01 03:52: Train Epoch 11: 319/634 Loss: 0.170336
2023-01-01 03:52: Train Epoch 11: 323/634 Loss: 0.172815
2023-01-01 03:53: Train Epoch 11: 327/634 Loss: 0.157884
2023-01-01 03:53: Train Epoch 11: 331/634 Loss: 0.152744
2023-01-01 03:54: Train Epoch 11: 335/634 Loss: 0.183464
2023-01-01 03:54: Train Epoch 11: 339/634 Loss: 0.168759
2023-01-01 03:55: Train Epoch 11: 343/634 Loss: 0.192879
2023-01-01 03:55: Train Epoch 11: 347/634 Loss: 0.148784
2023-01-01 03:56: Train Epoch 11: 351/634 Loss: 0.149937
2023-01-01 03:57: Train Epoch 11: 355/634 Loss: 0.140358
2023-01-01 03:57: Train Epoch 11: 359/634 Loss: 0.163014
2023-01-01 03:58: Train Epoch 11: 363/634 Loss: 0.167061
2023-01-01 03:58: Train Epoch 11: 367/634 Loss: 0.181248
2023-01-01 03:59: Train Epoch 11: 371/634 Loss: 0.145720
2023-01-01 03:59: Train Epoch 11: 375/634 Loss: 0.193994
2023-01-01 04:00: Train Epoch 11: 379/634 Loss: 0.144780
2023-01-01 04:00: Train Epoch 11: 383/634 Loss: 0.167393
2023-01-01 04:01: Train Epoch 11: 387/634 Loss: 0.157222
2023-01-01 04:01: Train Epoch 11: 391/634 Loss: 0.177925
2023-01-01 04:02: Train Epoch 11: 395/634 Loss: 0.152163
2023-01-01 04:03: Train Epoch 11: 399/634 Loss: 0.203886
2023-01-01 04:03: Train Epoch 11: 403/634 Loss: 0.145043
2023-01-01 04:04: Train Epoch 11: 407/634 Loss: 0.212613
2023-01-01 04:04: Train Epoch 11: 411/634 Loss: 0.157950
2023-01-01 04:05: Train Epoch 11: 415/634 Loss: 0.181083
2023-01-01 04:05: Train Epoch 11: 419/634 Loss: 0.183835
2023-01-01 04:06: Train Epoch 11: 423/634 Loss: 0.153881
2023-01-01 04:06: Train Epoch 11: 427/634 Loss: 0.182165
2023-01-01 04:07: Train Epoch 11: 431/634 Loss: 0.184586
2023-01-01 04:07: Train Epoch 11: 435/634 Loss: 0.190878
2023-01-01 04:08: Train Epoch 11: 439/634 Loss: 0.217313
2023-01-01 04:08: Train Epoch 11: 443/634 Loss: 0.189080
2023-01-01 04:09: Train Epoch 11: 447/634 Loss: 0.190254
2023-01-01 04:09: Train Epoch 11: 451/634 Loss: 0.164127
2023-01-01 04:10: Train Epoch 11: 455/634 Loss: 0.175137
2023-01-01 04:11: Train Epoch 11: 459/634 Loss: 0.193713
2023-01-01 04:11: Train Epoch 11: 463/634 Loss: 0.160359
2023-01-01 04:12: Train Epoch 11: 467/634 Loss: 0.189690
2023-01-01 04:12: Train Epoch 11: 471/634 Loss: 0.211159
2023-01-01 04:13: Train Epoch 11: 475/634 Loss: 0.167289
2023-01-01 04:13: Train Epoch 11: 479/634 Loss: 0.211496
2023-01-01 04:14: Train Epoch 11: 483/634 Loss: 0.147546
2023-01-01 04:14: Train Epoch 11: 487/634 Loss: 0.183099
2023-01-01 04:15: Train Epoch 11: 491/634 Loss: 0.133735
2023-01-01 04:16: Train Epoch 11: 495/634 Loss: 0.171467
2023-01-01 04:16: Train Epoch 11: 499/634 Loss: 0.167821
2023-01-01 04:17: Train Epoch 11: 503/634 Loss: 0.153260
2023-01-01 04:17: Train Epoch 11: 507/634 Loss: 0.152721
2023-01-01 04:18: Train Epoch 11: 511/634 Loss: 0.142305
2023-01-01 04:18: Train Epoch 11: 515/634 Loss: 0.184155
2023-01-01 04:19: Train Epoch 11: 519/634 Loss: 0.189793
2023-01-01 04:19: Train Epoch 11: 523/634 Loss: 0.173403
2023-01-01 04:20: Train Epoch 11: 527/634 Loss: 0.175464
2023-01-01 04:20: Train Epoch 11: 531/634 Loss: 0.199370
2023-01-01 04:21: Train Epoch 11: 535/634 Loss: 0.148671
2023-01-01 04:21: Train Epoch 11: 539/634 Loss: 0.212887
2023-01-01 04:22: Train Epoch 11: 543/634 Loss: 0.192818
2023-01-01 04:23: Train Epoch 11: 547/634 Loss: 0.159582
2023-01-01 04:23: Train Epoch 11: 551/634 Loss: 0.150005
2023-01-01 04:24: Train Epoch 11: 555/634 Loss: 0.194201
2023-01-01 04:24: Train Epoch 11: 559/634 Loss: 0.163449
2023-01-01 04:25: Train Epoch 11: 563/634 Loss: 0.200881
2023-01-01 04:25: Train Epoch 11: 567/634 Loss: 0.231691
2023-01-01 04:26: Train Epoch 11: 571/634 Loss: 0.169033
2023-01-01 04:26: Train Epoch 11: 575/634 Loss: 0.191175
2023-01-01 04:27: Train Epoch 11: 579/634 Loss: 0.178560
2023-01-01 04:28: Train Epoch 11: 583/634 Loss: 0.174404
2023-01-01 04:28: Train Epoch 11: 587/634 Loss: 0.160220
2023-01-01 04:29: Train Epoch 11: 591/634 Loss: 0.134238
2023-01-01 04:29: Train Epoch 11: 595/634 Loss: 0.174200
2023-01-01 04:30: Train Epoch 11: 599/634 Loss: 0.152285
2023-01-01 04:31: Train Epoch 11: 603/634 Loss: 0.176955
2023-01-01 04:31: Train Epoch 11: 607/634 Loss: 0.152532
2023-01-01 04:32: Train Epoch 11: 611/634 Loss: 0.177491
2023-01-01 04:32: Train Epoch 11: 615/634 Loss: 0.142603
2023-01-01 04:33: Train Epoch 11: 619/634 Loss: 0.185318
2023-01-01 04:33: Train Epoch 11: 623/634 Loss: 0.203738
2023-01-01 04:34: Train Epoch 11: 627/634 Loss: 0.184151
2023-01-01 04:34: Train Epoch 11: 631/634 Loss: 0.183740
2023-01-01 04:34: Train Epoch 11: 633/634 Loss: 0.074012
2023-01-01 04:34: **********Train Epoch 11: averaged Loss: 0.166746 
2023-01-01 04:34: 
Epoch time elapsed: 5133.357525348663

2023-01-01 04:37: 
 metrics validation: {'precision': 0.765329295987888, 'recall': 0.7776923076923077, 'f1-score': 0.7714612743227777, 'support': 1300, 'AUC': 0.9176730769230772, 'AUCPR': 0.8464489592546834, 'TP': 1011, 'FP': 310, 'TN': 2290, 'FN': 289} 

2023-01-01 04:37: **********Val Epoch 11: average Loss: 0.165292
2023-01-01 04:39: 
 Testing metrics {'precision': 0.8473138548539114, 'recall': 0.7320846905537459, 'f1-score': 0.7854958497160331, 'support': 1228, 'AUC': 0.9191848189370709, 'AUCPR': 0.8719737718674695, 'TP': 899, 'FP': 162, 'TN': 2294, 'FN': 329} 

2023-01-01 04:46: 
 Testing metrics {'precision': 0.9063348416289593, 'recall': 0.9090083957340594, 'f1-score': 0.9076696499376912, 'support': 4407, 'AUC': 0.979419692941624, 'AUCPR': 0.9624397724215709, 'TP': 4006, 'FP': 414, 'TN': 8400, 'FN': 401} 

2023-01-01 04:46: Train Epoch 12: 3/634 Loss: 0.136932
2023-01-01 04:47: Train Epoch 12: 7/634 Loss: 0.218045
2023-01-01 04:48: Train Epoch 12: 11/634 Loss: 0.185008
2023-01-01 04:48: Train Epoch 12: 15/634 Loss: 0.192812
2023-01-01 04:49: Train Epoch 12: 19/634 Loss: 0.161719
2023-01-01 04:49: Train Epoch 12: 23/634 Loss: 0.197510
2023-01-01 04:50: Train Epoch 12: 27/634 Loss: 0.231943
2023-01-01 04:50: Train Epoch 12: 31/634 Loss: 0.182998
2023-01-01 04:51: Train Epoch 12: 35/634 Loss: 0.225214
2023-01-01 04:51: Train Epoch 12: 39/634 Loss: 0.163624
2023-01-01 04:52: Train Epoch 12: 43/634 Loss: 0.183101
2023-01-01 04:52: Train Epoch 12: 47/634 Loss: 0.201328
2023-01-01 04:53: Train Epoch 12: 51/634 Loss: 0.200607
2023-01-01 04:53: Train Epoch 12: 55/634 Loss: 0.163362
2023-01-01 04:54: Train Epoch 12: 59/634 Loss: 0.190760
2023-01-01 04:54: Train Epoch 12: 63/634 Loss: 0.176323
2023-01-01 04:55: Train Epoch 12: 67/634 Loss: 0.170692
2023-01-01 04:55: Train Epoch 12: 71/634 Loss: 0.184522
2023-01-01 04:56: Train Epoch 12: 75/634 Loss: 0.154902
2023-01-01 04:56: Train Epoch 12: 79/634 Loss: 0.172635
2023-01-01 04:57: Train Epoch 12: 83/634 Loss: 0.152778
2023-01-01 04:57: Train Epoch 12: 87/634 Loss: 0.155768
2023-01-01 04:58: Train Epoch 12: 91/634 Loss: 0.162357
2023-01-01 04:59: Train Epoch 12: 95/634 Loss: 0.169440
2023-01-01 04:59: Train Epoch 12: 99/634 Loss: 0.134275
2023-01-01 05:00: Train Epoch 12: 103/634 Loss: 0.154964
2023-01-01 05:00: Train Epoch 12: 107/634 Loss: 0.150420
2023-01-01 05:01: Train Epoch 12: 111/634 Loss: 0.153244
2023-01-01 05:01: Train Epoch 12: 115/634 Loss: 0.188150
2023-01-01 05:02: Train Epoch 12: 119/634 Loss: 0.180363
2023-01-01 05:02: Train Epoch 12: 123/634 Loss: 0.140323
2023-01-01 05:03: Train Epoch 12: 127/634 Loss: 0.157847
2023-01-01 05:03: Train Epoch 12: 131/634 Loss: 0.176083
2023-01-01 05:04: Train Epoch 12: 135/634 Loss: 0.155209
2023-01-01 05:04: Train Epoch 12: 139/634 Loss: 0.172778
2023-01-01 05:05: Train Epoch 12: 143/634 Loss: 0.183292
2023-01-01 05:05: Train Epoch 12: 147/634 Loss: 0.163170
2023-01-01 05:06: Train Epoch 12: 151/634 Loss: 0.150520
2023-01-01 05:06: Train Epoch 12: 155/634 Loss: 0.145758
2023-01-01 05:07: Train Epoch 12: 159/634 Loss: 0.187335
2023-01-01 05:07: Train Epoch 12: 163/634 Loss: 0.184185
2023-01-01 05:08: Train Epoch 12: 167/634 Loss: 0.169364
2023-01-01 05:09: Train Epoch 12: 171/634 Loss: 0.155730
2023-01-01 05:09: Train Epoch 12: 175/634 Loss: 0.165985
2023-01-01 05:10: Train Epoch 12: 179/634 Loss: 0.152859
2023-01-01 05:10: Train Epoch 12: 183/634 Loss: 0.175199
2023-01-01 05:11: Train Epoch 12: 187/634 Loss: 0.154744
2023-01-01 05:11: Train Epoch 12: 191/634 Loss: 0.154752
2023-01-01 05:12: Train Epoch 12: 195/634 Loss: 0.179330
2023-01-01 05:12: Train Epoch 12: 199/634 Loss: 0.161845
2023-01-01 05:13: Train Epoch 12: 203/634 Loss: 0.217987
2023-01-01 05:13: Train Epoch 12: 207/634 Loss: 0.167423
2023-01-01 05:14: Train Epoch 12: 211/634 Loss: 0.191855
2023-01-01 05:14: Train Epoch 12: 215/634 Loss: 0.158136
2023-01-01 05:15: Train Epoch 12: 219/634 Loss: 0.190198
2023-01-01 05:16: Train Epoch 12: 223/634 Loss: 0.235205
2023-01-01 05:16: Train Epoch 12: 227/634 Loss: 0.194185
2023-01-01 05:17: Train Epoch 12: 231/634 Loss: 0.183630
2023-01-01 05:17: Train Epoch 12: 235/634 Loss: 0.150969
2023-01-01 05:18: Train Epoch 12: 239/634 Loss: 0.151370
2023-01-01 05:18: Train Epoch 12: 243/634 Loss: 0.179168
2023-01-01 05:19: Train Epoch 12: 247/634 Loss: 0.154934
2023-01-01 05:19: Train Epoch 12: 251/634 Loss: 0.155106
2023-01-01 05:20: Train Epoch 12: 255/634 Loss: 0.194779
2023-01-01 05:20: Train Epoch 12: 259/634 Loss: 0.147527
2023-01-01 05:21: Train Epoch 12: 263/634 Loss: 0.145829
2023-01-01 05:21: Train Epoch 12: 267/634 Loss: 0.145200
2023-01-01 05:22: Train Epoch 12: 271/634 Loss: 0.196183
2023-01-01 05:22: Train Epoch 12: 275/634 Loss: 0.177431
2023-01-01 05:23: Train Epoch 12: 279/634 Loss: 0.170457
2023-01-01 05:24: Train Epoch 12: 283/634 Loss: 0.154243
2023-01-01 05:24: Train Epoch 12: 287/634 Loss: 0.223394
2023-01-01 05:25: Train Epoch 12: 291/634 Loss: 0.136796
2023-01-01 05:25: Train Epoch 12: 295/634 Loss: 0.196119
2023-01-01 05:26: Train Epoch 12: 299/634 Loss: 0.223941
2023-01-01 05:26: Train Epoch 12: 303/634 Loss: 0.165721
2023-01-01 05:27: Train Epoch 12: 307/634 Loss: 0.217638
2023-01-01 05:27: Train Epoch 12: 311/634 Loss: 0.192357
2023-01-01 05:28: Train Epoch 12: 315/634 Loss: 0.161226
2023-01-01 05:28: Train Epoch 12: 319/634 Loss: 0.221237
2023-01-01 05:29: Train Epoch 12: 323/634 Loss: 0.190426
2023-01-01 05:29: Train Epoch 12: 327/634 Loss: 0.151514
2023-01-01 05:30: Train Epoch 12: 331/634 Loss: 0.185326
2023-01-01 05:30: Train Epoch 12: 335/634 Loss: 0.161759
2023-01-01 05:31: Train Epoch 12: 339/634 Loss: 0.188188
2023-01-01 05:32: Train Epoch 12: 343/634 Loss: 0.166917
2023-01-01 05:32: Train Epoch 12: 347/634 Loss: 0.170900
2023-01-01 05:33: Train Epoch 12: 351/634 Loss: 0.178334
2023-01-01 05:33: Train Epoch 12: 355/634 Loss: 0.170830
2023-01-01 05:34: Train Epoch 12: 359/634 Loss: 0.159431
2023-01-01 05:34: Train Epoch 12: 363/634 Loss: 0.150611
2023-01-01 05:35: Train Epoch 12: 367/634 Loss: 0.167337
2023-01-01 05:35: Train Epoch 12: 371/634 Loss: 0.163490
2023-01-01 05:36: Train Epoch 12: 375/634 Loss: 0.177981
2023-01-01 05:36: Train Epoch 12: 379/634 Loss: 0.201729
2023-01-01 05:37: Train Epoch 12: 383/634 Loss: 0.168757
2023-01-01 05:37: Train Epoch 12: 387/634 Loss: 0.190901
2023-01-01 05:38: Train Epoch 12: 391/634 Loss: 0.138667
2023-01-01 05:38: Train Epoch 12: 395/634 Loss: 0.171549
2023-01-01 05:39: Train Epoch 12: 399/634 Loss: 0.154609
2023-01-01 05:39: Train Epoch 12: 403/634 Loss: 0.175516
2023-01-01 05:40: Train Epoch 12: 407/634 Loss: 0.189726
2023-01-01 05:41: Train Epoch 12: 411/634 Loss: 0.171054
2023-01-01 05:41: Train Epoch 12: 415/634 Loss: 0.149758
2023-01-01 05:42: Train Epoch 12: 419/634 Loss: 0.156179
2023-01-01 05:42: Train Epoch 12: 423/634 Loss: 0.148879
2023-01-01 05:43: Train Epoch 12: 427/634 Loss: 0.145054
2023-01-01 05:43: Train Epoch 12: 431/634 Loss: 0.132049
2023-01-01 05:44: Train Epoch 12: 435/634 Loss: 0.147365
2023-01-01 05:44: Train Epoch 12: 439/634 Loss: 0.155008
2023-01-01 05:45: Train Epoch 12: 443/634 Loss: 0.166980
2023-01-01 05:45: Train Epoch 12: 447/634 Loss: 0.174748
2023-01-01 05:46: Train Epoch 12: 451/634 Loss: 0.172871
2023-01-01 05:46: Train Epoch 12: 455/634 Loss: 0.156823
2023-01-01 05:47: Train Epoch 12: 459/634 Loss: 0.189747
2023-01-01 05:47: Train Epoch 12: 463/634 Loss: 0.151160
2023-01-01 05:48: Train Epoch 12: 467/634 Loss: 0.153309
2023-01-01 05:48: Train Epoch 12: 471/634 Loss: 0.148854
2023-01-01 05:49: Train Epoch 12: 475/634 Loss: 0.140465
2023-01-01 05:49: Train Epoch 12: 479/634 Loss: 0.139829
2023-01-01 05:50: Train Epoch 12: 483/634 Loss: 0.159308
2023-01-01 05:51: Train Epoch 12: 487/634 Loss: 0.171701
2023-01-01 05:51: Train Epoch 12: 491/634 Loss: 0.194328
2023-01-01 05:52: Train Epoch 12: 495/634 Loss: 0.113955
2023-01-01 05:52: Train Epoch 12: 499/634 Loss: 0.180219
2023-01-01 05:53: Train Epoch 12: 503/634 Loss: 0.150533
2023-01-01 05:53: Train Epoch 12: 507/634 Loss: 0.179649
2023-01-01 05:54: Train Epoch 12: 511/634 Loss: 0.165823
2023-01-01 05:54: Train Epoch 12: 515/634 Loss: 0.187164
2023-01-01 05:55: Train Epoch 12: 519/634 Loss: 0.169450
2023-01-01 05:55: Train Epoch 12: 523/634 Loss: 0.144748
2023-01-01 05:56: Train Epoch 12: 527/634 Loss: 0.159558
2023-01-01 05:56: Train Epoch 12: 531/634 Loss: 0.159468
2023-01-01 05:57: Train Epoch 12: 535/634 Loss: 0.150284
2023-01-01 05:57: Train Epoch 12: 539/634 Loss: 0.182742
2023-01-01 05:58: Train Epoch 12: 543/634 Loss: 0.166067
2023-01-01 05:59: Train Epoch 12: 547/634 Loss: 0.160318
2023-01-01 05:59: Train Epoch 12: 551/634 Loss: 0.164238
2023-01-01 06:00: Train Epoch 12: 555/634 Loss: 0.161739
2023-01-01 06:00: Train Epoch 12: 559/634 Loss: 0.165600
2023-01-01 06:01: Train Epoch 12: 563/634 Loss: 0.188312
2023-01-01 06:01: Train Epoch 12: 567/634 Loss: 0.162085
2023-01-01 06:02: Train Epoch 12: 571/634 Loss: 0.174484
2023-01-01 06:02: Train Epoch 12: 575/634 Loss: 0.158762
2023-01-01 06:03: Train Epoch 12: 579/634 Loss: 0.207744
2023-01-01 06:03: Train Epoch 12: 583/634 Loss: 0.158098
2023-01-01 06:04: Train Epoch 12: 587/634 Loss: 0.153155
2023-01-01 06:04: Train Epoch 12: 591/634 Loss: 0.193011
2023-01-01 06:05: Train Epoch 12: 595/634 Loss: 0.180168
2023-01-01 06:05: Train Epoch 12: 599/634 Loss: 0.154154
2023-01-01 06:06: Train Epoch 12: 603/634 Loss: 0.180168
2023-01-01 06:07: Train Epoch 12: 607/634 Loss: 0.159036
2023-01-01 06:07: Train Epoch 12: 611/634 Loss: 0.170739
2023-01-01 06:08: Train Epoch 12: 615/634 Loss: 0.194226
2023-01-01 06:08: Train Epoch 12: 619/634 Loss: 0.180086
2023-01-01 06:09: Train Epoch 12: 623/634 Loss: 0.179122
2023-01-01 06:09: Train Epoch 12: 627/634 Loss: 0.166970
2023-01-01 06:10: Train Epoch 12: 631/634 Loss: 0.162858
2023-01-01 06:10: Train Epoch 12: 633/634 Loss: 0.075603
2023-01-01 06:10: **********Train Epoch 12: averaged Loss: 0.170080 
2023-01-01 06:10: 
Epoch time elapsed: 5056.366366386414

2023-01-01 06:12: 
 metrics validation: {'precision': 0.8118410381184104, 'recall': 0.77, 'f1-score': 0.7903671535728384, 'support': 1300, 'AUC': 0.9265186390532545, 'AUCPR': 0.8549735636361115, 'TP': 1001, 'FP': 232, 'TN': 2368, 'FN': 299} 

2023-01-01 06:12: **********Val Epoch 12: average Loss: 0.154501
2023-01-01 06:14: 
 Testing metrics {'precision': 0.8473138548539114, 'recall': 0.7320846905537459, 'f1-score': 0.7854958497160331, 'support': 1228, 'AUC': 0.9191848189370709, 'AUCPR': 0.8719737718674695, 'TP': 899, 'FP': 162, 'TN': 2294, 'FN': 329} 

2023-01-01 06:22: 
 Testing metrics {'precision': 0.9063348416289593, 'recall': 0.9090083957340594, 'f1-score': 0.9076696499376912, 'support': 4407, 'AUC': 0.979419692941624, 'AUCPR': 0.9624397724215709, 'TP': 4006, 'FP': 414, 'TN': 8400, 'FN': 401} 

2023-01-01 06:22: Train Epoch 13: 3/634 Loss: 0.159614
2023-01-01 06:23: Train Epoch 13: 7/634 Loss: 0.163318
2023-01-01 06:23: Train Epoch 13: 11/634 Loss: 0.154159
2023-01-01 06:24: Train Epoch 13: 15/634 Loss: 0.147922
2023-01-01 06:24: Train Epoch 13: 19/634 Loss: 0.154548
2023-01-01 06:25: Train Epoch 13: 23/634 Loss: 0.164627
2023-01-01 06:25: Train Epoch 13: 27/634 Loss: 0.167184
2023-01-01 06:26: Train Epoch 13: 31/634 Loss: 0.175605
2023-01-01 06:26: Train Epoch 13: 35/634 Loss: 0.168527
2023-01-01 06:27: Train Epoch 13: 39/634 Loss: 0.158333
2023-01-01 06:28: Train Epoch 13: 43/634 Loss: 0.203592
2023-01-01 06:28: Train Epoch 13: 47/634 Loss: 0.182531
2023-01-01 06:29: Train Epoch 13: 51/634 Loss: 0.161649
2023-01-01 06:29: Train Epoch 13: 55/634 Loss: 0.191214
2023-01-01 06:30: Train Epoch 13: 59/634 Loss: 0.165077
2023-01-01 06:30: Train Epoch 13: 63/634 Loss: 0.182154
2023-01-01 06:31: Train Epoch 13: 67/634 Loss: 0.155591
2023-01-01 06:31: Train Epoch 13: 71/634 Loss: 0.152798
2023-01-01 06:32: Train Epoch 13: 75/634 Loss: 0.150283
2023-01-01 06:32: Train Epoch 13: 79/634 Loss: 0.142907
2023-01-01 06:33: Train Epoch 13: 83/634 Loss: 0.165640
2023-01-01 06:33: Train Epoch 13: 87/634 Loss: 0.141063
2023-01-01 06:34: Train Epoch 13: 91/634 Loss: 0.156330
2023-01-01 06:34: Train Epoch 13: 95/634 Loss: 0.161960
2023-01-01 06:35: Train Epoch 13: 99/634 Loss: 0.162594
2023-01-01 06:36: Train Epoch 13: 103/634 Loss: 0.172480
2023-01-01 06:36: Train Epoch 13: 107/634 Loss: 0.163454
2023-01-01 06:37: Train Epoch 13: 111/634 Loss: 0.177412
2023-01-01 06:37: Train Epoch 13: 115/634 Loss: 0.163787
2023-01-01 06:38: Train Epoch 13: 119/634 Loss: 0.121001
2023-01-01 06:38: Train Epoch 13: 123/634 Loss: 0.195498
2023-01-01 06:39: Train Epoch 13: 127/634 Loss: 0.154749
2023-01-01 06:39: Train Epoch 13: 131/634 Loss: 0.148656
2023-01-01 06:40: Train Epoch 13: 135/634 Loss: 0.150995
2023-01-01 06:40: Train Epoch 13: 139/634 Loss: 0.169374
2023-01-01 06:41: Train Epoch 13: 143/634 Loss: 0.152525
2023-01-01 06:41: Train Epoch 13: 147/634 Loss: 0.184768
2023-01-01 06:42: Train Epoch 13: 151/634 Loss: 0.179743
2023-01-01 06:43: Train Epoch 13: 155/634 Loss: 0.155053
2023-01-01 06:43: Train Epoch 13: 159/634 Loss: 0.148763
2023-01-01 06:44: Train Epoch 13: 163/634 Loss: 0.139137
2023-01-01 06:44: Train Epoch 13: 167/634 Loss: 0.196271
2023-01-01 06:45: Train Epoch 13: 171/634 Loss: 0.146577
2023-01-01 06:45: Train Epoch 13: 175/634 Loss: 0.163754
2023-01-01 06:46: Train Epoch 13: 179/634 Loss: 0.134853
2023-01-01 06:46: Train Epoch 13: 183/634 Loss: 0.164777
2023-01-01 06:47: Train Epoch 13: 187/634 Loss: 0.149355
2023-01-01 06:47: Train Epoch 13: 191/634 Loss: 0.175713
2023-01-01 06:48: Train Epoch 13: 195/634 Loss: 0.160285
2023-01-01 06:48: Train Epoch 13: 199/634 Loss: 0.168863
2023-01-01 06:49: Train Epoch 13: 203/634 Loss: 0.159640
2023-01-01 06:49: Train Epoch 13: 207/634 Loss: 0.180232
2023-01-01 06:50: Train Epoch 13: 211/634 Loss: 0.158115
2023-01-01 06:51: Train Epoch 13: 215/634 Loss: 0.193440
2023-01-01 06:51: Train Epoch 13: 219/634 Loss: 0.151623
2023-01-01 06:52: Train Epoch 13: 223/634 Loss: 0.169914
2023-01-01 06:52: Train Epoch 13: 227/634 Loss: 0.143910
2023-01-01 06:53: Train Epoch 13: 231/634 Loss: 0.183206
2023-01-01 06:53: Train Epoch 13: 235/634 Loss: 0.177174
2023-01-01 06:54: Train Epoch 13: 239/634 Loss: 0.160503
2023-01-01 06:54: Train Epoch 13: 243/634 Loss: 0.175263
2023-01-01 06:55: Train Epoch 13: 247/634 Loss: 0.192702
2023-01-01 06:55: Train Epoch 13: 251/634 Loss: 0.177765
2023-01-01 06:56: Train Epoch 13: 255/634 Loss: 0.222450
2023-01-01 06:56: Train Epoch 13: 259/634 Loss: 0.161289
2023-01-01 06:57: Train Epoch 13: 263/634 Loss: 0.186916
2023-01-01 06:57: Train Epoch 13: 267/634 Loss: 0.201286
2023-01-01 06:58: Train Epoch 13: 271/634 Loss: 0.151576
2023-01-01 06:59: Train Epoch 13: 275/634 Loss: 0.178640
2023-01-01 06:59: Train Epoch 13: 279/634 Loss: 0.157136
2023-01-01 07:00: Train Epoch 13: 283/634 Loss: 0.153344
2023-01-01 07:00: Train Epoch 13: 287/634 Loss: 0.163386
2023-01-01 07:01: Train Epoch 13: 291/634 Loss: 0.152553
2023-01-01 07:01: Train Epoch 13: 295/634 Loss: 0.160081
2023-01-01 07:02: Train Epoch 13: 299/634 Loss: 0.155143
2023-01-01 07:02: Train Epoch 13: 303/634 Loss: 0.200720
2023-01-01 07:03: Train Epoch 13: 307/634 Loss: 0.124615
2023-01-01 07:03: Train Epoch 13: 311/634 Loss: 0.181778
2023-01-01 07:04: Train Epoch 13: 315/634 Loss: 0.146315
2023-01-01 07:04: Train Epoch 13: 319/634 Loss: 0.171736
2023-01-01 07:05: Train Epoch 13: 323/634 Loss: 0.152790
2023-01-01 07:06: Train Epoch 13: 327/634 Loss: 0.198230
2023-01-01 07:06: Train Epoch 13: 331/634 Loss: 0.174296
2023-01-01 07:07: Train Epoch 13: 335/634 Loss: 0.169671
2023-01-01 07:07: Train Epoch 13: 339/634 Loss: 0.162445
2023-01-01 07:08: Train Epoch 13: 343/634 Loss: 0.173667
2023-01-01 07:08: Train Epoch 13: 347/634 Loss: 0.170643
2023-01-01 07:09: Train Epoch 13: 351/634 Loss: 0.160430
2023-01-01 07:09: Train Epoch 13: 355/634 Loss: 0.199590
2023-01-01 07:10: Train Epoch 13: 359/634 Loss: 0.175789
2023-01-01 07:10: Train Epoch 13: 363/634 Loss: 0.157217
2023-01-01 07:11: Train Epoch 13: 367/634 Loss: 0.180634
2023-01-01 07:11: Train Epoch 13: 371/634 Loss: 0.183331
2023-01-01 07:12: Train Epoch 13: 375/634 Loss: 0.172827
2023-01-01 07:13: Train Epoch 13: 379/634 Loss: 0.165607
2023-01-01 07:13: Train Epoch 13: 383/634 Loss: 0.153863
2023-01-01 07:14: Train Epoch 13: 387/634 Loss: 0.191866
2023-01-01 07:14: Train Epoch 13: 391/634 Loss: 0.198162
2023-01-01 07:15: Train Epoch 13: 395/634 Loss: 0.158910
2023-01-01 07:15: Train Epoch 13: 399/634 Loss: 0.241451
2023-01-01 07:16: Train Epoch 13: 403/634 Loss: 0.164088
2023-01-01 07:16: Train Epoch 13: 407/634 Loss: 0.184567
2023-01-01 07:17: Train Epoch 13: 411/634 Loss: 0.223601
2023-01-01 07:17: Train Epoch 13: 415/634 Loss: 0.142083
2023-01-01 07:18: Train Epoch 13: 419/634 Loss: 0.181638
2023-01-01 07:18: Train Epoch 13: 423/634 Loss: 0.176610
2023-01-01 07:19: Train Epoch 13: 427/634 Loss: 0.177926
2023-01-01 07:19: Train Epoch 13: 431/634 Loss: 0.167645
2023-01-01 07:20: Train Epoch 13: 435/634 Loss: 0.245232
2023-01-01 07:21: Train Epoch 13: 439/634 Loss: 0.165942
2023-01-01 07:21: Train Epoch 13: 443/634 Loss: 0.209502
2023-01-01 07:22: Train Epoch 13: 447/634 Loss: 0.209441
2023-01-01 07:22: Train Epoch 13: 451/634 Loss: 0.194167
2023-01-01 07:23: Train Epoch 13: 455/634 Loss: 0.206041
2023-01-01 07:23: Train Epoch 13: 459/634 Loss: 0.160641
2023-01-01 07:24: Train Epoch 13: 463/634 Loss: 0.175035
2023-01-01 07:24: Train Epoch 13: 467/634 Loss: 0.163517
2023-01-01 07:25: Train Epoch 13: 471/634 Loss: 0.215095
2023-01-01 07:25: Train Epoch 13: 475/634 Loss: 0.184446
2023-01-01 07:26: Train Epoch 13: 479/634 Loss: 0.176905
2023-01-01 07:26: Train Epoch 13: 483/634 Loss: 0.170390
2023-01-01 07:27: Train Epoch 13: 487/634 Loss: 0.151029
2023-01-01 07:27: Train Epoch 13: 491/634 Loss: 0.148368
2023-01-01 07:28: Train Epoch 13: 495/634 Loss: 0.155547
2023-01-01 07:28: Train Epoch 13: 499/634 Loss: 0.157349
2023-01-01 07:29: Train Epoch 13: 503/634 Loss: 0.194091
2023-01-01 07:30: Train Epoch 13: 507/634 Loss: 0.182143
2023-01-01 07:30: Train Epoch 13: 511/634 Loss: 0.147162
2023-01-01 07:31: Train Epoch 13: 515/634 Loss: 0.176290
2023-01-01 07:31: Train Epoch 13: 519/634 Loss: 0.169726
2023-01-01 07:32: Train Epoch 13: 523/634 Loss: 0.175500
2023-01-01 07:32: Train Epoch 13: 527/634 Loss: 0.176122
2023-01-01 07:33: Train Epoch 13: 531/634 Loss: 0.179799
2023-01-01 07:33: Train Epoch 13: 535/634 Loss: 0.183677
2023-01-01 07:34: Train Epoch 13: 539/634 Loss: 0.211093
2023-01-01 07:34: Train Epoch 13: 543/634 Loss: 0.139831
2023-01-01 07:35: Train Epoch 13: 547/634 Loss: 0.270202
2023-01-01 07:35: Train Epoch 13: 551/634 Loss: 0.150991
2023-01-01 07:36: Train Epoch 13: 555/634 Loss: 0.172554
2023-01-01 07:36: Train Epoch 13: 559/634 Loss: 0.166367
2023-01-01 07:37: Train Epoch 13: 563/634 Loss: 0.172248
2023-01-01 07:37: Train Epoch 13: 567/634 Loss: 0.162623
2023-01-01 07:38: Train Epoch 13: 571/634 Loss: 0.222333
2023-01-01 07:39: Train Epoch 13: 575/634 Loss: 0.162565
2023-01-01 07:39: Train Epoch 13: 579/634 Loss: 0.262730
2023-01-01 07:40: Train Epoch 13: 583/634 Loss: 0.161079
2023-01-01 07:40: Train Epoch 13: 587/634 Loss: 0.177635
2023-01-01 07:41: Train Epoch 13: 591/634 Loss: 0.199592
2023-01-01 07:41: Train Epoch 13: 595/634 Loss: 0.219897
2023-01-01 07:42: Train Epoch 13: 599/634 Loss: 0.165480
2023-01-01 07:42: Train Epoch 13: 603/634 Loss: 0.176846
2023-01-01 07:43: Train Epoch 13: 607/634 Loss: 0.163910
2023-01-01 07:43: Train Epoch 13: 611/634 Loss: 0.196434
2023-01-01 07:44: Train Epoch 13: 615/634 Loss: 0.230164
2023-01-01 07:44: Train Epoch 13: 619/634 Loss: 0.174598
2023-01-01 07:45: Train Epoch 13: 623/634 Loss: 0.207015
2023-01-01 07:45: Train Epoch 13: 627/634 Loss: 0.233872
2023-01-01 07:46: Train Epoch 13: 631/634 Loss: 0.202547
2023-01-01 07:46: Train Epoch 13: 633/634 Loss: 0.067658
2023-01-01 07:46: **********Train Epoch 13: averaged Loss: 0.173098 
2023-01-01 07:46: 
Epoch time elapsed: 5064.8877825737

2023-01-01 07:48: 
 metrics validation: {'precision': 0.9029411764705882, 'recall': 0.4723076923076923, 'f1-score': 0.6202020202020203, 'support': 1300, 'AUC': 0.9173695266272189, 'AUCPR': 0.8481541106264985, 'TP': 614, 'FP': 66, 'TN': 2534, 'FN': 686} 

2023-01-01 07:48: **********Val Epoch 13: average Loss: 0.227224
2023-01-01 07:50: 
 Testing metrics {'precision': 0.8473138548539114, 'recall': 0.7320846905537459, 'f1-score': 0.7854958497160331, 'support': 1228, 'AUC': 0.9191848189370709, 'AUCPR': 0.8719737718674695, 'TP': 899, 'FP': 162, 'TN': 2294, 'FN': 329} 

2023-01-01 07:58: 
 Testing metrics {'precision': 0.9063348416289593, 'recall': 0.9090083957340594, 'f1-score': 0.9076696499376912, 'support': 4407, 'AUC': 0.979419692941624, 'AUCPR': 0.9624397724215709, 'TP': 4006, 'FP': 414, 'TN': 8400, 'FN': 401} 

2023-01-01 07:58: Train Epoch 14: 3/634 Loss: 0.154007
2023-01-01 07:59: Train Epoch 14: 7/634 Loss: 0.130605
2023-01-01 07:59: Train Epoch 14: 11/634 Loss: 0.183343
2023-01-01 08:00: Train Epoch 14: 15/634 Loss: 0.151809
2023-01-01 08:01: Train Epoch 14: 19/634 Loss: 0.162399
2023-01-01 08:01: Train Epoch 14: 23/634 Loss: 0.197937
2023-01-01 08:02: Train Epoch 14: 27/634 Loss: 0.153045
2023-01-01 08:02: Train Epoch 14: 31/634 Loss: 0.203548
2023-01-01 08:03: Train Epoch 14: 35/634 Loss: 0.203104
2023-01-01 08:03: Train Epoch 14: 39/634 Loss: 0.162721
2023-01-01 08:04: Train Epoch 14: 43/634 Loss: 0.229117
2023-01-01 08:04: Train Epoch 14: 47/634 Loss: 0.182450
2023-01-01 08:05: Train Epoch 14: 51/634 Loss: 0.180626
2023-01-01 08:05: Train Epoch 14: 55/634 Loss: 0.139017
2023-01-01 08:06: Train Epoch 14: 59/634 Loss: 0.131822
2023-01-01 08:06: Train Epoch 14: 63/634 Loss: 0.162775
2023-01-01 08:07: Train Epoch 14: 67/634 Loss: 0.164501
2023-01-01 08:07: Train Epoch 14: 71/634 Loss: 0.170636
2023-01-01 08:08: Train Epoch 14: 75/634 Loss: 0.175853
2023-01-01 08:08: Train Epoch 14: 79/634 Loss: 0.193248
2023-01-01 08:09: Train Epoch 14: 83/634 Loss: 0.168673
2023-01-01 08:09: Train Epoch 14: 87/634 Loss: 0.150612
2023-01-01 08:10: Train Epoch 14: 91/634 Loss: 0.170932
2023-01-01 08:11: Train Epoch 14: 95/634 Loss: 0.153473
2023-01-01 08:11: Train Epoch 14: 99/634 Loss: 0.142893
2023-01-01 08:12: Train Epoch 14: 103/634 Loss: 0.152761
2023-01-01 08:12: Train Epoch 14: 107/634 Loss: 0.141347
2023-01-01 08:13: Train Epoch 14: 111/634 Loss: 0.145468
2023-01-01 08:13: Train Epoch 14: 115/634 Loss: 0.170455
2023-01-01 08:14: Train Epoch 14: 119/634 Loss: 0.159476
2023-01-01 08:14: Train Epoch 14: 123/634 Loss: 0.173713
2023-01-01 08:15: Train Epoch 14: 127/634 Loss: 0.159633
2023-01-01 08:15: Train Epoch 14: 131/634 Loss: 0.173342
2023-01-01 08:16: Train Epoch 14: 135/634 Loss: 0.149387
2023-01-01 08:16: Train Epoch 14: 139/634 Loss: 0.163794
2023-01-01 08:17: Train Epoch 14: 143/634 Loss: 0.152038
2023-01-01 08:17: Train Epoch 14: 147/634 Loss: 0.165288
2023-01-01 08:18: Train Epoch 14: 151/634 Loss: 0.163447
2023-01-01 08:18: Train Epoch 14: 155/634 Loss: 0.199735
2023-01-01 08:19: Train Epoch 14: 159/634 Loss: 0.134547
2023-01-01 08:19: Train Epoch 14: 163/634 Loss: 0.169683
2023-01-01 08:20: Train Epoch 14: 167/634 Loss: 0.146553
2023-01-01 08:21: Train Epoch 14: 171/634 Loss: 0.160038
2023-01-01 08:21: Train Epoch 14: 175/634 Loss: 0.167213
2023-01-01 08:22: Train Epoch 14: 179/634 Loss: 0.179340
2023-01-01 08:22: Train Epoch 14: 183/634 Loss: 0.154414
2023-01-01 08:23: Train Epoch 14: 187/634 Loss: 0.151654
2023-01-01 08:23: Train Epoch 14: 191/634 Loss: 0.179718
2023-01-01 08:24: Train Epoch 14: 195/634 Loss: 0.145115
2023-01-01 08:24: Train Epoch 14: 199/634 Loss: 0.154344
2023-01-01 08:25: Train Epoch 14: 203/634 Loss: 0.150334
2023-01-01 08:25: Train Epoch 14: 207/634 Loss: 0.159022
2023-01-01 08:26: Train Epoch 14: 211/634 Loss: 0.152084
2023-01-01 08:26: Train Epoch 14: 215/634 Loss: 0.155593
2023-01-01 08:27: Train Epoch 14: 219/634 Loss: 0.186859
2023-01-01 08:27: Train Epoch 14: 223/634 Loss: 0.146748
2023-01-01 08:28: Train Epoch 14: 227/634 Loss: 0.147750
2023-01-01 08:29: Train Epoch 14: 231/634 Loss: 0.123320
2023-01-01 08:29: Train Epoch 14: 235/634 Loss: 0.188795
2023-01-01 08:30: Train Epoch 14: 239/634 Loss: 0.183465
2023-01-01 08:30: Train Epoch 14: 243/634 Loss: 0.164450
2023-01-01 08:31: Train Epoch 14: 247/634 Loss: 0.131253
2023-01-01 08:31: Train Epoch 14: 251/634 Loss: 0.145773
2023-01-01 08:32: Train Epoch 14: 255/634 Loss: 0.150151
2023-01-01 08:32: Train Epoch 14: 259/634 Loss: 0.194081
2023-01-01 08:33: Train Epoch 14: 263/634 Loss: 0.158322
2023-01-01 08:33: Train Epoch 14: 267/634 Loss: 0.199810
2023-01-01 08:34: Train Epoch 14: 271/634 Loss: 0.150138
2023-01-01 08:34: Train Epoch 14: 275/634 Loss: 0.156055
2023-01-01 08:35: Train Epoch 14: 279/634 Loss: 0.174176
2023-01-01 08:35: Train Epoch 14: 283/634 Loss: 0.158218
2023-01-01 08:36: Train Epoch 14: 287/634 Loss: 0.135166
2023-01-01 08:37: Train Epoch 14: 291/634 Loss: 0.149239
2023-01-01 08:37: Train Epoch 14: 295/634 Loss: 0.169190
2023-01-01 08:38: Train Epoch 14: 299/634 Loss: 0.202750
2023-01-01 08:38: Train Epoch 14: 303/634 Loss: 0.170499
2023-01-01 08:39: Train Epoch 14: 307/634 Loss: 0.158374
2023-01-01 08:39: Train Epoch 14: 311/634 Loss: 0.188820
2023-01-01 08:40: Train Epoch 14: 315/634 Loss: 0.182639
2023-01-01 08:41: Train Epoch 14: 319/634 Loss: 0.172152
2023-01-01 08:41: Train Epoch 14: 323/634 Loss: 0.162476
2023-01-01 08:42: Train Epoch 14: 327/634 Loss: 0.179676
2023-01-01 08:42: Train Epoch 14: 331/634 Loss: 0.200136
2023-01-01 08:43: Train Epoch 14: 335/634 Loss: 0.133569
2023-01-01 08:43: Train Epoch 14: 339/634 Loss: 0.200323
2023-01-01 08:44: Train Epoch 14: 343/634 Loss: 0.146303
2023-01-01 08:44: Train Epoch 14: 347/634 Loss: 0.157110
2023-01-01 08:45: Train Epoch 14: 351/634 Loss: 0.174374
2023-01-01 08:45: Train Epoch 14: 355/634 Loss: 0.168456
2023-01-01 08:46: Train Epoch 14: 359/634 Loss: 0.172907
2023-01-01 08:46: Train Epoch 14: 363/634 Loss: 0.152256
2023-01-01 08:47: Train Epoch 14: 367/634 Loss: 0.140327
2023-01-01 08:48: Train Epoch 14: 371/634 Loss: 0.159071
2023-01-01 08:48: Train Epoch 14: 375/634 Loss: 0.182353
2023-01-01 08:49: Train Epoch 14: 379/634 Loss: 0.170061
2023-01-01 08:49: Train Epoch 14: 383/634 Loss: 0.163386
2023-01-01 08:50: Train Epoch 14: 387/634 Loss: 0.205292
2023-01-01 08:50: Train Epoch 14: 391/634 Loss: 0.140489
2023-01-01 08:51: Train Epoch 14: 395/634 Loss: 0.141251
2023-01-01 08:51: Train Epoch 14: 399/634 Loss: 0.187127
2023-01-01 08:52: Train Epoch 14: 403/634 Loss: 0.158316
2023-01-01 08:52: Train Epoch 14: 407/634 Loss: 0.166947
2023-01-01 08:53: Train Epoch 14: 411/634 Loss: 0.173385
2023-01-01 08:53: Train Epoch 14: 415/634 Loss: 0.173463
2023-01-01 08:54: Train Epoch 14: 419/634 Loss: 0.146105
2023-01-01 08:55: Train Epoch 14: 423/634 Loss: 0.205643
2023-01-01 08:55: Train Epoch 14: 427/634 Loss: 0.145613
2023-01-01 08:56: Train Epoch 14: 431/634 Loss: 0.167164
2023-01-01 08:56: Train Epoch 14: 435/634 Loss: 0.187545
2023-01-01 08:57: Train Epoch 14: 439/634 Loss: 0.175687
2023-01-01 08:57: Train Epoch 14: 443/634 Loss: 0.210206
2023-01-01 08:58: Train Epoch 14: 447/634 Loss: 0.177668
2023-01-01 08:58: Train Epoch 14: 451/634 Loss: 0.194790
2023-01-01 08:59: Train Epoch 14: 455/634 Loss: 0.166084
2023-01-01 08:59: Train Epoch 14: 459/634 Loss: 0.199295
2023-01-01 09:00: Train Epoch 14: 463/634 Loss: 0.167029
2023-01-01 09:01: Train Epoch 14: 467/634 Loss: 0.166335
2023-01-01 09:01: Train Epoch 14: 471/634 Loss: 0.140574
2023-01-01 09:02: Train Epoch 14: 475/634 Loss: 0.161238
2023-01-01 09:02: Train Epoch 14: 479/634 Loss: 0.155980
2023-01-01 09:03: Train Epoch 14: 483/634 Loss: 0.150214
2023-01-01 09:03: Train Epoch 14: 487/634 Loss: 0.180299
2023-01-01 09:04: Train Epoch 14: 491/634 Loss: 0.150832
2023-01-01 09:04: Train Epoch 14: 495/634 Loss: 0.204859
2023-01-01 09:05: Train Epoch 14: 499/634 Loss: 0.154715
2023-01-01 09:05: Train Epoch 14: 503/634 Loss: 0.171239
2023-01-01 09:06: Train Epoch 14: 507/634 Loss: 0.215756
2023-01-01 09:07: Train Epoch 14: 511/634 Loss: 0.163150
2023-01-01 09:07: Train Epoch 14: 515/634 Loss: 0.195541
2023-01-01 09:08: Train Epoch 14: 519/634 Loss: 0.205319
2023-01-01 09:08: Train Epoch 14: 523/634 Loss: 0.171823
2023-01-01 09:09: Train Epoch 14: 527/634 Loss: 0.161955
2023-01-01 09:09: Train Epoch 14: 531/634 Loss: 0.213594
2023-01-01 09:10: Train Epoch 14: 535/634 Loss: 0.133379
2023-01-01 09:10: Train Epoch 14: 539/634 Loss: 0.154586
2023-01-01 09:11: Train Epoch 14: 543/634 Loss: 0.158842
2023-01-01 09:12: Train Epoch 14: 547/634 Loss: 0.151115
2023-01-01 09:12: Train Epoch 14: 551/634 Loss: 0.176193
2023-01-01 09:13: Train Epoch 14: 555/634 Loss: 0.136309
2023-01-01 09:13: Train Epoch 14: 559/634 Loss: 0.160625
2023-01-01 09:14: Train Epoch 14: 563/634 Loss: 0.160535
2023-01-01 09:14: Train Epoch 14: 567/634 Loss: 0.159548
2023-01-01 09:15: Train Epoch 14: 571/634 Loss: 0.158236
2023-01-01 09:15: Train Epoch 14: 575/634 Loss: 0.166438
2023-01-01 09:16: Train Epoch 14: 579/634 Loss: 0.137372
2023-01-01 09:16: Train Epoch 14: 583/634 Loss: 0.185413
2023-01-01 09:17: Train Epoch 14: 587/634 Loss: 0.149846
2023-01-01 09:17: Train Epoch 14: 591/634 Loss: 0.133699
2023-01-01 09:18: Train Epoch 14: 595/634 Loss: 0.217005
2023-01-01 09:19: Train Epoch 14: 599/634 Loss: 0.154090
2023-01-01 09:19: Train Epoch 14: 603/634 Loss: 0.189030
2023-01-01 09:20: Train Epoch 14: 607/634 Loss: 0.230133
2023-01-01 09:20: Train Epoch 14: 611/634 Loss: 0.192448
2023-01-01 09:21: Train Epoch 14: 615/634 Loss: 0.226304
2023-01-01 09:21: Train Epoch 14: 619/634 Loss: 0.189366
2023-01-01 09:22: Train Epoch 14: 623/634 Loss: 0.201396
2023-01-01 09:22: Train Epoch 14: 627/634 Loss: 0.285699
2023-01-01 09:23: Train Epoch 14: 631/634 Loss: 0.165901
2023-01-01 09:23: Train Epoch 14: 633/634 Loss: 0.096438
2023-01-01 09:23: **********Train Epoch 14: averaged Loss: 0.168064 
2023-01-01 09:23: 
Epoch time elapsed: 5119.9749348163605

2023-01-01 09:25: 
 metrics validation: {'precision': 0.9411764705882353, 'recall': 0.12307692307692308, 'f1-score': 0.217687074829932, 'support': 1300, 'AUC': 0.9051402366863904, 'AUCPR': 0.8110567319655153, 'TP': 160, 'FP': 10, 'TN': 2590, 'FN': 1140} 

2023-01-01 09:25: **********Val Epoch 14: average Loss: 0.460397
2023-01-01 09:25: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-01 09:25: Total training time: 1390.6640min, best loss: 0.151645
2023-01-01 09:25: Saving current best model to /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022123110145043936554013/best_model.pth
2023-01-01 09:27: 
 Testing metrics {'precision': 0.8473138548539114, 'recall': 0.7320846905537459, 'f1-score': 0.7854958497160331, 'support': 1228, 'AUC': 0.9191848189370709, 'AUCPR': 0.8719737718674695, 'TP': 899, 'FP': 162, 'TN': 2294, 'FN': 329} 

2023-01-01 09:34: 
 Testing metrics {'precision': 0.9063348416289593, 'recall': 0.9090083957340594, 'f1-score': 0.9076696499376912, 'support': 4407, 'AUC': 0.979419692941624, 'AUCPR': 0.9624397724215709, 'TP': 4006, 'FP': 414, 'TN': 8400, 'FN': 401} 

