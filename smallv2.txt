JUST SELF-LOOPS ADJACENCY MATRIX
2023-01-06 08:38: log dir: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010608385709590369386
2023-01-06 08:38: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010608385709590369386
2023-01-06 08:38: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010608385709590369386', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=32, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-06 08:38: Argument batch_size: 256
2023-01-06 08:38: Argument clc: 'vec'
2023-01-06 08:38: Argument cuda: True
2023-01-06 08:38: Argument dataset: '2020'
2023-01-06 08:38: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-06 08:38: Argument debug: False
2023-01-06 08:38: Argument default_graph: True
2023-01-06 08:38: Argument device: 'cpu'
2023-01-06 08:38: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-06 08:38: Argument early_stop: True
2023-01-06 08:38: Argument early_stop_patience: 8
2023-01-06 08:38: Argument embed_dim: 64
2023-01-06 08:38: Argument epochs: 30
2023-01-06 08:38: Argument grad_norm: False
2023-01-06 08:38: Argument horizon: 1
2023-01-06 08:38: Argument input_dim: 25
2023-01-06 08:38: Argument lag: 10
2023-01-06 08:38: Argument link_len: 2
2023-01-06 08:38: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010608385709590369386'
2023-01-06 08:38: Argument log_step: 1
2023-01-06 08:38: Argument loss_func: 'nllloss'
2023-01-06 08:38: Argument lr_decay: True
2023-01-06 08:38: Argument lr_decay_rate: 0.1
2023-01-06 08:38: Argument lr_decay_step: '20'
2023-01-06 08:38: Argument lr_init: 0.0001
2023-01-06 08:38: Argument max_grad_norm: 5
2023-01-06 08:38: Argument minbatch_size: 64
2023-01-06 08:38: Argument mode: 'train'
2023-01-06 08:38: Argument model: 'fire_GCN'
2023-01-06 08:38: Argument nan_fill: -1.0
2023-01-06 08:38: Argument num_layers: 1
2023-01-06 08:38: Argument num_nodes: 625
2023-01-06 08:38: Argument num_workers: 12
2023-01-06 08:38: Argument output_dim: 2
2023-01-06 08:38: Argument patch_height: 25
2023-01-06 08:38: Argument patch_width: 25
2023-01-06 08:38: Argument persistent_workers: True
2023-01-06 08:38: Argument pin_memory: True
2023-01-06 08:38: Argument plot: False
2023-01-06 08:38: Argument positive_weight: 0.5
2023-01-06 08:38: Argument prefetch_factor: 2
2023-01-06 08:38: Argument real_value: True
2023-01-06 08:38: Argument rnn_units: 32
2023-01-06 08:38: Argument seed: 10000
2023-01-06 08:38: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-06 08:38: Argument teacher_forcing: False
2023-01-06 08:38: Argument weight_decay: 0.0
2023-01-06 08:38: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([64, 2, 57, 32]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 32]) True
encoder.cell_list.0.gate.bias_pool torch.Size([64, 64]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([64, 2, 57, 16]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 16]) True
encoder.cell_list.0.update.bias_pool torch.Size([64, 32]) True
encoder.cell_list.0.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 20000]) True
fc1.bias torch.Size([2]) True
Total params num: 439496
*****************Finish Parameter****************
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010608385709590369386/run.log
2023-01-06 08:39: Train Epoch 1: 3/24 Loss: 0.408805
2023-01-06 08:39: Train Epoch 1: 7/24 Loss: 0.420312
2023-01-06 08:39: Train Epoch 1: 11/24 Loss: 0.399342
2023-01-06 08:39: Train Epoch 1: 15/24 Loss: 0.313444
2023-01-06 08:39: Train Epoch 1: 19/24 Loss: 0.348503
2023-01-06 08:39: Train Epoch 1: 23/24 Loss: 0.317342
2023-01-06 08:39: **********Train Epoch 1: averaged Loss: 0.367958 
2023-01-06 08:39: 
Epoch time elapsed: 54.41654944419861

2023-01-06 08:40: 
 metrics validation: {'precision': 0.506056527590848, 'recall': 0.752, 'f1-score': 0.6049879324215608, 'support': 500, 'AUC': 0.747978, 'AUCPR': 0.5935788074219186, 'TP': 376, 'FP': 367, 'TN': 633, 'FN': 124} 

2023-01-06 08:40: **********Val Epoch 1: average Loss: 0.299399
2023-01-06 08:40: *********************************Current best model saved!
2023-01-06 08:40: 
 Testing metrics {'precision': 0.5627586206896552, 'recall': 0.816, 'f1-score': 0.6661224489795918, 'support': 500, 'AUC': 0.833628, 'AUCPR': 0.716998519865139, 'TP': 408, 'FP': 317, 'TN': 683, 'FN': 92} 

2023-01-06 08:40: 
 Testing metrics {'precision': 0.6803149606299213, 'recall': 0.864, 'f1-score': 0.7612334801762113, 'support': 500, 'AUC': 0.906216, 'AUCPR': 0.8407892570800289, 'TP': 432, 'FP': 203, 'TN': 797, 'FN': 68} 

2023-01-06 08:41: Train Epoch 2: 3/24 Loss: 0.327859
2023-01-06 08:41: Train Epoch 2: 7/24 Loss: 0.280552
2023-01-06 08:41: Train Epoch 2: 11/24 Loss: 0.286715
2023-01-06 08:41: Train Epoch 2: 15/24 Loss: 0.282244
2023-01-06 08:41: Train Epoch 2: 19/24 Loss: 0.275509
2023-01-06 08:41: Train Epoch 2: 23/24 Loss: 0.240544
2023-01-06 08:41: **********Train Epoch 2: averaged Loss: 0.282237 
2023-01-06 08:41: 
Epoch time elapsed: 54.046710729599

2023-01-06 08:42: 
 metrics validation: {'precision': 0.7039473684210527, 'recall': 0.428, 'f1-score': 0.5323383084577115, 'support': 500, 'AUC': 0.7587739999999998, 'AUCPR': 0.6104789160366537, 'TP': 214, 'FP': 90, 'TN': 910, 'FN': 286} 

2023-01-06 08:42: **********Val Epoch 2: average Loss: 0.268379
2023-01-06 08:42: *********************************Current best model saved!
2023-01-06 08:42: 
 Testing metrics {'precision': 0.7865853658536586, 'recall': 0.516, 'f1-score': 0.6231884057971014, 'support': 500, 'AUC': 0.840354, 'AUCPR': 0.7297525150918727, 'TP': 258, 'FP': 70, 'TN': 930, 'FN': 242} 

2023-01-06 08:42: 
 Testing metrics {'precision': 0.8946135831381733, 'recall': 0.764, 'f1-score': 0.8241639697950378, 'support': 500, 'AUC': 0.9141520000000001, 'AUCPR': 0.8550702557373896, 'TP': 382, 'FP': 45, 'TN': 955, 'FN': 118} 

2023-01-06 08:42: Train Epoch 3: 3/24 Loss: 0.278131
2023-01-06 08:42: Train Epoch 3: 7/24 Loss: 0.278104
2023-01-06 08:43: Train Epoch 3: 11/24 Loss: 0.245040
2023-01-06 08:43: Train Epoch 3: 15/24 Loss: 0.270881
2023-01-06 08:43: Train Epoch 3: 19/24 Loss: 0.254148
2023-01-06 08:43: Train Epoch 3: 23/24 Loss: 0.210697
2023-01-06 08:43: **********Train Epoch 3: averaged Loss: 0.256167 
2023-01-06 08:43: 
Epoch time elapsed: 52.82136845588684

2023-01-06 08:43: 
 metrics validation: {'precision': 0.6993670886075949, 'recall': 0.442, 'f1-score': 0.5416666666666666, 'support': 500, 'AUC': 0.76632, 'AUCPR': 0.6272407818932269, 'TP': 221, 'FP': 95, 'TN': 905, 'FN': 279} 

2023-01-06 08:43: **********Val Epoch 3: average Loss: 0.266446
2023-01-06 08:43: *********************************Current best model saved!
2023-01-06 08:44: 
 Testing metrics {'precision': 0.7833827893175074, 'recall': 0.528, 'f1-score': 0.6308243727598566, 'support': 500, 'AUC': 0.84333, 'AUCPR': 0.7370448968599033, 'TP': 264, 'FP': 73, 'TN': 927, 'FN': 236} 

2023-01-06 08:44: 
 Testing metrics {'precision': 0.8975501113585747, 'recall': 0.806, 'f1-score': 0.8493150684931507, 'support': 500, 'AUC': 0.91899, 'AUCPR': 0.8644235165810421, 'TP': 403, 'FP': 46, 'TN': 954, 'FN': 97} 

2023-01-06 08:44: Train Epoch 4: 3/24 Loss: 0.249882
2023-01-06 08:44: Train Epoch 4: 7/24 Loss: 0.267437
2023-01-06 08:44: Train Epoch 4: 11/24 Loss: 0.256422
2023-01-06 08:45: Train Epoch 4: 15/24 Loss: 0.257606
2023-01-06 08:45: Train Epoch 4: 19/24 Loss: 0.271987
2023-01-06 08:45: Train Epoch 4: 23/24 Loss: 0.191523
2023-01-06 08:45: **********Train Epoch 4: averaged Loss: 0.249143 
2023-01-06 08:45: 
Epoch time elapsed: 52.79722809791565

2023-01-06 08:45: 
 metrics validation: {'precision': 0.579957356076759, 'recall': 0.544, 'f1-score': 0.5614035087719299, 'support': 500, 'AUC': 0.77561, 'AUCPR': 0.6527924684689989, 'TP': 272, 'FP': 197, 'TN': 803, 'FN': 228} 

2023-01-06 08:45: **********Val Epoch 4: average Loss: 0.262438
2023-01-06 08:45: *********************************Current best model saved!
2023-01-06 08:45: 
 Testing metrics {'precision': 0.6807228915662651, 'recall': 0.678, 'f1-score': 0.6793587174348699, 'support': 500, 'AUC': 0.844806, 'AUCPR': 0.7446780509775929, 'TP': 339, 'FP': 159, 'TN': 841, 'FN': 161} 

2023-01-06 08:46: 
 Testing metrics {'precision': 0.8346456692913385, 'recall': 0.848, 'f1-score': 0.8412698412698412, 'support': 500, 'AUC': 0.923528, 'AUCPR': 0.8763530077275475, 'TP': 424, 'FP': 84, 'TN': 916, 'FN': 76} 

2023-01-06 08:46: Train Epoch 5: 3/24 Loss: 0.243317
2023-01-06 08:46: Train Epoch 5: 7/24 Loss: 0.290070
2023-01-06 08:46: Train Epoch 5: 11/24 Loss: 0.233469
2023-01-06 08:46: Train Epoch 5: 15/24 Loss: 0.211959
2023-01-06 08:46: Train Epoch 5: 19/24 Loss: 0.232857
2023-01-06 08:47: Train Epoch 5: 23/24 Loss: 0.201232
2023-01-06 08:47: **********Train Epoch 5: averaged Loss: 0.235484 
2023-01-06 08:47: 
Epoch time elapsed: 52.53769898414612

2023-01-06 08:47: 
 metrics validation: {'precision': 0.7071005917159763, 'recall': 0.478, 'f1-score': 0.5704057279236276, 'support': 500, 'AUC': 0.782852, 'AUCPR': 0.6734731460538559, 'TP': 239, 'FP': 99, 'TN': 901, 'FN': 261} 

2023-01-06 08:47: **********Val Epoch 5: average Loss: 0.264025
2023-01-06 08:47: 
 Testing metrics {'precision': 0.6807228915662651, 'recall': 0.678, 'f1-score': 0.6793587174348699, 'support': 500, 'AUC': 0.844806, 'AUCPR': 0.7446780509775929, 'TP': 339, 'FP': 159, 'TN': 841, 'FN': 161} 

2023-01-06 08:47: 
 Testing metrics {'precision': 0.8346456692913385, 'recall': 0.848, 'f1-score': 0.8412698412698412, 'support': 500, 'AUC': 0.923528, 'AUCPR': 0.8763530077275475, 'TP': 424, 'FP': 84, 'TN': 916, 'FN': 76} 

2023-01-06 08:48: Train Epoch 6: 3/24 Loss: 0.258268
2023-01-06 08:48: Train Epoch 6: 7/24 Loss: 0.246221
2023-01-06 08:48: Train Epoch 6: 11/24 Loss: 0.211175
2023-01-06 08:48: Train Epoch 6: 15/24 Loss: 0.220935
2023-01-06 08:48: Train Epoch 6: 19/24 Loss: 0.231599
2023-01-06 08:48: Train Epoch 6: 23/24 Loss: 0.202780
2023-01-06 08:48: **********Train Epoch 6: averaged Loss: 0.228496 
2023-01-06 08:48: 
Epoch time elapsed: 48.66618323326111

2023-01-06 08:49: 
 metrics validation: {'precision': 0.7592592592592593, 'recall': 0.41, 'f1-score': 0.5324675324675325, 'support': 500, 'AUC': 0.783396, 'AUCPR': 0.6757758931183598, 'TP': 205, 'FP': 65, 'TN': 935, 'FN': 295} 

2023-01-06 08:49: **********Val Epoch 6: average Loss: 0.266745
2023-01-06 08:49: 
 Testing metrics {'precision': 0.6807228915662651, 'recall': 0.678, 'f1-score': 0.6793587174348699, 'support': 500, 'AUC': 0.844806, 'AUCPR': 0.7446780509775929, 'TP': 339, 'FP': 159, 'TN': 841, 'FN': 161} 

2023-01-06 08:49: 
 Testing metrics {'precision': 0.8346456692913385, 'recall': 0.848, 'f1-score': 0.8412698412698412, 'support': 500, 'AUC': 0.923528, 'AUCPR': 0.8763530077275475, 'TP': 424, 'FP': 84, 'TN': 916, 'FN': 76} 

2023-01-06 08:49: Train Epoch 7: 3/24 Loss: 0.230010
2023-01-06 08:49: Train Epoch 7: 7/24 Loss: 0.227300
2023-01-06 08:50: Train Epoch 7: 11/24 Loss: 0.231819
2023-01-06 08:50: Train Epoch 7: 15/24 Loss: 0.230128
2023-01-06 08:50: Train Epoch 7: 19/24 Loss: 0.243189
2023-01-06 08:50: Train Epoch 7: 23/24 Loss: 0.187554
2023-01-06 08:50: **********Train Epoch 7: averaged Loss: 0.225000 
2023-01-06 08:50: 
Epoch time elapsed: 52.07398533821106

2023-01-06 08:50: 
 metrics validation: {'precision': 0.6880222841225627, 'recall': 0.494, 'f1-score': 0.5750873108265425, 'support': 500, 'AUC': 0.7811480000000001, 'AUCPR': 0.6665440659988167, 'TP': 247, 'FP': 112, 'TN': 888, 'FN': 253} 

2023-01-06 08:50: **********Val Epoch 7: average Loss: 0.262830
2023-01-06 08:51: 
 Testing metrics {'precision': 0.6807228915662651, 'recall': 0.678, 'f1-score': 0.6793587174348699, 'support': 500, 'AUC': 0.844806, 'AUCPR': 0.7446780509775929, 'TP': 339, 'FP': 159, 'TN': 841, 'FN': 161} 

2023-01-06 08:51: 
 Testing metrics {'precision': 0.8346456692913385, 'recall': 0.848, 'f1-score': 0.8412698412698412, 'support': 500, 'AUC': 0.923528, 'AUCPR': 0.8763530077275475, 'TP': 424, 'FP': 84, 'TN': 916, 'FN': 76} 

2023-01-06 08:51: Train Epoch 8: 3/24 Loss: 0.225667
2023-01-06 08:51: Train Epoch 8: 7/24 Loss: 0.238320
2023-01-06 08:51: Train Epoch 8: 11/24 Loss: 0.234665
2023-01-06 08:51: Train Epoch 8: 15/24 Loss: 0.206781
2023-01-06 08:52: Train Epoch 8: 19/24 Loss: 0.252971
2023-01-06 08:52: Train Epoch 8: 23/24 Loss: 0.187141
2023-01-06 08:52: **********Train Epoch 8: averaged Loss: 0.224258 
2023-01-06 08:52: 
Epoch time elapsed: 51.37143039703369

2023-01-06 08:52: 
 metrics validation: {'precision': 0.6527415143603134, 'recall': 0.5, 'f1-score': 0.5662514156285391, 'support': 500, 'AUC': 0.7812959999999999, 'AUCPR': 0.6675279580151247, 'TP': 250, 'FP': 133, 'TN': 867, 'FN': 250} 

2023-01-06 08:52: **********Val Epoch 8: average Loss: 0.262014
2023-01-06 08:52: *********************************Current best model saved!
2023-01-06 08:52: 
 Testing metrics {'precision': 0.7408312958435208, 'recall': 0.606, 'f1-score': 0.6666666666666667, 'support': 500, 'AUC': 0.848326, 'AUCPR': 0.7517263099159597, 'TP': 303, 'FP': 106, 'TN': 894, 'FN': 197} 

2023-01-06 08:53: 
 Testing metrics {'precision': 0.8813559322033898, 'recall': 0.832, 'f1-score': 0.8559670781893003, 'support': 500, 'AUC': 0.9293260000000001, 'AUCPR': 0.8854278478128016, 'TP': 416, 'FP': 56, 'TN': 944, 'FN': 84} 

2023-01-06 08:53: Train Epoch 9: 3/24 Loss: 0.218469
2023-01-06 08:53: Train Epoch 9: 7/24 Loss: 0.203944
2023-01-06 08:53: Train Epoch 9: 11/24 Loss: 0.228095
2023-01-06 08:53: Train Epoch 9: 15/24 Loss: 0.252632
2023-01-06 08:53: Train Epoch 9: 19/24 Loss: 0.242962
2023-01-06 08:53: Train Epoch 9: 23/24 Loss: 0.154061
2023-01-06 08:53: **********Train Epoch 9: averaged Loss: 0.216694 
2023-01-06 08:53: 
Epoch time elapsed: 51.411441802978516

2023-01-06 08:54: 
 metrics validation: {'precision': 0.598343685300207, 'recall': 0.578, 'f1-score': 0.5879959308240081, 'support': 500, 'AUC': 0.786076, 'AUCPR': 0.6802986926796095, 'TP': 289, 'FP': 194, 'TN': 806, 'FN': 211} 

2023-01-06 08:54: **********Val Epoch 9: average Loss: 0.258400
2023-01-06 08:54: *********************************Current best model saved!
2023-01-06 08:54: 
 Testing metrics {'precision': 0.7008032128514057, 'recall': 0.698, 'f1-score': 0.6993987975951904, 'support': 500, 'AUC': 0.850448, 'AUCPR': 0.7577127639116589, 'TP': 349, 'FP': 149, 'TN': 851, 'FN': 151} 

2023-01-06 08:54: 
 Testing metrics {'precision': 0.8379446640316206, 'recall': 0.848, 'f1-score': 0.8429423459244534, 'support': 500, 'AUC': 0.9334959999999998, 'AUCPR': 0.8912805901687119, 'TP': 424, 'FP': 82, 'TN': 918, 'FN': 76} 

2023-01-06 08:54: Train Epoch 10: 3/24 Loss: 0.211922
2023-01-06 08:55: Train Epoch 10: 7/24 Loss: 0.207774
2023-01-06 08:55: Train Epoch 10: 11/24 Loss: 0.229279
2023-01-06 08:55: Train Epoch 10: 15/24 Loss: 0.257822
2023-01-06 08:55: Train Epoch 10: 19/24 Loss: 0.208245
2023-01-06 08:55: Train Epoch 10: 23/24 Loss: 0.212827
2023-01-06 08:55: **********Train Epoch 10: averaged Loss: 0.221311 
2023-01-06 08:55: 
Epoch time elapsed: 49.791929960250854

2023-01-06 08:55: 
 metrics validation: {'precision': 0.6435406698564593, 'recall': 0.538, 'f1-score': 0.5860566448801743, 'support': 500, 'AUC': 0.7890980000000001, 'AUCPR': 0.6857367113116895, 'TP': 269, 'FP': 149, 'TN': 851, 'FN': 231} 

2023-01-06 08:55: **********Val Epoch 10: average Loss: 0.258735
2023-01-06 08:56: 
 Testing metrics {'precision': 0.7008032128514057, 'recall': 0.698, 'f1-score': 0.6993987975951904, 'support': 500, 'AUC': 0.850448, 'AUCPR': 0.7577127639116589, 'TP': 349, 'FP': 149, 'TN': 851, 'FN': 151} 

2023-01-06 08:56: 
 Testing metrics {'precision': 0.8379446640316206, 'recall': 0.848, 'f1-score': 0.8429423459244534, 'support': 500, 'AUC': 0.9334959999999998, 'AUCPR': 0.8912805901687119, 'TP': 424, 'FP': 82, 'TN': 918, 'FN': 76} 

2023-01-06 08:56: Train Epoch 11: 3/24 Loss: 0.213181
2023-01-06 08:56: Train Epoch 11: 7/24 Loss: 0.212674
2023-01-06 08:56: Train Epoch 11: 11/24 Loss: 0.231211
2023-01-06 08:57: Train Epoch 11: 15/24 Loss: 0.240841
2023-01-06 08:57: Train Epoch 11: 19/24 Loss: 0.223267
2023-01-06 08:57: Train Epoch 11: 23/24 Loss: 0.199019
2023-01-06 08:57: **********Train Epoch 11: averaged Loss: 0.220032 
2023-01-06 08:57: 
Epoch time elapsed: 47.97495436668396

2023-01-06 08:57: 
 metrics validation: {'precision': 0.7398648648648649, 'recall': 0.438, 'f1-score': 0.5502512562814071, 'support': 500, 'AUC': 0.788182, 'AUCPR': 0.6849034176062085, 'TP': 219, 'FP': 77, 'TN': 923, 'FN': 281} 

2023-01-06 08:57: **********Val Epoch 11: average Loss: 0.265117
2023-01-06 08:57: 
 Testing metrics {'precision': 0.7008032128514057, 'recall': 0.698, 'f1-score': 0.6993987975951904, 'support': 500, 'AUC': 0.850448, 'AUCPR': 0.7577127639116589, 'TP': 349, 'FP': 149, 'TN': 851, 'FN': 151} 

2023-01-06 08:58: 
 Testing metrics {'precision': 0.8379446640316206, 'recall': 0.848, 'f1-score': 0.8429423459244534, 'support': 500, 'AUC': 0.9334959999999998, 'AUCPR': 0.8912805901687119, 'TP': 424, 'FP': 82, 'TN': 918, 'FN': 76} 

2023-01-06 08:58: Train Epoch 12: 3/24 Loss: 0.217014
2023-01-06 08:58: Train Epoch 12: 7/24 Loss: 0.215781
2023-01-06 08:58: Train Epoch 12: 11/24 Loss: 0.224421
2023-01-06 08:58: Train Epoch 12: 15/24 Loss: 0.216315
2023-01-06 08:58: Train Epoch 12: 19/24 Loss: 0.219353
2023-01-06 08:58: Train Epoch 12: 23/24 Loss: 0.189505
2023-01-06 08:58: **********Train Epoch 12: averaged Loss: 0.213731 
2023-01-06 08:58: 
Epoch time elapsed: 43.564945936203

2023-01-06 08:59: 
 metrics validation: {'precision': 0.7553191489361702, 'recall': 0.426, 'f1-score': 0.5447570332480818, 'support': 500, 'AUC': 0.7909739999999998, 'AUCPR': 0.6915794150812329, 'TP': 213, 'FP': 69, 'TN': 931, 'FN': 287} 

2023-01-06 08:59: **********Val Epoch 12: average Loss: 0.265132
2023-01-06 08:59: 
 Testing metrics {'precision': 0.7008032128514057, 'recall': 0.698, 'f1-score': 0.6993987975951904, 'support': 500, 'AUC': 0.850448, 'AUCPR': 0.7577127639116589, 'TP': 349, 'FP': 149, 'TN': 851, 'FN': 151} 

2023-01-06 08:59: 
 Testing metrics {'precision': 0.8379446640316206, 'recall': 0.848, 'f1-score': 0.8429423459244534, 'support': 500, 'AUC': 0.9334959999999998, 'AUCPR': 0.8912805901687119, 'TP': 424, 'FP': 82, 'TN': 918, 'FN': 76} 

2023-01-06 08:59: Train Epoch 13: 3/24 Loss: 0.230161
2023-01-06 08:59: Train Epoch 13: 7/24 Loss: 0.244381
2023-01-06 09:00: Train Epoch 13: 11/24 Loss: 0.217302
2023-01-06 09:00: Train Epoch 13: 15/24 Loss: 0.211775
2023-01-06 09:00: Train Epoch 13: 19/24 Loss: 0.230240
2023-01-06 09:00: Train Epoch 13: 23/24 Loss: 0.186746
2023-01-06 09:00: **********Train Epoch 13: averaged Loss: 0.220101 
2023-01-06 09:00: 
Epoch time elapsed: 49.17716145515442

2023-01-06 09:00: 
 metrics validation: {'precision': 0.6649874055415617, 'recall': 0.528, 'f1-score': 0.5886287625418061, 'support': 500, 'AUC': 0.7931560000000001, 'AUCPR': 0.6994347518457672, 'TP': 264, 'FP': 133, 'TN': 867, 'FN': 236} 

2023-01-06 09:00: **********Val Epoch 13: average Loss: 0.256366
2023-01-06 09:00: *********************************Current best model saved!
2023-01-06 09:01: 
 Testing metrics {'precision': 0.7452830188679245, 'recall': 0.632, 'f1-score': 0.683982683982684, 'support': 500, 'AUC': 0.852866, 'AUCPR': 0.76665048999111, 'TP': 316, 'FP': 108, 'TN': 892, 'FN': 184} 

2023-01-06 09:01: 
 Testing metrics {'precision': 0.8752598752598753, 'recall': 0.842, 'f1-score': 0.8583078491335373, 'support': 500, 'AUC': 0.939386, 'AUCPR': 0.9016444744966423, 'TP': 421, 'FP': 60, 'TN': 940, 'FN': 79} 

2023-01-06 09:01: Train Epoch 14: 3/24 Loss: 0.199915
2023-01-06 09:01: Train Epoch 14: 7/24 Loss: 0.210047
2023-01-06 09:01: Train Epoch 14: 11/24 Loss: 0.216045
2023-01-06 09:01: Train Epoch 14: 15/24 Loss: 0.246626
2023-01-06 09:02: Train Epoch 14: 19/24 Loss: 0.201520
2023-01-06 09:02: Train Epoch 14: 23/24 Loss: 0.168093
2023-01-06 09:02: **********Train Epoch 14: averaged Loss: 0.207041 
2023-01-06 09:02: 
Epoch time elapsed: 50.51636004447937

2023-01-06 09:02: 
 metrics validation: {'precision': 0.6634844868735084, 'recall': 0.556, 'f1-score': 0.6050054406964092, 'support': 500, 'AUC': 0.7990700000000001, 'AUCPR': 0.7088128988906595, 'TP': 278, 'FP': 141, 'TN': 859, 'FN': 222} 

2023-01-06 09:02: **********Val Epoch 14: average Loss: 0.252760
2023-01-06 09:02: *********************************Current best model saved!
2023-01-06 09:02: 
 Testing metrics {'precision': 0.7404921700223713, 'recall': 0.662, 'f1-score': 0.6990496304118268, 'support': 500, 'AUC': 0.853874, 'AUCPR': 0.7683839002759332, 'TP': 331, 'FP': 116, 'TN': 884, 'FN': 169} 

2023-01-06 09:03: 
 Testing metrics {'precision': 0.871900826446281, 'recall': 0.844, 'f1-score': 0.8577235772357723, 'support': 500, 'AUC': 0.94282, 'AUCPR': 0.9057352382501593, 'TP': 422, 'FP': 62, 'TN': 938, 'FN': 78} 

2023-01-06 09:03: Train Epoch 15: 3/24 Loss: 0.201505
2023-01-06 09:03: Train Epoch 15: 7/24 Loss: 0.215753
2023-01-06 09:03: Train Epoch 15: 11/24 Loss: 0.202032
2023-01-06 09:03: Train Epoch 15: 15/24 Loss: 0.215331
2023-01-06 09:03: Train Epoch 15: 19/24 Loss: 0.222260
2023-01-06 09:03: Train Epoch 15: 23/24 Loss: 0.184725
2023-01-06 09:03: **********Train Epoch 15: averaged Loss: 0.206934 
2023-01-06 09:03: 
Epoch time elapsed: 49.399943590164185

2023-01-06 09:04: 
 metrics validation: {'precision': 0.7261538461538461, 'recall': 0.472, 'f1-score': 0.5721212121212121, 'support': 500, 'AUC': 0.8009700000000001, 'AUCPR': 0.7098564335692503, 'TP': 236, 'FP': 89, 'TN': 911, 'FN': 264} 

2023-01-06 09:04: **********Val Epoch 15: average Loss: 0.257256
2023-01-06 09:04: 
 Testing metrics {'precision': 0.7404921700223713, 'recall': 0.662, 'f1-score': 0.6990496304118268, 'support': 500, 'AUC': 0.853874, 'AUCPR': 0.7683839002759332, 'TP': 331, 'FP': 116, 'TN': 884, 'FN': 169} 

2023-01-06 09:04: 
 Testing metrics {'precision': 0.871900826446281, 'recall': 0.844, 'f1-score': 0.8577235772357723, 'support': 500, 'AUC': 0.94282, 'AUCPR': 0.9057352382501593, 'TP': 422, 'FP': 62, 'TN': 938, 'FN': 78} 

2023-01-06 09:04: Train Epoch 16: 3/24 Loss: 0.224931
2023-01-06 09:04: Train Epoch 16: 7/24 Loss: 0.215393
2023-01-06 09:05: Train Epoch 16: 11/24 Loss: 0.204656
2023-01-06 09:05: Train Epoch 16: 15/24 Loss: 0.185637
2023-01-06 09:05: Train Epoch 16: 19/24 Loss: 0.206559
2023-01-06 09:05: Train Epoch 16: 23/24 Loss: 0.201109
2023-01-06 09:05: **********Train Epoch 16: averaged Loss: 0.206381 
2023-01-06 09:05: 
Epoch time elapsed: 51.16353154182434

2023-01-06 09:05: 
 metrics validation: {'precision': 0.7067448680351907, 'recall': 0.482, 'f1-score': 0.573127229488704, 'support': 500, 'AUC': 0.796448, 'AUCPR': 0.7027410545598172, 'TP': 241, 'FP': 100, 'TN': 900, 'FN': 259} 

2023-01-06 09:05: **********Val Epoch 16: average Loss: 0.258171
2023-01-06 09:06: 
 Testing metrics {'precision': 0.7404921700223713, 'recall': 0.662, 'f1-score': 0.6990496304118268, 'support': 500, 'AUC': 0.853874, 'AUCPR': 0.7683839002759332, 'TP': 331, 'FP': 116, 'TN': 884, 'FN': 169} 

2023-01-06 09:06: 
 Testing metrics {'precision': 0.871900826446281, 'recall': 0.844, 'f1-score': 0.8577235772357723, 'support': 500, 'AUC': 0.94282, 'AUCPR': 0.9057352382501593, 'TP': 422, 'FP': 62, 'TN': 938, 'FN': 78} 

2023-01-06 09:06: Train Epoch 17: 3/24 Loss: 0.225106
2023-01-06 09:06: Train Epoch 17: 7/24 Loss: 0.212790
2023-01-06 09:06: Train Epoch 17: 11/24 Loss: 0.216655
2023-01-06 09:06: Train Epoch 17: 15/24 Loss: 0.216171
2023-01-06 09:07: Train Epoch 17: 19/24 Loss: 0.212042
2023-01-06 09:07: Train Epoch 17: 23/24 Loss: 0.185055
2023-01-06 09:07: **********Train Epoch 17: averaged Loss: 0.211303 
2023-01-06 09:07: 
Epoch time elapsed: 46.907347679138184

2023-01-06 09:07: 
 metrics validation: {'precision': 0.6931818181818182, 'recall': 0.488, 'f1-score': 0.5727699530516431, 'support': 500, 'AUC': 0.791114, 'AUCPR': 0.6918319729991198, 'TP': 244, 'FP': 108, 'TN': 892, 'FN': 256} 

2023-01-06 09:07: **********Val Epoch 17: average Loss: 0.259897
2023-01-06 09:07: 
 Testing metrics {'precision': 0.7404921700223713, 'recall': 0.662, 'f1-score': 0.6990496304118268, 'support': 500, 'AUC': 0.853874, 'AUCPR': 0.7683839002759332, 'TP': 331, 'FP': 116, 'TN': 884, 'FN': 169} 

2023-01-06 09:08: 
 Testing metrics {'precision': 0.871900826446281, 'recall': 0.844, 'f1-score': 0.8577235772357723, 'support': 500, 'AUC': 0.94282, 'AUCPR': 0.9057352382501593, 'TP': 422, 'FP': 62, 'TN': 938, 'FN': 78} 

2023-01-06 09:08: Train Epoch 18: 3/24 Loss: 0.218695
2023-01-06 09:08: Train Epoch 18: 7/24 Loss: 0.212668
2023-01-06 09:08: Train Epoch 18: 11/24 Loss: 0.185470
2023-01-06 09:08: Train Epoch 18: 15/24 Loss: 0.210088
2023-01-06 09:08: Train Epoch 18: 19/24 Loss: 0.212449
2023-01-06 09:08: Train Epoch 18: 23/24 Loss: 0.197823
2023-01-06 09:08: **********Train Epoch 18: averaged Loss: 0.206199 
2023-01-06 09:08: 
Epoch time elapsed: 49.58601093292236

2023-01-06 09:09: 
 metrics validation: {'precision': 0.6972222222222222, 'recall': 0.502, 'f1-score': 0.5837209302325581, 'support': 500, 'AUC': 0.7957860000000001, 'AUCPR': 0.701755351480531, 'TP': 251, 'FP': 109, 'TN': 891, 'FN': 249} 

2023-01-06 09:09: **********Val Epoch 18: average Loss: 0.257280
2023-01-06 09:09: 
 Testing metrics {'precision': 0.7404921700223713, 'recall': 0.662, 'f1-score': 0.6990496304118268, 'support': 500, 'AUC': 0.853874, 'AUCPR': 0.7683839002759332, 'TP': 331, 'FP': 116, 'TN': 884, 'FN': 169} 

2023-01-06 09:09: 
 Testing metrics {'precision': 0.871900826446281, 'recall': 0.844, 'f1-score': 0.8577235772357723, 'support': 500, 'AUC': 0.94282, 'AUCPR': 0.9057352382501593, 'TP': 422, 'FP': 62, 'TN': 938, 'FN': 78} 

2023-01-06 09:09: Train Epoch 19: 3/24 Loss: 0.189658
2023-01-06 09:09: Train Epoch 19: 7/24 Loss: 0.229619
2023-01-06 09:10: Train Epoch 19: 11/24 Loss: 0.216342
2023-01-06 09:10: Train Epoch 19: 15/24 Loss: 0.231635
2023-01-06 09:10: Train Epoch 19: 19/24 Loss: 0.210087
2023-01-06 09:10: Train Epoch 19: 23/24 Loss: 0.185782
2023-01-06 09:10: **********Train Epoch 19: averaged Loss: 0.210520 
2023-01-06 09:10: 
Epoch time elapsed: 47.22261619567871

2023-01-06 09:10: 
 metrics validation: {'precision': 0.7466216216216216, 'recall': 0.442, 'f1-score': 0.5552763819095476, 'support': 500, 'AUC': 0.794096, 'AUCPR': 0.6984245662349202, 'TP': 221, 'FP': 75, 'TN': 925, 'FN': 279} 

2023-01-06 09:10: **********Val Epoch 19: average Loss: 0.263207
2023-01-06 09:11: 
 Testing metrics {'precision': 0.7404921700223713, 'recall': 0.662, 'f1-score': 0.6990496304118268, 'support': 500, 'AUC': 0.853874, 'AUCPR': 0.7683839002759332, 'TP': 331, 'FP': 116, 'TN': 884, 'FN': 169} 

2023-01-06 09:11: 
 Testing metrics {'precision': 0.871900826446281, 'recall': 0.844, 'f1-score': 0.8577235772357723, 'support': 500, 'AUC': 0.94282, 'AUCPR': 0.9057352382501593, 'TP': 422, 'FP': 62, 'TN': 938, 'FN': 78} 

2023-01-06 09:11: Train Epoch 20: 3/24 Loss: 0.228304
2023-01-06 09:11: Train Epoch 20: 7/24 Loss: 0.210362
2023-01-06 09:11: Train Epoch 20: 11/24 Loss: 0.207804
2023-01-06 09:11: Train Epoch 20: 15/24 Loss: 0.221334
2023-01-06 09:12: Train Epoch 20: 19/24 Loss: 0.215569
2023-01-06 09:12: Train Epoch 20: 23/24 Loss: 0.195543
2023-01-06 09:12: **********Train Epoch 20: averaged Loss: 0.213153 
2023-01-06 09:12: 
Epoch time elapsed: 51.274895429611206

2023-01-06 09:12: 
 metrics validation: {'precision': 0.6575342465753424, 'recall': 0.576, 'f1-score': 0.6140724946695095, 'support': 500, 'AUC': 0.792034, 'AUCPR': 0.6958974212424642, 'TP': 288, 'FP': 150, 'TN': 850, 'FN': 212} 

2023-01-06 09:12: **********Val Epoch 20: average Loss: 0.255322
2023-01-06 09:12: 
 Testing metrics {'precision': 0.7404921700223713, 'recall': 0.662, 'f1-score': 0.6990496304118268, 'support': 500, 'AUC': 0.853874, 'AUCPR': 0.7683839002759332, 'TP': 331, 'FP': 116, 'TN': 884, 'FN': 169} 

2023-01-06 09:13: 
 Testing metrics {'precision': 0.871900826446281, 'recall': 0.844, 'f1-score': 0.8577235772357723, 'support': 500, 'AUC': 0.94282, 'AUCPR': 0.9057352382501593, 'TP': 422, 'FP': 62, 'TN': 938, 'FN': 78} 

2023-01-06 09:13: Train Epoch 21: 3/24 Loss: 0.218963
2023-01-06 09:13: Train Epoch 21: 7/24 Loss: 0.220835
2023-01-06 09:13: Train Epoch 21: 11/24 Loss: 0.215636
2023-01-06 09:13: Train Epoch 21: 15/24 Loss: 0.209038
2023-01-06 09:13: Train Epoch 21: 19/24 Loss: 0.210031
2023-01-06 09:13: Train Epoch 21: 23/24 Loss: 0.178930
2023-01-06 09:13: **********Train Epoch 21: averaged Loss: 0.208905 
2023-01-06 09:13: 
Epoch time elapsed: 52.260316133499146

2023-01-06 09:14: 
 metrics validation: {'precision': 0.6879795396419437, 'recall': 0.538, 'f1-score': 0.6038159371492705, 'support': 500, 'AUC': 0.79898, 'AUCPR': 0.7083779719850253, 'TP': 269, 'FP': 122, 'TN': 878, 'FN': 231} 

2023-01-06 09:14: **********Val Epoch 21: average Loss: 0.253632
2023-01-06 09:14: 
 Testing metrics {'precision': 0.7404921700223713, 'recall': 0.662, 'f1-score': 0.6990496304118268, 'support': 500, 'AUC': 0.853874, 'AUCPR': 0.7683839002759332, 'TP': 331, 'FP': 116, 'TN': 884, 'FN': 169} 

2023-01-06 09:14: 
 Testing metrics {'precision': 0.871900826446281, 'recall': 0.844, 'f1-score': 0.8577235772357723, 'support': 500, 'AUC': 0.94282, 'AUCPR': 0.9057352382501593, 'TP': 422, 'FP': 62, 'TN': 938, 'FN': 78} 

2023-01-06 09:15: Train Epoch 22: 3/24 Loss: 0.237095
2023-01-06 09:15: Train Epoch 22: 7/24 Loss: 0.211247
2023-01-06 09:15: Train Epoch 22: 11/24 Loss: 0.214795
2023-01-06 09:15: Train Epoch 22: 15/24 Loss: 0.218618
2023-01-06 09:15: Train Epoch 22: 19/24 Loss: 0.193494
2023-01-06 09:15: Train Epoch 22: 23/24 Loss: 0.180720
2023-01-06 09:15: **********Train Epoch 22: averaged Loss: 0.209328 
2023-01-06 09:15: 
Epoch time elapsed: 48.71836876869202

2023-01-06 09:15: 
 metrics validation: {'precision': 0.7126099706744868, 'recall': 0.486, 'f1-score': 0.5778834720570749, 'support': 500, 'AUC': 0.798688, 'AUCPR': 0.707805703236649, 'TP': 243, 'FP': 98, 'TN': 902, 'FN': 257} 

2023-01-06 09:15: **********Val Epoch 22: average Loss: 0.255755
2023-01-06 09:15: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-06 09:15: Total training time: 37.0043min, best loss: 0.252760
2023-01-06 09:15: Saving current best model to /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010608385709590369386/best_model.pth
2023-01-06 09:16: 
 Testing metrics {'precision': 0.7404921700223713, 'recall': 0.662, 'f1-score': 0.6990496304118268, 'support': 500, 'AUC': 0.853874, 'AUCPR': 0.7683839002759332, 'TP': 331, 'FP': 116, 'TN': 884, 'FN': 169} 

2023-01-06 09:16: 
 Testing metrics {'precision': 0.871900826446281, 'recall': 0.844, 'f1-score': 0.8577235772357723, 'support': 500, 'AUC': 0.94282, 'AUCPR': 0.9057352382501593, 'TP': 422, 'FP': 62, 'TN': 938, 'FN': 78} 

