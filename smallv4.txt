#ONE KIND OF NORMALIZATION WEAKLY ONNECTIONS
2023-01-06 11:44: log dir: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611442540411669386
2023-01-06 11:44: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611442540411669386
2023-01-06 11:44: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611442540411669386', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=48, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-06 11:44: Argument batch_size: 256
2023-01-06 11:44: Argument clc: 'vec'
2023-01-06 11:44: Argument cuda: True
2023-01-06 11:44: Argument dataset: '2020'
2023-01-06 11:44: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-06 11:44: Argument debug: False
2023-01-06 11:44: Argument default_graph: True
2023-01-06 11:44: Argument device: 'cpu'
2023-01-06 11:44: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-06 11:44: Argument early_stop: True
2023-01-06 11:44: Argument early_stop_patience: 8
2023-01-06 11:44: Argument embed_dim: 64
2023-01-06 11:44: Argument epochs: 30
2023-01-06 11:44: Argument grad_norm: False
2023-01-06 11:44: Argument horizon: 1
2023-01-06 11:44: Argument input_dim: 25
2023-01-06 11:44: Argument lag: 10
2023-01-06 11:44: Argument link_len: 2
2023-01-06 11:44: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611442540411669386'
2023-01-06 11:44: Argument log_step: 1
2023-01-06 11:44: Argument loss_func: 'nllloss'
2023-01-06 11:44: Argument lr_decay: True
2023-01-06 11:44: Argument lr_decay_rate: 0.1
2023-01-06 11:44: Argument lr_decay_step: '20'
2023-01-06 11:44: Argument lr_init: 0.0001
2023-01-06 11:44: Argument max_grad_norm: 5
2023-01-06 11:44: Argument minbatch_size: 64
2023-01-06 11:44: Argument mode: 'train'
2023-01-06 11:44: Argument model: 'fire_GCN'
2023-01-06 11:44: Argument nan_fill: -1.0
2023-01-06 11:44: Argument num_layers: 1
2023-01-06 11:44: Argument num_nodes: 625
2023-01-06 11:44: Argument num_workers: 12
2023-01-06 11:44: Argument output_dim: 2
2023-01-06 11:44: Argument patch_height: 25
2023-01-06 11:44: Argument patch_width: 25
2023-01-06 11:44: Argument persistent_workers: True
2023-01-06 11:44: Argument pin_memory: True
2023-01-06 11:44: Argument plot: False
2023-01-06 11:44: Argument positive_weight: 0.5
2023-01-06 11:44: Argument prefetch_factor: 2
2023-01-06 11:44: Argument real_value: True
2023-01-06 11:44: Argument rnn_units: 48
2023-01-06 11:44: Argument seed: 10000
2023-01-06 11:44: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-06 11:44: Argument teacher_forcing: False
2023-01-06 11:44: Argument weight_decay: 0.0
2023-01-06 11:44: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.]])
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([64, 2, 73, 32]) True
encoder.cell_list.0.gate.weights_pool_adj torch.Size([64, 2, 73, 32]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 32]) True
encoder.cell_list.0.gate.bias_pool torch.Size([64, 96]) True
encoder.cell_list.0.gate.bias_pool_adj torch.Size([64, 96]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([64, 2, 73, 16]) True
encoder.cell_list.0.update.weights_pool_adj torch.Size([64, 2, 73, 16]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 16]) True
encoder.cell_list.0.update.bias_pool torch.Size([64, 48]) True
encoder.cell_list.0.update.bias_pool_adj torch.Size([64, 48]) True
encoder.cell_list.0.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 30000]) True
fc1.bias torch.Size([2]) True
Total params num: 1018600
*****************Finish Parameter****************
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611442540411669386/run.log
2023-01-06 11:44: Train Epoch 1: 3/24 Loss: 0.431163
2023-01-06 11:44: Train Epoch 1: 7/24 Loss: 0.326002
2023-01-06 11:45: Train Epoch 1: 11/24 Loss: 0.369282
2023-01-06 11:45: Train Epoch 1: 15/24 Loss: 0.326844
2023-01-06 11:45: Train Epoch 1: 19/24 Loss: 0.247760
2023-01-06 11:45: Train Epoch 1: 23/24 Loss: 0.208642
2023-01-06 11:45: **********Train Epoch 1: averaged Loss: 0.318282 
2023-01-06 11:45: 
Epoch time elapsed: 74.87990593910217

2023-01-06 11:46: 
 metrics validation: {'precision': 0.6008583690987125, 'recall': 0.56, 'f1-score': 0.5797101449275363, 'support': 500, 'AUC': 0.7825739999999999, 'AUCPR': 0.6485532381231728, 'TP': 280, 'FP': 186, 'TN': 814, 'FN': 220} 

2023-01-06 11:46: **********Val Epoch 1: average Loss: 0.255092
2023-01-06 11:46: *********************************Current best model saved!
2023-01-06 11:46: 
 Testing metrics {'precision': 0.7234848484848485, 'recall': 0.764, 'f1-score': 0.7431906614785992, 'support': 500, 'AUC': 0.8583379999999999, 'AUCPR': 0.7769890221916318, 'TP': 382, 'FP': 146, 'TN': 854, 'FN': 118} 

2023-01-06 11:47: 
 Testing metrics {'precision': 0.822992700729927, 'recall': 0.902, 'f1-score': 0.8606870229007634, 'support': 500, 'AUC': 0.95138, 'AUCPR': 0.9260100775440095, 'TP': 451, 'FP': 97, 'TN': 903, 'FN': 49} 

2023-01-06 11:47: Train Epoch 2: 3/24 Loss: 0.278936
2023-01-06 11:47: Train Epoch 2: 7/24 Loss: 0.290326
2023-01-06 11:47: Train Epoch 2: 11/24 Loss: 0.233726
2023-01-06 11:47: Train Epoch 2: 15/24 Loss: 0.227133
2023-01-06 11:48: Train Epoch 2: 19/24 Loss: 0.222760
2023-01-06 11:48: Train Epoch 2: 23/24 Loss: 0.165080
2023-01-06 11:48: **********Train Epoch 2: averaged Loss: 0.236327 
2023-01-06 11:48: 
Epoch time elapsed: 72.02812075614929

2023-01-06 11:48: 
 metrics validation: {'precision': 0.6683937823834197, 'recall': 0.516, 'f1-score': 0.582392776523702, 'support': 500, 'AUC': 0.7899140000000001, 'AUCPR': 0.661287990229701, 'TP': 258, 'FP': 128, 'TN': 872, 'FN': 242} 

2023-01-06 11:48: **********Val Epoch 2: average Loss: 0.268961
2023-01-06 11:48: Train Epoch 3: 3/24 Loss: 0.248386
2023-01-06 11:49: Train Epoch 3: 7/24 Loss: 0.265121
2023-01-06 11:49: Train Epoch 3: 11/24 Loss: 0.226167
2023-01-06 11:49: Train Epoch 3: 15/24 Loss: 0.239654
2023-01-06 11:49: Train Epoch 3: 19/24 Loss: 0.252437
2023-01-06 11:49: Train Epoch 3: 23/24 Loss: 0.205063
2023-01-06 11:49: **********Train Epoch 3: averaged Loss: 0.239471 
2023-01-06 11:49: 
Epoch time elapsed: 70.78913235664368

2023-01-06 11:50: 
 metrics validation: {'precision': 0.6382536382536382, 'recall': 0.614, 'f1-score': 0.6258919469928643, 'support': 500, 'AUC': 0.79913, 'AUCPR': 0.672226757074359, 'TP': 307, 'FP': 174, 'TN': 826, 'FN': 193} 

2023-01-06 11:50: **********Val Epoch 3: average Loss: 0.251968
2023-01-06 11:50: *********************************Current best model saved!
2023-01-06 11:50: 
 Testing metrics {'precision': 0.751984126984127, 'recall': 0.758, 'f1-score': 0.7549800796812749, 'support': 500, 'AUC': 0.8649700000000001, 'AUCPR': 0.7869006127195494, 'TP': 379, 'FP': 125, 'TN': 875, 'FN': 121} 

2023-01-06 11:51: 
 Testing metrics {'precision': 0.8370786516853933, 'recall': 0.894, 'f1-score': 0.8646034816247583, 'support': 500, 'AUC': 0.9595899999999998, 'AUCPR': 0.9383138719393342, 'TP': 447, 'FP': 87, 'TN': 913, 'FN': 53} 

2023-01-06 11:51: Train Epoch 4: 3/24 Loss: 0.236992
2023-01-06 11:51: Train Epoch 4: 7/24 Loss: 0.213182
2023-01-06 11:52: Train Epoch 4: 11/24 Loss: 0.209849
2023-01-06 11:52: Train Epoch 4: 15/24 Loss: 0.231833
2023-01-06 11:52: Train Epoch 4: 19/24 Loss: 0.204076
2023-01-06 11:52: Train Epoch 4: 23/24 Loss: 0.184574
2023-01-06 11:52: **********Train Epoch 4: averaged Loss: 0.213418 
2023-01-06 11:52: 
Epoch time elapsed: 72.11745929718018

2023-01-06 11:53: 
 metrics validation: {'precision': 0.7150837988826816, 'recall': 0.512, 'f1-score': 0.5967365967365967, 'support': 500, 'AUC': 0.80835, 'AUCPR': 0.6889632227252301, 'TP': 256, 'FP': 102, 'TN': 898, 'FN': 244} 

2023-01-06 11:53: **********Val Epoch 4: average Loss: 0.257611
2023-01-06 11:53: Train Epoch 5: 3/24 Loss: 0.222524
2023-01-06 11:53: Train Epoch 5: 7/24 Loss: 0.218262
2023-01-06 11:53: Train Epoch 5: 11/24 Loss: 0.234074
2023-01-06 11:53: Train Epoch 5: 15/24 Loss: 0.207688
2023-01-06 11:54: Train Epoch 5: 19/24 Loss: 0.207892
2023-01-06 11:54: Train Epoch 5: 23/24 Loss: 0.210074
2023-01-06 11:54: **********Train Epoch 5: averaged Loss: 0.216752 
2023-01-06 11:54: 
Epoch time elapsed: 73.75979828834534

2023-01-06 11:54: 
 metrics validation: {'precision': 0.692144373673036, 'recall': 0.652, 'f1-score': 0.6714727085478888, 'support': 500, 'AUC': 0.807018, 'AUCPR': 0.6879754659305144, 'TP': 326, 'FP': 145, 'TN': 855, 'FN': 174} 

2023-01-06 11:54: **********Val Epoch 5: average Loss: 0.250608
2023-01-06 11:54: *********************************Current best model saved!
2023-01-06 11:55: 
 Testing metrics {'precision': 0.7832618025751072, 'recall': 0.73, 'f1-score': 0.7556935817805382, 'support': 500, 'AUC': 0.8687580000000001, 'AUCPR': 0.7915519075113049, 'TP': 365, 'FP': 101, 'TN': 899, 'FN': 135} 

2023-01-06 11:55: 
 Testing metrics {'precision': 0.8528301886792453, 'recall': 0.904, 'f1-score': 0.8776699029126214, 'support': 500, 'AUC': 0.963268, 'AUCPR': 0.9414055619835996, 'TP': 452, 'FP': 78, 'TN': 922, 'FN': 48} 

2023-01-06 11:55: Train Epoch 6: 3/24 Loss: 0.186117
2023-01-06 11:55: Train Epoch 6: 7/24 Loss: 0.212569
2023-01-06 11:56: Train Epoch 6: 11/24 Loss: 0.211995
2023-01-06 11:56: Train Epoch 6: 15/24 Loss: 0.210203
2023-01-06 11:56: Train Epoch 6: 19/24 Loss: 0.205805
2023-01-06 11:56: Train Epoch 6: 23/24 Loss: 0.178386
2023-01-06 11:56: **********Train Epoch 6: averaged Loss: 0.200846 
2023-01-06 11:56: 
Epoch time elapsed: 70.55837869644165

2023-01-06 11:57: 
 metrics validation: {'precision': 0.7406340057636888, 'recall': 0.514, 'f1-score': 0.6068476977567886, 'support': 500, 'AUC': 0.809856, 'AUCPR': 0.7015294086491807, 'TP': 257, 'FP': 90, 'TN': 910, 'FN': 243} 

2023-01-06 11:57: **********Val Epoch 6: average Loss: 0.259090
2023-01-06 11:57: Train Epoch 7: 3/24 Loss: 0.217144
2023-01-06 11:57: Train Epoch 7: 7/24 Loss: 0.201822
2023-01-06 11:57: Train Epoch 7: 11/24 Loss: 0.189113
2023-01-06 11:57: Train Epoch 7: 15/24 Loss: 0.201861
2023-01-06 11:58: Train Epoch 7: 19/24 Loss: 0.215530
2023-01-06 11:58: Train Epoch 7: 23/24 Loss: 0.189389
2023-01-06 11:58: **********Train Epoch 7: averaged Loss: 0.202476 
2023-01-06 11:58: 
Epoch time elapsed: 69.6874213218689

2023-01-06 11:58: 
 metrics validation: {'precision': 0.701010101010101, 'recall': 0.694, 'f1-score': 0.6974874371859296, 'support': 500, 'AUC': 0.8084079999999999, 'AUCPR': 0.6991427469686233, 'TP': 347, 'FP': 148, 'TN': 852, 'FN': 153} 

2023-01-06 11:58: **********Val Epoch 7: average Loss: 0.252203
2023-01-06 11:58: Train Epoch 8: 3/24 Loss: 0.208584
2023-01-06 11:59: Train Epoch 8: 7/24 Loss: 0.216002
2023-01-06 11:59: Train Epoch 8: 11/24 Loss: 0.199410
2023-01-06 11:59: Train Epoch 8: 15/24 Loss: 0.216451
2023-01-06 11:59: Train Epoch 8: 19/24 Loss: 0.218965
2023-01-06 11:59: Train Epoch 8: 23/24 Loss: 0.174872
2023-01-06 11:59: **********Train Epoch 8: averaged Loss: 0.205714 
2023-01-06 11:59: 
Epoch time elapsed: 75.64814400672913

2023-01-06 12:00: 
 metrics validation: {'precision': 0.6902286902286903, 'recall': 0.664, 'f1-score': 0.6768603465851173, 'support': 500, 'AUC': 0.803878, 'AUCPR': 0.6965808397220173, 'TP': 332, 'FP': 149, 'TN': 851, 'FN': 168} 

2023-01-06 12:00: **********Val Epoch 8: average Loss: 0.254255
2023-01-06 12:00: Train Epoch 9: 3/24 Loss: 0.202157
2023-01-06 12:00: Train Epoch 9: 7/24 Loss: 0.209387
2023-01-06 12:01: Train Epoch 9: 11/24 Loss: 0.225257
2023-01-06 12:01: Train Epoch 9: 15/24 Loss: 0.259384
2023-01-06 12:01: Train Epoch 9: 19/24 Loss: 0.184550
2023-01-06 12:01: Train Epoch 9: 23/24 Loss: 0.183788
2023-01-06 12:01: **********Train Epoch 9: averaged Loss: 0.210754 
2023-01-06 12:01: 
Epoch time elapsed: 69.19882130622864

2023-01-06 12:02: 
 metrics validation: {'precision': 0.6528776978417267, 'recall': 0.726, 'f1-score': 0.6875, 'support': 500, 'AUC': 0.8054459999999999, 'AUCPR': 0.6987492787394672, 'TP': 363, 'FP': 193, 'TN': 807, 'FN': 137} 

2023-01-06 12:02: **********Val Epoch 9: average Loss: 0.253026
2023-01-06 12:02: Train Epoch 10: 3/24 Loss: 0.223255
2023-01-06 12:02: Train Epoch 10: 7/24 Loss: 0.223877
2023-01-06 12:02: Train Epoch 10: 11/24 Loss: 0.220771
2023-01-06 12:02: Train Epoch 10: 15/24 Loss: 0.201195
2023-01-06 12:03: Train Epoch 10: 19/24 Loss: 0.192769
2023-01-06 12:03: Train Epoch 10: 23/24 Loss: 0.187829
2023-01-06 12:03: **********Train Epoch 10: averaged Loss: 0.208283 
2023-01-06 12:03: 
Epoch time elapsed: 73.04996037483215

2023-01-06 12:03: 
 metrics validation: {'precision': 0.7564935064935064, 'recall': 0.466, 'f1-score': 0.5767326732673267, 'support': 500, 'AUC': 0.805874, 'AUCPR': 0.6990946236816019, 'TP': 233, 'FP': 75, 'TN': 925, 'FN': 267} 

2023-01-06 12:03: **********Val Epoch 10: average Loss: 0.261733
2023-01-06 12:03: Train Epoch 11: 3/24 Loss: 0.210995
2023-01-06 12:04: Train Epoch 11: 7/24 Loss: 0.226686
2023-01-06 12:04: Train Epoch 11: 11/24 Loss: 0.205602
2023-01-06 12:04: Train Epoch 11: 15/24 Loss: 0.200860
2023-01-06 12:04: Train Epoch 11: 19/24 Loss: 0.205554
2023-01-06 12:04: Train Epoch 11: 23/24 Loss: 0.198239
2023-01-06 12:04: **********Train Epoch 11: averaged Loss: 0.207989 
2023-01-06 12:04: 
Epoch time elapsed: 73.35381627082825

2023-01-06 12:05: 
 metrics validation: {'precision': 0.6573033707865169, 'recall': 0.702, 'f1-score': 0.6789168278529981, 'support': 500, 'AUC': 0.801576, 'AUCPR': 0.6943633412664046, 'TP': 351, 'FP': 183, 'TN': 817, 'FN': 149} 

2023-01-06 12:05: **********Val Epoch 11: average Loss: 0.255592
2023-01-06 12:05: Train Epoch 12: 3/24 Loss: 0.216089
2023-01-06 12:05: Train Epoch 12: 7/24 Loss: 0.206656
2023-01-06 12:05: Train Epoch 12: 11/24 Loss: 0.207972
2023-01-06 12:06: Train Epoch 12: 15/24 Loss: 0.212821
2023-01-06 12:06: Train Epoch 12: 19/24 Loss: 0.222011
2023-01-06 12:06: Train Epoch 12: 23/24 Loss: 0.166569
2023-01-06 12:06: **********Train Epoch 12: averaged Loss: 0.205353 
2023-01-06 12:06: 
Epoch time elapsed: 74.68635678291321

2023-01-06 12:07: 
 metrics validation: {'precision': 0.7209302325581395, 'recall': 0.558, 'f1-score': 0.6290868094701241, 'support': 500, 'AUC': 0.800846, 'AUCPR': 0.6953000341519501, 'TP': 279, 'FP': 108, 'TN': 892, 'FN': 221} 

2023-01-06 12:07: **********Val Epoch 12: average Loss: 0.256730
2023-01-06 12:07: Train Epoch 13: 3/24 Loss: 0.215019
2023-01-06 12:07: Train Epoch 13: 7/24 Loss: 0.208712
2023-01-06 12:07: Train Epoch 13: 11/24 Loss: 0.219493
2023-01-06 12:07: Train Epoch 13: 15/24 Loss: 0.207612
2023-01-06 12:08: Train Epoch 13: 19/24 Loss: 0.217737
2023-01-06 12:08: Train Epoch 13: 23/24 Loss: 0.171827
2023-01-06 12:08: **********Train Epoch 13: averaged Loss: 0.206733 
2023-01-06 12:08: 
Epoch time elapsed: 74.18643617630005

2023-01-06 12:08: 
 metrics validation: {'precision': 0.7735191637630662, 'recall': 0.444, 'f1-score': 0.5641677255400254, 'support': 500, 'AUC': 0.803176, 'AUCPR': 0.697907785734839, 'TP': 222, 'FP': 65, 'TN': 935, 'FN': 278} 

2023-01-06 12:08: **********Val Epoch 13: average Loss: 0.267440
2023-01-06 12:08: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-06 12:08: Total training time: 24.3540min, best loss: 0.250608
2023-01-06 12:08: Saving current best model to /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611442540411669386/best_model.pth
2023-01-06 12:09: 
 Testing metrics {'precision': 0.7832618025751072, 'recall': 0.73, 'f1-score': 0.7556935817805382, 'support': 500, 'AUC': 0.8687580000000001, 'AUCPR': 0.7915519075113049, 'TP': 365, 'FP': 101, 'TN': 899, 'FN': 135} 

2023-01-06 12:09: 
 Testing metrics {'precision': 0.8528301886792453, 'recall': 0.904, 'f1-score': 0.8776699029126214, 'support': 500, 'AUC': 0.963268, 'AUCPR': 0.9414055619835996, 'TP': 452, 'FP': 78, 'TN': 922, 'FN': 48} 

