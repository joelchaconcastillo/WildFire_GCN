2023-01-01 05:33: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010105332965474854013
2023-01-01 05:33: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010105332965474854013
2023-01-01 05:33: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010105332965474854013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=64, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-01 05:33: Argument batch_size: 256
2023-01-01 05:33: Argument clc: 'vec'
2023-01-01 05:33: Argument cuda: True
2023-01-01 05:33: Argument dataset: '2020'
2023-01-01 05:33: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-01 05:33: Argument debug: False
2023-01-01 05:33: Argument default_graph: True
2023-01-01 05:33: Argument device: 'cpu'
2023-01-01 05:33: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-01 05:33: Argument early_stop: True
2023-01-01 05:33: Argument early_stop_patience: 8
2023-01-01 05:33: Argument embed_dim: 64
2023-01-01 05:33: Argument epochs: 30
2023-01-01 05:33: Argument grad_norm: False
2023-01-01 05:33: Argument horizon: 1
2023-01-01 05:33: Argument input_dim: 25
2023-01-01 05:33: Argument lag: 10
2023-01-01 05:33: Argument link_len: 2
2023-01-01 05:33: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010105332965474854013'
2023-01-01 05:33: Argument log_step: 1
2023-01-01 05:33: Argument loss_func: 'nllloss'
2023-01-01 05:33: Argument lr_decay: True
2023-01-01 05:33: Argument lr_decay_rate: 0.1
2023-01-01 05:33: Argument lr_decay_step: '15, 20'
2023-01-01 05:33: Argument lr_init: 0.0001
2023-01-01 05:33: Argument max_grad_norm: 5
2023-01-01 05:33: Argument minbatch_size: 64
2023-01-01 05:33: Argument mode: 'train'
2023-01-01 05:33: Argument model: 'fire_GCN'
2023-01-01 05:33: Argument nan_fill: -1.0
2023-01-01 05:33: Argument num_layers: 1
2023-01-01 05:33: Argument num_nodes: 625
2023-01-01 05:33: Argument num_workers: 12
2023-01-01 05:33: Argument output_dim: 2
2023-01-01 05:33: Argument patch_height: 25
2023-01-01 05:33: Argument patch_width: 25
2023-01-01 05:33: Argument persistent_workers: True
2023-01-01 05:33: Argument pin_memory: True
2023-01-01 05:33: Argument plot: False
2023-01-01 05:33: Argument positive_weight: 0.5
2023-01-01 05:33: Argument prefetch_factor: 2
2023-01-01 05:33: Argument real_value: True
2023-01-01 05:33: Argument rnn_units: 64
2023-01-01 05:33: Argument seed: 10000
2023-01-01 05:33: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-01 05:33: Argument teacher_forcing: False
2023-01-01 05:33: Argument weight_decay: 0.0
2023-01-01 05:33: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([64, 2, 89, 64]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 64]) True
encoder.cell_list.0.gate.bias_pool torch.Size([64, 128]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([64, 2, 89, 32]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 32]) True
encoder.cell_list.0.update.bias_pool torch.Size([64, 64]) True
encoder.cell_list.0.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 40000]) True
fc1.bias torch.Size([2]) True
Total params num: 1232136
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010105332965474854013/run.log
2023-01-01 05:33: Train Epoch 1: 3/634 Loss: 0.600289
2023-01-01 05:34: Train Epoch 1: 7/634 Loss: 0.989079
2023-01-01 05:34: Train Epoch 1: 11/634 Loss: 1.179627
2023-01-01 05:34: Train Epoch 1: 15/634 Loss: 0.704595
2023-01-01 05:35: Train Epoch 1: 19/634 Loss: 0.610596
2023-01-01 05:35: Train Epoch 1: 23/634 Loss: 0.548251
2023-01-01 05:35: Train Epoch 1: 27/634 Loss: 0.657401
2023-01-01 05:36: Train Epoch 1: 31/634 Loss: 0.337064
2023-01-01 05:36: Train Epoch 1: 35/634 Loss: 0.290150
2023-01-01 05:36: Train Epoch 1: 39/634 Loss: 0.368151
2023-01-01 05:37: Train Epoch 1: 43/634 Loss: 0.477828
2023-01-01 05:37: Train Epoch 1: 47/634 Loss: 0.524736
2023-01-01 05:37: Train Epoch 1: 51/634 Loss: 0.381593
2023-01-01 05:38: Train Epoch 1: 55/634 Loss: 0.252428
2023-01-01 05:38: Train Epoch 1: 59/634 Loss: 0.256916
2023-01-01 05:39: Train Epoch 1: 63/634 Loss: 0.284704
2023-01-01 05:39: Train Epoch 1: 67/634 Loss: 0.341872
2023-01-01 05:39: Train Epoch 1: 71/634 Loss: 0.316396
2023-01-01 05:40: Train Epoch 1: 75/634 Loss: 0.267478
2023-01-01 05:40: Train Epoch 1: 79/634 Loss: 0.288134
2023-01-01 05:40: Train Epoch 1: 83/634 Loss: 0.342993
2023-01-01 05:41: Train Epoch 1: 87/634 Loss: 0.263124
2023-01-01 05:41: Train Epoch 1: 91/634 Loss: 0.212581
2023-01-01 05:41: Train Epoch 1: 95/634 Loss: 0.198300
2023-01-01 05:42: Train Epoch 1: 99/634 Loss: 0.316027
2023-01-01 05:42: Train Epoch 1: 103/634 Loss: 0.278485
2023-01-01 05:42: Train Epoch 1: 107/634 Loss: 0.250375
2023-01-01 05:43: Train Epoch 1: 111/634 Loss: 0.230970
2023-01-01 05:43: Train Epoch 1: 115/634 Loss: 0.260529
2023-01-01 05:43: Train Epoch 1: 119/634 Loss: 0.262594
2023-01-01 05:44: Train Epoch 1: 123/634 Loss: 0.240717
2023-01-01 05:44: Train Epoch 1: 127/634 Loss: 0.255279
2023-01-01 05:44: Train Epoch 1: 131/634 Loss: 0.209123
2023-01-01 05:45: Train Epoch 1: 135/634 Loss: 0.238648
2023-01-01 05:45: Train Epoch 1: 139/634 Loss: 0.225362
2023-01-01 05:45: Train Epoch 1: 143/634 Loss: 0.199499
2023-01-01 05:46: Train Epoch 1: 147/634 Loss: 0.184361
2023-01-01 05:46: Train Epoch 1: 151/634 Loss: 0.230011
2023-01-01 05:46: Train Epoch 1: 155/634 Loss: 0.241498
2023-01-01 05:47: Train Epoch 1: 159/634 Loss: 0.215988
2023-01-01 05:47: Train Epoch 1: 163/634 Loss: 0.227367
2023-01-01 05:47: Train Epoch 1: 167/634 Loss: 0.242747
2023-01-01 05:48: Train Epoch 1: 171/634 Loss: 0.208529
2023-01-01 05:48: Train Epoch 1: 175/634 Loss: 0.201226
2023-01-01 05:48: Train Epoch 1: 179/634 Loss: 0.247237
2023-01-01 05:49: Train Epoch 1: 183/634 Loss: 0.222911
2023-01-01 05:49: Train Epoch 1: 187/634 Loss: 0.201994
2023-01-01 05:50: Train Epoch 1: 191/634 Loss: 0.195167
2023-01-01 05:50: Train Epoch 1: 195/634 Loss: 0.210283
2023-01-01 05:50: Train Epoch 1: 199/634 Loss: 0.196565
2023-01-01 05:51: Train Epoch 1: 203/634 Loss: 0.210381
2023-01-01 05:51: Train Epoch 1: 207/634 Loss: 0.236809
2023-01-01 05:51: Train Epoch 1: 211/634 Loss: 0.229199
2023-01-01 05:52: Train Epoch 1: 215/634 Loss: 0.200933
2023-01-01 05:52: Train Epoch 1: 219/634 Loss: 0.210375
2023-01-01 05:52: Train Epoch 1: 223/634 Loss: 0.186524
2023-01-01 05:53: Train Epoch 1: 227/634 Loss: 0.207662
2023-01-01 05:53: Train Epoch 1: 231/634 Loss: 0.210490
2023-01-01 05:53: Train Epoch 1: 235/634 Loss: 0.190403
2023-01-01 05:54: Train Epoch 1: 239/634 Loss: 0.210886
2023-01-01 05:54: Train Epoch 1: 243/634 Loss: 0.189687
2023-01-01 05:54: Train Epoch 1: 247/634 Loss: 0.204267
2023-01-01 05:55: Train Epoch 1: 251/634 Loss: 0.202523
2023-01-01 05:55: Train Epoch 1: 255/634 Loss: 0.201351
2023-01-01 05:55: Train Epoch 1: 259/634 Loss: 0.218843
2023-01-01 05:56: Train Epoch 1: 263/634 Loss: 0.206447
2023-01-01 05:56: Train Epoch 1: 267/634 Loss: 0.229252
2023-01-01 05:56: Train Epoch 1: 271/634 Loss: 0.196555
2023-01-01 05:57: Train Epoch 1: 275/634 Loss: 0.184039
2023-01-01 05:57: Train Epoch 1: 279/634 Loss: 0.219498
2023-01-01 05:57: Train Epoch 1: 283/634 Loss: 0.209174
2023-01-01 05:58: Train Epoch 1: 287/634 Loss: 0.233357
2023-01-01 05:58: Train Epoch 1: 291/634 Loss: 0.235506
2023-01-01 05:58: Train Epoch 1: 295/634 Loss: 0.211136
2023-01-01 05:59: Train Epoch 1: 299/634 Loss: 0.198034
2023-01-01 05:59: Train Epoch 1: 303/634 Loss: 0.197556
2023-01-01 05:59: Train Epoch 1: 307/634 Loss: 0.205222
2023-01-01 06:00: Train Epoch 1: 311/634 Loss: 0.220293
2023-01-01 06:00: Train Epoch 1: 315/634 Loss: 0.202476
2023-01-01 06:00: Train Epoch 1: 319/634 Loss: 0.193562
2023-01-01 06:01: Train Epoch 1: 323/634 Loss: 0.187235
2023-01-01 06:01: Train Epoch 1: 327/634 Loss: 0.192294
2023-01-01 06:01: Train Epoch 1: 331/634 Loss: 0.198438
2023-01-01 06:02: Train Epoch 1: 335/634 Loss: 0.185172
2023-01-01 06:02: Train Epoch 1: 339/634 Loss: 0.215798
2023-01-01 06:03: Train Epoch 1: 343/634 Loss: 0.215923
2023-01-01 06:03: Train Epoch 1: 347/634 Loss: 0.202172
2023-01-01 06:03: Train Epoch 1: 351/634 Loss: 0.226333
2023-01-01 06:04: Train Epoch 1: 355/634 Loss: 0.214256
2023-01-01 06:04: Train Epoch 1: 359/634 Loss: 0.193822
2023-01-01 06:04: Train Epoch 1: 363/634 Loss: 0.161910
2023-01-01 06:05: Train Epoch 1: 367/634 Loss: 0.205118
2023-01-01 06:05: Train Epoch 1: 371/634 Loss: 0.198186
2023-01-01 06:05: Train Epoch 1: 375/634 Loss: 0.192465
2023-01-01 06:05: Train Epoch 1: 379/634 Loss: 0.232315
2023-01-01 06:06: Train Epoch 1: 383/634 Loss: 0.208579
2023-01-01 06:06: Train Epoch 1: 387/634 Loss: 0.175309
2023-01-01 06:06: Train Epoch 1: 391/634 Loss: 0.190185
2023-01-01 06:07: Train Epoch 1: 395/634 Loss: 0.200592
2023-01-01 06:07: Train Epoch 1: 399/634 Loss: 0.220988
2023-01-01 06:07: Train Epoch 1: 403/634 Loss: 0.170565
2023-01-01 06:08: Train Epoch 1: 407/634 Loss: 0.183164
2023-01-01 06:08: Train Epoch 1: 411/634 Loss: 0.213243
2023-01-01 06:08: Train Epoch 1: 415/634 Loss: 0.194359
2023-01-01 06:09: Train Epoch 1: 419/634 Loss: 0.185477
2023-01-01 06:09: Train Epoch 1: 423/634 Loss: 0.178533
2023-01-01 06:10: Train Epoch 1: 427/634 Loss: 0.215913
2023-01-01 06:10: Train Epoch 1: 431/634 Loss: 0.194266
2023-01-01 06:10: Train Epoch 1: 435/634 Loss: 0.203269
2023-01-01 06:11: Train Epoch 1: 439/634 Loss: 0.242957
2023-01-01 06:11: Train Epoch 1: 443/634 Loss: 0.212517
2023-01-01 06:11: Train Epoch 1: 447/634 Loss: 0.206743
2023-01-01 06:12: Train Epoch 1: 451/634 Loss: 0.186410
2023-01-01 06:12: Train Epoch 1: 455/634 Loss: 0.218574
2023-01-01 06:12: Train Epoch 1: 459/634 Loss: 0.208226
2023-01-01 06:13: Train Epoch 1: 463/634 Loss: 0.208901
2023-01-01 06:13: Train Epoch 1: 467/634 Loss: 0.233824
2023-01-01 06:13: Train Epoch 1: 471/634 Loss: 0.191567
2023-01-01 06:14: Train Epoch 1: 475/634 Loss: 0.190553
2023-01-01 06:14: Train Epoch 1: 479/634 Loss: 0.179802
2023-01-01 06:14: Train Epoch 1: 483/634 Loss: 0.188714
2023-01-01 06:15: Train Epoch 1: 487/634 Loss: 0.185813
2023-01-01 06:15: Train Epoch 1: 491/634 Loss: 0.222023
2023-01-01 06:15: Train Epoch 1: 495/634 Loss: 0.232868
2023-01-01 06:16: Train Epoch 1: 499/634 Loss: 0.199763
2023-01-01 06:16: Train Epoch 1: 503/634 Loss: 0.215837
2023-01-01 06:16: Train Epoch 1: 507/634 Loss: 0.203599
2023-01-01 06:17: Train Epoch 1: 511/634 Loss: 0.185538
2023-01-01 06:17: Train Epoch 1: 515/634 Loss: 0.196229
2023-01-01 06:18: Train Epoch 1: 519/634 Loss: 0.197554
2023-01-01 06:18: Train Epoch 1: 523/634 Loss: 0.202429
2023-01-01 06:18: Train Epoch 1: 527/634 Loss: 0.211442
2023-01-01 06:19: Train Epoch 1: 531/634 Loss: 0.226516
2023-01-01 06:19: Train Epoch 1: 535/634 Loss: 0.207190
2023-01-01 06:19: Train Epoch 1: 539/634 Loss: 0.200950
2023-01-01 06:20: Train Epoch 1: 543/634 Loss: 0.225162
2023-01-01 06:20: Train Epoch 1: 547/634 Loss: 0.218607
2023-01-01 06:20: Train Epoch 1: 551/634 Loss: 0.203170
2023-01-01 06:21: Train Epoch 1: 555/634 Loss: 0.211551
2023-01-01 06:21: Train Epoch 1: 559/634 Loss: 0.190460
2023-01-01 06:21: Train Epoch 1: 563/634 Loss: 0.225828
2023-01-01 06:22: Train Epoch 1: 567/634 Loss: 0.216320
2023-01-01 06:22: Train Epoch 1: 571/634 Loss: 0.201656
2023-01-01 06:22: Train Epoch 1: 575/634 Loss: 0.204129
2023-01-01 06:23: Train Epoch 1: 579/634 Loss: 0.192564
2023-01-01 06:23: Train Epoch 1: 583/634 Loss: 0.179454
2023-01-01 06:23: Train Epoch 1: 587/634 Loss: 0.211335
2023-01-01 06:24: Train Epoch 1: 591/634 Loss: 0.226213
2023-01-01 06:24: Train Epoch 1: 595/634 Loss: 0.204017
2023-01-01 06:24: Train Epoch 1: 599/634 Loss: 0.197291
2023-01-01 06:25: Train Epoch 1: 603/634 Loss: 0.176508
2023-01-01 06:25: Train Epoch 1: 607/634 Loss: 0.196977
2023-01-01 06:25: Train Epoch 1: 611/634 Loss: 0.214219
2023-01-01 06:26: Train Epoch 1: 615/634 Loss: 0.195686
2023-01-01 06:26: Train Epoch 1: 619/634 Loss: 0.204529
2023-01-01 06:27: Train Epoch 1: 623/634 Loss: 0.212652
2023-01-01 06:27: Train Epoch 1: 627/634 Loss: 0.205114
2023-01-01 06:27: Train Epoch 1: 631/634 Loss: 0.196921
2023-01-01 06:27: Train Epoch 1: 633/634 Loss: 0.088858
2023-01-01 06:27: **********Train Epoch 1: averaged Loss: 0.244351 
2023-01-01 06:27: 
Epoch time elapsed: 3260.8232831954956

2023-01-01 06:29: 
 metrics validation: {'precision': 0.7604961832061069, 'recall': 0.6130769230769231, 'f1-score': 0.6788756388415674, 'support': 1300, 'AUC': 0.8555804733727811, 'AUCPR': 0.7435841414728025, 'TP': 797, 'FP': 251, 'TN': 2349, 'FN': 503} 

2023-01-01 06:29: **********Val Epoch 1: average Loss: 0.219612
2023-01-01 06:29: *********************************Current best model saved!
2023-01-01 06:30: 
 Testing metrics {'precision': 0.827016520894072, 'recall': 0.6929967426710097, 'f1-score': 0.7540983606557377, 'support': 1228, 'AUC': 0.8834155402179333, 'AUCPR': 0.8103653452820181, 'TP': 851, 'FP': 178, 'TN': 2278, 'FN': 377} 

2023-01-01 06:35: 
 Testing metrics {'precision': 0.8976150325222838, 'recall': 0.8454731109598366, 'f1-score': 0.8707641972423463, 'support': 4407, 'AUC': 0.9679237329435826, 'AUCPR': 0.9427097590846599, 'TP': 3726, 'FP': 425, 'TN': 8389, 'FN': 681} 

2023-01-01 06:36: Train Epoch 2: 3/634 Loss: 0.189428
2023-01-01 06:36: Train Epoch 2: 7/634 Loss: 0.194868
2023-01-01 06:37: Train Epoch 2: 11/634 Loss: 0.200069
2023-01-01 06:37: Train Epoch 2: 15/634 Loss: 0.196272
2023-01-01 06:37: Train Epoch 2: 19/634 Loss: 0.194856
2023-01-01 06:38: Train Epoch 2: 23/634 Loss: 0.203124
2023-01-01 06:38: Train Epoch 2: 27/634 Loss: 0.186547
2023-01-01 06:38: Train Epoch 2: 31/634 Loss: 0.212506
2023-01-01 06:39: Train Epoch 2: 35/634 Loss: 0.170076
2023-01-01 06:39: Train Epoch 2: 39/634 Loss: 0.162312
2023-01-01 06:39: Train Epoch 2: 43/634 Loss: 0.210391
2023-01-01 06:40: Train Epoch 2: 47/634 Loss: 0.188554
2023-01-01 06:40: Train Epoch 2: 51/634 Loss: 0.179363
2023-01-01 06:40: Train Epoch 2: 55/634 Loss: 0.176536
2023-01-01 06:41: Train Epoch 2: 59/634 Loss: 0.223507
2023-01-01 06:41: Train Epoch 2: 63/634 Loss: 0.217855
2023-01-01 06:42: Train Epoch 2: 67/634 Loss: 0.213258
2023-01-01 06:42: Train Epoch 2: 71/634 Loss: 0.178554
2023-01-01 06:42: Train Epoch 2: 75/634 Loss: 0.206526
2023-01-01 06:43: Train Epoch 2: 79/634 Loss: 0.198443
2023-01-01 06:43: Train Epoch 2: 83/634 Loss: 0.240846
2023-01-01 06:43: Train Epoch 2: 87/634 Loss: 0.185678
2023-01-01 06:44: Train Epoch 2: 91/634 Loss: 0.201569
2023-01-01 06:44: Train Epoch 2: 95/634 Loss: 0.222122
2023-01-01 06:44: Train Epoch 2: 99/634 Loss: 0.174298
2023-01-01 06:45: Train Epoch 2: 103/634 Loss: 0.194838
2023-01-01 06:45: Train Epoch 2: 107/634 Loss: 0.229152
2023-01-01 06:45: Train Epoch 2: 111/634 Loss: 0.209217
2023-01-01 06:46: Train Epoch 2: 115/634 Loss: 0.205635
2023-01-01 06:46: Train Epoch 2: 119/634 Loss: 0.228881
2023-01-01 06:46: Train Epoch 2: 123/634 Loss: 0.209556
2023-01-01 06:47: Train Epoch 2: 127/634 Loss: 0.184529
2023-01-01 06:47: Train Epoch 2: 131/634 Loss: 0.266016
2023-01-01 06:47: Train Epoch 2: 135/634 Loss: 0.179251
2023-01-01 06:48: Train Epoch 2: 139/634 Loss: 0.196098
2023-01-01 06:48: Train Epoch 2: 143/634 Loss: 0.215486
2023-01-01 06:49: Train Epoch 2: 147/634 Loss: 0.206358
2023-01-01 06:49: Train Epoch 2: 151/634 Loss: 0.189684
2023-01-01 06:49: Train Epoch 2: 155/634 Loss: 0.198299
2023-01-01 06:50: Train Epoch 2: 159/634 Loss: 0.165038
2023-01-01 06:50: Train Epoch 2: 163/634 Loss: 0.197541
2023-01-01 06:50: Train Epoch 2: 167/634 Loss: 0.170468
2023-01-01 06:51: Train Epoch 2: 171/634 Loss: 0.181998
2023-01-01 06:51: Train Epoch 2: 175/634 Loss: 0.205832
2023-01-01 06:51: Train Epoch 2: 179/634 Loss: 0.215635
2023-01-01 06:52: Train Epoch 2: 183/634 Loss: 0.188065
2023-01-01 06:52: Train Epoch 2: 187/634 Loss: 0.168810
2023-01-01 06:52: Train Epoch 2: 191/634 Loss: 0.189302
2023-01-01 06:53: Train Epoch 2: 195/634 Loss: 0.185936
2023-01-01 06:53: Train Epoch 2: 199/634 Loss: 0.185412
2023-01-01 06:54: Train Epoch 2: 203/634 Loss: 0.209562
2023-01-01 06:54: Train Epoch 2: 207/634 Loss: 0.201250
2023-01-01 06:54: Train Epoch 2: 211/634 Loss: 0.199869
2023-01-01 06:55: Train Epoch 2: 215/634 Loss: 0.185718
2023-01-01 06:55: Train Epoch 2: 219/634 Loss: 0.203720
2023-01-01 06:55: Train Epoch 2: 223/634 Loss: 0.160854
2023-01-01 06:56: Train Epoch 2: 227/634 Loss: 0.214311
2023-01-01 06:56: Train Epoch 2: 231/634 Loss: 0.173804
2023-01-01 06:56: Train Epoch 2: 235/634 Loss: 0.195985
2023-01-01 06:57: Train Epoch 2: 239/634 Loss: 0.183018
2023-01-01 06:57: Train Epoch 2: 243/634 Loss: 0.180164
2023-01-01 06:58: Train Epoch 2: 247/634 Loss: 0.207989
2023-01-01 06:58: Train Epoch 2: 251/634 Loss: 0.201188
2023-01-01 06:58: Train Epoch 2: 255/634 Loss: 0.179451
2023-01-01 06:59: Train Epoch 2: 259/634 Loss: 0.181132
2023-01-01 06:59: Train Epoch 2: 263/634 Loss: 0.189991
2023-01-01 06:59: Train Epoch 2: 267/634 Loss: 0.165534
2023-01-01 07:00: Train Epoch 2: 271/634 Loss: 0.203299
2023-01-01 07:00: Train Epoch 2: 275/634 Loss: 0.184205
2023-01-01 07:00: Train Epoch 2: 279/634 Loss: 0.191554
2023-01-01 07:01: Train Epoch 2: 283/634 Loss: 0.161287
2023-01-01 07:01: Train Epoch 2: 287/634 Loss: 0.179527
2023-01-01 07:01: Train Epoch 2: 291/634 Loss: 0.208602
2023-01-01 07:02: Train Epoch 2: 295/634 Loss: 0.169296
2023-01-01 07:02: Train Epoch 2: 299/634 Loss: 0.191264
2023-01-01 07:03: Train Epoch 2: 303/634 Loss: 0.239962
2023-01-01 07:03: Train Epoch 2: 307/634 Loss: 0.177752
2023-01-01 07:03: Train Epoch 2: 311/634 Loss: 0.239141
2023-01-01 07:04: Train Epoch 2: 315/634 Loss: 0.243952
2023-01-01 07:04: Train Epoch 2: 319/634 Loss: 0.196220
2023-01-01 07:04: Train Epoch 2: 323/634 Loss: 0.269799
2023-01-01 07:05: Train Epoch 2: 327/634 Loss: 0.172430
2023-01-01 07:05: Train Epoch 2: 331/634 Loss: 0.190815
2023-01-01 07:05: Train Epoch 2: 335/634 Loss: 0.192708
2023-01-01 07:06: Train Epoch 2: 339/634 Loss: 0.185722
2023-01-01 07:06: Train Epoch 2: 343/634 Loss: 0.200703
2023-01-01 07:07: Train Epoch 2: 347/634 Loss: 0.211640
2023-01-01 07:07: Train Epoch 2: 351/634 Loss: 0.183323
2023-01-01 07:07: Train Epoch 2: 355/634 Loss: 0.178743
2023-01-01 07:08: Train Epoch 2: 359/634 Loss: 0.203999
2023-01-01 07:08: Train Epoch 2: 363/634 Loss: 0.187163
2023-01-01 07:08: Train Epoch 2: 367/634 Loss: 0.215416
2023-01-01 07:09: Train Epoch 2: 371/634 Loss: 0.184476
2023-01-01 07:09: Train Epoch 2: 375/634 Loss: 0.187149
2023-01-01 07:09: Train Epoch 2: 379/634 Loss: 0.154745
2023-01-01 07:10: Train Epoch 2: 383/634 Loss: 0.200104
2023-01-01 07:10: Train Epoch 2: 387/634 Loss: 0.227748
2023-01-01 07:10: Train Epoch 2: 391/634 Loss: 0.229424
2023-01-01 07:11: Train Epoch 2: 395/634 Loss: 0.176036
2023-01-01 07:11: Train Epoch 2: 399/634 Loss: 0.185153
2023-01-01 07:11: Train Epoch 2: 403/634 Loss: 0.179333
2023-01-01 07:12: Train Epoch 2: 407/634 Loss: 0.220025
2023-01-01 07:12: Train Epoch 2: 411/634 Loss: 0.183231
2023-01-01 07:12: Train Epoch 2: 415/634 Loss: 0.201604
2023-01-01 07:13: Train Epoch 2: 419/634 Loss: 0.195461
2023-01-01 07:13: Train Epoch 2: 423/634 Loss: 0.183797
2023-01-01 07:13: Train Epoch 2: 427/634 Loss: 0.161654
2023-01-01 07:14: Train Epoch 2: 431/634 Loss: 0.196061
2023-01-01 07:14: Train Epoch 2: 435/634 Loss: 0.218133
2023-01-01 07:15: Train Epoch 2: 439/634 Loss: 0.186084
2023-01-01 07:15: Train Epoch 2: 443/634 Loss: 0.180090
2023-01-01 07:15: Train Epoch 2: 447/634 Loss: 0.210953
2023-01-01 07:16: Train Epoch 2: 451/634 Loss: 0.173444
2023-01-01 07:16: Train Epoch 2: 455/634 Loss: 0.190828
2023-01-01 07:16: Train Epoch 2: 459/634 Loss: 0.192242
2023-01-01 07:17: Train Epoch 2: 463/634 Loss: 0.183911
2023-01-01 07:17: Train Epoch 2: 467/634 Loss: 0.169626
2023-01-01 07:17: Train Epoch 2: 471/634 Loss: 0.181909
2023-01-01 07:18: Train Epoch 2: 475/634 Loss: 0.165913
2023-01-01 07:18: Train Epoch 2: 479/634 Loss: 0.188291
2023-01-01 07:19: Train Epoch 2: 483/634 Loss: 0.214919
2023-01-01 07:19: Train Epoch 2: 487/634 Loss: 0.203284
2023-01-01 07:19: Train Epoch 2: 491/634 Loss: 0.183795
2023-01-01 07:20: Train Epoch 2: 495/634 Loss: 0.181252
2023-01-01 07:20: Train Epoch 2: 499/634 Loss: 0.196367
2023-01-01 07:20: Train Epoch 2: 503/634 Loss: 0.190071
2023-01-01 07:21: Train Epoch 2: 507/634 Loss: 0.166974
2023-01-01 07:21: Train Epoch 2: 511/634 Loss: 0.210370
2023-01-01 07:22: Train Epoch 2: 515/634 Loss: 0.171768
2023-01-01 07:22: Train Epoch 2: 519/634 Loss: 0.182319
2023-01-01 07:22: Train Epoch 2: 523/634 Loss: 0.193230
2023-01-01 07:23: Train Epoch 2: 527/634 Loss: 0.179016
2023-01-01 07:23: Train Epoch 2: 531/634 Loss: 0.171685
2023-01-01 07:23: Train Epoch 2: 535/634 Loss: 0.195496
2023-01-01 07:24: Train Epoch 2: 539/634 Loss: 0.179389
2023-01-01 07:24: Train Epoch 2: 543/634 Loss: 0.214319
2023-01-01 07:24: Train Epoch 2: 547/634 Loss: 0.178887
2023-01-01 07:25: Train Epoch 2: 551/634 Loss: 0.174087
2023-01-01 07:25: Train Epoch 2: 555/634 Loss: 0.178710
2023-01-01 07:25: Train Epoch 2: 559/634 Loss: 0.193171
2023-01-01 07:26: Train Epoch 2: 563/634 Loss: 0.167903
2023-01-01 07:26: Train Epoch 2: 567/634 Loss: 0.197838
2023-01-01 07:26: Train Epoch 2: 571/634 Loss: 0.208281
2023-01-01 07:27: Train Epoch 2: 575/634 Loss: 0.184687
2023-01-01 07:27: Train Epoch 2: 579/634 Loss: 0.162265
2023-01-01 07:28: Train Epoch 2: 583/634 Loss: 0.218146
2023-01-01 07:28: Train Epoch 2: 587/634 Loss: 0.210588
2023-01-01 07:28: Train Epoch 2: 591/634 Loss: 0.191934
2023-01-01 07:29: Train Epoch 2: 595/634 Loss: 0.199411
2023-01-01 07:29: Train Epoch 2: 599/634 Loss: 0.206069
2023-01-01 07:29: Train Epoch 2: 603/634 Loss: 0.196565
2023-01-01 07:30: Train Epoch 2: 607/634 Loss: 0.209302
2023-01-01 07:30: Train Epoch 2: 611/634 Loss: 0.194631
2023-01-01 07:31: Train Epoch 2: 615/634 Loss: 0.211592
2023-01-01 07:31: Train Epoch 2: 619/634 Loss: 0.211767
2023-01-01 07:31: Train Epoch 2: 623/634 Loss: 0.189979
2023-01-01 07:32: Train Epoch 2: 627/634 Loss: 0.167517
2023-01-01 07:32: Train Epoch 2: 631/634 Loss: 0.187734
2023-01-01 07:32: Train Epoch 2: 633/634 Loss: 0.064663
2023-01-01 07:32: **********Train Epoch 2: averaged Loss: 0.193422 
2023-01-01 07:32: 
Epoch time elapsed: 3402.6146099567413

2023-01-01 07:34: 
 metrics validation: {'precision': 0.7846460618145563, 'recall': 0.6053846153846154, 'f1-score': 0.6834563612679114, 'support': 1300, 'AUC': 0.8912224852071007, 'AUCPR': 0.7885331477114983, 'TP': 787, 'FP': 216, 'TN': 2384, 'FN': 513} 

2023-01-01 07:34: **********Val Epoch 2: average Loss: 0.191189
2023-01-01 07:34: *********************************Current best model saved!
2023-01-01 07:35: 
 Testing metrics {'precision': 0.8458333333333333, 'recall': 0.6612377850162866, 'f1-score': 0.7422303473491773, 'support': 1228, 'AUC': 0.9019568510010715, 'AUCPR': 0.8379780616437654, 'TP': 812, 'FP': 148, 'TN': 2308, 'FN': 416} 

2023-01-01 07:40: 
 Testing metrics {'precision': 0.8982483256053581, 'recall': 0.7912412071704107, 'f1-score': 0.8413560139944505, 'support': 4407, 'AUC': 0.9667594651720871, 'AUCPR': 0.9364636515178052, 'TP': 3487, 'FP': 395, 'TN': 8419, 'FN': 920} 

2023-01-01 07:41: Train Epoch 3: 3/634 Loss: 0.175489
2023-01-01 07:41: Train Epoch 3: 7/634 Loss: 0.160787
2023-01-01 07:41: Train Epoch 3: 11/634 Loss: 0.192939
2023-01-01 07:42: Train Epoch 3: 15/634 Loss: 0.191434
2023-01-01 07:42: Train Epoch 3: 19/634 Loss: 0.192749
2023-01-01 07:42: Train Epoch 3: 23/634 Loss: 0.180322
2023-01-01 07:43: Train Epoch 3: 27/634 Loss: 0.170283
2023-01-01 07:43: Train Epoch 3: 31/634 Loss: 0.189225
2023-01-01 07:43: Train Epoch 3: 35/634 Loss: 0.231116
2023-01-01 07:44: Train Epoch 3: 39/634 Loss: 0.188238
2023-01-01 07:44: Train Epoch 3: 43/634 Loss: 0.192108
2023-01-01 07:45: Train Epoch 3: 47/634 Loss: 0.201619
2023-01-01 07:45: Train Epoch 3: 51/634 Loss: 0.197994
2023-01-01 07:45: Train Epoch 3: 55/634 Loss: 0.177777
2023-01-01 07:46: Train Epoch 3: 59/634 Loss: 0.185799
2023-01-01 07:46: Train Epoch 3: 63/634 Loss: 0.221658
2023-01-01 07:46: Train Epoch 3: 67/634 Loss: 0.185555
2023-01-01 07:47: Train Epoch 3: 71/634 Loss: 0.203757
2023-01-01 07:47: Train Epoch 3: 75/634 Loss: 0.177395
2023-01-01 07:47: Train Epoch 3: 79/634 Loss: 0.209886
2023-01-01 07:48: Train Epoch 3: 83/634 Loss: 0.187257
2023-01-01 07:48: Train Epoch 3: 87/634 Loss: 0.182305
2023-01-01 07:49: Train Epoch 3: 91/634 Loss: 0.189285
2023-01-01 07:49: Train Epoch 3: 95/634 Loss: 0.168993
2023-01-01 07:49: Train Epoch 3: 99/634 Loss: 0.173734
2023-01-01 07:50: Train Epoch 3: 103/634 Loss: 0.185171
2023-01-01 07:50: Train Epoch 3: 107/634 Loss: 0.189217
2023-01-01 07:50: Train Epoch 3: 111/634 Loss: 0.187501
2023-01-01 07:51: Train Epoch 3: 115/634 Loss: 0.198308
2023-01-01 07:51: Train Epoch 3: 119/634 Loss: 0.191135
2023-01-01 07:52: Train Epoch 3: 123/634 Loss: 0.201869
2023-01-01 07:52: Train Epoch 3: 127/634 Loss: 0.180360
2023-01-01 07:52: Train Epoch 3: 131/634 Loss: 0.149136
2023-01-01 07:53: Train Epoch 3: 135/634 Loss: 0.223154
2023-01-01 07:53: Train Epoch 3: 139/634 Loss: 0.243037
2023-01-01 07:53: Train Epoch 3: 143/634 Loss: 0.182465
2023-01-01 07:54: Train Epoch 3: 147/634 Loss: 0.170976
2023-01-01 07:54: Train Epoch 3: 151/634 Loss: 0.213887
2023-01-01 07:54: Train Epoch 3: 155/634 Loss: 0.159197
2023-01-01 07:55: Train Epoch 3: 159/634 Loss: 0.177285
2023-01-01 07:55: Train Epoch 3: 163/634 Loss: 0.190832
2023-01-01 07:56: Train Epoch 3: 167/634 Loss: 0.206736
2023-01-01 07:56: Train Epoch 3: 171/634 Loss: 0.188106
2023-01-01 07:56: Train Epoch 3: 175/634 Loss: 0.202438
2023-01-01 07:57: Train Epoch 3: 179/634 Loss: 0.179299
2023-01-01 07:57: Train Epoch 3: 183/634 Loss: 0.195680
2023-01-01 07:57: Train Epoch 3: 187/634 Loss: 0.207168
2023-01-01 07:58: Train Epoch 3: 191/634 Loss: 0.218008
2023-01-01 07:58: Train Epoch 3: 195/634 Loss: 0.165493
2023-01-01 07:58: Train Epoch 3: 199/634 Loss: 0.199307
2023-01-01 07:59: Train Epoch 3: 203/634 Loss: 0.150272
2023-01-01 07:59: Train Epoch 3: 207/634 Loss: 0.221538
2023-01-01 07:59: Train Epoch 3: 211/634 Loss: 0.187982
2023-01-01 08:00: Train Epoch 3: 215/634 Loss: 0.210442
2023-01-01 08:00: Train Epoch 3: 219/634 Loss: 0.189705
2023-01-01 08:01: Train Epoch 3: 223/634 Loss: 0.162412
2023-01-01 08:01: Train Epoch 3: 227/634 Loss: 0.179301
2023-01-01 08:01: Train Epoch 3: 231/634 Loss: 0.207044
2023-01-01 08:02: Train Epoch 3: 235/634 Loss: 0.188460
2023-01-01 08:02: Train Epoch 3: 239/634 Loss: 0.184632
2023-01-01 08:02: Train Epoch 3: 243/634 Loss: 0.201974
2023-01-01 08:03: Train Epoch 3: 247/634 Loss: 0.195089
2023-01-01 08:03: Train Epoch 3: 251/634 Loss: 0.207482
2023-01-01 08:03: Train Epoch 3: 255/634 Loss: 0.187570
2023-01-01 08:04: Train Epoch 3: 259/634 Loss: 0.183297
2023-01-01 08:04: Train Epoch 3: 263/634 Loss: 0.178486
2023-01-01 08:05: Train Epoch 3: 267/634 Loss: 0.197984
2023-01-01 08:05: Train Epoch 3: 271/634 Loss: 0.179155
2023-01-01 08:05: Train Epoch 3: 275/634 Loss: 0.170917
2023-01-01 08:06: Train Epoch 3: 279/634 Loss: 0.214414
2023-01-01 08:06: Train Epoch 3: 283/634 Loss: 0.155825
2023-01-01 08:06: Train Epoch 3: 287/634 Loss: 0.164978
2023-01-01 08:07: Train Epoch 3: 291/634 Loss: 0.159163
2023-01-01 08:07: Train Epoch 3: 295/634 Loss: 0.186199
2023-01-01 08:07: Train Epoch 3: 299/634 Loss: 0.174263
2023-01-01 08:08: Train Epoch 3: 303/634 Loss: 0.173744
2023-01-01 08:08: Train Epoch 3: 307/634 Loss: 0.199656
2023-01-01 08:09: Train Epoch 3: 311/634 Loss: 0.169965
2023-01-01 08:09: Train Epoch 3: 315/634 Loss: 0.174082
2023-01-01 08:09: Train Epoch 3: 319/634 Loss: 0.176773
2023-01-01 08:10: Train Epoch 3: 323/634 Loss: 0.179498
2023-01-01 08:10: Train Epoch 3: 327/634 Loss: 0.171966
2023-01-01 08:10: Train Epoch 3: 331/634 Loss: 0.194519
2023-01-01 08:11: Train Epoch 3: 335/634 Loss: 0.178247
2023-01-01 08:11: Train Epoch 3: 339/634 Loss: 0.181498
2023-01-01 08:11: Train Epoch 3: 343/634 Loss: 0.180651
2023-01-01 08:12: Train Epoch 3: 347/634 Loss: 0.153415
2023-01-01 08:12: Train Epoch 3: 351/634 Loss: 0.173713
2023-01-01 08:12: Train Epoch 3: 355/634 Loss: 0.177266
2023-01-01 08:13: Train Epoch 3: 359/634 Loss: 0.161417
2023-01-01 08:13: Train Epoch 3: 363/634 Loss: 0.177856
2023-01-01 08:14: Train Epoch 3: 367/634 Loss: 0.197583
2023-01-01 08:14: Train Epoch 3: 371/634 Loss: 0.230400
2023-01-01 08:14: Train Epoch 3: 375/634 Loss: 0.191161
2023-01-01 08:15: Train Epoch 3: 379/634 Loss: 0.179252
2023-01-01 08:15: Train Epoch 3: 383/634 Loss: 0.233622
2023-01-01 08:15: Train Epoch 3: 387/634 Loss: 0.153747
2023-01-01 08:16: Train Epoch 3: 391/634 Loss: 0.192431
2023-01-01 08:16: Train Epoch 3: 395/634 Loss: 0.199010
2023-01-01 08:16: Train Epoch 3: 399/634 Loss: 0.189304
2023-01-01 08:17: Train Epoch 3: 403/634 Loss: 0.173038
2023-01-01 08:17: Train Epoch 3: 407/634 Loss: 0.190967
2023-01-01 08:18: Train Epoch 3: 411/634 Loss: 0.179704
2023-01-01 08:18: Train Epoch 3: 415/634 Loss: 0.191341
2023-01-01 08:18: Train Epoch 3: 419/634 Loss: 0.196151
2023-01-01 08:19: Train Epoch 3: 423/634 Loss: 0.175388
2023-01-01 08:19: Train Epoch 3: 427/634 Loss: 0.190167
2023-01-01 08:19: Train Epoch 3: 431/634 Loss: 0.171500
2023-01-01 08:20: Train Epoch 3: 435/634 Loss: 0.193809
2023-01-01 08:20: Train Epoch 3: 439/634 Loss: 0.157524
2023-01-01 08:20: Train Epoch 3: 443/634 Loss: 0.171210
2023-01-01 08:21: Train Epoch 3: 447/634 Loss: 0.182250
2023-01-01 08:21: Train Epoch 3: 451/634 Loss: 0.182508
2023-01-01 08:21: Train Epoch 3: 455/634 Loss: 0.194168
2023-01-01 08:22: Train Epoch 3: 459/634 Loss: 0.178807
2023-01-01 08:22: Train Epoch 3: 463/634 Loss: 0.181139
2023-01-01 08:23: Train Epoch 3: 467/634 Loss: 0.171950
2023-01-01 08:23: Train Epoch 3: 471/634 Loss: 0.194402
2023-01-01 08:23: Train Epoch 3: 475/634 Loss: 0.142965
2023-01-01 08:24: Train Epoch 3: 479/634 Loss: 0.188602
2023-01-01 08:24: Train Epoch 3: 483/634 Loss: 0.179668
2023-01-01 08:24: Train Epoch 3: 487/634 Loss: 0.215843
2023-01-01 08:25: Train Epoch 3: 491/634 Loss: 0.175961
2023-01-01 08:25: Train Epoch 3: 495/634 Loss: 0.180198
2023-01-01 08:25: Train Epoch 3: 499/634 Loss: 0.193510
2023-01-01 08:26: Train Epoch 3: 503/634 Loss: 0.173298
2023-01-01 08:26: Train Epoch 3: 507/634 Loss: 0.184214
2023-01-01 08:27: Train Epoch 3: 511/634 Loss: 0.178826
2023-01-01 08:27: Train Epoch 3: 515/634 Loss: 0.166243
2023-01-01 08:27: Train Epoch 3: 519/634 Loss: 0.145596
2023-01-01 08:28: Train Epoch 3: 523/634 Loss: 0.177363
2023-01-01 08:28: Train Epoch 3: 527/634 Loss: 0.194804
2023-01-01 08:28: Train Epoch 3: 531/634 Loss: 0.181519
2023-01-01 08:29: Train Epoch 3: 535/634 Loss: 0.183476
2023-01-01 08:29: Train Epoch 3: 539/634 Loss: 0.200259
2023-01-01 08:29: Train Epoch 3: 543/634 Loss: 0.157824
2023-01-01 08:30: Train Epoch 3: 547/634 Loss: 0.177905
2023-01-01 08:30: Train Epoch 3: 551/634 Loss: 0.179154
2023-01-01 08:30: Train Epoch 3: 555/634 Loss: 0.177733
2023-01-01 08:31: Train Epoch 3: 559/634 Loss: 0.183606
2023-01-01 08:31: Train Epoch 3: 563/634 Loss: 0.169803
2023-01-01 08:31: Train Epoch 3: 567/634 Loss: 0.199779
2023-01-01 08:32: Train Epoch 3: 571/634 Loss: 0.175130
2023-01-01 08:32: Train Epoch 3: 575/634 Loss: 0.200368
2023-01-01 08:32: Train Epoch 3: 579/634 Loss: 0.180376
2023-01-01 08:33: Train Epoch 3: 583/634 Loss: 0.177579
2023-01-01 08:33: Train Epoch 3: 587/634 Loss: 0.193032
2023-01-01 08:34: Train Epoch 3: 591/634 Loss: 0.186103
2023-01-01 08:34: Train Epoch 3: 595/634 Loss: 0.213711
2023-01-01 08:34: Train Epoch 3: 599/634 Loss: 0.183510
2023-01-01 08:35: Train Epoch 3: 603/634 Loss: 0.184885
2023-01-01 08:35: Train Epoch 3: 607/634 Loss: 0.188239
2023-01-01 08:35: Train Epoch 3: 611/634 Loss: 0.159568
2023-01-01 08:36: Train Epoch 3: 615/634 Loss: 0.211313
2023-01-01 08:36: Train Epoch 3: 619/634 Loss: 0.191754
2023-01-01 08:36: Train Epoch 3: 623/634 Loss: 0.190675
2023-01-01 08:37: Train Epoch 3: 627/634 Loss: 0.162001
2023-01-01 08:37: Train Epoch 3: 631/634 Loss: 0.181452
2023-01-01 08:37: Train Epoch 3: 633/634 Loss: 0.099750
2023-01-01 08:37: **********Train Epoch 3: averaged Loss: 0.185072 
2023-01-01 08:37: 
Epoch time elapsed: 3413.3007242679596

2023-01-01 08:39: 
 metrics validation: {'precision': 0.7437956204379562, 'recall': 0.7838461538461539, 'f1-score': 0.7632958801498126, 'support': 1300, 'AUC': 0.9033751479289941, 'AUCPR': 0.8225724770768692, 'TP': 1019, 'FP': 351, 'TN': 2249, 'FN': 281} 

2023-01-01 08:39: **********Val Epoch 3: average Loss: 0.175832
2023-01-01 08:39: *********************************Current best model saved!
2023-01-01 08:40: 
 Testing metrics {'precision': 0.7885095753538718, 'recall': 0.7711726384364821, 'f1-score': 0.7797447509263071, 'support': 1228, 'AUC': 0.9120560960859001, 'AUCPR': 0.8595261692722443, 'TP': 947, 'FP': 254, 'TN': 2202, 'FN': 281} 

2023-01-01 08:45: 
 Testing metrics {'precision': 0.8628328008519702, 'recall': 0.9192194236442024, 'f1-score': 0.8901340364754999, 'support': 4407, 'AUC': 0.9742860145397539, 'AUCPR': 0.952571609380292, 'TP': 4051, 'FP': 644, 'TN': 8170, 'FN': 356} 

2023-01-01 08:46: Train Epoch 4: 3/634 Loss: 0.220212
2023-01-01 08:46: Train Epoch 4: 7/634 Loss: 0.160605
2023-01-01 08:46: Train Epoch 4: 11/634 Loss: 0.204185
2023-01-01 08:47: Train Epoch 4: 15/634 Loss: 0.173107
2023-01-01 08:47: Train Epoch 4: 19/634 Loss: 0.145517
2023-01-01 08:48: Train Epoch 4: 23/634 Loss: 0.172879
2023-01-01 08:48: Train Epoch 4: 27/634 Loss: 0.194731
2023-01-01 08:48: Train Epoch 4: 31/634 Loss: 0.187820
2023-01-01 08:49: Train Epoch 4: 35/634 Loss: 0.195868
2023-01-01 08:49: Train Epoch 4: 39/634 Loss: 0.178322
2023-01-01 08:49: Train Epoch 4: 43/634 Loss: 0.232404
2023-01-01 08:50: Train Epoch 4: 47/634 Loss: 0.169069
2023-01-01 08:50: Train Epoch 4: 51/634 Loss: 0.198034
2023-01-01 08:50: Train Epoch 4: 55/634 Loss: 0.165428
2023-01-01 08:51: Train Epoch 4: 59/634 Loss: 0.181915
2023-01-01 08:51: Train Epoch 4: 63/634 Loss: 0.169633
2023-01-01 08:51: Train Epoch 4: 67/634 Loss: 0.145164
2023-01-01 08:52: Train Epoch 4: 71/634 Loss: 0.155741
2023-01-01 08:52: Train Epoch 4: 75/634 Loss: 0.161561
2023-01-01 08:52: Train Epoch 4: 79/634 Loss: 0.182021
2023-01-01 08:53: Train Epoch 4: 83/634 Loss: 0.148776
2023-01-01 08:53: Train Epoch 4: 87/634 Loss: 0.155580
2023-01-01 08:53: Train Epoch 4: 91/634 Loss: 0.201086
2023-01-01 08:54: Train Epoch 4: 95/634 Loss: 0.209016
2023-01-01 08:54: Train Epoch 4: 99/634 Loss: 0.167122
2023-01-01 08:54: Train Epoch 4: 103/634 Loss: 0.167888
2023-01-01 08:55: Train Epoch 4: 107/634 Loss: 0.202507
2023-01-01 08:55: Train Epoch 4: 111/634 Loss: 0.201024
2023-01-01 08:55: Train Epoch 4: 115/634 Loss: 0.178901
2023-01-01 08:56: Train Epoch 4: 119/634 Loss: 0.155081
2023-01-01 08:56: Train Epoch 4: 123/634 Loss: 0.188391
2023-01-01 08:56: Train Epoch 4: 127/634 Loss: 0.177774
2023-01-01 08:57: Train Epoch 4: 131/634 Loss: 0.177407
2023-01-01 08:57: Train Epoch 4: 135/634 Loss: 0.161784
2023-01-01 08:57: Train Epoch 4: 139/634 Loss: 0.201470
2023-01-01 08:58: Train Epoch 4: 143/634 Loss: 0.178627
2023-01-01 08:58: Train Epoch 4: 147/634 Loss: 0.135565
2023-01-01 08:58: Train Epoch 4: 151/634 Loss: 0.177327
2023-01-01 08:59: Train Epoch 4: 155/634 Loss: 0.188486
2023-01-01 08:59: Train Epoch 4: 159/634 Loss: 0.152538
2023-01-01 08:59: Train Epoch 4: 163/634 Loss: 0.171404
2023-01-01 09:00: Train Epoch 4: 167/634 Loss: 0.172059
2023-01-01 09:00: Train Epoch 4: 171/634 Loss: 0.175625
2023-01-01 09:00: Train Epoch 4: 175/634 Loss: 0.176562
2023-01-01 09:01: Train Epoch 4: 179/634 Loss: 0.161664
2023-01-01 09:01: Train Epoch 4: 183/634 Loss: 0.176649
2023-01-01 09:02: Train Epoch 4: 187/634 Loss: 0.157280
2023-01-01 09:02: Train Epoch 4: 191/634 Loss: 0.159163
2023-01-01 09:02: Train Epoch 4: 195/634 Loss: 0.162149
2023-01-01 09:03: Train Epoch 4: 199/634 Loss: 0.171936
2023-01-01 09:03: Train Epoch 4: 203/634 Loss: 0.178360
2023-01-01 09:03: Train Epoch 4: 207/634 Loss: 0.166532
2023-01-01 09:04: Train Epoch 4: 211/634 Loss: 0.156035
2023-01-01 09:04: Train Epoch 4: 215/634 Loss: 0.161843
2023-01-01 09:04: Train Epoch 4: 219/634 Loss: 0.180950
2023-01-01 09:05: Train Epoch 4: 223/634 Loss: 0.195302
2023-01-01 09:05: Train Epoch 4: 227/634 Loss: 0.189452
2023-01-01 09:06: Train Epoch 4: 231/634 Loss: 0.202392
2023-01-01 09:06: Train Epoch 4: 235/634 Loss: 0.172771
2023-01-01 09:06: Train Epoch 4: 239/634 Loss: 0.160560
2023-01-01 09:07: Train Epoch 4: 243/634 Loss: 0.156320
2023-01-01 09:07: Train Epoch 4: 247/634 Loss: 0.175567
2023-01-01 09:07: Train Epoch 4: 251/634 Loss: 0.157575
2023-01-01 09:08: Train Epoch 4: 255/634 Loss: 0.193975
2023-01-01 09:08: Train Epoch 4: 259/634 Loss: 0.156175
2023-01-01 09:09: Train Epoch 4: 263/634 Loss: 0.173669
2023-01-01 09:09: Train Epoch 4: 267/634 Loss: 0.162634
2023-01-01 09:09: Train Epoch 4: 271/634 Loss: 0.152695
2023-01-01 09:10: Train Epoch 4: 275/634 Loss: 0.169436
2023-01-01 09:10: Train Epoch 4: 279/634 Loss: 0.161908
2023-01-01 09:10: Train Epoch 4: 283/634 Loss: 0.158930
2023-01-01 09:11: Train Epoch 4: 287/634 Loss: 0.178297
2023-01-01 09:11: Train Epoch 4: 291/634 Loss: 0.169231
2023-01-01 09:11: Train Epoch 4: 295/634 Loss: 0.197478
2023-01-01 09:12: Train Epoch 4: 299/634 Loss: 0.164096
2023-01-01 09:12: Train Epoch 4: 303/634 Loss: 0.176334
2023-01-01 09:13: Train Epoch 4: 307/634 Loss: 0.179495
2023-01-01 09:13: Train Epoch 4: 311/634 Loss: 0.165659
2023-01-01 09:13: Train Epoch 4: 315/634 Loss: 0.197069
2023-01-01 09:14: Train Epoch 4: 319/634 Loss: 0.171295
2023-01-01 09:14: Train Epoch 4: 323/634 Loss: 0.170631
2023-01-01 09:14: Train Epoch 4: 327/634 Loss: 0.164491
2023-01-01 09:15: Train Epoch 4: 331/634 Loss: 0.172707
2023-01-01 09:15: Train Epoch 4: 335/634 Loss: 0.168058
2023-01-01 09:15: Train Epoch 4: 339/634 Loss: 0.160837
2023-01-01 09:16: Train Epoch 4: 343/634 Loss: 0.214380
2023-01-01 09:16: Train Epoch 4: 347/634 Loss: 0.179570
2023-01-01 09:16: Train Epoch 4: 351/634 Loss: 0.156001
2023-01-01 09:17: Train Epoch 4: 355/634 Loss: 0.205789
2023-01-01 09:17: Train Epoch 4: 359/634 Loss: 0.212071
2023-01-01 09:18: Train Epoch 4: 363/634 Loss: 0.198964
2023-01-01 09:18: Train Epoch 4: 367/634 Loss: 0.188185
2023-01-01 09:18: Train Epoch 4: 371/634 Loss: 0.177229
2023-01-01 09:19: Train Epoch 4: 375/634 Loss: 0.154618
2023-01-01 09:19: Train Epoch 4: 379/634 Loss: 0.196273
2023-01-01 09:19: Train Epoch 4: 383/634 Loss: 0.152509
2023-01-01 09:20: Train Epoch 4: 387/634 Loss: 0.142348
2023-01-01 09:20: Train Epoch 4: 391/634 Loss: 0.171005
2023-01-01 09:20: Train Epoch 4: 395/634 Loss: 0.177457
2023-01-01 09:21: Train Epoch 4: 399/634 Loss: 0.167737
2023-01-01 09:21: Train Epoch 4: 403/634 Loss: 0.149728
2023-01-01 09:21: Train Epoch 4: 407/634 Loss: 0.236230
2023-01-01 09:22: Train Epoch 4: 411/634 Loss: 0.175319
2023-01-01 09:22: Train Epoch 4: 415/634 Loss: 0.209128
2023-01-01 09:23: Train Epoch 4: 419/634 Loss: 0.180303
2023-01-01 09:23: Train Epoch 4: 423/634 Loss: 0.185913
2023-01-01 09:23: Train Epoch 4: 427/634 Loss: 0.186089
2023-01-01 09:24: Train Epoch 4: 431/634 Loss: 0.206331
2023-01-01 09:24: Train Epoch 4: 435/634 Loss: 0.141452
2023-01-01 09:24: Train Epoch 4: 439/634 Loss: 0.188748
2023-01-01 09:25: Train Epoch 4: 443/634 Loss: 0.164376
2023-01-01 09:25: Train Epoch 4: 447/634 Loss: 0.196561
2023-01-01 09:25: Train Epoch 4: 451/634 Loss: 0.179008
2023-01-01 09:26: Train Epoch 4: 455/634 Loss: 0.167834
2023-01-01 09:26: Train Epoch 4: 459/634 Loss: 0.175118
2023-01-01 09:26: Train Epoch 4: 463/634 Loss: 0.176466
2023-01-01 09:27: Train Epoch 4: 467/634 Loss: 0.178807
2023-01-01 09:27: Train Epoch 4: 471/634 Loss: 0.185086
2023-01-01 09:27: Train Epoch 4: 475/634 Loss: 0.184356
2023-01-01 09:28: Train Epoch 4: 479/634 Loss: 0.175256
2023-01-01 09:28: Train Epoch 4: 483/634 Loss: 0.170555
2023-01-01 09:29: Train Epoch 4: 487/634 Loss: 0.200973
2023-01-01 09:29: Train Epoch 4: 491/634 Loss: 0.171746
2023-01-01 09:29: Train Epoch 4: 495/634 Loss: 0.203373
2023-01-01 09:30: Train Epoch 4: 499/634 Loss: 0.185327
2023-01-01 09:30: Train Epoch 4: 503/634 Loss: 0.173652
2023-01-01 09:30: Train Epoch 4: 507/634 Loss: 0.224564
2023-01-01 09:31: Train Epoch 4: 511/634 Loss: 0.191181
2023-01-01 09:31: Train Epoch 4: 515/634 Loss: 0.156004
2023-01-01 09:32: Train Epoch 4: 519/634 Loss: 0.165310
2023-01-01 09:32: Train Epoch 4: 523/634 Loss: 0.172019
2023-01-01 09:32: Train Epoch 4: 527/634 Loss: 0.158124
2023-01-01 09:33: Train Epoch 4: 531/634 Loss: 0.179989
2023-01-01 09:33: Train Epoch 4: 535/634 Loss: 0.164257
2023-01-01 09:33: Train Epoch 4: 539/634 Loss: 0.167816
2023-01-01 09:34: Train Epoch 4: 543/634 Loss: 0.178957
2023-01-01 09:34: Train Epoch 4: 547/634 Loss: 0.153821
2023-01-01 09:35: Train Epoch 4: 551/634 Loss: 0.143871
2023-01-01 09:35: Train Epoch 4: 555/634 Loss: 0.185769
2023-01-01 09:35: Train Epoch 4: 559/634 Loss: 0.150210
2023-01-01 09:36: Train Epoch 4: 563/634 Loss: 0.163053
2023-01-01 09:36: Train Epoch 4: 567/634 Loss: 0.144418
2023-01-01 09:36: Train Epoch 4: 571/634 Loss: 0.166209
2023-01-01 09:37: Train Epoch 4: 575/634 Loss: 0.129168
2023-01-01 09:37: Train Epoch 4: 579/634 Loss: 0.156078
2023-01-01 09:38: Train Epoch 4: 583/634 Loss: 0.152640
2023-01-01 09:38: Train Epoch 4: 587/634 Loss: 0.164158
2023-01-01 09:38: Train Epoch 4: 591/634 Loss: 0.170206
2023-01-01 09:39: Train Epoch 4: 595/634 Loss: 0.138015
2023-01-01 09:39: Train Epoch 4: 599/634 Loss: 0.156412
2023-01-01 09:39: Train Epoch 4: 603/634 Loss: 0.167817
2023-01-01 09:40: Train Epoch 4: 607/634 Loss: 0.148274
2023-01-01 09:40: Train Epoch 4: 611/634 Loss: 0.158847
2023-01-01 09:40: Train Epoch 4: 615/634 Loss: 0.158470
2023-01-01 09:41: Train Epoch 4: 619/634 Loss: 0.180904
2023-01-01 09:41: Train Epoch 4: 623/634 Loss: 0.155212
2023-01-01 09:41: Train Epoch 4: 627/634 Loss: 0.172396
2023-01-01 09:42: Train Epoch 4: 631/634 Loss: 0.131765
2023-01-01 09:42: Train Epoch 4: 633/634 Loss: 0.079137
2023-01-01 09:42: **********Train Epoch 4: averaged Loss: 0.173275 
2023-01-01 09:42: 
Epoch time elapsed: 3393.8830213546753

2023-01-01 09:43: 
 metrics validation: {'precision': 0.8214285714285714, 'recall': 0.6723076923076923, 'f1-score': 0.7394247038917089, 'support': 1300, 'AUC': 0.9189674556213017, 'AUCPR': 0.8442930371246051, 'TP': 874, 'FP': 190, 'TN': 2410, 'FN': 426} 

2023-01-01 09:43: **********Val Epoch 4: average Loss: 0.167796
2023-01-01 09:43: *********************************Current best model saved!
2023-01-01 09:45: 
 Testing metrics {'precision': 0.8551165146909828, 'recall': 0.6872964169381107, 'f1-score': 0.762076749435666, 'support': 1228, 'AUC': 0.9221765615550298, 'AUCPR': 0.8732191373473247, 'TP': 844, 'FP': 143, 'TN': 2313, 'FN': 384} 

2023-01-01 09:50: 
 Testing metrics {'precision': 0.9146124523506989, 'recall': 0.8166553210800999, 'f1-score': 0.8628626228722129, 'support': 4407, 'AUC': 0.9729413295441597, 'AUCPR': 0.9489349820992912, 'TP': 3599, 'FP': 336, 'TN': 8478, 'FN': 808} 

2023-01-01 09:50: Train Epoch 5: 3/634 Loss: 0.184844
2023-01-01 09:51: Train Epoch 5: 7/634 Loss: 0.178562
2023-01-01 09:51: Train Epoch 5: 11/634 Loss: 0.183378
2023-01-01 09:51: Train Epoch 5: 15/634 Loss: 0.165074
2023-01-01 09:52: Train Epoch 5: 19/634 Loss: 0.154356
2023-01-01 09:52: Train Epoch 5: 23/634 Loss: 0.184220
2023-01-01 09:52: Train Epoch 5: 27/634 Loss: 0.163485
2023-01-01 09:53: Train Epoch 5: 31/634 Loss: 0.169049
2023-01-01 09:53: Train Epoch 5: 35/634 Loss: 0.144620
2023-01-01 09:53: Train Epoch 5: 39/634 Loss: 0.182051
2023-01-01 09:54: Train Epoch 5: 43/634 Loss: 0.145704
2023-01-01 09:54: Train Epoch 5: 47/634 Loss: 0.164513
2023-01-01 09:55: Train Epoch 5: 51/634 Loss: 0.136995
2023-01-01 09:55: Train Epoch 5: 55/634 Loss: 0.167027
2023-01-01 09:55: Train Epoch 5: 59/634 Loss: 0.144422
2023-01-01 09:56: Train Epoch 5: 63/634 Loss: 0.171057
2023-01-01 09:56: Train Epoch 5: 67/634 Loss: 0.158494
2023-01-01 09:56: Train Epoch 5: 71/634 Loss: 0.166152
2023-01-01 09:57: Train Epoch 5: 75/634 Loss: 0.169535
2023-01-01 09:57: Train Epoch 5: 79/634 Loss: 0.169107
2023-01-01 09:57: Train Epoch 5: 83/634 Loss: 0.176888
2023-01-01 09:58: Train Epoch 5: 87/634 Loss: 0.192138
2023-01-01 09:58: Train Epoch 5: 91/634 Loss: 0.163657
2023-01-01 09:59: Train Epoch 5: 95/634 Loss: 0.179240
2023-01-01 09:59: Train Epoch 5: 99/634 Loss: 0.149609
2023-01-01 09:59: Train Epoch 5: 103/634 Loss: 0.164895
2023-01-01 10:00: Train Epoch 5: 107/634 Loss: 0.197398
2023-01-01 10:00: Train Epoch 5: 111/634 Loss: 0.152016
2023-01-01 10:00: Train Epoch 5: 115/634 Loss: 0.147693
2023-01-01 10:01: Train Epoch 5: 119/634 Loss: 0.163190
2023-01-01 10:01: Train Epoch 5: 123/634 Loss: 0.182633
2023-01-01 10:01: Train Epoch 5: 127/634 Loss: 0.160241
2023-01-01 10:02: Train Epoch 5: 131/634 Loss: 0.179171
2023-01-01 10:02: Train Epoch 5: 135/634 Loss: 0.153502
2023-01-01 10:03: Train Epoch 5: 139/634 Loss: 0.162324
2023-01-01 10:03: Train Epoch 5: 143/634 Loss: 0.157206
2023-01-01 10:03: Train Epoch 5: 147/634 Loss: 0.205879
2023-01-01 10:04: Train Epoch 5: 151/634 Loss: 0.157751
2023-01-01 10:04: Train Epoch 5: 155/634 Loss: 0.179899
2023-01-01 10:04: Train Epoch 5: 159/634 Loss: 0.152968
2023-01-01 10:05: Train Epoch 5: 163/634 Loss: 0.178741
2023-01-01 10:05: Train Epoch 5: 167/634 Loss: 0.152721
2023-01-01 10:05: Train Epoch 5: 171/634 Loss: 0.170542
2023-01-01 10:06: Train Epoch 5: 175/634 Loss: 0.151798
2023-01-01 10:06: Train Epoch 5: 179/634 Loss: 0.161446
2023-01-01 10:07: Train Epoch 5: 183/634 Loss: 0.181588
2023-01-01 10:07: Train Epoch 5: 187/634 Loss: 0.140376
2023-01-01 10:07: Train Epoch 5: 191/634 Loss: 0.182904
2023-01-01 10:08: Train Epoch 5: 195/634 Loss: 0.151845
2023-01-01 10:08: Train Epoch 5: 199/634 Loss: 0.184933
2023-01-01 10:08: Train Epoch 5: 203/634 Loss: 0.145133
2023-01-01 10:09: Train Epoch 5: 207/634 Loss: 0.155072
2023-01-01 10:09: Train Epoch 5: 211/634 Loss: 0.138831
2023-01-01 10:09: Train Epoch 5: 215/634 Loss: 0.154837
2023-01-01 10:10: Train Epoch 5: 219/634 Loss: 0.156098
2023-01-01 10:10: Train Epoch 5: 223/634 Loss: 0.177803
2023-01-01 10:11: Train Epoch 5: 227/634 Loss: 0.175054
2023-01-01 10:11: Train Epoch 5: 231/634 Loss: 0.184109
2023-01-01 10:11: Train Epoch 5: 235/634 Loss: 0.184464
2023-01-01 10:12: Train Epoch 5: 239/634 Loss: 0.148129
2023-01-01 10:12: Train Epoch 5: 243/634 Loss: 0.147277
2023-01-01 10:12: Train Epoch 5: 247/634 Loss: 0.156901
2023-01-01 10:13: Train Epoch 5: 251/634 Loss: 0.171755
2023-01-01 10:13: Train Epoch 5: 255/634 Loss: 0.165725
2023-01-01 10:13: Train Epoch 5: 259/634 Loss: 0.157795
2023-01-01 10:14: Train Epoch 5: 263/634 Loss: 0.152158
2023-01-01 10:14: Train Epoch 5: 267/634 Loss: 0.193188
2023-01-01 10:15: Train Epoch 5: 271/634 Loss: 0.161217
2023-01-01 10:15: Train Epoch 5: 275/634 Loss: 0.166169
2023-01-01 10:15: Train Epoch 5: 279/634 Loss: 0.161733
2023-01-01 10:16: Train Epoch 5: 283/634 Loss: 0.157287
2023-01-01 10:16: Train Epoch 5: 287/634 Loss: 0.135898
2023-01-01 10:16: Train Epoch 5: 291/634 Loss: 0.195417
2023-01-01 10:17: Train Epoch 5: 295/634 Loss: 0.175034
2023-01-01 10:17: Train Epoch 5: 299/634 Loss: 0.173023
2023-01-01 10:17: Train Epoch 5: 303/634 Loss: 0.165171
2023-01-01 10:18: Train Epoch 5: 307/634 Loss: 0.160407
2023-01-01 10:18: Train Epoch 5: 311/634 Loss: 0.177291
2023-01-01 10:18: Train Epoch 5: 315/634 Loss: 0.173076
2023-01-01 10:19: Train Epoch 5: 319/634 Loss: 0.159210
2023-01-01 10:19: Train Epoch 5: 323/634 Loss: 0.171312
2023-01-01 10:19: Train Epoch 5: 327/634 Loss: 0.204153
2023-01-01 10:20: Train Epoch 5: 331/634 Loss: 0.188458
2023-01-01 10:20: Train Epoch 5: 335/634 Loss: 0.167586
2023-01-01 10:20: Train Epoch 5: 339/634 Loss: 0.183770
2023-01-01 10:21: Train Epoch 5: 343/634 Loss: 0.202103
2023-01-01 10:21: Train Epoch 5: 347/634 Loss: 0.189301
2023-01-01 10:22: Train Epoch 5: 351/634 Loss: 0.233481
2023-01-01 10:22: Train Epoch 5: 355/634 Loss: 0.190866
2023-01-01 10:22: Train Epoch 5: 359/634 Loss: 0.171837
2023-01-01 10:23: Train Epoch 5: 363/634 Loss: 0.224609
2023-01-01 10:23: Train Epoch 5: 367/634 Loss: 0.180866
2023-01-01 10:23: Train Epoch 5: 371/634 Loss: 0.174179
2023-01-01 10:24: Train Epoch 5: 375/634 Loss: 0.139973
2023-01-01 10:24: Train Epoch 5: 379/634 Loss: 0.174915
2023-01-01 10:24: Train Epoch 5: 383/634 Loss: 0.167952
2023-01-01 10:25: Train Epoch 5: 387/634 Loss: 0.184967
2023-01-01 10:25: Train Epoch 5: 391/634 Loss: 0.163184
2023-01-01 10:26: Train Epoch 5: 395/634 Loss: 0.171070
2023-01-01 10:26: Train Epoch 5: 399/634 Loss: 0.186793
2023-01-01 10:26: Train Epoch 5: 403/634 Loss: 0.193302
2023-01-01 10:27: Train Epoch 5: 407/634 Loss: 0.160777
2023-01-01 10:27: Train Epoch 5: 411/634 Loss: 0.182051
2023-01-01 10:27: Train Epoch 5: 415/634 Loss: 0.184023
2023-01-01 10:28: Train Epoch 5: 419/634 Loss: 0.186348
2023-01-01 10:28: Train Epoch 5: 423/634 Loss: 0.163881
2023-01-01 10:28: Train Epoch 5: 427/634 Loss: 0.207597
2023-01-01 10:29: Train Epoch 5: 431/634 Loss: 0.150956
2023-01-01 10:29: Train Epoch 5: 435/634 Loss: 0.168432
2023-01-01 10:30: Train Epoch 5: 439/634 Loss: 0.178501
2023-01-01 10:30: Train Epoch 5: 443/634 Loss: 0.176690
2023-01-01 10:30: Train Epoch 5: 447/634 Loss: 0.177524
2023-01-01 10:31: Train Epoch 5: 451/634 Loss: 0.145169
2023-01-01 10:31: Train Epoch 5: 455/634 Loss: 0.168685
2023-01-01 10:31: Train Epoch 5: 459/634 Loss: 0.168019
2023-01-01 10:32: Train Epoch 5: 463/634 Loss: 0.156597
2023-01-01 10:32: Train Epoch 5: 467/634 Loss: 0.163283
2023-01-01 10:32: Train Epoch 5: 471/634 Loss: 0.159866
2023-01-01 10:33: Train Epoch 5: 475/634 Loss: 0.168568
2023-01-01 10:33: Train Epoch 5: 479/634 Loss: 0.153025
2023-01-01 10:33: Train Epoch 5: 483/634 Loss: 0.130513
2023-01-01 10:34: Train Epoch 5: 487/634 Loss: 0.194842
2023-01-01 10:34: Train Epoch 5: 491/634 Loss: 0.154846
2023-01-01 10:35: Train Epoch 5: 495/634 Loss: 0.173168
2023-01-01 10:35: Train Epoch 5: 499/634 Loss: 0.193252
2023-01-01 10:35: Train Epoch 5: 503/634 Loss: 0.167569
2023-01-01 10:36: Train Epoch 5: 507/634 Loss: 0.181213
2023-01-01 10:36: Train Epoch 5: 511/634 Loss: 0.186596
2023-01-01 10:36: Train Epoch 5: 515/634 Loss: 0.178285
2023-01-01 10:37: Train Epoch 5: 519/634 Loss: 0.175239
2023-01-01 10:37: Train Epoch 5: 523/634 Loss: 0.166505
2023-01-01 10:37: Train Epoch 5: 527/634 Loss: 0.177979
2023-01-01 10:38: Train Epoch 5: 531/634 Loss: 0.187847
2023-01-01 10:38: Train Epoch 5: 535/634 Loss: 0.160717
2023-01-01 10:39: Train Epoch 5: 539/634 Loss: 0.178298
2023-01-01 10:39: Train Epoch 5: 543/634 Loss: 0.166821
2023-01-01 10:39: Train Epoch 5: 547/634 Loss: 0.168643
2023-01-01 10:40: Train Epoch 5: 551/634 Loss: 0.164500
2023-01-01 10:40: Train Epoch 5: 555/634 Loss: 0.147789
2023-01-01 10:40: Train Epoch 5: 559/634 Loss: 0.176455
2023-01-01 10:41: Train Epoch 5: 563/634 Loss: 0.150621
2023-01-01 10:41: Train Epoch 5: 567/634 Loss: 0.188139
2023-01-01 10:42: Train Epoch 5: 571/634 Loss: 0.174347
2023-01-01 10:42: Train Epoch 5: 575/634 Loss: 0.177877
2023-01-01 10:42: Train Epoch 5: 579/634 Loss: 0.137708
2023-01-01 10:43: Train Epoch 5: 583/634 Loss: 0.172764
2023-01-01 10:43: Train Epoch 5: 587/634 Loss: 0.156490
2023-01-01 10:43: Train Epoch 5: 591/634 Loss: 0.168556
2023-01-01 10:44: Train Epoch 5: 595/634 Loss: 0.167536
2023-01-01 10:44: Train Epoch 5: 599/634 Loss: 0.161421
2023-01-01 10:44: Train Epoch 5: 603/634 Loss: 0.164122
2023-01-01 10:45: Train Epoch 5: 607/634 Loss: 0.158594
2023-01-01 10:45: Train Epoch 5: 611/634 Loss: 0.151054
2023-01-01 10:45: Train Epoch 5: 615/634 Loss: 0.174132
2023-01-01 10:46: Train Epoch 5: 619/634 Loss: 0.185748
2023-01-01 10:46: Train Epoch 5: 623/634 Loss: 0.158855
2023-01-01 10:47: Train Epoch 5: 627/634 Loss: 0.158286
2023-01-01 10:47: Train Epoch 5: 631/634 Loss: 0.189309
2023-01-01 10:47: Train Epoch 5: 633/634 Loss: 0.068998
2023-01-01 10:47: **********Train Epoch 5: averaged Loss: 0.168826 
2023-01-01 10:47: 
Epoch time elapsed: 3435.7088119983673

2023-01-01 10:49: 
 metrics validation: {'precision': 0.7757980697847068, 'recall': 0.8038461538461539, 'f1-score': 0.7895731016244807, 'support': 1300, 'AUC': 0.9253218934911244, 'AUCPR': 0.8571118670159099, 'TP': 1045, 'FP': 302, 'TN': 2298, 'FN': 255} 

2023-01-01 10:49: **********Val Epoch 5: average Loss: 0.155374
2023-01-01 10:49: *********************************Current best model saved!
2023-01-01 10:50: 
 Testing metrics {'precision': 0.8096856414613424, 'recall': 0.7760586319218241, 'f1-score': 0.7925155925155926, 'support': 1228, 'AUC': 0.9260224246411103, 'AUCPR': 0.8814196290905293, 'TP': 953, 'FP': 224, 'TN': 2232, 'FN': 275} 

2023-01-01 10:55: 
 Testing metrics {'precision': 0.8662952646239555, 'recall': 0.8468345813478557, 'f1-score': 0.8564543889845095, 'support': 4407, 'AUC': 0.9690275655790093, 'AUCPR': 0.9429331310281731, 'TP': 3732, 'FP': 576, 'TN': 8238, 'FN': 675} 

2023-01-01 10:56: Train Epoch 6: 3/634 Loss: 0.155348
2023-01-01 10:56: Train Epoch 6: 7/634 Loss: 0.136986
2023-01-01 10:56: Train Epoch 6: 11/634 Loss: 0.155503
2023-01-01 10:57: Train Epoch 6: 15/634 Loss: 0.157878
2023-01-01 10:57: Train Epoch 6: 19/634 Loss: 0.152822
2023-01-01 10:57: Train Epoch 6: 23/634 Loss: 0.204052
2023-01-01 10:58: Train Epoch 6: 27/634 Loss: 0.137556
2023-01-01 10:58: Train Epoch 6: 31/634 Loss: 0.151191
2023-01-01 10:59: Train Epoch 6: 35/634 Loss: 0.185486
2023-01-01 10:59: Train Epoch 6: 39/634 Loss: 0.167890
2023-01-01 10:59: Train Epoch 6: 43/634 Loss: 0.176565
2023-01-01 11:00: Train Epoch 6: 47/634 Loss: 0.182113
2023-01-01 11:00: Train Epoch 6: 51/634 Loss: 0.176475
2023-01-01 11:00: Train Epoch 6: 55/634 Loss: 0.166880
2023-01-01 11:01: Train Epoch 6: 59/634 Loss: 0.173472
2023-01-01 11:01: Train Epoch 6: 63/634 Loss: 0.156187
2023-01-01 11:02: Train Epoch 6: 67/634 Loss: 0.170317
2023-01-01 11:02: Train Epoch 6: 71/634 Loss: 0.142186
2023-01-01 11:02: Train Epoch 6: 75/634 Loss: 0.156886
2023-01-01 11:03: Train Epoch 6: 79/634 Loss: 0.158077
2023-01-01 11:03: Train Epoch 6: 83/634 Loss: 0.178332
2023-01-01 11:03: Train Epoch 6: 87/634 Loss: 0.156039
2023-01-01 11:04: Train Epoch 6: 91/634 Loss: 0.140706
2023-01-01 11:04: Train Epoch 6: 95/634 Loss: 0.182612
2023-01-01 11:05: Train Epoch 6: 99/634 Loss: 0.176564
2023-01-01 11:05: Train Epoch 6: 103/634 Loss: 0.165824
2023-01-01 11:05: Train Epoch 6: 107/634 Loss: 0.183412
2023-01-01 11:06: Train Epoch 6: 111/634 Loss: 0.206546
2023-01-01 11:06: Train Epoch 6: 115/634 Loss: 0.155727
2023-01-01 11:06: Train Epoch 6: 119/634 Loss: 0.162476
2023-01-01 11:07: Train Epoch 6: 123/634 Loss: 0.180781
2023-01-01 11:07: Train Epoch 6: 127/634 Loss: 0.139313
2023-01-01 11:07: Train Epoch 6: 131/634 Loss: 0.156313
2023-01-01 11:08: Train Epoch 6: 135/634 Loss: 0.140205
2023-01-01 11:08: Train Epoch 6: 139/634 Loss: 0.179098
2023-01-01 11:09: Train Epoch 6: 143/634 Loss: 0.144559
2023-01-01 11:09: Train Epoch 6: 147/634 Loss: 0.142292
2023-01-01 11:09: Train Epoch 6: 151/634 Loss: 0.161595
2023-01-01 11:10: Train Epoch 6: 155/634 Loss: 0.166043
2023-01-01 11:10: Train Epoch 6: 159/634 Loss: 0.145005
2023-01-01 11:10: Train Epoch 6: 163/634 Loss: 0.154230
2023-01-01 11:11: Train Epoch 6: 167/634 Loss: 0.153587
2023-01-01 11:11: Train Epoch 6: 171/634 Loss: 0.155661
2023-01-01 11:11: Train Epoch 6: 175/634 Loss: 0.183936
2023-01-01 11:12: Train Epoch 6: 179/634 Loss: 0.175561
2023-01-01 11:12: Train Epoch 6: 183/634 Loss: 0.169643
2023-01-01 11:12: Train Epoch 6: 187/634 Loss: 0.160453
2023-01-01 11:13: Train Epoch 6: 191/634 Loss: 0.164868
2023-01-01 11:13: Train Epoch 6: 195/634 Loss: 0.156301
2023-01-01 11:14: Train Epoch 6: 199/634 Loss: 0.161987
2023-01-01 11:14: Train Epoch 6: 203/634 Loss: 0.177703
2023-01-01 11:14: Train Epoch 6: 207/634 Loss: 0.170124
2023-01-01 11:15: Train Epoch 6: 211/634 Loss: 0.159464
2023-01-01 11:15: Train Epoch 6: 215/634 Loss: 0.159622
2023-01-01 11:15: Train Epoch 6: 219/634 Loss: 0.144207
2023-01-01 11:16: Train Epoch 6: 223/634 Loss: 0.129745
2023-01-01 11:16: Train Epoch 6: 227/634 Loss: 0.186933
2023-01-01 11:16: Train Epoch 6: 231/634 Loss: 0.175017
2023-01-01 11:17: Train Epoch 6: 235/634 Loss: 0.149980
2023-01-01 11:17: Train Epoch 6: 239/634 Loss: 0.174712
2023-01-01 11:17: Train Epoch 6: 243/634 Loss: 0.161721
2023-01-01 11:18: Train Epoch 6: 247/634 Loss: 0.188454
2023-01-01 11:18: Train Epoch 6: 251/634 Loss: 0.164247
2023-01-01 11:18: Train Epoch 6: 255/634 Loss: 0.188746
2023-01-01 11:19: Train Epoch 6: 259/634 Loss: 0.159778
2023-01-01 11:19: Train Epoch 6: 263/634 Loss: 0.154378
2023-01-01 11:19: Train Epoch 6: 267/634 Loss: 0.196268
2023-01-01 11:20: Train Epoch 6: 271/634 Loss: 0.167046
2023-01-01 11:20: Train Epoch 6: 275/634 Loss: 0.177326
2023-01-01 11:20: Train Epoch 6: 279/634 Loss: 0.184888
2023-01-01 11:21: Train Epoch 6: 283/634 Loss: 0.144850
2023-01-01 11:21: Train Epoch 6: 287/634 Loss: 0.170004
2023-01-01 11:21: Train Epoch 6: 291/634 Loss: 0.181334
2023-01-01 11:22: Train Epoch 6: 295/634 Loss: 0.178513
2023-01-01 11:22: Train Epoch 6: 299/634 Loss: 0.129910
2023-01-01 11:22: Train Epoch 6: 303/634 Loss: 0.145619
2023-01-01 11:23: Train Epoch 6: 307/634 Loss: 0.173333
2023-01-01 11:23: Train Epoch 6: 311/634 Loss: 0.166364
2023-01-01 11:23: Train Epoch 6: 315/634 Loss: 0.149311
2023-01-01 11:24: Train Epoch 6: 319/634 Loss: 0.143449
2023-01-01 11:24: Train Epoch 6: 323/634 Loss: 0.167747
2023-01-01 11:25: Train Epoch 6: 327/634 Loss: 0.152887
2023-01-01 11:25: Train Epoch 6: 331/634 Loss: 0.175873
2023-01-01 11:25: Train Epoch 6: 335/634 Loss: 0.146779
2023-01-01 11:26: Train Epoch 6: 339/634 Loss: 0.174324
2023-01-01 11:26: Train Epoch 6: 343/634 Loss: 0.153287
2023-01-01 11:26: Train Epoch 6: 347/634 Loss: 0.134350
2023-01-01 11:27: Train Epoch 6: 351/634 Loss: 0.183264
2023-01-01 11:27: Train Epoch 6: 355/634 Loss: 0.160672
2023-01-01 11:27: Train Epoch 6: 359/634 Loss: 0.157145
2023-01-01 11:28: Train Epoch 6: 363/634 Loss: 0.174234
2023-01-01 11:28: Train Epoch 6: 367/634 Loss: 0.159475
2023-01-01 11:28: Train Epoch 6: 371/634 Loss: 0.157972
2023-01-01 11:29: Train Epoch 6: 375/634 Loss: 0.168282
2023-01-01 11:29: Train Epoch 6: 379/634 Loss: 0.181176
2023-01-01 11:29: Train Epoch 6: 383/634 Loss: 0.148284
2023-01-01 11:30: Train Epoch 6: 387/634 Loss: 0.177099
2023-01-01 11:30: Train Epoch 6: 391/634 Loss: 0.149746
2023-01-01 11:30: Train Epoch 6: 395/634 Loss: 0.159171
2023-01-01 11:31: Train Epoch 6: 399/634 Loss: 0.135424
2023-01-01 11:31: Train Epoch 6: 403/634 Loss: 0.160460
2023-01-01 11:32: Train Epoch 6: 407/634 Loss: 0.184807
2023-01-01 11:32: Train Epoch 6: 411/634 Loss: 0.151001
2023-01-01 11:32: Train Epoch 6: 415/634 Loss: 0.157030
2023-01-01 11:33: Train Epoch 6: 419/634 Loss: 0.157524
2023-01-01 11:33: Train Epoch 6: 423/634 Loss: 0.150904
2023-01-01 11:33: Train Epoch 6: 427/634 Loss: 0.136576
2023-01-01 11:34: Train Epoch 6: 431/634 Loss: 0.141642
2023-01-01 11:34: Train Epoch 6: 435/634 Loss: 0.175194
2023-01-01 11:34: Train Epoch 6: 439/634 Loss: 0.154720
2023-01-01 11:35: Train Epoch 6: 443/634 Loss: 0.141776
2023-01-01 11:35: Train Epoch 6: 447/634 Loss: 0.113637
2023-01-01 11:35: Train Epoch 6: 451/634 Loss: 0.139691
2023-01-01 11:36: Train Epoch 6: 455/634 Loss: 0.143289
2023-01-01 11:36: Train Epoch 6: 459/634 Loss: 0.130629
2023-01-01 11:36: Train Epoch 6: 463/634 Loss: 0.168350
2023-01-01 11:37: Train Epoch 6: 467/634 Loss: 0.138459
2023-01-01 11:37: Train Epoch 6: 471/634 Loss: 0.180705
2023-01-01 11:37: Train Epoch 6: 475/634 Loss: 0.156990
2023-01-01 11:38: Train Epoch 6: 479/634 Loss: 0.140222
2023-01-01 11:38: Train Epoch 6: 483/634 Loss: 0.193854
2023-01-01 11:38: Train Epoch 6: 487/634 Loss: 0.156316
2023-01-01 11:39: Train Epoch 6: 491/634 Loss: 0.167672
2023-01-01 11:39: Train Epoch 6: 495/634 Loss: 0.146199
2023-01-01 11:40: Train Epoch 6: 499/634 Loss: 0.191274
2023-01-01 11:40: Train Epoch 6: 503/634 Loss: 0.144992
2023-01-01 11:40: Train Epoch 6: 507/634 Loss: 0.184200
2023-01-01 11:41: Train Epoch 6: 511/634 Loss: 0.183119
2023-01-01 11:41: Train Epoch 6: 515/634 Loss: 0.183357
2023-01-01 11:41: Train Epoch 6: 519/634 Loss: 0.163669
2023-01-01 11:42: Train Epoch 6: 523/634 Loss: 0.153408
2023-01-01 11:42: Train Epoch 6: 527/634 Loss: 0.152620
2023-01-01 11:42: Train Epoch 6: 531/634 Loss: 0.168192
2023-01-01 11:43: Train Epoch 6: 535/634 Loss: 0.132917
2023-01-01 11:43: Train Epoch 6: 539/634 Loss: 0.149028
2023-01-01 11:44: Train Epoch 6: 543/634 Loss: 0.151923
2023-01-01 11:44: Train Epoch 6: 547/634 Loss: 0.159157
2023-01-01 11:44: Train Epoch 6: 551/634 Loss: 0.169959
2023-01-01 11:45: Train Epoch 6: 555/634 Loss: 0.163068
2023-01-01 11:45: Train Epoch 6: 559/634 Loss: 0.163939
2023-01-01 11:45: Train Epoch 6: 563/634 Loss: 0.170785
2023-01-01 11:46: Train Epoch 6: 567/634 Loss: 0.156748
2023-01-01 11:46: Train Epoch 6: 571/634 Loss: 0.166923
2023-01-01 11:46: Train Epoch 6: 575/634 Loss: 0.148127
2023-01-01 11:47: Train Epoch 6: 579/634 Loss: 0.174675
2023-01-01 11:47: Train Epoch 6: 583/634 Loss: 0.169601
2023-01-01 11:48: Train Epoch 6: 587/634 Loss: 0.154471
2023-01-01 11:48: Train Epoch 6: 591/634 Loss: 0.151546
2023-01-01 11:48: Train Epoch 6: 595/634 Loss: 0.155195
2023-01-01 11:49: Train Epoch 6: 599/634 Loss: 0.146141
2023-01-01 11:49: Train Epoch 6: 603/634 Loss: 0.179890
2023-01-01 11:49: Train Epoch 6: 607/634 Loss: 0.169315
2023-01-01 11:50: Train Epoch 6: 611/634 Loss: 0.170897
2023-01-01 11:50: Train Epoch 6: 615/634 Loss: 0.158920
2023-01-01 11:50: Train Epoch 6: 619/634 Loss: 0.158624
2023-01-01 11:51: Train Epoch 6: 623/634 Loss: 0.132201
2023-01-01 11:51: Train Epoch 6: 627/634 Loss: 0.155413
2023-01-01 11:51: Train Epoch 6: 631/634 Loss: 0.135763
2023-01-01 11:51: Train Epoch 6: 633/634 Loss: 0.058539
2023-01-01 11:51: **********Train Epoch 6: averaged Loss: 0.160692 
2023-01-01 11:51: 
Epoch time elapsed: 3377.7520711421967

2023-01-01 11:53: 
 metrics validation: {'precision': 0.764026402640264, 'recall': 0.7123076923076923, 'f1-score': 0.7372611464968154, 'support': 1300, 'AUC': 0.9039405325443787, 'AUCPR': 0.8285127010696234, 'TP': 926, 'FP': 286, 'TN': 2314, 'FN': 374} 

2023-01-01 11:53: **********Val Epoch 6: average Loss: 0.179707
2023-01-01 11:54: 
 Testing metrics {'precision': 0.8096856414613424, 'recall': 0.7760586319218241, 'f1-score': 0.7925155925155926, 'support': 1228, 'AUC': 0.9260224246411103, 'AUCPR': 0.8814196290905293, 'TP': 953, 'FP': 224, 'TN': 2232, 'FN': 275} 

2023-01-01 12:00: 
 Testing metrics {'precision': 0.8662952646239555, 'recall': 0.8468345813478557, 'f1-score': 0.8564543889845095, 'support': 4407, 'AUC': 0.9690275655790093, 'AUCPR': 0.9429331310281731, 'TP': 3732, 'FP': 576, 'TN': 8238, 'FN': 675} 

2023-01-01 12:00: Train Epoch 7: 3/634 Loss: 0.180090
2023-01-01 12:01: Train Epoch 7: 7/634 Loss: 0.175532
2023-01-01 12:01: Train Epoch 7: 11/634 Loss: 0.156817
2023-01-01 12:01: Train Epoch 7: 15/634 Loss: 0.162147
2023-01-01 12:02: Train Epoch 7: 19/634 Loss: 0.191427
2023-01-01 12:02: Train Epoch 7: 23/634 Loss: 0.158839
2023-01-01 12:02: Train Epoch 7: 27/634 Loss: 0.185629
2023-01-01 12:03: Train Epoch 7: 31/634 Loss: 0.168936
2023-01-01 12:03: Train Epoch 7: 35/634 Loss: 0.144019
2023-01-01 12:03: Train Epoch 7: 39/634 Loss: 0.171800
2023-01-01 12:04: Train Epoch 7: 43/634 Loss: 0.131644
2023-01-01 12:04: Train Epoch 7: 47/634 Loss: 0.189629
2023-01-01 12:05: Train Epoch 7: 51/634 Loss: 0.155677
2023-01-01 12:05: Train Epoch 7: 55/634 Loss: 0.166410
2023-01-01 12:05: Train Epoch 7: 59/634 Loss: 0.194913
2023-01-01 12:06: Train Epoch 7: 63/634 Loss: 0.157643
2023-01-01 12:06: Train Epoch 7: 67/634 Loss: 0.141789
2023-01-01 12:06: Train Epoch 7: 71/634 Loss: 0.171925
2023-01-01 12:07: Train Epoch 7: 75/634 Loss: 0.144473
2023-01-01 12:07: Train Epoch 7: 79/634 Loss: 0.165416
2023-01-01 12:07: Train Epoch 7: 83/634 Loss: 0.165574
2023-01-01 12:08: Train Epoch 7: 87/634 Loss: 0.158781
2023-01-01 12:08: Train Epoch 7: 91/634 Loss: 0.149785
2023-01-01 12:08: Train Epoch 7: 95/634 Loss: 0.148778
2023-01-01 12:09: Train Epoch 7: 99/634 Loss: 0.147637
2023-01-01 12:09: Train Epoch 7: 103/634 Loss: 0.179623
2023-01-01 12:10: Train Epoch 7: 107/634 Loss: 0.153521
2023-01-01 12:10: Train Epoch 7: 111/634 Loss: 0.130532
2023-01-01 12:10: Train Epoch 7: 115/634 Loss: 0.175518
2023-01-01 12:11: Train Epoch 7: 119/634 Loss: 0.120874
2023-01-01 12:11: Train Epoch 7: 123/634 Loss: 0.186018
2023-01-01 12:11: Train Epoch 7: 127/634 Loss: 0.160200
2023-01-01 12:12: Train Epoch 7: 131/634 Loss: 0.160100
2023-01-01 12:12: Train Epoch 7: 135/634 Loss: 0.157569
2023-01-01 12:12: Train Epoch 7: 139/634 Loss: 0.160938
2023-01-01 12:13: Train Epoch 7: 143/634 Loss: 0.175740
2023-01-01 12:13: Train Epoch 7: 147/634 Loss: 0.148496
2023-01-01 12:14: Train Epoch 7: 151/634 Loss: 0.145795
2023-01-01 12:14: Train Epoch 7: 155/634 Loss: 0.167183
2023-01-01 12:14: Train Epoch 7: 159/634 Loss: 0.174050
2023-01-01 12:15: Train Epoch 7: 163/634 Loss: 0.152401
2023-01-01 12:15: Train Epoch 7: 167/634 Loss: 0.172122
2023-01-01 12:15: Train Epoch 7: 171/634 Loss: 0.130222
2023-01-01 12:16: Train Epoch 7: 175/634 Loss: 0.149928
2023-01-01 12:16: Train Epoch 7: 179/634 Loss: 0.158098
2023-01-01 12:16: Train Epoch 7: 183/634 Loss: 0.160404
2023-01-01 12:17: Train Epoch 7: 187/634 Loss: 0.152683
2023-01-01 12:17: Train Epoch 7: 191/634 Loss: 0.183594
2023-01-01 12:18: Train Epoch 7: 195/634 Loss: 0.142101
2023-01-01 12:18: Train Epoch 7: 199/634 Loss: 0.158045
2023-01-01 12:18: Train Epoch 7: 203/634 Loss: 0.148330
2023-01-01 12:19: Train Epoch 7: 207/634 Loss: 0.167983
2023-01-01 12:19: Train Epoch 7: 211/634 Loss: 0.142030
2023-01-01 12:19: Train Epoch 7: 215/634 Loss: 0.148106
2023-01-01 12:20: Train Epoch 7: 219/634 Loss: 0.162113
2023-01-01 12:20: Train Epoch 7: 223/634 Loss: 0.189180
2023-01-01 12:20: Train Epoch 7: 227/634 Loss: 0.148257
2023-01-01 12:21: Train Epoch 7: 231/634 Loss: 0.132490
2023-01-01 12:21: Train Epoch 7: 235/634 Loss: 0.153105
2023-01-01 12:21: Train Epoch 7: 239/634 Loss: 0.174185
2023-01-01 12:22: Train Epoch 7: 243/634 Loss: 0.164752
2023-01-01 12:22: Train Epoch 7: 247/634 Loss: 0.157740
2023-01-01 12:23: Train Epoch 7: 251/634 Loss: 0.201674
2023-01-01 12:23: Train Epoch 7: 255/634 Loss: 0.153598
2023-01-01 12:23: Train Epoch 7: 259/634 Loss: 0.183937
2023-01-01 12:24: Train Epoch 7: 263/634 Loss: 0.135216
2023-01-01 12:24: Train Epoch 7: 267/634 Loss: 0.206359
2023-01-01 12:24: Train Epoch 7: 271/634 Loss: 0.152225
2023-01-01 12:25: Train Epoch 7: 275/634 Loss: 0.200590
2023-01-01 12:25: Train Epoch 7: 279/634 Loss: 0.187398
2023-01-01 12:26: Train Epoch 7: 283/634 Loss: 0.154366
2023-01-01 12:26: Train Epoch 7: 287/634 Loss: 0.152512
2023-01-01 12:26: Train Epoch 7: 291/634 Loss: 0.170795
2023-01-01 12:27: Train Epoch 7: 295/634 Loss: 0.158618
2023-01-01 12:27: Train Epoch 7: 299/634 Loss: 0.186515
2023-01-01 12:27: Train Epoch 7: 303/634 Loss: 0.177464
2023-01-01 12:28: Train Epoch 7: 307/634 Loss: 0.161877
2023-01-01 12:28: Train Epoch 7: 311/634 Loss: 0.169851
2023-01-01 12:29: Train Epoch 7: 315/634 Loss: 0.161995
2023-01-01 12:29: Train Epoch 7: 319/634 Loss: 0.176166
2023-01-01 12:29: Train Epoch 7: 323/634 Loss: 0.156698
2023-01-01 12:30: Train Epoch 7: 327/634 Loss: 0.140370
2023-01-01 12:30: Train Epoch 7: 331/634 Loss: 0.135587
2023-01-01 12:30: Train Epoch 7: 335/634 Loss: 0.175574
2023-01-01 12:31: Train Epoch 7: 339/634 Loss: 0.163230
2023-01-01 12:31: Train Epoch 7: 343/634 Loss: 0.186559
2023-01-01 12:32: Train Epoch 7: 347/634 Loss: 0.165546
2023-01-01 12:32: Train Epoch 7: 351/634 Loss: 0.164463
2023-01-01 12:32: Train Epoch 7: 355/634 Loss: 0.184010
2023-01-01 12:33: Train Epoch 7: 359/634 Loss: 0.177477
2023-01-01 12:33: Train Epoch 7: 363/634 Loss: 0.167948
2023-01-01 12:33: Train Epoch 7: 367/634 Loss: 0.177158
2023-01-01 12:34: Train Epoch 7: 371/634 Loss: 0.156209
2023-01-01 12:34: Train Epoch 7: 375/634 Loss: 0.159576
2023-01-01 12:34: Train Epoch 7: 379/634 Loss: 0.194840
2023-01-01 12:35: Train Epoch 7: 383/634 Loss: 0.160196
2023-01-01 12:35: Train Epoch 7: 387/634 Loss: 0.224619
2023-01-01 12:35: Train Epoch 7: 391/634 Loss: 0.170413
2023-01-01 12:36: Train Epoch 7: 395/634 Loss: 0.163814
2023-01-01 12:36: Train Epoch 7: 399/634 Loss: 0.175132
2023-01-01 12:37: Train Epoch 7: 403/634 Loss: 0.187318
2023-01-01 12:37: Train Epoch 7: 407/634 Loss: 0.154274
2023-01-01 12:37: Train Epoch 7: 411/634 Loss: 0.166372
2023-01-01 12:38: Train Epoch 7: 415/634 Loss: 0.204633
2023-01-01 12:38: Train Epoch 7: 419/634 Loss: 0.154067
2023-01-01 12:38: Train Epoch 7: 423/634 Loss: 0.142395
2023-01-01 12:39: Train Epoch 7: 427/634 Loss: 0.203778
2023-01-01 12:39: Train Epoch 7: 431/634 Loss: 0.197164
2023-01-01 12:39: Train Epoch 7: 435/634 Loss: 0.163251
2023-01-01 12:40: Train Epoch 7: 439/634 Loss: 0.191437
2023-01-01 12:40: Train Epoch 7: 443/634 Loss: 0.132510
2023-01-01 12:40: Train Epoch 7: 447/634 Loss: 0.166644
2023-01-01 12:41: Train Epoch 7: 451/634 Loss: 0.172400
2023-01-01 12:41: Train Epoch 7: 455/634 Loss: 0.173739
2023-01-01 12:42: Train Epoch 7: 459/634 Loss: 0.144178
2023-01-01 12:42: Train Epoch 7: 463/634 Loss: 0.148020
2023-01-01 12:42: Train Epoch 7: 467/634 Loss: 0.176899
2023-01-01 12:43: Train Epoch 7: 471/634 Loss: 0.159603
2023-01-01 12:43: Train Epoch 7: 475/634 Loss: 0.155322
2023-01-01 12:43: Train Epoch 7: 479/634 Loss: 0.169311
2023-01-01 12:44: Train Epoch 7: 483/634 Loss: 0.133072
2023-01-01 12:44: Train Epoch 7: 487/634 Loss: 0.162300
2023-01-01 12:44: Train Epoch 7: 491/634 Loss: 0.137466
2023-01-01 12:45: Train Epoch 7: 495/634 Loss: 0.163180
2023-01-01 12:45: Train Epoch 7: 499/634 Loss: 0.140973
2023-01-01 12:46: Train Epoch 7: 503/634 Loss: 0.160920
2023-01-01 12:46: Train Epoch 7: 507/634 Loss: 0.161619
2023-01-01 12:46: Train Epoch 7: 511/634 Loss: 0.172322
2023-01-01 12:47: Train Epoch 7: 515/634 Loss: 0.127039
2023-01-01 12:47: Train Epoch 7: 519/634 Loss: 0.136393
2023-01-01 12:47: Train Epoch 7: 523/634 Loss: 0.130775
2023-01-01 12:48: Train Epoch 7: 527/634 Loss: 0.151583
2023-01-01 12:48: Train Epoch 7: 531/634 Loss: 0.140256
2023-01-01 12:48: Train Epoch 7: 535/634 Loss: 0.181581
2023-01-01 12:49: Train Epoch 7: 539/634 Loss: 0.163773
2023-01-01 12:49: Train Epoch 7: 543/634 Loss: 0.139005
2023-01-01 12:50: Train Epoch 7: 547/634 Loss: 0.156439
2023-01-01 12:50: Train Epoch 7: 551/634 Loss: 0.153319
2023-01-01 12:50: Train Epoch 7: 555/634 Loss: 0.158691
2023-01-01 12:51: Train Epoch 7: 559/634 Loss: 0.176613
2023-01-01 12:51: Train Epoch 7: 563/634 Loss: 0.191148
2023-01-01 12:51: Train Epoch 7: 567/634 Loss: 0.142801
2023-01-01 12:52: Train Epoch 7: 571/634 Loss: 0.144292
2023-01-01 12:52: Train Epoch 7: 575/634 Loss: 0.154774
2023-01-01 12:53: Train Epoch 7: 579/634 Loss: 0.177032
2023-01-01 12:53: Train Epoch 7: 583/634 Loss: 0.148637
2023-01-01 12:53: Train Epoch 7: 587/634 Loss: 0.139583
2023-01-01 12:54: Train Epoch 7: 591/634 Loss: 0.140864
2023-01-01 12:54: Train Epoch 7: 595/634 Loss: 0.169981
2023-01-01 12:54: Train Epoch 7: 599/634 Loss: 0.141217
2023-01-01 12:55: Train Epoch 7: 603/634 Loss: 0.152856
2023-01-01 12:55: Train Epoch 7: 607/634 Loss: 0.167191
2023-01-01 12:55: Train Epoch 7: 611/634 Loss: 0.137867
2023-01-01 12:56: Train Epoch 7: 615/634 Loss: 0.146853
2023-01-01 12:56: Train Epoch 7: 619/634 Loss: 0.150281
2023-01-01 12:56: Train Epoch 7: 623/634 Loss: 0.154661
2023-01-01 12:57: Train Epoch 7: 627/634 Loss: 0.176447
2023-01-01 12:57: Train Epoch 7: 631/634 Loss: 0.158057
2023-01-01 12:57: Train Epoch 7: 633/634 Loss: 0.060602
2023-01-01 12:57: **********Train Epoch 7: averaged Loss: 0.161545 
2023-01-01 12:57: 
Epoch time elapsed: 3449.868748188019

2023-01-01 12:59: 
 metrics validation: {'precision': 0.872057318321392, 'recall': 0.6553846153846153, 'f1-score': 0.7483530961791832, 'support': 1300, 'AUC': 0.9315381656804733, 'AUCPR': 0.8710217758680376, 'TP': 852, 'FP': 125, 'TN': 2475, 'FN': 448} 

2023-01-01 12:59: **********Val Epoch 7: average Loss: 0.159079
2023-01-01 13:00: 
 Testing metrics {'precision': 0.8096856414613424, 'recall': 0.7760586319218241, 'f1-score': 0.7925155925155926, 'support': 1228, 'AUC': 0.9260224246411103, 'AUCPR': 0.8814196290905293, 'TP': 953, 'FP': 224, 'TN': 2232, 'FN': 275} 

2023-01-01 13:05: 
 Testing metrics {'precision': 0.8662952646239555, 'recall': 0.8468345813478557, 'f1-score': 0.8564543889845095, 'support': 4407, 'AUC': 0.9690275655790093, 'AUCPR': 0.9429331310281731, 'TP': 3732, 'FP': 576, 'TN': 8238, 'FN': 675} 

2023-01-01 13:05: Train Epoch 8: 3/634 Loss: 0.181826
2023-01-01 13:06: Train Epoch 8: 7/634 Loss: 0.150892
2023-01-01 13:06: Train Epoch 8: 11/634 Loss: 0.179407
2023-01-01 13:07: Train Epoch 8: 15/634 Loss: 0.172478
2023-01-01 13:07: Train Epoch 8: 19/634 Loss: 0.152375
2023-01-01 13:07: Train Epoch 8: 23/634 Loss: 0.192482
2023-01-01 13:08: Train Epoch 8: 27/634 Loss: 0.161639
2023-01-01 13:08: Train Epoch 8: 31/634 Loss: 0.179787
2023-01-01 13:08: Train Epoch 8: 35/634 Loss: 0.203614
2023-01-01 13:09: Train Epoch 8: 39/634 Loss: 0.140778
2023-01-01 13:09: Train Epoch 8: 43/634 Loss: 0.163688
2023-01-01 13:09: Train Epoch 8: 47/634 Loss: 0.144502
2023-01-01 13:10: Train Epoch 8: 51/634 Loss: 0.189245
2023-01-01 13:10: Train Epoch 8: 55/634 Loss: 0.132769
2023-01-01 13:10: Train Epoch 8: 59/634 Loss: 0.143443
2023-01-01 13:11: Train Epoch 8: 63/634 Loss: 0.168744
2023-01-01 13:11: Train Epoch 8: 67/634 Loss: 0.139941
2023-01-01 13:12: Train Epoch 8: 71/634 Loss: 0.152657
2023-01-01 13:12: Train Epoch 8: 75/634 Loss: 0.158965
2023-01-01 13:12: Train Epoch 8: 79/634 Loss: 0.165302
2023-01-01 13:13: Train Epoch 8: 83/634 Loss: 0.161152
2023-01-01 13:13: Train Epoch 8: 87/634 Loss: 0.157402
2023-01-01 13:13: Train Epoch 8: 91/634 Loss: 0.209859
2023-01-01 13:14: Train Epoch 8: 95/634 Loss: 0.191580
2023-01-01 13:14: Train Epoch 8: 99/634 Loss: 0.177728
2023-01-01 13:14: Train Epoch 8: 103/634 Loss: 0.193525
2023-01-01 13:15: Train Epoch 8: 107/634 Loss: 0.147065
2023-01-01 13:15: Train Epoch 8: 111/634 Loss: 0.192412
2023-01-01 13:15: Train Epoch 8: 115/634 Loss: 0.200822
2023-01-01 13:16: Train Epoch 8: 119/634 Loss: 0.146355
2023-01-01 13:16: Train Epoch 8: 123/634 Loss: 0.155323
2023-01-01 13:17: Train Epoch 8: 127/634 Loss: 0.208712
2023-01-01 13:17: Train Epoch 8: 131/634 Loss: 0.175864
2023-01-01 13:17: Train Epoch 8: 135/634 Loss: 0.166046
2023-01-01 13:17: Train Epoch 8: 139/634 Loss: 0.221096
2023-01-01 13:18: Train Epoch 8: 143/634 Loss: 0.197027
2023-01-01 13:18: Train Epoch 8: 147/634 Loss: 0.153375
2023-01-01 13:19: Train Epoch 8: 151/634 Loss: 0.193091
2023-01-01 13:19: Train Epoch 8: 155/634 Loss: 0.218468
2023-01-01 13:19: Train Epoch 8: 159/634 Loss: 0.191940
2023-01-01 13:20: Train Epoch 8: 163/634 Loss: 0.187059
2023-01-01 13:20: Train Epoch 8: 167/634 Loss: 0.286734
2023-01-01 13:20: Train Epoch 8: 171/634 Loss: 0.151633
2023-01-01 13:21: Train Epoch 8: 175/634 Loss: 0.148873
2023-01-01 13:21: Train Epoch 8: 179/634 Loss: 0.172550
2023-01-01 13:22: Train Epoch 8: 183/634 Loss: 0.236427
2023-01-01 13:22: Train Epoch 8: 187/634 Loss: 0.183256
2023-01-01 13:22: Train Epoch 8: 191/634 Loss: 0.183704
2023-01-01 13:23: Train Epoch 8: 195/634 Loss: 0.197938
2023-01-01 13:23: Train Epoch 8: 199/634 Loss: 0.203022
2023-01-01 13:23: Train Epoch 8: 203/634 Loss: 0.157670
2023-01-01 13:24: Train Epoch 8: 207/634 Loss: 0.243021
2023-01-01 13:24: Train Epoch 8: 211/634 Loss: 0.253871
2023-01-01 13:24: Train Epoch 8: 215/634 Loss: 0.184442
2023-01-01 13:25: Train Epoch 8: 219/634 Loss: 0.219032
2023-01-01 13:25: Train Epoch 8: 223/634 Loss: 0.233629
2023-01-01 13:26: Train Epoch 8: 227/634 Loss: 0.168938
2023-01-01 13:26: Train Epoch 8: 231/634 Loss: 0.169986
2023-01-01 13:26: Train Epoch 8: 235/634 Loss: 0.175103
2023-01-01 13:27: Train Epoch 8: 239/634 Loss: 0.184116
2023-01-01 13:27: Train Epoch 8: 243/634 Loss: 0.173787
2023-01-01 13:27: Train Epoch 8: 247/634 Loss: 0.188286
2023-01-01 13:28: Train Epoch 8: 251/634 Loss: 0.176218
2023-01-01 13:28: Train Epoch 8: 255/634 Loss: 0.185583
2023-01-01 13:28: Train Epoch 8: 259/634 Loss: 0.180656
2023-01-01 13:29: Train Epoch 8: 263/634 Loss: 0.178103
2023-01-01 13:29: Train Epoch 8: 267/634 Loss: 0.134679
2023-01-01 13:30: Train Epoch 8: 271/634 Loss: 0.144832
2023-01-01 13:30: Train Epoch 8: 275/634 Loss: 0.167294
2023-01-01 13:30: Train Epoch 8: 279/634 Loss: 0.203755
2023-01-01 13:31: Train Epoch 8: 283/634 Loss: 0.124359
2023-01-01 13:31: Train Epoch 8: 287/634 Loss: 0.181296
2023-01-01 13:31: Train Epoch 8: 291/634 Loss: 0.195683
2023-01-01 13:32: Train Epoch 8: 295/634 Loss: 0.181574
2023-01-01 13:32: Train Epoch 8: 299/634 Loss: 0.144042
2023-01-01 13:32: Train Epoch 8: 303/634 Loss: 0.155282
2023-01-01 13:33: Train Epoch 8: 307/634 Loss: 0.176167
2023-01-01 13:33: Train Epoch 8: 311/634 Loss: 0.163081
2023-01-01 13:34: Train Epoch 8: 315/634 Loss: 0.164852
2023-01-01 13:34: Train Epoch 8: 319/634 Loss: 0.183578
2023-01-01 13:34: Train Epoch 8: 323/634 Loss: 0.162995
2023-01-01 13:35: Train Epoch 8: 327/634 Loss: 0.156433
2023-01-01 13:35: Train Epoch 8: 331/634 Loss: 0.195905
2023-01-01 13:35: Train Epoch 8: 335/634 Loss: 0.154101
2023-01-01 13:36: Train Epoch 8: 339/634 Loss: 0.168526
2023-01-01 13:36: Train Epoch 8: 343/634 Loss: 0.146234
2023-01-01 13:36: Train Epoch 8: 347/634 Loss: 0.155308
2023-01-01 13:37: Train Epoch 8: 351/634 Loss: 0.160643
2023-01-01 13:37: Train Epoch 8: 355/634 Loss: 0.165812
2023-01-01 13:37: Train Epoch 8: 359/634 Loss: 0.163167
2023-01-01 13:38: Train Epoch 8: 363/634 Loss: 0.178721
2023-01-01 13:38: Train Epoch 8: 367/634 Loss: 0.182098
2023-01-01 13:39: Train Epoch 8: 371/634 Loss: 0.165588
2023-01-01 13:39: Train Epoch 8: 375/634 Loss: 0.151165
2023-01-01 13:39: Train Epoch 8: 379/634 Loss: 0.149608
2023-01-01 13:40: Train Epoch 8: 383/634 Loss: 0.152211
2023-01-01 13:40: Train Epoch 8: 387/634 Loss: 0.157363
2023-01-01 13:40: Train Epoch 8: 391/634 Loss: 0.160413
2023-01-01 13:41: Train Epoch 8: 395/634 Loss: 0.154618
2023-01-01 13:41: Train Epoch 8: 399/634 Loss: 0.161589
2023-01-01 13:41: Train Epoch 8: 403/634 Loss: 0.182514
2023-01-01 13:42: Train Epoch 8: 407/634 Loss: 0.144568
2023-01-01 13:42: Train Epoch 8: 411/634 Loss: 0.176622
2023-01-01 13:43: Train Epoch 8: 415/634 Loss: 0.144280
2023-01-01 13:43: Train Epoch 8: 419/634 Loss: 0.155999
2023-01-01 13:43: Train Epoch 8: 423/634 Loss: 0.207651
2023-01-01 13:44: Train Epoch 8: 427/634 Loss: 0.170768
2023-01-01 13:44: Train Epoch 8: 431/634 Loss: 0.161314
2023-01-01 13:44: Train Epoch 8: 435/634 Loss: 0.175075
2023-01-01 13:45: Train Epoch 8: 439/634 Loss: 0.163715
2023-01-01 13:45: Train Epoch 8: 443/634 Loss: 0.171916
2023-01-01 13:45: Train Epoch 8: 447/634 Loss: 0.190323
2023-01-01 13:46: Train Epoch 8: 451/634 Loss: 0.184268
2023-01-01 13:46: Train Epoch 8: 455/634 Loss: 0.171882
2023-01-01 13:46: Train Epoch 8: 459/634 Loss: 0.155127
2023-01-01 13:47: Train Epoch 8: 463/634 Loss: 0.195365
2023-01-01 13:47: Train Epoch 8: 467/634 Loss: 0.168780
2023-01-01 13:48: Train Epoch 8: 471/634 Loss: 0.138854
2023-01-01 13:48: Train Epoch 8: 475/634 Loss: 0.201272
2023-01-01 13:48: Train Epoch 8: 479/634 Loss: 0.174336
2023-01-01 13:49: Train Epoch 8: 483/634 Loss: 0.177226
2023-01-01 13:49: Train Epoch 8: 487/634 Loss: 0.184764
2023-01-01 13:49: Train Epoch 8: 491/634 Loss: 0.143620
2023-01-01 13:50: Train Epoch 8: 495/634 Loss: 0.152295
2023-01-01 13:50: Train Epoch 8: 499/634 Loss: 0.196796
2023-01-01 13:50: Train Epoch 8: 503/634 Loss: 0.188651
2023-01-01 13:51: Train Epoch 8: 507/634 Loss: 0.140649
2023-01-01 13:51: Train Epoch 8: 511/634 Loss: 0.164830
2023-01-01 13:51: Train Epoch 8: 515/634 Loss: 0.158027
2023-01-01 13:52: Train Epoch 8: 519/634 Loss: 0.173868
2023-01-01 13:52: Train Epoch 8: 523/634 Loss: 0.153492
2023-01-01 13:52: Train Epoch 8: 527/634 Loss: 0.161333
2023-01-01 13:53: Train Epoch 8: 531/634 Loss: 0.124824
2023-01-01 13:53: Train Epoch 8: 535/634 Loss: 0.150886
2023-01-01 13:53: Train Epoch 8: 539/634 Loss: 0.161881
2023-01-01 13:54: Train Epoch 8: 543/634 Loss: 0.140545
2023-01-01 13:54: Train Epoch 8: 547/634 Loss: 0.192847
2023-01-01 13:54: Train Epoch 8: 551/634 Loss: 0.186539
2023-01-01 13:55: Train Epoch 8: 555/634 Loss: 0.133877
2023-01-01 13:55: Train Epoch 8: 559/634 Loss: 0.146826
2023-01-01 13:55: Train Epoch 8: 563/634 Loss: 0.153315
2023-01-01 13:56: Train Epoch 8: 567/634 Loss: 0.185984
2023-01-01 13:56: Train Epoch 8: 571/634 Loss: 0.192962
2023-01-01 13:57: Train Epoch 8: 575/634 Loss: 0.174719
2023-01-01 13:57: Train Epoch 8: 579/634 Loss: 0.145564
2023-01-01 13:57: Train Epoch 8: 583/634 Loss: 0.166307
2023-01-01 13:58: Train Epoch 8: 587/634 Loss: 0.168574
2023-01-01 13:58: Train Epoch 8: 591/634 Loss: 0.165758
2023-01-01 13:58: Train Epoch 8: 595/634 Loss: 0.204097
2023-01-01 13:59: Train Epoch 8: 599/634 Loss: 0.173413
2023-01-01 13:59: Train Epoch 8: 603/634 Loss: 0.165165
2023-01-01 13:59: Train Epoch 8: 607/634 Loss: 0.147426
2023-01-01 14:00: Train Epoch 8: 611/634 Loss: 0.131678
2023-01-01 14:00: Train Epoch 8: 615/634 Loss: 0.173560
2023-01-01 14:00: Train Epoch 8: 619/634 Loss: 0.140513
2023-01-01 14:01: Train Epoch 8: 623/634 Loss: 0.154093
2023-01-01 14:01: Train Epoch 8: 627/634 Loss: 0.161836
2023-01-01 14:01: Train Epoch 8: 631/634 Loss: 0.158526
2023-01-01 14:02: Train Epoch 8: 633/634 Loss: 0.083446
2023-01-01 14:02: **********Train Epoch 8: averaged Loss: 0.171291 
2023-01-01 14:02: 
Epoch time elapsed: 3385.40727186203

2023-01-01 14:03: 
 metrics validation: {'precision': 0.7571533382245048, 'recall': 0.7938461538461539, 'f1-score': 0.7750657153586181, 'support': 1300, 'AUC': 0.921057396449704, 'AUCPR': 0.8465357262471631, 'TP': 1032, 'FP': 331, 'TN': 2269, 'FN': 268} 

2023-01-01 14:03: **********Val Epoch 8: average Loss: 0.163332
2023-01-01 14:04: 
 Testing metrics {'precision': 0.8096856414613424, 'recall': 0.7760586319218241, 'f1-score': 0.7925155925155926, 'support': 1228, 'AUC': 0.9260224246411103, 'AUCPR': 0.8814196290905293, 'TP': 953, 'FP': 224, 'TN': 2232, 'FN': 275} 

2023-01-01 14:10: 
 Testing metrics {'precision': 0.8662952646239555, 'recall': 0.8468345813478557, 'f1-score': 0.8564543889845095, 'support': 4407, 'AUC': 0.9690275655790093, 'AUCPR': 0.9429331310281731, 'TP': 3732, 'FP': 576, 'TN': 8238, 'FN': 675} 

2023-01-01 14:10: Train Epoch 9: 3/634 Loss: 0.184370
2023-01-01 14:10: Train Epoch 9: 7/634 Loss: 0.183644
2023-01-01 14:11: Train Epoch 9: 11/634 Loss: 0.145555
2023-01-01 14:11: Train Epoch 9: 15/634 Loss: 0.152672
2023-01-01 14:11: Train Epoch 9: 19/634 Loss: 0.161747
2023-01-01 14:12: Train Epoch 9: 23/634 Loss: 0.133917
2023-01-01 14:12: Train Epoch 9: 27/634 Loss: 0.134781
2023-01-01 14:12: Train Epoch 9: 31/634 Loss: 0.168953
2023-01-01 14:13: Train Epoch 9: 35/634 Loss: 0.164284
2023-01-01 14:13: Train Epoch 9: 39/634 Loss: 0.151025
2023-01-01 14:13: Train Epoch 9: 43/634 Loss: 0.173406
2023-01-01 14:14: Train Epoch 9: 47/634 Loss: 0.162233
2023-01-01 14:14: Train Epoch 9: 51/634 Loss: 0.168719
2023-01-01 14:14: Train Epoch 9: 55/634 Loss: 0.213958
2023-01-01 14:15: Train Epoch 9: 59/634 Loss: 0.192370
2023-01-01 14:15: Train Epoch 9: 63/634 Loss: 0.145935
2023-01-01 14:16: Train Epoch 9: 67/634 Loss: 0.201303
2023-01-01 14:16: Train Epoch 9: 71/634 Loss: 0.215724
2023-01-01 14:16: Train Epoch 9: 75/634 Loss: 0.148122
2023-01-01 14:17: Train Epoch 9: 79/634 Loss: 0.170774
2023-01-01 14:17: Train Epoch 9: 83/634 Loss: 0.220257
2023-01-01 14:17: Train Epoch 9: 87/634 Loss: 0.161732
2023-01-01 14:18: Train Epoch 9: 91/634 Loss: 0.173258
2023-01-01 14:18: Train Epoch 9: 95/634 Loss: 0.211917
2023-01-01 14:18: Train Epoch 9: 99/634 Loss: 0.172835
2023-01-01 14:19: Train Epoch 9: 103/634 Loss: 0.180405
2023-01-01 14:19: Train Epoch 9: 107/634 Loss: 0.179439
2023-01-01 14:20: Train Epoch 9: 111/634 Loss: 0.175572
2023-01-01 14:20: Train Epoch 9: 115/634 Loss: 0.147497
2023-01-01 14:20: Train Epoch 9: 119/634 Loss: 0.214344
2023-01-01 14:21: Train Epoch 9: 123/634 Loss: 0.210061
2023-01-01 14:21: Train Epoch 9: 127/634 Loss: 0.164783
2023-01-01 14:21: Train Epoch 9: 131/634 Loss: 0.156768
2023-01-01 14:22: Train Epoch 9: 135/634 Loss: 0.181017
2023-01-01 14:22: Train Epoch 9: 139/634 Loss: 0.166672
2023-01-01 14:22: Train Epoch 9: 143/634 Loss: 0.173030
2023-01-01 14:23: Train Epoch 9: 147/634 Loss: 0.149371
2023-01-01 14:23: Train Epoch 9: 151/634 Loss: 0.144785
2023-01-01 14:24: Train Epoch 9: 155/634 Loss: 0.163000
2023-01-01 14:24: Train Epoch 9: 159/634 Loss: 0.170121
2023-01-01 14:24: Train Epoch 9: 163/634 Loss: 0.133183
2023-01-01 14:25: Train Epoch 9: 167/634 Loss: 0.189155
2023-01-01 14:25: Train Epoch 9: 171/634 Loss: 0.154947
2023-01-01 14:25: Train Epoch 9: 175/634 Loss: 0.191034
2023-01-01 14:26: Train Epoch 9: 179/634 Loss: 0.168260
2023-01-01 14:26: Train Epoch 9: 183/634 Loss: 0.171718
2023-01-01 14:27: Train Epoch 9: 187/634 Loss: 0.145932
2023-01-01 14:27: Train Epoch 9: 191/634 Loss: 0.149169
2023-01-01 14:27: Train Epoch 9: 195/634 Loss: 0.149102
2023-01-01 14:28: Train Epoch 9: 199/634 Loss: 0.165705
2023-01-01 14:28: Train Epoch 9: 203/634 Loss: 0.157999
2023-01-01 14:29: Train Epoch 9: 207/634 Loss: 0.172639
2023-01-01 14:29: Train Epoch 9: 211/634 Loss: 0.151625
2023-01-01 14:29: Train Epoch 9: 215/634 Loss: 0.142759
2023-01-01 14:30: Train Epoch 9: 219/634 Loss: 0.159644
2023-01-01 14:30: Train Epoch 9: 223/634 Loss: 0.141015
2023-01-01 14:30: Train Epoch 9: 227/634 Loss: 0.158791
2023-01-01 14:31: Train Epoch 9: 231/634 Loss: 0.154768
2023-01-01 14:31: Train Epoch 9: 235/634 Loss: 0.171748
2023-01-01 14:31: Train Epoch 9: 239/634 Loss: 0.185740
2023-01-01 14:32: Train Epoch 9: 243/634 Loss: 0.158035
2023-01-01 14:32: Train Epoch 9: 247/634 Loss: 0.160020
2023-01-01 14:33: Train Epoch 9: 251/634 Loss: 0.169000
2023-01-01 14:33: Train Epoch 9: 255/634 Loss: 0.163952
2023-01-01 14:33: Train Epoch 9: 259/634 Loss: 0.169081
2023-01-01 14:34: Train Epoch 9: 263/634 Loss: 0.142247
2023-01-01 14:34: Train Epoch 9: 267/634 Loss: 0.153156
2023-01-01 14:34: Train Epoch 9: 271/634 Loss: 0.168410
2023-01-01 14:35: Train Epoch 9: 275/634 Loss: 0.158014
2023-01-01 14:35: Train Epoch 9: 279/634 Loss: 0.165888
2023-01-01 14:35: Train Epoch 9: 283/634 Loss: 0.150355
2023-01-01 14:36: Train Epoch 9: 287/634 Loss: 0.150202
2023-01-01 14:36: Train Epoch 9: 291/634 Loss: 0.182084
2023-01-01 14:37: Train Epoch 9: 295/634 Loss: 0.157621
2023-01-01 14:37: Train Epoch 9: 299/634 Loss: 0.156163
2023-01-01 14:37: Train Epoch 9: 303/634 Loss: 0.142619
2023-01-01 14:38: Train Epoch 9: 307/634 Loss: 0.172854
2023-01-01 14:38: Train Epoch 9: 311/634 Loss: 0.164776
2023-01-01 14:38: Train Epoch 9: 315/634 Loss: 0.151574
2023-01-01 14:39: Train Epoch 9: 319/634 Loss: 0.174592
2023-01-01 14:39: Train Epoch 9: 323/634 Loss: 0.161188
2023-01-01 14:39: Train Epoch 9: 327/634 Loss: 0.170772
2023-01-01 14:40: Train Epoch 9: 331/634 Loss: 0.154899
2023-01-01 14:40: Train Epoch 9: 335/634 Loss: 0.161065
2023-01-01 14:41: Train Epoch 9: 339/634 Loss: 0.155177
2023-01-01 14:41: Train Epoch 9: 343/634 Loss: 0.143419
2023-01-01 14:41: Train Epoch 9: 347/634 Loss: 0.137175
2023-01-01 14:42: Train Epoch 9: 351/634 Loss: 0.163776
2023-01-01 14:42: Train Epoch 9: 355/634 Loss: 0.145840
2023-01-01 14:42: Train Epoch 9: 359/634 Loss: 0.136223
2023-01-01 14:43: Train Epoch 9: 363/634 Loss: 0.146642
2023-01-01 14:43: Train Epoch 9: 367/634 Loss: 0.165130
2023-01-01 14:43: Train Epoch 9: 371/634 Loss: 0.140140
2023-01-01 14:44: Train Epoch 9: 375/634 Loss: 0.173962
2023-01-01 14:44: Train Epoch 9: 379/634 Loss: 0.163345
2023-01-01 14:44: Train Epoch 9: 383/634 Loss: 0.175753
2023-01-01 14:45: Train Epoch 9: 387/634 Loss: 0.149538
2023-01-01 14:45: Train Epoch 9: 391/634 Loss: 0.176931
2023-01-01 14:45: Train Epoch 9: 395/634 Loss: 0.157943
2023-01-01 14:46: Train Epoch 9: 399/634 Loss: 0.146161
2023-01-01 14:46: Train Epoch 9: 403/634 Loss: 0.169002
2023-01-01 14:47: Train Epoch 9: 407/634 Loss: 0.179445
2023-01-01 14:47: Train Epoch 9: 411/634 Loss: 0.136831
2023-01-01 14:47: Train Epoch 9: 415/634 Loss: 0.153069
2023-01-01 14:48: Train Epoch 9: 419/634 Loss: 0.133232
2023-01-01 14:48: Train Epoch 9: 423/634 Loss: 0.143641
2023-01-01 14:48: Train Epoch 9: 427/634 Loss: 0.156681
2023-01-01 14:49: Train Epoch 9: 431/634 Loss: 0.161212
2023-01-01 14:49: Train Epoch 9: 435/634 Loss: 0.191851
2023-01-01 14:50: Train Epoch 9: 439/634 Loss: 0.152775
2023-01-01 14:50: Train Epoch 9: 443/634 Loss: 0.173319
2023-01-01 14:50: Train Epoch 9: 447/634 Loss: 0.165217
2023-01-01 14:51: Train Epoch 9: 451/634 Loss: 0.133872
2023-01-01 14:51: Train Epoch 9: 455/634 Loss: 0.167438
2023-01-01 14:51: Train Epoch 9: 459/634 Loss: 0.149540
2023-01-01 14:52: Train Epoch 9: 463/634 Loss: 0.145284
2023-01-01 14:52: Train Epoch 9: 467/634 Loss: 0.136679
2023-01-01 14:53: Train Epoch 9: 471/634 Loss: 0.168217
2023-01-01 14:53: Train Epoch 9: 475/634 Loss: 0.155076
2023-01-01 14:53: Train Epoch 9: 479/634 Loss: 0.161855
2023-01-01 14:54: Train Epoch 9: 483/634 Loss: 0.167808
2023-01-01 14:54: Train Epoch 9: 487/634 Loss: 0.170411
2023-01-01 14:54: Train Epoch 9: 491/634 Loss: 0.156362
2023-01-01 14:55: Train Epoch 9: 495/634 Loss: 0.143843
2023-01-01 14:55: Train Epoch 9: 499/634 Loss: 0.138004
2023-01-01 14:55: Train Epoch 9: 503/634 Loss: 0.151518
2023-01-01 14:56: Train Epoch 9: 507/634 Loss: 0.139364
2023-01-01 14:56: Train Epoch 9: 511/634 Loss: 0.152142
2023-01-01 14:57: Train Epoch 9: 515/634 Loss: 0.164374
2023-01-01 14:57: Train Epoch 9: 519/634 Loss: 0.158157
2023-01-01 14:57: Train Epoch 9: 523/634 Loss: 0.158439
2023-01-01 14:58: Train Epoch 9: 527/634 Loss: 0.165327
2023-01-01 14:58: Train Epoch 9: 531/634 Loss: 0.159030
2023-01-01 14:58: Train Epoch 9: 535/634 Loss: 0.170753
2023-01-01 14:59: Train Epoch 9: 539/634 Loss: 0.166001
2023-01-01 14:59: Train Epoch 9: 543/634 Loss: 0.166496
2023-01-01 14:59: Train Epoch 9: 547/634 Loss: 0.148346
2023-01-01 15:00: Train Epoch 9: 551/634 Loss: 0.124196
2023-01-01 15:00: Train Epoch 9: 555/634 Loss: 0.171174
2023-01-01 15:01: Train Epoch 9: 559/634 Loss: 0.159554
2023-01-01 15:01: Train Epoch 9: 563/634 Loss: 0.160244
2023-01-01 15:01: Train Epoch 9: 567/634 Loss: 0.214364
2023-01-01 15:02: Train Epoch 9: 571/634 Loss: 0.143025
2023-01-01 15:02: Train Epoch 9: 575/634 Loss: 0.148789
2023-01-01 15:02: Train Epoch 9: 579/634 Loss: 0.150414
2023-01-01 15:03: Train Epoch 9: 583/634 Loss: 0.143279
2023-01-01 15:03: Train Epoch 9: 587/634 Loss: 0.179896
2023-01-01 15:03: Train Epoch 9: 591/634 Loss: 0.185669
2023-01-01 15:04: Train Epoch 9: 595/634 Loss: 0.141310
2023-01-01 15:04: Train Epoch 9: 599/634 Loss: 0.157543
2023-01-01 15:05: Train Epoch 9: 603/634 Loss: 0.147677
2023-01-01 15:05: Train Epoch 9: 607/634 Loss: 0.164232
2023-01-01 15:05: Train Epoch 9: 611/634 Loss: 0.173832
2023-01-01 15:06: Train Epoch 9: 615/634 Loss: 0.163336
2023-01-01 15:06: Train Epoch 9: 619/634 Loss: 0.158920
2023-01-01 15:06: Train Epoch 9: 623/634 Loss: 0.156148
2023-01-01 15:07: Train Epoch 9: 627/634 Loss: 0.145587
2023-01-01 15:07: Train Epoch 9: 631/634 Loss: 0.184137
2023-01-01 15:07: Train Epoch 9: 633/634 Loss: 0.073156
2023-01-01 15:07: **********Train Epoch 9: averaged Loss: 0.161623 
2023-01-01 15:07: 
Epoch time elapsed: 3456.284751176834

2023-01-01 15:09: 
 metrics validation: {'precision': 0.9292929292929293, 'recall': 0.28307692307692306, 'f1-score': 0.4339622641509434, 'support': 1300, 'AUC': 0.9329884615384615, 'AUCPR': 0.8687902045392673, 'TP': 368, 'FP': 28, 'TN': 2572, 'FN': 932} 

2023-01-01 15:09: **********Val Epoch 9: average Loss: 0.246822
2023-01-01 15:10: 
 Testing metrics {'precision': 0.8096856414613424, 'recall': 0.7760586319218241, 'f1-score': 0.7925155925155926, 'support': 1228, 'AUC': 0.9260224246411103, 'AUCPR': 0.8814196290905293, 'TP': 953, 'FP': 224, 'TN': 2232, 'FN': 275} 

2023-01-01 15:15: 
 Testing metrics {'precision': 0.8662952646239555, 'recall': 0.8468345813478557, 'f1-score': 0.8564543889845095, 'support': 4407, 'AUC': 0.9690275655790093, 'AUCPR': 0.9429331310281731, 'TP': 3732, 'FP': 576, 'TN': 8238, 'FN': 675} 

2023-01-01 15:16: Train Epoch 10: 3/634 Loss: 0.146879
2023-01-01 15:16: Train Epoch 10: 7/634 Loss: 0.134804
2023-01-01 15:16: Train Epoch 10: 11/634 Loss: 0.202682
2023-01-01 15:17: Train Epoch 10: 15/634 Loss: 0.152955
2023-01-01 15:17: Train Epoch 10: 19/634 Loss: 0.155190
2023-01-01 15:17: Train Epoch 10: 23/634 Loss: 0.156407
2023-01-01 15:18: Train Epoch 10: 27/634 Loss: 0.162870
2023-01-01 15:18: Train Epoch 10: 31/634 Loss: 0.156614
2023-01-01 15:18: Train Epoch 10: 35/634 Loss: 0.129829
2023-01-01 15:19: Train Epoch 10: 39/634 Loss: 0.145172
2023-01-01 15:19: Train Epoch 10: 43/634 Loss: 0.169006
2023-01-01 15:20: Train Epoch 10: 47/634 Loss: 0.164838
2023-01-01 15:20: Train Epoch 10: 51/634 Loss: 0.154481
2023-01-01 15:20: Train Epoch 10: 55/634 Loss: 0.172386
2023-01-01 15:21: Train Epoch 10: 59/634 Loss: 0.161941
2023-01-01 15:21: Train Epoch 10: 63/634 Loss: 0.142788
2023-01-01 15:21: Train Epoch 10: 67/634 Loss: 0.146925
2023-01-01 15:22: Train Epoch 10: 71/634 Loss: 0.150011
2023-01-01 15:22: Train Epoch 10: 75/634 Loss: 0.157145
2023-01-01 15:22: Train Epoch 10: 79/634 Loss: 0.158248
2023-01-01 15:23: Train Epoch 10: 83/634 Loss: 0.146522
2023-01-01 15:23: Train Epoch 10: 87/634 Loss: 0.164840
2023-01-01 15:24: Train Epoch 10: 91/634 Loss: 0.175895
2023-01-01 15:24: Train Epoch 10: 95/634 Loss: 0.144199
2023-01-01 15:24: Train Epoch 10: 99/634 Loss: 0.126292
2023-01-01 15:25: Train Epoch 10: 103/634 Loss: 0.184341
2023-01-01 15:25: Train Epoch 10: 107/634 Loss: 0.171851
2023-01-01 15:25: Train Epoch 10: 111/634 Loss: 0.154062
2023-01-01 15:26: Train Epoch 10: 115/634 Loss: 0.122783
2023-01-01 15:26: Train Epoch 10: 119/634 Loss: 0.173059
2023-01-01 15:26: Train Epoch 10: 123/634 Loss: 0.160783
2023-01-01 15:27: Train Epoch 10: 127/634 Loss: 0.147022
2023-01-01 15:27: Train Epoch 10: 131/634 Loss: 0.204968
2023-01-01 15:27: Train Epoch 10: 135/634 Loss: 0.160335
2023-01-01 15:28: Train Epoch 10: 139/634 Loss: 0.175822
2023-01-01 15:28: Train Epoch 10: 143/634 Loss: 0.160445
2023-01-01 15:29: Train Epoch 10: 147/634 Loss: 0.154037
2023-01-01 15:29: Train Epoch 10: 151/634 Loss: 0.184864
2023-01-01 15:29: Train Epoch 10: 155/634 Loss: 0.155273
2023-01-01 15:30: Train Epoch 10: 159/634 Loss: 0.139649
2023-01-01 15:30: Train Epoch 10: 163/634 Loss: 0.164899
2023-01-01 15:30: Train Epoch 10: 167/634 Loss: 0.168136
2023-01-01 15:31: Train Epoch 10: 171/634 Loss: 0.162836
2023-01-01 15:31: Train Epoch 10: 175/634 Loss: 0.166146
2023-01-01 15:31: Train Epoch 10: 179/634 Loss: 0.163977
2023-01-01 15:32: Train Epoch 10: 183/634 Loss: 0.155994
2023-01-01 15:32: Train Epoch 10: 187/634 Loss: 0.162737
2023-01-01 15:32: Train Epoch 10: 191/634 Loss: 0.148919
2023-01-01 15:33: Train Epoch 10: 195/634 Loss: 0.146540
2023-01-01 15:33: Train Epoch 10: 199/634 Loss: 0.160114
2023-01-01 15:33: Train Epoch 10: 203/634 Loss: 0.169400
2023-01-01 15:34: Train Epoch 10: 207/634 Loss: 0.146476
2023-01-01 15:34: Train Epoch 10: 211/634 Loss: 0.156905
2023-01-01 15:34: Train Epoch 10: 215/634 Loss: 0.172931
2023-01-01 15:35: Train Epoch 10: 219/634 Loss: 0.151303
2023-01-01 15:35: Train Epoch 10: 223/634 Loss: 0.188977
2023-01-01 15:36: Train Epoch 10: 227/634 Loss: 0.154318
2023-01-01 15:36: Train Epoch 10: 231/634 Loss: 0.141188
2023-01-01 15:36: Train Epoch 10: 235/634 Loss: 0.150374
2023-01-01 15:37: Train Epoch 10: 239/634 Loss: 0.192219
2023-01-01 15:37: Train Epoch 10: 243/634 Loss: 0.143519
2023-01-01 15:37: Train Epoch 10: 247/634 Loss: 0.189386
2023-01-01 15:38: Train Epoch 10: 251/634 Loss: 0.177708
2023-01-01 15:38: Train Epoch 10: 255/634 Loss: 0.194196
2023-01-01 15:38: Train Epoch 10: 259/634 Loss: 0.163177
2023-01-01 15:39: Train Epoch 10: 263/634 Loss: 0.153275
2023-01-01 15:39: Train Epoch 10: 267/634 Loss: 0.189854
2023-01-01 15:39: Train Epoch 10: 271/634 Loss: 0.147340
2023-01-01 15:40: Train Epoch 10: 275/634 Loss: 0.173910
2023-01-01 15:40: Train Epoch 10: 279/634 Loss: 0.155281
2023-01-01 15:40: Train Epoch 10: 283/634 Loss: 0.164485
2023-01-01 15:41: Train Epoch 10: 287/634 Loss: 0.144003
2023-01-01 15:41: Train Epoch 10: 291/634 Loss: 0.157443
2023-01-01 15:42: Train Epoch 10: 295/634 Loss: 0.143691
2023-01-01 15:42: Train Epoch 10: 299/634 Loss: 0.168378
2023-01-01 15:42: Train Epoch 10: 303/634 Loss: 0.130919
2023-01-01 15:43: Train Epoch 10: 307/634 Loss: 0.168758
2023-01-01 15:43: Train Epoch 10: 311/634 Loss: 0.198951
2023-01-01 15:43: Train Epoch 10: 315/634 Loss: 0.193105
2023-01-01 15:44: Train Epoch 10: 319/634 Loss: 0.151495
2023-01-01 15:44: Train Epoch 10: 323/634 Loss: 0.182675
2023-01-01 15:44: Train Epoch 10: 327/634 Loss: 0.205210
2023-01-01 15:45: Train Epoch 10: 331/634 Loss: 0.176324
2023-01-01 15:45: Train Epoch 10: 335/634 Loss: 0.175748
2023-01-01 15:45: Train Epoch 10: 339/634 Loss: 0.196463
2023-01-01 15:46: Train Epoch 10: 343/634 Loss: 0.177962
2023-01-01 15:46: Train Epoch 10: 347/634 Loss: 0.194262
2023-01-01 15:47: Train Epoch 10: 351/634 Loss: 0.147603
2023-01-01 15:47: Train Epoch 10: 355/634 Loss: 0.172782
2023-01-01 15:47: Train Epoch 10: 359/634 Loss: 0.158483
2023-01-01 15:48: Train Epoch 10: 363/634 Loss: 0.156686
2023-01-01 15:48: Train Epoch 10: 367/634 Loss: 0.159064
2023-01-01 15:48: Train Epoch 10: 371/634 Loss: 0.145137
2023-01-01 15:49: Train Epoch 10: 375/634 Loss: 0.138071
2023-01-01 15:49: Train Epoch 10: 379/634 Loss: 0.148902
2023-01-01 15:49: Train Epoch 10: 383/634 Loss: 0.161461
2023-01-01 15:50: Train Epoch 10: 387/634 Loss: 0.186185
2023-01-01 15:50: Train Epoch 10: 391/634 Loss: 0.149760
2023-01-01 15:50: Train Epoch 10: 395/634 Loss: 0.205521
2023-01-01 15:51: Train Epoch 10: 399/634 Loss: 0.163378
2023-01-01 15:51: Train Epoch 10: 403/634 Loss: 0.150946
2023-01-01 15:52: Train Epoch 10: 407/634 Loss: 0.161249
2023-01-01 15:52: Train Epoch 10: 411/634 Loss: 0.189727
2023-01-01 15:52: Train Epoch 10: 415/634 Loss: 0.148607
2023-01-01 15:53: Train Epoch 10: 419/634 Loss: 0.168700
2023-01-01 15:53: Train Epoch 10: 423/634 Loss: 0.152273
2023-01-01 15:53: Train Epoch 10: 427/634 Loss: 0.155230
2023-01-01 15:54: Train Epoch 10: 431/634 Loss: 0.147670
2023-01-01 15:54: Train Epoch 10: 435/634 Loss: 0.185658
2023-01-01 15:54: Train Epoch 10: 439/634 Loss: 0.165006
2023-01-01 15:55: Train Epoch 10: 443/634 Loss: 0.171886
2023-01-01 15:55: Train Epoch 10: 447/634 Loss: 0.175311
2023-01-01 15:55: Train Epoch 10: 451/634 Loss: 0.171055
2023-01-01 15:56: Train Epoch 10: 455/634 Loss: 0.148181
2023-01-01 15:56: Train Epoch 10: 459/634 Loss: 0.238257
2023-01-01 15:57: Train Epoch 10: 463/634 Loss: 0.163415
2023-01-01 15:57: Train Epoch 10: 467/634 Loss: 0.186008
2023-01-01 15:57: Train Epoch 10: 471/634 Loss: 0.261556
2023-01-01 15:58: Train Epoch 10: 475/634 Loss: 0.166092
2023-01-01 15:58: Train Epoch 10: 479/634 Loss: 0.156296
2023-01-01 15:58: Train Epoch 10: 483/634 Loss: 0.170145
2023-01-01 15:59: Train Epoch 10: 487/634 Loss: 0.150088
2023-01-01 15:59: Train Epoch 10: 491/634 Loss: 0.148332
2023-01-01 15:59: Train Epoch 10: 495/634 Loss: 0.158980
2023-01-01 16:00: Train Epoch 10: 499/634 Loss: 0.149496
2023-01-01 16:00: Train Epoch 10: 503/634 Loss: 0.155879
2023-01-01 16:00: Train Epoch 10: 507/634 Loss: 0.153947
2023-01-01 16:01: Train Epoch 10: 511/634 Loss: 0.176462
2023-01-01 16:01: Train Epoch 10: 515/634 Loss: 0.137261
2023-01-01 16:01: Train Epoch 10: 519/634 Loss: 0.147707
2023-01-01 16:02: Train Epoch 10: 523/634 Loss: 0.180795
2023-01-01 16:02: Train Epoch 10: 527/634 Loss: 0.151402
2023-01-01 16:02: Train Epoch 10: 531/634 Loss: 0.137837
2023-01-01 16:03: Train Epoch 10: 535/634 Loss: 0.150589
2023-01-01 16:03: Train Epoch 10: 539/634 Loss: 0.150712
2023-01-01 16:04: Train Epoch 10: 543/634 Loss: 0.131444
2023-01-01 16:04: Train Epoch 10: 547/634 Loss: 0.147188
2023-01-01 16:04: Train Epoch 10: 551/634 Loss: 0.169408
2023-01-01 16:05: Train Epoch 10: 555/634 Loss: 0.148354
2023-01-01 16:05: Train Epoch 10: 559/634 Loss: 0.154652
2023-01-01 16:05: Train Epoch 10: 563/634 Loss: 0.150631
2023-01-01 16:06: Train Epoch 10: 567/634 Loss: 0.165370
2023-01-01 16:06: Train Epoch 10: 571/634 Loss: 0.140622
2023-01-01 16:07: Train Epoch 10: 575/634 Loss: 0.141383
2023-01-01 16:07: Train Epoch 10: 579/634 Loss: 0.144396
2023-01-01 16:07: Train Epoch 10: 583/634 Loss: 0.145501
2023-01-01 16:08: Train Epoch 10: 587/634 Loss: 0.177178
2023-01-01 16:08: Train Epoch 10: 591/634 Loss: 0.154889
2023-01-01 16:08: Train Epoch 10: 595/634 Loss: 0.163614
2023-01-01 16:09: Train Epoch 10: 599/634 Loss: 0.150422
2023-01-01 16:09: Train Epoch 10: 603/634 Loss: 0.166605
2023-01-01 16:09: Train Epoch 10: 607/634 Loss: 0.165301
2023-01-01 16:10: Train Epoch 10: 611/634 Loss: 0.170892
2023-01-01 16:10: Train Epoch 10: 615/634 Loss: 0.168975
2023-01-01 16:10: Train Epoch 10: 619/634 Loss: 0.145004
2023-01-01 16:11: Train Epoch 10: 623/634 Loss: 0.159502
2023-01-01 16:11: Train Epoch 10: 627/634 Loss: 0.178569
2023-01-01 16:12: Train Epoch 10: 631/634 Loss: 0.162399
2023-01-01 16:12: Train Epoch 10: 633/634 Loss: 0.078964
2023-01-01 16:12: **********Train Epoch 10: averaged Loss: 0.161806 
2023-01-01 16:12: 
Epoch time elapsed: 3393.077499628067

2023-01-01 16:13: 
 metrics validation: {'precision': 0.9395161290322581, 'recall': 0.35846153846153844, 'f1-score': 0.5189309576837416, 'support': 1300, 'AUC': 0.9192625739644971, 'AUCPR': 0.855823593362377, 'TP': 466, 'FP': 30, 'TN': 2570, 'FN': 834} 

2023-01-01 16:13: **********Val Epoch 10: average Loss: 0.248122
2023-01-01 16:15: 
 Testing metrics {'precision': 0.8096856414613424, 'recall': 0.7760586319218241, 'f1-score': 0.7925155925155926, 'support': 1228, 'AUC': 0.9260224246411103, 'AUCPR': 0.8814196290905293, 'TP': 953, 'FP': 224, 'TN': 2232, 'FN': 275} 

2023-01-01 16:20: 
 Testing metrics {'precision': 0.8662952646239555, 'recall': 0.8468345813478557, 'f1-score': 0.8564543889845095, 'support': 4407, 'AUC': 0.9690275655790093, 'AUCPR': 0.9429331310281731, 'TP': 3732, 'FP': 576, 'TN': 8238, 'FN': 675} 

2023-01-01 16:20: Train Epoch 11: 3/634 Loss: 0.164922
2023-01-01 16:21: Train Epoch 11: 7/634 Loss: 0.133058
2023-01-01 16:21: Train Epoch 11: 11/634 Loss: 0.201763
2023-01-01 16:21: Train Epoch 11: 15/634 Loss: 0.147847
2023-01-01 16:22: Train Epoch 11: 19/634 Loss: 0.162379
2023-01-01 16:22: Train Epoch 11: 23/634 Loss: 0.167555
2023-01-01 16:23: Train Epoch 11: 27/634 Loss: 0.178832
2023-01-01 16:23: Train Epoch 11: 31/634 Loss: 0.160980
2023-01-01 16:23: Train Epoch 11: 35/634 Loss: 0.146919
2023-01-01 16:24: Train Epoch 11: 39/634 Loss: 0.147697
2023-01-01 16:24: Train Epoch 11: 43/634 Loss: 0.154864
2023-01-01 16:24: Train Epoch 11: 47/634 Loss: 0.173224
2023-01-01 16:25: Train Epoch 11: 51/634 Loss: 0.161314
2023-01-01 16:25: Train Epoch 11: 55/634 Loss: 0.173390
2023-01-01 16:25: Train Epoch 11: 59/634 Loss: 0.163039
2023-01-01 16:26: Train Epoch 11: 63/634 Loss: 0.193510
2023-01-01 16:26: Train Epoch 11: 67/634 Loss: 0.190725
2023-01-01 16:26: Train Epoch 11: 71/634 Loss: 0.170716
2023-01-01 16:27: Train Epoch 11: 75/634 Loss: 0.212044
2023-01-01 16:27: Train Epoch 11: 79/634 Loss: 0.143808
2023-01-01 16:27: Train Epoch 11: 83/634 Loss: 0.172664
2023-01-01 16:28: Train Epoch 11: 87/634 Loss: 0.173755
2023-01-01 16:28: Train Epoch 11: 91/634 Loss: 0.162109
2023-01-01 16:29: Train Epoch 11: 95/634 Loss: 0.135531
2023-01-01 16:29: Train Epoch 11: 99/634 Loss: 0.172742
2023-01-01 16:29: Train Epoch 11: 103/634 Loss: 0.198947
2023-01-01 16:30: Train Epoch 11: 107/634 Loss: 0.139944
2023-01-01 16:30: Train Epoch 11: 111/634 Loss: 0.178679
2023-01-01 16:30: Train Epoch 11: 115/634 Loss: 0.186423
2023-01-01 16:31: Train Epoch 11: 119/634 Loss: 0.176044
2023-01-01 16:31: Train Epoch 11: 123/634 Loss: 0.164726
2023-01-01 16:32: Train Epoch 11: 127/634 Loss: 0.164105
2023-01-01 16:32: Train Epoch 11: 131/634 Loss: 0.145806
2023-01-01 16:32: Train Epoch 11: 135/634 Loss: 0.169800
2023-01-01 16:33: Train Epoch 11: 139/634 Loss: 0.230227
2023-01-01 16:33: Train Epoch 11: 143/634 Loss: 0.150195
2023-01-01 16:33: Train Epoch 11: 147/634 Loss: 0.204833
2023-01-01 16:34: Train Epoch 11: 151/634 Loss: 0.179719
2023-01-01 16:34: Train Epoch 11: 155/634 Loss: 0.159234
2023-01-01 16:34: Train Epoch 11: 159/634 Loss: 0.183972
2023-01-01 16:35: Train Epoch 11: 163/634 Loss: 0.181144
2023-01-01 16:35: Train Epoch 11: 167/634 Loss: 0.135403
2023-01-01 16:36: Train Epoch 11: 171/634 Loss: 0.147126
2023-01-01 16:36: Train Epoch 11: 175/634 Loss: 0.166255
2023-01-01 16:36: Train Epoch 11: 179/634 Loss: 0.196603
2023-01-01 16:37: Train Epoch 11: 183/634 Loss: 0.171466
2023-01-01 16:37: Train Epoch 11: 187/634 Loss: 0.191819
2023-01-01 16:37: Train Epoch 11: 191/634 Loss: 0.175125
2023-01-01 16:38: Train Epoch 11: 195/634 Loss: 0.132926
2023-01-01 16:38: Train Epoch 11: 199/634 Loss: 0.255105
2023-01-01 16:38: Train Epoch 11: 203/634 Loss: 0.215652
2023-01-01 16:39: Train Epoch 11: 207/634 Loss: 0.134018
2023-01-01 16:39: Train Epoch 11: 211/634 Loss: 0.198794
2023-01-01 16:40: Train Epoch 11: 215/634 Loss: 0.166348
2023-01-01 16:40: Train Epoch 11: 219/634 Loss: 0.169578
2023-01-01 16:40: Train Epoch 11: 223/634 Loss: 0.159532
2023-01-01 16:41: Train Epoch 11: 227/634 Loss: 0.178912
2023-01-01 16:41: Train Epoch 11: 231/634 Loss: 0.195270
2023-01-01 16:41: Train Epoch 11: 235/634 Loss: 0.159437
2023-01-01 16:42: Train Epoch 11: 239/634 Loss: 0.203995
2023-01-01 16:42: Train Epoch 11: 243/634 Loss: 0.163382
2023-01-01 16:43: Train Epoch 11: 247/634 Loss: 0.157765
2023-01-01 16:43: Train Epoch 11: 251/634 Loss: 0.197694
2023-01-01 16:43: Train Epoch 11: 255/634 Loss: 0.169766
2023-01-01 16:44: Train Epoch 11: 259/634 Loss: 0.182475
2023-01-01 16:44: Train Epoch 11: 263/634 Loss: 0.133939
2023-01-01 16:44: Train Epoch 11: 267/634 Loss: 0.182873
2023-01-01 16:45: Train Epoch 11: 271/634 Loss: 0.159298
2023-01-01 16:45: Train Epoch 11: 275/634 Loss: 0.161102
2023-01-01 16:45: Train Epoch 11: 279/634 Loss: 0.147945
2023-01-01 16:46: Train Epoch 11: 283/634 Loss: 0.144834
2023-01-01 16:46: Train Epoch 11: 287/634 Loss: 0.163988
2023-01-01 16:46: Train Epoch 11: 291/634 Loss: 0.170023
2023-01-01 16:47: Train Epoch 11: 295/634 Loss: 0.151828
2023-01-01 16:47: Train Epoch 11: 299/634 Loss: 0.159771
2023-01-01 16:47: Train Epoch 11: 303/634 Loss: 0.165720
2023-01-01 16:48: Train Epoch 11: 307/634 Loss: 0.152415
2023-01-01 16:48: Train Epoch 11: 311/634 Loss: 0.158104
2023-01-01 16:49: Train Epoch 11: 315/634 Loss: 0.180188
2023-01-01 16:49: Train Epoch 11: 319/634 Loss: 0.159796
2023-01-01 16:49: Train Epoch 11: 323/634 Loss: 0.155383
2023-01-01 16:50: Train Epoch 11: 327/634 Loss: 0.161818
2023-01-01 16:50: Train Epoch 11: 331/634 Loss: 0.170404
2023-01-01 16:50: Train Epoch 11: 335/634 Loss: 0.147941
2023-01-01 16:51: Train Epoch 11: 339/634 Loss: 0.164223
2023-01-01 16:51: Train Epoch 11: 343/634 Loss: 0.178305
2023-01-01 16:51: Train Epoch 11: 347/634 Loss: 0.157931
2023-01-01 16:52: Train Epoch 11: 351/634 Loss: 0.165414
2023-01-01 16:52: Train Epoch 11: 355/634 Loss: 0.176417
2023-01-01 16:52: Train Epoch 11: 359/634 Loss: 0.163323
2023-01-01 16:53: Train Epoch 11: 363/634 Loss: 0.169461
2023-01-01 16:53: Train Epoch 11: 367/634 Loss: 0.183124
2023-01-01 16:54: Train Epoch 11: 371/634 Loss: 0.170696
2023-01-01 16:54: Train Epoch 11: 375/634 Loss: 0.178286
2023-01-01 16:54: Train Epoch 11: 379/634 Loss: 0.171385
2023-01-01 16:55: Train Epoch 11: 383/634 Loss: 0.147575
2023-01-01 16:55: Train Epoch 11: 387/634 Loss: 0.154643
2023-01-01 16:56: Train Epoch 11: 391/634 Loss: 0.162150
2023-01-01 16:56: Train Epoch 11: 395/634 Loss: 0.147948
2023-01-01 16:56: Train Epoch 11: 399/634 Loss: 0.157873
2023-01-01 16:57: Train Epoch 11: 403/634 Loss: 0.153199
2023-01-01 16:57: Train Epoch 11: 407/634 Loss: 0.192876
2023-01-01 16:57: Train Epoch 11: 411/634 Loss: 0.173581
2023-01-01 16:58: Train Epoch 11: 415/634 Loss: 0.138840
2023-01-01 16:58: Train Epoch 11: 419/634 Loss: 0.137354
2023-01-01 16:58: Train Epoch 11: 423/634 Loss: 0.206176
2023-01-01 16:59: Train Epoch 11: 427/634 Loss: 0.163634
2023-01-01 16:59: Train Epoch 11: 431/634 Loss: 0.157857
2023-01-01 16:59: Train Epoch 11: 435/634 Loss: 0.169668
2023-01-01 17:00: Train Epoch 11: 439/634 Loss: 0.150225
2023-01-01 17:00: Train Epoch 11: 443/634 Loss: 0.147386
2023-01-01 17:00: Train Epoch 11: 447/634 Loss: 0.147242
2023-01-01 17:01: Train Epoch 11: 451/634 Loss: 0.150755
2023-01-01 17:01: Train Epoch 11: 455/634 Loss: 0.145134
2023-01-01 17:02: Train Epoch 11: 459/634 Loss: 0.148529
2023-01-01 17:02: Train Epoch 11: 463/634 Loss: 0.144290
2023-01-01 17:02: Train Epoch 11: 467/634 Loss: 0.158953
2023-01-01 17:03: Train Epoch 11: 471/634 Loss: 0.151264
2023-01-01 17:03: Train Epoch 11: 475/634 Loss: 0.155107
2023-01-01 17:03: Train Epoch 11: 479/634 Loss: 0.187215
2023-01-01 17:04: Train Epoch 11: 483/634 Loss: 0.172428
2023-01-01 17:04: Train Epoch 11: 487/634 Loss: 0.155258
2023-01-01 17:04: Train Epoch 11: 491/634 Loss: 0.172116
2023-01-01 17:05: Train Epoch 11: 495/634 Loss: 0.170268
2023-01-01 17:05: Train Epoch 11: 499/634 Loss: 0.160274
2023-01-01 17:06: Train Epoch 11: 503/634 Loss: 0.160047
2023-01-01 17:06: Train Epoch 11: 507/634 Loss: 0.165720
2023-01-01 17:06: Train Epoch 11: 511/634 Loss: 0.147972
2023-01-01 17:07: Train Epoch 11: 515/634 Loss: 0.158592
2023-01-01 17:07: Train Epoch 11: 519/634 Loss: 0.146361
2023-01-01 17:07: Train Epoch 11: 523/634 Loss: 0.139517
2023-01-01 17:08: Train Epoch 11: 527/634 Loss: 0.167360
2023-01-01 17:08: Train Epoch 11: 531/634 Loss: 0.176141
2023-01-01 17:08: Train Epoch 11: 535/634 Loss: 0.152180
2023-01-01 17:09: Train Epoch 11: 539/634 Loss: 0.130333
2023-01-01 17:09: Train Epoch 11: 543/634 Loss: 0.191603
2023-01-01 17:09: Train Epoch 11: 547/634 Loss: 0.147045
2023-01-01 17:10: Train Epoch 11: 551/634 Loss: 0.140766
2023-01-01 17:10: Train Epoch 11: 555/634 Loss: 0.156445
2023-01-01 17:10: Train Epoch 11: 559/634 Loss: 0.177066
2023-01-01 17:11: Train Epoch 11: 563/634 Loss: 0.153939
2023-01-01 17:11: Train Epoch 11: 567/634 Loss: 0.202668
2023-01-01 17:12: Train Epoch 11: 571/634 Loss: 0.153078
2023-01-01 17:12: Train Epoch 11: 575/634 Loss: 0.151384
2023-01-01 17:12: Train Epoch 11: 579/634 Loss: 0.157814
2023-01-01 17:13: Train Epoch 11: 583/634 Loss: 0.170281
2023-01-01 17:13: Train Epoch 11: 587/634 Loss: 0.144872
2023-01-01 17:13: Train Epoch 11: 591/634 Loss: 0.121470
2023-01-01 17:14: Train Epoch 11: 595/634 Loss: 0.150117
2023-01-01 17:14: Train Epoch 11: 599/634 Loss: 0.162223
2023-01-01 17:14: Train Epoch 11: 603/634 Loss: 0.147323
2023-01-01 17:15: Train Epoch 11: 607/634 Loss: 0.170423
2023-01-01 17:15: Train Epoch 11: 611/634 Loss: 0.140195
2023-01-01 17:16: Train Epoch 11: 615/634 Loss: 0.181015
2023-01-01 17:16: Train Epoch 11: 619/634 Loss: 0.160238
2023-01-01 17:16: Train Epoch 11: 623/634 Loss: 0.146663
2023-01-01 17:17: Train Epoch 11: 627/634 Loss: 0.151551
2023-01-01 17:17: Train Epoch 11: 631/634 Loss: 0.159750
2023-01-01 17:17: Train Epoch 11: 633/634 Loss: 0.063403
2023-01-01 17:17: **********Train Epoch 11: averaged Loss: 0.164371 
2023-01-01 17:17: 
Epoch time elapsed: 3426.6422684192657

2023-01-01 17:18: 
 metrics validation: {'precision': 0.8307560137457045, 'recall': 0.7438461538461538, 'f1-score': 0.7849025974025975, 'support': 1300, 'AUC': 0.9325931952662723, 'AUCPR': 0.874600145591462, 'TP': 967, 'FP': 197, 'TN': 2403, 'FN': 333} 

2023-01-01 17:18: **********Val Epoch 11: average Loss: 0.149266
2023-01-01 17:18: *********************************Current best model saved!
2023-01-01 17:20: 
 Testing metrics {'precision': 0.8746411483253589, 'recall': 0.744299674267101, 'f1-score': 0.8042234931808183, 'support': 1228, 'AUC': 0.9328590356396355, 'AUCPR': 0.8919627656900914, 'TP': 914, 'FP': 131, 'TN': 2325, 'FN': 314} 

2023-01-01 17:25: 
 Testing metrics {'precision': 0.9164711403097138, 'recall': 0.8863172226004085, 'f1-score': 0.9011420002307071, 'support': 4407, 'AUC': 0.9785882110216286, 'AUCPR': 0.961339954119548, 'TP': 3906, 'FP': 356, 'TN': 8458, 'FN': 501} 

2023-01-01 17:25: Train Epoch 12: 3/634 Loss: 0.142117
2023-01-01 17:26: Train Epoch 12: 7/634 Loss: 0.134858
2023-01-01 17:26: Train Epoch 12: 11/634 Loss: 0.139451
2023-01-01 17:26: Train Epoch 12: 15/634 Loss: 0.153346
2023-01-01 17:27: Train Epoch 12: 19/634 Loss: 0.165145
2023-01-01 17:27: Train Epoch 12: 23/634 Loss: 0.179837
2023-01-01 17:28: Train Epoch 12: 27/634 Loss: 0.153372
2023-01-01 17:28: Train Epoch 12: 31/634 Loss: 0.144634
2023-01-01 17:28: Train Epoch 12: 35/634 Loss: 0.123850
2023-01-01 17:29: Train Epoch 12: 39/634 Loss: 0.132210
2023-01-01 17:29: Train Epoch 12: 43/634 Loss: 0.144303
2023-01-01 17:29: Train Epoch 12: 47/634 Loss: 0.187341
2023-01-01 17:30: Train Epoch 12: 51/634 Loss: 0.156400
2023-01-01 17:30: Train Epoch 12: 55/634 Loss: 0.168477
2023-01-01 17:30: Train Epoch 12: 59/634 Loss: 0.150741
2023-01-01 17:31: Train Epoch 12: 63/634 Loss: 0.147505
2023-01-01 17:31: Train Epoch 12: 67/634 Loss: 0.164294
2023-01-01 17:32: Train Epoch 12: 71/634 Loss: 0.146872
2023-01-01 17:32: Train Epoch 12: 75/634 Loss: 0.156440
2023-01-01 17:32: Train Epoch 12: 79/634 Loss: 0.148360
2023-01-01 17:33: Train Epoch 12: 83/634 Loss: 0.149377
2023-01-01 17:33: Train Epoch 12: 87/634 Loss: 0.163688
2023-01-01 17:33: Train Epoch 12: 91/634 Loss: 0.148696
2023-01-01 17:34: Train Epoch 12: 95/634 Loss: 0.135370
2023-01-01 17:34: Train Epoch 12: 99/634 Loss: 0.163628
2023-01-01 17:34: Train Epoch 12: 103/634 Loss: 0.167657
2023-01-01 17:35: Train Epoch 12: 107/634 Loss: 0.168589
2023-01-01 17:35: Train Epoch 12: 111/634 Loss: 0.185074
2023-01-01 17:35: Train Epoch 12: 115/634 Loss: 0.188573
2023-01-01 17:36: Train Epoch 12: 119/634 Loss: 0.150004
2023-01-01 17:36: Train Epoch 12: 123/634 Loss: 0.145770
2023-01-01 17:37: Train Epoch 12: 127/634 Loss: 0.129958
2023-01-01 17:37: Train Epoch 12: 131/634 Loss: 0.156056
2023-01-01 17:37: Train Epoch 12: 135/634 Loss: 0.160068
2023-01-01 17:38: Train Epoch 12: 139/634 Loss: 0.145463
2023-01-01 17:38: Train Epoch 12: 143/634 Loss: 0.165947
2023-01-01 17:38: Train Epoch 12: 147/634 Loss: 0.166173
2023-01-01 17:39: Train Epoch 12: 151/634 Loss: 0.150825
2023-01-01 17:39: Train Epoch 12: 155/634 Loss: 0.165080
2023-01-01 17:39: Train Epoch 12: 159/634 Loss: 0.155858
2023-01-01 17:40: Train Epoch 12: 163/634 Loss: 0.150665
2023-01-01 17:40: Train Epoch 12: 167/634 Loss: 0.152303
2023-01-01 17:40: Train Epoch 12: 171/634 Loss: 0.143362
2023-01-01 17:41: Train Epoch 12: 175/634 Loss: 0.153641
2023-01-01 17:41: Train Epoch 12: 179/634 Loss: 0.158845
2023-01-01 17:42: Train Epoch 12: 183/634 Loss: 0.161418
2023-01-01 17:42: Train Epoch 12: 187/634 Loss: 0.119726
2023-01-01 17:42: Train Epoch 12: 191/634 Loss: 0.174867
2023-01-01 17:43: Train Epoch 12: 195/634 Loss: 0.146918
2023-01-01 17:43: Train Epoch 12: 199/634 Loss: 0.172422
2023-01-01 17:43: Train Epoch 12: 203/634 Loss: 0.147689
2023-01-01 17:44: Train Epoch 12: 207/634 Loss: 0.147324
2023-01-01 17:44: Train Epoch 12: 211/634 Loss: 0.117765
2023-01-01 17:44: Train Epoch 12: 215/634 Loss: 0.174714
2023-01-01 17:45: Train Epoch 12: 219/634 Loss: 0.143216
2023-01-01 17:45: Train Epoch 12: 223/634 Loss: 0.161982
2023-01-01 17:45: Train Epoch 12: 227/634 Loss: 0.162175
2023-01-01 17:46: Train Epoch 12: 231/634 Loss: 0.123140
2023-01-01 17:46: Train Epoch 12: 235/634 Loss: 0.190530
2023-01-01 17:47: Train Epoch 12: 239/634 Loss: 0.168143
2023-01-01 17:47: Train Epoch 12: 243/634 Loss: 0.177228
2023-01-01 17:47: Train Epoch 12: 247/634 Loss: 0.160278
2023-01-01 17:48: Train Epoch 12: 251/634 Loss: 0.165562
2023-01-01 17:48: Train Epoch 12: 255/634 Loss: 0.137209
2023-01-01 17:48: Train Epoch 12: 259/634 Loss: 0.134056
2023-01-01 17:49: Train Epoch 12: 263/634 Loss: 0.157546
2023-01-01 17:49: Train Epoch 12: 267/634 Loss: 0.161059
2023-01-01 17:49: Train Epoch 12: 271/634 Loss: 0.179105
2023-01-01 17:50: Train Epoch 12: 275/634 Loss: 0.211815
2023-01-01 17:50: Train Epoch 12: 279/634 Loss: 0.164752
2023-01-01 17:50: Train Epoch 12: 283/634 Loss: 0.204002
2023-01-01 17:51: Train Epoch 12: 287/634 Loss: 0.157580
2023-01-01 17:51: Train Epoch 12: 291/634 Loss: 0.137079
2023-01-01 17:51: Train Epoch 12: 295/634 Loss: 0.157593
2023-01-01 17:52: Train Epoch 12: 299/634 Loss: 0.161925
2023-01-01 17:52: Train Epoch 12: 303/634 Loss: 0.143417
2023-01-01 17:52: Train Epoch 12: 307/634 Loss: 0.169705
2023-01-01 17:53: Train Epoch 12: 311/634 Loss: 0.149552
2023-01-01 17:53: Train Epoch 12: 315/634 Loss: 0.152026
2023-01-01 17:53: Train Epoch 12: 319/634 Loss: 0.173145
2023-01-01 17:54: Train Epoch 12: 323/634 Loss: 0.130733
2023-01-01 17:54: Train Epoch 12: 327/634 Loss: 0.154848
2023-01-01 17:55: Train Epoch 12: 331/634 Loss: 0.149134
2023-01-01 17:55: Train Epoch 12: 335/634 Loss: 0.133851
2023-01-01 17:55: Train Epoch 12: 339/634 Loss: 0.135172
2023-01-01 17:56: Train Epoch 12: 343/634 Loss: 0.131351
2023-01-01 17:56: Train Epoch 12: 347/634 Loss: 0.167084
2023-01-01 17:56: Train Epoch 12: 351/634 Loss: 0.144276
2023-01-01 17:57: Train Epoch 12: 355/634 Loss: 0.149627
2023-01-01 17:57: Train Epoch 12: 359/634 Loss: 0.136702
2023-01-01 17:57: Train Epoch 12: 363/634 Loss: 0.162650
2023-01-01 17:58: Train Epoch 12: 367/634 Loss: 0.154321
2023-01-01 17:58: Train Epoch 12: 371/634 Loss: 0.184527
2023-01-01 17:59: Train Epoch 12: 375/634 Loss: 0.158119
2023-01-01 17:59: Train Epoch 12: 379/634 Loss: 0.162257
2023-01-01 17:59: Train Epoch 12: 383/634 Loss: 0.158096
2023-01-01 18:00: Train Epoch 12: 387/634 Loss: 0.142176
2023-01-01 18:00: Train Epoch 12: 391/634 Loss: 0.172366
2023-01-01 18:00: Train Epoch 12: 395/634 Loss: 0.161358
2023-01-01 18:01: Train Epoch 12: 399/634 Loss: 0.151124
2023-01-01 18:01: Train Epoch 12: 403/634 Loss: 0.165303
2023-01-01 18:01: Train Epoch 12: 407/634 Loss: 0.172639
2023-01-01 18:02: Train Epoch 12: 411/634 Loss: 0.141417
2023-01-01 18:02: Train Epoch 12: 415/634 Loss: 0.140926
2023-01-01 18:03: Train Epoch 12: 419/634 Loss: 0.182377
2023-01-01 18:03: Train Epoch 12: 423/634 Loss: 0.142302
2023-01-01 18:03: Train Epoch 12: 427/634 Loss: 0.140719
2023-01-01 18:04: Train Epoch 12: 431/634 Loss: 0.152248
2023-01-01 18:04: Train Epoch 12: 435/634 Loss: 0.142188
2023-01-01 18:04: Train Epoch 12: 439/634 Loss: 0.158116
2023-01-01 18:05: Train Epoch 12: 443/634 Loss: 0.145069
2023-01-01 18:05: Train Epoch 12: 447/634 Loss: 0.129643
2023-01-01 18:05: Train Epoch 12: 451/634 Loss: 0.139090
2023-01-01 18:06: Train Epoch 12: 455/634 Loss: 0.147428
2023-01-01 18:06: Train Epoch 12: 459/634 Loss: 0.170062
2023-01-01 18:07: Train Epoch 12: 463/634 Loss: 0.159830
2023-01-01 18:07: Train Epoch 12: 467/634 Loss: 0.149139
2023-01-01 18:07: Train Epoch 12: 471/634 Loss: 0.153444
2023-01-01 18:08: Train Epoch 12: 475/634 Loss: 0.144640
2023-01-01 18:08: Train Epoch 12: 479/634 Loss: 0.137848
2023-01-01 18:08: Train Epoch 12: 483/634 Loss: 0.120078
2023-01-01 18:09: Train Epoch 12: 487/634 Loss: 0.123691
2023-01-01 18:09: Train Epoch 12: 491/634 Loss: 0.164818
2023-01-01 18:10: Train Epoch 12: 495/634 Loss: 0.186593
2023-01-01 18:10: Train Epoch 12: 499/634 Loss: 0.159863
2023-01-01 18:10: Train Epoch 12: 503/634 Loss: 0.146648
2023-01-01 18:11: Train Epoch 12: 507/634 Loss: 0.156606
2023-01-01 18:11: Train Epoch 12: 511/634 Loss: 0.156760
2023-01-01 18:11: Train Epoch 12: 515/634 Loss: 0.178170
2023-01-01 18:12: Train Epoch 12: 519/634 Loss: 0.144813
2023-01-01 18:12: Train Epoch 12: 523/634 Loss: 0.144753
2023-01-01 18:12: Train Epoch 12: 527/634 Loss: 0.144142
2023-01-01 18:13: Train Epoch 12: 531/634 Loss: 0.152957
2023-01-01 18:13: Train Epoch 12: 535/634 Loss: 0.154242
2023-01-01 18:13: Train Epoch 12: 539/634 Loss: 0.164476
2023-01-01 18:14: Train Epoch 12: 543/634 Loss: 0.146381
2023-01-01 18:14: Train Epoch 12: 547/634 Loss: 0.162343
2023-01-01 18:14: Train Epoch 12: 551/634 Loss: 0.165917
2023-01-01 18:15: Train Epoch 12: 555/634 Loss: 0.150676
2023-01-01 18:15: Train Epoch 12: 559/634 Loss: 0.170134
2023-01-01 18:16: Train Epoch 12: 563/634 Loss: 0.140102
2023-01-01 18:16: Train Epoch 12: 567/634 Loss: 0.143321
2023-01-01 18:16: Train Epoch 12: 571/634 Loss: 0.130343
2023-01-01 18:17: Train Epoch 12: 575/634 Loss: 0.146397
2023-01-01 18:17: Train Epoch 12: 579/634 Loss: 0.139642
2023-01-01 18:17: Train Epoch 12: 583/634 Loss: 0.145345
2023-01-01 18:18: Train Epoch 12: 587/634 Loss: 0.135016
2023-01-01 18:18: Train Epoch 12: 591/634 Loss: 0.154064
2023-01-01 18:18: Train Epoch 12: 595/634 Loss: 0.144717
2023-01-01 18:19: Train Epoch 12: 599/634 Loss: 0.163512
2023-01-01 18:19: Train Epoch 12: 603/634 Loss: 0.136293
2023-01-01 18:19: Train Epoch 12: 607/634 Loss: 0.172452
2023-01-01 18:20: Train Epoch 12: 611/634 Loss: 0.180451
2023-01-01 18:20: Train Epoch 12: 615/634 Loss: 0.130882
2023-01-01 18:21: Train Epoch 12: 619/634 Loss: 0.151976
2023-01-01 18:21: Train Epoch 12: 623/634 Loss: 0.145273
2023-01-01 18:21: Train Epoch 12: 627/634 Loss: 0.132932
2023-01-01 18:22: Train Epoch 12: 631/634 Loss: 0.178585
2023-01-01 18:22: Train Epoch 12: 633/634 Loss: 0.062684
2023-01-01 18:22: **********Train Epoch 12: averaged Loss: 0.153517 
2023-01-01 18:22: 
Epoch time elapsed: 3403.631378173828

2023-01-01 18:23: 
 metrics validation: {'precision': 0.727403156384505, 'recall': 0.78, 'f1-score': 0.7527839643652562, 'support': 1300, 'AUC': 0.9009008875739644, 'AUCPR': 0.8126315790295684, 'TP': 1014, 'FP': 380, 'TN': 2220, 'FN': 286} 

2023-01-01 18:23: **********Val Epoch 12: average Loss: 0.183226
2023-01-01 18:25: 
 Testing metrics {'precision': 0.8746411483253589, 'recall': 0.744299674267101, 'f1-score': 0.8042234931808183, 'support': 1228, 'AUC': 0.9328590356396355, 'AUCPR': 0.8919627656900914, 'TP': 914, 'FP': 131, 'TN': 2325, 'FN': 314} 

2023-01-01 18:30: 
 Testing metrics {'precision': 0.9164711403097138, 'recall': 0.8863172226004085, 'f1-score': 0.9011420002307071, 'support': 4407, 'AUC': 0.9785882110216286, 'AUCPR': 0.961339954119548, 'TP': 3906, 'FP': 356, 'TN': 8458, 'FN': 501} 

2023-01-01 18:30: Train Epoch 13: 3/634 Loss: 0.161886
2023-01-01 18:30: Train Epoch 13: 7/634 Loss: 0.161399
2023-01-01 18:31: Train Epoch 13: 11/634 Loss: 0.125708
2023-01-01 18:31: Train Epoch 13: 15/634 Loss: 0.133448
2023-01-01 18:31: Train Epoch 13: 19/634 Loss: 0.173721
2023-01-01 18:32: Train Epoch 13: 23/634 Loss: 0.139661
2023-01-01 18:32: Train Epoch 13: 27/634 Loss: 0.162951
2023-01-01 18:33: Train Epoch 13: 31/634 Loss: 0.158119
2023-01-01 18:33: Train Epoch 13: 35/634 Loss: 0.144781
2023-01-01 18:33: Train Epoch 13: 39/634 Loss: 0.174592
2023-01-01 18:34: Train Epoch 13: 43/634 Loss: 0.154632
2023-01-01 18:34: Train Epoch 13: 47/634 Loss: 0.158131
2023-01-01 18:34: Train Epoch 13: 51/634 Loss: 0.141512
2023-01-01 18:35: Train Epoch 13: 55/634 Loss: 0.149733
2023-01-01 18:35: Train Epoch 13: 59/634 Loss: 0.142876
2023-01-01 18:35: Train Epoch 13: 63/634 Loss: 0.157686
2023-01-01 18:36: Train Epoch 13: 67/634 Loss: 0.181195
2023-01-01 18:36: Train Epoch 13: 71/634 Loss: 0.151653
2023-01-01 18:37: Train Epoch 13: 75/634 Loss: 0.139440
2023-01-01 18:37: Train Epoch 13: 79/634 Loss: 0.156869
2023-01-01 18:37: Train Epoch 13: 83/634 Loss: 0.156056
2023-01-01 18:38: Train Epoch 13: 87/634 Loss: 0.149167
2023-01-01 18:38: Train Epoch 13: 91/634 Loss: 0.160266
2023-01-01 18:38: Train Epoch 13: 95/634 Loss: 0.158499
2023-01-01 18:39: Train Epoch 13: 99/634 Loss: 0.172035
2023-01-01 18:39: Train Epoch 13: 103/634 Loss: 0.162791
2023-01-01 18:39: Train Epoch 13: 107/634 Loss: 0.148532
2023-01-01 18:40: Train Epoch 13: 111/634 Loss: 0.169477
2023-01-01 18:40: Train Epoch 13: 115/634 Loss: 0.147447
2023-01-01 18:41: Train Epoch 13: 119/634 Loss: 0.162036
2023-01-01 18:41: Train Epoch 13: 123/634 Loss: 0.145280
2023-01-01 18:41: Train Epoch 13: 127/634 Loss: 0.155073
2023-01-01 18:42: Train Epoch 13: 131/634 Loss: 0.168127
2023-01-01 18:42: Train Epoch 13: 135/634 Loss: 0.148905
2023-01-01 18:42: Train Epoch 13: 139/634 Loss: 0.153176
2023-01-01 18:43: Train Epoch 13: 143/634 Loss: 0.158689
2023-01-01 18:43: Train Epoch 13: 147/634 Loss: 0.180444
2023-01-01 18:43: Train Epoch 13: 151/634 Loss: 0.131852
2023-01-01 18:44: Train Epoch 13: 155/634 Loss: 0.135940
2023-01-01 18:44: Train Epoch 13: 159/634 Loss: 0.170002
2023-01-01 18:44: Train Epoch 13: 163/634 Loss: 0.155931
2023-01-01 18:45: Train Epoch 13: 167/634 Loss: 0.169272
2023-01-01 18:45: Train Epoch 13: 171/634 Loss: 0.160601
2023-01-01 18:46: Train Epoch 13: 175/634 Loss: 0.182523
2023-01-01 18:46: Train Epoch 13: 179/634 Loss: 0.191377
2023-01-01 18:46: Train Epoch 13: 183/634 Loss: 0.168831
2023-01-01 18:47: Train Epoch 13: 187/634 Loss: 0.210582
2023-01-01 18:47: Train Epoch 13: 191/634 Loss: 0.159064
2023-01-01 18:47: Train Epoch 13: 195/634 Loss: 0.178624
2023-01-01 18:48: Train Epoch 13: 199/634 Loss: 0.184896
2023-01-01 18:48: Train Epoch 13: 203/634 Loss: 0.145724
2023-01-01 18:48: Train Epoch 13: 207/634 Loss: 0.150095
2023-01-01 18:49: Train Epoch 13: 211/634 Loss: 0.166713
2023-01-01 18:49: Train Epoch 13: 215/634 Loss: 0.124748
2023-01-01 18:50: Train Epoch 13: 219/634 Loss: 0.153999
2023-01-01 18:50: Train Epoch 13: 223/634 Loss: 0.173076
2023-01-01 18:50: Train Epoch 13: 227/634 Loss: 0.164110
2023-01-01 18:51: Train Epoch 13: 231/634 Loss: 0.169316
2023-01-01 18:51: Train Epoch 13: 235/634 Loss: 0.168960
2023-01-01 18:51: Train Epoch 13: 239/634 Loss: 0.146887
2023-01-01 18:52: Train Epoch 13: 243/634 Loss: 0.141375
2023-01-01 18:52: Train Epoch 13: 247/634 Loss: 0.143516
2023-01-01 18:52: Train Epoch 13: 251/634 Loss: 0.168627
2023-01-01 18:53: Train Epoch 13: 255/634 Loss: 0.163400
2023-01-01 18:53: Train Epoch 13: 259/634 Loss: 0.134834
2023-01-01 18:54: Train Epoch 13: 263/634 Loss: 0.143064
2023-01-01 18:54: Train Epoch 13: 267/634 Loss: 0.148603
2023-01-01 18:54: Train Epoch 13: 271/634 Loss: 0.150491
2023-01-01 18:55: Train Epoch 13: 275/634 Loss: 0.144194
2023-01-01 18:55: Train Epoch 13: 279/634 Loss: 0.148755
2023-01-01 18:55: Train Epoch 13: 283/634 Loss: 0.148467
2023-01-01 18:56: Train Epoch 13: 287/634 Loss: 0.142286
2023-01-01 18:56: Train Epoch 13: 291/634 Loss: 0.152275
2023-01-01 18:57: Train Epoch 13: 295/634 Loss: 0.150523
2023-01-01 18:57: Train Epoch 13: 299/634 Loss: 0.153448
2023-01-01 18:57: Train Epoch 13: 303/634 Loss: 0.151073
2023-01-01 18:58: Train Epoch 13: 307/634 Loss: 0.154244
2023-01-01 18:58: Train Epoch 13: 311/634 Loss: 0.147311
2023-01-01 18:58: Train Epoch 13: 315/634 Loss: 0.183540
2023-01-01 18:59: Train Epoch 13: 319/634 Loss: 0.144247
2023-01-01 18:59: Train Epoch 13: 323/634 Loss: 0.181230
2023-01-01 18:59: Train Epoch 13: 327/634 Loss: 0.158849
2023-01-01 19:00: Train Epoch 13: 331/634 Loss: 0.160764
2023-01-01 19:00: Train Epoch 13: 335/634 Loss: 0.126064
2023-01-01 19:00: Train Epoch 13: 339/634 Loss: 0.182230
2023-01-01 19:01: Train Epoch 13: 343/634 Loss: 0.158838
2023-01-01 19:01: Train Epoch 13: 347/634 Loss: 0.146654
2023-01-01 19:02: Train Epoch 13: 351/634 Loss: 0.191362
2023-01-01 19:02: Train Epoch 13: 355/634 Loss: 0.152776
2023-01-01 19:02: Train Epoch 13: 359/634 Loss: 0.154167
2023-01-01 19:03: Train Epoch 13: 363/634 Loss: 0.150493
2023-01-01 19:03: Train Epoch 13: 367/634 Loss: 0.158263
2023-01-01 19:03: Train Epoch 13: 371/634 Loss: 0.178772
2023-01-01 19:04: Train Epoch 13: 375/634 Loss: 0.132286
2023-01-01 19:04: Train Epoch 13: 379/634 Loss: 0.167056
2023-01-01 19:04: Train Epoch 13: 383/634 Loss: 0.164883
2023-01-01 19:05: Train Epoch 13: 387/634 Loss: 0.159275
2023-01-01 19:05: Train Epoch 13: 391/634 Loss: 0.136266
2023-01-01 19:06: Train Epoch 13: 395/634 Loss: 0.172119
2023-01-01 19:06: Train Epoch 13: 399/634 Loss: 0.129840
2023-01-01 19:06: Train Epoch 13: 403/634 Loss: 0.145932
2023-01-01 19:07: Train Epoch 13: 407/634 Loss: 0.169132
2023-01-01 19:07: Train Epoch 13: 411/634 Loss: 0.171465
2023-01-01 19:07: Train Epoch 13: 415/634 Loss: 0.140028
2023-01-01 19:08: Train Epoch 13: 419/634 Loss: 0.159842
2023-01-01 19:08: Train Epoch 13: 423/634 Loss: 0.152353
2023-01-01 19:08: Train Epoch 13: 427/634 Loss: 0.148972
2023-01-01 19:09: Train Epoch 13: 431/634 Loss: 0.155873
2023-01-01 19:09: Train Epoch 13: 435/634 Loss: 0.207577
2023-01-01 19:10: Train Epoch 13: 439/634 Loss: 0.183917
2023-01-01 19:10: Train Epoch 13: 443/634 Loss: 0.152449
2023-01-01 19:10: Train Epoch 13: 447/634 Loss: 0.160527
2023-01-01 19:11: Train Epoch 13: 451/634 Loss: 0.137183
2023-01-01 19:11: Train Epoch 13: 455/634 Loss: 0.170346
2023-01-01 19:11: Train Epoch 13: 459/634 Loss: 0.149670
2023-01-01 19:12: Train Epoch 13: 463/634 Loss: 0.159979
2023-01-01 19:12: Train Epoch 13: 467/634 Loss: 0.137233
2023-01-01 19:12: Train Epoch 13: 471/634 Loss: 0.154096
2023-01-01 19:13: Train Epoch 13: 475/634 Loss: 0.128473
2023-01-01 19:13: Train Epoch 13: 479/634 Loss: 0.160441
2023-01-01 19:14: Train Epoch 13: 483/634 Loss: 0.135214
2023-01-01 19:14: Train Epoch 13: 487/634 Loss: 0.152992
2023-01-01 19:14: Train Epoch 13: 491/634 Loss: 0.143072
2023-01-01 19:15: Train Epoch 13: 495/634 Loss: 0.149358
2023-01-01 19:15: Train Epoch 13: 499/634 Loss: 0.174329
2023-01-01 19:15: Train Epoch 13: 503/634 Loss: 0.166514
2023-01-01 19:16: Train Epoch 13: 507/634 Loss: 0.164799
2023-01-01 19:16: Train Epoch 13: 511/634 Loss: 0.152255
2023-01-01 19:16: Train Epoch 13: 515/634 Loss: 0.156842
2023-01-01 19:17: Train Epoch 13: 519/634 Loss: 0.174400
2023-01-01 19:17: Train Epoch 13: 523/634 Loss: 0.166967
2023-01-01 19:17: Train Epoch 13: 527/634 Loss: 0.152035
2023-01-01 19:18: Train Epoch 13: 531/634 Loss: 0.155572
2023-01-01 19:18: Train Epoch 13: 535/634 Loss: 0.172433
2023-01-01 19:19: Train Epoch 13: 539/634 Loss: 0.188568
2023-01-01 19:19: Train Epoch 13: 543/634 Loss: 0.139653
2023-01-01 19:19: Train Epoch 13: 547/634 Loss: 0.179766
2023-01-01 19:20: Train Epoch 13: 551/634 Loss: 0.156694
2023-01-01 19:20: Train Epoch 13: 555/634 Loss: 0.154819
2023-01-01 19:20: Train Epoch 13: 559/634 Loss: 0.168850
2023-01-01 19:21: Train Epoch 13: 563/634 Loss: 0.152065
2023-01-01 19:21: Train Epoch 13: 567/634 Loss: 0.170996
2023-01-01 19:21: Train Epoch 13: 571/634 Loss: 0.163199
2023-01-01 19:22: Train Epoch 13: 575/634 Loss: 0.171311
2023-01-01 19:22: Train Epoch 13: 579/634 Loss: 0.135456
2023-01-01 19:23: Train Epoch 13: 583/634 Loss: 0.130568
2023-01-01 19:23: Train Epoch 13: 587/634 Loss: 0.136603
2023-01-01 19:23: Train Epoch 13: 591/634 Loss: 0.147349
2023-01-01 19:24: Train Epoch 13: 595/634 Loss: 0.146970
2023-01-01 19:24: Train Epoch 13: 599/634 Loss: 0.141494
2023-01-01 19:24: Train Epoch 13: 603/634 Loss: 0.144041
2023-01-01 19:25: Train Epoch 13: 607/634 Loss: 0.140851
2023-01-01 19:25: Train Epoch 13: 611/634 Loss: 0.165876
2023-01-01 19:25: Train Epoch 13: 615/634 Loss: 0.134131
2023-01-01 19:26: Train Epoch 13: 619/634 Loss: 0.154366
2023-01-01 19:26: Train Epoch 13: 623/634 Loss: 0.149532
2023-01-01 19:26: Train Epoch 13: 627/634 Loss: 0.158558
2023-01-01 19:27: Train Epoch 13: 631/634 Loss: 0.146733
2023-01-01 19:27: Train Epoch 13: 633/634 Loss: 0.050357
2023-01-01 19:27: **********Train Epoch 13: averaged Loss: 0.155954 
2023-01-01 19:27: 
Epoch time elapsed: 3437.320107460022

2023-01-01 19:28: 
 metrics validation: {'precision': 0.8227960819234195, 'recall': 0.7107692307692308, 'f1-score': 0.7626908790755264, 'support': 1300, 'AUC': 0.9269263313609466, 'AUCPR': 0.8645923496093773, 'TP': 924, 'FP': 199, 'TN': 2401, 'FN': 376} 

2023-01-01 19:28: **********Val Epoch 13: average Loss: 0.157893
2023-01-01 19:30: 
 Testing metrics {'precision': 0.8746411483253589, 'recall': 0.744299674267101, 'f1-score': 0.8042234931808183, 'support': 1228, 'AUC': 0.9328590356396355, 'AUCPR': 0.8919627656900914, 'TP': 914, 'FP': 131, 'TN': 2325, 'FN': 314} 

2023-01-01 19:35: 
 Testing metrics {'precision': 0.9164711403097138, 'recall': 0.8863172226004085, 'f1-score': 0.9011420002307071, 'support': 4407, 'AUC': 0.9785882110216286, 'AUCPR': 0.961339954119548, 'TP': 3906, 'FP': 356, 'TN': 8458, 'FN': 501} 

2023-01-01 19:35: Train Epoch 14: 3/634 Loss: 0.156576
2023-01-01 19:35: Train Epoch 14: 7/634 Loss: 0.138645
2023-01-01 19:36: Train Epoch 14: 11/634 Loss: 0.156166
2023-01-01 19:36: Train Epoch 14: 15/634 Loss: 0.172281
2023-01-01 19:36: Train Epoch 14: 19/634 Loss: 0.186859
2023-01-01 19:37: Train Epoch 14: 23/634 Loss: 0.154892
2023-01-01 19:37: Train Epoch 14: 27/634 Loss: 0.156895
2023-01-01 19:38: Train Epoch 14: 31/634 Loss: 0.156670
2023-01-01 19:38: Train Epoch 14: 35/634 Loss: 0.161918
2023-01-01 19:38: Train Epoch 14: 39/634 Loss: 0.175328
2023-01-01 19:39: Train Epoch 14: 43/634 Loss: 0.163830
2023-01-01 19:39: Train Epoch 14: 47/634 Loss: 0.167644
2023-01-01 19:39: Train Epoch 14: 51/634 Loss: 0.151493
2023-01-01 19:40: Train Epoch 14: 55/634 Loss: 0.182244
2023-01-01 19:40: Train Epoch 14: 59/634 Loss: 0.159029
2023-01-01 19:40: Train Epoch 14: 63/634 Loss: 0.154348
2023-01-01 19:41: Train Epoch 14: 67/634 Loss: 0.142402
2023-01-01 19:41: Train Epoch 14: 71/634 Loss: 0.162230
2023-01-01 19:41: Train Epoch 14: 75/634 Loss: 0.165185
2023-01-01 19:42: Train Epoch 14: 79/634 Loss: 0.180764
2023-01-01 19:42: Train Epoch 14: 83/634 Loss: 0.157889
2023-01-01 19:43: Train Epoch 14: 87/634 Loss: 0.147798
2023-01-01 19:43: Train Epoch 14: 91/634 Loss: 0.166220
2023-01-01 19:43: Train Epoch 14: 95/634 Loss: 0.148546
2023-01-01 19:44: Train Epoch 14: 99/634 Loss: 0.164964
2023-01-01 19:44: Train Epoch 14: 103/634 Loss: 0.142265
2023-01-01 19:44: Train Epoch 14: 107/634 Loss: 0.139651
2023-01-01 19:45: Train Epoch 14: 111/634 Loss: 0.163594
2023-01-01 19:45: Train Epoch 14: 115/634 Loss: 0.132516
2023-01-01 19:45: Train Epoch 14: 119/634 Loss: 0.142448
2023-01-01 19:46: Train Epoch 14: 123/634 Loss: 0.180796
2023-01-01 19:46: Train Epoch 14: 127/634 Loss: 0.151240
2023-01-01 19:46: Train Epoch 14: 131/634 Loss: 0.150059
2023-01-01 19:47: Train Epoch 14: 135/634 Loss: 0.167549
2023-01-01 19:47: Train Epoch 14: 139/634 Loss: 0.155791
2023-01-01 19:47: Train Epoch 14: 143/634 Loss: 0.147981
2023-01-01 19:48: Train Epoch 14: 147/634 Loss: 0.152321
2023-01-01 19:48: Train Epoch 14: 151/634 Loss: 0.155553
2023-01-01 19:49: Train Epoch 14: 155/634 Loss: 0.159462
2023-01-01 19:49: Train Epoch 14: 159/634 Loss: 0.181245
2023-01-01 19:49: Train Epoch 14: 163/634 Loss: 0.142708
2023-01-01 19:50: Train Epoch 14: 167/634 Loss: 0.135432
2023-01-01 19:50: Train Epoch 14: 171/634 Loss: 0.156631
2023-01-01 19:50: Train Epoch 14: 175/634 Loss: 0.165980
2023-01-01 19:51: Train Epoch 14: 179/634 Loss: 0.126743
2023-01-01 19:51: Train Epoch 14: 183/634 Loss: 0.165561
2023-01-01 19:51: Train Epoch 14: 187/634 Loss: 0.152370
2023-01-01 19:52: Train Epoch 14: 191/634 Loss: 0.166946
2023-01-01 19:52: Train Epoch 14: 195/634 Loss: 0.177248
2023-01-01 19:52: Train Epoch 14: 199/634 Loss: 0.197006
2023-01-01 19:53: Train Epoch 14: 203/634 Loss: 0.184291
2023-01-01 19:53: Train Epoch 14: 207/634 Loss: 0.186854
2023-01-01 19:54: Train Epoch 14: 211/634 Loss: 0.149423
2023-01-01 19:54: Train Epoch 14: 215/634 Loss: 0.143081
2023-01-01 19:54: Train Epoch 14: 219/634 Loss: 0.196057
2023-01-01 19:55: Train Epoch 14: 223/634 Loss: 0.150554
2023-01-01 19:55: Train Epoch 14: 227/634 Loss: 0.187624
2023-01-01 19:55: Train Epoch 14: 231/634 Loss: 0.143283
2023-01-01 19:56: Train Epoch 14: 235/634 Loss: 0.140982
2023-01-01 19:56: Train Epoch 14: 239/634 Loss: 0.160970
2023-01-01 19:57: Train Epoch 14: 243/634 Loss: 0.163035
2023-01-01 19:57: Train Epoch 14: 247/634 Loss: 0.161282
2023-01-01 19:57: Train Epoch 14: 251/634 Loss: 0.166222
2023-01-01 19:58: Train Epoch 14: 255/634 Loss: 0.141573
2023-01-01 19:58: Train Epoch 14: 259/634 Loss: 0.177129
2023-01-01 19:58: Train Epoch 14: 263/634 Loss: 0.138323
2023-01-01 19:59: Train Epoch 14: 267/634 Loss: 0.150830
2023-01-01 19:59: Train Epoch 14: 271/634 Loss: 0.165545
2023-01-01 19:59: Train Epoch 14: 275/634 Loss: 0.151013
2023-01-01 20:00: Train Epoch 14: 279/634 Loss: 0.144749
2023-01-01 20:00: Train Epoch 14: 283/634 Loss: 0.182646
2023-01-01 20:01: Train Epoch 14: 287/634 Loss: 0.150108
2023-01-01 20:01: Train Epoch 14: 291/634 Loss: 0.166709
2023-01-01 20:01: Train Epoch 14: 295/634 Loss: 0.152134
2023-01-01 20:02: Train Epoch 14: 299/634 Loss: 0.158337
2023-01-01 20:02: Train Epoch 14: 303/634 Loss: 0.150581
2023-01-01 20:02: Train Epoch 14: 307/634 Loss: 0.185344
2023-01-01 20:03: Train Epoch 14: 311/634 Loss: 0.137431
2023-01-01 20:03: Train Epoch 14: 315/634 Loss: 0.150539
2023-01-01 20:03: Train Epoch 14: 319/634 Loss: 0.162635
2023-01-01 20:04: Train Epoch 14: 323/634 Loss: 0.150236
2023-01-01 20:04: Train Epoch 14: 327/634 Loss: 0.157167
2023-01-01 20:05: Train Epoch 14: 331/634 Loss: 0.195708
2023-01-01 20:05: Train Epoch 14: 335/634 Loss: 0.175323
2023-01-01 20:05: Train Epoch 14: 339/634 Loss: 0.152897
2023-01-01 20:06: Train Epoch 14: 343/634 Loss: 0.188212
2023-01-01 20:06: Train Epoch 14: 347/634 Loss: 0.166819
2023-01-01 20:06: Train Epoch 14: 351/634 Loss: 0.164562
2023-01-01 20:07: Train Epoch 14: 355/634 Loss: 0.150808
2023-01-01 20:07: Train Epoch 14: 359/634 Loss: 0.142645
2023-01-01 20:08: Train Epoch 14: 363/634 Loss: 0.136053
2023-01-01 20:08: Train Epoch 14: 367/634 Loss: 0.169859
2023-01-01 20:08: Train Epoch 14: 371/634 Loss: 0.132399
2023-01-01 20:09: Train Epoch 14: 375/634 Loss: 0.162722
2023-01-01 20:09: Train Epoch 14: 379/634 Loss: 0.146970
2023-01-01 20:09: Train Epoch 14: 383/634 Loss: 0.171585
2023-01-01 20:10: Train Epoch 14: 387/634 Loss: 0.159190
2023-01-01 20:10: Train Epoch 14: 391/634 Loss: 0.176982
2023-01-01 20:11: Train Epoch 14: 395/634 Loss: 0.158378
2023-01-01 20:11: Train Epoch 14: 399/634 Loss: 0.158304
2023-01-01 20:11: Train Epoch 14: 403/634 Loss: 0.180239
2023-01-01 20:12: Train Epoch 14: 407/634 Loss: 0.171139
2023-01-01 20:12: Train Epoch 14: 411/634 Loss: 0.170781
2023-01-01 20:12: Train Epoch 14: 415/634 Loss: 0.201317
2023-01-01 20:13: Train Epoch 14: 419/634 Loss: 0.174924
2023-01-01 20:13: Train Epoch 14: 423/634 Loss: 0.171336
2023-01-01 20:13: Train Epoch 14: 427/634 Loss: 0.175020
2023-01-01 20:14: Train Epoch 14: 431/634 Loss: 0.140683
2023-01-01 20:14: Train Epoch 14: 435/634 Loss: 0.151657
2023-01-01 20:15: Train Epoch 14: 439/634 Loss: 0.177617
2023-01-01 20:15: Train Epoch 14: 443/634 Loss: 0.193266
2023-01-01 20:15: Train Epoch 14: 447/634 Loss: 0.135462
2023-01-01 20:16: Train Epoch 14: 451/634 Loss: 0.167095
2023-01-01 20:16: Train Epoch 14: 455/634 Loss: 0.179231
2023-01-01 20:16: Train Epoch 14: 459/634 Loss: 0.156145
2023-01-01 20:17: Train Epoch 14: 463/634 Loss: 0.133697
2023-01-01 20:17: Train Epoch 14: 467/634 Loss: 0.152248
2023-01-01 20:17: Train Epoch 14: 471/634 Loss: 0.128034
2023-01-01 20:18: Train Epoch 14: 475/634 Loss: 0.165334
2023-01-01 20:18: Train Epoch 14: 479/634 Loss: 0.151147
2023-01-01 20:19: Train Epoch 14: 483/634 Loss: 0.149730
2023-01-01 20:19: Train Epoch 14: 487/634 Loss: 0.164110
2023-01-01 20:19: Train Epoch 14: 491/634 Loss: 0.145844
2023-01-01 20:20: Train Epoch 14: 495/634 Loss: 0.177579
2023-01-01 20:20: Train Epoch 14: 499/634 Loss: 0.153041
2023-01-01 20:20: Train Epoch 14: 503/634 Loss: 0.152501
2023-01-01 20:21: Train Epoch 14: 507/634 Loss: 0.201056
2023-01-01 20:21: Train Epoch 14: 511/634 Loss: 0.135345
2023-01-01 20:21: Train Epoch 14: 515/634 Loss: 0.142724
2023-01-01 20:22: Train Epoch 14: 519/634 Loss: 0.154559
2023-01-01 20:22: Train Epoch 14: 523/634 Loss: 0.180594
2023-01-01 20:23: Train Epoch 14: 527/634 Loss: 0.147292
2023-01-01 20:23: Train Epoch 14: 531/634 Loss: 0.170565
2023-01-01 20:23: Train Epoch 14: 535/634 Loss: 0.152975
2023-01-01 20:24: Train Epoch 14: 539/634 Loss: 0.154337
2023-01-01 20:24: Train Epoch 14: 543/634 Loss: 0.177634
2023-01-01 20:24: Train Epoch 14: 547/634 Loss: 0.156454
2023-01-01 20:25: Train Epoch 14: 551/634 Loss: 0.188543
2023-01-01 20:25: Train Epoch 14: 555/634 Loss: 0.165277
2023-01-01 20:25: Train Epoch 14: 559/634 Loss: 0.167411
2023-01-01 20:26: Train Epoch 14: 563/634 Loss: 0.163872
2023-01-01 20:26: Train Epoch 14: 567/634 Loss: 0.201577
2023-01-01 20:27: Train Epoch 14: 571/634 Loss: 0.209130
2023-01-01 20:27: Train Epoch 14: 575/634 Loss: 0.201924
2023-01-01 20:27: Train Epoch 14: 579/634 Loss: 0.200411
2023-01-01 20:28: Train Epoch 14: 583/634 Loss: 0.142475
2023-01-01 20:28: Train Epoch 14: 587/634 Loss: 0.162076
2023-01-01 20:28: Train Epoch 14: 591/634 Loss: 0.227147
2023-01-01 20:29: Train Epoch 14: 595/634 Loss: 0.145833
2023-01-01 20:29: Train Epoch 14: 599/634 Loss: 0.140905
2023-01-01 20:30: Train Epoch 14: 603/634 Loss: 0.211970
2023-01-01 20:30: Train Epoch 14: 607/634 Loss: 0.173930
2023-01-01 20:30: Train Epoch 14: 611/634 Loss: 0.153968
2023-01-01 20:31: Train Epoch 14: 615/634 Loss: 0.231631
2023-01-01 20:31: Train Epoch 14: 619/634 Loss: 0.159302
2023-01-01 20:31: Train Epoch 14: 623/634 Loss: 0.163375
2023-01-01 20:32: Train Epoch 14: 627/634 Loss: 0.140439
2023-01-01 20:32: Train Epoch 14: 631/634 Loss: 0.178130
2023-01-01 20:32: Train Epoch 14: 633/634 Loss: 0.060169
2023-01-01 20:32: **********Train Epoch 14: averaged Loss: 0.161876 
2023-01-01 20:32: 
Epoch time elapsed: 3452.954149723053

2023-01-01 20:34: 
 metrics validation: {'precision': 0.9166666666666666, 'recall': 0.4230769230769231, 'f1-score': 0.5789473684210527, 'support': 1300, 'AUC': 0.9248795857988165, 'AUCPR': 0.8605826089356032, 'TP': 550, 'FP': 50, 'TN': 2550, 'FN': 750} 

2023-01-01 20:34: **********Val Epoch 14: average Loss: 0.228192
2023-01-01 20:35: 
 Testing metrics {'precision': 0.8746411483253589, 'recall': 0.744299674267101, 'f1-score': 0.8042234931808183, 'support': 1228, 'AUC': 0.9328590356396355, 'AUCPR': 0.8919627656900914, 'TP': 914, 'FP': 131, 'TN': 2325, 'FN': 314} 

2023-01-01 20:40: 
 Testing metrics {'precision': 0.9164711403097138, 'recall': 0.8863172226004085, 'f1-score': 0.9011420002307071, 'support': 4407, 'AUC': 0.9785882110216286, 'AUCPR': 0.961339954119548, 'TP': 3906, 'FP': 356, 'TN': 8458, 'FN': 501} 

2023-01-01 20:40: Train Epoch 15: 3/634 Loss: 0.134968
2023-01-01 20:41: Train Epoch 15: 7/634 Loss: 0.178952
2023-01-01 20:41: Train Epoch 15: 11/634 Loss: 0.143653
2023-01-01 20:41: Train Epoch 15: 15/634 Loss: 0.152064
2023-01-01 20:42: Train Epoch 15: 19/634 Loss: 0.133852
2023-01-01 20:42: Train Epoch 15: 23/634 Loss: 0.152317
2023-01-01 20:42: Train Epoch 15: 27/634 Loss: 0.163273
2023-01-01 20:43: Train Epoch 15: 31/634 Loss: 0.193112
2023-01-01 20:43: Train Epoch 15: 35/634 Loss: 0.164244
2023-01-01 20:44: Train Epoch 15: 39/634 Loss: 0.185771
2023-01-01 20:44: Train Epoch 15: 43/634 Loss: 0.170741
2023-01-01 20:44: Train Epoch 15: 47/634 Loss: 0.154659
2023-01-01 20:45: Train Epoch 15: 51/634 Loss: 0.172122
2023-01-01 20:45: Train Epoch 15: 55/634 Loss: 0.152034
2023-01-01 20:45: Train Epoch 15: 59/634 Loss: 0.164671
2023-01-01 20:46: Train Epoch 15: 63/634 Loss: 0.178851
2023-01-01 20:46: Train Epoch 15: 67/634 Loss: 0.176486
2023-01-01 20:46: Train Epoch 15: 71/634 Loss: 0.127342
2023-01-01 20:47: Train Epoch 15: 75/634 Loss: 0.164370
2023-01-01 20:47: Train Epoch 15: 79/634 Loss: 0.172999
2023-01-01 20:47: Train Epoch 15: 83/634 Loss: 0.156182
2023-01-01 20:48: Train Epoch 15: 87/634 Loss: 0.164201
2023-01-01 20:48: Train Epoch 15: 91/634 Loss: 0.149674
2023-01-01 20:48: Train Epoch 15: 95/634 Loss: 0.144490
2023-01-01 20:49: Train Epoch 15: 99/634 Loss: 0.151028
2023-01-01 20:49: Train Epoch 15: 103/634 Loss: 0.140866
2023-01-01 20:49: Train Epoch 15: 107/634 Loss: 0.148512
2023-01-01 20:50: Train Epoch 15: 111/634 Loss: 0.158508
2023-01-01 20:50: Train Epoch 15: 115/634 Loss: 0.194341
2023-01-01 20:50: Train Epoch 15: 119/634 Loss: 0.149465
2023-01-01 20:51: Train Epoch 15: 123/634 Loss: 0.132490
2023-01-01 20:51: Train Epoch 15: 127/634 Loss: 0.143297
2023-01-01 20:51: Train Epoch 15: 131/634 Loss: 0.149921
2023-01-01 20:52: Train Epoch 15: 135/634 Loss: 0.196353
2023-01-01 20:52: Train Epoch 15: 139/634 Loss: 0.147468
2023-01-01 20:52: Train Epoch 15: 143/634 Loss: 0.167597
2023-01-01 20:53: Train Epoch 15: 147/634 Loss: 0.127372
2023-01-01 20:53: Train Epoch 15: 151/634 Loss: 0.152492
2023-01-01 20:54: Train Epoch 15: 155/634 Loss: 0.148983
2023-01-01 20:54: Train Epoch 15: 159/634 Loss: 0.153537
2023-01-01 20:54: Train Epoch 15: 163/634 Loss: 0.161530
2023-01-01 20:55: Train Epoch 15: 167/634 Loss: 0.156299
2023-01-01 20:55: Train Epoch 15: 171/634 Loss: 0.141199
2023-01-01 20:55: Train Epoch 15: 175/634 Loss: 0.151352
2023-01-01 20:56: Train Epoch 15: 179/634 Loss: 0.142071
2023-01-01 20:56: Train Epoch 15: 183/634 Loss: 0.195709
2023-01-01 20:56: Train Epoch 15: 187/634 Loss: 0.150135
2023-01-01 20:57: Train Epoch 15: 191/634 Loss: 0.163386
2023-01-01 20:57: Train Epoch 15: 195/634 Loss: 0.155862
2023-01-01 20:57: Train Epoch 15: 199/634 Loss: 0.146895
2023-01-01 20:58: Train Epoch 15: 203/634 Loss: 0.165116
2023-01-01 20:58: Train Epoch 15: 207/634 Loss: 0.145272
2023-01-01 20:58: Train Epoch 15: 211/634 Loss: 0.137355
2023-01-01 20:59: Train Epoch 15: 215/634 Loss: 0.173369
2023-01-01 20:59: Train Epoch 15: 219/634 Loss: 0.149621
2023-01-01 20:59: Train Epoch 15: 223/634 Loss: 0.182555
2023-01-01 21:00: Train Epoch 15: 227/634 Loss: 0.149481
2023-01-01 21:00: Train Epoch 15: 231/634 Loss: 0.150292
2023-01-01 21:00: Train Epoch 15: 235/634 Loss: 0.135484
2023-01-01 21:01: Train Epoch 15: 239/634 Loss: 0.134716
2023-01-01 21:01: Train Epoch 15: 243/634 Loss: 0.152618
2023-01-01 21:01: Train Epoch 15: 247/634 Loss: 0.141585
2023-01-01 21:02: Train Epoch 15: 251/634 Loss: 0.147449
2023-01-01 21:02: Train Epoch 15: 255/634 Loss: 0.162349
2023-01-01 21:02: Train Epoch 15: 259/634 Loss: 0.163379
2023-01-01 21:03: Train Epoch 15: 263/634 Loss: 0.173233
2023-01-01 21:03: Train Epoch 15: 267/634 Loss: 0.148934
2023-01-01 21:03: Train Epoch 15: 271/634 Loss: 0.143209
2023-01-01 21:04: Train Epoch 15: 275/634 Loss: 0.158808
2023-01-01 21:04: Train Epoch 15: 279/634 Loss: 0.180410
2023-01-01 21:04: Train Epoch 15: 283/634 Loss: 0.146497
2023-01-01 21:05: Train Epoch 15: 287/634 Loss: 0.158576
2023-01-01 21:05: Train Epoch 15: 291/634 Loss: 0.132517
2023-01-01 21:05: Train Epoch 15: 295/634 Loss: 0.177746
2023-01-01 21:06: Train Epoch 15: 299/634 Loss: 0.137782
2023-01-01 21:06: Train Epoch 15: 303/634 Loss: 0.130356
2023-01-01 21:06: Train Epoch 15: 307/634 Loss: 0.142903
2023-01-01 21:07: Train Epoch 15: 311/634 Loss: 0.164825
2023-01-01 21:07: Train Epoch 15: 315/634 Loss: 0.163270
2023-01-01 21:07: Train Epoch 15: 319/634 Loss: 0.153513
2023-01-01 21:08: Train Epoch 15: 323/634 Loss: 0.155825
2023-01-01 21:08: Train Epoch 15: 327/634 Loss: 0.153802
2023-01-01 21:09: Train Epoch 15: 331/634 Loss: 0.179371
2023-01-01 21:09: Train Epoch 15: 335/634 Loss: 0.131927
2023-01-01 21:09: Train Epoch 15: 339/634 Loss: 0.164287
2023-01-01 21:10: Train Epoch 15: 343/634 Loss: 0.143632
2023-01-01 21:10: Train Epoch 15: 347/634 Loss: 0.155026
2023-01-01 21:10: Train Epoch 15: 351/634 Loss: 0.158295
2023-01-01 21:11: Train Epoch 15: 355/634 Loss: 0.184025
2023-01-01 21:11: Train Epoch 15: 359/634 Loss: 0.161888
2023-01-01 21:11: Train Epoch 15: 363/634 Loss: 0.148832
2023-01-01 21:12: Train Epoch 15: 367/634 Loss: 0.148793
2023-01-01 21:12: Train Epoch 15: 371/634 Loss: 0.170474
2023-01-01 21:13: Train Epoch 15: 375/634 Loss: 0.133002
2023-01-01 21:13: Train Epoch 15: 379/634 Loss: 0.159204
2023-01-01 21:13: Train Epoch 15: 383/634 Loss: 0.133425
2023-01-01 21:14: Train Epoch 15: 387/634 Loss: 0.143964
2023-01-01 21:14: Train Epoch 15: 391/634 Loss: 0.145791
2023-01-01 21:14: Train Epoch 15: 395/634 Loss: 0.191331
2023-01-01 21:15: Train Epoch 15: 399/634 Loss: 0.135187
2023-01-01 21:15: Train Epoch 15: 403/634 Loss: 0.160131
2023-01-01 21:15: Train Epoch 15: 407/634 Loss: 0.171045
2023-01-01 21:16: Train Epoch 15: 411/634 Loss: 0.179935
2023-01-01 21:16: Train Epoch 15: 415/634 Loss: 0.156176
2023-01-01 21:17: Train Epoch 15: 419/634 Loss: 0.135213
2023-01-01 21:17: Train Epoch 15: 423/634 Loss: 0.127547
2023-01-01 21:17: Train Epoch 15: 427/634 Loss: 0.153950
2023-01-01 21:18: Train Epoch 15: 431/634 Loss: 0.154287
2023-01-01 21:18: Train Epoch 15: 435/634 Loss: 0.168126
2023-01-01 21:18: Train Epoch 15: 439/634 Loss: 0.174203
2023-01-01 21:19: Train Epoch 15: 443/634 Loss: 0.144167
2023-01-01 21:19: Train Epoch 15: 447/634 Loss: 0.156402
2023-01-01 21:19: Train Epoch 15: 451/634 Loss: 0.171539
2023-01-01 21:20: Train Epoch 15: 455/634 Loss: 0.159421
2023-01-01 21:20: Train Epoch 15: 459/634 Loss: 0.123029
2023-01-01 21:20: Train Epoch 15: 463/634 Loss: 0.132936
2023-01-01 21:21: Train Epoch 15: 467/634 Loss: 0.195415
2023-01-01 21:21: Train Epoch 15: 471/634 Loss: 0.177731
2023-01-01 21:21: Train Epoch 15: 475/634 Loss: 0.154654
2023-01-01 21:22: Train Epoch 15: 479/634 Loss: 0.134562
2023-01-01 21:22: Train Epoch 15: 483/634 Loss: 0.144334
2023-01-01 21:23: Train Epoch 15: 487/634 Loss: 0.177086
2023-01-01 21:23: Train Epoch 15: 491/634 Loss: 0.149279
2023-01-01 21:23: Train Epoch 15: 495/634 Loss: 0.177748
2023-01-01 21:24: Train Epoch 15: 499/634 Loss: 0.209147
2023-01-01 21:24: Train Epoch 15: 503/634 Loss: 0.178216
2023-01-01 21:24: Train Epoch 15: 507/634 Loss: 0.171029
2023-01-01 21:25: Train Epoch 15: 511/634 Loss: 0.137585
2023-01-01 21:25: Train Epoch 15: 515/634 Loss: 0.148731
2023-01-01 21:25: Train Epoch 15: 519/634 Loss: 0.144666
2023-01-01 21:26: Train Epoch 15: 523/634 Loss: 0.148914
2023-01-01 21:26: Train Epoch 15: 527/634 Loss: 0.146984
2023-01-01 21:26: Train Epoch 15: 531/634 Loss: 0.145926
2023-01-01 21:27: Train Epoch 15: 535/634 Loss: 0.154080
2023-01-01 21:27: Train Epoch 15: 539/634 Loss: 0.148687
2023-01-01 21:28: Train Epoch 15: 543/634 Loss: 0.159132
2023-01-01 21:28: Train Epoch 15: 547/634 Loss: 0.155098
2023-01-01 21:28: Train Epoch 15: 551/634 Loss: 0.139211
2023-01-01 21:29: Train Epoch 15: 555/634 Loss: 0.135620
2023-01-01 21:29: Train Epoch 15: 559/634 Loss: 0.160804
2023-01-01 21:29: Train Epoch 15: 563/634 Loss: 0.174963
2023-01-01 21:30: Train Epoch 15: 567/634 Loss: 0.139802
2023-01-01 21:30: Train Epoch 15: 571/634 Loss: 0.163668
2023-01-01 21:30: Train Epoch 15: 575/634 Loss: 0.163715
2023-01-01 21:31: Train Epoch 15: 579/634 Loss: 0.169909
2023-01-01 21:31: Train Epoch 15: 583/634 Loss: 0.155127
2023-01-01 21:32: Train Epoch 15: 587/634 Loss: 0.168563
2023-01-01 21:32: Train Epoch 15: 591/634 Loss: 0.150122
2023-01-01 21:32: Train Epoch 15: 595/634 Loss: 0.145230
2023-01-01 21:33: Train Epoch 15: 599/634 Loss: 0.141205
2023-01-01 21:33: Train Epoch 15: 603/634 Loss: 0.157319
2023-01-01 21:33: Train Epoch 15: 607/634 Loss: 0.163125
2023-01-01 21:34: Train Epoch 15: 611/634 Loss: 0.174199
2023-01-01 21:34: Train Epoch 15: 615/634 Loss: 0.169384
2023-01-01 21:34: Train Epoch 15: 619/634 Loss: 0.172285
2023-01-01 21:35: Train Epoch 15: 623/634 Loss: 0.167926
2023-01-01 21:35: Train Epoch 15: 627/634 Loss: 0.149539
2023-01-01 21:35: Train Epoch 15: 631/634 Loss: 0.156577
2023-01-01 21:36: Train Epoch 15: 633/634 Loss: 0.061560
2023-01-01 21:36: **********Train Epoch 15: averaged Loss: 0.155887 
2023-01-01 21:36: 
Epoch time elapsed: 3339.0968868732452

2023-01-01 21:37: 
 metrics validation: {'precision': 0.809910641754671, 'recall': 0.7669230769230769, 'f1-score': 0.7878308968787041, 'support': 1300, 'AUC': 0.9262071005917158, 'AUCPR': 0.8595214001238112, 'TP': 997, 'FP': 234, 'TN': 2366, 'FN': 303} 

2023-01-01 21:37: **********Val Epoch 15: average Loss: 0.155002
2023-01-01 21:38: 
 Testing metrics {'precision': 0.8746411483253589, 'recall': 0.744299674267101, 'f1-score': 0.8042234931808183, 'support': 1228, 'AUC': 0.9328590356396355, 'AUCPR': 0.8919627656900914, 'TP': 914, 'FP': 131, 'TN': 2325, 'FN': 314} 

2023-01-01 21:44: 
 Testing metrics {'precision': 0.9164711403097138, 'recall': 0.8863172226004085, 'f1-score': 0.9011420002307071, 'support': 4407, 'AUC': 0.9785882110216286, 'AUCPR': 0.961339954119548, 'TP': 3906, 'FP': 356, 'TN': 8458, 'FN': 501} 

2023-01-01 21:44: Train Epoch 16: 3/634 Loss: 0.165743
2023-01-01 21:45: Train Epoch 16: 7/634 Loss: 0.159847
2023-01-01 21:45: Train Epoch 16: 11/634 Loss: 0.177645
2023-01-01 21:45: Train Epoch 16: 15/634 Loss: 0.124053
2023-01-01 21:46: Train Epoch 16: 19/634 Loss: 0.163593
2023-01-01 21:46: Train Epoch 16: 23/634 Loss: 0.165315
2023-01-01 21:46: Train Epoch 16: 27/634 Loss: 0.162421
2023-01-01 21:47: Train Epoch 16: 31/634 Loss: 0.146928
2023-01-01 21:47: Train Epoch 16: 35/634 Loss: 0.155134
2023-01-01 21:48: Train Epoch 16: 39/634 Loss: 0.138791
2023-01-01 21:48: Train Epoch 16: 43/634 Loss: 0.137503
2023-01-01 21:48: Train Epoch 16: 47/634 Loss: 0.128124
2023-01-01 21:49: Train Epoch 16: 51/634 Loss: 0.147117
2023-01-01 21:49: Train Epoch 16: 55/634 Loss: 0.150896
2023-01-01 21:49: Train Epoch 16: 59/634 Loss: 0.155553
2023-01-01 21:50: Train Epoch 16: 63/634 Loss: 0.143940
2023-01-01 21:50: Train Epoch 16: 67/634 Loss: 0.130992
2023-01-01 21:50: Train Epoch 16: 71/634 Loss: 0.145774
2023-01-01 21:51: Train Epoch 16: 75/634 Loss: 0.144250
2023-01-01 21:51: Train Epoch 16: 79/634 Loss: 0.157785
2023-01-01 21:51: Train Epoch 16: 83/634 Loss: 0.152101
2023-01-01 21:52: Train Epoch 16: 87/634 Loss: 0.167302
2023-01-01 21:52: Train Epoch 16: 91/634 Loss: 0.149025
2023-01-01 21:52: Train Epoch 16: 95/634 Loss: 0.130786
2023-01-01 21:53: Train Epoch 16: 99/634 Loss: 0.128795
2023-01-01 21:53: Train Epoch 16: 103/634 Loss: 0.157679
2023-01-01 21:53: Train Epoch 16: 107/634 Loss: 0.139156
2023-01-01 21:54: Train Epoch 16: 111/634 Loss: 0.149758
2023-01-01 21:54: Train Epoch 16: 115/634 Loss: 0.136121
2023-01-01 21:54: Train Epoch 16: 119/634 Loss: 0.140623
2023-01-01 21:55: Train Epoch 16: 123/634 Loss: 0.155318
2023-01-01 21:55: Train Epoch 16: 127/634 Loss: 0.168389
2023-01-01 21:55: Train Epoch 16: 131/634 Loss: 0.155865
2023-01-01 21:56: Train Epoch 16: 135/634 Loss: 0.168547
2023-01-01 21:56: Train Epoch 16: 139/634 Loss: 0.180840
2023-01-01 21:56: Train Epoch 16: 143/634 Loss: 0.159606
2023-01-01 21:57: Train Epoch 16: 147/634 Loss: 0.160105
2023-01-01 21:57: Train Epoch 16: 151/634 Loss: 0.131991
2023-01-01 21:57: Train Epoch 16: 155/634 Loss: 0.153171
2023-01-01 21:58: Train Epoch 16: 159/634 Loss: 0.156603
2023-01-01 21:58: Train Epoch 16: 163/634 Loss: 0.154461
2023-01-01 21:58: Train Epoch 16: 167/634 Loss: 0.146342
2023-01-01 21:59: Train Epoch 16: 171/634 Loss: 0.141851
2023-01-01 21:59: Train Epoch 16: 175/634 Loss: 0.138670
2023-01-01 22:00: Train Epoch 16: 179/634 Loss: 0.168780
2023-01-01 22:00: Train Epoch 16: 183/634 Loss: 0.155934
2023-01-01 22:00: Train Epoch 16: 187/634 Loss: 0.129669
2023-01-01 22:01: Train Epoch 16: 191/634 Loss: 0.139295
2023-01-01 22:01: Train Epoch 16: 195/634 Loss: 0.137124
2023-01-01 22:01: Train Epoch 16: 199/634 Loss: 0.167970
2023-01-01 22:02: Train Epoch 16: 203/634 Loss: 0.138762
2023-01-01 22:02: Train Epoch 16: 207/634 Loss: 0.134033
2023-01-01 22:02: Train Epoch 16: 211/634 Loss: 0.147821
2023-01-01 22:03: Train Epoch 16: 215/634 Loss: 0.145404
2023-01-01 22:03: Train Epoch 16: 219/634 Loss: 0.135400
2023-01-01 22:04: Train Epoch 16: 223/634 Loss: 0.157009
2023-01-01 22:04: Train Epoch 16: 227/634 Loss: 0.153741
2023-01-01 22:04: Train Epoch 16: 231/634 Loss: 0.141325
2023-01-01 22:05: Train Epoch 16: 235/634 Loss: 0.138026
2023-01-01 22:05: Train Epoch 16: 239/634 Loss: 0.134707
2023-01-01 22:05: Train Epoch 16: 243/634 Loss: 0.148544
2023-01-01 22:06: Train Epoch 16: 247/634 Loss: 0.156227
2023-01-01 22:06: Train Epoch 16: 251/634 Loss: 0.139871
2023-01-01 22:06: Train Epoch 16: 255/634 Loss: 0.139808
2023-01-01 22:07: Train Epoch 16: 259/634 Loss: 0.131201
2023-01-01 22:07: Train Epoch 16: 263/634 Loss: 0.132220
2023-01-01 22:08: Train Epoch 16: 267/634 Loss: 0.140278
2023-01-01 22:08: Train Epoch 16: 271/634 Loss: 0.140613
2023-01-01 22:08: Train Epoch 16: 275/634 Loss: 0.149811
2023-01-01 22:09: Train Epoch 16: 279/634 Loss: 0.130445
2023-01-01 22:09: Train Epoch 16: 283/634 Loss: 0.149595
2023-01-01 22:09: Train Epoch 16: 287/634 Loss: 0.150718
2023-01-01 22:10: Train Epoch 16: 291/634 Loss: 0.127640
2023-01-01 22:10: Train Epoch 16: 295/634 Loss: 0.147618
2023-01-01 22:10: Train Epoch 16: 299/634 Loss: 0.118298
2023-01-01 22:11: Train Epoch 16: 303/634 Loss: 0.161241
2023-01-01 22:11: Train Epoch 16: 307/634 Loss: 0.154180
2023-01-01 22:11: Train Epoch 16: 311/634 Loss: 0.148246
2023-01-01 22:12: Train Epoch 16: 315/634 Loss: 0.151323
2023-01-01 22:12: Train Epoch 16: 319/634 Loss: 0.131966
2023-01-01 22:13: Train Epoch 16: 323/634 Loss: 0.137586
2023-01-01 22:13: Train Epoch 16: 327/634 Loss: 0.158315
2023-01-01 22:13: Train Epoch 16: 331/634 Loss: 0.159584
2023-01-01 22:14: Train Epoch 16: 335/634 Loss: 0.143845
2023-01-01 22:14: Train Epoch 16: 339/634 Loss: 0.138116
2023-01-01 22:14: Train Epoch 16: 343/634 Loss: 0.144410
2023-01-01 22:15: Train Epoch 16: 347/634 Loss: 0.142918
2023-01-01 22:15: Train Epoch 16: 351/634 Loss: 0.159854
2023-01-01 22:16: Train Epoch 16: 355/634 Loss: 0.140913
2023-01-01 22:16: Train Epoch 16: 359/634 Loss: 0.152035
2023-01-01 22:16: Train Epoch 16: 363/634 Loss: 0.134989
2023-01-01 22:17: Train Epoch 16: 367/634 Loss: 0.160903
2023-01-01 22:17: Train Epoch 16: 371/634 Loss: 0.148894
2023-01-01 22:17: Train Epoch 16: 375/634 Loss: 0.164699
2023-01-01 22:18: Train Epoch 16: 379/634 Loss: 0.141016
2023-01-01 22:18: Train Epoch 16: 383/634 Loss: 0.138126
2023-01-01 22:18: Train Epoch 16: 387/634 Loss: 0.133910
2023-01-01 22:19: Train Epoch 16: 391/634 Loss: 0.148676
2023-01-01 22:19: Train Epoch 16: 395/634 Loss: 0.142326
2023-01-01 22:19: Train Epoch 16: 399/634 Loss: 0.154995
2023-01-01 22:20: Train Epoch 16: 403/634 Loss: 0.153266
2023-01-01 22:20: Train Epoch 16: 407/634 Loss: 0.113961
2023-01-01 22:21: Train Epoch 16: 411/634 Loss: 0.138091
2023-01-01 22:21: Train Epoch 16: 415/634 Loss: 0.169269
2023-01-01 22:21: Train Epoch 16: 419/634 Loss: 0.136479
2023-01-01 22:22: Train Epoch 16: 423/634 Loss: 0.117025
2023-01-01 22:22: Train Epoch 16: 427/634 Loss: 0.149397
2023-01-01 22:22: Train Epoch 16: 431/634 Loss: 0.142923
2023-01-01 22:23: Train Epoch 16: 435/634 Loss: 0.136723
2023-01-01 22:23: Train Epoch 16: 439/634 Loss: 0.143597
2023-01-01 22:23: Train Epoch 16: 443/634 Loss: 0.139888
2023-01-01 22:24: Train Epoch 16: 447/634 Loss: 0.150832
2023-01-01 22:24: Train Epoch 16: 451/634 Loss: 0.121800
2023-01-01 22:24: Train Epoch 16: 455/634 Loss: 0.117875
2023-01-01 22:25: Train Epoch 16: 459/634 Loss: 0.138107
2023-01-01 22:25: Train Epoch 16: 463/634 Loss: 0.153171
2023-01-01 22:26: Train Epoch 16: 467/634 Loss: 0.174026
2023-01-01 22:26: Train Epoch 16: 471/634 Loss: 0.137274
2023-01-01 22:26: Train Epoch 16: 475/634 Loss: 0.139723
2023-01-01 22:27: Train Epoch 16: 479/634 Loss: 0.144257
2023-01-01 22:27: Train Epoch 16: 483/634 Loss: 0.125123
2023-01-01 22:27: Train Epoch 16: 487/634 Loss: 0.131659
2023-01-01 22:28: Train Epoch 16: 491/634 Loss: 0.148794
2023-01-01 22:28: Train Epoch 16: 495/634 Loss: 0.165554
2023-01-01 22:28: Train Epoch 16: 499/634 Loss: 0.137313
2023-01-01 22:29: Train Epoch 16: 503/634 Loss: 0.121962
2023-01-01 22:29: Train Epoch 16: 507/634 Loss: 0.169850
2023-01-01 22:29: Train Epoch 16: 511/634 Loss: 0.144129
2023-01-01 22:30: Train Epoch 16: 515/634 Loss: 0.152343
2023-01-01 22:30: Train Epoch 16: 519/634 Loss: 0.132868
2023-01-01 22:31: Train Epoch 16: 523/634 Loss: 0.125499
2023-01-01 22:31: Train Epoch 16: 527/634 Loss: 0.137169
2023-01-01 22:31: Train Epoch 16: 531/634 Loss: 0.163732
2023-01-01 22:32: Train Epoch 16: 535/634 Loss: 0.157777
2023-01-01 22:32: Train Epoch 16: 539/634 Loss: 0.161040
2023-01-01 22:32: Train Epoch 16: 543/634 Loss: 0.122195
2023-01-01 22:33: Train Epoch 16: 547/634 Loss: 0.153919
2023-01-01 22:33: Train Epoch 16: 551/634 Loss: 0.160633
2023-01-01 22:33: Train Epoch 16: 555/634 Loss: 0.152865
2023-01-01 22:34: Train Epoch 16: 559/634 Loss: 0.113587
2023-01-01 22:34: Train Epoch 16: 563/634 Loss: 0.161587
2023-01-01 22:35: Train Epoch 16: 567/634 Loss: 0.127805
2023-01-01 22:35: Train Epoch 16: 571/634 Loss: 0.141362
2023-01-01 22:35: Train Epoch 16: 575/634 Loss: 0.155356
2023-01-01 22:36: Train Epoch 16: 579/634 Loss: 0.116378
2023-01-01 22:36: Train Epoch 16: 583/634 Loss: 0.133252
2023-01-01 22:36: Train Epoch 16: 587/634 Loss: 0.154664
2023-01-01 22:37: Train Epoch 16: 591/634 Loss: 0.151741
2023-01-01 22:37: Train Epoch 16: 595/634 Loss: 0.150504
2023-01-01 22:37: Train Epoch 16: 599/634 Loss: 0.151602
2023-01-01 22:38: Train Epoch 16: 603/634 Loss: 0.179281
2023-01-01 22:38: Train Epoch 16: 607/634 Loss: 0.154861
2023-01-01 22:38: Train Epoch 16: 611/634 Loss: 0.141714
2023-01-01 22:39: Train Epoch 16: 615/634 Loss: 0.145265
2023-01-01 22:39: Train Epoch 16: 619/634 Loss: 0.128974
2023-01-01 22:39: Train Epoch 16: 623/634 Loss: 0.127926
2023-01-01 22:40: Train Epoch 16: 627/634 Loss: 0.146490
2023-01-01 22:40: Train Epoch 16: 631/634 Loss: 0.147979
2023-01-01 22:40: Train Epoch 16: 633/634 Loss: 0.062199
2023-01-01 22:40: **********Train Epoch 16: averaged Loss: 0.145409 
2023-01-01 22:40: 
Epoch time elapsed: 3388.6203093528748

2023-01-01 22:42: 
 metrics validation: {'precision': 0.8551724137931035, 'recall': 0.6676923076923077, 'f1-score': 0.7498920086393088, 'support': 1300, 'AUC': 0.9293855029585799, 'AUCPR': 0.870491980853421, 'TP': 868, 'FP': 147, 'TN': 2453, 'FN': 432} 

2023-01-01 22:42: **********Val Epoch 16: average Loss: 0.162930
2023-01-01 22:43: 
 Testing metrics {'precision': 0.8746411483253589, 'recall': 0.744299674267101, 'f1-score': 0.8042234931808183, 'support': 1228, 'AUC': 0.9328590356396355, 'AUCPR': 0.8919627656900914, 'TP': 914, 'FP': 131, 'TN': 2325, 'FN': 314} 

2023-01-01 22:48: 
 Testing metrics {'precision': 0.9164711403097138, 'recall': 0.8863172226004085, 'f1-score': 0.9011420002307071, 'support': 4407, 'AUC': 0.9785882110216286, 'AUCPR': 0.961339954119548, 'TP': 3906, 'FP': 356, 'TN': 8458, 'FN': 501} 

2023-01-01 22:49: Train Epoch 17: 3/634 Loss: 0.160367
2023-01-01 22:49: Train Epoch 17: 7/634 Loss: 0.145614
2023-01-01 22:49: Train Epoch 17: 11/634 Loss: 0.166402
2023-01-01 22:50: Train Epoch 17: 15/634 Loss: 0.165834
2023-01-01 22:50: Train Epoch 17: 19/634 Loss: 0.156341
2023-01-01 22:50: Train Epoch 17: 23/634 Loss: 0.161058
2023-01-01 22:51: Train Epoch 17: 27/634 Loss: 0.165957
2023-01-01 22:51: Train Epoch 17: 31/634 Loss: 0.168109
2023-01-01 22:52: Train Epoch 17: 35/634 Loss: 0.142810
2023-01-01 22:52: Train Epoch 17: 39/634 Loss: 0.130674
2023-01-01 22:52: Train Epoch 17: 43/634 Loss: 0.149783
2023-01-01 22:53: Train Epoch 17: 47/634 Loss: 0.123840
2023-01-01 22:53: Train Epoch 17: 51/634 Loss: 0.183474
2023-01-01 22:53: Train Epoch 17: 55/634 Loss: 0.142789
2023-01-01 22:54: Train Epoch 17: 59/634 Loss: 0.134679
2023-01-01 22:54: Train Epoch 17: 63/634 Loss: 0.148369
2023-01-01 22:54: Train Epoch 17: 67/634 Loss: 0.141330
2023-01-01 22:55: Train Epoch 17: 71/634 Loss: 0.163662
2023-01-01 22:55: Train Epoch 17: 75/634 Loss: 0.160742
2023-01-01 22:56: Train Epoch 17: 79/634 Loss: 0.130852
2023-01-01 22:56: Train Epoch 17: 83/634 Loss: 0.138694
2023-01-01 22:56: Train Epoch 17: 87/634 Loss: 0.139874
2023-01-01 22:57: Train Epoch 17: 91/634 Loss: 0.141172
2023-01-01 22:57: Train Epoch 17: 95/634 Loss: 0.133696
2023-01-01 22:57: Train Epoch 17: 99/634 Loss: 0.155290
2023-01-01 22:58: Train Epoch 17: 103/634 Loss: 0.133335
2023-01-01 22:58: Train Epoch 17: 107/634 Loss: 0.156285
2023-01-01 22:58: Train Epoch 17: 111/634 Loss: 0.168278
2023-01-01 22:59: Train Epoch 17: 115/634 Loss: 0.111715
2023-01-01 22:59: Train Epoch 17: 119/634 Loss: 0.171692
2023-01-01 22:59: Train Epoch 17: 123/634 Loss: 0.125809
2023-01-01 23:00: Train Epoch 17: 127/634 Loss: 0.148869
2023-01-01 23:00: Train Epoch 17: 131/634 Loss: 0.136323
2023-01-01 23:00: Train Epoch 17: 135/634 Loss: 0.149148
2023-01-01 23:01: Train Epoch 17: 139/634 Loss: 0.149606
2023-01-01 23:01: Train Epoch 17: 143/634 Loss: 0.135287
2023-01-01 23:02: Train Epoch 17: 147/634 Loss: 0.132797
2023-01-01 23:02: Train Epoch 17: 151/634 Loss: 0.134756
2023-01-01 23:02: Train Epoch 17: 155/634 Loss: 0.131049
2023-01-01 23:03: Train Epoch 17: 159/634 Loss: 0.149271
2023-01-01 23:03: Train Epoch 17: 163/634 Loss: 0.153219
2023-01-01 23:03: Train Epoch 17: 167/634 Loss: 0.151217
2023-01-01 23:04: Train Epoch 17: 171/634 Loss: 0.160164
2023-01-01 23:04: Train Epoch 17: 175/634 Loss: 0.140571
2023-01-01 23:04: Train Epoch 17: 179/634 Loss: 0.152280
2023-01-01 23:05: Train Epoch 17: 183/634 Loss: 0.187966
2023-01-01 23:05: Train Epoch 17: 187/634 Loss: 0.150915
2023-01-01 23:06: Train Epoch 17: 191/634 Loss: 0.169551
2023-01-01 23:06: Train Epoch 17: 195/634 Loss: 0.123439
2023-01-01 23:06: Train Epoch 17: 199/634 Loss: 0.149660
2023-01-01 23:07: Train Epoch 17: 203/634 Loss: 0.157166
2023-01-01 23:07: Train Epoch 17: 207/634 Loss: 0.156344
2023-01-01 23:07: Train Epoch 17: 211/634 Loss: 0.112437
2023-01-01 23:08: Train Epoch 17: 215/634 Loss: 0.182096
2023-01-01 23:08: Train Epoch 17: 219/634 Loss: 0.133180
2023-01-01 23:08: Train Epoch 17: 223/634 Loss: 0.155726
2023-01-01 23:09: Train Epoch 17: 227/634 Loss: 0.127239
2023-01-01 23:09: Train Epoch 17: 231/634 Loss: 0.108810
2023-01-01 23:09: Train Epoch 17: 235/634 Loss: 0.143964
2023-01-01 23:10: Train Epoch 17: 239/634 Loss: 0.154798
2023-01-01 23:10: Train Epoch 17: 243/634 Loss: 0.170366
2023-01-01 23:11: Train Epoch 17: 247/634 Loss: 0.141060
2023-01-01 23:11: Train Epoch 17: 251/634 Loss: 0.133003
2023-01-01 23:11: Train Epoch 17: 255/634 Loss: 0.131685
2023-01-01 23:12: Train Epoch 17: 259/634 Loss: 0.151324
2023-01-01 23:12: Train Epoch 17: 263/634 Loss: 0.135859
2023-01-01 23:12: Train Epoch 17: 267/634 Loss: 0.129917
2023-01-01 23:13: Train Epoch 17: 271/634 Loss: 0.137065
2023-01-01 23:13: Train Epoch 17: 275/634 Loss: 0.148245
2023-01-01 23:13: Train Epoch 17: 279/634 Loss: 0.127141
2023-01-01 23:14: Train Epoch 17: 283/634 Loss: 0.136078
2023-01-01 23:14: Train Epoch 17: 287/634 Loss: 0.154153
2023-01-01 23:14: Train Epoch 17: 291/634 Loss: 0.137373
2023-01-01 23:15: Train Epoch 17: 295/634 Loss: 0.150389
2023-01-01 23:15: Train Epoch 17: 299/634 Loss: 0.131510
2023-01-01 23:16: Train Epoch 17: 303/634 Loss: 0.149130
2023-01-01 23:16: Train Epoch 17: 307/634 Loss: 0.159764
2023-01-01 23:16: Train Epoch 17: 311/634 Loss: 0.123929
2023-01-01 23:17: Train Epoch 17: 315/634 Loss: 0.144416
2023-01-01 23:17: Train Epoch 17: 319/634 Loss: 0.179115
2023-01-01 23:17: Train Epoch 17: 323/634 Loss: 0.133151
2023-01-01 23:18: Train Epoch 17: 327/634 Loss: 0.150017
2023-01-01 23:18: Train Epoch 17: 331/634 Loss: 0.126213
2023-01-01 23:18: Train Epoch 17: 335/634 Loss: 0.136392
2023-01-01 23:19: Train Epoch 17: 339/634 Loss: 0.179709
2023-01-01 23:19: Train Epoch 17: 343/634 Loss: 0.145440
2023-01-01 23:19: Train Epoch 17: 347/634 Loss: 0.134713
2023-01-01 23:20: Train Epoch 17: 351/634 Loss: 0.135820
2023-01-01 23:20: Train Epoch 17: 355/634 Loss: 0.141879
2023-01-01 23:20: Train Epoch 17: 359/634 Loss: 0.158587
2023-01-01 23:21: Train Epoch 17: 363/634 Loss: 0.113243
2023-01-01 23:21: Train Epoch 17: 367/634 Loss: 0.145103
2023-01-01 23:22: Train Epoch 17: 371/634 Loss: 0.139001
2023-01-01 23:22: Train Epoch 17: 375/634 Loss: 0.140059
2023-01-01 23:22: Train Epoch 17: 379/634 Loss: 0.136172
2023-01-01 23:23: Train Epoch 17: 383/634 Loss: 0.148652
2023-01-01 23:23: Train Epoch 17: 387/634 Loss: 0.135177
2023-01-01 23:23: Train Epoch 17: 391/634 Loss: 0.153008
2023-01-01 23:24: Train Epoch 17: 395/634 Loss: 0.142836
2023-01-01 23:24: Train Epoch 17: 399/634 Loss: 0.116934
2023-01-01 23:24: Train Epoch 17: 403/634 Loss: 0.146466
2023-01-01 23:25: Train Epoch 17: 407/634 Loss: 0.149464
2023-01-01 23:25: Train Epoch 17: 411/634 Loss: 0.146766
2023-01-01 23:26: Train Epoch 17: 415/634 Loss: 0.137756
2023-01-01 23:26: Train Epoch 17: 419/634 Loss: 0.124220
2023-01-01 23:26: Train Epoch 17: 423/634 Loss: 0.133234
2023-01-01 23:27: Train Epoch 17: 427/634 Loss: 0.145287
2023-01-01 23:27: Train Epoch 17: 431/634 Loss: 0.167568
2023-01-01 23:27: Train Epoch 17: 435/634 Loss: 0.153918
2023-01-01 23:28: Train Epoch 17: 439/634 Loss: 0.140052
2023-01-01 23:28: Train Epoch 17: 443/634 Loss: 0.138599
2023-01-01 23:28: Train Epoch 17: 447/634 Loss: 0.150431
2023-01-01 23:29: Train Epoch 17: 451/634 Loss: 0.141911
2023-01-01 23:29: Train Epoch 17: 455/634 Loss: 0.133706
2023-01-01 23:29: Train Epoch 17: 459/634 Loss: 0.141786
2023-01-01 23:30: Train Epoch 17: 463/634 Loss: 0.150415
2023-01-01 23:30: Train Epoch 17: 467/634 Loss: 0.166931
2023-01-01 23:30: Train Epoch 17: 471/634 Loss: 0.128211
2023-01-01 23:31: Train Epoch 17: 475/634 Loss: 0.152232
2023-01-01 23:31: Train Epoch 17: 479/634 Loss: 0.140595
2023-01-01 23:32: Train Epoch 17: 483/634 Loss: 0.135319
2023-01-01 23:32: Train Epoch 17: 487/634 Loss: 0.184503
2023-01-01 23:32: Train Epoch 17: 491/634 Loss: 0.165760
2023-01-01 23:33: Train Epoch 17: 495/634 Loss: 0.143109
2023-01-01 23:33: Train Epoch 17: 499/634 Loss: 0.149827
2023-01-01 23:33: Train Epoch 17: 503/634 Loss: 0.133930
2023-01-01 23:34: Train Epoch 17: 507/634 Loss: 0.151973
2023-01-01 23:34: Train Epoch 17: 511/634 Loss: 0.168555
2023-01-01 23:34: Train Epoch 17: 515/634 Loss: 0.148898
2023-01-01 23:35: Train Epoch 17: 519/634 Loss: 0.130183
2023-01-01 23:35: Train Epoch 17: 523/634 Loss: 0.157446
2023-01-01 23:36: Train Epoch 17: 527/634 Loss: 0.163802
2023-01-01 23:36: Train Epoch 17: 531/634 Loss: 0.158294
2023-01-01 23:36: Train Epoch 17: 535/634 Loss: 0.132540
2023-01-01 23:37: Train Epoch 17: 539/634 Loss: 0.151140
2023-01-01 23:37: Train Epoch 17: 543/634 Loss: 0.133491
2023-01-01 23:37: Train Epoch 17: 547/634 Loss: 0.175062
2023-01-01 23:38: Train Epoch 17: 551/634 Loss: 0.153800
2023-01-01 23:38: Train Epoch 17: 555/634 Loss: 0.132583
2023-01-01 23:38: Train Epoch 17: 559/634 Loss: 0.129517
2023-01-01 23:39: Train Epoch 17: 563/634 Loss: 0.172091
2023-01-01 23:39: Train Epoch 17: 567/634 Loss: 0.149858
2023-01-01 23:39: Train Epoch 17: 571/634 Loss: 0.154827
2023-01-01 23:40: Train Epoch 17: 575/634 Loss: 0.175022
2023-01-01 23:40: Train Epoch 17: 579/634 Loss: 0.124815
2023-01-01 23:40: Train Epoch 17: 583/634 Loss: 0.143242
2023-01-01 23:41: Train Epoch 17: 587/634 Loss: 0.122077
2023-01-01 23:41: Train Epoch 17: 591/634 Loss: 0.161966
2023-01-01 23:41: Train Epoch 17: 595/634 Loss: 0.142091
2023-01-01 23:42: Train Epoch 17: 599/634 Loss: 0.125446
2023-01-01 23:42: Train Epoch 17: 603/634 Loss: 0.140153
2023-01-01 23:43: Train Epoch 17: 607/634 Loss: 0.147342
2023-01-01 23:43: Train Epoch 17: 611/634 Loss: 0.143467
2023-01-01 23:43: Train Epoch 17: 615/634 Loss: 0.171820
2023-01-01 23:44: Train Epoch 17: 619/634 Loss: 0.144370
2023-01-01 23:44: Train Epoch 17: 623/634 Loss: 0.139226
2023-01-01 23:44: Train Epoch 17: 627/634 Loss: 0.160951
2023-01-01 23:44: Train Epoch 17: 631/634 Loss: 0.126592
2023-01-01 23:45: Train Epoch 17: 633/634 Loss: 0.052189
2023-01-01 23:45: **********Train Epoch 17: averaged Loss: 0.145452 
2023-01-01 23:45: 
Epoch time elapsed: 3384.533227443695

2023-01-01 23:46: 
 metrics validation: {'precision': 0.8571428571428571, 'recall': 0.6276923076923077, 'f1-score': 0.7246891651865008, 'support': 1300, 'AUC': 0.9254316568047338, 'AUCPR': 0.861013204512318, 'TP': 816, 'FP': 136, 'TN': 2464, 'FN': 484} 

2023-01-01 23:46: **********Val Epoch 17: average Loss: 0.172148
2023-01-01 23:47: 
 Testing metrics {'precision': 0.8746411483253589, 'recall': 0.744299674267101, 'f1-score': 0.8042234931808183, 'support': 1228, 'AUC': 0.9328590356396355, 'AUCPR': 0.8919627656900914, 'TP': 914, 'FP': 131, 'TN': 2325, 'FN': 314} 

2023-01-01 23:52: 
 Testing metrics {'precision': 0.9164711403097138, 'recall': 0.8863172226004085, 'f1-score': 0.9011420002307071, 'support': 4407, 'AUC': 0.9785882110216286, 'AUCPR': 0.961339954119548, 'TP': 3906, 'FP': 356, 'TN': 8458, 'FN': 501} 

2023-01-01 23:53: Train Epoch 18: 3/634 Loss: 0.144451
2023-01-01 23:53: Train Epoch 18: 7/634 Loss: 0.154492
2023-01-01 23:54: Train Epoch 18: 11/634 Loss: 0.139432
2023-01-01 23:54: Train Epoch 18: 15/634 Loss: 0.144086
2023-01-01 23:54: Train Epoch 18: 19/634 Loss: 0.136095
2023-01-01 23:55: Train Epoch 18: 23/634 Loss: 0.157359
2023-01-01 23:55: Train Epoch 18: 27/634 Loss: 0.147953
2023-01-01 23:55: Train Epoch 18: 31/634 Loss: 0.136905
2023-01-01 23:56: Train Epoch 18: 35/634 Loss: 0.168272
2023-01-01 23:56: Train Epoch 18: 39/634 Loss: 0.139664
2023-01-01 23:56: Train Epoch 18: 43/634 Loss: 0.146286
2023-01-01 23:57: Train Epoch 18: 47/634 Loss: 0.142527
2023-01-01 23:57: Train Epoch 18: 51/634 Loss: 0.148731
2023-01-01 23:57: Train Epoch 18: 55/634 Loss: 0.137978
2023-01-01 23:58: Train Epoch 18: 59/634 Loss: 0.165647
2023-01-01 23:58: Train Epoch 18: 63/634 Loss: 0.143471
2023-01-01 23:58: Train Epoch 18: 67/634 Loss: 0.163067
2023-01-01 23:59: Train Epoch 18: 71/634 Loss: 0.126364
2023-01-01 23:59: Train Epoch 18: 75/634 Loss: 0.131832
2023-01-02 00:00: Train Epoch 18: 79/634 Loss: 0.159038
2023-01-02 00:00: Train Epoch 18: 83/634 Loss: 0.138413
2023-01-02 00:00: Train Epoch 18: 87/634 Loss: 0.146193
2023-01-02 00:01: Train Epoch 18: 91/634 Loss: 0.132629
2023-01-02 00:01: Train Epoch 18: 95/634 Loss: 0.135835
2023-01-02 00:01: Train Epoch 18: 99/634 Loss: 0.147570
2023-01-02 00:02: Train Epoch 18: 103/634 Loss: 0.155584
2023-01-02 00:02: Train Epoch 18: 107/634 Loss: 0.166044
2023-01-02 00:02: Train Epoch 18: 111/634 Loss: 0.155219
2023-01-02 00:03: Train Epoch 18: 115/634 Loss: 0.118275
2023-01-02 00:03: Train Epoch 18: 119/634 Loss: 0.133632
2023-01-02 00:04: Train Epoch 18: 123/634 Loss: 0.163500
2023-01-02 00:04: Train Epoch 18: 127/634 Loss: 0.128290
2023-01-02 00:04: Train Epoch 18: 131/634 Loss: 0.157932
2023-01-02 00:05: Train Epoch 18: 135/634 Loss: 0.178340
2023-01-02 00:05: Train Epoch 18: 139/634 Loss: 0.154913
2023-01-02 00:05: Train Epoch 18: 143/634 Loss: 0.145733
2023-01-02 00:06: Train Epoch 18: 147/634 Loss: 0.169320
2023-01-02 00:06: Train Epoch 18: 151/634 Loss: 0.173014
2023-01-02 00:06: Train Epoch 18: 155/634 Loss: 0.151680
2023-01-02 00:07: Train Epoch 18: 159/634 Loss: 0.130162
2023-01-02 00:07: Train Epoch 18: 163/634 Loss: 0.157464
2023-01-02 00:08: Train Epoch 18: 167/634 Loss: 0.130059
2023-01-02 00:08: Train Epoch 18: 171/634 Loss: 0.153612
2023-01-02 00:08: Train Epoch 18: 175/634 Loss: 0.130580
2023-01-02 00:09: Train Epoch 18: 179/634 Loss: 0.149839
2023-01-02 00:09: Train Epoch 18: 183/634 Loss: 0.142412
2023-01-02 00:09: Train Epoch 18: 187/634 Loss: 0.145497
2023-01-02 00:10: Train Epoch 18: 191/634 Loss: 0.133800
2023-01-02 00:10: Train Epoch 18: 195/634 Loss: 0.133360
2023-01-02 00:10: Train Epoch 18: 199/634 Loss: 0.121560
2023-01-02 00:11: Train Epoch 18: 203/634 Loss: 0.138416
2023-01-02 00:11: Train Epoch 18: 207/634 Loss: 0.136002
2023-01-02 00:12: Train Epoch 18: 211/634 Loss: 0.130051
2023-01-02 00:12: Train Epoch 18: 215/634 Loss: 0.153024
2023-01-02 00:12: Train Epoch 18: 219/634 Loss: 0.172007
2023-01-02 00:13: Train Epoch 18: 223/634 Loss: 0.155925
2023-01-02 00:13: Train Epoch 18: 227/634 Loss: 0.142070
2023-01-02 00:13: Train Epoch 18: 231/634 Loss: 0.111250
2023-01-02 00:14: Train Epoch 18: 235/634 Loss: 0.151045
2023-01-02 00:14: Train Epoch 18: 239/634 Loss: 0.132875
2023-01-02 00:14: Train Epoch 18: 243/634 Loss: 0.144879
2023-01-02 00:15: Train Epoch 18: 247/634 Loss: 0.127906
2023-01-02 00:15: Train Epoch 18: 251/634 Loss: 0.135972
2023-01-02 00:15: Train Epoch 18: 255/634 Loss: 0.152049
2023-01-02 00:16: Train Epoch 18: 259/634 Loss: 0.129265
2023-01-02 00:16: Train Epoch 18: 263/634 Loss: 0.123401
2023-01-02 00:17: Train Epoch 18: 267/634 Loss: 0.141924
2023-01-02 00:17: Train Epoch 18: 271/634 Loss: 0.153602
2023-01-02 00:17: Train Epoch 18: 275/634 Loss: 0.143830
2023-01-02 00:18: Train Epoch 18: 279/634 Loss: 0.142781
2023-01-02 00:18: Train Epoch 18: 283/634 Loss: 0.136600
2023-01-02 00:18: Train Epoch 18: 287/634 Loss: 0.143114
2023-01-02 00:19: Train Epoch 18: 291/634 Loss: 0.132262
2023-01-02 00:19: Train Epoch 18: 295/634 Loss: 0.140013
2023-01-02 00:19: Train Epoch 18: 299/634 Loss: 0.134695
2023-01-02 00:20: Train Epoch 18: 303/634 Loss: 0.143539
2023-01-02 00:20: Train Epoch 18: 307/634 Loss: 0.154468
2023-01-02 00:20: Train Epoch 18: 311/634 Loss: 0.159921
2023-01-02 00:21: Train Epoch 18: 315/634 Loss: 0.166089
2023-01-02 00:21: Train Epoch 18: 319/634 Loss: 0.136638
2023-01-02 00:21: Train Epoch 18: 323/634 Loss: 0.124510
2023-01-02 00:22: Train Epoch 18: 327/634 Loss: 0.152712
2023-01-02 00:22: Train Epoch 18: 331/634 Loss: 0.133260
2023-01-02 00:23: Train Epoch 18: 335/634 Loss: 0.154372
2023-01-02 00:23: Train Epoch 18: 339/634 Loss: 0.136235
2023-01-02 00:23: Train Epoch 18: 343/634 Loss: 0.120538
2023-01-02 00:24: Train Epoch 18: 347/634 Loss: 0.143817
2023-01-02 00:24: Train Epoch 18: 351/634 Loss: 0.146639
2023-01-02 00:24: Train Epoch 18: 355/634 Loss: 0.118103
2023-01-02 00:25: Train Epoch 18: 359/634 Loss: 0.155320
2023-01-02 00:25: Train Epoch 18: 363/634 Loss: 0.123672
2023-01-02 00:25: Train Epoch 18: 367/634 Loss: 0.151588
2023-01-02 00:26: Train Epoch 18: 371/634 Loss: 0.140231
2023-01-02 00:26: Train Epoch 18: 375/634 Loss: 0.130101
2023-01-02 00:26: Train Epoch 18: 379/634 Loss: 0.142479
2023-01-02 00:27: Train Epoch 18: 383/634 Loss: 0.132161
2023-01-02 00:27: Train Epoch 18: 387/634 Loss: 0.148423
2023-01-02 00:28: Train Epoch 18: 391/634 Loss: 0.165105
2023-01-02 00:28: Train Epoch 18: 395/634 Loss: 0.130662
2023-01-02 00:28: Train Epoch 18: 399/634 Loss: 0.137026
2023-01-02 00:29: Train Epoch 18: 403/634 Loss: 0.177426
2023-01-02 00:29: Train Epoch 18: 407/634 Loss: 0.139424
2023-01-02 00:29: Train Epoch 18: 411/634 Loss: 0.172578
2023-01-02 00:30: Train Epoch 18: 415/634 Loss: 0.117913
2023-01-02 00:30: Train Epoch 18: 419/634 Loss: 0.128218
2023-01-02 00:31: Train Epoch 18: 423/634 Loss: 0.134900
2023-01-02 00:31: Train Epoch 18: 427/634 Loss: 0.150625
2023-01-02 00:31: Train Epoch 18: 431/634 Loss: 0.158543
2023-01-02 00:32: Train Epoch 18: 435/634 Loss: 0.142131
2023-01-02 00:32: Train Epoch 18: 439/634 Loss: 0.134436
2023-01-02 00:32: Train Epoch 18: 443/634 Loss: 0.134074
2023-01-02 00:33: Train Epoch 18: 447/634 Loss: 0.136192
2023-01-02 00:33: Train Epoch 18: 451/634 Loss: 0.138165
2023-01-02 00:33: Train Epoch 18: 455/634 Loss: 0.146206
2023-01-02 00:34: Train Epoch 18: 459/634 Loss: 0.151533
2023-01-02 00:34: Train Epoch 18: 463/634 Loss: 0.120131
2023-01-02 00:35: Train Epoch 18: 467/634 Loss: 0.149811
2023-01-02 00:35: Train Epoch 18: 471/634 Loss: 0.123733
2023-01-02 00:35: Train Epoch 18: 475/634 Loss: 0.135144
2023-01-02 00:36: Train Epoch 18: 479/634 Loss: 0.124643
2023-01-02 00:36: Train Epoch 18: 483/634 Loss: 0.134426
2023-01-02 00:36: Train Epoch 18: 487/634 Loss: 0.135836
2023-01-02 00:37: Train Epoch 18: 491/634 Loss: 0.136295
2023-01-02 00:37: Train Epoch 18: 495/634 Loss: 0.140746
2023-01-02 00:37: Train Epoch 18: 499/634 Loss: 0.131852
2023-01-02 00:38: Train Epoch 18: 503/634 Loss: 0.172188
2023-01-02 00:38: Train Epoch 18: 507/634 Loss: 0.148454
2023-01-02 00:38: Train Epoch 18: 511/634 Loss: 0.152242
2023-01-02 00:39: Train Epoch 18: 515/634 Loss: 0.140755
2023-01-02 00:39: Train Epoch 18: 519/634 Loss: 0.146063
2023-01-02 00:39: Train Epoch 18: 523/634 Loss: 0.156749
2023-01-02 00:40: Train Epoch 18: 527/634 Loss: 0.136010
2023-01-02 00:40: Train Epoch 18: 531/634 Loss: 0.151085
2023-01-02 00:40: Train Epoch 18: 535/634 Loss: 0.147345
2023-01-02 00:41: Train Epoch 18: 539/634 Loss: 0.148098
2023-01-02 00:41: Train Epoch 18: 543/634 Loss: 0.137754
2023-01-02 00:41: Train Epoch 18: 547/634 Loss: 0.163433
2023-01-02 00:42: Train Epoch 18: 551/634 Loss: 0.174155
2023-01-02 00:42: Train Epoch 18: 555/634 Loss: 0.158059
2023-01-02 00:42: Train Epoch 18: 559/634 Loss: 0.148555
2023-01-02 00:43: Train Epoch 18: 563/634 Loss: 0.154450
2023-01-02 00:43: Train Epoch 18: 567/634 Loss: 0.129349
2023-01-02 00:43: Train Epoch 18: 571/634 Loss: 0.126369
2023-01-02 00:44: Train Epoch 18: 575/634 Loss: 0.133763
2023-01-02 00:44: Train Epoch 18: 579/634 Loss: 0.138536
2023-01-02 00:44: Train Epoch 18: 583/634 Loss: 0.121271
2023-01-02 00:45: Train Epoch 18: 587/634 Loss: 0.125162
2023-01-02 00:45: Train Epoch 18: 591/634 Loss: 0.132666
2023-01-02 00:45: Train Epoch 18: 595/634 Loss: 0.145907
2023-01-02 00:46: Train Epoch 18: 599/634 Loss: 0.128608
2023-01-02 00:46: Train Epoch 18: 603/634 Loss: 0.146379
2023-01-02 00:46: Train Epoch 18: 607/634 Loss: 0.142306
2023-01-02 00:47: Train Epoch 18: 611/634 Loss: 0.123189
2023-01-02 00:47: Train Epoch 18: 615/634 Loss: 0.124913
2023-01-02 00:47: Train Epoch 18: 619/634 Loss: 0.142489
2023-01-02 00:48: Train Epoch 18: 623/634 Loss: 0.139618
2023-01-02 00:48: Train Epoch 18: 627/634 Loss: 0.155803
2023-01-02 00:48: Train Epoch 18: 631/634 Loss: 0.162403
2023-01-02 00:49: Train Epoch 18: 633/634 Loss: 0.052098
2023-01-02 00:49: **********Train Epoch 18: averaged Loss: 0.142565 
2023-01-02 00:49: 
Epoch time elapsed: 3372.16530752182

2023-01-02 00:50: 
 metrics validation: {'precision': 0.8789473684210526, 'recall': 0.6423076923076924, 'f1-score': 0.7422222222222223, 'support': 1300, 'AUC': 0.9332834319526628, 'AUCPR': 0.8747819971552426, 'TP': 835, 'FP': 115, 'TN': 2485, 'FN': 465} 

2023-01-02 00:50: **********Val Epoch 18: average Loss: 0.166057
2023-01-02 00:51: 
 Testing metrics {'precision': 0.8746411483253589, 'recall': 0.744299674267101, 'f1-score': 0.8042234931808183, 'support': 1228, 'AUC': 0.9328590356396355, 'AUCPR': 0.8919627656900914, 'TP': 914, 'FP': 131, 'TN': 2325, 'FN': 314} 

2023-01-02 00:56: 
 Testing metrics {'precision': 0.9164711403097138, 'recall': 0.8863172226004085, 'f1-score': 0.9011420002307071, 'support': 4407, 'AUC': 0.9785882110216286, 'AUCPR': 0.961339954119548, 'TP': 3906, 'FP': 356, 'TN': 8458, 'FN': 501} 

2023-01-02 00:57: Train Epoch 19: 3/634 Loss: 0.151255
2023-01-02 00:57: Train Epoch 19: 7/634 Loss: 0.156828
2023-01-02 00:57: Train Epoch 19: 11/634 Loss: 0.157742
2023-01-02 00:58: Train Epoch 19: 15/634 Loss: 0.156663
2023-01-02 00:58: Train Epoch 19: 19/634 Loss: 0.164250
2023-01-02 00:59: Train Epoch 19: 23/634 Loss: 0.148282
2023-01-02 00:59: Train Epoch 19: 27/634 Loss: 0.142210
2023-01-02 00:59: Train Epoch 19: 31/634 Loss: 0.153888
2023-01-02 01:00: Train Epoch 19: 35/634 Loss: 0.152384
2023-01-02 01:00: Train Epoch 19: 39/634 Loss: 0.140269
2023-01-02 01:00: Train Epoch 19: 43/634 Loss: 0.139061
2023-01-02 01:01: Train Epoch 19: 47/634 Loss: 0.141873
2023-01-02 01:01: Train Epoch 19: 51/634 Loss: 0.156191
2023-01-02 01:01: Train Epoch 19: 55/634 Loss: 0.150341
2023-01-02 01:02: Train Epoch 19: 59/634 Loss: 0.138055
2023-01-02 01:02: Train Epoch 19: 63/634 Loss: 0.163303
2023-01-02 01:02: Train Epoch 19: 67/634 Loss: 0.154707
2023-01-02 01:03: Train Epoch 19: 71/634 Loss: 0.152817
2023-01-02 01:03: Train Epoch 19: 75/634 Loss: 0.135712
2023-01-02 01:03: Train Epoch 19: 79/634 Loss: 0.166153
2023-01-02 01:04: Train Epoch 19: 83/634 Loss: 0.152153
2023-01-02 01:04: Train Epoch 19: 87/634 Loss: 0.152190
2023-01-02 01:04: Train Epoch 19: 91/634 Loss: 0.159458
2023-01-02 01:05: Train Epoch 19: 95/634 Loss: 0.153437
2023-01-02 01:05: Train Epoch 19: 99/634 Loss: 0.154444
2023-01-02 01:05: Train Epoch 19: 103/634 Loss: 0.163056
2023-01-02 01:06: Train Epoch 19: 107/634 Loss: 0.158173
2023-01-02 01:06: Train Epoch 19: 111/634 Loss: 0.142640
2023-01-02 01:06: Train Epoch 19: 115/634 Loss: 0.147357
2023-01-02 01:07: Train Epoch 19: 119/634 Loss: 0.134245
2023-01-02 01:07: Train Epoch 19: 123/634 Loss: 0.154869
2023-01-02 01:07: Train Epoch 19: 127/634 Loss: 0.139521
2023-01-02 01:08: Train Epoch 19: 131/634 Loss: 0.157452
2023-01-02 01:08: Train Epoch 19: 135/634 Loss: 0.137333
2023-01-02 01:08: Train Epoch 19: 139/634 Loss: 0.151155
2023-01-02 01:09: Train Epoch 19: 143/634 Loss: 0.151825
2023-01-02 01:09: Train Epoch 19: 147/634 Loss: 0.124032
2023-01-02 01:09: Train Epoch 19: 151/634 Loss: 0.141510
2023-01-02 01:10: Train Epoch 19: 155/634 Loss: 0.144250
2023-01-02 01:10: Train Epoch 19: 159/634 Loss: 0.143208
2023-01-02 01:11: Train Epoch 19: 163/634 Loss: 0.149333
2023-01-02 01:11: Train Epoch 19: 167/634 Loss: 0.161595
2023-01-02 01:11: Train Epoch 19: 171/634 Loss: 0.143157
2023-01-02 01:12: Train Epoch 19: 175/634 Loss: 0.155881
2023-01-02 01:12: Train Epoch 19: 179/634 Loss: 0.150353
2023-01-02 01:12: Train Epoch 19: 183/634 Loss: 0.142106
2023-01-02 01:13: Train Epoch 19: 187/634 Loss: 0.169200
2023-01-02 01:13: Train Epoch 19: 191/634 Loss: 0.110812
2023-01-02 01:13: Train Epoch 19: 195/634 Loss: 0.152594
2023-01-02 01:14: Train Epoch 19: 199/634 Loss: 0.151607
2023-01-02 01:14: Train Epoch 19: 203/634 Loss: 0.173075
2023-01-02 01:14: Train Epoch 19: 207/634 Loss: 0.153024
2023-01-02 01:15: Train Epoch 19: 211/634 Loss: 0.131597
2023-01-02 01:15: Train Epoch 19: 215/634 Loss: 0.143019
2023-01-02 01:15: Train Epoch 19: 219/634 Loss: 0.185021
2023-01-02 01:16: Train Epoch 19: 223/634 Loss: 0.136981
2023-01-02 01:16: Train Epoch 19: 227/634 Loss: 0.164802
2023-01-02 01:16: Train Epoch 19: 231/634 Loss: 0.146522
2023-01-02 01:17: Train Epoch 19: 235/634 Loss: 0.174352
2023-01-02 01:17: Train Epoch 19: 239/634 Loss: 0.147120
2023-01-02 01:17: Train Epoch 19: 243/634 Loss: 0.124859
2023-01-02 01:18: Train Epoch 19: 247/634 Loss: 0.141969
2023-01-02 01:18: Train Epoch 19: 251/634 Loss: 0.154438
2023-01-02 01:19: Train Epoch 19: 255/634 Loss: 0.140057
2023-01-02 01:19: Train Epoch 19: 259/634 Loss: 0.134691
2023-01-02 01:19: Train Epoch 19: 263/634 Loss: 0.126008
2023-01-02 01:20: Train Epoch 19: 267/634 Loss: 0.139945
2023-01-02 01:20: Train Epoch 19: 271/634 Loss: 0.155535
2023-01-02 01:20: Train Epoch 19: 275/634 Loss: 0.126167
2023-01-02 01:21: Train Epoch 19: 279/634 Loss: 0.142788
2023-01-02 01:21: Train Epoch 19: 283/634 Loss: 0.164129
2023-01-02 01:21: Train Epoch 19: 287/634 Loss: 0.148277
2023-01-02 01:22: Train Epoch 19: 291/634 Loss: 0.157403
2023-01-02 01:22: Train Epoch 19: 295/634 Loss: 0.122451
2023-01-02 01:22: Train Epoch 19: 299/634 Loss: 0.164086
2023-01-02 01:23: Train Epoch 19: 303/634 Loss: 0.133399
2023-01-02 01:23: Train Epoch 19: 307/634 Loss: 0.153761
2023-01-02 01:23: Train Epoch 19: 311/634 Loss: 0.141222
2023-01-02 01:24: Train Epoch 19: 315/634 Loss: 0.147141
2023-01-02 01:24: Train Epoch 19: 319/634 Loss: 0.133577
2023-01-02 01:24: Train Epoch 19: 323/634 Loss: 0.159195
2023-01-02 01:25: Train Epoch 19: 327/634 Loss: 0.142816
2023-01-02 01:25: Train Epoch 19: 331/634 Loss: 0.136266
2023-01-02 01:25: Train Epoch 19: 335/634 Loss: 0.124714
2023-01-02 01:26: Train Epoch 19: 339/634 Loss: 0.146670
2023-01-02 01:26: Train Epoch 19: 343/634 Loss: 0.115661
2023-01-02 01:26: Train Epoch 19: 347/634 Loss: 0.157671
2023-01-02 01:27: Train Epoch 19: 351/634 Loss: 0.145966
2023-01-02 01:27: Train Epoch 19: 355/634 Loss: 0.137312
2023-01-02 01:28: Train Epoch 19: 359/634 Loss: 0.143851
2023-01-02 01:28: Train Epoch 19: 363/634 Loss: 0.156035
2023-01-02 01:28: Train Epoch 19: 367/634 Loss: 0.120013
2023-01-02 01:29: Train Epoch 19: 371/634 Loss: 0.131776
2023-01-02 01:29: Train Epoch 19: 375/634 Loss: 0.135790
2023-01-02 01:29: Train Epoch 19: 379/634 Loss: 0.155797
2023-01-02 01:30: Train Epoch 19: 383/634 Loss: 0.126681
2023-01-02 01:30: Train Epoch 19: 387/634 Loss: 0.157571
2023-01-02 01:30: Train Epoch 19: 391/634 Loss: 0.149827
2023-01-02 01:31: Train Epoch 19: 395/634 Loss: 0.138976
2023-01-02 01:31: Train Epoch 19: 399/634 Loss: 0.142553
2023-01-02 01:31: Train Epoch 19: 403/634 Loss: 0.133926
2023-01-02 01:32: Train Epoch 19: 407/634 Loss: 0.137505
2023-01-02 01:32: Train Epoch 19: 411/634 Loss: 0.142091
2023-01-02 01:33: Train Epoch 19: 415/634 Loss: 0.141077
2023-01-02 01:33: Train Epoch 19: 419/634 Loss: 0.128880
2023-01-02 01:33: Train Epoch 19: 423/634 Loss: 0.145160
2023-01-02 01:34: Train Epoch 19: 427/634 Loss: 0.136341
2023-01-02 01:34: Train Epoch 19: 431/634 Loss: 0.149139
2023-01-02 01:34: Train Epoch 19: 435/634 Loss: 0.143304
2023-01-02 01:35: Train Epoch 19: 439/634 Loss: 0.167267
2023-01-02 01:35: Train Epoch 19: 443/634 Loss: 0.153023
2023-01-02 01:35: Train Epoch 19: 447/634 Loss: 0.132342
2023-01-02 01:36: Train Epoch 19: 451/634 Loss: 0.147152
2023-01-02 01:36: Train Epoch 19: 455/634 Loss: 0.140676
2023-01-02 01:36: Train Epoch 19: 459/634 Loss: 0.142027
2023-01-02 01:37: Train Epoch 19: 463/634 Loss: 0.160319
2023-01-02 01:37: Train Epoch 19: 467/634 Loss: 0.134019
2023-01-02 01:37: Train Epoch 19: 471/634 Loss: 0.141143
2023-01-02 01:38: Train Epoch 19: 475/634 Loss: 0.167985
2023-01-02 01:38: Train Epoch 19: 479/634 Loss: 0.147079
2023-01-02 01:38: Train Epoch 19: 483/634 Loss: 0.150544
2023-01-02 01:39: Train Epoch 19: 487/634 Loss: 0.142721
2023-01-02 01:39: Train Epoch 19: 491/634 Loss: 0.158174
2023-01-02 01:39: Train Epoch 19: 495/634 Loss: 0.136055
2023-01-02 01:40: Train Epoch 19: 499/634 Loss: 0.144808
2023-01-02 01:40: Train Epoch 19: 503/634 Loss: 0.139359
2023-01-02 01:40: Train Epoch 19: 507/634 Loss: 0.140617
2023-01-02 01:41: Train Epoch 19: 511/634 Loss: 0.143245
2023-01-02 01:41: Train Epoch 19: 515/634 Loss: 0.150320
2023-01-02 01:41: Train Epoch 19: 519/634 Loss: 0.134160
2023-01-02 01:42: Train Epoch 19: 523/634 Loss: 0.142022
2023-01-02 01:42: Train Epoch 19: 527/634 Loss: 0.146019
2023-01-02 01:42: Train Epoch 19: 531/634 Loss: 0.139948
2023-01-02 01:43: Train Epoch 19: 535/634 Loss: 0.157245
2023-01-02 01:43: Train Epoch 19: 539/634 Loss: 0.143597
2023-01-02 01:44: Train Epoch 19: 543/634 Loss: 0.145641
2023-01-02 01:44: Train Epoch 19: 547/634 Loss: 0.142135
2023-01-02 01:44: Train Epoch 19: 551/634 Loss: 0.151040
2023-01-02 01:45: Train Epoch 19: 555/634 Loss: 0.145310
2023-01-02 01:45: Train Epoch 19: 559/634 Loss: 0.153863
2023-01-02 01:45: Train Epoch 19: 563/634 Loss: 0.154108
2023-01-02 01:46: Train Epoch 19: 567/634 Loss: 0.138178
2023-01-02 01:46: Train Epoch 19: 571/634 Loss: 0.156452
2023-01-02 01:46: Train Epoch 19: 575/634 Loss: 0.141953
2023-01-02 01:47: Train Epoch 19: 579/634 Loss: 0.139132
2023-01-02 01:47: Train Epoch 19: 583/634 Loss: 0.130538
2023-01-02 01:47: Train Epoch 19: 587/634 Loss: 0.146049
2023-01-02 01:48: Train Epoch 19: 591/634 Loss: 0.132820
2023-01-02 01:48: Train Epoch 19: 595/634 Loss: 0.119863
2023-01-02 01:48: Train Epoch 19: 599/634 Loss: 0.132981
2023-01-02 01:49: Train Epoch 19: 603/634 Loss: 0.129567
2023-01-02 01:49: Train Epoch 19: 607/634 Loss: 0.147255
2023-01-02 01:49: Train Epoch 19: 611/634 Loss: 0.166613
2023-01-02 01:50: Train Epoch 19: 615/634 Loss: 0.127331
2023-01-02 01:50: Train Epoch 19: 619/634 Loss: 0.139279
2023-01-02 01:50: Train Epoch 19: 623/634 Loss: 0.132669
2023-01-02 01:51: Train Epoch 19: 627/634 Loss: 0.157833
2023-01-02 01:51: Train Epoch 19: 631/634 Loss: 0.144952
2023-01-02 01:51: Train Epoch 19: 633/634 Loss: 0.060693
2023-01-02 01:51: **********Train Epoch 19: averaged Loss: 0.145277 
2023-01-02 01:51: 
Epoch time elapsed: 3289.030594587326

2023-01-02 01:53: 
 metrics validation: {'precision': 0.874361593462717, 'recall': 0.6584615384615384, 'f1-score': 0.7512066695919262, 'support': 1300, 'AUC': 0.9333872781065089, 'AUCPR': 0.8749656588463456, 'TP': 856, 'FP': 123, 'TN': 2477, 'FN': 444} 

2023-01-02 01:53: **********Val Epoch 19: average Loss: 0.161909
2023-01-02 01:53: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-02 01:53: Total training time: 1219.7040min, best loss: 0.149266
2023-01-02 01:53: Saving current best model to /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010105332965474854013/best_model.pth
2023-01-02 01:54: 
 Testing metrics {'precision': 0.8746411483253589, 'recall': 0.744299674267101, 'f1-score': 0.8042234931808183, 'support': 1228, 'AUC': 0.9328590356396355, 'AUCPR': 0.8919627656900914, 'TP': 914, 'FP': 131, 'TN': 2325, 'FN': 314} 

