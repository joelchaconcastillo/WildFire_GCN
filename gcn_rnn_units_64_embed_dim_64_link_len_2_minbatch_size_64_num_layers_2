2023-01-03 18:27: log dir: /home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010318271890977154013
2023-01-03 18:27: Experiment log path in: /home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010318271890977154013
2023-01-03 18:27: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010318271890977154013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=2, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=64, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-03 18:27: Argument batch_size: 256
2023-01-03 18:27: Argument clc: 'vec'
2023-01-03 18:27: Argument cuda: True
2023-01-03 18:27: Argument dataset: '2020'
2023-01-03 18:27: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-03 18:27: Argument debug: False
2023-01-03 18:27: Argument default_graph: True
2023-01-03 18:27: Argument device: 'cpu'
2023-01-03 18:27: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-03 18:27: Argument early_stop: True
2023-01-03 18:27: Argument early_stop_patience: 8
2023-01-03 18:27: Argument embed_dim: 64
2023-01-03 18:27: Argument epochs: 30
2023-01-03 18:27: Argument grad_norm: False
2023-01-03 18:27: Argument horizon: 1
2023-01-03 18:27: Argument input_dim: 25
2023-01-03 18:27: Argument lag: 10
2023-01-03 18:27: Argument link_len: 2
2023-01-03 18:27: Argument log_dir: '/home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010318271890977154013'
2023-01-03 18:27: Argument log_step: 1
2023-01-03 18:27: Argument loss_func: 'nllloss'
2023-01-03 18:27: Argument lr_decay: True
2023-01-03 18:27: Argument lr_decay_rate: 0.1
2023-01-03 18:27: Argument lr_decay_step: '15'
2023-01-03 18:27: Argument lr_init: 0.0001
2023-01-03 18:27: Argument max_grad_norm: 5
2023-01-03 18:27: Argument minbatch_size: 64
2023-01-03 18:27: Argument mode: 'train'
2023-01-03 18:27: Argument model: 'fire_GCN'
2023-01-03 18:27: Argument nan_fill: -1.0
2023-01-03 18:27: Argument num_layers: 2
2023-01-03 18:27: Argument num_nodes: 625
2023-01-03 18:27: Argument num_workers: 12
2023-01-03 18:27: Argument output_dim: 2
2023-01-03 18:27: Argument patch_height: 25
2023-01-03 18:27: Argument patch_width: 25
2023-01-03 18:27: Argument persistent_workers: True
2023-01-03 18:27: Argument pin_memory: True
2023-01-03 18:27: Argument plot: False
2023-01-03 18:27: Argument positive_weight: 0.5
2023-01-03 18:27: Argument prefetch_factor: 2
2023-01-03 18:27: Argument real_value: True
2023-01-03 18:27: Argument rnn_units: 64
2023-01-03 18:27: Argument seed: 10000
2023-01-03 18:27: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-03 18:27: Argument teacher_forcing: False
2023-01-03 18:27: Argument weight_decay: 0.0
2023-01-03 18:27: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([64, 2, 89, 64]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 64]) True
encoder.cell_list.0.gate.bias_pool torch.Size([64, 128]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([64, 2, 89, 32]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 32]) True
encoder.cell_list.0.update.bias_pool torch.Size([64, 64]) True
encoder.cell_list.0.update.T torch.Size([10]) True
encoder.cell_list.1.gate.weights_pool torch.Size([64, 2, 128, 64]) True
encoder.cell_list.1.gate.weights_window torch.Size([64, 64, 64]) True
encoder.cell_list.1.gate.bias_pool torch.Size([64, 128]) True
encoder.cell_list.1.gate.T torch.Size([10]) True
encoder.cell_list.1.update.weights_pool torch.Size([64, 2, 128, 32]) True
encoder.cell_list.1.update.weights_window torch.Size([64, 64, 32]) True
encoder.cell_list.1.update.bias_pool torch.Size([64, 64]) True
encoder.cell_list.1.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 40000]) True
fc1.bias torch.Size([2]) True
Total params num: 3210524
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/tuningLayers/WildFire_GCN/experiments/2020/2023010318271890977154013/run.log
2023-01-03 18:28: Train Epoch 1: 3/634 Loss: 0.555571
2023-01-03 18:29: Train Epoch 1: 7/634 Loss: 2.684524
2023-01-03 18:30: Train Epoch 1: 11/634 Loss: 2.141752
2023-01-03 18:32: Train Epoch 1: 15/634 Loss: 1.451489
2023-01-03 18:33: Train Epoch 1: 19/634 Loss: 0.497018
2023-01-03 18:34: Train Epoch 1: 23/634 Loss: 0.609325
2023-01-03 18:35: Train Epoch 1: 27/634 Loss: 0.361781
2023-01-03 18:36: Train Epoch 1: 31/634 Loss: 0.433794
2023-01-03 18:37: Train Epoch 1: 35/634 Loss: 0.474927
2023-01-03 18:38: Train Epoch 1: 39/634 Loss: 0.423957
2023-01-03 18:39: Train Epoch 1: 43/634 Loss: 0.243301
2023-01-03 18:40: Train Epoch 1: 47/634 Loss: 0.309122
2023-01-03 18:42: Train Epoch 1: 51/634 Loss: 0.413570
2023-01-03 18:43: Train Epoch 1: 55/634 Loss: 0.353309
2023-01-03 18:44: Train Epoch 1: 59/634 Loss: 0.240217
2023-01-03 18:45: Train Epoch 1: 63/634 Loss: 0.250826
2023-01-03 18:46: Train Epoch 1: 67/634 Loss: 0.321846
2023-01-03 18:47: Train Epoch 1: 71/634 Loss: 0.386900
2023-01-03 18:48: Train Epoch 1: 75/634 Loss: 0.284006
2023-01-03 18:49: Train Epoch 1: 79/634 Loss: 0.269185
2023-01-03 18:50: Train Epoch 1: 83/634 Loss: 0.257533
2023-01-03 18:52: Train Epoch 1: 87/634 Loss: 0.283263
2023-01-03 18:53: Train Epoch 1: 91/634 Loss: 0.244904
2023-01-03 18:54: Train Epoch 1: 95/634 Loss: 0.298069
2023-01-03 18:55: Train Epoch 1: 99/634 Loss: 0.272665
2023-01-03 18:56: Train Epoch 1: 103/634 Loss: 0.263382
2023-01-03 18:57: Train Epoch 1: 107/634 Loss: 0.204866
2023-01-03 18:58: Train Epoch 1: 111/634 Loss: 0.276736
2023-01-03 18:59: Train Epoch 1: 115/634 Loss: 0.238022
2023-01-03 19:01: Train Epoch 1: 119/634 Loss: 0.265019
2023-01-03 19:02: Train Epoch 1: 123/634 Loss: 0.235615
2023-01-03 19:03: Train Epoch 1: 127/634 Loss: 0.246995
2023-01-03 19:04: Train Epoch 1: 131/634 Loss: 0.226422
2023-01-03 19:05: Train Epoch 1: 135/634 Loss: 0.215893
2023-01-03 19:06: Train Epoch 1: 139/634 Loss: 0.221461
2023-01-03 19:07: Train Epoch 1: 143/634 Loss: 0.282859
2023-01-03 19:09: Train Epoch 1: 147/634 Loss: 0.256009
2023-01-03 19:10: Train Epoch 1: 151/634 Loss: 0.231347
2023-01-03 19:11: Train Epoch 1: 155/634 Loss: 0.215845
2023-01-03 19:12: Train Epoch 1: 159/634 Loss: 0.225003
2023-01-03 19:13: Train Epoch 1: 163/634 Loss: 0.226164
2023-01-03 19:14: Train Epoch 1: 167/634 Loss: 0.206853
2023-01-03 19:15: Train Epoch 1: 171/634 Loss: 0.268375
2023-01-03 19:16: Train Epoch 1: 175/634 Loss: 0.214914
2023-01-03 19:18: Train Epoch 1: 179/634 Loss: 0.290534
2023-01-03 19:19: Train Epoch 1: 183/634 Loss: 0.228542
2023-01-03 19:20: Train Epoch 1: 187/634 Loss: 0.210614
2023-01-03 19:21: Train Epoch 1: 191/634 Loss: 0.194993
2023-01-03 19:22: Train Epoch 1: 195/634 Loss: 0.224138
2023-01-03 19:23: Train Epoch 1: 199/634 Loss: 0.209722
2023-01-03 19:24: Train Epoch 1: 203/634 Loss: 0.216054
2023-01-03 19:25: Train Epoch 1: 207/634 Loss: 0.213765
2023-01-03 19:27: Train Epoch 1: 211/634 Loss: 0.227477
2023-01-03 19:28: Train Epoch 1: 215/634 Loss: 0.213188
2023-01-03 19:29: Train Epoch 1: 219/634 Loss: 0.186507
2023-01-03 19:30: Train Epoch 1: 223/634 Loss: 0.236015
2023-01-03 19:31: Train Epoch 1: 227/634 Loss: 0.210898
2023-01-03 19:32: Train Epoch 1: 231/634 Loss: 0.199748
2023-01-03 19:33: Train Epoch 1: 235/634 Loss: 0.242161
2023-01-03 19:34: Train Epoch 1: 239/634 Loss: 0.214420
2023-01-03 19:36: Train Epoch 1: 243/634 Loss: 0.221241
2023-01-03 19:37: Train Epoch 1: 247/634 Loss: 0.231841
2023-01-03 19:38: Train Epoch 1: 251/634 Loss: 0.222459
2023-01-03 19:39: Train Epoch 1: 255/634 Loss: 0.203103
2023-01-03 19:40: Train Epoch 1: 259/634 Loss: 0.232407
2023-01-03 19:41: Train Epoch 1: 263/634 Loss: 0.210999
2023-01-03 19:42: Train Epoch 1: 267/634 Loss: 0.214849
2023-01-03 19:43: Train Epoch 1: 271/634 Loss: 0.231690
2023-01-03 19:45: Train Epoch 1: 275/634 Loss: 0.207452
2023-01-03 19:46: Train Epoch 1: 279/634 Loss: 0.247330
2023-01-03 19:47: Train Epoch 1: 283/634 Loss: 0.216159
2023-01-03 19:48: Train Epoch 1: 287/634 Loss: 0.185178
2023-01-03 19:49: Train Epoch 1: 291/634 Loss: 0.191933
2023-01-03 19:50: Train Epoch 1: 295/634 Loss: 0.209533
2023-01-03 19:52: Train Epoch 1: 299/634 Loss: 0.230008
2023-01-03 19:53: Train Epoch 1: 303/634 Loss: 0.193754
2023-01-03 19:54: Train Epoch 1: 307/634 Loss: 0.230500
2023-01-03 19:55: Train Epoch 1: 311/634 Loss: 0.230631
2023-01-03 19:57: Train Epoch 1: 315/634 Loss: 0.217643
2023-01-03 19:58: Train Epoch 1: 319/634 Loss: 0.218107
2023-01-03 19:59: Train Epoch 1: 323/634 Loss: 0.211909
2023-01-03 20:00: Train Epoch 1: 327/634 Loss: 0.199979
2023-01-03 20:02: Train Epoch 1: 331/634 Loss: 0.217663
2023-01-03 20:03: Train Epoch 1: 335/634 Loss: 0.230642
2023-01-03 20:04: Train Epoch 1: 339/634 Loss: 0.211485
2023-01-03 20:05: Train Epoch 1: 343/634 Loss: 0.215912
2023-01-03 20:06: Train Epoch 1: 347/634 Loss: 0.222825
2023-01-03 20:07: Train Epoch 1: 351/634 Loss: 0.209535
2023-01-03 20:08: Train Epoch 1: 355/634 Loss: 0.231110
2023-01-03 20:09: Train Epoch 1: 359/634 Loss: 0.245114
2023-01-03 20:11: Train Epoch 1: 363/634 Loss: 0.228046
2023-01-03 20:12: Train Epoch 1: 367/634 Loss: 0.269460
2023-01-03 20:13: Train Epoch 1: 371/634 Loss: 0.208432
2023-01-03 20:14: Train Epoch 1: 375/634 Loss: 0.226519
2023-01-03 20:15: Train Epoch 1: 379/634 Loss: 0.263663
2023-01-03 20:16: Train Epoch 1: 383/634 Loss: 0.199755
2023-01-03 20:17: Train Epoch 1: 387/634 Loss: 0.268816
2023-01-03 20:18: Train Epoch 1: 391/634 Loss: 0.209779
2023-01-03 20:19: Train Epoch 1: 395/634 Loss: 0.219029
2023-01-03 20:21: Train Epoch 1: 399/634 Loss: 0.224197
2023-01-03 20:22: Train Epoch 1: 403/634 Loss: 0.209297
2023-01-03 20:23: Train Epoch 1: 407/634 Loss: 0.205394
2023-01-03 20:24: Train Epoch 1: 411/634 Loss: 0.194711
2023-01-03 20:25: Train Epoch 1: 415/634 Loss: 0.184151
2023-01-03 20:26: Train Epoch 1: 419/634 Loss: 0.196596
2023-01-03 20:27: Train Epoch 1: 423/634 Loss: 0.207906
2023-01-03 20:28: Train Epoch 1: 427/634 Loss: 0.200232
2023-01-03 20:30: Train Epoch 1: 431/634 Loss: 0.209480
2023-01-03 20:31: Train Epoch 1: 435/634 Loss: 0.202403
2023-01-03 20:32: Train Epoch 1: 439/634 Loss: 0.196264
2023-01-03 20:33: Train Epoch 1: 443/634 Loss: 0.197095
2023-01-03 20:34: Train Epoch 1: 447/634 Loss: 0.190811
2023-01-03 20:35: Train Epoch 1: 451/634 Loss: 0.202345
2023-01-03 20:36: Train Epoch 1: 455/634 Loss: 0.195098
2023-01-03 20:37: Train Epoch 1: 459/634 Loss: 0.198028
2023-01-03 20:38: Train Epoch 1: 463/634 Loss: 0.186737
2023-01-03 20:40: Train Epoch 1: 467/634 Loss: 0.215813
2023-01-03 20:41: Train Epoch 1: 471/634 Loss: 0.220324
2023-01-03 20:42: Train Epoch 1: 475/634 Loss: 0.207261
2023-01-03 20:43: Train Epoch 1: 479/634 Loss: 0.216002
2023-01-03 20:44: Train Epoch 1: 483/634 Loss: 0.192938
2023-01-03 20:45: Train Epoch 1: 487/634 Loss: 0.213968
2023-01-03 20:46: Train Epoch 1: 491/634 Loss: 0.217295
2023-01-03 20:48: Train Epoch 1: 495/634 Loss: 0.177334
2023-01-03 20:49: Train Epoch 1: 499/634 Loss: 0.224675
2023-01-03 20:50: Train Epoch 1: 503/634 Loss: 0.205686
2023-01-03 20:51: Train Epoch 1: 507/634 Loss: 0.219264
2023-01-03 20:52: Train Epoch 1: 511/634 Loss: 0.215345
2023-01-03 20:53: Train Epoch 1: 515/634 Loss: 0.216576
2023-01-03 20:54: Train Epoch 1: 519/634 Loss: 0.179439
2023-01-03 20:56: Train Epoch 1: 523/634 Loss: 0.213563
2023-01-03 20:57: Train Epoch 1: 527/634 Loss: 0.209809
2023-01-03 20:58: Train Epoch 1: 531/634 Loss: 0.186107
2023-01-03 20:59: Train Epoch 1: 535/634 Loss: 0.210663
2023-01-03 21:00: Train Epoch 1: 539/634 Loss: 0.227294
2023-01-03 21:01: Train Epoch 1: 543/634 Loss: 0.213445
2023-01-03 21:02: Train Epoch 1: 547/634 Loss: 0.196791
2023-01-03 21:04: Train Epoch 1: 551/634 Loss: 0.251136
2023-01-03 21:05: Train Epoch 1: 555/634 Loss: 0.255983
2023-01-03 21:06: Train Epoch 1: 559/634 Loss: 0.198097
2023-01-03 21:07: Train Epoch 1: 563/634 Loss: 0.195748
2023-01-03 21:08: Train Epoch 1: 567/634 Loss: 0.188691
2023-01-03 21:09: Train Epoch 1: 571/634 Loss: 0.189082
2023-01-03 21:10: Train Epoch 1: 575/634 Loss: 0.226859
2023-01-03 21:11: Train Epoch 1: 579/634 Loss: 0.200070
2023-01-03 21:13: Train Epoch 1: 583/634 Loss: 0.211751
2023-01-03 21:14: Train Epoch 1: 587/634 Loss: 0.208368
2023-01-03 21:15: Train Epoch 1: 591/634 Loss: 0.203496
2023-01-03 21:16: Train Epoch 1: 595/634 Loss: 0.200935
2023-01-03 21:17: Train Epoch 1: 599/634 Loss: 0.205231
2023-01-03 21:18: Train Epoch 1: 603/634 Loss: 0.216206
2023-01-03 21:19: Train Epoch 1: 607/634 Loss: 0.235303
2023-01-03 21:20: Train Epoch 1: 611/634 Loss: 0.224165
2023-01-03 21:21: Train Epoch 1: 615/634 Loss: 0.195703
2023-01-03 21:23: Train Epoch 1: 619/634 Loss: 0.219541
2023-01-03 21:24: Train Epoch 1: 623/634 Loss: 0.205028
2023-01-03 21:25: Train Epoch 1: 627/634 Loss: 0.214915
2023-01-03 21:26: Train Epoch 1: 631/634 Loss: 0.254820
2023-01-03 21:27: Train Epoch 1: 633/634 Loss: 0.088999
2023-01-03 21:27: **********Train Epoch 1: averaged Loss: 0.271134 
2023-01-03 21:27: 
Epoch time elapsed: 10788.093899011612

2023-01-03 21:31: 
 metrics validation: {'precision': 0.7654867256637168, 'recall': 0.26615384615384613, 'f1-score': 0.39497716894977164, 'support': 1300, 'AUC': 0.8480615384615385, 'AUCPR': 0.7173582079266922, 'TP': 346, 'FP': 106, 'TN': 2494, 'FN': 954} 

2023-01-03 21:31: **********Val Epoch 1: average Loss: 0.248488
2023-01-03 21:31: *********************************Current best model saved!
2023-01-03 21:36: 
 Testing metrics {'precision': 0.8803827751196173, 'recall': 0.4495114006514658, 'f1-score': 0.5951482479784367, 'support': 1228, 'AUC': 0.8788568048467358, 'AUCPR': 0.8073363362545367, 'TP': 552, 'FP': 75, 'TN': 2381, 'FN': 676} 

2023-01-03 21:51: 
 Testing metrics {'precision': 0.9412893323100537, 'recall': 0.5566144769684592, 'f1-score': 0.6995579637815484, 'support': 4407, 'AUC': 0.9604215893305457, 'AUCPR': 0.9179139001654203, 'TP': 2453, 'FP': 153, 'TN': 8661, 'FN': 1954} 

2023-01-03 21:52: Train Epoch 2: 3/634 Loss: 0.233093
2023-01-03 21:54: Train Epoch 2: 7/634 Loss: 0.224547
2023-01-03 21:55: Train Epoch 2: 11/634 Loss: 0.188125
2023-01-03 21:56: Train Epoch 2: 15/634 Loss: 0.256806
2023-01-03 21:57: Train Epoch 2: 19/634 Loss: 0.228695
2023-01-03 21:59: Train Epoch 2: 23/634 Loss: 0.197449
2023-01-03 22:00: Train Epoch 2: 27/634 Loss: 0.268528
2023-01-03 22:01: Train Epoch 2: 31/634 Loss: 0.212245
2023-01-03 22:02: Train Epoch 2: 35/634 Loss: 0.208823
2023-01-03 22:04: Train Epoch 2: 39/634 Loss: 0.187904
2023-01-03 22:05: Train Epoch 2: 43/634 Loss: 0.200193
2023-01-03 22:06: Train Epoch 2: 47/634 Loss: 0.215599
2023-01-03 22:07: Train Epoch 2: 51/634 Loss: 0.212702
2023-01-03 22:09: Train Epoch 2: 55/634 Loss: 0.190421
2023-01-03 22:10: Train Epoch 2: 59/634 Loss: 0.201188
2023-01-03 22:11: Train Epoch 2: 63/634 Loss: 0.195180
2023-01-03 22:12: Train Epoch 2: 67/634 Loss: 0.199496
2023-01-03 22:14: Train Epoch 2: 71/634 Loss: 0.200446
2023-01-03 22:15: Train Epoch 2: 75/634 Loss: 0.195514
2023-01-03 22:16: Train Epoch 2: 79/634 Loss: 0.197521
2023-01-03 22:18: Train Epoch 2: 83/634 Loss: 0.236274
2023-01-03 22:19: Train Epoch 2: 87/634 Loss: 0.188697
2023-01-03 22:20: Train Epoch 2: 91/634 Loss: 0.217275
2023-01-03 22:21: Train Epoch 2: 95/634 Loss: 0.237699
2023-01-03 22:22: Train Epoch 2: 99/634 Loss: 0.215171
2023-01-03 22:24: Train Epoch 2: 103/634 Loss: 0.204953
2023-01-03 22:25: Train Epoch 2: 107/634 Loss: 0.180599
2023-01-03 22:26: Train Epoch 2: 111/634 Loss: 0.192942
2023-01-03 22:27: Train Epoch 2: 115/634 Loss: 0.184428
2023-01-03 22:29: Train Epoch 2: 119/634 Loss: 0.210791
2023-01-03 22:30: Train Epoch 2: 123/634 Loss: 0.196147
2023-01-03 22:31: Train Epoch 2: 127/634 Loss: 0.215579
2023-01-03 22:33: Train Epoch 2: 131/634 Loss: 0.172186
2023-01-03 22:34: Train Epoch 2: 135/634 Loss: 0.205567
2023-01-03 22:35: Train Epoch 2: 139/634 Loss: 0.192365
2023-01-03 22:36: Train Epoch 2: 143/634 Loss: 0.191152
2023-01-03 22:38: Train Epoch 2: 147/634 Loss: 0.191602
2023-01-03 22:39: Train Epoch 2: 151/634 Loss: 0.185105
2023-01-03 22:40: Train Epoch 2: 155/634 Loss: 0.212306
2023-01-03 22:41: Train Epoch 2: 159/634 Loss: 0.226061
2023-01-03 22:42: Train Epoch 2: 163/634 Loss: 0.202764
2023-01-03 22:43: Train Epoch 2: 167/634 Loss: 0.200014
2023-01-03 22:45: Train Epoch 2: 171/634 Loss: 0.214421
2023-01-03 22:46: Train Epoch 2: 175/634 Loss: 0.184757
2023-01-03 22:47: Train Epoch 2: 179/634 Loss: 0.208201
2023-01-03 22:49: Train Epoch 2: 183/634 Loss: 0.201362
2023-01-03 22:50: Train Epoch 2: 187/634 Loss: 0.210865
2023-01-03 22:51: Train Epoch 2: 191/634 Loss: 0.221722
2023-01-03 22:52: Train Epoch 2: 195/634 Loss: 0.171398
2023-01-03 22:54: Train Epoch 2: 199/634 Loss: 0.220612
2023-01-03 22:55: Train Epoch 2: 203/634 Loss: 0.201567
2023-01-03 22:56: Train Epoch 2: 207/634 Loss: 0.193373
2023-01-03 22:57: Train Epoch 2: 211/634 Loss: 0.214937
2023-01-03 22:59: Train Epoch 2: 215/634 Loss: 0.239301
2023-01-03 23:00: Train Epoch 2: 219/634 Loss: 0.208157
2023-01-03 23:01: Train Epoch 2: 223/634 Loss: 0.240189
2023-01-03 23:02: Train Epoch 2: 227/634 Loss: 0.185208
2023-01-03 23:04: Train Epoch 2: 231/634 Loss: 0.288552
2023-01-03 23:05: Train Epoch 2: 235/634 Loss: 0.212017
2023-01-03 23:06: Train Epoch 2: 239/634 Loss: 0.211824
2023-01-03 23:08: Train Epoch 2: 243/634 Loss: 0.242661
2023-01-03 23:09: Train Epoch 2: 247/634 Loss: 0.207067
2023-01-03 23:10: Train Epoch 2: 251/634 Loss: 0.195921
2023-01-03 23:11: Train Epoch 2: 255/634 Loss: 0.224902
2023-01-03 23:13: Train Epoch 2: 259/634 Loss: 0.158643
2023-01-03 23:14: Train Epoch 2: 263/634 Loss: 0.330567
2023-01-03 23:15: Train Epoch 2: 267/634 Loss: 0.180433
2023-01-03 23:16: Train Epoch 2: 271/634 Loss: 0.200030
2023-01-03 23:17: Train Epoch 2: 275/634 Loss: 0.312204
2023-01-03 23:18: Train Epoch 2: 279/634 Loss: 0.194058
2023-01-03 23:19: Train Epoch 2: 283/634 Loss: 0.219559
2023-01-03 23:20: Train Epoch 2: 287/634 Loss: 0.205184
2023-01-03 23:21: Train Epoch 2: 291/634 Loss: 0.222628
2023-01-03 23:22: Train Epoch 2: 295/634 Loss: 0.197343
2023-01-03 23:24: Train Epoch 2: 299/634 Loss: 0.204734
2023-01-03 23:25: Train Epoch 2: 303/634 Loss: 0.209266
2023-01-03 23:26: Train Epoch 2: 307/634 Loss: 0.195305
2023-01-03 23:27: Train Epoch 2: 311/634 Loss: 0.236317
2023-01-03 23:28: Train Epoch 2: 315/634 Loss: 0.190714
2023-01-03 23:29: Train Epoch 2: 319/634 Loss: 0.211973
2023-01-03 23:30: Train Epoch 2: 323/634 Loss: 0.168766
2023-01-03 23:31: Train Epoch 2: 327/634 Loss: 0.223911
2023-01-03 23:32: Train Epoch 2: 331/634 Loss: 0.185857
2023-01-03 23:34: Train Epoch 2: 335/634 Loss: 0.166431
2023-01-03 23:35: Train Epoch 2: 339/634 Loss: 0.181376
2023-01-03 23:36: Train Epoch 2: 343/634 Loss: 0.215845
2023-01-03 23:37: Train Epoch 2: 347/634 Loss: 0.201955
2023-01-03 23:38: Train Epoch 2: 351/634 Loss: 0.213866
2023-01-03 23:39: Train Epoch 2: 355/634 Loss: 0.204066
2023-01-03 23:40: Train Epoch 2: 359/634 Loss: 0.222191
2023-01-03 23:41: Train Epoch 2: 363/634 Loss: 0.219798
2023-01-03 23:43: Train Epoch 2: 367/634 Loss: 0.258543
2023-01-03 23:44: Train Epoch 2: 371/634 Loss: 0.211683
2023-01-03 23:45: Train Epoch 2: 375/634 Loss: 0.233243
2023-01-03 23:46: Train Epoch 2: 379/634 Loss: 0.217310
2023-01-03 23:47: Train Epoch 2: 383/634 Loss: 0.203822
2023-01-03 23:48: Train Epoch 2: 387/634 Loss: 0.200600
2023-01-03 23:50: Train Epoch 2: 391/634 Loss: 0.218672
2023-01-03 23:51: Train Epoch 2: 395/634 Loss: 0.218919
2023-01-03 23:52: Train Epoch 2: 399/634 Loss: 0.212360
2023-01-03 23:53: Train Epoch 2: 403/634 Loss: 0.208770
2023-01-03 23:54: Train Epoch 2: 407/634 Loss: 0.172326
2023-01-03 23:55: Train Epoch 2: 411/634 Loss: 0.204654
2023-01-03 23:56: Train Epoch 2: 415/634 Loss: 0.223090
2023-01-03 23:58: Train Epoch 2: 419/634 Loss: 0.217129
2023-01-03 23:59: Train Epoch 2: 423/634 Loss: 0.207056
2023-01-04 00:00: Train Epoch 2: 427/634 Loss: 0.204321
2023-01-04 00:01: Train Epoch 2: 431/634 Loss: 0.231264
2023-01-04 00:02: Train Epoch 2: 435/634 Loss: 0.201020
2023-01-04 00:03: Train Epoch 2: 439/634 Loss: 0.212882
2023-01-04 00:05: Train Epoch 2: 443/634 Loss: 0.216631
2023-01-04 00:06: Train Epoch 2: 447/634 Loss: 0.188075
2023-01-04 00:07: Train Epoch 2: 451/634 Loss: 0.211499
2023-01-04 00:08: Train Epoch 2: 455/634 Loss: 0.228190
2023-01-04 00:09: Train Epoch 2: 459/634 Loss: 0.200906
2023-01-04 00:10: Train Epoch 2: 463/634 Loss: 0.206738
2023-01-04 00:12: Train Epoch 2: 467/634 Loss: 0.185607
2023-01-04 00:13: Train Epoch 2: 471/634 Loss: 0.193214
2023-01-04 00:14: Train Epoch 2: 475/634 Loss: 0.210632
2023-01-04 00:15: Train Epoch 2: 479/634 Loss: 0.181204
2023-01-04 00:16: Train Epoch 2: 483/634 Loss: 0.188260
2023-01-04 00:17: Train Epoch 2: 487/634 Loss: 0.190023
2023-01-04 00:19: Train Epoch 2: 491/634 Loss: 0.201787
2023-01-04 00:20: Train Epoch 2: 495/634 Loss: 0.177984
2023-01-04 00:21: Train Epoch 2: 499/634 Loss: 0.174693
2023-01-04 00:22: Train Epoch 2: 503/634 Loss: 0.207300
2023-01-04 00:23: Train Epoch 2: 507/634 Loss: 0.184563
2023-01-04 00:25: Train Epoch 2: 511/634 Loss: 0.186250
2023-01-04 00:26: Train Epoch 2: 515/634 Loss: 0.215204
2023-01-04 00:27: Train Epoch 2: 519/634 Loss: 0.214597
2023-01-04 00:28: Train Epoch 2: 523/634 Loss: 0.190459
2023-01-04 00:29: Train Epoch 2: 527/634 Loss: 0.200700
2023-01-04 00:30: Train Epoch 2: 531/634 Loss: 0.174906
2023-01-04 00:32: Train Epoch 2: 535/634 Loss: 0.191457
2023-01-04 00:33: Train Epoch 2: 539/634 Loss: 0.164984
2023-01-04 00:34: Train Epoch 2: 543/634 Loss: 0.167087
2023-01-04 00:35: Train Epoch 2: 547/634 Loss: 0.207587
2023-01-04 00:36: Train Epoch 2: 551/634 Loss: 0.189271
2023-01-04 00:37: Train Epoch 2: 555/634 Loss: 0.184510
2023-01-04 00:39: Train Epoch 2: 559/634 Loss: 0.188406
2023-01-04 00:40: Train Epoch 2: 563/634 Loss: 0.185907
2023-01-04 00:41: Train Epoch 2: 567/634 Loss: 0.206184
2023-01-04 00:42: Train Epoch 2: 571/634 Loss: 0.199080
2023-01-04 00:43: Train Epoch 2: 575/634 Loss: 0.182981
2023-01-04 00:44: Train Epoch 2: 579/634 Loss: 0.194940
2023-01-04 00:46: Train Epoch 2: 583/634 Loss: 0.177899
2023-01-04 00:47: Train Epoch 2: 587/634 Loss: 0.162962
2023-01-04 00:48: Train Epoch 2: 591/634 Loss: 0.192535
2023-01-04 00:49: Train Epoch 2: 595/634 Loss: 0.181900
2023-01-04 00:50: Train Epoch 2: 599/634 Loss: 0.162740
2023-01-04 00:51: Train Epoch 2: 603/634 Loss: 0.192845
2023-01-04 00:52: Train Epoch 2: 607/634 Loss: 0.189250
2023-01-04 00:53: Train Epoch 2: 611/634 Loss: 0.179708
2023-01-04 00:54: Train Epoch 2: 615/634 Loss: 0.168937
2023-01-04 00:56: Train Epoch 2: 619/634 Loss: 0.218168
2023-01-04 00:57: Train Epoch 2: 623/634 Loss: 0.216685
2023-01-04 00:58: Train Epoch 2: 627/634 Loss: 0.172456
2023-01-04 00:59: Train Epoch 2: 631/634 Loss: 0.196759
2023-01-04 01:00: Train Epoch 2: 633/634 Loss: 0.097472
2023-01-04 01:00: **********Train Epoch 2: averaged Loss: 0.203811 
2023-01-04 01:00: 
Epoch time elapsed: 11320.47729921341

2023-01-04 01:04: 
 metrics validation: {'precision': 0.6642670157068062, 'recall': 0.7807692307692308, 'f1-score': 0.7178217821782178, 'support': 1300, 'AUC': 0.871485798816568, 'AUCPR': 0.7536871954986015, 'TP': 1015, 'FP': 513, 'TN': 2087, 'FN': 285} 

2023-01-04 01:04: **********Val Epoch 2: average Loss: 0.208174
2023-01-04 01:04: *********************************Current best model saved!
2023-01-04 01:08: 
 Testing metrics {'precision': 0.7322206095791002, 'recall': 0.8216612377850163, 'f1-score': 0.7743668457405987, 'support': 1228, 'AUC': 0.901324549862598, 'AUCPR': 0.8391306033344283, 'TP': 1009, 'FP': 369, 'TN': 2087, 'FN': 219} 

2023-01-04 01:23: 
 Testing metrics {'precision': 0.8204819277108434, 'recall': 0.9271613342409802, 'f1-score': 0.8705656759348035, 'support': 4407, 'AUC': 0.9654447338637414, 'AUCPR': 0.9323009306982912, 'TP': 4086, 'FP': 894, 'TN': 7920, 'FN': 321} 

2023-01-04 01:24: Train Epoch 3: 3/634 Loss: 0.236911
2023-01-04 01:25: Train Epoch 3: 7/634 Loss: 0.180824
2023-01-04 01:26: Train Epoch 3: 11/634 Loss: 0.191496
2023-01-04 01:27: Train Epoch 3: 15/634 Loss: 0.184655
2023-01-04 01:29: Train Epoch 3: 19/634 Loss: 0.170527
2023-01-04 01:30: Train Epoch 3: 23/634 Loss: 0.215374
2023-01-04 01:31: Train Epoch 3: 27/634 Loss: 0.204656
2023-01-04 01:32: Train Epoch 3: 31/634 Loss: 0.183423
2023-01-04 01:33: Train Epoch 3: 35/634 Loss: 0.198917
2023-01-04 01:34: Train Epoch 3: 39/634 Loss: 0.201241
2023-01-04 01:35: Train Epoch 3: 43/634 Loss: 0.219790
2023-01-04 01:36: Train Epoch 3: 47/634 Loss: 0.189914
2023-01-04 01:37: Train Epoch 3: 51/634 Loss: 0.223216
2023-01-04 01:39: Train Epoch 3: 55/634 Loss: 0.203112
2023-01-04 01:40: Train Epoch 3: 59/634 Loss: 0.195290
2023-01-04 01:41: Train Epoch 3: 63/634 Loss: 0.187196
2023-01-04 01:42: Train Epoch 3: 67/634 Loss: 0.187955
2023-01-04 01:43: Train Epoch 3: 71/634 Loss: 0.188285
2023-01-04 01:44: Train Epoch 3: 75/634 Loss: 0.181661
2023-01-04 01:46: Train Epoch 3: 79/634 Loss: 0.197737
2023-01-04 01:47: Train Epoch 3: 83/634 Loss: 0.193848
2023-01-04 01:48: Train Epoch 3: 87/634 Loss: 0.197108
2023-01-04 01:49: Train Epoch 3: 91/634 Loss: 0.203273
2023-01-04 01:51: Train Epoch 3: 95/634 Loss: 0.188117
2023-01-04 01:52: Train Epoch 3: 99/634 Loss: 0.202732
2023-01-04 01:53: Train Epoch 3: 103/634 Loss: 0.175183
2023-01-04 01:54: Train Epoch 3: 107/634 Loss: 0.182360
2023-01-04 01:56: Train Epoch 3: 111/634 Loss: 0.186180
2023-01-04 01:57: Train Epoch 3: 115/634 Loss: 0.185724
2023-01-04 01:58: Train Epoch 3: 119/634 Loss: 0.200831
2023-01-04 02:00: Train Epoch 3: 123/634 Loss: 0.200178
2023-01-04 02:01: Train Epoch 3: 127/634 Loss: 0.192318
2023-01-04 02:02: Train Epoch 3: 131/634 Loss: 0.221038
2023-01-04 02:03: Train Epoch 3: 135/634 Loss: 0.198502
2023-01-04 02:05: Train Epoch 3: 139/634 Loss: 0.195140
2023-01-04 02:06: Train Epoch 3: 143/634 Loss: 0.186892
2023-01-04 02:07: Train Epoch 3: 147/634 Loss: 0.189418
2023-01-04 02:09: Train Epoch 3: 151/634 Loss: 0.172362
2023-01-04 02:10: Train Epoch 3: 155/634 Loss: 0.208943
2023-01-04 02:11: Train Epoch 3: 159/634 Loss: 0.203803
2023-01-04 02:12: Train Epoch 3: 163/634 Loss: 0.170722
2023-01-04 02:14: Train Epoch 3: 167/634 Loss: 0.174704
2023-01-04 02:15: Train Epoch 3: 171/634 Loss: 0.196529
2023-01-04 02:16: Train Epoch 3: 175/634 Loss: 0.160157
2023-01-04 02:18: Train Epoch 3: 179/634 Loss: 0.217864
2023-01-04 02:19: Train Epoch 3: 183/634 Loss: 0.194830
2023-01-04 02:20: Train Epoch 3: 187/634 Loss: 0.185103
2023-01-04 02:21: Train Epoch 3: 191/634 Loss: 0.198296
2023-01-04 02:23: Train Epoch 3: 195/634 Loss: 0.216794
2023-01-04 02:24: Train Epoch 3: 199/634 Loss: 0.241969
2023-01-04 02:25: Train Epoch 3: 203/634 Loss: 0.184086
2023-01-04 02:26: Train Epoch 3: 207/634 Loss: 0.168725
2023-01-04 02:28: Train Epoch 3: 211/634 Loss: 0.183447
2023-01-04 02:29: Train Epoch 3: 215/634 Loss: 0.203033
2023-01-04 02:30: Train Epoch 3: 219/634 Loss: 0.193745
2023-01-04 02:31: Train Epoch 3: 223/634 Loss: 0.159837
2023-01-04 02:32: Train Epoch 3: 227/634 Loss: 0.194064
2023-01-04 02:34: Train Epoch 3: 231/634 Loss: 0.194672
2023-01-04 02:35: Train Epoch 3: 235/634 Loss: 0.220042
2023-01-04 02:36: Train Epoch 3: 239/634 Loss: 0.216698
2023-01-04 02:38: Train Epoch 3: 243/634 Loss: 0.177626
2023-01-04 02:39: Train Epoch 3: 247/634 Loss: 0.205048
2023-01-04 02:40: Train Epoch 3: 251/634 Loss: 0.191897
2023-01-04 02:41: Train Epoch 3: 255/634 Loss: 0.187602
2023-01-04 02:42: Train Epoch 3: 259/634 Loss: 0.179557
2023-01-04 02:44: Train Epoch 3: 263/634 Loss: 0.180912
2023-01-04 02:45: Train Epoch 3: 267/634 Loss: 0.169854
2023-01-04 02:46: Train Epoch 3: 271/634 Loss: 0.174316
2023-01-04 02:47: Train Epoch 3: 275/634 Loss: 0.208581
2023-01-04 02:48: Train Epoch 3: 279/634 Loss: 0.201542
2023-01-04 02:49: Train Epoch 3: 283/634 Loss: 0.215534
2023-01-04 02:50: Train Epoch 3: 287/634 Loss: 0.183387
2023-01-04 02:52: Train Epoch 3: 291/634 Loss: 0.170910
2023-01-04 02:53: Train Epoch 3: 295/634 Loss: 0.176376
2023-01-04 02:54: Train Epoch 3: 299/634 Loss: 0.190733
2023-01-04 02:55: Train Epoch 3: 303/634 Loss: 0.195390
2023-01-04 02:56: Train Epoch 3: 307/634 Loss: 0.161131
2023-01-04 02:57: Train Epoch 3: 311/634 Loss: 0.195929
2023-01-04 02:58: Train Epoch 3: 315/634 Loss: 0.173609
2023-01-04 02:59: Train Epoch 3: 319/634 Loss: 0.149900
2023-01-04 03:01: Train Epoch 3: 323/634 Loss: 0.179658
2023-01-04 03:02: Train Epoch 3: 327/634 Loss: 0.152772
2023-01-04 03:03: Train Epoch 3: 331/634 Loss: 0.217109
2023-01-04 03:04: Train Epoch 3: 335/634 Loss: 0.213293
2023-01-04 03:05: Train Epoch 3: 339/634 Loss: 0.194434
2023-01-04 03:06: Train Epoch 3: 343/634 Loss: 0.189279
2023-01-04 03:07: Train Epoch 3: 347/634 Loss: 0.186891
2023-01-04 03:08: Train Epoch 3: 351/634 Loss: 0.179082
2023-01-04 03:10: Train Epoch 3: 355/634 Loss: 0.188469
2023-01-04 03:11: Train Epoch 3: 359/634 Loss: 0.185504
2023-01-04 03:12: Train Epoch 3: 363/634 Loss: 0.180781
2023-01-04 03:13: Train Epoch 3: 367/634 Loss: 0.191568
2023-01-04 03:14: Train Epoch 3: 371/634 Loss: 0.198242
2023-01-04 03:15: Train Epoch 3: 375/634 Loss: 0.163833
2023-01-04 03:17: Train Epoch 3: 379/634 Loss: 0.182070
2023-01-04 03:18: Train Epoch 3: 383/634 Loss: 0.172159
2023-01-04 03:19: Train Epoch 3: 387/634 Loss: 0.169709
2023-01-04 03:20: Train Epoch 3: 391/634 Loss: 0.224627
2023-01-04 03:21: Train Epoch 3: 395/634 Loss: 0.196836
2023-01-04 03:22: Train Epoch 3: 399/634 Loss: 0.169186
2023-01-04 03:23: Train Epoch 3: 403/634 Loss: 0.172825
2023-01-04 03:25: Train Epoch 3: 407/634 Loss: 0.199816
2023-01-04 03:26: Train Epoch 3: 411/634 Loss: 0.222623
2023-01-04 03:27: Train Epoch 3: 415/634 Loss: 0.182898
2023-01-04 03:28: Train Epoch 3: 419/634 Loss: 0.185692
2023-01-04 03:29: Train Epoch 3: 423/634 Loss: 0.193938
2023-01-04 03:30: Train Epoch 3: 427/634 Loss: 0.191230
2023-01-04 03:31: Train Epoch 3: 431/634 Loss: 0.218811
2023-01-04 03:33: Train Epoch 3: 435/634 Loss: 0.197416
2023-01-04 03:34: Train Epoch 3: 439/634 Loss: 0.193517
2023-01-04 03:35: Train Epoch 3: 443/634 Loss: 0.177128
2023-01-04 03:36: Train Epoch 3: 447/634 Loss: 0.193121
2023-01-04 03:37: Train Epoch 3: 451/634 Loss: 0.217051
2023-01-04 03:38: Train Epoch 3: 455/634 Loss: 0.157034
2023-01-04 03:39: Train Epoch 3: 459/634 Loss: 0.173190
2023-01-04 03:40: Train Epoch 3: 463/634 Loss: 0.182608
2023-01-04 03:42: Train Epoch 3: 467/634 Loss: 0.162600
2023-01-04 03:43: Train Epoch 3: 471/634 Loss: 0.195854
2023-01-04 03:44: Train Epoch 3: 475/634 Loss: 0.194413
2023-01-04 03:45: Train Epoch 3: 479/634 Loss: 0.200637
2023-01-04 03:46: Train Epoch 3: 483/634 Loss: 0.204604
2023-01-04 03:47: Train Epoch 3: 487/634 Loss: 0.183267
2023-01-04 03:48: Train Epoch 3: 491/634 Loss: 0.196694
2023-01-04 03:49: Train Epoch 3: 495/634 Loss: 0.213133
2023-01-04 03:51: Train Epoch 3: 499/634 Loss: 0.161554
2023-01-04 03:52: Train Epoch 3: 503/634 Loss: 0.177510
2023-01-04 03:53: Train Epoch 3: 507/634 Loss: 0.173278
2023-01-04 03:54: Train Epoch 3: 511/634 Loss: 0.234383
2023-01-04 03:55: Train Epoch 3: 515/634 Loss: 0.172732
2023-01-04 03:56: Train Epoch 3: 519/634 Loss: 0.182537
2023-01-04 03:57: Train Epoch 3: 523/634 Loss: 0.177029
2023-01-04 03:58: Train Epoch 3: 527/634 Loss: 0.190828
2023-01-04 04:00: Train Epoch 3: 531/634 Loss: 0.219402
2023-01-04 04:01: Train Epoch 3: 535/634 Loss: 0.169863
2023-01-04 04:02: Train Epoch 3: 539/634 Loss: 0.182415
2023-01-04 04:03: Train Epoch 3: 543/634 Loss: 0.202218
2023-01-04 04:04: Train Epoch 3: 547/634 Loss: 0.199716
2023-01-04 04:05: Train Epoch 3: 551/634 Loss: 0.226625
2023-01-04 04:07: Train Epoch 3: 555/634 Loss: 0.182240
2023-01-04 04:08: Train Epoch 3: 559/634 Loss: 0.194394
2023-01-04 04:09: Train Epoch 3: 563/634 Loss: 0.205616
2023-01-04 04:10: Train Epoch 3: 567/634 Loss: 0.189781
2023-01-04 04:11: Train Epoch 3: 571/634 Loss: 0.191490
2023-01-04 04:12: Train Epoch 3: 575/634 Loss: 0.189406
2023-01-04 04:14: Train Epoch 3: 579/634 Loss: 0.203259
2023-01-04 04:15: Train Epoch 3: 583/634 Loss: 0.221073
2023-01-04 04:16: Train Epoch 3: 587/634 Loss: 0.196777
2023-01-04 04:17: Train Epoch 3: 591/634 Loss: 0.154456
2023-01-04 04:18: Train Epoch 3: 595/634 Loss: 0.251139
2023-01-04 04:20: Train Epoch 3: 599/634 Loss: 0.199951
2023-01-04 04:21: Train Epoch 3: 603/634 Loss: 0.198647
2023-01-04 04:22: Train Epoch 3: 607/634 Loss: 0.195914
2023-01-04 04:23: Train Epoch 3: 611/634 Loss: 0.167305
2023-01-04 04:24: Train Epoch 3: 615/634 Loss: 0.194978
2023-01-04 04:25: Train Epoch 3: 619/634 Loss: 0.185056
2023-01-04 04:27: Train Epoch 3: 623/634 Loss: 0.177884
2023-01-04 04:28: Train Epoch 3: 627/634 Loss: 0.173129
2023-01-04 04:29: Train Epoch 3: 631/634 Loss: 0.190290
2023-01-04 04:30: Train Epoch 3: 633/634 Loss: 0.063718
2023-01-04 04:30: **********Train Epoch 3: averaged Loss: 0.190777 
2023-01-04 04:30: 
Epoch time elapsed: 11212.951211690903

2023-01-04 04:34: 
 metrics validation: {'precision': 0.752548656163114, 'recall': 0.6246153846153846, 'f1-score': 0.6826397646069777, 'support': 1300, 'AUC': 0.8878127218934911, 'AUCPR': 0.7947471258894806, 'TP': 812, 'FP': 267, 'TN': 2333, 'FN': 488} 

2023-01-04 04:34: **********Val Epoch 3: average Loss: 0.189051
2023-01-04 04:34: *********************************Current best model saved!
2023-01-04 04:39: 
 Testing metrics {'precision': 0.8200956937799043, 'recall': 0.6978827361563518, 'f1-score': 0.7540695116586009, 'support': 1228, 'AUC': 0.9050593374996021, 'AUCPR': 0.8428690273119946, 'TP': 857, 'FP': 188, 'TN': 2268, 'FN': 371} 

2023-01-04 04:54: 
 Testing metrics {'precision': 0.8798191970220686, 'recall': 0.7508509189925119, 'f1-score': 0.8102350636630753, 'support': 4407, 'AUC': 0.9541577030869006, 'AUCPR': 0.908737200669726, 'TP': 3309, 'FP': 452, 'TN': 8362, 'FN': 1098} 

2023-01-04 04:55: Train Epoch 4: 3/634 Loss: 0.175373
2023-01-04 04:56: Train Epoch 4: 7/634 Loss: 0.184419
2023-01-04 04:57: Train Epoch 4: 11/634 Loss: 0.156961
2023-01-04 04:58: Train Epoch 4: 15/634 Loss: 0.201018
2023-01-04 04:59: Train Epoch 4: 19/634 Loss: 0.179879
2023-01-04 05:00: Train Epoch 4: 23/634 Loss: 0.226791
2023-01-04 05:01: Train Epoch 4: 27/634 Loss: 0.203830
2023-01-04 05:03: Train Epoch 4: 31/634 Loss: 0.169736
2023-01-04 05:04: Train Epoch 4: 35/634 Loss: 0.191446
2023-01-04 05:05: Train Epoch 4: 39/634 Loss: 0.163859
2023-01-04 05:06: Train Epoch 4: 43/634 Loss: 0.192842
2023-01-04 05:07: Train Epoch 4: 47/634 Loss: 0.185992
2023-01-04 05:08: Train Epoch 4: 51/634 Loss: 0.189804
2023-01-04 05:09: Train Epoch 4: 55/634 Loss: 0.169323
2023-01-04 05:10: Train Epoch 4: 59/634 Loss: 0.168144
2023-01-04 05:11: Train Epoch 4: 63/634 Loss: 0.188974
2023-01-04 05:13: Train Epoch 4: 67/634 Loss: 0.208801
2023-01-04 05:14: Train Epoch 4: 71/634 Loss: 0.163977
2023-01-04 05:15: Train Epoch 4: 75/634 Loss: 0.239915
2023-01-04 05:16: Train Epoch 4: 79/634 Loss: 0.191749
2023-01-04 05:17: Train Epoch 4: 83/634 Loss: 0.219988
2023-01-04 05:18: Train Epoch 4: 87/634 Loss: 0.174813
2023-01-04 05:19: Train Epoch 4: 91/634 Loss: 0.214693
2023-01-04 05:20: Train Epoch 4: 95/634 Loss: 0.178339
2023-01-04 05:22: Train Epoch 4: 99/634 Loss: 0.172547
2023-01-04 05:23: Train Epoch 4: 103/634 Loss: 0.198945
2023-01-04 05:24: Train Epoch 4: 107/634 Loss: 0.186361
2023-01-04 05:25: Train Epoch 4: 111/634 Loss: 0.177295
2023-01-04 05:26: Train Epoch 4: 115/634 Loss: 0.169191
2023-01-04 05:27: Train Epoch 4: 119/634 Loss: 0.198214
2023-01-04 05:28: Train Epoch 4: 123/634 Loss: 0.199297
2023-01-04 05:29: Train Epoch 4: 127/634 Loss: 0.172659
2023-01-04 05:31: Train Epoch 4: 131/634 Loss: 0.153591
2023-01-04 05:32: Train Epoch 4: 135/634 Loss: 0.174628
2023-01-04 05:33: Train Epoch 4: 139/634 Loss: 0.185930
2023-01-04 05:34: Train Epoch 4: 143/634 Loss: 0.174263
2023-01-04 05:35: Train Epoch 4: 147/634 Loss: 0.175138
2023-01-04 05:36: Train Epoch 4: 151/634 Loss: 0.181958
2023-01-04 05:38: Train Epoch 4: 155/634 Loss: 0.190596
2023-01-04 05:39: Train Epoch 4: 159/634 Loss: 0.192960
2023-01-04 05:40: Train Epoch 4: 163/634 Loss: 0.176617
2023-01-04 05:41: Train Epoch 4: 167/634 Loss: 0.164735
2023-01-04 05:42: Train Epoch 4: 171/634 Loss: 0.175569
2023-01-04 05:44: Train Epoch 4: 175/634 Loss: 0.167433
2023-01-04 05:45: Train Epoch 4: 179/634 Loss: 0.190526
2023-01-04 05:46: Train Epoch 4: 183/634 Loss: 0.176060
2023-01-04 05:47: Train Epoch 4: 187/634 Loss: 0.197184
2023-01-04 05:49: Train Epoch 4: 191/634 Loss: 0.166853
2023-01-04 05:50: Train Epoch 4: 195/634 Loss: 0.163566
2023-01-04 05:51: Train Epoch 4: 199/634 Loss: 0.176016
2023-01-04 05:52: Train Epoch 4: 203/634 Loss: 0.211622
2023-01-04 05:53: Train Epoch 4: 207/634 Loss: 0.199567
2023-01-04 05:54: Train Epoch 4: 211/634 Loss: 0.197041
2023-01-04 05:56: Train Epoch 4: 215/634 Loss: 0.206858
2023-01-04 05:57: Train Epoch 4: 219/634 Loss: 0.246785
2023-01-04 05:58: Train Epoch 4: 223/634 Loss: 0.227095
2023-01-04 05:59: Train Epoch 4: 227/634 Loss: 0.171552
2023-01-04 06:00: Train Epoch 4: 231/634 Loss: 0.161088
2023-01-04 06:02: Train Epoch 4: 235/634 Loss: 0.216089
2023-01-04 06:03: Train Epoch 4: 239/634 Loss: 0.205717
2023-01-04 06:04: Train Epoch 4: 243/634 Loss: 0.167746
2023-01-04 06:06: Train Epoch 4: 247/634 Loss: 0.204546
2023-01-04 06:07: Train Epoch 4: 251/634 Loss: 0.178417
2023-01-04 06:08: Train Epoch 4: 255/634 Loss: 0.223328
2023-01-04 06:09: Train Epoch 4: 259/634 Loss: 0.172158
2023-01-04 06:10: Train Epoch 4: 263/634 Loss: 0.192413
2023-01-04 06:12: Train Epoch 4: 267/634 Loss: 0.202454
2023-01-04 06:13: Train Epoch 4: 271/634 Loss: 0.188013
2023-01-04 06:14: Train Epoch 4: 275/634 Loss: 0.191561
2023-01-04 06:15: Train Epoch 4: 279/634 Loss: 0.169786
2023-01-04 06:17: Train Epoch 4: 283/634 Loss: 0.139528
2023-01-04 06:18: Train Epoch 4: 287/634 Loss: 0.194815
2023-01-04 06:19: Train Epoch 4: 291/634 Loss: 0.173601
2023-01-04 06:20: Train Epoch 4: 295/634 Loss: 0.186077
2023-01-04 06:21: Train Epoch 4: 299/634 Loss: 0.165365
2023-01-04 06:22: Train Epoch 4: 303/634 Loss: 0.184545
2023-01-04 06:24: Train Epoch 4: 307/634 Loss: 0.169903
2023-01-04 06:25: Train Epoch 4: 311/634 Loss: 0.186575
2023-01-04 06:26: Train Epoch 4: 315/634 Loss: 0.177899
2023-01-04 06:27: Train Epoch 4: 319/634 Loss: 0.149664
2023-01-04 06:28: Train Epoch 4: 323/634 Loss: 0.148146
2023-01-04 06:29: Train Epoch 4: 327/634 Loss: 0.176201
2023-01-04 06:30: Train Epoch 4: 331/634 Loss: 0.159850
2023-01-04 06:32: Train Epoch 4: 335/634 Loss: 0.211567
2023-01-04 06:33: Train Epoch 4: 339/634 Loss: 0.169780
2023-01-04 06:34: Train Epoch 4: 343/634 Loss: 0.186497
2023-01-04 06:35: Train Epoch 4: 347/634 Loss: 0.157242
2023-01-04 06:36: Train Epoch 4: 351/634 Loss: 0.181676
2023-01-04 06:38: Train Epoch 4: 355/634 Loss: 0.151733
2023-01-04 06:39: Train Epoch 4: 359/634 Loss: 0.172081
2023-01-04 06:40: Train Epoch 4: 363/634 Loss: 0.159578
2023-01-04 06:41: Train Epoch 4: 367/634 Loss: 0.184186
2023-01-04 06:42: Train Epoch 4: 371/634 Loss: 0.148627
2023-01-04 06:43: Train Epoch 4: 375/634 Loss: 0.193671
2023-01-04 06:45: Train Epoch 4: 379/634 Loss: 0.183207
2023-01-04 06:46: Train Epoch 4: 383/634 Loss: 0.173358
2023-01-04 06:47: Train Epoch 4: 387/634 Loss: 0.149241
2023-01-04 06:48: Train Epoch 4: 391/634 Loss: 0.196659
2023-01-04 06:49: Train Epoch 4: 395/634 Loss: 0.169625
2023-01-04 06:50: Train Epoch 4: 399/634 Loss: 0.179199
2023-01-04 06:51: Train Epoch 4: 403/634 Loss: 0.174826
2023-01-04 06:52: Train Epoch 4: 407/634 Loss: 0.164814
2023-01-04 06:54: Train Epoch 4: 411/634 Loss: 0.189741
2023-01-04 06:55: Train Epoch 4: 415/634 Loss: 0.188003
2023-01-04 06:56: Train Epoch 4: 419/634 Loss: 0.209705
2023-01-04 06:57: Train Epoch 4: 423/634 Loss: 0.197188
2023-01-04 06:58: Train Epoch 4: 427/634 Loss: 0.174466
2023-01-04 06:59: Train Epoch 4: 431/634 Loss: 0.169223
2023-01-04 07:00: Train Epoch 4: 435/634 Loss: 0.167007
2023-01-04 07:01: Train Epoch 4: 439/634 Loss: 0.227368
2023-01-04 07:03: Train Epoch 4: 443/634 Loss: 0.181047
2023-01-04 07:04: Train Epoch 4: 447/634 Loss: 0.206646
2023-01-04 07:05: Train Epoch 4: 451/634 Loss: 0.179270
2023-01-04 07:06: Train Epoch 4: 455/634 Loss: 0.158366
2023-01-04 07:07: Train Epoch 4: 459/634 Loss: 0.179108
2023-01-04 07:08: Train Epoch 4: 463/634 Loss: 0.167535
2023-01-04 07:09: Train Epoch 4: 467/634 Loss: 0.171737
2023-01-04 07:11: Train Epoch 4: 471/634 Loss: 0.187789
2023-01-04 07:12: Train Epoch 4: 475/634 Loss: 0.150702
2023-01-04 07:13: Train Epoch 4: 479/634 Loss: 0.155750
2023-01-04 07:14: Train Epoch 4: 483/634 Loss: 0.178519
2023-01-04 07:15: Train Epoch 4: 487/634 Loss: 0.157351
2023-01-04 07:16: Train Epoch 4: 491/634 Loss: 0.155027
2023-01-04 07:17: Train Epoch 4: 495/634 Loss: 0.164269
2023-01-04 07:19: Train Epoch 4: 499/634 Loss: 0.155491
2023-01-04 07:20: Train Epoch 4: 503/634 Loss: 0.183427
2023-01-04 07:21: Train Epoch 4: 507/634 Loss: 0.181330
2023-01-04 07:22: Train Epoch 4: 511/634 Loss: 0.164007
2023-01-04 07:23: Train Epoch 4: 515/634 Loss: 0.155658
2023-01-04 07:24: Train Epoch 4: 519/634 Loss: 0.170665
2023-01-04 07:25: Train Epoch 4: 523/634 Loss: 0.195051
2023-01-04 07:27: Train Epoch 4: 527/634 Loss: 0.168770
2023-01-04 07:28: Train Epoch 4: 531/634 Loss: 0.176558
2023-01-04 07:29: Train Epoch 4: 535/634 Loss: 0.164040
2023-01-04 07:30: Train Epoch 4: 539/634 Loss: 0.153639
2023-01-04 07:31: Train Epoch 4: 543/634 Loss: 0.162040
2023-01-04 07:32: Train Epoch 4: 547/634 Loss: 0.180269
2023-01-04 07:33: Train Epoch 4: 551/634 Loss: 0.156465
2023-01-04 07:34: Train Epoch 4: 555/634 Loss: 0.194104
2023-01-04 07:35: Train Epoch 4: 559/634 Loss: 0.168861
2023-01-04 07:37: Train Epoch 4: 563/634 Loss: 0.161960
2023-01-04 07:38: Train Epoch 4: 567/634 Loss: 0.172311
2023-01-04 07:39: Train Epoch 4: 571/634 Loss: 0.156468
2023-01-04 07:40: Train Epoch 4: 575/634 Loss: 0.166348
2023-01-04 07:41: Train Epoch 4: 579/634 Loss: 0.164126
2023-01-04 07:42: Train Epoch 4: 583/634 Loss: 0.144566
2023-01-04 07:43: Train Epoch 4: 587/634 Loss: 0.142811
2023-01-04 07:44: Train Epoch 4: 591/634 Loss: 0.146319
2023-01-04 07:45: Train Epoch 4: 595/634 Loss: 0.177915
2023-01-04 07:46: Train Epoch 4: 599/634 Loss: 0.142772
2023-01-04 07:48: Train Epoch 4: 603/634 Loss: 0.187526
2023-01-04 07:49: Train Epoch 4: 607/634 Loss: 0.159730
2023-01-04 07:50: Train Epoch 4: 611/634 Loss: 0.154489
2023-01-04 07:51: Train Epoch 4: 615/634 Loss: 0.159010
2023-01-04 07:52: Train Epoch 4: 619/634 Loss: 0.190132
2023-01-04 07:53: Train Epoch 4: 623/634 Loss: 0.172660
2023-01-04 07:54: Train Epoch 4: 627/634 Loss: 0.169819
2023-01-04 07:56: Train Epoch 4: 631/634 Loss: 0.200145
2023-01-04 07:56: Train Epoch 4: 633/634 Loss: 0.091658
2023-01-04 07:56: **********Train Epoch 4: averaged Loss: 0.178361 
2023-01-04 07:56: 
Epoch time elapsed: 10946.047797679901

2023-01-04 08:01: 
 metrics validation: {'precision': 0.6895585143658024, 'recall': 0.7569230769230769, 'f1-score': 0.7216721672167216, 'support': 1300, 'AUC': 0.8855514792899408, 'AUCPR': 0.7889096286801281, 'TP': 984, 'FP': 443, 'TN': 2157, 'FN': 316} 

2023-01-04 08:01: **********Val Epoch 4: average Loss: 0.195334
2023-01-04 08:05: 
 Testing metrics {'precision': 0.8200956937799043, 'recall': 0.6978827361563518, 'f1-score': 0.7540695116586009, 'support': 1228, 'AUC': 0.9050593374996021, 'AUCPR': 0.8428690273119946, 'TP': 857, 'FP': 188, 'TN': 2268, 'FN': 371} 

2023-01-04 08:20: 
 Testing metrics {'precision': 0.8798191970220686, 'recall': 0.7508509189925119, 'f1-score': 0.8102350636630753, 'support': 4407, 'AUC': 0.9541577030869006, 'AUCPR': 0.908737200669726, 'TP': 3309, 'FP': 452, 'TN': 8362, 'FN': 1098} 

2023-01-04 08:22: Train Epoch 5: 3/634 Loss: 0.170052
2023-01-04 08:23: Train Epoch 5: 7/634 Loss: 0.192274
2023-01-04 08:24: Train Epoch 5: 11/634 Loss: 0.214257
2023-01-04 08:25: Train Epoch 5: 15/634 Loss: 0.196349
2023-01-04 08:27: Train Epoch 5: 19/634 Loss: 0.215821
2023-01-04 08:28: Train Epoch 5: 23/634 Loss: 0.173094
2023-01-04 08:29: Train Epoch 5: 27/634 Loss: 0.183947
2023-01-04 08:30: Train Epoch 5: 31/634 Loss: 0.170994
2023-01-04 08:32: Train Epoch 5: 35/634 Loss: 0.180504
2023-01-04 08:33: Train Epoch 5: 39/634 Loss: 0.172907
2023-01-04 08:34: Train Epoch 5: 43/634 Loss: 0.166881
2023-01-04 08:35: Train Epoch 5: 47/634 Loss: 0.182089
2023-01-04 08:37: Train Epoch 5: 51/634 Loss: 0.173882
2023-01-04 08:38: Train Epoch 5: 55/634 Loss: 0.198452
2023-01-04 08:39: Train Epoch 5: 59/634 Loss: 0.186494
2023-01-04 08:41: Train Epoch 5: 63/634 Loss: 0.201091
2023-01-04 08:42: Train Epoch 5: 67/634 Loss: 0.158615
2023-01-04 08:43: Train Epoch 5: 71/634 Loss: 0.161271
2023-01-04 08:45: Train Epoch 5: 75/634 Loss: 0.202075
2023-01-04 08:46: Train Epoch 5: 79/634 Loss: 0.209131
2023-01-04 08:47: Train Epoch 5: 83/634 Loss: 0.204693
2023-01-04 08:48: Train Epoch 5: 87/634 Loss: 0.182570
2023-01-04 08:50: Train Epoch 5: 91/634 Loss: 0.208490
2023-01-04 08:51: Train Epoch 5: 95/634 Loss: 0.171928
2023-01-04 08:52: Train Epoch 5: 99/634 Loss: 0.178012
2023-01-04 08:53: Train Epoch 5: 103/634 Loss: 0.206143
2023-01-04 08:55: Train Epoch 5: 107/634 Loss: 0.168183
2023-01-04 08:56: Train Epoch 5: 111/634 Loss: 0.180419
2023-01-04 08:57: Train Epoch 5: 115/634 Loss: 0.182497
2023-01-04 08:59: Train Epoch 5: 119/634 Loss: 0.181718
2023-01-04 09:00: Train Epoch 5: 123/634 Loss: 0.171270
2023-01-04 09:01: Train Epoch 5: 127/634 Loss: 0.175296
2023-01-04 09:02: Train Epoch 5: 131/634 Loss: 0.151352
2023-01-04 09:03: Train Epoch 5: 135/634 Loss: 0.182705
2023-01-04 09:05: Train Epoch 5: 139/634 Loss: 0.176793
2023-01-04 09:06: Train Epoch 5: 143/634 Loss: 0.178546
2023-01-04 09:07: Train Epoch 5: 147/634 Loss: 0.176812
2023-01-04 09:08: Train Epoch 5: 151/634 Loss: 0.193362
2023-01-04 09:09: Train Epoch 5: 155/634 Loss: 0.129624
2023-01-04 09:10: Train Epoch 5: 159/634 Loss: 0.198463
2023-01-04 09:12: Train Epoch 5: 163/634 Loss: 0.197338
2023-01-04 09:13: Train Epoch 5: 167/634 Loss: 0.209394
2023-01-04 09:14: Train Epoch 5: 171/634 Loss: 0.183249
2023-01-04 09:15: Train Epoch 5: 175/634 Loss: 0.196229
2023-01-04 09:16: Train Epoch 5: 179/634 Loss: 0.204800
2023-01-04 09:17: Train Epoch 5: 183/634 Loss: 0.188935
2023-01-04 09:19: Train Epoch 5: 187/634 Loss: 0.212275
2023-01-04 09:20: Train Epoch 5: 191/634 Loss: 0.177190
2023-01-04 09:21: Train Epoch 5: 195/634 Loss: 0.174043
2023-01-04 09:22: Train Epoch 5: 199/634 Loss: 0.192460
2023-01-04 09:23: Train Epoch 5: 203/634 Loss: 0.190925
2023-01-04 09:24: Train Epoch 5: 207/634 Loss: 0.208302
2023-01-04 09:26: Train Epoch 5: 211/634 Loss: 0.188502
2023-01-04 09:27: Train Epoch 5: 215/634 Loss: 0.170573
2023-01-04 09:28: Train Epoch 5: 219/634 Loss: 0.178562
2023-01-04 09:29: Train Epoch 5: 223/634 Loss: 0.181053
2023-01-04 09:30: Train Epoch 5: 227/634 Loss: 0.174403
2023-01-04 09:31: Train Epoch 5: 231/634 Loss: 0.187285
2023-01-04 09:32: Train Epoch 5: 235/634 Loss: 0.177855
2023-01-04 09:34: Train Epoch 5: 239/634 Loss: 0.159316
2023-01-04 09:35: Train Epoch 5: 243/634 Loss: 0.164929
2023-01-04 09:36: Train Epoch 5: 247/634 Loss: 0.160039
2023-01-04 09:37: Train Epoch 5: 251/634 Loss: 0.227139
2023-01-04 09:38: Train Epoch 5: 255/634 Loss: 0.186201
2023-01-04 09:39: Train Epoch 5: 259/634 Loss: 0.197168
2023-01-04 09:40: Train Epoch 5: 263/634 Loss: 0.211736
2023-01-04 09:41: Train Epoch 5: 267/634 Loss: 0.181242
2023-01-04 09:43: Train Epoch 5: 271/634 Loss: 0.149431
2023-01-04 09:44: Train Epoch 5: 275/634 Loss: 0.181455
2023-01-04 09:45: Train Epoch 5: 279/634 Loss: 0.162168
2023-01-04 09:46: Train Epoch 5: 283/634 Loss: 0.178622
2023-01-04 09:47: Train Epoch 5: 287/634 Loss: 0.171771
2023-01-04 09:48: Train Epoch 5: 291/634 Loss: 0.188193
2023-01-04 09:49: Train Epoch 5: 295/634 Loss: 0.183312
2023-01-04 09:51: Train Epoch 5: 299/634 Loss: 0.191648
2023-01-04 09:52: Train Epoch 5: 303/634 Loss: 0.172894
2023-01-04 09:53: Train Epoch 5: 307/634 Loss: 0.190294
2023-01-04 09:54: Train Epoch 5: 311/634 Loss: 0.188412
2023-01-04 09:55: Train Epoch 5: 315/634 Loss: 0.199615
2023-01-04 09:56: Train Epoch 5: 319/634 Loss: 0.177817
2023-01-04 09:57: Train Epoch 5: 323/634 Loss: 0.192743
2023-01-04 09:59: Train Epoch 5: 327/634 Loss: 0.167351
2023-01-04 10:00: Train Epoch 5: 331/634 Loss: 0.211732
2023-01-04 10:01: Train Epoch 5: 335/634 Loss: 0.202536
2023-01-04 10:02: Train Epoch 5: 339/634 Loss: 0.200743
2023-01-04 10:03: Train Epoch 5: 343/634 Loss: 0.230607
2023-01-04 10:04: Train Epoch 5: 347/634 Loss: 0.238460
2023-01-04 10:06: Train Epoch 5: 351/634 Loss: 0.197259
2023-01-04 10:07: Train Epoch 5: 355/634 Loss: 0.212858
2023-01-04 10:08: Train Epoch 5: 359/634 Loss: 0.199062
2023-01-04 10:09: Train Epoch 5: 363/634 Loss: 0.171026
2023-01-04 10:10: Train Epoch 5: 367/634 Loss: 0.208715
2023-01-04 10:11: Train Epoch 5: 371/634 Loss: 0.174246
2023-01-04 10:12: Train Epoch 5: 375/634 Loss: 0.159934
2023-01-04 10:14: Train Epoch 5: 379/634 Loss: 0.155795
2023-01-04 10:15: Train Epoch 5: 383/634 Loss: 0.167801
2023-01-04 10:16: Train Epoch 5: 387/634 Loss: 0.206612
2023-01-04 10:17: Train Epoch 5: 391/634 Loss: 0.158153
2023-01-04 10:18: Train Epoch 5: 395/634 Loss: 0.157233
2023-01-04 10:20: Train Epoch 5: 399/634 Loss: 0.208552
2023-01-04 10:21: Train Epoch 5: 403/634 Loss: 0.204918
2023-01-04 10:22: Train Epoch 5: 407/634 Loss: 0.192351
2023-01-04 10:23: Train Epoch 5: 411/634 Loss: 0.187482
2023-01-04 10:25: Train Epoch 5: 415/634 Loss: 0.199117
2023-01-04 10:26: Train Epoch 5: 419/634 Loss: 0.177895
2023-01-04 10:27: Train Epoch 5: 423/634 Loss: 0.178254
2023-01-04 10:28: Train Epoch 5: 427/634 Loss: 0.177268
2023-01-04 10:29: Train Epoch 5: 431/634 Loss: 0.174614
2023-01-04 10:30: Train Epoch 5: 435/634 Loss: 0.159055
2023-01-04 10:32: Train Epoch 5: 439/634 Loss: 0.190006
2023-01-04 10:33: Train Epoch 5: 443/634 Loss: 0.177036
2023-01-04 10:34: Train Epoch 5: 447/634 Loss: 0.189197
2023-01-04 10:35: Train Epoch 5: 451/634 Loss: 0.174158
2023-01-04 10:36: Train Epoch 5: 455/634 Loss: 0.171159
2023-01-04 10:37: Train Epoch 5: 459/634 Loss: 0.180065
2023-01-04 10:38: Train Epoch 5: 463/634 Loss: 0.188506
2023-01-04 10:39: Train Epoch 5: 467/634 Loss: 0.180482
2023-01-04 10:41: Train Epoch 5: 471/634 Loss: 0.182173
2023-01-04 10:42: Train Epoch 5: 475/634 Loss: 0.173274
2023-01-04 10:43: Train Epoch 5: 479/634 Loss: 0.157928
2023-01-04 10:44: Train Epoch 5: 483/634 Loss: 0.165630
2023-01-04 10:45: Train Epoch 5: 487/634 Loss: 0.174056
2023-01-04 10:46: Train Epoch 5: 491/634 Loss: 0.181643
2023-01-04 10:47: Train Epoch 5: 495/634 Loss: 0.152576
2023-01-04 10:49: Train Epoch 5: 499/634 Loss: 0.196559
2023-01-04 10:50: Train Epoch 5: 503/634 Loss: 0.162374
2023-01-04 10:51: Train Epoch 5: 507/634 Loss: 0.178660
2023-01-04 10:52: Train Epoch 5: 511/634 Loss: 0.184687
2023-01-04 10:53: Train Epoch 5: 515/634 Loss: 0.222542
2023-01-04 10:55: Train Epoch 5: 519/634 Loss: 0.176559
2023-01-04 10:56: Train Epoch 5: 523/634 Loss: 0.175953
2023-01-04 10:57: Train Epoch 5: 527/634 Loss: 0.177876
2023-01-04 10:58: Train Epoch 5: 531/634 Loss: 0.170910
2023-01-04 11:00: Train Epoch 5: 535/634 Loss: 0.161808
2023-01-04 11:01: Train Epoch 5: 539/634 Loss: 0.161416
2023-01-04 11:02: Train Epoch 5: 543/634 Loss: 0.152203
2023-01-04 11:04: Train Epoch 5: 547/634 Loss: 0.187035
2023-01-04 11:05: Train Epoch 5: 551/634 Loss: 0.188780
2023-01-04 11:06: Train Epoch 5: 555/634 Loss: 0.179684
2023-01-04 11:08: Train Epoch 5: 559/634 Loss: 0.164741
2023-01-04 11:09: Train Epoch 5: 563/634 Loss: 0.161035
2023-01-04 11:10: Train Epoch 5: 567/634 Loss: 0.190593
2023-01-04 11:11: Train Epoch 5: 571/634 Loss: 0.192092
2023-01-04 11:12: Train Epoch 5: 575/634 Loss: 0.186960
2023-01-04 11:13: Train Epoch 5: 579/634 Loss: 0.165566
2023-01-04 11:14: Train Epoch 5: 583/634 Loss: 0.168949
2023-01-04 11:16: Train Epoch 5: 587/634 Loss: 0.183277
2023-01-04 11:17: Train Epoch 5: 591/634 Loss: 0.164540
2023-01-04 11:18: Train Epoch 5: 595/634 Loss: 0.179661
2023-01-04 11:19: Train Epoch 5: 599/634 Loss: 0.221517
2023-01-04 11:20: Train Epoch 5: 603/634 Loss: 0.210239
2023-01-04 11:21: Train Epoch 5: 607/634 Loss: 0.168014
2023-01-04 11:23: Train Epoch 5: 611/634 Loss: 0.163732
2023-01-04 11:24: Train Epoch 5: 615/634 Loss: 0.164751
2023-01-04 11:25: Train Epoch 5: 619/634 Loss: 0.189691
2023-01-04 11:26: Train Epoch 5: 623/634 Loss: 0.164166
2023-01-04 11:28: Train Epoch 5: 627/634 Loss: 0.213165
2023-01-04 11:29: Train Epoch 5: 631/634 Loss: 0.191505
2023-01-04 11:29: Train Epoch 5: 633/634 Loss: 0.063720
2023-01-04 11:29: **********Train Epoch 5: averaged Loss: 0.182522 
2023-01-04 11:29: 
Epoch time elapsed: 11343.377126216888

2023-01-04 11:34: 
 metrics validation: {'precision': 0.7042640990371389, 'recall': 0.7876923076923077, 'f1-score': 0.7436456063907044, 'support': 1300, 'AUC': 0.8920988165680473, 'AUCPR': 0.8018425350079743, 'TP': 1024, 'FP': 430, 'TN': 2170, 'FN': 276} 

2023-01-04 11:34: **********Val Epoch 5: average Loss: 0.189658
2023-01-04 11:38: 
 Testing metrics {'precision': 0.8200956937799043, 'recall': 0.6978827361563518, 'f1-score': 0.7540695116586009, 'support': 1228, 'AUC': 0.9050593374996021, 'AUCPR': 0.8428690273119946, 'TP': 857, 'FP': 188, 'TN': 2268, 'FN': 371} 

2023-01-04 11:53: 
 Testing metrics {'precision': 0.8798191970220686, 'recall': 0.7508509189925119, 'f1-score': 0.8102350636630753, 'support': 4407, 'AUC': 0.9541577030869006, 'AUCPR': 0.908737200669726, 'TP': 3309, 'FP': 452, 'TN': 8362, 'FN': 1098} 

2023-01-04 11:55: Train Epoch 6: 3/634 Loss: 0.169326
2023-01-04 11:56: Train Epoch 6: 7/634 Loss: 0.184368
2023-01-04 11:57: Train Epoch 6: 11/634 Loss: 0.173836
2023-01-04 11:58: Train Epoch 6: 15/634 Loss: 0.191662
2023-01-04 11:59: Train Epoch 6: 19/634 Loss: 0.209575
2023-01-04 12:01: Train Epoch 6: 23/634 Loss: 0.193735
2023-01-04 12:02: Train Epoch 6: 27/634 Loss: 0.204585
2023-01-04 12:03: Train Epoch 6: 31/634 Loss: 0.180941
2023-01-04 12:04: Train Epoch 6: 35/634 Loss: 0.190467
2023-01-04 12:05: Train Epoch 6: 39/634 Loss: 0.150580
2023-01-04 12:07: Train Epoch 6: 43/634 Loss: 0.190419
2023-01-04 12:08: Train Epoch 6: 47/634 Loss: 0.175442
2023-01-04 12:09: Train Epoch 6: 51/634 Loss: 0.177605
2023-01-04 12:10: Train Epoch 6: 55/634 Loss: 0.194665
2023-01-04 12:11: Train Epoch 6: 59/634 Loss: 0.181476
2023-01-04 12:12: Train Epoch 6: 63/634 Loss: 0.155874
2023-01-04 12:14: Train Epoch 6: 67/634 Loss: 0.190767
2023-01-04 12:15: Train Epoch 6: 71/634 Loss: 0.206831
2023-01-04 12:16: Train Epoch 6: 75/634 Loss: 0.209105
2023-01-04 12:17: Train Epoch 6: 79/634 Loss: 0.202826
2023-01-04 12:18: Train Epoch 6: 83/634 Loss: 0.224474
2023-01-04 12:19: Train Epoch 6: 87/634 Loss: 0.197285
2023-01-04 12:20: Train Epoch 6: 91/634 Loss: 0.168513
2023-01-04 12:22: Train Epoch 6: 95/634 Loss: 0.193380
2023-01-04 12:23: Train Epoch 6: 99/634 Loss: 0.180394
2023-01-04 12:24: Train Epoch 6: 103/634 Loss: 0.174501
2023-01-04 12:25: Train Epoch 6: 107/634 Loss: 0.138754
2023-01-04 12:26: Train Epoch 6: 111/634 Loss: 0.166329
2023-01-04 12:27: Train Epoch 6: 115/634 Loss: 0.174469
2023-01-04 12:29: Train Epoch 6: 119/634 Loss: 0.167642
2023-01-04 12:30: Train Epoch 6: 123/634 Loss: 0.198936
2023-01-04 12:31: Train Epoch 6: 127/634 Loss: 0.215898
2023-01-04 12:32: Train Epoch 6: 131/634 Loss: 0.156669
2023-01-04 12:33: Train Epoch 6: 135/634 Loss: 0.176641
2023-01-04 12:34: Train Epoch 6: 139/634 Loss: 0.168810
2023-01-04 12:36: Train Epoch 6: 143/634 Loss: 0.201225
2023-01-04 12:37: Train Epoch 6: 147/634 Loss: 0.219888
2023-01-04 12:38: Train Epoch 6: 151/634 Loss: 0.168711
2023-01-04 12:39: Train Epoch 6: 155/634 Loss: 0.176187
2023-01-04 12:40: Train Epoch 6: 159/634 Loss: 0.156668
2023-01-04 12:41: Train Epoch 6: 163/634 Loss: 0.156713
2023-01-04 12:42: Train Epoch 6: 167/634 Loss: 0.198491
2023-01-04 12:44: Train Epoch 6: 171/634 Loss: 0.170122
2023-01-04 12:45: Train Epoch 6: 175/634 Loss: 0.182317
2023-01-04 12:46: Train Epoch 6: 179/634 Loss: 0.190178
2023-01-04 12:47: Train Epoch 6: 183/634 Loss: 0.242755
2023-01-04 12:48: Train Epoch 6: 187/634 Loss: 0.167882
2023-01-04 12:49: Train Epoch 6: 191/634 Loss: 0.203275
2023-01-04 12:50: Train Epoch 6: 195/634 Loss: 0.174566
2023-01-04 12:52: Train Epoch 6: 199/634 Loss: 0.189142
2023-01-04 12:53: Train Epoch 6: 203/634 Loss: 0.149699
2023-01-04 12:54: Train Epoch 6: 207/634 Loss: 0.177863
2023-01-04 12:55: Train Epoch 6: 211/634 Loss: 0.186393
2023-01-04 12:56: Train Epoch 6: 215/634 Loss: 0.166895
2023-01-04 12:57: Train Epoch 6: 219/634 Loss: 0.178873
2023-01-04 12:59: Train Epoch 6: 223/634 Loss: 0.150605
2023-01-04 13:00: Train Epoch 6: 227/634 Loss: 0.190386
2023-01-04 13:01: Train Epoch 6: 231/634 Loss: 0.204326
2023-01-04 13:02: Train Epoch 6: 235/634 Loss: 0.194716
2023-01-04 13:03: Train Epoch 6: 239/634 Loss: 0.193969
2023-01-04 13:04: Train Epoch 6: 243/634 Loss: 0.192557
2023-01-04 13:05: Train Epoch 6: 247/634 Loss: 0.184064
2023-01-04 13:07: Train Epoch 6: 251/634 Loss: 0.198981
2023-01-04 13:08: Train Epoch 6: 255/634 Loss: 0.177330
2023-01-04 13:09: Train Epoch 6: 259/634 Loss: 0.193060
2023-01-04 13:10: Train Epoch 6: 263/634 Loss: 0.207102
2023-01-04 13:11: Train Epoch 6: 267/634 Loss: 0.203190
2023-01-04 13:12: Train Epoch 6: 271/634 Loss: 0.209470
2023-01-04 13:13: Train Epoch 6: 275/634 Loss: 0.183449
2023-01-04 13:14: Train Epoch 6: 279/634 Loss: 0.185694
2023-01-04 13:16: Train Epoch 6: 283/634 Loss: 0.183368
2023-01-04 13:17: Train Epoch 6: 287/634 Loss: 0.186263
2023-01-04 13:18: Train Epoch 6: 291/634 Loss: 0.191957
2023-01-04 13:19: Train Epoch 6: 295/634 Loss: 0.193008
2023-01-04 13:20: Train Epoch 6: 299/634 Loss: 0.171794
2023-01-04 13:21: Train Epoch 6: 303/634 Loss: 0.204037
2023-01-04 13:22: Train Epoch 6: 307/634 Loss: 0.135177
2023-01-04 13:24: Train Epoch 6: 311/634 Loss: 0.204582
2023-01-04 13:25: Train Epoch 6: 315/634 Loss: 0.178373
2023-01-04 13:26: Train Epoch 6: 319/634 Loss: 0.157513
2023-01-04 13:27: Train Epoch 6: 323/634 Loss: 0.157884
2023-01-04 13:28: Train Epoch 6: 327/634 Loss: 0.192105
2023-01-04 13:29: Train Epoch 6: 331/634 Loss: 0.214742
2023-01-04 13:30: Train Epoch 6: 335/634 Loss: 0.168216
2023-01-04 13:32: Train Epoch 6: 339/634 Loss: 0.190428
2023-01-04 13:33: Train Epoch 6: 343/634 Loss: 0.189340
2023-01-04 13:34: Train Epoch 6: 347/634 Loss: 0.154963
2023-01-04 13:35: Train Epoch 6: 351/634 Loss: 0.163499
2023-01-04 13:36: Train Epoch 6: 355/634 Loss: 0.169110
2023-01-04 13:37: Train Epoch 6: 359/634 Loss: 0.183199
2023-01-04 13:38: Train Epoch 6: 363/634 Loss: 0.160762
2023-01-04 13:39: Train Epoch 6: 367/634 Loss: 0.171771
2023-01-04 13:41: Train Epoch 6: 371/634 Loss: 0.183517
2023-01-04 13:42: Train Epoch 6: 375/634 Loss: 0.155930
2023-01-04 13:43: Train Epoch 6: 379/634 Loss: 0.149004
2023-01-04 13:44: Train Epoch 6: 383/634 Loss: 0.187750
2023-01-04 13:45: Train Epoch 6: 387/634 Loss: 0.179848
2023-01-04 13:46: Train Epoch 6: 391/634 Loss: 0.156876
2023-01-04 13:47: Train Epoch 6: 395/634 Loss: 0.179319
2023-01-04 13:49: Train Epoch 6: 399/634 Loss: 0.162905
2023-01-04 13:50: Train Epoch 6: 403/634 Loss: 0.189841
2023-01-04 13:51: Train Epoch 6: 407/634 Loss: 0.206644
2023-01-04 13:52: Train Epoch 6: 411/634 Loss: 0.190150
2023-01-04 13:53: Train Epoch 6: 415/634 Loss: 0.206294
2023-01-04 13:54: Train Epoch 6: 419/634 Loss: 0.188407
2023-01-04 13:55: Train Epoch 6: 423/634 Loss: 0.230572
2023-01-04 13:56: Train Epoch 6: 427/634 Loss: 0.166980
2023-01-04 13:57: Train Epoch 6: 431/634 Loss: 0.173057
2023-01-04 13:59: Train Epoch 6: 435/634 Loss: 0.165881
2023-01-04 14:00: Train Epoch 6: 439/634 Loss: 0.172701
2023-01-04 14:01: Train Epoch 6: 443/634 Loss: 0.156376
2023-01-04 14:02: Train Epoch 6: 447/634 Loss: 0.182998
2023-01-04 14:03: Train Epoch 6: 451/634 Loss: 0.204120
2023-01-04 14:04: Train Epoch 6: 455/634 Loss: 0.182400
2023-01-04 14:05: Train Epoch 6: 459/634 Loss: 0.198420
2023-01-04 14:07: Train Epoch 6: 463/634 Loss: 0.174507
2023-01-04 14:08: Train Epoch 6: 467/634 Loss: 0.155538
2023-01-04 14:09: Train Epoch 6: 471/634 Loss: 0.175631
2023-01-04 14:10: Train Epoch 6: 475/634 Loss: 0.179369
2023-01-04 14:11: Train Epoch 6: 479/634 Loss: 0.181579
2023-01-04 14:12: Train Epoch 6: 483/634 Loss: 0.204785
2023-01-04 14:13: Train Epoch 6: 487/634 Loss: 0.156419
2023-01-04 14:14: Train Epoch 6: 491/634 Loss: 0.206331
2023-01-04 14:16: Train Epoch 6: 495/634 Loss: 0.168212
2023-01-04 14:17: Train Epoch 6: 499/634 Loss: 0.160388
2023-01-04 14:18: Train Epoch 6: 503/634 Loss: 0.204041
2023-01-04 14:19: Train Epoch 6: 507/634 Loss: 0.198010
2023-01-04 14:20: Train Epoch 6: 511/634 Loss: 0.178156
2023-01-04 14:21: Train Epoch 6: 515/634 Loss: 0.152130
2023-01-04 14:22: Train Epoch 6: 519/634 Loss: 0.169548
2023-01-04 14:24: Train Epoch 6: 523/634 Loss: 0.176408
2023-01-04 14:25: Train Epoch 6: 527/634 Loss: 0.160814
2023-01-04 14:26: Train Epoch 6: 531/634 Loss: 0.180837
2023-01-04 14:27: Train Epoch 6: 535/634 Loss: 0.171508
2023-01-04 14:28: Train Epoch 6: 539/634 Loss: 0.174062
2023-01-04 14:29: Train Epoch 6: 543/634 Loss: 0.174765
2023-01-04 14:30: Train Epoch 6: 547/634 Loss: 0.178252
2023-01-04 14:32: Train Epoch 6: 551/634 Loss: 0.163539
2023-01-04 14:33: Train Epoch 6: 555/634 Loss: 0.156340
2023-01-04 14:34: Train Epoch 6: 559/634 Loss: 0.167797
2023-01-04 14:35: Train Epoch 6: 563/634 Loss: 0.166482
2023-01-04 14:36: Train Epoch 6: 567/634 Loss: 0.193495
2023-01-04 14:37: Train Epoch 6: 571/634 Loss: 0.186345
2023-01-04 14:38: Train Epoch 6: 575/634 Loss: 0.185861
2023-01-04 14:40: Train Epoch 6: 579/634 Loss: 0.181318
2023-01-04 14:41: Train Epoch 6: 583/634 Loss: 0.179839
2023-01-04 14:42: Train Epoch 6: 587/634 Loss: 0.188259
2023-01-04 14:43: Train Epoch 6: 591/634 Loss: 0.180794
2023-01-04 14:44: Train Epoch 6: 595/634 Loss: 0.214241
2023-01-04 14:45: Train Epoch 6: 599/634 Loss: 0.172541
2023-01-04 14:46: Train Epoch 6: 603/634 Loss: 0.242222
2023-01-04 14:48: Train Epoch 6: 607/634 Loss: 0.198197
2023-01-04 14:49: Train Epoch 6: 611/634 Loss: 0.210433
2023-01-04 14:50: Train Epoch 6: 615/634 Loss: 0.167171
2023-01-04 14:51: Train Epoch 6: 619/634 Loss: 0.158798
2023-01-04 14:52: Train Epoch 6: 623/634 Loss: 0.168463
2023-01-04 14:54: Train Epoch 6: 627/634 Loss: 0.130122
2023-01-04 14:55: Train Epoch 6: 631/634 Loss: 0.218107
2023-01-04 14:55: Train Epoch 6: 633/634 Loss: 0.091689
2023-01-04 14:55: **********Train Epoch 6: averaged Loss: 0.181503 
2023-01-04 14:55: 
Epoch time elapsed: 10917.711006641388

2023-01-04 15:00: 
 metrics validation: {'precision': 0.8446726572528883, 'recall': 0.5061538461538462, 'f1-score': 0.6329966329966329, 'support': 1300, 'AUC': 0.9111514792899407, 'AUCPR': 0.8295998121052103, 'TP': 658, 'FP': 121, 'TN': 2479, 'FN': 642} 

2023-01-04 15:00: **********Val Epoch 6: average Loss: 0.188643
2023-01-04 15:00: *********************************Current best model saved!
2023-01-04 15:04: 
 Testing metrics {'precision': 0.8953626634958383, 'recall': 0.6131921824104235, 'f1-score': 0.7278878685355245, 'support': 1228, 'AUC': 0.9206162001718851, 'AUCPR': 0.8684893097613874, 'TP': 753, 'FP': 88, 'TN': 2368, 'FN': 475} 

2023-01-04 15:19: 
 Testing metrics {'precision': 0.9340625, 'recall': 0.6782391649648287, 'f1-score': 0.7858551334297358, 'support': 4407, 'AUC': 0.9665259628572218, 'AUCPR': 0.9337173992941454, 'TP': 2989, 'FP': 211, 'TN': 8603, 'FN': 1418} 

2023-01-04 15:21: Train Epoch 7: 3/634 Loss: 0.196697
2023-01-04 15:22: Train Epoch 7: 7/634 Loss: 0.144903
2023-01-04 15:23: Train Epoch 7: 11/634 Loss: 0.186862
2023-01-04 15:24: Train Epoch 7: 15/634 Loss: 0.145280
2023-01-04 15:25: Train Epoch 7: 19/634 Loss: 0.151801
2023-01-04 15:26: Train Epoch 7: 23/634 Loss: 0.168995
2023-01-04 15:27: Train Epoch 7: 27/634 Loss: 0.143437
2023-01-04 15:29: Train Epoch 7: 31/634 Loss: 0.155541
2023-01-04 15:30: Train Epoch 7: 35/634 Loss: 0.186239
2023-01-04 15:31: Train Epoch 7: 39/634 Loss: 0.177076
2023-01-04 15:32: Train Epoch 7: 43/634 Loss: 0.222925
2023-01-04 15:33: Train Epoch 7: 47/634 Loss: 0.221205
2023-01-04 15:34: Train Epoch 7: 51/634 Loss: 0.168233
2023-01-04 15:35: Train Epoch 7: 55/634 Loss: 0.260703
2023-01-04 15:36: Train Epoch 7: 59/634 Loss: 0.166823
2023-01-04 15:38: Train Epoch 7: 63/634 Loss: 0.212309
2023-01-04 15:39: Train Epoch 7: 67/634 Loss: 0.271385
2023-01-04 15:40: Train Epoch 7: 71/634 Loss: 0.175124
2023-01-04 15:41: Train Epoch 7: 75/634 Loss: 0.261522
2023-01-04 15:42: Train Epoch 7: 79/634 Loss: 0.197123
2023-01-04 15:44: Train Epoch 7: 83/634 Loss: 0.216894
2023-01-04 15:45: Train Epoch 7: 87/634 Loss: 0.239614
2023-01-04 15:46: Train Epoch 7: 91/634 Loss: 0.177597
2023-01-04 15:47: Train Epoch 7: 95/634 Loss: 0.276444
2023-01-04 15:48: Train Epoch 7: 99/634 Loss: 0.171426
2023-01-04 15:50: Train Epoch 7: 103/634 Loss: 0.208758
2023-01-04 15:51: Train Epoch 7: 107/634 Loss: 0.161821
2023-01-04 15:52: Train Epoch 7: 111/634 Loss: 0.165630
2023-01-04 15:53: Train Epoch 7: 115/634 Loss: 0.190161
2023-01-04 15:54: Train Epoch 7: 119/634 Loss: 0.195881
2023-01-04 15:55: Train Epoch 7: 123/634 Loss: 0.170851
2023-01-04 15:56: Train Epoch 7: 127/634 Loss: 0.166738
2023-01-04 15:58: Train Epoch 7: 131/634 Loss: 0.175690
2023-01-04 15:59: Train Epoch 7: 135/634 Loss: 0.179935
2023-01-04 16:00: Train Epoch 7: 139/634 Loss: 0.164891
2023-01-04 16:01: Train Epoch 7: 143/634 Loss: 0.169771
2023-01-04 16:02: Train Epoch 7: 147/634 Loss: 0.167734
2023-01-04 16:03: Train Epoch 7: 151/634 Loss: 0.136832
2023-01-04 16:04: Train Epoch 7: 155/634 Loss: 0.208015
2023-01-04 16:05: Train Epoch 7: 159/634 Loss: 0.174919
2023-01-04 16:06: Train Epoch 7: 163/634 Loss: 0.217721
2023-01-04 16:08: Train Epoch 7: 167/634 Loss: 0.188143
2023-01-04 16:09: Train Epoch 7: 171/634 Loss: 0.180004
2023-01-04 16:10: Train Epoch 7: 175/634 Loss: 0.203032
2023-01-04 16:11: Train Epoch 7: 179/634 Loss: 0.187734
2023-01-04 16:12: Train Epoch 7: 183/634 Loss: 0.193458
2023-01-04 16:13: Train Epoch 7: 187/634 Loss: 0.191858
2023-01-04 16:14: Train Epoch 7: 191/634 Loss: 0.178857
2023-01-04 16:15: Train Epoch 7: 195/634 Loss: 0.216193
2023-01-04 16:17: Train Epoch 7: 199/634 Loss: 0.160778
2023-01-04 16:18: Train Epoch 7: 203/634 Loss: 0.173391
2023-01-04 16:19: Train Epoch 7: 207/634 Loss: 0.207299
2023-01-04 16:20: Train Epoch 7: 211/634 Loss: 0.146655
2023-01-04 16:21: Train Epoch 7: 215/634 Loss: 0.149004
2023-01-04 16:22: Train Epoch 7: 219/634 Loss: 0.171296
2023-01-04 16:24: Train Epoch 7: 223/634 Loss: 0.180286
2023-01-04 16:25: Train Epoch 7: 227/634 Loss: 0.159602
2023-01-04 16:26: Train Epoch 7: 231/634 Loss: 0.151391
2023-01-04 16:27: Train Epoch 7: 235/634 Loss: 0.153691
2023-01-04 16:28: Train Epoch 7: 239/634 Loss: 0.154931
2023-01-04 16:30: Train Epoch 7: 243/634 Loss: 0.174708
2023-01-04 16:31: Train Epoch 7: 247/634 Loss: 0.154792
2023-01-04 16:32: Train Epoch 7: 251/634 Loss: 0.176342
2023-01-04 16:33: Train Epoch 7: 255/634 Loss: 0.147615
2023-01-04 16:34: Train Epoch 7: 259/634 Loss: 0.142704
2023-01-04 16:35: Train Epoch 7: 263/634 Loss: 0.193921
2023-01-04 16:36: Train Epoch 7: 267/634 Loss: 0.211208
2023-01-04 16:38: Train Epoch 7: 271/634 Loss: 0.168255
2023-01-04 16:39: Train Epoch 7: 275/634 Loss: 0.156628
2023-01-04 16:40: Train Epoch 7: 279/634 Loss: 0.227615
2023-01-04 16:41: Train Epoch 7: 283/634 Loss: 0.162138
2023-01-04 16:42: Train Epoch 7: 287/634 Loss: 0.164528
2023-01-04 16:43: Train Epoch 7: 291/634 Loss: 0.174611
2023-01-04 16:45: Train Epoch 7: 295/634 Loss: 0.180924
2023-01-04 16:46: Train Epoch 7: 299/634 Loss: 0.156831
2023-01-04 16:47: Train Epoch 7: 303/634 Loss: 0.162949
2023-01-04 16:48: Train Epoch 7: 307/634 Loss: 0.161270
2023-01-04 16:49: Train Epoch 7: 311/634 Loss: 0.174408
2023-01-04 16:50: Train Epoch 7: 315/634 Loss: 0.165098
2023-01-04 16:52: Train Epoch 7: 319/634 Loss: 0.161417
2023-01-04 16:53: Train Epoch 7: 323/634 Loss: 0.203686
2023-01-04 16:54: Train Epoch 7: 327/634 Loss: 0.138278
2023-01-04 16:55: Train Epoch 7: 331/634 Loss: 0.157238
2023-01-04 16:56: Train Epoch 7: 335/634 Loss: 0.187519
2023-01-04 16:57: Train Epoch 7: 339/634 Loss: 0.171590
2023-01-04 16:59: Train Epoch 7: 343/634 Loss: 0.166144
2023-01-04 17:00: Train Epoch 7: 347/634 Loss: 0.146400
2023-01-04 17:01: Train Epoch 7: 351/634 Loss: 0.189581
2023-01-04 17:02: Train Epoch 7: 355/634 Loss: 0.153826
2023-01-04 17:03: Train Epoch 7: 359/634 Loss: 0.177099
