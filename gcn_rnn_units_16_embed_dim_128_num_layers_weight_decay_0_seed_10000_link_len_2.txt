2022-12-28 12:46: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221228124629
2022-12-28 12:46: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221228124629
2022-12-28 12:46: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=128, epochs=30, gamma=1.0, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221228124629', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='10, 15, 20, 25', lr_init=0.0005, mae_thresh=None, mape_thresh=0.0, max_grad_norm=5, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, test_ratio=0.2, val_ratio=0.2, weight_decay=0.01, window_len=10)
2022-12-28 12:46: Argument batch_size: 256
2022-12-28 12:46: Argument clc: 'vec'
2022-12-28 12:46: Argument cuda: True
2022-12-28 12:46: Argument dataset: '2020'
2022-12-28 12:46: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-28 12:46: Argument debug: False
2022-12-28 12:46: Argument default_graph: True
2022-12-28 12:46: Argument device: 'cpu'
2022-12-28 12:46: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-28 12:46: Argument early_stop: True
2022-12-28 12:46: Argument early_stop_patience: 8
2022-12-28 12:46: Argument embed_dim: 128
2022-12-28 12:46: Argument epochs: 30
2022-12-28 12:46: Argument gamma: 1.0
2022-12-28 12:46: Argument grad_norm: False
2022-12-28 12:46: Argument horizon: 1
2022-12-28 12:46: Argument input_dim: 25
2022-12-28 12:46: Argument lag: 10
2022-12-28 12:46: Argument link_len: 2
2022-12-28 12:46: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221228124629'
2022-12-28 12:46: Argument log_step: 1
2022-12-28 12:46: Argument loss_func: 'nllloss'
2022-12-28 12:46: Argument lr_decay: True
2022-12-28 12:46: Argument lr_decay_rate: 0.1
2022-12-28 12:46: Argument lr_decay_step: '10, 15, 20, 25'
2022-12-28 12:46: Argument lr_init: 0.0005
2022-12-28 12:46: Argument mae_thresh: None
2022-12-28 12:46: Argument mape_thresh: 0.0
2022-12-28 12:46: Argument max_grad_norm: 5
2022-12-28 12:46: Argument mode: 'train'
2022-12-28 12:46: Argument model: 'fire_GCN'
2022-12-28 12:46: Argument nan_fill: 0.5
2022-12-28 12:46: Argument num_layers: 1
2022-12-28 12:46: Argument num_nodes: 625
2022-12-28 12:46: Argument num_workers: 20
2022-12-28 12:46: Argument output_dim: 2
2022-12-28 12:46: Argument patch_height: 25
2022-12-28 12:46: Argument patch_width: 25
2022-12-28 12:46: Argument persistent_workers: True
2022-12-28 12:46: Argument pin_memory: True
2022-12-28 12:46: Argument plot: False
2022-12-28 12:46: Argument positive_weight: 0.5
2022-12-28 12:46: Argument prefetch_factor: 2
2022-12-28 12:46: Argument real_value: True
2022-12-28 12:46: Argument rnn_units: 16
2022-12-28 12:46: Argument seed: 10000
2022-12-28 12:46: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-28 12:46: Argument teacher_forcing: False
2022-12-28 12:46: Argument test_ratio: 0.2
2022-12-28 12:46: Argument val_ratio: 0.2
2022-12-28 12:46: Argument weight_decay: 0.01
2022-12-28 12:46: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 128]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([128, 2, 41, 16]) True
encoder.cell_list.0.gate.weights_window torch.Size([128, 1, 16]) True
encoder.cell_list.0.gate.bias_pool torch.Size([128, 32]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([128, 2, 41, 8]) True
encoder.cell_list.0.update.weights_window torch.Size([128, 1, 8]) True
encoder.cell_list.0.update.bias_pool torch.Size([128, 16]) True
encoder.cell_list.0.update.T torch.Size([10]) True
end_conv.weight torch.Size([2, 1, 625, 16]) True
end_conv.bias torch.Size([2]) True
Total params num: 361192
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221228124629/run.log
2022-12-28 12:46: Train Epoch 1: 0/159 Loss: 0.675325
2022-12-28 12:46: Train Epoch 1: 1/159 Loss: 2.301424
2022-12-28 12:47: Train Epoch 1: 2/159 Loss: 1.012393
2022-12-28 12:47: Train Epoch 1: 3/159 Loss: 0.978397
2022-12-28 12:47: Train Epoch 1: 4/159 Loss: 1.092069
2022-12-28 12:47: Train Epoch 1: 5/159 Loss: 0.632940
2022-12-28 12:47: Train Epoch 1: 6/159 Loss: 0.794675
2022-12-28 12:47: Train Epoch 1: 7/159 Loss: 0.855727
2022-12-28 12:47: Train Epoch 1: 8/159 Loss: 0.985690
2022-12-28 12:47: Train Epoch 1: 9/159 Loss: 0.703043
2022-12-28 12:47: Train Epoch 1: 10/159 Loss: 0.652888
2022-12-28 12:48: Train Epoch 1: 11/159 Loss: 0.879350
2022-12-28 12:48: Train Epoch 1: 12/159 Loss: 0.846341
2022-12-28 12:48: Train Epoch 1: 13/159 Loss: 0.655464
2022-12-28 12:48: Train Epoch 1: 14/159 Loss: 0.698061
2022-12-28 12:48: Train Epoch 1: 15/159 Loss: 0.778171
2022-12-28 12:48: Train Epoch 1: 16/159 Loss: 0.767417
2022-12-28 12:48: Train Epoch 1: 17/159 Loss: 0.625351
2022-12-28 12:48: Train Epoch 1: 18/159 Loss: 0.637237
2022-12-28 12:48: Train Epoch 1: 19/159 Loss: 0.671733
2022-12-28 12:49: Train Epoch 1: 20/159 Loss: 0.678457
2022-12-28 12:49: Train Epoch 1: 21/159 Loss: 0.651542
2022-12-28 12:49: Train Epoch 1: 22/159 Loss: 0.599842
2022-12-28 12:49: Train Epoch 1: 23/159 Loss: 0.568834
2022-12-28 12:49: Train Epoch 1: 24/159 Loss: 0.655716
2022-12-28 12:49: Train Epoch 1: 25/159 Loss: 0.668258
2022-12-28 12:49: Train Epoch 1: 26/159 Loss: 0.587522
2022-12-28 12:49: Train Epoch 1: 27/159 Loss: 0.655406
2022-12-28 12:49: Train Epoch 1: 28/159 Loss: 0.639336
2022-12-28 12:50: Train Epoch 1: 29/159 Loss: 0.683011
2022-12-28 12:50: Train Epoch 1: 30/159 Loss: 0.666604
2022-12-28 12:50: Train Epoch 1: 31/159 Loss: 0.584872
2022-12-28 12:50: Train Epoch 1: 32/159 Loss: 0.582433
2022-12-28 12:50: Train Epoch 1: 33/159 Loss: 0.672735
2022-12-28 12:50: Train Epoch 1: 34/159 Loss: 0.663304
2022-12-28 12:50: Train Epoch 1: 35/159 Loss: 0.591486
2022-12-28 12:50: Train Epoch 1: 36/159 Loss: 0.571217
2022-12-28 12:50: Train Epoch 1: 37/159 Loss: 0.610721
2022-12-28 12:51: Train Epoch 1: 38/159 Loss: 0.620417
2022-12-28 12:51: Train Epoch 1: 39/159 Loss: 0.570792
2022-12-28 12:51: Train Epoch 1: 40/159 Loss: 0.578793
2022-12-28 12:51: Train Epoch 1: 41/159 Loss: 0.626185
2022-12-28 12:51: Train Epoch 1: 42/159 Loss: 0.604505
2022-12-28 12:51: Train Epoch 1: 43/159 Loss: 0.519241
2022-12-28 12:51: Train Epoch 1: 44/159 Loss: 0.540383
2022-12-28 12:51: Train Epoch 1: 45/159 Loss: 0.532440
2022-12-28 12:51: Train Epoch 1: 46/159 Loss: 0.520807
2022-12-28 12:52: Train Epoch 1: 47/159 Loss: 0.511401
2022-12-28 12:52: Train Epoch 1: 48/159 Loss: 0.506953
2022-12-28 12:52: Train Epoch 1: 49/159 Loss: 0.517508
2022-12-28 12:52: Train Epoch 1: 50/159 Loss: 0.475819
2022-12-28 12:52: Train Epoch 1: 51/159 Loss: 0.477322
2022-12-28 12:52: Train Epoch 1: 52/159 Loss: 0.509307
2022-12-28 12:52: Train Epoch 1: 53/159 Loss: 0.476482
2022-12-28 12:52: Train Epoch 1: 54/159 Loss: 0.489756
2022-12-28 12:52: Train Epoch 1: 55/159 Loss: 0.450258
2022-12-28 12:53: Train Epoch 1: 56/159 Loss: 0.452816
2022-12-28 12:53: Train Epoch 1: 57/159 Loss: 0.452389
2022-12-28 12:53: Train Epoch 1: 58/159 Loss: 0.441406
2022-12-28 12:53: Train Epoch 1: 59/159 Loss: 0.454153
2022-12-28 12:53: Train Epoch 1: 60/159 Loss: 0.422578
2022-12-28 12:53: Train Epoch 1: 61/159 Loss: 0.443778
2022-12-28 12:53: Train Epoch 1: 62/159 Loss: 0.459484
2022-12-28 12:53: Train Epoch 1: 63/159 Loss: 0.378145
2022-12-28 12:53: Train Epoch 1: 64/159 Loss: 0.458133
2022-12-28 12:54: Train Epoch 1: 65/159 Loss: 0.455793
2022-12-28 12:54: Train Epoch 1: 66/159 Loss: 0.384919
2022-12-28 12:54: Train Epoch 1: 67/159 Loss: 0.409811
2022-12-28 12:54: Train Epoch 1: 68/159 Loss: 0.393392
2022-12-28 12:54: Train Epoch 1: 69/159 Loss: 0.456675
2022-12-28 12:54: Train Epoch 1: 70/159 Loss: 0.334751
2022-12-28 12:54: Train Epoch 1: 71/159 Loss: 0.399932
2022-12-28 12:54: Train Epoch 1: 72/159 Loss: 0.389399
2022-12-28 12:54: Train Epoch 1: 73/159 Loss: 0.414128
2022-12-28 12:55: Train Epoch 1: 74/159 Loss: 0.369378
2022-12-28 12:55: Train Epoch 1: 75/159 Loss: 0.386472
2022-12-28 12:55: Train Epoch 1: 76/159 Loss: 0.409852
2022-12-28 12:55: Train Epoch 1: 77/159 Loss: 0.362623
2022-12-28 12:55: Train Epoch 1: 78/159 Loss: 0.373921
2022-12-28 12:55: Train Epoch 1: 79/159 Loss: 0.433139
2022-12-28 12:55: Train Epoch 1: 80/159 Loss: 0.359984
2022-12-28 12:55: Train Epoch 1: 81/159 Loss: 0.334346
2022-12-28 12:55: Train Epoch 1: 82/159 Loss: 0.339116
2022-12-28 12:56: Train Epoch 1: 83/159 Loss: 0.357267
2022-12-28 12:56: Train Epoch 1: 84/159 Loss: 0.356649
2022-12-28 12:56: Train Epoch 1: 85/159 Loss: 0.378481
2022-12-28 12:56: Train Epoch 1: 86/159 Loss: 0.331649
2022-12-28 12:56: Train Epoch 1: 87/159 Loss: 0.377559
2022-12-28 12:56: Train Epoch 1: 88/159 Loss: 0.352032
2022-12-28 12:56: Train Epoch 1: 89/159 Loss: 0.396401
2022-12-28 12:56: Train Epoch 1: 90/159 Loss: 0.373613
2022-12-28 12:56: Train Epoch 1: 91/159 Loss: 0.339077
2022-12-28 12:56: Train Epoch 1: 92/159 Loss: 0.338932
2022-12-28 12:57: Train Epoch 1: 93/159 Loss: 0.376805
2022-12-28 12:57: Train Epoch 1: 94/159 Loss: 0.302620
2022-12-28 12:57: Train Epoch 1: 95/159 Loss: 0.365438
2022-12-28 12:57: Train Epoch 1: 96/159 Loss: 0.355545
2022-12-28 12:57: Train Epoch 1: 97/159 Loss: 0.316398
2022-12-28 12:57: Train Epoch 1: 98/159 Loss: 0.329123
2022-12-28 12:57: Train Epoch 1: 99/159 Loss: 0.352174
2022-12-28 12:57: Train Epoch 1: 100/159 Loss: 0.308553
2022-12-28 12:57: Train Epoch 1: 101/159 Loss: 0.336348
2022-12-28 12:58: Train Epoch 1: 102/159 Loss: 0.333074
2022-12-28 12:58: Train Epoch 1: 103/159 Loss: 0.307920
2022-12-28 12:58: Train Epoch 1: 104/159 Loss: 0.359301
2022-12-28 12:58: Train Epoch 1: 105/159 Loss: 0.331297
2022-12-28 12:58: Train Epoch 1: 106/159 Loss: 0.325481
2022-12-28 12:58: Train Epoch 1: 107/159 Loss: 0.332776
2022-12-28 12:58: Train Epoch 1: 108/159 Loss: 0.416543
2022-12-28 12:58: Train Epoch 1: 109/159 Loss: 0.326818
2022-12-28 12:58: Train Epoch 1: 110/159 Loss: 0.270861
2022-12-28 12:59: Train Epoch 1: 111/159 Loss: 0.269901
2022-12-28 12:59: Train Epoch 1: 112/159 Loss: 0.315833
2022-12-28 12:59: Train Epoch 1: 113/159 Loss: 0.362910
2022-12-28 12:59: Train Epoch 1: 114/159 Loss: 0.318630
2022-12-28 12:59: Train Epoch 1: 115/159 Loss: 0.308256
2022-12-28 12:59: Train Epoch 1: 116/159 Loss: 0.326341
2022-12-28 12:59: Train Epoch 1: 117/159 Loss: 0.318440
2022-12-28 12:59: Train Epoch 1: 118/159 Loss: 0.286191
2022-12-28 12:59: Train Epoch 1: 119/159 Loss: 0.306844
2022-12-28 13:00: Train Epoch 1: 120/159 Loss: 0.329074
2022-12-28 13:00: Train Epoch 1: 121/159 Loss: 0.322113
2022-12-28 13:00: Train Epoch 1: 122/159 Loss: 0.288008
2022-12-28 13:00: Train Epoch 1: 123/159 Loss: 0.349305
2022-12-28 13:00: Train Epoch 1: 124/159 Loss: 0.285549
2022-12-28 13:00: Train Epoch 1: 125/159 Loss: 0.340048
2022-12-28 13:00: Train Epoch 1: 126/159 Loss: 0.295845
2022-12-28 13:00: Train Epoch 1: 127/159 Loss: 0.433641
2022-12-28 13:00: Train Epoch 1: 128/159 Loss: 0.294388
2022-12-28 13:00: Train Epoch 1: 129/159 Loss: 0.404289
2022-12-28 13:01: Train Epoch 1: 130/159 Loss: 0.297026
2022-12-28 13:01: Train Epoch 1: 131/159 Loss: 0.389575
2022-12-28 13:01: Train Epoch 1: 132/159 Loss: 0.319593
2022-12-28 13:01: Train Epoch 1: 133/159 Loss: 0.254605
2022-12-28 13:01: Train Epoch 1: 134/159 Loss: 0.308725
2022-12-28 13:01: Train Epoch 1: 135/159 Loss: 0.335938
2022-12-28 13:01: Train Epoch 1: 136/159 Loss: 0.325727
2022-12-28 13:01: Train Epoch 1: 137/159 Loss: 0.332829
2022-12-28 13:01: Train Epoch 1: 138/159 Loss: 0.299430
2022-12-28 13:02: Train Epoch 1: 139/159 Loss: 0.338176
2022-12-28 13:02: Train Epoch 1: 140/159 Loss: 0.321827
2022-12-28 13:02: Train Epoch 1: 141/159 Loss: 0.280799
2022-12-28 13:02: Train Epoch 1: 142/159 Loss: 0.298145
2022-12-28 13:02: Train Epoch 1: 143/159 Loss: 0.311074
2022-12-28 13:02: Train Epoch 1: 144/159 Loss: 0.342053
2022-12-28 13:02: Train Epoch 1: 145/159 Loss: 0.239672
2022-12-28 13:02: Train Epoch 1: 146/159 Loss: 0.321730
2022-12-28 13:02: Train Epoch 1: 147/159 Loss: 0.327214
2022-12-28 13:03: Train Epoch 1: 148/159 Loss: 0.284043
2022-12-28 13:03: Train Epoch 1: 149/159 Loss: 0.319895
2022-12-28 13:03: Train Epoch 1: 150/159 Loss: 0.393571
2022-12-28 13:03: Train Epoch 1: 151/159 Loss: 0.350307
2022-12-28 13:03: Train Epoch 1: 152/159 Loss: 0.302040
2022-12-28 13:03: Train Epoch 1: 153/159 Loss: 0.397562
2022-12-28 13:03: Train Epoch 1: 154/159 Loss: 0.300413
2022-12-28 13:03: Train Epoch 1: 155/159 Loss: 0.264222
2022-12-28 13:03: Train Epoch 1: 156/159 Loss: 0.342242
2022-12-28 13:03: Train Epoch 1: 157/159 Loss: 0.346554
2022-12-28 13:04: Train Epoch 1: 158/159 Loss: 0.379421
2022-12-28 13:04: **********Train Epoch 1: averaged Loss: 0.466683 
2022-12-28 13:04: 
Epoch time elapsed: 1051.5889558792114

2022-12-28 13:04: 
 metrics validation: {'precision': 0.6082783443311338, 'recall': 0.78, 'f1-score': 0.6835187057633973, 'support': 1300, 'AUC': 0.8031198224852071, 'AUCPR': 0.7108908186497719, 'TP': 1014, 'FP': 653, 'TN': 1947, 'FN': 286} 

2022-12-28 13:04: **********Val Epoch 1: average Loss: 0.602841
2022-12-28 13:04: *********************************Current best model saved!
2022-12-28 13:04: 
 Testing metrics {'precision': 0.6745283018867925, 'recall': 0.8151465798045603, 'f1-score': 0.7382005899705015, 'support': 1228, 'AUC': 0.8566029215164086, 'AUCPR': 0.7807216821782551, 'TP': 1001, 'FP': 483, 'TN': 1973, 'FN': 227} 

2022-12-28 13:05: Train Epoch 2: 0/159 Loss: 0.371478
2022-12-28 13:05: Train Epoch 2: 1/159 Loss: 0.282707
2022-12-28 13:05: Train Epoch 2: 2/159 Loss: 0.267963
2022-12-28 13:05: Train Epoch 2: 3/159 Loss: 0.360355
2022-12-28 13:05: Train Epoch 2: 4/159 Loss: 0.377895
2022-12-28 13:05: Train Epoch 2: 5/159 Loss: 0.306879
2022-12-28 13:05: Train Epoch 2: 6/159 Loss: 0.301480
2022-12-28 13:05: Train Epoch 2: 7/159 Loss: 0.343454
2022-12-28 13:05: Train Epoch 2: 8/159 Loss: 0.369700
2022-12-28 13:06: Train Epoch 2: 9/159 Loss: 0.324288
2022-12-28 13:06: Train Epoch 2: 10/159 Loss: 0.325627
2022-12-28 13:06: Train Epoch 2: 11/159 Loss: 0.297695
2022-12-28 13:06: Train Epoch 2: 12/159 Loss: 0.272883
2022-12-28 13:06: Train Epoch 2: 13/159 Loss: 0.314515
2022-12-28 13:06: Train Epoch 2: 14/159 Loss: 0.316446
2022-12-28 13:06: Train Epoch 2: 15/159 Loss: 0.291342
2022-12-28 13:06: Train Epoch 2: 16/159 Loss: 0.368390
2022-12-28 13:06: Train Epoch 2: 17/159 Loss: 0.274604
2022-12-28 13:07: Train Epoch 2: 18/159 Loss: 0.309601
2022-12-28 13:07: Train Epoch 2: 19/159 Loss: 0.348657
2022-12-28 13:07: Train Epoch 2: 20/159 Loss: 0.300299
2022-12-28 13:07: Train Epoch 2: 21/159 Loss: 0.321987
2022-12-28 13:07: Train Epoch 2: 22/159 Loss: 0.293711
2022-12-28 13:07: Train Epoch 2: 23/159 Loss: 0.347498
2022-12-28 13:07: Train Epoch 2: 24/159 Loss: 0.338593
2022-12-28 13:07: Train Epoch 2: 25/159 Loss: 0.351240
2022-12-28 13:07: Train Epoch 2: 26/159 Loss: 0.234535
2022-12-28 13:08: Train Epoch 2: 27/159 Loss: 0.292157
2022-12-28 13:08: Train Epoch 2: 28/159 Loss: 0.302979
2022-12-28 13:08: Train Epoch 2: 29/159 Loss: 0.328740
2022-12-28 13:08: Train Epoch 2: 30/159 Loss: 0.409220
2022-12-28 13:08: Train Epoch 2: 31/159 Loss: 0.354759
2022-12-28 13:08: Train Epoch 2: 32/159 Loss: 0.293465
2022-12-28 13:08: Train Epoch 2: 33/159 Loss: 0.339197
2022-12-28 13:08: Train Epoch 2: 34/159 Loss: 0.339286
2022-12-28 13:08: Train Epoch 2: 35/159 Loss: 0.327707
2022-12-28 13:09: Train Epoch 2: 36/159 Loss: 0.271650
2022-12-28 13:09: Train Epoch 2: 37/159 Loss: 0.338034
2022-12-28 13:09: Train Epoch 2: 38/159 Loss: 0.303749
2022-12-28 13:09: Train Epoch 2: 39/159 Loss: 0.284807
2022-12-28 13:09: Train Epoch 2: 40/159 Loss: 0.311046
2022-12-28 13:09: Train Epoch 2: 41/159 Loss: 0.294011
2022-12-28 13:09: Train Epoch 2: 42/159 Loss: 0.335728
2022-12-28 13:09: Train Epoch 2: 43/159 Loss: 0.305263
2022-12-28 13:09: Train Epoch 2: 44/159 Loss: 0.297581
2022-12-28 13:10: Train Epoch 2: 45/159 Loss: 0.253714
2022-12-28 13:10: Train Epoch 2: 46/159 Loss: 0.253716
2022-12-28 13:10: Train Epoch 2: 47/159 Loss: 0.302453
2022-12-28 13:10: Train Epoch 2: 48/159 Loss: 0.311296
2022-12-28 13:10: Train Epoch 2: 49/159 Loss: 0.316522
2022-12-28 13:10: Train Epoch 2: 50/159 Loss: 0.310417
2022-12-28 13:10: Train Epoch 2: 51/159 Loss: 0.310812
2022-12-28 13:10: Train Epoch 2: 52/159 Loss: 0.294999
2022-12-28 13:10: Train Epoch 2: 53/159 Loss: 0.310389
2022-12-28 13:11: Train Epoch 2: 54/159 Loss: 0.265847
2022-12-28 13:11: Train Epoch 2: 55/159 Loss: 0.343951
2022-12-28 13:11: Train Epoch 2: 56/159 Loss: 0.273871
2022-12-28 13:11: Train Epoch 2: 57/159 Loss: 0.334534
2022-12-28 13:11: Train Epoch 2: 58/159 Loss: 0.389699
2022-12-28 13:11: Train Epoch 2: 59/159 Loss: 0.349072
2022-12-28 13:11: Train Epoch 2: 60/159 Loss: 0.313903
2022-12-28 13:11: Train Epoch 2: 61/159 Loss: 0.244467
2022-12-28 13:11: Train Epoch 2: 62/159 Loss: 0.386906
2022-12-28 13:12: Train Epoch 2: 63/159 Loss: 0.321057
2022-12-28 13:12: Train Epoch 2: 64/159 Loss: 0.305619
2022-12-28 13:12: Train Epoch 2: 65/159 Loss: 0.280627
2022-12-28 13:12: Train Epoch 2: 66/159 Loss: 0.383409
2022-12-28 13:12: Train Epoch 2: 67/159 Loss: 0.321465
2022-12-28 13:12: Train Epoch 2: 68/159 Loss: 0.332217
2022-12-28 13:12: Train Epoch 2: 69/159 Loss: 0.313410
2022-12-28 13:12: Train Epoch 2: 70/159 Loss: 0.291053
2022-12-28 13:12: Train Epoch 2: 71/159 Loss: 0.292492
2022-12-28 13:13: Train Epoch 2: 72/159 Loss: 0.349543
2022-12-28 13:13: Train Epoch 2: 73/159 Loss: 0.297925
2022-12-28 13:13: Train Epoch 2: 74/159 Loss: 0.342466
2022-12-28 13:13: Train Epoch 2: 75/159 Loss: 0.335957
2022-12-28 13:13: Train Epoch 2: 76/159 Loss: 0.273390
2022-12-28 13:13: Train Epoch 2: 77/159 Loss: 0.281801
2022-12-28 13:13: Train Epoch 2: 78/159 Loss: 0.255912
2022-12-28 13:13: Train Epoch 2: 79/159 Loss: 0.305097
2022-12-28 13:13: Train Epoch 2: 80/159 Loss: 0.377531
2022-12-28 13:14: Train Epoch 2: 81/159 Loss: 0.267705
2022-12-28 13:14: Train Epoch 2: 82/159 Loss: 0.259090
2022-12-28 13:14: Train Epoch 2: 83/159 Loss: 0.303824
2022-12-28 13:14: Train Epoch 2: 84/159 Loss: 0.319858
2022-12-28 13:14: Train Epoch 2: 85/159 Loss: 0.325756
2022-12-28 13:14: Train Epoch 2: 86/159 Loss: 0.307514
2022-12-28 13:14: Train Epoch 2: 87/159 Loss: 0.298319
2022-12-28 13:14: Train Epoch 2: 88/159 Loss: 0.388511
2022-12-28 13:14: Train Epoch 2: 89/159 Loss: 0.339959
2022-12-28 13:14: Train Epoch 2: 90/159 Loss: 0.257382
2022-12-28 13:15: Train Epoch 2: 91/159 Loss: 0.366393
2022-12-28 13:15: Train Epoch 2: 92/159 Loss: 0.289637
2022-12-28 13:15: Train Epoch 2: 93/159 Loss: 0.341183
2022-12-28 13:15: Train Epoch 2: 94/159 Loss: 0.354385
2022-12-28 13:15: Train Epoch 2: 95/159 Loss: 0.304287
2022-12-28 13:15: Train Epoch 2: 96/159 Loss: 0.300562
2022-12-28 13:15: Train Epoch 2: 97/159 Loss: 0.346794
2022-12-28 13:15: Train Epoch 2: 98/159 Loss: 0.303388
2022-12-28 13:15: Train Epoch 2: 99/159 Loss: 0.314794
2022-12-28 13:16: Train Epoch 2: 100/159 Loss: 0.312619
2022-12-28 13:16: Train Epoch 2: 101/159 Loss: 0.274010
2022-12-28 13:16: Train Epoch 2: 102/159 Loss: 0.329930
2022-12-28 13:16: Train Epoch 2: 103/159 Loss: 0.282400
2022-12-28 13:16: Train Epoch 2: 104/159 Loss: 0.308617
2022-12-28 13:16: Train Epoch 2: 105/159 Loss: 0.286979
2022-12-28 13:16: Train Epoch 2: 106/159 Loss: 0.333278
2022-12-28 13:16: Train Epoch 2: 107/159 Loss: 0.336347
2022-12-28 13:16: Train Epoch 2: 108/159 Loss: 0.289380
2022-12-28 13:17: Train Epoch 2: 109/159 Loss: 0.318086
2022-12-28 13:17: Train Epoch 2: 110/159 Loss: 0.264883
2022-12-28 13:17: Train Epoch 2: 111/159 Loss: 0.273891
2022-12-28 13:17: Train Epoch 2: 112/159 Loss: 0.274086
2022-12-28 13:17: Train Epoch 2: 113/159 Loss: 0.309835
2022-12-28 13:17: Train Epoch 2: 114/159 Loss: 0.316951
2022-12-28 13:17: Train Epoch 2: 115/159 Loss: 0.276694
2022-12-28 13:17: Train Epoch 2: 116/159 Loss: 0.295228
2022-12-28 13:17: Train Epoch 2: 117/159 Loss: 0.280496
2022-12-28 13:18: Train Epoch 2: 118/159 Loss: 0.319598
2022-12-28 13:18: Train Epoch 2: 119/159 Loss: 0.336871
2022-12-28 13:18: Train Epoch 2: 120/159 Loss: 0.333776
2022-12-28 13:18: Train Epoch 2: 121/159 Loss: 0.299355
2022-12-28 13:18: Train Epoch 2: 122/159 Loss: 0.342951
2022-12-28 13:18: Train Epoch 2: 123/159 Loss: 0.250632
2022-12-28 13:18: Train Epoch 2: 124/159 Loss: 0.325916
2022-12-28 13:18: Train Epoch 2: 125/159 Loss: 0.295566
2022-12-28 13:18: Train Epoch 2: 126/159 Loss: 0.369663
2022-12-28 13:19: Train Epoch 2: 127/159 Loss: 0.300115
2022-12-28 13:19: Train Epoch 2: 128/159 Loss: 0.312429
2022-12-28 13:19: Train Epoch 2: 129/159 Loss: 0.406624
2022-12-28 13:19: Train Epoch 2: 130/159 Loss: 0.253812
2022-12-28 13:19: Train Epoch 2: 131/159 Loss: 0.321837
2022-12-28 13:19: Train Epoch 2: 132/159 Loss: 0.381581
2022-12-28 13:19: Train Epoch 2: 133/159 Loss: 0.275712
2022-12-28 13:19: Train Epoch 2: 134/159 Loss: 0.300089
2022-12-28 13:19: Train Epoch 2: 135/159 Loss: 0.282271
2022-12-28 13:20: Train Epoch 2: 136/159 Loss: 0.347265
2022-12-28 13:20: Train Epoch 2: 137/159 Loss: 0.311656
2022-12-28 13:20: Train Epoch 2: 138/159 Loss: 0.265709
2022-12-28 13:20: Train Epoch 2: 139/159 Loss: 0.248565
2022-12-28 13:20: Train Epoch 2: 140/159 Loss: 0.351841
2022-12-28 13:20: Train Epoch 2: 141/159 Loss: 0.308088
2022-12-28 13:20: Train Epoch 2: 142/159 Loss: 0.293143
2022-12-28 13:20: Train Epoch 2: 143/159 Loss: 0.285420
2022-12-28 13:20: Train Epoch 2: 144/159 Loss: 0.311293
2022-12-28 13:21: Train Epoch 2: 145/159 Loss: 0.311375
2022-12-28 13:21: Train Epoch 2: 146/159 Loss: 0.293421
2022-12-28 13:21: Train Epoch 2: 147/159 Loss: 0.351060
2022-12-28 13:21: Train Epoch 2: 148/159 Loss: 0.336263
2022-12-28 13:21: Train Epoch 2: 149/159 Loss: 0.387959
2022-12-28 13:21: Train Epoch 2: 150/159 Loss: 0.330644
2022-12-28 13:21: Train Epoch 2: 151/159 Loss: 0.279269
2022-12-28 13:21: Train Epoch 2: 152/159 Loss: 0.293031
2022-12-28 13:21: Train Epoch 2: 153/159 Loss: 0.276981
2022-12-28 13:22: Train Epoch 2: 154/159 Loss: 0.325485
2022-12-28 13:22: Train Epoch 2: 155/159 Loss: 0.284662
2022-12-28 13:22: Train Epoch 2: 156/159 Loss: 0.292418
2022-12-28 13:22: Train Epoch 2: 157/159 Loss: 0.296119
2022-12-28 13:22: Train Epoch 2: 158/159 Loss: 0.301902
2022-12-28 13:22: **********Train Epoch 2: averaged Loss: 0.312680 
2022-12-28 13:22: 
Epoch time elapsed: 1054.2209792137146

2022-12-28 13:22: 
 metrics validation: {'precision': 0.631578947368421, 'recall': 0.7753846153846153, 'f1-score': 0.6961325966850828, 'support': 1300, 'AUC': 0.8133606508875739, 'AUCPR': 0.7214302377652541, 'TP': 1008, 'FP': 588, 'TN': 2012, 'FN': 292} 

2022-12-28 13:22: **********Val Epoch 2: average Loss: 0.566122
2022-12-28 13:22: *********************************Current best model saved!
2022-12-28 13:23: 
 Testing metrics {'precision': 0.6988120195667366, 'recall': 0.8143322475570033, 'f1-score': 0.7521624670928921, 'support': 1228, 'AUC': 0.860537976530255, 'AUCPR': 0.7845281578918321, 'TP': 1000, 'FP': 431, 'TN': 2025, 'FN': 228} 

2022-12-28 13:23: Train Epoch 3: 0/159 Loss: 0.279732
2022-12-28 13:23: Train Epoch 3: 1/159 Loss: 0.281299
2022-12-28 13:23: Train Epoch 3: 2/159 Loss: 0.315720
2022-12-28 13:23: Train Epoch 3: 3/159 Loss: 0.334447
2022-12-28 13:23: Train Epoch 3: 4/159 Loss: 0.381347
2022-12-28 13:23: Train Epoch 3: 5/159 Loss: 0.322143
2022-12-28 13:23: Train Epoch 3: 6/159 Loss: 0.316353
2022-12-28 13:23: Train Epoch 3: 7/159 Loss: 0.281904
2022-12-28 13:24: Train Epoch 3: 8/159 Loss: 0.347008
2022-12-28 13:24: Train Epoch 3: 9/159 Loss: 0.402966
2022-12-28 13:24: Train Epoch 3: 10/159 Loss: 0.317310
2022-12-28 13:24: Train Epoch 3: 11/159 Loss: 0.368689
2022-12-28 13:24: Train Epoch 3: 12/159 Loss: 0.318602
2022-12-28 13:24: Train Epoch 3: 13/159 Loss: 0.349783
2022-12-28 13:24: Train Epoch 3: 14/159 Loss: 0.276629
2022-12-28 13:24: Train Epoch 3: 15/159 Loss: 0.395063
2022-12-28 13:24: Train Epoch 3: 16/159 Loss: 0.260541
2022-12-28 13:25: Train Epoch 3: 17/159 Loss: 0.327003
2022-12-28 13:25: Train Epoch 3: 18/159 Loss: 0.271789
2022-12-28 13:25: Train Epoch 3: 19/159 Loss: 0.328951
2022-12-28 13:25: Train Epoch 3: 20/159 Loss: 0.312790
2022-12-28 13:25: Train Epoch 3: 21/159 Loss: 0.285408
2022-12-28 13:25: Train Epoch 3: 22/159 Loss: 0.337694
2022-12-28 13:25: Train Epoch 3: 23/159 Loss: 0.293532
2022-12-28 13:25: Train Epoch 3: 24/159 Loss: 0.266419
2022-12-28 13:25: Train Epoch 3: 25/159 Loss: 0.321312
2022-12-28 13:26: Train Epoch 3: 26/159 Loss: 0.320867
2022-12-28 13:26: Train Epoch 3: 27/159 Loss: 0.315175
2022-12-28 13:26: Train Epoch 3: 28/159 Loss: 0.314944
2022-12-28 13:26: Train Epoch 3: 29/159 Loss: 0.364456
2022-12-28 13:26: Train Epoch 3: 30/159 Loss: 0.324278
2022-12-28 13:26: Train Epoch 3: 31/159 Loss: 0.314147
2022-12-28 13:26: Train Epoch 3: 32/159 Loss: 0.267864
2022-12-28 13:26: Train Epoch 3: 33/159 Loss: 0.234128
2022-12-28 13:26: Train Epoch 3: 34/159 Loss: 0.300645
2022-12-28 13:27: Train Epoch 3: 35/159 Loss: 0.289973
2022-12-28 13:27: Train Epoch 3: 36/159 Loss: 0.315817
2022-12-28 13:27: Train Epoch 3: 37/159 Loss: 0.266980
2022-12-28 13:27: Train Epoch 3: 38/159 Loss: 0.335137
2022-12-28 13:27: Train Epoch 3: 39/159 Loss: 0.284622
2022-12-28 13:27: Train Epoch 3: 40/159 Loss: 0.282887
2022-12-28 13:27: Train Epoch 3: 41/159 Loss: 0.329259
2022-12-28 13:27: Train Epoch 3: 42/159 Loss: 0.332609
2022-12-28 13:27: Train Epoch 3: 43/159 Loss: 0.294241
2022-12-28 13:28: Train Epoch 3: 44/159 Loss: 0.320360
2022-12-28 13:28: Train Epoch 3: 45/159 Loss: 0.319615
2022-12-28 13:28: Train Epoch 3: 46/159 Loss: 0.280544
2022-12-28 13:28: Train Epoch 3: 47/159 Loss: 0.367730
2022-12-28 13:28: Train Epoch 3: 48/159 Loss: 0.312256
2022-12-28 13:28: Train Epoch 3: 49/159 Loss: 0.294440
2022-12-28 13:28: Train Epoch 3: 50/159 Loss: 0.259848
2022-12-28 13:28: Train Epoch 3: 51/159 Loss: 0.299183
2022-12-28 13:28: Train Epoch 3: 52/159 Loss: 0.303137
2022-12-28 13:29: Train Epoch 3: 53/159 Loss: 0.286014
2022-12-28 13:29: Train Epoch 3: 54/159 Loss: 0.321385
2022-12-28 13:29: Train Epoch 3: 55/159 Loss: 0.252456
2022-12-28 13:29: Train Epoch 3: 56/159 Loss: 0.321178
2022-12-28 13:29: Train Epoch 3: 57/159 Loss: 0.312933
2022-12-28 13:29: Train Epoch 3: 58/159 Loss: 0.267718
2022-12-28 13:29: Train Epoch 3: 59/159 Loss: 0.352499
2022-12-28 13:29: Train Epoch 3: 60/159 Loss: 0.290761
2022-12-28 13:29: Train Epoch 3: 61/159 Loss: 0.282845
2022-12-28 13:30: Train Epoch 3: 62/159 Loss: 0.319115
2022-12-28 13:30: Train Epoch 3: 63/159 Loss: 0.256835
2022-12-28 13:30: Train Epoch 3: 64/159 Loss: 0.325416
2022-12-28 13:30: Train Epoch 3: 65/159 Loss: 0.339919
2022-12-28 13:30: Train Epoch 3: 66/159 Loss: 0.297796
2022-12-28 13:30: Train Epoch 3: 67/159 Loss: 0.311705
2022-12-28 13:30: Train Epoch 3: 68/159 Loss: 0.296188
2022-12-28 13:30: Train Epoch 3: 69/159 Loss: 0.292135
2022-12-28 13:31: Train Epoch 3: 70/159 Loss: 0.282313
2022-12-28 13:31: Train Epoch 3: 71/159 Loss: 0.295338
2022-12-28 13:31: Train Epoch 3: 72/159 Loss: 0.252452
2022-12-28 13:31: Train Epoch 3: 73/159 Loss: 0.268263
2022-12-28 13:31: Train Epoch 3: 74/159 Loss: 0.229854
2022-12-28 13:31: Train Epoch 3: 75/159 Loss: 0.337213
2022-12-28 13:31: Train Epoch 3: 76/159 Loss: 0.301683
2022-12-28 13:31: Train Epoch 3: 77/159 Loss: 0.304725
2022-12-28 13:31: Train Epoch 3: 78/159 Loss: 0.257328
2022-12-28 13:32: Train Epoch 3: 79/159 Loss: 0.316901
2022-12-28 13:32: Train Epoch 3: 80/159 Loss: 0.256662
2022-12-28 13:32: Train Epoch 3: 81/159 Loss: 0.302586
2022-12-28 13:32: Train Epoch 3: 82/159 Loss: 0.354884
2022-12-28 13:32: Train Epoch 3: 83/159 Loss: 0.320523
2022-12-28 13:32: Train Epoch 3: 84/159 Loss: 0.300486
2022-12-28 13:32: Train Epoch 3: 85/159 Loss: 0.303231
2022-12-28 13:32: Train Epoch 3: 86/159 Loss: 0.378654
2022-12-28 13:32: Train Epoch 3: 87/159 Loss: 0.304707
2022-12-28 13:33: Train Epoch 3: 88/159 Loss: 0.300447
2022-12-28 13:33: Train Epoch 3: 89/159 Loss: 0.345320
2022-12-28 13:33: Train Epoch 3: 90/159 Loss: 0.353457
2022-12-28 13:33: Train Epoch 3: 91/159 Loss: 0.278617
2022-12-28 13:33: Train Epoch 3: 92/159 Loss: 0.294800
2022-12-28 13:33: Train Epoch 3: 93/159 Loss: 0.295630
2022-12-28 13:33: Train Epoch 3: 94/159 Loss: 0.304567
2022-12-28 13:33: Train Epoch 3: 95/159 Loss: 0.314114
2022-12-28 13:33: Train Epoch 3: 96/159 Loss: 0.314158
2022-12-28 13:34: Train Epoch 3: 97/159 Loss: 0.315214
2022-12-28 13:34: Train Epoch 3: 98/159 Loss: 0.296379
2022-12-28 13:34: Train Epoch 3: 99/159 Loss: 0.269908
2022-12-28 13:34: Train Epoch 3: 100/159 Loss: 0.337831
2022-12-28 13:34: Train Epoch 3: 101/159 Loss: 0.289017
2022-12-28 13:34: Train Epoch 3: 102/159 Loss: 0.239943
2022-12-28 13:34: Train Epoch 3: 103/159 Loss: 0.306600
2022-12-28 13:34: Train Epoch 3: 104/159 Loss: 0.279293
2022-12-28 13:34: Train Epoch 3: 105/159 Loss: 0.297373
2022-12-28 13:35: Train Epoch 3: 106/159 Loss: 0.302829
2022-12-28 13:35: Train Epoch 3: 107/159 Loss: 0.258397
2022-12-28 13:35: Train Epoch 3: 108/159 Loss: 0.318280
2022-12-28 13:35: Train Epoch 3: 109/159 Loss: 0.279728
2022-12-28 13:35: Train Epoch 3: 110/159 Loss: 0.294748
2022-12-28 13:35: Train Epoch 3: 111/159 Loss: 0.300924
2022-12-28 13:35: Train Epoch 3: 112/159 Loss: 0.293291
2022-12-28 13:35: Train Epoch 3: 113/159 Loss: 0.344429
2022-12-28 13:35: Train Epoch 3: 114/159 Loss: 0.333236
2022-12-28 13:36: Train Epoch 3: 115/159 Loss: 0.251001
2022-12-28 13:36: Train Epoch 3: 116/159 Loss: 0.276769
2022-12-28 13:36: Train Epoch 3: 117/159 Loss: 0.309573
2022-12-28 13:36: Train Epoch 3: 118/159 Loss: 0.305418
2022-12-28 13:36: Train Epoch 3: 119/159 Loss: 0.372890
2022-12-28 13:36: Train Epoch 3: 120/159 Loss: 0.319386
2022-12-28 13:36: Train Epoch 3: 121/159 Loss: 0.285068
2022-12-28 13:36: Train Epoch 3: 122/159 Loss: 0.293621
2022-12-28 13:36: Train Epoch 3: 123/159 Loss: 0.302074
2022-12-28 13:37: Train Epoch 3: 124/159 Loss: 0.279858
2022-12-28 13:37: Train Epoch 3: 125/159 Loss: 0.314485
2022-12-28 13:37: Train Epoch 3: 126/159 Loss: 0.322940
2022-12-28 13:37: Train Epoch 3: 127/159 Loss: 0.335220
2022-12-28 13:37: Train Epoch 3: 128/159 Loss: 0.306766
2022-12-28 13:37: Train Epoch 3: 129/159 Loss: 0.323138
2022-12-28 13:37: Train Epoch 3: 130/159 Loss: 0.298709
2022-12-28 13:37: Train Epoch 3: 131/159 Loss: 0.314103
2022-12-28 13:37: Train Epoch 3: 132/159 Loss: 0.336968
2022-12-28 13:38: Train Epoch 3: 133/159 Loss: 0.344728
2022-12-28 13:38: Train Epoch 3: 134/159 Loss: 0.295474
2022-12-28 13:38: Train Epoch 3: 135/159 Loss: 0.284958
2022-12-28 13:38: Train Epoch 3: 136/159 Loss: 0.320460
2022-12-28 13:38: Train Epoch 3: 137/159 Loss: 0.244270
2022-12-28 13:38: Train Epoch 3: 138/159 Loss: 0.261128
2022-12-28 13:38: Train Epoch 3: 139/159 Loss: 0.307419
2022-12-28 13:38: Train Epoch 3: 140/159 Loss: 0.319255
2022-12-28 13:38: Train Epoch 3: 141/159 Loss: 0.388528
2022-12-28 13:39: Train Epoch 3: 142/159 Loss: 0.316578
2022-12-28 13:39: Train Epoch 3: 143/159 Loss: 0.311030
2022-12-28 13:39: Train Epoch 3: 144/159 Loss: 0.293211
2022-12-28 13:39: Train Epoch 3: 145/159 Loss: 0.277861
2022-12-28 13:39: Train Epoch 3: 146/159 Loss: 0.325071
2022-12-28 13:39: Train Epoch 3: 147/159 Loss: 0.328161
2022-12-28 13:39: Train Epoch 3: 148/159 Loss: 0.277630
2022-12-28 13:39: Train Epoch 3: 149/159 Loss: 0.287098
2022-12-28 13:39: Train Epoch 3: 150/159 Loss: 0.299437
2022-12-28 13:40: Train Epoch 3: 151/159 Loss: 0.271253
2022-12-28 13:40: Train Epoch 3: 152/159 Loss: 0.320031
2022-12-28 13:40: Train Epoch 3: 153/159 Loss: 0.284499
2022-12-28 13:40: Train Epoch 3: 154/159 Loss: 0.280241
2022-12-28 13:40: Train Epoch 3: 155/159 Loss: 0.345551
2022-12-28 13:40: Train Epoch 3: 156/159 Loss: 0.322253
2022-12-28 13:40: Train Epoch 3: 157/159 Loss: 0.285676
2022-12-28 13:40: Train Epoch 3: 158/159 Loss: 0.358138
2022-12-28 13:40: **********Train Epoch 3: averaged Loss: 0.306231 
2022-12-28 13:40: 
Epoch time elapsed: 1058.6435828208923

2022-12-28 13:41: 
 metrics validation: {'precision': 0.6758922068463219, 'recall': 0.7138461538461538, 'f1-score': 0.6943509165731387, 'support': 1300, 'AUC': 0.81996449704142, 'AUCPR': 0.729925852520459, 'TP': 928, 'FP': 445, 'TN': 2155, 'FN': 372} 

2022-12-28 13:41: **********Val Epoch 3: average Loss: 0.534424
2022-12-28 13:41: *********************************Current best model saved!
2022-12-28 13:41: 
 Testing metrics {'precision': 0.7476340694006309, 'recall': 0.7719869706840391, 'f1-score': 0.7596153846153846, 'support': 1228, 'AUC': 0.8618877919129115, 'AUCPR': 0.7853136130556707, 'TP': 948, 'FP': 320, 'TN': 2136, 'FN': 280} 

2022-12-28 13:41: Train Epoch 4: 0/159 Loss: 0.335456
2022-12-28 13:41: Train Epoch 4: 1/159 Loss: 0.258644
2022-12-28 13:41: Train Epoch 4: 2/159 Loss: 0.383495
2022-12-28 13:41: Train Epoch 4: 3/159 Loss: 0.262209
2022-12-28 13:41: Train Epoch 4: 4/159 Loss: 0.314541
2022-12-28 13:42: Train Epoch 4: 5/159 Loss: 0.310653
2022-12-28 13:42: Train Epoch 4: 6/159 Loss: 0.300180
2022-12-28 13:42: Train Epoch 4: 7/159 Loss: 0.288306
2022-12-28 13:42: Train Epoch 4: 8/159 Loss: 0.340047
2022-12-28 13:42: Train Epoch 4: 9/159 Loss: 0.283444
2022-12-28 13:42: Train Epoch 4: 10/159 Loss: 0.282900
2022-12-28 13:42: Train Epoch 4: 11/159 Loss: 0.318208
2022-12-28 13:42: Train Epoch 4: 12/159 Loss: 0.262597
2022-12-28 13:43: Train Epoch 4: 13/159 Loss: 0.265697
2022-12-28 13:43: Train Epoch 4: 14/159 Loss: 0.305989
2022-12-28 13:43: Train Epoch 4: 15/159 Loss: 0.308227
2022-12-28 13:43: Train Epoch 4: 16/159 Loss: 0.325415
2022-12-28 13:43: Train Epoch 4: 17/159 Loss: 0.318345
2022-12-28 13:43: Train Epoch 4: 18/159 Loss: 0.330074
2022-12-28 13:43: Train Epoch 4: 19/159 Loss: 0.258834
2022-12-28 13:43: Train Epoch 4: 20/159 Loss: 0.369352
2022-12-28 13:43: Train Epoch 4: 21/159 Loss: 0.279648
2022-12-28 13:44: Train Epoch 4: 22/159 Loss: 0.312483
2022-12-28 13:44: Train Epoch 4: 23/159 Loss: 0.306479
2022-12-28 13:44: Train Epoch 4: 24/159 Loss: 0.305541
2022-12-28 13:44: Train Epoch 4: 25/159 Loss: 0.320413
2022-12-28 13:44: Train Epoch 4: 26/159 Loss: 0.333594
2022-12-28 13:44: Train Epoch 4: 27/159 Loss: 0.310101
2022-12-28 13:44: Train Epoch 4: 28/159 Loss: 0.248533
2022-12-28 13:44: Train Epoch 4: 29/159 Loss: 0.368947
2022-12-28 13:44: Train Epoch 4: 30/159 Loss: 0.317772
2022-12-28 13:45: Train Epoch 4: 31/159 Loss: 0.273389
2022-12-28 13:45: Train Epoch 4: 32/159 Loss: 0.296075
2022-12-28 13:45: Train Epoch 4: 33/159 Loss: 0.338383
2022-12-28 13:45: Train Epoch 4: 34/159 Loss: 0.316133
2022-12-28 13:45: Train Epoch 4: 35/159 Loss: 0.338221
2022-12-28 13:45: Train Epoch 4: 36/159 Loss: 0.301032
2022-12-28 13:45: Train Epoch 4: 37/159 Loss: 0.321128
2022-12-28 13:45: Train Epoch 4: 38/159 Loss: 0.294843
2022-12-28 13:45: Train Epoch 4: 39/159 Loss: 0.270424
2022-12-28 13:46: Train Epoch 4: 40/159 Loss: 0.316206
2022-12-28 13:46: Train Epoch 4: 41/159 Loss: 0.326912
2022-12-28 13:46: Train Epoch 4: 42/159 Loss: 0.282986
2022-12-28 13:46: Train Epoch 4: 43/159 Loss: 0.314497
2022-12-28 13:46: Train Epoch 4: 44/159 Loss: 0.372310
2022-12-28 13:46: Train Epoch 4: 45/159 Loss: 0.333615
2022-12-28 13:46: Train Epoch 4: 46/159 Loss: 0.281262
2022-12-28 13:46: Train Epoch 4: 47/159 Loss: 0.259733
2022-12-28 13:46: Train Epoch 4: 48/159 Loss: 0.292746
2022-12-28 13:47: Train Epoch 4: 49/159 Loss: 0.307238
2022-12-28 13:47: Train Epoch 4: 50/159 Loss: 0.291825
2022-12-28 13:47: Train Epoch 4: 51/159 Loss: 0.306756
2022-12-28 13:47: Train Epoch 4: 52/159 Loss: 0.338178
2022-12-28 13:47: Train Epoch 4: 53/159 Loss: 0.292892
2022-12-28 13:47: Train Epoch 4: 54/159 Loss: 0.331424
2022-12-28 13:47: Train Epoch 4: 55/159 Loss: 0.308521
2022-12-28 13:47: Train Epoch 4: 56/159 Loss: 0.300314
2022-12-28 13:47: Train Epoch 4: 57/159 Loss: 0.265654
2022-12-28 13:48: Train Epoch 4: 58/159 Loss: 0.328152
2022-12-28 13:48: Train Epoch 4: 59/159 Loss: 0.317056
2022-12-28 13:48: Train Epoch 4: 60/159 Loss: 0.333867
2022-12-28 13:48: Train Epoch 4: 61/159 Loss: 0.317412
2022-12-28 13:48: Train Epoch 4: 62/159 Loss: 0.276104
2022-12-28 13:48: Train Epoch 4: 63/159 Loss: 0.311446
2022-12-28 13:48: Train Epoch 4: 64/159 Loss: 0.318776
2022-12-28 13:48: Train Epoch 4: 65/159 Loss: 0.256077
2022-12-28 13:48: Train Epoch 4: 66/159 Loss: 0.242885
2022-12-28 13:49: Train Epoch 4: 67/159 Loss: 0.319558
2022-12-28 13:49: Train Epoch 4: 68/159 Loss: 0.323586
2022-12-28 13:49: Train Epoch 4: 69/159 Loss: 0.270597
2022-12-28 13:49: Train Epoch 4: 70/159 Loss: 0.354576
2022-12-28 13:49: Train Epoch 4: 71/159 Loss: 0.306424
2022-12-28 13:49: Train Epoch 4: 72/159 Loss: 0.297108
2022-12-28 13:49: Train Epoch 4: 73/159 Loss: 0.295004
2022-12-28 13:49: Train Epoch 4: 74/159 Loss: 0.302568
2022-12-28 13:49: Train Epoch 4: 75/159 Loss: 0.314879
2022-12-28 13:50: Train Epoch 4: 76/159 Loss: 0.266201
2022-12-28 13:50: Train Epoch 4: 77/159 Loss: 0.254707
2022-12-28 13:50: Train Epoch 4: 78/159 Loss: 0.339001
2022-12-28 13:50: Train Epoch 4: 79/159 Loss: 0.290264
2022-12-28 13:50: Train Epoch 4: 80/159 Loss: 0.285867
2022-12-28 13:50: Train Epoch 4: 81/159 Loss: 0.331903
2022-12-28 13:50: Train Epoch 4: 82/159 Loss: 0.299516
2022-12-28 13:50: Train Epoch 4: 83/159 Loss: 0.254708
2022-12-28 13:51: Train Epoch 4: 84/159 Loss: 0.313314
2022-12-28 13:51: Train Epoch 4: 85/159 Loss: 0.264461
2022-12-28 13:51: Train Epoch 4: 86/159 Loss: 0.281893
2022-12-28 13:51: Train Epoch 4: 87/159 Loss: 0.234983
2022-12-28 13:51: Train Epoch 4: 88/159 Loss: 0.324001
2022-12-28 13:51: Train Epoch 4: 89/159 Loss: 0.369320
2022-12-28 13:51: Train Epoch 4: 90/159 Loss: 0.341267
2022-12-28 13:51: Train Epoch 4: 91/159 Loss: 0.299474
2022-12-28 13:51: Train Epoch 4: 92/159 Loss: 0.294701
2022-12-28 13:52: Train Epoch 4: 93/159 Loss: 0.247171
2022-12-28 13:52: Train Epoch 4: 94/159 Loss: 0.365339
2022-12-28 13:52: Train Epoch 4: 95/159 Loss: 0.295336
2022-12-28 13:52: Train Epoch 4: 96/159 Loss: 0.302031
2022-12-28 13:52: Train Epoch 4: 97/159 Loss: 0.259936
2022-12-28 13:52: Train Epoch 4: 98/159 Loss: 0.248803
2022-12-28 13:52: Train Epoch 4: 99/159 Loss: 0.375605
2022-12-28 13:52: Train Epoch 4: 100/159 Loss: 0.294153
2022-12-28 13:52: Train Epoch 4: 101/159 Loss: 0.336897
2022-12-28 13:53: Train Epoch 4: 102/159 Loss: 0.293438
2022-12-28 13:53: Train Epoch 4: 103/159 Loss: 0.341788
2022-12-28 13:53: Train Epoch 4: 104/159 Loss: 0.314999
2022-12-28 13:53: Train Epoch 4: 105/159 Loss: 0.364973
2022-12-28 13:53: Train Epoch 4: 106/159 Loss: 0.328109
2022-12-28 13:53: Train Epoch 4: 107/159 Loss: 0.343332
2022-12-28 13:53: Train Epoch 4: 108/159 Loss: 0.284465
2022-12-28 13:53: Train Epoch 4: 109/159 Loss: 0.257206
2022-12-28 13:53: Train Epoch 4: 110/159 Loss: 0.329116
2022-12-28 13:54: Train Epoch 4: 111/159 Loss: 0.305733
2022-12-28 13:54: Train Epoch 4: 112/159 Loss: 0.246715
2022-12-28 13:54: Train Epoch 4: 113/159 Loss: 0.256389
2022-12-28 13:54: Train Epoch 4: 114/159 Loss: 0.351622
2022-12-28 13:54: Train Epoch 4: 115/159 Loss: 0.305536
2022-12-28 13:54: Train Epoch 4: 116/159 Loss: 0.272391
2022-12-28 13:54: Train Epoch 4: 117/159 Loss: 0.255320
2022-12-28 13:54: Train Epoch 4: 118/159 Loss: 0.335649
2022-12-28 13:54: Train Epoch 4: 119/159 Loss: 0.306046
2022-12-28 13:55: Train Epoch 4: 120/159 Loss: 0.288822
2022-12-28 13:55: Train Epoch 4: 121/159 Loss: 0.288869
2022-12-28 13:55: Train Epoch 4: 122/159 Loss: 0.349208
2022-12-28 13:55: Train Epoch 4: 123/159 Loss: 0.301136
2022-12-28 13:55: Train Epoch 4: 124/159 Loss: 0.362302
2022-12-28 13:55: Train Epoch 4: 125/159 Loss: 0.284191
2022-12-28 13:55: Train Epoch 4: 126/159 Loss: 0.266529
2022-12-28 13:55: Train Epoch 4: 127/159 Loss: 0.284008
2022-12-28 13:55: Train Epoch 4: 128/159 Loss: 0.316451
2022-12-28 13:56: Train Epoch 4: 129/159 Loss: 0.228842
2022-12-28 13:56: Train Epoch 4: 130/159 Loss: 0.312079
2022-12-28 13:56: Train Epoch 4: 131/159 Loss: 0.261437
2022-12-28 13:56: Train Epoch 4: 132/159 Loss: 0.350374
2022-12-28 13:56: Train Epoch 4: 133/159 Loss: 0.239824
2022-12-28 13:56: Train Epoch 4: 134/159 Loss: 0.307188
2022-12-28 13:56: Train Epoch 4: 135/159 Loss: 0.347719
2022-12-28 13:56: Train Epoch 4: 136/159 Loss: 0.322822
2022-12-28 13:56: Train Epoch 4: 137/159 Loss: 0.265124
2022-12-28 13:57: Train Epoch 4: 138/159 Loss: 0.324701
2022-12-28 13:57: Train Epoch 4: 139/159 Loss: 0.249984
2022-12-28 13:57: Train Epoch 4: 140/159 Loss: 0.301092
2022-12-28 13:57: Train Epoch 4: 141/159 Loss: 0.353256
2022-12-28 13:57: Train Epoch 4: 142/159 Loss: 0.309804
2022-12-28 13:57: Train Epoch 4: 143/159 Loss: 0.332633
2022-12-28 13:57: Train Epoch 4: 144/159 Loss: 0.324640
2022-12-28 13:57: Train Epoch 4: 145/159 Loss: 0.264301
2022-12-28 13:57: Train Epoch 4: 146/159 Loss: 0.286162
2022-12-28 13:58: Train Epoch 4: 147/159 Loss: 0.300947
2022-12-28 13:58: Train Epoch 4: 148/159 Loss: 0.253728
2022-12-28 13:58: Train Epoch 4: 149/159 Loss: 0.293527
2022-12-28 13:58: Train Epoch 4: 150/159 Loss: 0.341429
2022-12-28 13:58: Train Epoch 4: 151/159 Loss: 0.336304
2022-12-28 13:58: Train Epoch 4: 152/159 Loss: 0.269563
2022-12-28 13:58: Train Epoch 4: 153/159 Loss: 0.324879
2022-12-28 13:58: Train Epoch 4: 154/159 Loss: 0.322501
2022-12-28 13:58: Train Epoch 4: 155/159 Loss: 0.302985
2022-12-28 13:59: Train Epoch 4: 156/159 Loss: 0.264491
2022-12-28 13:59: Train Epoch 4: 157/159 Loss: 0.294693
2022-12-28 13:59: Train Epoch 4: 158/159 Loss: 0.342335
2022-12-28 13:59: **********Train Epoch 4: averaged Loss: 0.303896 
2022-12-28 13:59: 
Epoch time elapsed: 1067.4189834594727

2022-12-28 13:59: 
 metrics validation: {'precision': 0.7479338842975206, 'recall': 0.556923076923077, 'f1-score': 0.6384479717813051, 'support': 1300, 'AUC': 0.8227168639053254, 'AUCPR': 0.7327620616346335, 'TP': 724, 'FP': 244, 'TN': 2356, 'FN': 576} 

2022-12-28 13:59: **********Val Epoch 4: average Loss: 0.546168
2022-12-28 13:59: 
 Testing metrics {'precision': 0.8110047846889952, 'recall': 0.5521172638436482, 'f1-score': 0.6569767441860466, 'support': 1228, 'AUC': 0.8634826364205456, 'AUCPR': 0.7875476899146158, 'TP': 678, 'FP': 158, 'TN': 2298, 'FN': 550} 

2022-12-28 13:59: Train Epoch 5: 0/159 Loss: 0.260879
2022-12-28 14:00: Train Epoch 5: 1/159 Loss: 0.296271
2022-12-28 14:00: Train Epoch 5: 2/159 Loss: 0.316810
2022-12-28 14:00: Train Epoch 5: 3/159 Loss: 0.305625
2022-12-28 14:00: Train Epoch 5: 4/159 Loss: 0.274888
2022-12-28 14:00: Train Epoch 5: 5/159 Loss: 0.315193
2022-12-28 14:00: Train Epoch 5: 6/159 Loss: 0.281110
2022-12-28 14:00: Train Epoch 5: 7/159 Loss: 0.290454
2022-12-28 14:00: Train Epoch 5: 8/159 Loss: 0.272507
2022-12-28 14:00: Train Epoch 5: 9/159 Loss: 0.324373
2022-12-28 14:01: Train Epoch 5: 10/159 Loss: 0.293287
2022-12-28 14:01: Train Epoch 5: 11/159 Loss: 0.319000
2022-12-28 14:01: Train Epoch 5: 12/159 Loss: 0.292378
2022-12-28 14:01: Train Epoch 5: 13/159 Loss: 0.348673
2022-12-28 14:01: Train Epoch 5: 14/159 Loss: 0.305143
2022-12-28 14:01: Train Epoch 5: 15/159 Loss: 0.406612
2022-12-28 14:01: Train Epoch 5: 16/159 Loss: 0.330916
2022-12-28 14:01: Train Epoch 5: 17/159 Loss: 0.301848
2022-12-28 14:01: Train Epoch 5: 18/159 Loss: 0.279949
2022-12-28 14:02: Train Epoch 5: 19/159 Loss: 0.316903
2022-12-28 14:02: Train Epoch 5: 20/159 Loss: 0.225148
2022-12-28 14:02: Train Epoch 5: 21/159 Loss: 0.286925
2022-12-28 14:02: Train Epoch 5: 22/159 Loss: 0.289034
2022-12-28 14:02: Train Epoch 5: 23/159 Loss: 0.320721
2022-12-28 14:02: Train Epoch 5: 24/159 Loss: 0.304774
2022-12-28 14:02: Train Epoch 5: 25/159 Loss: 0.308622
2022-12-28 14:02: Train Epoch 5: 26/159 Loss: 0.327779
2022-12-28 14:02: Train Epoch 5: 27/159 Loss: 0.324223
2022-12-28 14:03: Train Epoch 5: 28/159 Loss: 0.277701
2022-12-28 14:03: Train Epoch 5: 29/159 Loss: 0.348811
2022-12-28 14:03: Train Epoch 5: 30/159 Loss: 0.295819
2022-12-28 14:03: Train Epoch 5: 31/159 Loss: 0.272030
2022-12-28 14:03: Train Epoch 5: 32/159 Loss: 0.320331
2022-12-28 14:03: Train Epoch 5: 33/159 Loss: 0.293751
2022-12-28 14:03: Train Epoch 5: 34/159 Loss: 0.275216
2022-12-28 14:03: Train Epoch 5: 35/159 Loss: 0.344451
2022-12-28 14:03: Train Epoch 5: 36/159 Loss: 0.308966
2022-12-28 14:04: Train Epoch 5: 37/159 Loss: 0.299339
2022-12-28 14:04: Train Epoch 5: 38/159 Loss: 0.277534
2022-12-28 14:04: Train Epoch 5: 39/159 Loss: 0.305724
2022-12-28 14:04: Train Epoch 5: 40/159 Loss: 0.247363
2022-12-28 14:04: Train Epoch 5: 41/159 Loss: 0.274491
2022-12-28 14:04: Train Epoch 5: 42/159 Loss: 0.259070
2022-12-28 14:04: Train Epoch 5: 43/159 Loss: 0.340196
2022-12-28 14:04: Train Epoch 5: 44/159 Loss: 0.300602
2022-12-28 14:04: Train Epoch 5: 45/159 Loss: 0.235468
2022-12-28 14:05: Train Epoch 5: 46/159 Loss: 0.277228
2022-12-28 14:05: Train Epoch 5: 47/159 Loss: 0.347483
2022-12-28 14:05: Train Epoch 5: 48/159 Loss: 0.293155
2022-12-28 14:05: Train Epoch 5: 49/159 Loss: 0.299442
2022-12-28 14:05: Train Epoch 5: 50/159 Loss: 0.284276
2022-12-28 14:05: Train Epoch 5: 51/159 Loss: 0.362695
2022-12-28 14:05: Train Epoch 5: 52/159 Loss: 0.304669
2022-12-28 14:05: Train Epoch 5: 53/159 Loss: 0.230552
2022-12-28 14:05: Train Epoch 5: 54/159 Loss: 0.253569
2022-12-28 14:06: Train Epoch 5: 55/159 Loss: 0.287442
2022-12-28 14:06: Train Epoch 5: 56/159 Loss: 0.282233
2022-12-28 14:06: Train Epoch 5: 57/159 Loss: 0.294117
2022-12-28 14:06: Train Epoch 5: 58/159 Loss: 0.355767
2022-12-28 14:06: Train Epoch 5: 59/159 Loss: 0.310246
2022-12-28 14:06: Train Epoch 5: 60/159 Loss: 0.309197
2022-12-28 14:06: Train Epoch 5: 61/159 Loss: 0.277672
2022-12-28 14:06: Train Epoch 5: 62/159 Loss: 0.265489
2022-12-28 14:06: Train Epoch 5: 63/159 Loss: 0.316486
2022-12-28 14:07: Train Epoch 5: 64/159 Loss: 0.308474
2022-12-28 14:07: Train Epoch 5: 65/159 Loss: 0.297262
2022-12-28 14:07: Train Epoch 5: 66/159 Loss: 0.287690
2022-12-28 14:07: Train Epoch 5: 67/159 Loss: 0.353329
2022-12-28 14:07: Train Epoch 5: 68/159 Loss: 0.333797
2022-12-28 14:07: Train Epoch 5: 69/159 Loss: 0.242650
2022-12-28 14:07: Train Epoch 5: 70/159 Loss: 0.306100
2022-12-28 14:07: Train Epoch 5: 71/159 Loss: 0.345481
2022-12-28 14:07: Train Epoch 5: 72/159 Loss: 0.308349
2022-12-28 14:08: Train Epoch 5: 73/159 Loss: 0.272042
2022-12-28 14:08: Train Epoch 5: 74/159 Loss: 0.252444
2022-12-28 14:08: Train Epoch 5: 75/159 Loss: 0.290111
2022-12-28 14:08: Train Epoch 5: 76/159 Loss: 0.346793
2022-12-28 14:08: Train Epoch 5: 77/159 Loss: 0.284176
2022-12-28 14:08: Train Epoch 5: 78/159 Loss: 0.326434
2022-12-28 14:08: Train Epoch 5: 79/159 Loss: 0.295729
2022-12-28 14:08: Train Epoch 5: 80/159 Loss: 0.281301
2022-12-28 14:08: Train Epoch 5: 81/159 Loss: 0.273522
2022-12-28 14:09: Train Epoch 5: 82/159 Loss: 0.312436
2022-12-28 14:09: Train Epoch 5: 83/159 Loss: 0.367970
2022-12-28 14:09: Train Epoch 5: 84/159 Loss: 0.272755
2022-12-28 14:09: Train Epoch 5: 85/159 Loss: 0.282568
2022-12-28 14:09: Train Epoch 5: 86/159 Loss: 0.295311
2022-12-28 14:09: Train Epoch 5: 87/159 Loss: 0.343614
2022-12-28 14:09: Train Epoch 5: 88/159 Loss: 0.281492
2022-12-28 14:09: Train Epoch 5: 89/159 Loss: 0.347807
2022-12-28 14:09: Train Epoch 5: 90/159 Loss: 0.316102
2022-12-28 14:10: Train Epoch 5: 91/159 Loss: 0.306351
2022-12-28 14:10: Train Epoch 5: 92/159 Loss: 0.245586
2022-12-28 14:10: Train Epoch 5: 93/159 Loss: 0.317907
2022-12-28 14:10: Train Epoch 5: 94/159 Loss: 0.302004
2022-12-28 14:10: Train Epoch 5: 95/159 Loss: 0.287631
2022-12-28 14:10: Train Epoch 5: 96/159 Loss: 0.280419
2022-12-28 14:10: Train Epoch 5: 97/159 Loss: 0.280467
2022-12-28 14:10: Train Epoch 5: 98/159 Loss: 0.337080
2022-12-28 14:10: Train Epoch 5: 99/159 Loss: 0.317959
2022-12-28 14:11: Train Epoch 5: 100/159 Loss: 0.340736
2022-12-28 14:11: Train Epoch 5: 101/159 Loss: 0.289704
2022-12-28 14:11: Train Epoch 5: 102/159 Loss: 0.244417
2022-12-28 14:11: Train Epoch 5: 103/159 Loss: 0.271382
2022-12-28 14:11: Train Epoch 5: 104/159 Loss: 0.296630
2022-12-28 14:11: Train Epoch 5: 105/159 Loss: 0.317135
2022-12-28 14:11: Train Epoch 5: 106/159 Loss: 0.264257
2022-12-28 14:11: Train Epoch 5: 107/159 Loss: 0.278218
2022-12-28 14:12: Train Epoch 5: 108/159 Loss: 0.292605
2022-12-28 14:12: Train Epoch 5: 109/159 Loss: 0.334903
2022-12-28 14:12: Train Epoch 5: 110/159 Loss: 0.336018
2022-12-28 14:12: Train Epoch 5: 111/159 Loss: 0.297970
2022-12-28 14:12: Train Epoch 5: 112/159 Loss: 0.278192
2022-12-28 14:12: Train Epoch 5: 113/159 Loss: 0.257431
2022-12-28 14:12: Train Epoch 5: 114/159 Loss: 0.309631
2022-12-28 14:12: Train Epoch 5: 115/159 Loss: 0.251510
2022-12-28 14:12: Train Epoch 5: 116/159 Loss: 0.332060
2022-12-28 14:13: Train Epoch 5: 117/159 Loss: 0.310537
2022-12-28 14:13: Train Epoch 5: 118/159 Loss: 0.300829
2022-12-28 14:13: Train Epoch 5: 119/159 Loss: 0.327675
2022-12-28 14:13: Train Epoch 5: 120/159 Loss: 0.295013
2022-12-28 14:13: Train Epoch 5: 121/159 Loss: 0.318965
2022-12-28 14:13: Train Epoch 5: 122/159 Loss: 0.315792
2022-12-28 14:13: Train Epoch 5: 123/159 Loss: 0.331472
2022-12-28 14:13: Train Epoch 5: 124/159 Loss: 0.301506
2022-12-28 14:13: Train Epoch 5: 125/159 Loss: 0.306194
2022-12-28 14:14: Train Epoch 5: 126/159 Loss: 0.287647
2022-12-28 14:14: Train Epoch 5: 127/159 Loss: 0.283932
2022-12-28 14:14: Train Epoch 5: 128/159 Loss: 0.291248
2022-12-28 14:14: Train Epoch 5: 129/159 Loss: 0.342492
2022-12-28 14:14: Train Epoch 5: 130/159 Loss: 0.345983
2022-12-28 14:14: Train Epoch 5: 131/159 Loss: 0.244215
2022-12-28 14:14: Train Epoch 5: 132/159 Loss: 0.342718
2022-12-28 14:14: Train Epoch 5: 133/159 Loss: 0.294634
2022-12-28 14:14: Train Epoch 5: 134/159 Loss: 0.336972
2022-12-28 14:15: Train Epoch 5: 135/159 Loss: 0.361789
2022-12-28 14:15: Train Epoch 5: 136/159 Loss: 0.314304
2022-12-28 14:15: Train Epoch 5: 137/159 Loss: 0.215286
2022-12-28 14:15: Train Epoch 5: 138/159 Loss: 0.277242
2022-12-28 14:15: Train Epoch 5: 139/159 Loss: 0.319264
2022-12-28 14:15: Train Epoch 5: 140/159 Loss: 0.273334
2022-12-28 14:15: Train Epoch 5: 141/159 Loss: 0.210724
2022-12-28 14:15: Train Epoch 5: 142/159 Loss: 0.278087
2022-12-28 14:15: Train Epoch 5: 143/159 Loss: 0.309123
2022-12-28 14:16: Train Epoch 5: 144/159 Loss: 0.336035
2022-12-28 14:16: Train Epoch 5: 145/159 Loss: 0.278944
2022-12-28 14:16: Train Epoch 5: 146/159 Loss: 0.341766
2022-12-28 14:16: Train Epoch 5: 147/159 Loss: 0.273173
2022-12-28 14:16: Train Epoch 5: 148/159 Loss: 0.321733
2022-12-28 14:16: Train Epoch 5: 149/159 Loss: 0.307587
2022-12-28 14:16: Train Epoch 5: 150/159 Loss: 0.298034
2022-12-28 14:16: Train Epoch 5: 151/159 Loss: 0.262739
2022-12-28 14:17: Train Epoch 5: 152/159 Loss: 0.295431
2022-12-28 14:17: Train Epoch 5: 153/159 Loss: 0.324128
2022-12-28 14:17: Train Epoch 5: 154/159 Loss: 0.289183
2022-12-28 14:17: Train Epoch 5: 155/159 Loss: 0.323643
2022-12-28 14:17: Train Epoch 5: 156/159 Loss: 0.275284
2022-12-28 14:17: Train Epoch 5: 157/159 Loss: 0.271205
2022-12-28 14:17: Train Epoch 5: 158/159 Loss: 0.236778
2022-12-28 14:17: **********Train Epoch 5: averaged Loss: 0.299467 
2022-12-28 14:17: 
Epoch time elapsed: 1063.4734997749329

2022-12-28 14:17: 
 metrics validation: {'precision': 0.7655016910935738, 'recall': 0.5223076923076924, 'f1-score': 0.6209419295839049, 'support': 1300, 'AUC': 0.8273757396449704, 'AUCPR': 0.738254429474034, 'TP': 679, 'FP': 208, 'TN': 2392, 'FN': 621} 

2022-12-28 14:17: **********Val Epoch 5: average Loss: 0.552861
2022-12-28 14:18: 
 Testing metrics {'precision': 0.8241758241758241, 'recall': 0.48859934853420195, 'f1-score': 0.6134969325153374, 'support': 1228, 'AUC': 0.8631855510403293, 'AUCPR': 0.785703858751328, 'TP': 600, 'FP': 128, 'TN': 2328, 'FN': 628} 

2022-12-28 14:18: Train Epoch 6: 0/159 Loss: 0.258685
2022-12-28 14:18: Train Epoch 6: 1/159 Loss: 0.340492
2022-12-28 14:18: Train Epoch 6: 2/159 Loss: 0.267572
2022-12-28 14:18: Train Epoch 6: 3/159 Loss: 0.273056
2022-12-28 14:18: Train Epoch 6: 4/159 Loss: 0.374502
2022-12-28 14:18: Train Epoch 6: 5/159 Loss: 0.259172
2022-12-28 14:19: Train Epoch 6: 6/159 Loss: 0.331216
2022-12-28 14:19: Train Epoch 6: 7/159 Loss: 0.298302
2022-12-28 14:19: Train Epoch 6: 8/159 Loss: 0.286818
2022-12-28 14:19: Train Epoch 6: 9/159 Loss: 0.313669
2022-12-28 14:19: Train Epoch 6: 10/159 Loss: 0.270620
2022-12-28 14:19: Train Epoch 6: 11/159 Loss: 0.295110
2022-12-28 14:19: Train Epoch 6: 12/159 Loss: 0.327496
2022-12-28 14:19: Train Epoch 6: 13/159 Loss: 0.273985
2022-12-28 14:19: Train Epoch 6: 14/159 Loss: 0.291417
2022-12-28 14:20: Train Epoch 6: 15/159 Loss: 0.306374
2022-12-28 14:20: Train Epoch 6: 16/159 Loss: 0.305110
2022-12-28 14:20: Train Epoch 6: 17/159 Loss: 0.254834
2022-12-28 14:20: Train Epoch 6: 18/159 Loss: 0.312280
2022-12-28 14:20: Train Epoch 6: 19/159 Loss: 0.287292
2022-12-28 14:20: Train Epoch 6: 20/159 Loss: 0.253754
2022-12-28 14:20: Train Epoch 6: 21/159 Loss: 0.318867
2022-12-28 14:20: Train Epoch 6: 22/159 Loss: 0.318100
2022-12-28 14:20: Train Epoch 6: 23/159 Loss: 0.328836
2022-12-28 14:21: Train Epoch 6: 24/159 Loss: 0.329004
2022-12-28 14:21: Train Epoch 6: 25/159 Loss: 0.272568
2022-12-28 14:21: Train Epoch 6: 26/159 Loss: 0.272722
2022-12-28 14:21: Train Epoch 6: 27/159 Loss: 0.354688
2022-12-28 14:21: Train Epoch 6: 28/159 Loss: 0.300551
2022-12-28 14:21: Train Epoch 6: 29/159 Loss: 0.328770
2022-12-28 14:21: Train Epoch 6: 30/159 Loss: 0.324120
2022-12-28 14:21: Train Epoch 6: 31/159 Loss: 0.289481
2022-12-28 14:21: Train Epoch 6: 32/159 Loss: 0.276913
2022-12-28 14:22: Train Epoch 6: 33/159 Loss: 0.303202
2022-12-28 14:22: Train Epoch 6: 34/159 Loss: 0.309223
2022-12-28 14:22: Train Epoch 6: 35/159 Loss: 0.255351
2022-12-28 14:22: Train Epoch 6: 36/159 Loss: 0.347634
2022-12-28 14:22: Train Epoch 6: 37/159 Loss: 0.346790
2022-12-28 14:22: Train Epoch 6: 38/159 Loss: 0.342971
2022-12-28 14:22: Train Epoch 6: 39/159 Loss: 0.230762
2022-12-28 14:22: Train Epoch 6: 40/159 Loss: 0.308007
2022-12-28 14:23: Train Epoch 6: 41/159 Loss: 0.312238
2022-12-28 14:23: Train Epoch 6: 42/159 Loss: 0.296609
2022-12-28 14:23: Train Epoch 6: 43/159 Loss: 0.398271
2022-12-28 14:23: Train Epoch 6: 44/159 Loss: 0.250016
2022-12-28 14:23: Train Epoch 6: 45/159 Loss: 0.385349
2022-12-28 14:23: Train Epoch 6: 46/159 Loss: 0.280695
2022-12-28 14:23: Train Epoch 6: 47/159 Loss: 0.283886
2022-12-28 14:23: Train Epoch 6: 48/159 Loss: 0.302140
2022-12-28 14:23: Train Epoch 6: 49/159 Loss: 0.283316
2022-12-28 14:23: Train Epoch 6: 50/159 Loss: 0.270878
2022-12-28 14:24: Train Epoch 6: 51/159 Loss: 0.254604
2022-12-28 14:24: Train Epoch 6: 52/159 Loss: 0.277905
2022-12-28 14:24: Train Epoch 6: 53/159 Loss: 0.306743
2022-12-28 14:24: Train Epoch 6: 54/159 Loss: 0.296882
2022-12-28 14:24: Train Epoch 6: 55/159 Loss: 0.365139
2022-12-28 14:24: Train Epoch 6: 56/159 Loss: 0.312934
2022-12-28 14:24: Train Epoch 6: 57/159 Loss: 0.307059
2022-12-28 14:24: Train Epoch 6: 58/159 Loss: 0.290944
2022-12-28 14:24: Train Epoch 6: 59/159 Loss: 0.299264
2022-12-28 14:25: Train Epoch 6: 60/159 Loss: 0.315898
2022-12-28 14:25: Train Epoch 6: 61/159 Loss: 0.312737
2022-12-28 14:25: Train Epoch 6: 62/159 Loss: 0.250906
2022-12-28 14:25: Train Epoch 6: 63/159 Loss: 0.296075
2022-12-28 14:25: Train Epoch 6: 64/159 Loss: 0.312874
2022-12-28 14:25: Train Epoch 6: 65/159 Loss: 0.259871
2022-12-28 14:25: Train Epoch 6: 66/159 Loss: 0.198084
2022-12-28 14:25: Train Epoch 6: 67/159 Loss: 0.282620
2022-12-28 14:25: Train Epoch 6: 68/159 Loss: 0.316269
2022-12-28 14:26: Train Epoch 6: 69/159 Loss: 0.319845
2022-12-28 14:26: Train Epoch 6: 70/159 Loss: 0.301655
2022-12-28 14:26: Train Epoch 6: 71/159 Loss: 0.332680
2022-12-28 14:26: Train Epoch 6: 72/159 Loss: 0.271542
2022-12-28 14:26: Train Epoch 6: 73/159 Loss: 0.285458
2022-12-28 14:26: Train Epoch 6: 74/159 Loss: 0.269193
2022-12-28 14:26: Train Epoch 6: 75/159 Loss: 0.298570
2022-12-28 14:26: Train Epoch 6: 76/159 Loss: 0.239229
2022-12-28 14:26: Train Epoch 6: 77/159 Loss: 0.332286
2022-12-28 14:26: Train Epoch 6: 78/159 Loss: 0.298099
2022-12-28 14:27: Train Epoch 6: 79/159 Loss: 0.305413
2022-12-28 14:27: Train Epoch 6: 80/159 Loss: 0.318862
2022-12-28 14:27: Train Epoch 6: 81/159 Loss: 0.323251
2022-12-28 14:27: Train Epoch 6: 82/159 Loss: 0.330275
2022-12-28 14:27: Train Epoch 6: 83/159 Loss: 0.244692
2022-12-28 14:27: Train Epoch 6: 84/159 Loss: 0.319514
2022-12-28 14:27: Train Epoch 6: 85/159 Loss: 0.277137
2022-12-28 14:27: Train Epoch 6: 86/159 Loss: 0.297916
2022-12-28 14:28: Train Epoch 6: 87/159 Loss: 0.335119
2022-12-28 14:28: Train Epoch 6: 88/159 Loss: 0.302381
2022-12-28 14:28: Train Epoch 6: 89/159 Loss: 0.315404
2022-12-28 14:28: Train Epoch 6: 90/159 Loss: 0.325679
2022-12-28 14:28: Train Epoch 6: 91/159 Loss: 0.292060
2022-12-28 14:28: Train Epoch 6: 92/159 Loss: 0.306957
2022-12-28 14:28: Train Epoch 6: 93/159 Loss: 0.286996
2022-12-28 14:28: Train Epoch 6: 94/159 Loss: 0.307171
2022-12-28 14:28: Train Epoch 6: 95/159 Loss: 0.294331
2022-12-28 14:29: Train Epoch 6: 96/159 Loss: 0.294577
2022-12-28 14:29: Train Epoch 6: 97/159 Loss: 0.300991
2022-12-28 14:29: Train Epoch 6: 98/159 Loss: 0.311355
2022-12-28 14:29: Train Epoch 6: 99/159 Loss: 0.296449
2022-12-28 14:29: Train Epoch 6: 100/159 Loss: 0.267577
2022-12-28 14:29: Train Epoch 6: 101/159 Loss: 0.281839
2022-12-28 14:29: Train Epoch 6: 102/159 Loss: 0.317847
2022-12-28 14:29: Train Epoch 6: 103/159 Loss: 0.304527
2022-12-28 14:29: Train Epoch 6: 104/159 Loss: 0.298031
2022-12-28 14:30: Train Epoch 6: 105/159 Loss: 0.319472
2022-12-28 14:30: Train Epoch 6: 106/159 Loss: 0.262707
2022-12-28 14:30: Train Epoch 6: 107/159 Loss: 0.278093
2022-12-28 14:30: Train Epoch 6: 108/159 Loss: 0.334222
2022-12-28 14:30: Train Epoch 6: 109/159 Loss: 0.309828
2022-12-28 14:30: Train Epoch 6: 110/159 Loss: 0.271979
2022-12-28 14:30: Train Epoch 6: 111/159 Loss: 0.304288
2022-12-28 14:30: Train Epoch 6: 112/159 Loss: 0.266071
2022-12-28 14:30: Train Epoch 6: 113/159 Loss: 0.261734
2022-12-28 14:31: Train Epoch 6: 114/159 Loss: 0.310414
2022-12-28 14:31: Train Epoch 6: 115/159 Loss: 0.300502
2022-12-28 14:31: Train Epoch 6: 116/159 Loss: 0.227770
2022-12-28 14:31: Train Epoch 6: 117/159 Loss: 0.307483
2022-12-28 14:31: Train Epoch 6: 118/159 Loss: 0.281153
2022-12-28 14:31: Train Epoch 6: 119/159 Loss: 0.261140
2022-12-28 14:31: Train Epoch 6: 120/159 Loss: 0.311466
2022-12-28 14:31: Train Epoch 6: 121/159 Loss: 0.314524
2022-12-28 14:31: Train Epoch 6: 122/159 Loss: 0.292849
2022-12-28 14:32: Train Epoch 6: 123/159 Loss: 0.335876
2022-12-28 14:32: Train Epoch 6: 124/159 Loss: 0.275479
2022-12-28 14:32: Train Epoch 6: 125/159 Loss: 0.346534
2022-12-28 14:32: Train Epoch 6: 126/159 Loss: 0.297440
2022-12-28 14:32: Train Epoch 6: 127/159 Loss: 0.273165
2022-12-28 14:32: Train Epoch 6: 128/159 Loss: 0.320422
2022-12-28 14:32: Train Epoch 6: 129/159 Loss: 0.286769
2022-12-28 14:32: Train Epoch 6: 130/159 Loss: 0.306559
2022-12-28 14:32: Train Epoch 6: 131/159 Loss: 0.283099
2022-12-28 14:32: Train Epoch 6: 132/159 Loss: 0.253511
2022-12-28 14:33: Train Epoch 6: 133/159 Loss: 0.276906
2022-12-28 14:33: Train Epoch 6: 134/159 Loss: 0.355901
2022-12-28 14:33: Train Epoch 6: 135/159 Loss: 0.271683
2022-12-28 14:33: Train Epoch 6: 136/159 Loss: 0.269823
2022-12-28 14:33: Train Epoch 6: 137/159 Loss: 0.291712
2022-12-28 14:33: Train Epoch 6: 138/159 Loss: 0.384283
2022-12-28 14:33: Train Epoch 6: 139/159 Loss: 0.317002
2022-12-28 14:33: Train Epoch 6: 140/159 Loss: 0.338410
2022-12-28 14:33: Train Epoch 6: 141/159 Loss: 0.274075
2022-12-28 14:34: Train Epoch 6: 142/159 Loss: 0.345793
2022-12-28 14:34: Train Epoch 6: 143/159 Loss: 0.279347
2022-12-28 14:34: Train Epoch 6: 144/159 Loss: 0.304093
2022-12-28 14:34: Train Epoch 6: 145/159 Loss: 0.281177
2022-12-28 14:34: Train Epoch 6: 146/159 Loss: 0.309822
2022-12-28 14:34: Train Epoch 6: 147/159 Loss: 0.297856
2022-12-28 14:34: Train Epoch 6: 148/159 Loss: 0.325652
2022-12-28 14:34: Train Epoch 6: 149/159 Loss: 0.300302
2022-12-28 14:34: Train Epoch 6: 150/159 Loss: 0.247828
2022-12-28 14:35: Train Epoch 6: 151/159 Loss: 0.305975
2022-12-28 14:35: Train Epoch 6: 152/159 Loss: 0.295116
2022-12-28 14:35: Train Epoch 6: 153/159 Loss: 0.275575
2022-12-28 14:35: Train Epoch 6: 154/159 Loss: 0.308779
2022-12-28 14:35: Train Epoch 6: 155/159 Loss: 0.320363
2022-12-28 14:35: Train Epoch 6: 156/159 Loss: 0.362317
2022-12-28 14:35: Train Epoch 6: 157/159 Loss: 0.268925
2022-12-28 14:35: Train Epoch 6: 158/159 Loss: 0.222794
2022-12-28 14:35: **********Train Epoch 6: averaged Loss: 0.298689 
2022-12-28 14:35: 
Epoch time elapsed: 1052.865805387497

2022-12-28 14:36: 
 metrics validation: {'precision': 0.7731182795698924, 'recall': 0.553076923076923, 'f1-score': 0.6448430493273541, 'support': 1300, 'AUC': 0.8277526627218934, 'AUCPR': 0.7401227994182377, 'TP': 719, 'FP': 211, 'TN': 2389, 'FN': 581} 

2022-12-28 14:36: **********Val Epoch 6: average Loss: 0.553042
2022-12-28 14:36: 
 Testing metrics {'precision': 0.8214765100671141, 'recall': 0.498371335504886, 'f1-score': 0.6203750633552965, 'support': 1228, 'AUC': 0.8643264782650214, 'AUCPR': 0.7889825678092344, 'TP': 612, 'FP': 133, 'TN': 2323, 'FN': 616} 

2022-12-28 14:36: Train Epoch 7: 0/159 Loss: 0.298460
2022-12-28 14:36: Train Epoch 7: 1/159 Loss: 0.319516
2022-12-28 14:36: Train Epoch 7: 2/159 Loss: 0.331449
2022-12-28 14:36: Train Epoch 7: 3/159 Loss: 0.277963
2022-12-28 14:37: Train Epoch 7: 4/159 Loss: 0.287075
2022-12-28 14:37: Train Epoch 7: 5/159 Loss: 0.284678
2022-12-28 14:37: Train Epoch 7: 6/159 Loss: 0.247662
2022-12-28 14:37: Train Epoch 7: 7/159 Loss: 0.294483
2022-12-28 14:37: Train Epoch 7: 8/159 Loss: 0.306944
2022-12-28 14:37: Train Epoch 7: 9/159 Loss: 0.235587
2022-12-28 14:37: Train Epoch 7: 10/159 Loss: 0.287876
2022-12-28 14:37: Train Epoch 7: 11/159 Loss: 0.299116
2022-12-28 14:37: Train Epoch 7: 12/159 Loss: 0.248358
2022-12-28 14:37: Train Epoch 7: 13/159 Loss: 0.278577
2022-12-28 14:38: Train Epoch 7: 14/159 Loss: 0.291356
2022-12-28 14:38: Train Epoch 7: 15/159 Loss: 0.288215
2022-12-28 14:38: Train Epoch 7: 16/159 Loss: 0.300428
2022-12-28 14:38: Train Epoch 7: 17/159 Loss: 0.329143
2022-12-28 14:38: Train Epoch 7: 18/159 Loss: 0.270794
2022-12-28 14:38: Train Epoch 7: 19/159 Loss: 0.296112
2022-12-28 14:38: Train Epoch 7: 20/159 Loss: 0.336099
2022-12-28 14:38: Train Epoch 7: 21/159 Loss: 0.251059
2022-12-28 14:39: Train Epoch 7: 22/159 Loss: 0.321363
2022-12-28 14:39: Train Epoch 7: 23/159 Loss: 0.336222
2022-12-28 14:39: Train Epoch 7: 24/159 Loss: 0.340275
2022-12-28 14:39: Train Epoch 7: 25/159 Loss: 0.274166
2022-12-28 14:39: Train Epoch 7: 26/159 Loss: 0.248078
2022-12-28 14:39: Train Epoch 7: 27/159 Loss: 0.335964
2022-12-28 14:39: Train Epoch 7: 28/159 Loss: 0.288081
2022-12-28 14:39: Train Epoch 7: 29/159 Loss: 0.355410
2022-12-28 14:39: Train Epoch 7: 30/159 Loss: 0.263590
2022-12-28 14:40: Train Epoch 7: 31/159 Loss: 0.290776
2022-12-28 14:40: Train Epoch 7: 32/159 Loss: 0.262124
2022-12-28 14:40: Train Epoch 7: 33/159 Loss: 0.321894
2022-12-28 14:40: Train Epoch 7: 34/159 Loss: 0.289770
2022-12-28 14:40: Train Epoch 7: 35/159 Loss: 0.343281
2022-12-28 14:40: Train Epoch 7: 36/159 Loss: 0.303305
2022-12-28 14:40: Train Epoch 7: 37/159 Loss: 0.303990
2022-12-28 14:40: Train Epoch 7: 38/159 Loss: 0.300652
2022-12-28 14:41: Train Epoch 7: 39/159 Loss: 0.358572
2022-12-28 14:41: Train Epoch 7: 40/159 Loss: 0.272523
2022-12-28 14:41: Train Epoch 7: 41/159 Loss: 0.298841
2022-12-28 14:41: Train Epoch 7: 42/159 Loss: 0.335683
2022-12-28 14:41: Train Epoch 7: 43/159 Loss: 0.248283
2022-12-28 14:41: Train Epoch 7: 44/159 Loss: 0.336007
2022-12-28 14:41: Train Epoch 7: 45/159 Loss: 0.315609
2022-12-28 14:41: Train Epoch 7: 46/159 Loss: 0.249691
2022-12-28 14:41: Train Epoch 7: 47/159 Loss: 0.229060
2022-12-28 14:42: Train Epoch 7: 48/159 Loss: 0.363292
2022-12-28 14:42: Train Epoch 7: 49/159 Loss: 0.305389
2022-12-28 14:42: Train Epoch 7: 50/159 Loss: 0.248461
2022-12-28 14:42: Train Epoch 7: 51/159 Loss: 0.287960
2022-12-28 14:42: Train Epoch 7: 52/159 Loss: 0.314408
2022-12-28 14:42: Train Epoch 7: 53/159 Loss: 0.320474
2022-12-28 14:42: Train Epoch 7: 54/159 Loss: 0.304080
2022-12-28 14:42: Train Epoch 7: 55/159 Loss: 0.299358
2022-12-28 14:42: Train Epoch 7: 56/159 Loss: 0.332069
2022-12-28 14:43: Train Epoch 7: 57/159 Loss: 0.281227
2022-12-28 14:43: Train Epoch 7: 58/159 Loss: 0.298852
2022-12-28 14:43: Train Epoch 7: 59/159 Loss: 0.280809
2022-12-28 14:43: Train Epoch 7: 60/159 Loss: 0.261466
2022-12-28 14:43: Train Epoch 7: 61/159 Loss: 0.353256
2022-12-28 14:43: Train Epoch 7: 62/159 Loss: 0.310853
2022-12-28 14:43: Train Epoch 7: 63/159 Loss: 0.284326
2022-12-28 14:43: Train Epoch 7: 64/159 Loss: 0.311718
2022-12-28 14:43: Train Epoch 7: 65/159 Loss: 0.251548
2022-12-28 14:43: Train Epoch 7: 66/159 Loss: 0.321381
2022-12-28 14:44: Train Epoch 7: 67/159 Loss: 0.283549
2022-12-28 14:44: Train Epoch 7: 68/159 Loss: 0.261309
2022-12-28 14:44: Train Epoch 7: 69/159 Loss: 0.322288
2022-12-28 14:44: Train Epoch 7: 70/159 Loss: 0.264322
2022-12-28 14:44: Train Epoch 7: 71/159 Loss: 0.359578
2022-12-28 14:44: Train Epoch 7: 72/159 Loss: 0.303434
2022-12-28 14:44: Train Epoch 7: 73/159 Loss: 0.276840
2022-12-28 14:44: Train Epoch 7: 74/159 Loss: 0.393974
2022-12-28 14:44: Train Epoch 7: 75/159 Loss: 0.358313
2022-12-28 14:45: Train Epoch 7: 76/159 Loss: 0.303747
2022-12-28 14:45: Train Epoch 7: 77/159 Loss: 0.316094
2022-12-28 14:45: Train Epoch 7: 78/159 Loss: 0.254028
2022-12-28 14:45: Train Epoch 7: 79/159 Loss: 0.271795
2022-12-28 14:45: Train Epoch 7: 80/159 Loss: 0.264088
2022-12-28 14:45: Train Epoch 7: 81/159 Loss: 0.291754
2022-12-28 14:45: Train Epoch 7: 82/159 Loss: 0.257095
2022-12-28 14:45: Train Epoch 7: 83/159 Loss: 0.291169
2022-12-28 14:45: Train Epoch 7: 84/159 Loss: 0.286321
2022-12-28 14:46: Train Epoch 7: 85/159 Loss: 0.299384
2022-12-28 14:46: Train Epoch 7: 86/159 Loss: 0.290149
2022-12-28 14:46: Train Epoch 7: 87/159 Loss: 0.286715
2022-12-28 14:46: Train Epoch 7: 88/159 Loss: 0.305901
2022-12-28 14:46: Train Epoch 7: 89/159 Loss: 0.317826
2022-12-28 14:46: Train Epoch 7: 90/159 Loss: 0.266990
2022-12-28 14:46: Train Epoch 7: 91/159 Loss: 0.308367
2022-12-28 14:46: Train Epoch 7: 92/159 Loss: 0.282759
2022-12-28 14:46: Train Epoch 7: 93/159 Loss: 0.267826
2022-12-28 14:47: Train Epoch 7: 94/159 Loss: 0.223499
2022-12-28 14:47: Train Epoch 7: 95/159 Loss: 0.308417
2022-12-28 14:47: Train Epoch 7: 96/159 Loss: 0.263581
2022-12-28 14:47: Train Epoch 7: 97/159 Loss: 0.244022
2022-12-28 14:47: Train Epoch 7: 98/159 Loss: 0.332307
2022-12-28 14:47: Train Epoch 7: 99/159 Loss: 0.283966
2022-12-28 14:47: Train Epoch 7: 100/159 Loss: 0.243426
2022-12-28 14:47: Train Epoch 7: 101/159 Loss: 0.376727
2022-12-28 14:47: Train Epoch 7: 102/159 Loss: 0.282857
2022-12-28 14:48: Train Epoch 7: 103/159 Loss: 0.311008
2022-12-28 14:48: Train Epoch 7: 104/159 Loss: 0.335794
2022-12-28 14:48: Train Epoch 7: 105/159 Loss: 0.387753
2022-12-28 14:48: Train Epoch 7: 106/159 Loss: 0.348037
2022-12-28 14:48: Train Epoch 7: 107/159 Loss: 0.246885
2022-12-28 14:48: Train Epoch 7: 108/159 Loss: 0.286647
2022-12-28 14:48: Train Epoch 7: 109/159 Loss: 0.294409
2022-12-28 14:48: Train Epoch 7: 110/159 Loss: 0.258978
2022-12-28 14:48: Train Epoch 7: 111/159 Loss: 0.277455
2022-12-28 14:48: Train Epoch 7: 112/159 Loss: 0.284954
2022-12-28 14:49: Train Epoch 7: 113/159 Loss: 0.341555
2022-12-28 14:49: Train Epoch 7: 114/159 Loss: 0.283724
2022-12-28 14:49: Train Epoch 7: 115/159 Loss: 0.247213
2022-12-28 14:49: Train Epoch 7: 116/159 Loss: 0.272083
2022-12-28 14:49: Train Epoch 7: 117/159 Loss: 0.228816
2022-12-28 14:49: Train Epoch 7: 118/159 Loss: 0.299494
2022-12-28 14:49: Train Epoch 7: 119/159 Loss: 0.289262
2022-12-28 14:49: Train Epoch 7: 120/159 Loss: 0.286771
2022-12-28 14:49: Train Epoch 7: 121/159 Loss: 0.222748
2022-12-28 14:50: Train Epoch 7: 122/159 Loss: 0.314011
2022-12-28 14:50: Train Epoch 7: 123/159 Loss: 0.271824
2022-12-28 14:50: Train Epoch 7: 124/159 Loss: 0.296195
2022-12-28 14:50: Train Epoch 7: 125/159 Loss: 0.254886
2022-12-28 14:50: Train Epoch 7: 126/159 Loss: 0.291623
2022-12-28 14:50: Train Epoch 7: 127/159 Loss: 0.324642
2022-12-28 14:50: Train Epoch 7: 128/159 Loss: 0.389174
2022-12-28 14:50: Train Epoch 7: 129/159 Loss: 0.342987
2022-12-28 14:50: Train Epoch 7: 130/159 Loss: 0.272127
2022-12-28 14:51: Train Epoch 7: 131/159 Loss: 0.273639
2022-12-28 14:51: Train Epoch 7: 132/159 Loss: 0.304341
2022-12-28 14:51: Train Epoch 7: 133/159 Loss: 0.299626
2022-12-28 14:51: Train Epoch 7: 134/159 Loss: 0.322571
2022-12-28 14:51: Train Epoch 7: 135/159 Loss: 0.286923
2022-12-28 14:51: Train Epoch 7: 136/159 Loss: 0.324510
2022-12-28 14:51: Train Epoch 7: 137/159 Loss: 0.267091
2022-12-28 14:51: Train Epoch 7: 138/159 Loss: 0.281609
2022-12-28 14:51: Train Epoch 7: 139/159 Loss: 0.253632
2022-12-28 14:52: Train Epoch 7: 140/159 Loss: 0.386699
2022-12-28 14:52: Train Epoch 7: 141/159 Loss: 0.294001
2022-12-28 14:52: Train Epoch 7: 142/159 Loss: 0.231542
2022-12-28 14:52: Train Epoch 7: 143/159 Loss: 0.348697
2022-12-28 14:52: Train Epoch 7: 144/159 Loss: 0.272973
2022-12-28 14:52: Train Epoch 7: 145/159 Loss: 0.290180
2022-12-28 14:52: Train Epoch 7: 146/159 Loss: 0.372444
2022-12-28 14:52: Train Epoch 7: 147/159 Loss: 0.331626
2022-12-28 14:53: Train Epoch 7: 148/159 Loss: 0.292154
2022-12-28 14:53: Train Epoch 7: 149/159 Loss: 0.267852
2022-12-28 14:53: Train Epoch 7: 150/159 Loss: 0.249742
2022-12-28 14:53: Train Epoch 7: 151/159 Loss: 0.300417
2022-12-28 14:53: Train Epoch 7: 152/159 Loss: 0.250261
2022-12-28 14:53: Train Epoch 7: 153/159 Loss: 0.338041
2022-12-28 14:53: Train Epoch 7: 154/159 Loss: 0.216224
2022-12-28 14:53: Train Epoch 7: 155/159 Loss: 0.233083
2022-12-28 14:53: Train Epoch 7: 156/159 Loss: 0.288458
2022-12-28 14:54: Train Epoch 7: 157/159 Loss: 0.247271
2022-12-28 14:54: Train Epoch 7: 158/159 Loss: 0.293176
2022-12-28 14:54: **********Train Epoch 7: averaged Loss: 0.294587 
2022-12-28 14:54: 
Epoch time elapsed: 1058.2448172569275

2022-12-28 14:54: 
 metrics validation: {'precision': 0.7793427230046949, 'recall': 0.5107692307692308, 'f1-score': 0.6171003717472119, 'support': 1300, 'AUC': 0.8300079881656804, 'AUCPR': 0.7438423453871834, 'TP': 664, 'FP': 188, 'TN': 2412, 'FN': 636} 

2022-12-28 14:54: **********Val Epoch 7: average Loss: 0.566734
2022-12-28 14:54: 
 Testing metrics {'precision': 0.8396624472573839, 'recall': 0.48615635179153094, 'f1-score': 0.6157813305827746, 'support': 1228, 'AUC': 0.8673944816390624, 'AUCPR': 0.7951179552138752, 'TP': 597, 'FP': 114, 'TN': 2342, 'FN': 631} 

2022-12-28 14:54: Train Epoch 8: 0/159 Loss: 0.398717
2022-12-28 14:54: Train Epoch 8: 1/159 Loss: 0.365624
2022-12-28 14:55: Train Epoch 8: 2/159 Loss: 0.336841
2022-12-28 14:55: Train Epoch 8: 3/159 Loss: 0.278761
2022-12-28 14:55: Train Epoch 8: 4/159 Loss: 0.236553
2022-12-28 14:55: Train Epoch 8: 5/159 Loss: 0.251819
2022-12-28 14:55: Train Epoch 8: 6/159 Loss: 0.306163
2022-12-28 14:55: Train Epoch 8: 7/159 Loss: 0.268690
2022-12-28 14:55: Train Epoch 8: 8/159 Loss: 0.289765
2022-12-28 14:55: Train Epoch 8: 9/159 Loss: 0.303285
2022-12-28 14:55: Train Epoch 8: 10/159 Loss: 0.250309
2022-12-28 14:56: Train Epoch 8: 11/159 Loss: 0.231234
2022-12-28 14:56: Train Epoch 8: 12/159 Loss: 0.259997
2022-12-28 14:56: Train Epoch 8: 13/159 Loss: 0.285182
2022-12-28 14:56: Train Epoch 8: 14/159 Loss: 0.255984
2022-12-28 14:56: Train Epoch 8: 15/159 Loss: 0.246085
2022-12-28 14:56: Train Epoch 8: 16/159 Loss: 0.286273
2022-12-28 14:56: Train Epoch 8: 17/159 Loss: 0.318391
2022-12-28 14:56: Train Epoch 8: 18/159 Loss: 0.321147
2022-12-28 14:56: Train Epoch 8: 19/159 Loss: 0.268726
2022-12-28 14:57: Train Epoch 8: 20/159 Loss: 0.341532
2022-12-28 14:57: Train Epoch 8: 21/159 Loss: 0.276033
2022-12-28 14:57: Train Epoch 8: 22/159 Loss: 0.279396
2022-12-28 14:57: Train Epoch 8: 23/159 Loss: 0.244370
2022-12-28 14:57: Train Epoch 8: 24/159 Loss: 0.264972
2022-12-28 14:57: Train Epoch 8: 25/159 Loss: 0.293992
2022-12-28 14:57: Train Epoch 8: 26/159 Loss: 0.259393
2022-12-28 14:57: Train Epoch 8: 27/159 Loss: 0.361784
2022-12-28 14:57: Train Epoch 8: 28/159 Loss: 0.287561
2022-12-28 14:58: Train Epoch 8: 29/159 Loss: 0.234899
2022-12-28 14:58: Train Epoch 8: 30/159 Loss: 0.218679
2022-12-28 14:58: Train Epoch 8: 31/159 Loss: 0.319537
2022-12-28 14:58: Train Epoch 8: 32/159 Loss: 0.332389
2022-12-28 14:58: Train Epoch 8: 33/159 Loss: 0.283193
2022-12-28 14:58: Train Epoch 8: 34/159 Loss: 0.242932
2022-12-28 14:58: Train Epoch 8: 35/159 Loss: 0.394307
2022-12-28 14:58: Train Epoch 8: 36/159 Loss: 0.272811
2022-12-28 14:58: Train Epoch 8: 37/159 Loss: 0.262287
2022-12-28 14:59: Train Epoch 8: 38/159 Loss: 0.328356
2022-12-28 14:59: Train Epoch 8: 39/159 Loss: 0.319896
2022-12-28 14:59: Train Epoch 8: 40/159 Loss: 0.271837
2022-12-28 14:59: Train Epoch 8: 41/159 Loss: 0.318287
Traceback (most recent call last):
  File "/home/joel.chacon/tmp/WildFire_GCN/Run_Model.py", line 201, in <module>
    trainer.train()
  File "/home/joel.chacon/tmp/WildFire_GCN/Trainer.py", line 117, in train
    train_epoch_loss = self.train_epoch(epoch)
  File "/home/joel.chacon/tmp/WildFire_GCN/Trainer.py", line 88, in train_epoch
    loss.backward()
  File "/home/joel.chacon/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/joel.chacon/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
