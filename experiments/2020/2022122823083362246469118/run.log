2022-12-28 23:08: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122823083362246469118
2022-12-28 23:08: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122823083362246469118
2022-12-28 23:08: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=128, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122823083362246469118', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0005, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-28 23:08: Argument batch_size: 256
2022-12-28 23:08: Argument clc: 'vec'
2022-12-28 23:08: Argument cuda: True
2022-12-28 23:08: Argument dataset: '2020'
2022-12-28 23:08: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-28 23:08: Argument debug: False
2022-12-28 23:08: Argument default_graph: True
2022-12-28 23:08: Argument device: 'cpu'
2022-12-28 23:08: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-28 23:08: Argument early_stop: True
2022-12-28 23:08: Argument early_stop_patience: 8
2022-12-28 23:08: Argument embed_dim: 128
2022-12-28 23:08: Argument epochs: 30
2022-12-28 23:08: Argument grad_norm: False
2022-12-28 23:08: Argument horizon: 1
2022-12-28 23:08: Argument input_dim: 25
2022-12-28 23:08: Argument lag: 10
2022-12-28 23:08: Argument link_len: 2
2022-12-28 23:08: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122823083362246469118'
2022-12-28 23:08: Argument log_step: 1
2022-12-28 23:08: Argument loss_func: 'nllloss'
2022-12-28 23:08: Argument lr_decay: True
2022-12-28 23:08: Argument lr_decay_rate: 0.1
2022-12-28 23:08: Argument lr_decay_step: '15, 20'
2022-12-28 23:08: Argument lr_init: 0.0005
2022-12-28 23:08: Argument max_grad_norm: 5
2022-12-28 23:08: Argument minbatch_size: 64
2022-12-28 23:08: Argument mode: 'train'
2022-12-28 23:08: Argument model: 'fire_GCN'
2022-12-28 23:08: Argument nan_fill: 0.5
2022-12-28 23:08: Argument num_layers: 1
2022-12-28 23:08: Argument num_nodes: 625
2022-12-28 23:08: Argument num_workers: 20
2022-12-28 23:08: Argument output_dim: 2
2022-12-28 23:08: Argument patch_height: 25
2022-12-28 23:08: Argument patch_width: 25
2022-12-28 23:08: Argument persistent_workers: True
2022-12-28 23:08: Argument pin_memory: True
2022-12-28 23:08: Argument plot: False
2022-12-28 23:08: Argument positive_weight: 0.5
2022-12-28 23:08: Argument prefetch_factor: 2
2022-12-28 23:08: Argument real_value: True
2022-12-28 23:08: Argument rnn_units: 16
2022-12-28 23:08: Argument seed: 10000
2022-12-28 23:08: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-28 23:08: Argument teacher_forcing: False
2022-12-28 23:08: Argument weight_decay: 0.0
2022-12-28 23:08: Argument window_len: 10
2022-12-28 23:08: Train Epoch 1: 3/244 Loss: 2.431704
2022-12-28 23:08: Train Epoch 1: 7/244 Loss: 1.424968
2022-12-28 23:08: Train Epoch 1: 11/244 Loss: 1.055997
2022-12-28 23:08: Train Epoch 1: 15/244 Loss: 1.340065
2022-12-28 23:09: Train Epoch 1: 19/244 Loss: 1.203026
2022-12-28 23:09: Train Epoch 1: 23/244 Loss: 0.908692
2022-12-28 23:09: Train Epoch 1: 27/244 Loss: 0.649870
2022-12-28 23:09: Train Epoch 1: 31/244 Loss: 0.755478
2022-12-28 23:09: Train Epoch 1: 35/244 Loss: 0.919882
2022-12-28 23:09: Train Epoch 1: 39/244 Loss: 0.808776
2022-12-28 23:09: Train Epoch 1: 43/244 Loss: 0.660949
2022-12-28 23:09: Train Epoch 1: 47/244 Loss: 0.637967
2022-12-28 23:09: Train Epoch 1: 51/244 Loss: 0.757106
2022-12-28 23:09: Train Epoch 1: 55/244 Loss: 0.798311
2022-12-28 23:09: Train Epoch 1: 59/244 Loss: 0.754616
2022-12-28 23:09: Train Epoch 1: 63/244 Loss: 0.618850
2022-12-28 23:09: Train Epoch 1: 67/244 Loss: 0.690893
2022-12-28 23:09: Train Epoch 1: 71/244 Loss: 0.661784
2022-12-28 23:10: Train Epoch 1: 75/244 Loss: 0.676161
2022-12-28 23:10: Train Epoch 1: 79/244 Loss: 0.645081
2022-12-28 23:10: Train Epoch 1: 83/244 Loss: 0.663597
2022-12-28 23:10: Train Epoch 1: 87/244 Loss: 0.680435
2022-12-28 23:10: Train Epoch 1: 91/244 Loss: 0.687211
2022-12-28 23:10: Train Epoch 1: 95/244 Loss: 0.684892
2022-12-28 23:10: Train Epoch 1: 99/244 Loss: 0.676773
2022-12-28 23:10: Train Epoch 1: 103/244 Loss: 0.664274
2022-12-28 23:10: Train Epoch 1: 107/244 Loss: 0.648607
2022-12-28 23:10: Train Epoch 1: 111/244 Loss: 0.649501
2022-12-28 23:10: Train Epoch 1: 115/244 Loss: 0.614530
2022-12-28 23:10: Train Epoch 1: 119/244 Loss: 0.666204
2022-12-28 23:10: Train Epoch 1: 123/244 Loss: 0.623618
2022-12-28 23:11: Train Epoch 1: 127/244 Loss: 0.616110
2022-12-28 23:11: Train Epoch 1: 131/244 Loss: 0.617887
2022-12-28 23:11: Train Epoch 1: 135/244 Loss: 0.676129
2022-12-28 23:11: Train Epoch 1: 139/244 Loss: 0.589423
2022-12-28 23:11: Train Epoch 1: 143/244 Loss: 0.629971
2022-12-28 23:11: Train Epoch 1: 147/244 Loss: 0.644078
2022-12-28 23:11: Train Epoch 1: 151/244 Loss: 0.587194
2022-12-28 23:11: Train Epoch 1: 155/244 Loss: 0.618647
2022-12-28 23:11: Train Epoch 1: 159/244 Loss: 0.639624
2022-12-28 23:11: Train Epoch 1: 163/244 Loss: 0.658735
2022-12-28 23:11: Train Epoch 1: 167/244 Loss: 0.611820
2022-12-28 23:11: Train Epoch 1: 171/244 Loss: 0.632146
2022-12-28 23:11: Train Epoch 1: 175/244 Loss: 0.620947
2022-12-28 23:11: Train Epoch 1: 179/244 Loss: 0.621849
2022-12-28 23:11: Train Epoch 1: 183/244 Loss: 0.631577
2022-12-28 23:12: Train Epoch 1: 187/244 Loss: 0.656283
2022-12-28 23:12: Train Epoch 1: 191/244 Loss: 0.628182
2022-12-28 23:12: Train Epoch 1: 195/244 Loss: 0.631494
2022-12-28 23:12: Train Epoch 1: 199/244 Loss: 0.632077
2022-12-28 23:12: Train Epoch 1: 203/244 Loss: 0.613693
2022-12-28 23:12: Train Epoch 1: 207/244 Loss: 0.612159
2022-12-28 23:12: Train Epoch 1: 211/244 Loss: 0.629109
2022-12-28 23:12: Train Epoch 1: 215/244 Loss: 0.613590
2022-12-28 23:12: Train Epoch 1: 219/244 Loss: 0.586247
2022-12-28 23:12: Train Epoch 1: 223/244 Loss: 0.662495
2022-12-28 23:12: Train Epoch 1: 227/244 Loss: 0.639930
2022-12-28 23:12: Train Epoch 1: 231/244 Loss: 0.660419
2022-12-28 23:12: Train Epoch 1: 235/244 Loss: 0.599740
2022-12-28 23:12: Train Epoch 1: 239/244 Loss: 0.613111
2022-12-28 23:12: Train Epoch 1: 243/244 Loss: 0.619800
2022-12-28 23:12: **********Train Epoch 1: averaged Loss: 0.728759 
2022-12-28 23:12: 
Epoch time elapsed: 264.97339272499084

2022-12-28 23:13: 
 metrics validation: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1300, 'AUC': 0.7440445266272189, 'AUCPR': 0.5764940134968269, 'TP': 0, 'FP': 0, 'TN': 2600, 'FN': 1300} 

2022-12-28 23:13: **********Val Epoch 1: average Loss: 0.599321
2022-12-28 23:13: *********************************Current best model saved!
2022-12-28 23:13: 
 Testing metrics {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1228, 'AUC': 0.835062573608208, 'AUCPR': 0.7092224515605383, 'TP': 0, 'FP': 0, 'TN': 2456, 'FN': 1228} 

2022-12-28 23:13: Train Epoch 2: 3/244 Loss: 0.645862
2022-12-28 23:14: Train Epoch 2: 7/244 Loss: 0.585107
2022-12-28 23:14: Train Epoch 2: 11/244 Loss: 0.651062
2022-12-28 23:14: Train Epoch 2: 15/244 Loss: 0.616985
2022-12-28 23:14: Train Epoch 2: 19/244 Loss: 0.636688
2022-12-28 23:14: Train Epoch 2: 23/244 Loss: 0.600483
2022-12-28 23:14: Train Epoch 2: 27/244 Loss: 0.593664
2022-12-28 23:14: Train Epoch 2: 31/244 Loss: 0.662281
2022-12-28 23:14: Train Epoch 2: 35/244 Loss: 0.609041
2022-12-28 23:14: Train Epoch 2: 39/244 Loss: 0.609041
2022-12-28 23:14: Train Epoch 2: 43/244 Loss: 0.617598
2022-12-28 23:14: Train Epoch 2: 47/244 Loss: 0.599066
2022-12-28 23:14: Train Epoch 2: 51/244 Loss: 0.649530
2022-12-28 23:15: Train Epoch 2: 55/244 Loss: 0.588201
2022-12-28 23:15: Train Epoch 2: 59/244 Loss: 0.598445
2022-12-28 23:15: Train Epoch 2: 63/244 Loss: 0.639061
2022-12-28 23:15: Train Epoch 2: 67/244 Loss: 0.638616
2022-12-28 23:15: Train Epoch 2: 71/244 Loss: 0.636967
2022-12-28 23:15: Train Epoch 2: 75/244 Loss: 0.618032
2022-12-28 23:15: Train Epoch 2: 79/244 Loss: 0.639291
2022-12-28 23:15: Train Epoch 2: 83/244 Loss: 0.602176
2022-12-28 23:15: Train Epoch 2: 87/244 Loss: 0.624754
2022-12-28 23:15: Train Epoch 2: 91/244 Loss: 0.621970
2022-12-28 23:15: Train Epoch 2: 95/244 Loss: 0.628133
2022-12-28 23:15: Train Epoch 2: 99/244 Loss: 0.621106
2022-12-28 23:15: Train Epoch 2: 103/244 Loss: 0.610771
2022-12-28 23:15: Train Epoch 2: 107/244 Loss: 0.622719
2022-12-28 23:16: Train Epoch 2: 111/244 Loss: 0.601072
2022-12-28 23:16: Train Epoch 2: 115/244 Loss: 0.603117
2022-12-28 23:16: Train Epoch 2: 119/244 Loss: 0.632758
2022-12-28 23:16: Train Epoch 2: 123/244 Loss: 0.610429
2022-12-28 23:16: Train Epoch 2: 127/244 Loss: 0.588967
2022-12-28 23:16: Train Epoch 2: 131/244 Loss: 0.662490
2022-12-28 23:16: Train Epoch 2: 135/244 Loss: 0.607965
2022-12-28 23:16: Train Epoch 2: 139/244 Loss: 0.617011
2022-12-28 23:16: Train Epoch 2: 143/244 Loss: 0.580777
2022-12-28 23:16: Train Epoch 2: 147/244 Loss: 0.573905
2022-12-28 23:16: Train Epoch 2: 151/244 Loss: 0.590700
2022-12-28 23:16: Train Epoch 2: 155/244 Loss: 0.594058
2022-12-28 23:16: Train Epoch 2: 159/244 Loss: 0.605435
2022-12-28 23:16: Train Epoch 2: 163/244 Loss: 0.607431
2022-12-28 23:17: Train Epoch 2: 167/244 Loss: 0.596704
2022-12-28 23:17: Train Epoch 2: 171/244 Loss: 0.578851
2022-12-28 23:17: Train Epoch 2: 175/244 Loss: 0.622965
2022-12-28 23:17: Train Epoch 2: 179/244 Loss: 0.626255
2022-12-28 23:17: Train Epoch 2: 183/244 Loss: 0.609051
2022-12-28 23:17: Train Epoch 2: 187/244 Loss: 0.582624
2022-12-28 23:17: Train Epoch 2: 191/244 Loss: 0.594364
2022-12-28 23:17: Train Epoch 2: 195/244 Loss: 0.587089
2022-12-28 23:17: Train Epoch 2: 199/244 Loss: 0.601805
2022-12-28 23:17: Train Epoch 2: 203/244 Loss: 0.615877
2022-12-28 23:17: Train Epoch 2: 207/244 Loss: 0.575709
2022-12-28 23:17: Train Epoch 2: 211/244 Loss: 0.587469
2022-12-28 23:17: Train Epoch 2: 215/244 Loss: 0.601428
2022-12-28 23:17: Train Epoch 2: 219/244 Loss: 0.590833
2022-12-28 23:18: Train Epoch 2: 223/244 Loss: 0.569153
2022-12-28 23:18: Train Epoch 2: 227/244 Loss: 0.614438
2022-12-28 23:18: Train Epoch 2: 231/244 Loss: 0.604845
2022-12-28 23:18: Train Epoch 2: 235/244 Loss: 0.612534
2022-12-28 23:18: Train Epoch 2: 239/244 Loss: 0.603162
2022-12-28 23:18: Train Epoch 2: 243/244 Loss: 0.632883
2022-12-28 23:18: **********Train Epoch 2: averaged Loss: 0.610669 
2022-12-28 23:18: 
Epoch time elapsed: 266.721116065979

2022-12-28 23:18: 
 metrics validation: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1300, 'AUC': 0.7182875739644972, 'AUCPR': 0.5584961536456989, 'TP': 0, 'FP': 0, 'TN': 2600, 'FN': 1300} 

2022-12-28 23:18: **********Val Epoch 2: average Loss: 0.588047
2022-12-28 23:18: *********************************Current best model saved!
2022-12-28 23:19: 
 Testing metrics {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1228, 'AUC': 0.8463017512122144, 'AUCPR': 0.7416048671189391, 'TP': 0, 'FP': 0, 'TN': 2456, 'FN': 1228} 

2022-12-28 23:19: Train Epoch 3: 3/244 Loss: 0.591879
2022-12-28 23:19: Train Epoch 3: 7/244 Loss: 0.576450
2022-12-28 23:19: Train Epoch 3: 11/244 Loss: 0.616623
2022-12-28 23:19: Train Epoch 3: 15/244 Loss: 0.599951
2022-12-28 23:19: Train Epoch 3: 19/244 Loss: 0.597131
2022-12-28 23:19: Train Epoch 3: 23/244 Loss: 0.582037
2022-12-28 23:19: Train Epoch 3: 27/244 Loss: 0.587114
2022-12-28 23:19: Train Epoch 3: 31/244 Loss: 0.590204
2022-12-28 23:19: Train Epoch 3: 35/244 Loss: 0.591958
2022-12-28 23:19: Train Epoch 3: 39/244 Loss: 0.597807
2022-12-28 23:19: Train Epoch 3: 43/244 Loss: 0.599355
2022-12-28 23:20: Train Epoch 3: 47/244 Loss: 0.580518
2022-12-28 23:20: Train Epoch 3: 51/244 Loss: 0.578254
2022-12-28 23:20: Train Epoch 3: 55/244 Loss: 0.571516
2022-12-28 23:20: Train Epoch 3: 59/244 Loss: 0.589401
2022-12-28 23:20: Train Epoch 3: 63/244 Loss: 0.583385
2022-12-28 23:20: Train Epoch 3: 67/244 Loss: 0.562712
2022-12-28 23:20: Train Epoch 3: 71/244 Loss: 0.569388
2022-12-28 23:20: Train Epoch 3: 75/244 Loss: 0.576132
2022-12-28 23:20: Train Epoch 3: 79/244 Loss: 0.564309
2022-12-28 23:20: Train Epoch 3: 83/244 Loss: 0.580091
2022-12-28 23:20: Train Epoch 3: 87/244 Loss: 0.549424
2022-12-28 23:20: Train Epoch 3: 91/244 Loss: 0.525369
2022-12-28 23:20: Train Epoch 3: 95/244 Loss: 0.545683
2022-12-28 23:20: Train Epoch 3: 99/244 Loss: 0.566050
2022-12-28 23:21: Train Epoch 3: 103/244 Loss: 0.564763
2022-12-28 23:21: Train Epoch 3: 107/244 Loss: 0.586595
2022-12-28 23:21: Train Epoch 3: 111/244 Loss: 0.608706
2022-12-28 23:21: Train Epoch 3: 115/244 Loss: 0.554867
2022-12-28 23:21: Train Epoch 3: 119/244 Loss: 0.540319
2022-12-28 23:21: Train Epoch 3: 123/244 Loss: 0.524224
2022-12-28 23:21: Train Epoch 3: 127/244 Loss: 0.514476
2022-12-28 23:21: Train Epoch 3: 131/244 Loss: 0.547380
2022-12-28 23:21: Train Epoch 3: 135/244 Loss: 0.513632
2022-12-28 23:21: Train Epoch 3: 139/244 Loss: 0.523797
2022-12-28 23:21: Train Epoch 3: 143/244 Loss: 0.532879
2022-12-28 23:21: Train Epoch 3: 147/244 Loss: 0.527413
2022-12-28 23:22: Train Epoch 3: 151/244 Loss: 0.544015
2022-12-28 23:22: Train Epoch 3: 155/244 Loss: 0.511794
2022-12-28 23:22: Train Epoch 3: 159/244 Loss: 0.499813
2022-12-28 23:22: Train Epoch 3: 163/244 Loss: 0.491113
2022-12-28 23:22: Train Epoch 3: 167/244 Loss: 0.540092
2022-12-28 23:22: Train Epoch 3: 171/244 Loss: 0.525956
2022-12-28 23:22: Train Epoch 3: 175/244 Loss: 0.519533
2022-12-28 23:22: Train Epoch 3: 179/244 Loss: 0.519604
2022-12-28 23:22: Train Epoch 3: 183/244 Loss: 0.515691
2022-12-28 23:22: Train Epoch 3: 187/244 Loss: 0.492820
2022-12-28 23:22: Train Epoch 3: 191/244 Loss: 0.493710
2022-12-28 23:22: Train Epoch 3: 195/244 Loss: 0.493827
2022-12-28 23:22: Train Epoch 3: 199/244 Loss: 0.504073
2022-12-28 23:22: Train Epoch 3: 203/244 Loss: 0.451462
2022-12-28 23:23: Train Epoch 3: 207/244 Loss: 0.504136
2022-12-28 23:23: Train Epoch 3: 211/244 Loss: 0.504291
2022-12-28 23:23: Train Epoch 3: 215/244 Loss: 0.494318
2022-12-28 23:23: Train Epoch 3: 219/244 Loss: 0.481296
2022-12-28 23:23: Train Epoch 3: 223/244 Loss: 0.468849
2022-12-28 23:23: Train Epoch 3: 227/244 Loss: 0.485204
2022-12-28 23:23: Train Epoch 3: 231/244 Loss: 0.458762
2022-12-28 23:23: Train Epoch 3: 235/244 Loss: 0.459237
2022-12-28 23:23: Train Epoch 3: 239/244 Loss: 0.466114
2022-12-28 23:23: Train Epoch 3: 243/244 Loss: 0.429806
2022-12-28 23:23: **********Train Epoch 3: averaged Loss: 0.538808 
2022-12-28 23:23: 
Epoch time elapsed: 271.2151606082916

2022-12-28 23:24: 
 metrics validation: {'precision': 0.7391304347826086, 'recall': 0.1176923076923077, 'f1-score': 0.20305242203052423, 'support': 1300, 'AUC': 0.7326985207100591, 'AUCPR': 0.5972731142931226, 'TP': 153, 'FP': 54, 'TN': 2546, 'FN': 1147} 

2022-12-28 23:24: **********Val Epoch 3: average Loss: 0.547200
2022-12-28 23:24: *********************************Current best model saved!
2022-12-28 23:24: 
 Testing metrics {'precision': 0.8458781362007168, 'recall': 0.19218241042345277, 'f1-score': 0.3132050431320504, 'support': 1228, 'AUC': 0.8535049111926917, 'AUCPR': 0.7649783300220019, 'TP': 236, 'FP': 43, 'TN': 2413, 'FN': 992} 

2022-12-28 23:24: Train Epoch 4: 3/244 Loss: 0.444710
2022-12-28 23:24: Train Epoch 4: 7/244 Loss: 0.455495
2022-12-28 23:24: Train Epoch 4: 11/244 Loss: 0.443398
2022-12-28 23:24: Train Epoch 4: 15/244 Loss: 0.438651
2022-12-28 23:24: Train Epoch 4: 19/244 Loss: 0.455541
2022-12-28 23:24: Train Epoch 4: 23/244 Loss: 0.453317
2022-12-28 23:25: Train Epoch 4: 27/244 Loss: 0.403776
2022-12-28 23:25: Train Epoch 4: 31/244 Loss: 0.432186
2022-12-28 23:25: Train Epoch 4: 35/244 Loss: 0.436084
2022-12-28 23:25: Train Epoch 4: 39/244 Loss: 0.438990
2022-12-28 23:25: Train Epoch 4: 43/244 Loss: 0.424799
2022-12-28 23:25: Train Epoch 4: 47/244 Loss: 0.413814
2022-12-28 23:25: Train Epoch 4: 51/244 Loss: 0.455692
2022-12-28 23:25: Train Epoch 4: 55/244 Loss: 0.386528
2022-12-28 23:25: Train Epoch 4: 59/244 Loss: 0.422002
2022-12-28 23:25: Train Epoch 4: 63/244 Loss: 0.424089
2022-12-28 23:25: Train Epoch 4: 67/244 Loss: 0.364946
2022-12-28 23:25: Train Epoch 4: 71/244 Loss: 0.359436
2022-12-28 23:25: Train Epoch 4: 75/244 Loss: 0.378144
2022-12-28 23:25: Train Epoch 4: 79/244 Loss: 0.350238
2022-12-28 23:26: Train Epoch 4: 83/244 Loss: 0.349961
2022-12-28 23:26: Train Epoch 4: 87/244 Loss: 0.373989
2022-12-28 23:26: Train Epoch 4: 91/244 Loss: 0.348545
2022-12-28 23:26: Train Epoch 4: 95/244 Loss: 0.391363
2022-12-28 23:26: Train Epoch 4: 99/244 Loss: 0.354371
2022-12-28 23:26: Train Epoch 4: 103/244 Loss: 0.361203
2022-12-28 23:26: Train Epoch 4: 107/244 Loss: 0.338986
2022-12-28 23:26: Train Epoch 4: 111/244 Loss: 0.343388
2022-12-28 23:26: Train Epoch 4: 115/244 Loss: 0.340651
2022-12-28 23:26: Train Epoch 4: 119/244 Loss: 0.274193
2022-12-28 23:26: Train Epoch 4: 123/244 Loss: 0.263719
2022-12-28 23:26: Train Epoch 4: 127/244 Loss: 0.303694
2022-12-28 23:26: Train Epoch 4: 131/244 Loss: 0.283500
2022-12-28 23:26: Train Epoch 4: 135/244 Loss: 0.271274
2022-12-28 23:27: Train Epoch 4: 139/244 Loss: 0.336354
2022-12-28 23:27: Train Epoch 4: 143/244 Loss: 0.276318
2022-12-28 23:27: Train Epoch 4: 147/244 Loss: 0.290307
2022-12-28 23:27: Train Epoch 4: 151/244 Loss: 0.282094
2022-12-28 23:27: Train Epoch 4: 155/244 Loss: 0.305975
2022-12-28 23:27: Train Epoch 4: 159/244 Loss: 0.305588
2022-12-28 23:27: Train Epoch 4: 163/244 Loss: 0.268414
2022-12-28 23:27: Train Epoch 4: 167/244 Loss: 0.292932
2022-12-28 23:27: Train Epoch 4: 171/244 Loss: 0.283153
2022-12-28 23:27: Train Epoch 4: 175/244 Loss: 0.260859
2022-12-28 23:27: Train Epoch 4: 179/244 Loss: 0.254588
2022-12-28 23:27: Train Epoch 4: 183/244 Loss: 0.357378
2022-12-28 23:27: Train Epoch 4: 187/244 Loss: 0.258773
2022-12-28 23:27: Train Epoch 4: 191/244 Loss: 0.315054
2022-12-28 23:28: Train Epoch 4: 195/244 Loss: 0.208983
2022-12-28 23:28: Train Epoch 4: 199/244 Loss: 0.242050
2022-12-28 23:28: Train Epoch 4: 203/244 Loss: 0.304608
2022-12-28 23:28: Train Epoch 4: 207/244 Loss: 0.233150
2022-12-28 23:28: Train Epoch 4: 211/244 Loss: 0.238966
2022-12-28 23:28: Train Epoch 4: 215/244 Loss: 0.282541
2022-12-28 23:28: Train Epoch 4: 219/244 Loss: 0.263979
2022-12-28 23:28: Train Epoch 4: 223/244 Loss: 0.241217
2022-12-28 23:28: Train Epoch 4: 227/244 Loss: 0.224777
2022-12-28 23:28: Train Epoch 4: 231/244 Loss: 0.228739
2022-12-28 23:28: Train Epoch 4: 235/244 Loss: 0.268064
2022-12-28 23:28: Train Epoch 4: 239/244 Loss: 0.276069
2022-12-28 23:28: Train Epoch 4: 243/244 Loss: 0.202374
2022-12-28 23:28: **********Train Epoch 4: averaged Loss: 0.332524 
2022-12-28 23:28: 
Epoch time elapsed: 262.2993679046631

2022-12-28 23:29: 
 metrics validation: {'precision': 0.7647714604236343, 'recall': 0.5276923076923077, 'f1-score': 0.6244879380974055, 'support': 1300, 'AUC': 0.8006949704142012, 'AUCPR': 0.7126638933701938, 'TP': 686, 'FP': 211, 'TN': 2389, 'FN': 614} 

2022-12-28 23:29: **********Val Epoch 4: average Loss: 0.583762
2022-12-28 23:29: 
 Testing metrics {'precision': 0.8458781362007168, 'recall': 0.19218241042345277, 'f1-score': 0.3132050431320504, 'support': 1228, 'AUC': 0.8535049111926917, 'AUCPR': 0.7649783300220019, 'TP': 236, 'FP': 43, 'TN': 2413, 'FN': 992} 

2022-12-28 23:29: Train Epoch 5: 3/244 Loss: 0.441371
2022-12-28 23:29: Train Epoch 5: 7/244 Loss: 0.452946
2022-12-28 23:29: Train Epoch 5: 11/244 Loss: 0.403733
2022-12-28 23:30: Train Epoch 5: 15/244 Loss: 0.455799
2022-12-28 23:30: Train Epoch 5: 19/244 Loss: 0.456284
2022-12-28 23:30: Train Epoch 5: 23/244 Loss: 0.430119
2022-12-28 23:30: Train Epoch 5: 27/244 Loss: 0.416533
2022-12-28 23:30: Train Epoch 5: 31/244 Loss: 0.436599
2022-12-28 23:30: Train Epoch 5: 35/244 Loss: 0.453226
2022-12-28 23:30: Train Epoch 5: 39/244 Loss: 0.442052
2022-12-28 23:30: Train Epoch 5: 43/244 Loss: 0.427023
2022-12-28 23:30: Train Epoch 5: 47/244 Loss: 0.402612
2022-12-28 23:30: Train Epoch 5: 51/244 Loss: 0.418626
2022-12-28 23:30: Train Epoch 5: 55/244 Loss: 0.433951
2022-12-28 23:30: Train Epoch 5: 59/244 Loss: 0.384060
2022-12-28 23:30: Train Epoch 5: 63/244 Loss: 0.406032
2022-12-28 23:30: Train Epoch 5: 67/244 Loss: 0.392877
2022-12-28 23:31: Train Epoch 5: 71/244 Loss: 0.412745
2022-12-28 23:31: Train Epoch 5: 75/244 Loss: 0.389181
2022-12-28 23:31: Train Epoch 5: 79/244 Loss: 0.385095
2022-12-28 23:31: Train Epoch 5: 83/244 Loss: 0.388917
2022-12-28 23:31: Train Epoch 5: 87/244 Loss: 0.413492
2022-12-28 23:31: Train Epoch 5: 91/244 Loss: 0.376870
2022-12-28 23:31: Train Epoch 5: 95/244 Loss: 0.413616
2022-12-28 23:31: Train Epoch 5: 99/244 Loss: 0.401648
2022-12-28 23:31: Train Epoch 5: 103/244 Loss: 0.394144
2022-12-28 23:31: Train Epoch 5: 107/244 Loss: 0.386602
2022-12-28 23:31: Train Epoch 5: 111/244 Loss: 0.404719
2022-12-28 23:31: Train Epoch 5: 115/244 Loss: 0.361577
2022-12-28 23:31: Train Epoch 5: 119/244 Loss: 0.350493
2022-12-28 23:31: Train Epoch 5: 123/244 Loss: 0.341938
2022-12-28 23:32: Train Epoch 5: 127/244 Loss: 0.323993
2022-12-28 23:32: Train Epoch 5: 131/244 Loss: 0.363391
2022-12-28 23:32: Train Epoch 5: 135/244 Loss: 0.344513
2022-12-28 23:32: Train Epoch 5: 139/244 Loss: 0.364447
2022-12-28 23:32: Train Epoch 5: 143/244 Loss: 0.330427
2022-12-28 23:32: Train Epoch 5: 147/244 Loss: 0.336540
2022-12-28 23:32: Train Epoch 5: 151/244 Loss: 0.354973
2022-12-28 23:32: Train Epoch 5: 155/244 Loss: 0.359806
2022-12-28 23:32: Train Epoch 5: 159/244 Loss: 0.299011
2022-12-28 23:32: Train Epoch 5: 163/244 Loss: 0.320493
2022-12-28 23:32: Train Epoch 5: 167/244 Loss: 0.367427
2022-12-28 23:32: Train Epoch 5: 171/244 Loss: 0.310475
2022-12-28 23:32: Train Epoch 5: 175/244 Loss: 0.334956
2022-12-28 23:32: Train Epoch 5: 179/244 Loss: 0.256323
2022-12-28 23:32: Train Epoch 5: 183/244 Loss: 0.288599
2022-12-28 23:33: Train Epoch 5: 187/244 Loss: 0.300767
2022-12-28 23:33: Train Epoch 5: 191/244 Loss: 0.325369
2022-12-28 23:33: Train Epoch 5: 195/244 Loss: 0.245943
2022-12-28 23:33: Train Epoch 5: 199/244 Loss: 0.335453
2022-12-28 23:33: Train Epoch 5: 203/244 Loss: 0.269647
2022-12-28 23:33: Train Epoch 5: 207/244 Loss: 0.269057
2022-12-28 23:33: Train Epoch 5: 211/244 Loss: 0.287105
2022-12-28 23:33: Train Epoch 5: 215/244 Loss: 0.290913
2022-12-28 23:33: Train Epoch 5: 219/244 Loss: 0.264733
2022-12-28 23:33: Train Epoch 5: 223/244 Loss: 0.293058
2022-12-28 23:33: Train Epoch 5: 227/244 Loss: 0.267699
2022-12-28 23:33: Train Epoch 5: 231/244 Loss: 0.273183
2022-12-28 23:33: Train Epoch 5: 235/244 Loss: 0.264794
2022-12-28 23:33: Train Epoch 5: 239/244 Loss: 0.302375
2022-12-28 23:33: Train Epoch 5: 243/244 Loss: 0.240861
2022-12-28 23:33: **********Train Epoch 5: averaged Loss: 0.358380 
2022-12-28 23:33: 
Epoch time elapsed: 255.221200466156

2022-12-28 23:34: 
 metrics validation: {'precision': 0.7520576131687243, 'recall': 0.5623076923076923, 'f1-score': 0.6434859154929577, 'support': 1300, 'AUC': 0.7974727810650888, 'AUCPR': 0.7079085165790553, 'TP': 731, 'FP': 241, 'TN': 2359, 'FN': 569} 

2022-12-28 23:34: **********Val Epoch 5: average Loss: 0.554240
2022-12-28 23:34: 
 Testing metrics {'precision': 0.8458781362007168, 'recall': 0.19218241042345277, 'f1-score': 0.3132050431320504, 'support': 1228, 'AUC': 0.8535049111926917, 'AUCPR': 0.7649783300220019, 'TP': 236, 'FP': 43, 'TN': 2413, 'FN': 992} 

2022-12-28 23:34: Train Epoch 6: 3/244 Loss: 0.428644
2022-12-28 23:34: Train Epoch 6: 7/244 Loss: 0.459259
2022-12-28 23:35: Train Epoch 6: 11/244 Loss: 0.469463
2022-12-28 23:35: Train Epoch 6: 15/244 Loss: 0.433410
2022-12-28 23:35: Train Epoch 6: 19/244 Loss: 0.473790
2022-12-28 23:35: Train Epoch 6: 23/244 Loss: 0.443882
2022-12-28 23:35: Train Epoch 6: 27/244 Loss: 0.409366
2022-12-28 23:35: Train Epoch 6: 31/244 Loss: 0.498157
2022-12-28 23:35: Train Epoch 6: 35/244 Loss: 0.427333
2022-12-28 23:35: Train Epoch 6: 39/244 Loss: 0.416066
2022-12-28 23:35: Train Epoch 6: 43/244 Loss: 0.430710
2022-12-28 23:35: Train Epoch 6: 47/244 Loss: 0.461719
2022-12-28 23:35: Train Epoch 6: 51/244 Loss: 0.438199
2022-12-28 23:35: Train Epoch 6: 55/244 Loss: 0.421366
2022-12-28 23:35: Train Epoch 6: 59/244 Loss: 0.441146
2022-12-28 23:36: Train Epoch 6: 63/244 Loss: 0.426976
2022-12-28 23:36: Train Epoch 6: 67/244 Loss: 0.403870
2022-12-28 23:36: Train Epoch 6: 71/244 Loss: 0.399305
2022-12-28 23:36: Train Epoch 6: 75/244 Loss: 0.390165
2022-12-28 23:36: Train Epoch 6: 79/244 Loss: 0.368684
2022-12-28 23:36: Train Epoch 6: 83/244 Loss: 0.406461
2022-12-28 23:36: Train Epoch 6: 87/244 Loss: 0.351032
2022-12-28 23:36: Train Epoch 6: 91/244 Loss: 0.342079
2022-12-28 23:36: Train Epoch 6: 95/244 Loss: 0.352326
2022-12-28 23:36: Train Epoch 6: 99/244 Loss: 0.361313
2022-12-28 23:36: Train Epoch 6: 103/244 Loss: 0.378560
2022-12-28 23:36: Train Epoch 6: 107/244 Loss: 0.310747
2022-12-28 23:36: Train Epoch 6: 111/244 Loss: 0.333050
2022-12-28 23:36: Train Epoch 6: 115/244 Loss: 0.327205
2022-12-28 23:37: Train Epoch 6: 119/244 Loss: 0.332548
2022-12-28 23:37: Train Epoch 6: 123/244 Loss: 0.330767
2022-12-28 23:37: Train Epoch 6: 127/244 Loss: 0.300977
2022-12-28 23:37: Train Epoch 6: 131/244 Loss: 0.281246
2022-12-28 23:37: Train Epoch 6: 135/244 Loss: 0.299830
2022-12-28 23:37: Train Epoch 6: 139/244 Loss: 0.308348
2022-12-28 23:37: Train Epoch 6: 143/244 Loss: 0.298043
2022-12-28 23:37: Train Epoch 6: 147/244 Loss: 0.297666
2022-12-28 23:37: Train Epoch 6: 151/244 Loss: 0.339114
2022-12-28 23:37: Train Epoch 6: 155/244 Loss: 0.339988
2022-12-28 23:37: Train Epoch 6: 159/244 Loss: 0.257312
2022-12-28 23:37: Train Epoch 6: 163/244 Loss: 0.292382
2022-12-28 23:37: Train Epoch 6: 167/244 Loss: 0.290086
2022-12-28 23:37: Train Epoch 6: 171/244 Loss: 0.320075
2022-12-28 23:37: Train Epoch 6: 175/244 Loss: 0.269517
2022-12-28 23:38: Train Epoch 6: 179/244 Loss: 0.304739
2022-12-28 23:38: Train Epoch 6: 183/244 Loss: 0.259872
2022-12-28 23:38: Train Epoch 6: 187/244 Loss: 0.262504
2022-12-28 23:38: Train Epoch 6: 191/244 Loss: 0.281885
2022-12-28 23:38: Train Epoch 6: 195/244 Loss: 0.275395
2022-12-28 23:38: Train Epoch 6: 199/244 Loss: 0.278450
2022-12-28 23:38: Train Epoch 6: 203/244 Loss: 0.276847
2022-12-28 23:38: Train Epoch 6: 207/244 Loss: 0.273793
2022-12-28 23:38: Train Epoch 6: 211/244 Loss: 0.277760
2022-12-28 23:38: Train Epoch 6: 215/244 Loss: 0.256861
2022-12-28 23:38: Train Epoch 6: 219/244 Loss: 0.243885
2022-12-28 23:38: Train Epoch 6: 223/244 Loss: 0.269954
2022-12-28 23:38: Train Epoch 6: 227/244 Loss: 0.279265
2022-12-28 23:38: Train Epoch 6: 231/244 Loss: 0.191360
2022-12-28 23:38: Train Epoch 6: 235/244 Loss: 0.273102
2022-12-28 23:39: Train Epoch 6: 239/244 Loss: 0.239168
2022-12-28 23:39: Train Epoch 6: 243/244 Loss: 0.290323
2022-12-28 23:39: **********Train Epoch 6: averaged Loss: 0.342579 
2022-12-28 23:39: 
Epoch time elapsed: 258.13252210617065

2022-12-28 23:39: 
 metrics validation: {'precision': 0.7504835589941973, 'recall': 0.5969230769230769, 'f1-score': 0.6649528706083976, 'support': 1300, 'AUC': 0.8009434911242602, 'AUCPR': 0.7134797311283636, 'TP': 776, 'FP': 258, 'TN': 2342, 'FN': 524} 

2022-12-28 23:39: **********Val Epoch 6: average Loss: 0.551274
2022-12-28 23:39: 
 Testing metrics {'precision': 0.8458781362007168, 'recall': 0.19218241042345277, 'f1-score': 0.3132050431320504, 'support': 1228, 'AUC': 0.8535049111926917, 'AUCPR': 0.7649783300220019, 'TP': 236, 'FP': 43, 'TN': 2413, 'FN': 992} 

2022-12-28 23:39: Train Epoch 7: 3/244 Loss: 0.445616
2022-12-28 23:40: Train Epoch 7: 7/244 Loss: 0.456305
2022-12-28 23:40: Train Epoch 7: 11/244 Loss: 0.464156
2022-12-28 23:40: Train Epoch 7: 15/244 Loss: 0.438319
2022-12-28 23:40: Train Epoch 7: 19/244 Loss: 0.431437
2022-12-28 23:40: Train Epoch 7: 23/244 Loss: 0.427220
2022-12-28 23:40: Train Epoch 7: 27/244 Loss: 0.430485
2022-12-28 23:40: Train Epoch 7: 31/244 Loss: 0.426745
2022-12-28 23:40: Train Epoch 7: 35/244 Loss: 0.433873
2022-12-28 23:40: Train Epoch 7: 39/244 Loss: 0.398408
2022-12-28 23:40: Train Epoch 7: 43/244 Loss: 0.433259
2022-12-28 23:40: Train Epoch 7: 47/244 Loss: 0.424696
2022-12-28 23:40: Train Epoch 7: 51/244 Loss: 0.417813
2022-12-28 23:40: Train Epoch 7: 55/244 Loss: 0.439713
2022-12-28 23:40: Train Epoch 7: 59/244 Loss: 0.409346
2022-12-28 23:41: Train Epoch 7: 63/244 Loss: 0.434205
2022-12-28 23:41: Train Epoch 7: 67/244 Loss: 0.407377
2022-12-28 23:41: Train Epoch 7: 71/244 Loss: 0.424066
2022-12-28 23:41: Train Epoch 7: 75/244 Loss: 0.382912
2022-12-28 23:41: Train Epoch 7: 79/244 Loss: 0.427822
2022-12-28 23:41: Train Epoch 7: 83/244 Loss: 0.367548
2022-12-28 23:41: Train Epoch 7: 87/244 Loss: 0.378501
2022-12-28 23:41: Train Epoch 7: 91/244 Loss: 0.411559
2022-12-28 23:41: Train Epoch 7: 95/244 Loss: 0.347769
2022-12-28 23:41: Train Epoch 7: 99/244 Loss: 0.361895
2022-12-28 23:41: Train Epoch 7: 103/244 Loss: 0.359594
2022-12-28 23:41: Train Epoch 7: 107/244 Loss: 0.293141
2022-12-28 23:41: Train Epoch 7: 111/244 Loss: 0.351432
2022-12-28 23:41: Train Epoch 7: 115/244 Loss: 0.322275
2022-12-28 23:42: Train Epoch 7: 119/244 Loss: 0.297864
2022-12-28 23:42: Train Epoch 7: 123/244 Loss: 0.317887
2022-12-28 23:42: Train Epoch 7: 127/244 Loss: 0.309928
2022-12-28 23:42: Train Epoch 7: 131/244 Loss: 0.295004
2022-12-28 23:42: Train Epoch 7: 135/244 Loss: 0.316785
2022-12-28 23:42: Train Epoch 7: 139/244 Loss: 0.298816
2022-12-28 23:42: Train Epoch 7: 143/244 Loss: 0.351339
2022-12-28 23:42: Train Epoch 7: 147/244 Loss: 0.395569
2022-12-28 23:42: Train Epoch 7: 151/244 Loss: 0.282294
2022-12-28 23:42: Train Epoch 7: 155/244 Loss: 0.342047
2022-12-28 23:42: Train Epoch 7: 159/244 Loss: 0.289778
2022-12-28 23:42: Train Epoch 7: 163/244 Loss: 0.249840
2022-12-28 23:42: Train Epoch 7: 167/244 Loss: 0.270951
2022-12-28 23:43: Train Epoch 7: 171/244 Loss: 0.290632
2022-12-28 23:43: Train Epoch 7: 175/244 Loss: 0.229383
2022-12-28 23:43: Train Epoch 7: 179/244 Loss: 0.248333
2022-12-28 23:43: Train Epoch 7: 183/244 Loss: 0.277440
2022-12-28 23:43: Train Epoch 7: 187/244 Loss: 0.255944
2022-12-28 23:43: Train Epoch 7: 191/244 Loss: 0.215052
2022-12-28 23:43: Train Epoch 7: 195/244 Loss: 0.270868
2022-12-28 23:43: Train Epoch 7: 199/244 Loss: 0.256291
2022-12-28 23:43: Train Epoch 7: 203/244 Loss: 0.267995
2022-12-28 23:43: Train Epoch 7: 207/244 Loss: 0.243174
2022-12-28 23:43: Train Epoch 7: 211/244 Loss: 0.241172
2022-12-28 23:43: Train Epoch 7: 215/244 Loss: 0.279612
2022-12-28 23:43: Train Epoch 7: 219/244 Loss: 0.224433
2022-12-28 23:43: Train Epoch 7: 223/244 Loss: 0.227081
2022-12-28 23:44: Train Epoch 7: 227/244 Loss: 0.248140
2022-12-28 23:44: Train Epoch 7: 231/244 Loss: 0.260199
2022-12-28 23:44: Train Epoch 7: 235/244 Loss: 0.236983
2022-12-28 23:44: Train Epoch 7: 239/244 Loss: 0.275761
2022-12-28 23:44: Train Epoch 7: 243/244 Loss: 0.293522
2022-12-28 23:44: **********Train Epoch 7: averaged Loss: 0.337830 
2022-12-28 23:44: 
Epoch time elapsed: 265.3166320323944

2022-12-28 23:44: 
 metrics validation: {'precision': 0.7547931382441978, 'recall': 0.5753846153846154, 'f1-score': 0.6529899607158447, 'support': 1300, 'AUC': 0.7998094674556213, 'AUCPR': 0.7106758104803088, 'TP': 748, 'FP': 243, 'TN': 2357, 'FN': 552} 

2022-12-28 23:44: **********Val Epoch 7: average Loss: 0.557473
2022-12-28 23:45: 
 Testing metrics {'precision': 0.8458781362007168, 'recall': 0.19218241042345277, 'f1-score': 0.3132050431320504, 'support': 1228, 'AUC': 0.8535049111926917, 'AUCPR': 0.7649783300220019, 'TP': 236, 'FP': 43, 'TN': 2413, 'FN': 992} 

2022-12-28 23:45: Train Epoch 8: 3/244 Loss: 0.418829
2022-12-28 23:45: Train Epoch 8: 7/244 Loss: 0.465845
2022-12-28 23:45: Train Epoch 8: 11/244 Loss: 0.427653
2022-12-28 23:45: Train Epoch 8: 15/244 Loss: 0.474836
2022-12-28 23:45: Train Epoch 8: 19/244 Loss: 0.466598
2022-12-28 23:45: Train Epoch 8: 23/244 Loss: 0.445030
2022-12-28 23:45: Train Epoch 8: 27/244 Loss: 0.447838
2022-12-28 23:45: Train Epoch 8: 31/244 Loss: 0.457950
2022-12-28 23:45: Train Epoch 8: 35/244 Loss: 0.448965
2022-12-28 23:45: Train Epoch 8: 39/244 Loss: 0.444967
2022-12-28 23:45: Train Epoch 8: 43/244 Loss: 0.398590
2022-12-28 23:45: Train Epoch 8: 47/244 Loss: 0.410378
2022-12-28 23:46: Train Epoch 8: 51/244 Loss: 0.423303
2022-12-28 23:46: Train Epoch 8: 55/244 Loss: 0.433468
2022-12-28 23:46: Train Epoch 8: 59/244 Loss: 0.408745
2022-12-28 23:46: Train Epoch 8: 63/244 Loss: 0.420628
2022-12-28 23:46: Train Epoch 8: 67/244 Loss: 0.417656
2022-12-28 23:46: Train Epoch 8: 71/244 Loss: 0.424310
2022-12-28 23:46: Train Epoch 8: 75/244 Loss: 0.400589
2022-12-28 23:46: Train Epoch 8: 79/244 Loss: 0.375131
2022-12-28 23:46: Train Epoch 8: 83/244 Loss: 0.406755
2022-12-28 23:46: Train Epoch 8: 87/244 Loss: 0.383902
2022-12-28 23:46: Train Epoch 8: 91/244 Loss: 0.402011
2022-12-28 23:46: Train Epoch 8: 95/244 Loss: 0.409050
2022-12-28 23:46: Train Epoch 8: 99/244 Loss: 0.394296
2022-12-28 23:46: Train Epoch 8: 103/244 Loss: 0.375158
2022-12-28 23:47: Train Epoch 8: 107/244 Loss: 0.340981
2022-12-28 23:47: Train Epoch 8: 111/244 Loss: 0.367790
2022-12-28 23:47: Train Epoch 8: 115/244 Loss: 0.339417
2022-12-28 23:47: Train Epoch 8: 119/244 Loss: 0.352696
2022-12-28 23:47: Train Epoch 8: 123/244 Loss: 0.377263
2022-12-28 23:47: Train Epoch 8: 127/244 Loss: 0.329739
2022-12-28 23:47: Train Epoch 8: 131/244 Loss: 0.322115
2022-12-28 23:47: Train Epoch 8: 135/244 Loss: 0.362909
2022-12-28 23:47: Train Epoch 8: 139/244 Loss: 0.352392
2022-12-28 23:47: Train Epoch 8: 143/244 Loss: 0.351037
2022-12-28 23:47: Train Epoch 8: 147/244 Loss: 0.367229
2022-12-28 23:47: Train Epoch 8: 151/244 Loss: 0.343796
2022-12-28 23:47: Train Epoch 8: 155/244 Loss: 0.351313
2022-12-28 23:47: Train Epoch 8: 159/244 Loss: 0.360679
2022-12-28 23:48: Train Epoch 8: 163/244 Loss: 0.284581
2022-12-28 23:48: Train Epoch 8: 167/244 Loss: 0.374090
2022-12-28 23:48: Train Epoch 8: 171/244 Loss: 0.323726
2022-12-28 23:48: Train Epoch 8: 175/244 Loss: 0.298319
2022-12-28 23:48: Train Epoch 8: 179/244 Loss: 0.281036
2022-12-28 23:48: Train Epoch 8: 183/244 Loss: 0.318881
2022-12-28 23:48: Train Epoch 8: 187/244 Loss: 0.301968
2022-12-28 23:48: Train Epoch 8: 191/244 Loss: 0.279694
2022-12-28 23:48: Train Epoch 8: 195/244 Loss: 0.277847
2022-12-28 23:48: Train Epoch 8: 199/244 Loss: 0.269002
2022-12-28 23:48: Train Epoch 8: 203/244 Loss: 0.268241
2022-12-28 23:48: Train Epoch 8: 207/244 Loss: 0.202209
2022-12-28 23:48: Train Epoch 8: 211/244 Loss: 0.246369
2022-12-28 23:48: Train Epoch 8: 215/244 Loss: 0.259185
2022-12-28 23:48: Train Epoch 8: 219/244 Loss: 0.239290
2022-12-28 23:49: Train Epoch 8: 223/244 Loss: 0.317424
2022-12-28 23:49: Train Epoch 8: 227/244 Loss: 0.280994
2022-12-28 23:49: Train Epoch 8: 231/244 Loss: 0.249803
2022-12-28 23:49: Train Epoch 8: 235/244 Loss: 0.239629
2022-12-28 23:49: Train Epoch 8: 239/244 Loss: 0.228648
2022-12-28 23:49: Train Epoch 8: 243/244 Loss: 0.297848
2022-12-28 23:49: **********Train Epoch 8: averaged Loss: 0.356404 
2022-12-28 23:49: 
Epoch time elapsed: 251.6183316707611

2022-12-28 23:49: 
 metrics validation: {'precision': 0.7481481481481481, 'recall': 0.38846153846153847, 'f1-score': 0.5113924050632911, 'support': 1300, 'AUC': 0.7965686390532544, 'AUCPR': 0.7055611526229405, 'TP': 505, 'FP': 170, 'TN': 2430, 'FN': 795} 

2022-12-28 23:49: **********Val Epoch 8: average Loss: 0.590995
2022-12-28 23:50: 
 Testing metrics {'precision': 0.8458781362007168, 'recall': 0.19218241042345277, 'f1-score': 0.3132050431320504, 'support': 1228, 'AUC': 0.8535049111926917, 'AUCPR': 0.7649783300220019, 'TP': 236, 'FP': 43, 'TN': 2413, 'FN': 992} 

2022-12-28 23:50: Train Epoch 9: 3/244 Loss: 0.463707
2022-12-28 23:50: Train Epoch 9: 7/244 Loss: 0.464391
2022-12-28 23:50: Train Epoch 9: 11/244 Loss: 0.460571
2022-12-28 23:50: Train Epoch 9: 15/244 Loss: 0.469971
2022-12-28 23:50: Train Epoch 9: 19/244 Loss: 0.422167
2022-12-28 23:50: Train Epoch 9: 23/244 Loss: 0.462027
2022-12-28 23:50: Train Epoch 9: 27/244 Loss: 0.396542
2022-12-28 23:50: Train Epoch 9: 31/244 Loss: 0.453214
2022-12-28 23:50: Train Epoch 9: 35/244 Loss: 0.413408
2022-12-28 23:50: Train Epoch 9: 39/244 Loss: 0.445887
2022-12-28 23:51: Train Epoch 9: 43/244 Loss: 0.411117
2022-12-28 23:51: Train Epoch 9: 47/244 Loss: 0.437579
2022-12-28 23:51: Train Epoch 9: 51/244 Loss: 0.394697
2022-12-28 23:51: Train Epoch 9: 55/244 Loss: 0.397407
2022-12-28 23:51: Train Epoch 9: 59/244 Loss: 0.404952
2022-12-28 23:51: Train Epoch 9: 63/244 Loss: 0.366792
2022-12-28 23:51: Train Epoch 9: 67/244 Loss: 0.389918
2022-12-28 23:51: Train Epoch 9: 71/244 Loss: 0.381032
2022-12-28 23:51: Train Epoch 9: 75/244 Loss: 0.349064
2022-12-28 23:51: Train Epoch 9: 79/244 Loss: 0.360907
2022-12-28 23:51: Train Epoch 9: 83/244 Loss: 0.336094
2022-12-28 23:51: Train Epoch 9: 87/244 Loss: 0.319706
2022-12-28 23:51: Train Epoch 9: 91/244 Loss: 0.329325
2022-12-28 23:51: Train Epoch 9: 95/244 Loss: 0.317500
2022-12-28 23:52: Train Epoch 9: 99/244 Loss: 0.331967
2022-12-28 23:52: Train Epoch 9: 103/244 Loss: 0.338178
2022-12-28 23:52: Train Epoch 9: 107/244 Loss: 0.374580
2022-12-28 23:52: Train Epoch 9: 111/244 Loss: 0.277508
2022-12-28 23:52: Train Epoch 9: 115/244 Loss: 0.289841
2022-12-28 23:52: Train Epoch 9: 119/244 Loss: 0.296895
2022-12-28 23:52: Train Epoch 9: 123/244 Loss: 0.303364
2022-12-28 23:52: Train Epoch 9: 127/244 Loss: 0.342172
2022-12-28 23:52: Train Epoch 9: 131/244 Loss: 0.299897
2022-12-28 23:52: Train Epoch 9: 135/244 Loss: 0.315943
2022-12-28 23:52: Train Epoch 9: 139/244 Loss: 0.288937
2022-12-28 23:52: Train Epoch 9: 143/244 Loss: 0.312935
2022-12-28 23:52: Train Epoch 9: 147/244 Loss: 0.294079
2022-12-28 23:52: Train Epoch 9: 151/244 Loss: 0.336660
2022-12-28 23:53: Train Epoch 9: 155/244 Loss: 0.311345
2022-12-28 23:53: Train Epoch 9: 159/244 Loss: 0.294940
2022-12-28 23:53: Train Epoch 9: 163/244 Loss: 0.308328
2022-12-28 23:53: Train Epoch 9: 167/244 Loss: 0.299885
2022-12-28 23:53: Train Epoch 9: 171/244 Loss: 0.232577
2022-12-28 23:53: Train Epoch 9: 175/244 Loss: 0.294070
2022-12-28 23:53: Train Epoch 9: 179/244 Loss: 0.296805
2022-12-28 23:53: Train Epoch 9: 183/244 Loss: 0.322070
2022-12-28 23:53: Train Epoch 9: 187/244 Loss: 0.276208
2022-12-28 23:53: Train Epoch 9: 191/244 Loss: 0.307053
2022-12-28 23:53: Train Epoch 9: 195/244 Loss: 0.290287
2022-12-28 23:53: Train Epoch 9: 199/244 Loss: 0.281030
2022-12-28 23:53: Train Epoch 9: 203/244 Loss: 0.298523
2022-12-28 23:53: Train Epoch 9: 207/244 Loss: 0.272476
2022-12-28 23:53: Train Epoch 9: 211/244 Loss: 0.261377
2022-12-28 23:54: Train Epoch 9: 215/244 Loss: 0.299852
2022-12-28 23:54: Train Epoch 9: 219/244 Loss: 0.298446
2022-12-28 23:54: Train Epoch 9: 223/244 Loss: 0.275254
2022-12-28 23:54: Train Epoch 9: 227/244 Loss: 0.309482
2022-12-28 23:54: Train Epoch 9: 231/244 Loss: 0.216732
2022-12-28 23:54: Train Epoch 9: 235/244 Loss: 0.246002
2022-12-28 23:54: Train Epoch 9: 239/244 Loss: 0.315988
2022-12-28 23:54: Train Epoch 9: 243/244 Loss: 0.279943
2022-12-28 23:54: **********Train Epoch 9: averaged Loss: 0.338354 
2022-12-28 23:54: 
Epoch time elapsed: 252.19127106666565

2022-12-28 23:54: 
 metrics validation: {'precision': 0.7135593220338983, 'recall': 0.6476923076923077, 'f1-score': 0.6790322580645161, 'support': 1300, 'AUC': 0.797798224852071, 'AUCPR': 0.7083892297607858, 'TP': 842, 'FP': 338, 'TN': 2262, 'FN': 458} 

2022-12-28 23:54: **********Val Epoch 9: average Loss: 0.552628
2022-12-28 23:55: 
 Testing metrics {'precision': 0.8458781362007168, 'recall': 0.19218241042345277, 'f1-score': 0.3132050431320504, 'support': 1228, 'AUC': 0.8535049111926917, 'AUCPR': 0.7649783300220019, 'TP': 236, 'FP': 43, 'TN': 2413, 'FN': 992} 

2022-12-28 23:55: Train Epoch 10: 3/244 Loss: 0.466350
2022-12-28 23:55: Train Epoch 10: 7/244 Loss: 0.425593
2022-12-28 23:55: Train Epoch 10: 11/244 Loss: 0.447914
2022-12-28 23:55: Train Epoch 10: 15/244 Loss: 0.421647
2022-12-28 23:55: Train Epoch 10: 19/244 Loss: 0.415676
2022-12-28 23:55: Train Epoch 10: 23/244 Loss: 0.450492
2022-12-28 23:55: Train Epoch 10: 27/244 Loss: 0.419219
2022-12-28 23:55: Train Epoch 10: 31/244 Loss: 0.429734
2022-12-28 23:55: Train Epoch 10: 35/244 Loss: 0.423513
2022-12-28 23:56: Train Epoch 10: 39/244 Loss: 0.431476
2022-12-28 23:56: Train Epoch 10: 43/244 Loss: 0.444426
2022-12-28 23:56: Train Epoch 10: 47/244 Loss: 0.403794
2022-12-28 23:56: Train Epoch 10: 51/244 Loss: 0.418229
2022-12-28 23:56: Train Epoch 10: 55/244 Loss: 0.431573
2022-12-28 23:56: Train Epoch 10: 59/244 Loss: 0.423529
2022-12-28 23:56: Train Epoch 10: 63/244 Loss: 0.421065
2022-12-28 23:56: Train Epoch 10: 67/244 Loss: 0.364495
2022-12-28 23:56: Train Epoch 10: 71/244 Loss: 0.412535
2022-12-28 23:56: Train Epoch 10: 75/244 Loss: 0.426392
2022-12-28 23:56: Train Epoch 10: 79/244 Loss: 0.391521
2022-12-28 23:56: Train Epoch 10: 83/244 Loss: 0.388254
2022-12-28 23:56: Train Epoch 10: 87/244 Loss: 0.413771
2022-12-28 23:57: Train Epoch 10: 91/244 Loss: 0.357957
2022-12-28 23:57: Train Epoch 10: 95/244 Loss: 0.347159
2022-12-28 23:57: Train Epoch 10: 99/244 Loss: 0.349421
2022-12-28 23:57: Train Epoch 10: 103/244 Loss: 0.343679
2022-12-28 23:57: Train Epoch 10: 107/244 Loss: 0.303002
2022-12-28 23:57: Train Epoch 10: 111/244 Loss: 0.337469
2022-12-28 23:57: Train Epoch 10: 115/244 Loss: 0.333091
2022-12-28 23:57: Train Epoch 10: 119/244 Loss: 0.313213
2022-12-28 23:57: Train Epoch 10: 123/244 Loss: 0.285486
2022-12-28 23:57: Train Epoch 10: 127/244 Loss: 0.284243
2022-12-28 23:57: Train Epoch 10: 131/244 Loss: 0.344640
2022-12-28 23:57: Train Epoch 10: 135/244 Loss: 0.350792
2022-12-28 23:57: Train Epoch 10: 139/244 Loss: 0.278134
2022-12-28 23:57: Train Epoch 10: 143/244 Loss: 0.300616
2022-12-28 23:58: Train Epoch 10: 147/244 Loss: 0.256348
2022-12-28 23:58: Train Epoch 10: 151/244 Loss: 0.265566
2022-12-28 23:58: Train Epoch 10: 155/244 Loss: 0.358214
2022-12-28 23:58: Train Epoch 10: 159/244 Loss: 0.246628
2022-12-28 23:58: Train Epoch 10: 163/244 Loss: 0.279617
2022-12-28 23:58: Train Epoch 10: 167/244 Loss: 0.336982
2022-12-28 23:58: Train Epoch 10: 171/244 Loss: 0.253308
2022-12-28 23:58: Train Epoch 10: 175/244 Loss: 0.354118
2022-12-28 23:58: Train Epoch 10: 179/244 Loss: 0.323071
2022-12-28 23:58: Train Epoch 10: 183/244 Loss: 0.300974
2022-12-28 23:58: Train Epoch 10: 187/244 Loss: 0.326560
2022-12-28 23:58: Train Epoch 10: 191/244 Loss: 0.247725
2022-12-28 23:58: Train Epoch 10: 195/244 Loss: 0.274516
2022-12-28 23:58: Train Epoch 10: 199/244 Loss: 0.279662
2022-12-28 23:59: Train Epoch 10: 203/244 Loss: 0.228306
2022-12-28 23:59: Train Epoch 10: 207/244 Loss: 0.286195
2022-12-28 23:59: Train Epoch 10: 211/244 Loss: 0.278711
2022-12-28 23:59: Train Epoch 10: 215/244 Loss: 0.306946
2022-12-28 23:59: Train Epoch 10: 219/244 Loss: 0.265989
2022-12-28 23:59: Train Epoch 10: 223/244 Loss: 0.252325
2022-12-28 23:59: Train Epoch 10: 227/244 Loss: 0.324347
2022-12-28 23:59: Train Epoch 10: 231/244 Loss: 0.326810
2022-12-28 23:59: Train Epoch 10: 235/244 Loss: 0.249110
2022-12-28 23:59: Train Epoch 10: 239/244 Loss: 0.307788
2022-12-28 23:59: Train Epoch 10: 243/244 Loss: 0.256111
2022-12-28 23:59: **********Train Epoch 10: averaged Loss: 0.344033 
2022-12-28 23:59: 
Epoch time elapsed: 262.43907713890076

2022-12-29 00:00: 
 metrics validation: {'precision': 0.6595900439238653, 'recall': 0.693076923076923, 'f1-score': 0.6759189797449362, 'support': 1300, 'AUC': 0.796819822485207, 'AUCPR': 0.7090690677071083, 'TP': 901, 'FP': 465, 'TN': 2135, 'FN': 399} 

2022-12-29 00:00: **********Val Epoch 10: average Loss: 0.556354
2022-12-29 00:00: 
 Testing metrics {'precision': 0.8458781362007168, 'recall': 0.19218241042345277, 'f1-score': 0.3132050431320504, 'support': 1228, 'AUC': 0.8535049111926917, 'AUCPR': 0.7649783300220019, 'TP': 236, 'FP': 43, 'TN': 2413, 'FN': 992} 

2022-12-29 00:00: Train Epoch 11: 3/244 Loss: 0.446323
2022-12-29 00:00: Train Epoch 11: 7/244 Loss: 0.452088
2022-12-29 00:00: Train Epoch 11: 11/244 Loss: 0.457175
2022-12-29 00:00: Train Epoch 11: 15/244 Loss: 0.426180
2022-12-29 00:00: Train Epoch 11: 19/244 Loss: 0.420174
2022-12-29 00:01: Train Epoch 11: 23/244 Loss: 0.418812
2022-12-29 00:01: Train Epoch 11: 27/244 Loss: 0.452540
2022-12-29 00:01: Train Epoch 11: 31/244 Loss: 0.411260
2022-12-29 00:01: Train Epoch 11: 35/244 Loss: 0.433006
2022-12-29 00:01: Train Epoch 11: 39/244 Loss: 0.425981
2022-12-29 00:01: Train Epoch 11: 43/244 Loss: 0.419025
2022-12-29 00:01: Train Epoch 11: 47/244 Loss: 0.395885
2022-12-29 00:01: Train Epoch 11: 51/244 Loss: 0.419894
2022-12-29 00:01: Train Epoch 11: 55/244 Loss: 0.371240
2022-12-29 00:01: Train Epoch 11: 59/244 Loss: 0.403554
2022-12-29 00:01: Train Epoch 11: 63/244 Loss: 0.379156
2022-12-29 00:01: Train Epoch 11: 67/244 Loss: 0.354076
2022-12-29 00:01: Train Epoch 11: 71/244 Loss: 0.294340
2022-12-29 00:01: Train Epoch 11: 75/244 Loss: 0.388489
2022-12-29 00:02: Train Epoch 11: 79/244 Loss: 0.340282
2022-12-29 00:02: Train Epoch 11: 83/244 Loss: 0.351719
2022-12-29 00:02: Train Epoch 11: 87/244 Loss: 0.371431
2022-12-29 00:02: Train Epoch 11: 91/244 Loss: 0.314213
2022-12-29 00:02: Train Epoch 11: 95/244 Loss: 0.354786
2022-12-29 00:02: Train Epoch 11: 99/244 Loss: 0.304265
2022-12-29 00:02: Train Epoch 11: 103/244 Loss: 0.333743
2022-12-29 00:02: Train Epoch 11: 107/244 Loss: 0.320875
2022-12-29 00:02: Train Epoch 11: 111/244 Loss: 0.304771
2022-12-29 00:02: Train Epoch 11: 115/244 Loss: 0.331025
2022-12-29 00:02: Train Epoch 11: 119/244 Loss: 0.353569
2022-12-29 00:02: Train Epoch 11: 123/244 Loss: 0.306896
2022-12-29 00:02: Train Epoch 11: 127/244 Loss: 0.276264
2022-12-29 00:02: Train Epoch 11: 131/244 Loss: 0.302416
2022-12-29 00:02: Train Epoch 11: 135/244 Loss: 0.294375
2022-12-29 00:03: Train Epoch 11: 139/244 Loss: 0.307860
2022-12-29 00:03: Train Epoch 11: 143/244 Loss: 0.284054
2022-12-29 00:03: Train Epoch 11: 147/244 Loss: 0.245738
2022-12-29 00:03: Train Epoch 11: 151/244 Loss: 0.292088
2022-12-29 00:03: Train Epoch 11: 155/244 Loss: 0.268099
2022-12-29 00:03: Train Epoch 11: 159/244 Loss: 0.325595
2022-12-29 00:03: Train Epoch 11: 163/244 Loss: 0.305865
2022-12-29 00:03: Train Epoch 11: 167/244 Loss: 0.253536
2022-12-29 00:03: Train Epoch 11: 171/244 Loss: 0.332757
2022-12-29 00:03: Train Epoch 11: 175/244 Loss: 0.325186
2022-12-29 00:03: Train Epoch 11: 179/244 Loss: 0.305543
2022-12-29 00:03: Train Epoch 11: 183/244 Loss: 0.314039
2022-12-29 00:03: Train Epoch 11: 187/244 Loss: 0.308133
2022-12-29 00:03: Train Epoch 11: 191/244 Loss: 0.243664
2022-12-29 00:04: Train Epoch 11: 195/244 Loss: 0.263673
2022-12-29 00:04: Train Epoch 11: 199/244 Loss: 0.332494
2022-12-29 00:04: Train Epoch 11: 203/244 Loss: 0.246166
2022-12-29 00:04: Train Epoch 11: 207/244 Loss: 0.253452
2022-12-29 00:04: Train Epoch 11: 211/244 Loss: 0.265721
2022-12-29 00:04: Train Epoch 11: 215/244 Loss: 0.246869
2022-12-29 00:04: Train Epoch 11: 219/244 Loss: 0.415395
2022-12-29 00:04: Train Epoch 11: 223/244 Loss: 0.255435
2022-12-29 00:04: Train Epoch 11: 227/244 Loss: 0.369938
2022-12-29 00:04: Train Epoch 11: 231/244 Loss: 0.276575
2022-12-29 00:04: Train Epoch 11: 235/244 Loss: 0.186837
2022-12-29 00:04: Train Epoch 11: 239/244 Loss: 0.347533
2022-12-29 00:04: Train Epoch 11: 243/244 Loss: 0.254402
2022-12-29 00:04: **********Train Epoch 11: averaged Loss: 0.335352 
2022-12-29 00:04: 
Epoch time elapsed: 260.68853282928467

2022-12-29 00:05: 
 metrics validation: {'precision': 0.6579520697167756, 'recall': 0.696923076923077, 'f1-score': 0.6768771012327233, 'support': 1300, 'AUC': 0.7964106508875739, 'AUCPR': 0.7072775543349236, 'TP': 906, 'FP': 471, 'TN': 2129, 'FN': 394} 

2022-12-29 00:05: **********Val Epoch 11: average Loss: 0.550401
2022-12-29 00:05: Validation performance didn't improve for 8 epochs. Training stops.
2022-12-29 00:05: Total training time: 56.8149min, best loss: 0.547200
2022-12-29 00:05: Saving current best model to /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122823083362246469118/best_model.pth
2022-12-29 00:05: 
 Testing metrics {'precision': 0.8458781362007168, 'recall': 0.19218241042345277, 'f1-score': 0.3132050431320504, 'support': 1228, 'AUC': 0.8535049111926917, 'AUCPR': 0.7649783300220019, 'TP': 236, 'FP': 43, 'TN': 2413, 'FN': 992} 

