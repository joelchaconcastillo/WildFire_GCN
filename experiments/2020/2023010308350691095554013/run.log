2023-01-03 08:35: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010308350691095554013
2023-01-03 08:35: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010308350691095554013
2023-01-03 08:35: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010308350691095554013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=2, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=32, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-03 08:35: Argument batch_size: 256
2023-01-03 08:35: Argument clc: 'vec'
2023-01-03 08:35: Argument cuda: True
2023-01-03 08:35: Argument dataset: '2020'
2023-01-03 08:35: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-03 08:35: Argument debug: False
2023-01-03 08:35: Argument default_graph: True
2023-01-03 08:35: Argument device: 'cpu'
2023-01-03 08:35: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-03 08:35: Argument early_stop: True
2023-01-03 08:35: Argument early_stop_patience: 8
2023-01-03 08:35: Argument embed_dim: 64
2023-01-03 08:35: Argument epochs: 30
2023-01-03 08:35: Argument grad_norm: False
2023-01-03 08:35: Argument horizon: 1
2023-01-03 08:35: Argument input_dim: 25
2023-01-03 08:35: Argument lag: 10
2023-01-03 08:35: Argument link_len: 2
2023-01-03 08:35: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010308350691095554013'
2023-01-03 08:35: Argument log_step: 1
2023-01-03 08:35: Argument loss_func: 'nllloss'
2023-01-03 08:35: Argument lr_decay: True
2023-01-03 08:35: Argument lr_decay_rate: 0.1
2023-01-03 08:35: Argument lr_decay_step: '15'
2023-01-03 08:35: Argument lr_init: 0.0001
2023-01-03 08:35: Argument max_grad_norm: 5
2023-01-03 08:35: Argument minbatch_size: 64
2023-01-03 08:35: Argument mode: 'train'
2023-01-03 08:35: Argument model: 'fire_GCN'
2023-01-03 08:35: Argument nan_fill: -1.0
2023-01-03 08:35: Argument num_layers: 2
2023-01-03 08:35: Argument num_nodes: 625
2023-01-03 08:35: Argument num_workers: 12
2023-01-03 08:35: Argument output_dim: 2
2023-01-03 08:35: Argument patch_height: 25
2023-01-03 08:35: Argument patch_width: 25
2023-01-03 08:35: Argument persistent_workers: True
2023-01-03 08:35: Argument pin_memory: True
2023-01-03 08:35: Argument plot: False
2023-01-03 08:35: Argument positive_weight: 0.5
2023-01-03 08:35: Argument prefetch_factor: 2
2023-01-03 08:35: Argument real_value: True
2023-01-03 08:35: Argument rnn_units: 32
2023-01-03 08:35: Argument seed: 10000
2023-01-03 08:35: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-03 08:35: Argument teacher_forcing: False
2023-01-03 08:35: Argument weight_decay: 0.0
2023-01-03 08:35: Argument window_len: 10
2023-01-03 08:35: Train Epoch 1: 3/634 Loss: 0.381273
2023-01-03 08:35: Train Epoch 1: 7/634 Loss: 0.694171
2023-01-03 08:36: Train Epoch 1: 11/634 Loss: 0.405180
2023-01-03 08:36: Train Epoch 1: 15/634 Loss: 0.297008
2023-01-03 08:36: Train Epoch 1: 19/634 Loss: 0.441488
2023-01-03 08:37: Train Epoch 1: 23/634 Loss: 0.439463
2023-01-03 08:37: Train Epoch 1: 27/634 Loss: 0.290152
2023-01-03 08:37: Train Epoch 1: 31/634 Loss: 0.243348
2023-01-03 08:38: Train Epoch 1: 35/634 Loss: 0.258262
2023-01-03 08:38: Train Epoch 1: 39/634 Loss: 0.294121
2023-01-03 08:38: Train Epoch 1: 43/634 Loss: 0.252106
2023-01-03 08:39: Train Epoch 1: 47/634 Loss: 0.287439
2023-01-03 08:39: Train Epoch 1: 51/634 Loss: 0.252320
2023-01-03 08:39: Train Epoch 1: 55/634 Loss: 0.198349
2023-01-03 08:39: Train Epoch 1: 59/634 Loss: 0.255369
2023-01-03 08:40: Train Epoch 1: 63/634 Loss: 0.274198
2023-01-03 08:40: Train Epoch 1: 67/634 Loss: 0.236333
2023-01-03 08:40: Train Epoch 1: 71/634 Loss: 0.227362
2023-01-03 08:41: Train Epoch 1: 75/634 Loss: 0.216995
2023-01-03 08:41: Train Epoch 1: 79/634 Loss: 0.192750
2023-01-03 08:42: Train Epoch 1: 83/634 Loss: 0.226389
2023-01-03 08:42: Train Epoch 1: 87/634 Loss: 0.249243
2023-01-03 08:43: Train Epoch 1: 91/634 Loss: 0.239216
2023-01-03 08:43: Train Epoch 1: 95/634 Loss: 0.241606
2023-01-03 08:43: Train Epoch 1: 99/634 Loss: 0.195353
2023-01-03 08:44: Train Epoch 1: 103/634 Loss: 0.198136
2023-01-03 08:44: Train Epoch 1: 107/634 Loss: 0.255756
2023-01-03 08:45: Train Epoch 1: 111/634 Loss: 0.245212
2023-01-03 08:45: Train Epoch 1: 115/634 Loss: 0.220618
2023-01-03 08:46: Train Epoch 1: 119/634 Loss: 0.226632
2023-01-03 08:46: Train Epoch 1: 123/634 Loss: 0.234619
2023-01-03 08:47: Train Epoch 1: 127/634 Loss: 0.250398
2023-01-03 08:47: Train Epoch 1: 131/634 Loss: 0.187943
2023-01-03 08:47: Train Epoch 1: 135/634 Loss: 0.232340
2023-01-03 08:47: Train Epoch 1: 139/634 Loss: 0.213160
2023-01-03 08:48: Train Epoch 1: 143/634 Loss: 0.264387
2023-01-03 08:48: Train Epoch 1: 147/634 Loss: 0.213951
2023-01-03 08:48: Train Epoch 1: 151/634 Loss: 0.237101
2023-01-03 08:49: Train Epoch 1: 155/634 Loss: 0.224424
2023-01-03 08:49: Train Epoch 1: 159/634 Loss: 0.219713
2023-01-03 08:49: Train Epoch 1: 163/634 Loss: 0.233113
2023-01-03 08:50: Train Epoch 1: 167/634 Loss: 0.227844
2023-01-03 08:50: Train Epoch 1: 171/634 Loss: 0.252347
2023-01-03 08:50: Train Epoch 1: 175/634 Loss: 0.190548
2023-01-03 08:51: Train Epoch 1: 179/634 Loss: 0.209286
2023-01-03 08:51: Train Epoch 1: 183/634 Loss: 0.201074
2023-01-03 08:51: Train Epoch 1: 187/634 Loss: 0.224374
2023-01-03 08:52: Train Epoch 1: 191/634 Loss: 0.226451
2023-01-03 08:52: Train Epoch 1: 195/634 Loss: 0.216614
2023-01-03 08:52: Train Epoch 1: 199/634 Loss: 0.187395
2023-01-03 08:53: Train Epoch 1: 203/634 Loss: 0.194177
2023-01-03 08:53: Train Epoch 1: 207/634 Loss: 0.223482
2023-01-03 08:53: Train Epoch 1: 211/634 Loss: 0.230253
2023-01-03 08:54: Train Epoch 1: 215/634 Loss: 0.202635
2023-01-03 08:54: Train Epoch 1: 219/634 Loss: 0.210124
2023-01-03 08:54: Train Epoch 1: 223/634 Loss: 0.195174
2023-01-03 08:54: Train Epoch 1: 227/634 Loss: 0.193405
2023-01-03 08:55: Train Epoch 1: 231/634 Loss: 0.227558
2023-01-03 08:55: Train Epoch 1: 235/634 Loss: 0.209201
2023-01-03 08:55: Train Epoch 1: 239/634 Loss: 0.190643
2023-01-03 08:56: Train Epoch 1: 243/634 Loss: 0.217752
2023-01-03 08:56: Train Epoch 1: 247/634 Loss: 0.199352
2023-01-03 08:56: Train Epoch 1: 251/634 Loss: 0.206837
2023-01-03 08:57: Train Epoch 1: 255/634 Loss: 0.206595
2023-01-03 08:57: Train Epoch 1: 259/634 Loss: 0.199382
2023-01-03 08:57: Train Epoch 1: 263/634 Loss: 0.210786
2023-01-03 08:58: Train Epoch 1: 267/634 Loss: 0.217711
2023-01-03 08:58: Train Epoch 1: 271/634 Loss: 0.231455
2023-01-03 08:58: Train Epoch 1: 275/634 Loss: 0.179915
2023-01-03 08:58: Train Epoch 1: 279/634 Loss: 0.222695
2023-01-03 08:59: Train Epoch 1: 283/634 Loss: 0.176500
2023-01-03 08:59: Train Epoch 1: 287/634 Loss: 0.202648
2023-01-03 08:59: Train Epoch 1: 291/634 Loss: 0.202845
2023-01-03 09:00: Train Epoch 1: 295/634 Loss: 0.217478
2023-01-03 09:00: Train Epoch 1: 299/634 Loss: 0.207713
2023-01-03 09:00: Train Epoch 1: 303/634 Loss: 0.206839
2023-01-03 09:01: Train Epoch 1: 307/634 Loss: 0.198568
2023-01-03 09:01: Train Epoch 1: 311/634 Loss: 0.212228
2023-01-03 09:02: Train Epoch 1: 315/634 Loss: 0.196907
2023-01-03 09:02: Train Epoch 1: 319/634 Loss: 0.208867
2023-01-03 09:02: Train Epoch 1: 323/634 Loss: 0.199095
2023-01-03 09:03: Train Epoch 1: 327/634 Loss: 0.183735
2023-01-03 09:03: Train Epoch 1: 331/634 Loss: 0.203709
2023-01-03 09:03: Train Epoch 1: 335/634 Loss: 0.224047
2023-01-03 09:03: Train Epoch 1: 339/634 Loss: 0.186160
2023-01-03 09:04: Train Epoch 1: 343/634 Loss: 0.202330
2023-01-03 09:04: Train Epoch 1: 347/634 Loss: 0.198412
2023-01-03 09:04: Train Epoch 1: 351/634 Loss: 0.205506
2023-01-03 09:05: Train Epoch 1: 355/634 Loss: 0.191045
2023-01-03 09:05: Train Epoch 1: 359/634 Loss: 0.180035
2023-01-03 09:05: Train Epoch 1: 363/634 Loss: 0.179506
2023-01-03 09:06: Train Epoch 1: 367/634 Loss: 0.177172
2023-01-03 09:06: Train Epoch 1: 371/634 Loss: 0.204305
2023-01-03 09:06: Train Epoch 1: 375/634 Loss: 0.179030
2023-01-03 09:07: Train Epoch 1: 379/634 Loss: 0.214950
2023-01-03 09:07: Train Epoch 1: 383/634 Loss: 0.217629
2023-01-03 09:07: Train Epoch 1: 387/634 Loss: 0.231880
2023-01-03 09:08: Train Epoch 1: 391/634 Loss: 0.215464
2023-01-03 09:08: Train Epoch 1: 395/634 Loss: 0.250322
2023-01-03 09:08: Train Epoch 1: 399/634 Loss: 0.180990
2023-01-03 09:09: Train Epoch 1: 403/634 Loss: 0.230676
2023-01-03 09:09: Train Epoch 1: 407/634 Loss: 0.203125
2023-01-03 09:09: Train Epoch 1: 411/634 Loss: 0.214249
2023-01-03 09:10: Train Epoch 1: 415/634 Loss: 0.202530
2023-01-03 09:10: Train Epoch 1: 419/634 Loss: 0.181205
2023-01-03 09:10: Train Epoch 1: 423/634 Loss: 0.208236
2023-01-03 09:11: Train Epoch 1: 427/634 Loss: 0.212293
2023-01-03 09:11: Train Epoch 1: 431/634 Loss: 0.213807
2023-01-03 09:11: Train Epoch 1: 435/634 Loss: 0.248300
2023-01-03 09:12: Train Epoch 1: 439/634 Loss: 0.191592
2023-01-03 09:12: Train Epoch 1: 443/634 Loss: 0.224490
2023-01-03 09:12: Train Epoch 1: 447/634 Loss: 0.223921
2023-01-03 09:13: Train Epoch 1: 451/634 Loss: 0.207768
2023-01-03 09:13: Train Epoch 1: 455/634 Loss: 0.294264
2023-01-03 09:13: Train Epoch 1: 459/634 Loss: 0.207567
2023-01-03 09:14: Train Epoch 1: 463/634 Loss: 0.204002
2023-01-03 09:14: Train Epoch 1: 467/634 Loss: 0.204816
2023-01-03 09:14: Train Epoch 1: 471/634 Loss: 0.189727
2023-01-03 09:15: Train Epoch 1: 475/634 Loss: 0.200041
2023-01-03 09:15: Train Epoch 1: 479/634 Loss: 0.193779
2023-01-03 09:15: Train Epoch 1: 483/634 Loss: 0.169403
2023-01-03 09:15: Train Epoch 1: 487/634 Loss: 0.187194
2023-01-03 09:16: Train Epoch 1: 491/634 Loss: 0.206022
2023-01-03 09:16: Train Epoch 1: 495/634 Loss: 0.213554
2023-01-03 09:16: Train Epoch 1: 499/634 Loss: 0.208675
2023-01-03 09:17: Train Epoch 1: 503/634 Loss: 0.203262
2023-01-03 09:17: Train Epoch 1: 507/634 Loss: 0.194849
2023-01-03 09:17: Train Epoch 1: 511/634 Loss: 0.200539
2023-01-03 09:18: Train Epoch 1: 515/634 Loss: 0.204352
2023-01-03 09:18: Train Epoch 1: 519/634 Loss: 0.200827
2023-01-03 09:18: Train Epoch 1: 523/634 Loss: 0.217777
2023-01-03 09:19: Train Epoch 1: 527/634 Loss: 0.187075
2023-01-03 09:19: Train Epoch 1: 531/634 Loss: 0.185851
2023-01-03 09:19: Train Epoch 1: 535/634 Loss: 0.196976
2023-01-03 09:20: Train Epoch 1: 539/634 Loss: 0.213665
2023-01-03 09:20: Train Epoch 1: 543/634 Loss: 0.212565
2023-01-03 09:20: Train Epoch 1: 547/634 Loss: 0.182057
2023-01-03 09:21: Train Epoch 1: 551/634 Loss: 0.216091
2023-01-03 09:21: Train Epoch 1: 555/634 Loss: 0.188836
2023-01-03 09:21: Train Epoch 1: 559/634 Loss: 0.228933
2023-01-03 09:22: Train Epoch 1: 563/634 Loss: 0.222348
2023-01-03 09:22: Train Epoch 1: 567/634 Loss: 0.206837
2023-01-03 09:22: Train Epoch 1: 571/634 Loss: 0.190397
2023-01-03 09:23: Train Epoch 1: 575/634 Loss: 0.193285
2023-01-03 09:23: Train Epoch 1: 579/634 Loss: 0.182168
2023-01-03 09:23: Train Epoch 1: 583/634 Loss: 0.185947
2023-01-03 09:24: Train Epoch 1: 587/634 Loss: 0.192377
2023-01-03 09:24: Train Epoch 1: 591/634 Loss: 0.187082
2023-01-03 09:24: Train Epoch 1: 595/634 Loss: 0.177136
2023-01-03 09:25: Train Epoch 1: 599/634 Loss: 0.227812
2023-01-03 09:25: Train Epoch 1: 603/634 Loss: 0.186608
2023-01-03 09:25: Train Epoch 1: 607/634 Loss: 0.186030
2023-01-03 09:25: Train Epoch 1: 611/634 Loss: 0.196627
2023-01-03 09:26: Train Epoch 1: 615/634 Loss: 0.173759
2023-01-03 09:26: Train Epoch 1: 619/634 Loss: 0.204266
2023-01-03 09:26: Train Epoch 1: 623/634 Loss: 0.209533
2023-01-03 09:27: Train Epoch 1: 627/634 Loss: 0.204676
2023-01-03 09:27: Train Epoch 1: 631/634 Loss: 0.199872
2023-01-03 09:27: Train Epoch 1: 633/634 Loss: 0.086443
2023-01-03 09:27: **********Train Epoch 1: averaged Loss: 0.220101 
2023-01-03 09:27: 
Epoch time elapsed: 3154.1091437339783

2023-01-03 09:29: 
 metrics validation: {'precision': 0.7302573203194321, 'recall': 0.6330769230769231, 'f1-score': 0.6782035434693037, 'support': 1300, 'AUC': 0.8337532544378697, 'AUCPR': 0.7490226047570501, 'TP': 823, 'FP': 304, 'TN': 2296, 'FN': 477} 

2023-01-03 09:29: **********Val Epoch 1: average Loss: 0.234868
2023-01-03 09:29: *********************************Current best model saved!
2023-01-03 09:30: 
 Testing metrics {'precision': 0.783756345177665, 'recall': 0.6286644951140065, 'f1-score': 0.6976954360596476, 'support': 1228, 'AUC': 0.8665881070356185, 'AUCPR': 0.7982672106769758, 'TP': 772, 'FP': 213, 'TN': 2243, 'FN': 456} 

2023-01-03 09:36: 
 Testing metrics {'precision': 0.9010989010989011, 'recall': 0.8931245745405038, 'f1-score': 0.8970940170940171, 'support': 4407, 'AUC': 0.9703618369377389, 'AUCPR': 0.9415096506639175, 'TP': 3936, 'FP': 432, 'TN': 8382, 'FN': 471} 

2023-01-03 09:36: Train Epoch 2: 3/634 Loss: 0.159757
2023-01-03 09:36: Train Epoch 2: 7/634 Loss: 0.180077
2023-01-03 09:37: Train Epoch 2: 11/634 Loss: 0.173823
2023-01-03 09:37: Train Epoch 2: 15/634 Loss: 0.181926
2023-01-03 09:37: Train Epoch 2: 19/634 Loss: 0.192407
2023-01-03 09:38: Train Epoch 2: 23/634 Loss: 0.183453
2023-01-03 09:38: Train Epoch 2: 27/634 Loss: 0.188762
2023-01-03 09:38: Train Epoch 2: 31/634 Loss: 0.203099
2023-01-03 09:38: Train Epoch 2: 35/634 Loss: 0.206485
2023-01-03 09:39: Train Epoch 2: 39/634 Loss: 0.224859
2023-01-03 09:39: Train Epoch 2: 43/634 Loss: 0.198890
2023-01-03 09:39: Train Epoch 2: 47/634 Loss: 0.221131
2023-01-03 09:40: Train Epoch 2: 51/634 Loss: 0.248778
2023-01-03 09:40: Train Epoch 2: 55/634 Loss: 0.182581
2023-01-03 09:41: Train Epoch 2: 59/634 Loss: 0.244277
2023-01-03 09:41: Train Epoch 2: 63/634 Loss: 0.222931
2023-01-03 09:41: Train Epoch 2: 67/634 Loss: 0.180192
2023-01-03 09:42: Train Epoch 2: 71/634 Loss: 0.237357
2023-01-03 09:42: Train Epoch 2: 75/634 Loss: 0.211349
2023-01-03 09:42: Train Epoch 2: 79/634 Loss: 0.197200
2023-01-03 09:42: Train Epoch 2: 83/634 Loss: 0.184903
2023-01-03 09:43: Train Epoch 2: 87/634 Loss: 0.196663
2023-01-03 09:43: Train Epoch 2: 91/634 Loss: 0.196683
2023-01-03 09:43: Train Epoch 2: 95/634 Loss: 0.165053
2023-01-03 09:44: Train Epoch 2: 99/634 Loss: 0.198923
2023-01-03 09:44: Train Epoch 2: 103/634 Loss: 0.200354
2023-01-03 09:44: Train Epoch 2: 107/634 Loss: 0.191050
2023-01-03 09:45: Train Epoch 2: 111/634 Loss: 0.224385
2023-01-03 09:45: Train Epoch 2: 115/634 Loss: 0.176939
2023-01-03 09:45: Train Epoch 2: 119/634 Loss: 0.209001
2023-01-03 09:46: Train Epoch 2: 123/634 Loss: 0.213727
2023-01-03 09:46: Train Epoch 2: 127/634 Loss: 0.190151
2023-01-03 09:46: Train Epoch 2: 131/634 Loss: 0.216122
2023-01-03 09:46: Train Epoch 2: 135/634 Loss: 0.171939
2023-01-03 09:47: Train Epoch 2: 139/634 Loss: 0.188086
2023-01-03 09:47: Train Epoch 2: 143/634 Loss: 0.205760
2023-01-03 09:47: Train Epoch 2: 147/634 Loss: 0.209640
2023-01-03 09:48: Train Epoch 2: 151/634 Loss: 0.195415
2023-01-03 09:48: Train Epoch 2: 155/634 Loss: 0.221159
2023-01-03 09:48: Train Epoch 2: 159/634 Loss: 0.194050
2023-01-03 09:49: Train Epoch 2: 163/634 Loss: 0.195841
2023-01-03 09:49: Train Epoch 2: 167/634 Loss: 0.221439
2023-01-03 09:49: Train Epoch 2: 171/634 Loss: 0.231975
2023-01-03 09:50: Train Epoch 2: 175/634 Loss: 0.180360
2023-01-03 09:50: Train Epoch 2: 179/634 Loss: 0.227363
2023-01-03 09:50: Train Epoch 2: 183/634 Loss: 0.216332
2023-01-03 09:51: Train Epoch 2: 187/634 Loss: 0.176202
2023-01-03 09:51: Train Epoch 2: 191/634 Loss: 0.219023
2023-01-03 09:51: Train Epoch 2: 195/634 Loss: 0.200397
2023-01-03 09:52: Train Epoch 2: 199/634 Loss: 0.190966
2023-01-03 09:52: Train Epoch 2: 203/634 Loss: 0.212303
2023-01-03 09:52: Train Epoch 2: 207/634 Loss: 0.174673
2023-01-03 09:52: Train Epoch 2: 211/634 Loss: 0.172119
2023-01-03 09:53: Train Epoch 2: 215/634 Loss: 0.213084
2023-01-03 09:53: Train Epoch 2: 219/634 Loss: 0.191046
2023-01-03 09:53: Train Epoch 2: 223/634 Loss: 0.192793
2023-01-03 09:54: Train Epoch 2: 227/634 Loss: 0.180040
2023-01-03 09:54: Train Epoch 2: 231/634 Loss: 0.171936
2023-01-03 09:54: Train Epoch 2: 235/634 Loss: 0.201643
2023-01-03 09:55: Train Epoch 2: 239/634 Loss: 0.186715
2023-01-03 09:55: Train Epoch 2: 243/634 Loss: 0.217612
2023-01-03 09:55: Train Epoch 2: 247/634 Loss: 0.180240
2023-01-03 09:56: Train Epoch 2: 251/634 Loss: 0.194251
2023-01-03 09:56: Train Epoch 2: 255/634 Loss: 0.199405
2023-01-03 09:56: Train Epoch 2: 259/634 Loss: 0.176169
2023-01-03 09:57: Train Epoch 2: 263/634 Loss: 0.197346
2023-01-03 09:57: Train Epoch 2: 267/634 Loss: 0.210584
2023-01-03 09:57: Train Epoch 2: 271/634 Loss: 0.192199
2023-01-03 09:57: Train Epoch 2: 275/634 Loss: 0.189580
2023-01-03 09:58: Train Epoch 2: 279/634 Loss: 0.190142
2023-01-03 09:58: Train Epoch 2: 283/634 Loss: 0.195456
2023-01-03 09:58: Train Epoch 2: 287/634 Loss: 0.205559
2023-01-03 09:59: Train Epoch 2: 291/634 Loss: 0.206585
2023-01-03 09:59: Train Epoch 2: 295/634 Loss: 0.164489
2023-01-03 09:59: Train Epoch 2: 299/634 Loss: 0.197980
2023-01-03 10:00: Train Epoch 2: 303/634 Loss: 0.202058
2023-01-03 10:00: Train Epoch 2: 307/634 Loss: 0.191043
2023-01-03 10:00: Train Epoch 2: 311/634 Loss: 0.190717
2023-01-03 10:01: Train Epoch 2: 315/634 Loss: 0.168864
2023-01-03 10:01: Train Epoch 2: 319/634 Loss: 0.193885
2023-01-03 10:01: Train Epoch 2: 323/634 Loss: 0.191089
2023-01-03 10:02: Train Epoch 2: 327/634 Loss: 0.157538
2023-01-03 10:02: Train Epoch 2: 331/634 Loss: 0.212584
2023-01-03 10:02: Train Epoch 2: 335/634 Loss: 0.227909
2023-01-03 10:03: Train Epoch 2: 339/634 Loss: 0.227452
2023-01-03 10:03: Train Epoch 2: 343/634 Loss: 0.242807
2023-01-03 10:03: Train Epoch 2: 347/634 Loss: 0.194917
2023-01-03 10:04: Train Epoch 2: 351/634 Loss: 0.256643
2023-01-03 10:04: Train Epoch 2: 355/634 Loss: 0.187477
2023-01-03 10:04: Train Epoch 2: 359/634 Loss: 0.186678
2023-01-03 10:04: Train Epoch 2: 363/634 Loss: 0.217131
2023-01-03 10:05: Train Epoch 2: 367/634 Loss: 0.207503
2023-01-03 10:05: Train Epoch 2: 371/634 Loss: 0.187862
2023-01-03 10:05: Train Epoch 2: 375/634 Loss: 0.188139
2023-01-03 10:06: Train Epoch 2: 379/634 Loss: 0.222485
2023-01-03 10:06: Train Epoch 2: 383/634 Loss: 0.198379
2023-01-03 10:06: Train Epoch 2: 387/634 Loss: 0.271026
2023-01-03 10:07: Train Epoch 2: 391/634 Loss: 0.164990
2023-01-03 10:07: Train Epoch 2: 395/634 Loss: 0.164154
2023-01-03 10:07: Train Epoch 2: 399/634 Loss: 0.235522
2023-01-03 10:08: Train Epoch 2: 403/634 Loss: 0.191542
2023-01-03 10:08: Train Epoch 2: 407/634 Loss: 0.170935
2023-01-03 10:08: Train Epoch 2: 411/634 Loss: 0.205560
2023-01-03 10:09: Train Epoch 2: 415/634 Loss: 0.208885
2023-01-03 10:09: Train Epoch 2: 419/634 Loss: 0.194594
2023-01-03 10:09: Train Epoch 2: 423/634 Loss: 0.257567
2023-01-03 10:10: Train Epoch 2: 427/634 Loss: 0.194620
2023-01-03 10:10: Train Epoch 2: 431/634 Loss: 0.183447
2023-01-03 10:10: Train Epoch 2: 435/634 Loss: 0.209576
2023-01-03 10:11: Train Epoch 2: 439/634 Loss: 0.175674
2023-01-03 10:11: Train Epoch 2: 443/634 Loss: 0.170931
2023-01-03 10:11: Train Epoch 2: 447/634 Loss: 0.232420
2023-01-03 10:12: Train Epoch 2: 451/634 Loss: 0.176009
2023-01-03 10:12: Train Epoch 2: 455/634 Loss: 0.180552
2023-01-03 10:12: Train Epoch 2: 459/634 Loss: 0.200218
2023-01-03 10:13: Train Epoch 2: 463/634 Loss: 0.169815
2023-01-03 10:13: Train Epoch 2: 467/634 Loss: 0.206688
2023-01-03 10:13: Train Epoch 2: 471/634 Loss: 0.196549
2023-01-03 10:13: Train Epoch 2: 475/634 Loss: 0.189551
2023-01-03 10:14: Train Epoch 2: 479/634 Loss: 0.222520
2023-01-03 10:14: Train Epoch 2: 483/634 Loss: 0.198533
2023-01-03 10:15: Train Epoch 2: 487/634 Loss: 0.217454
2023-01-03 10:15: Train Epoch 2: 491/634 Loss: 0.186949
2023-01-03 10:16: Train Epoch 2: 495/634 Loss: 0.197644
2023-01-03 10:16: Train Epoch 2: 499/634 Loss: 0.171978
2023-01-03 10:17: Train Epoch 2: 503/634 Loss: 0.183909
2023-01-03 10:17: Train Epoch 2: 507/634 Loss: 0.183356
2023-01-03 10:17: Train Epoch 2: 511/634 Loss: 0.192409
2023-01-03 10:18: Train Epoch 2: 515/634 Loss: 0.185492
2023-01-03 10:18: Train Epoch 2: 519/634 Loss: 0.192944
2023-01-03 10:19: Train Epoch 2: 523/634 Loss: 0.183571
2023-01-03 10:19: Train Epoch 2: 527/634 Loss: 0.209563
2023-01-03 10:19: Train Epoch 2: 531/634 Loss: 0.182407
2023-01-03 10:20: Train Epoch 2: 535/634 Loss: 0.161377
2023-01-03 10:20: Train Epoch 2: 539/634 Loss: 0.209532
2023-01-03 10:21: Train Epoch 2: 543/634 Loss: 0.197033
2023-01-03 10:21: Train Epoch 2: 547/634 Loss: 0.207777
2023-01-03 10:21: Train Epoch 2: 551/634 Loss: 0.198303
2023-01-03 10:22: Train Epoch 2: 555/634 Loss: 0.174538
2023-01-03 10:22: Train Epoch 2: 559/634 Loss: 0.237271
2023-01-03 10:22: Train Epoch 2: 563/634 Loss: 0.201561
2023-01-03 10:22: Train Epoch 2: 567/634 Loss: 0.207998
2023-01-03 10:23: Train Epoch 2: 571/634 Loss: 0.177954
2023-01-03 10:23: Train Epoch 2: 575/634 Loss: 0.218818
2023-01-03 10:23: Train Epoch 2: 579/634 Loss: 0.180943
2023-01-03 10:24: Train Epoch 2: 583/634 Loss: 0.174993
2023-01-03 10:24: Train Epoch 2: 587/634 Loss: 0.162747
2023-01-03 10:24: Train Epoch 2: 591/634 Loss: 0.176910
2023-01-03 10:25: Train Epoch 2: 595/634 Loss: 0.208267
2023-01-03 10:25: Train Epoch 2: 599/634 Loss: 0.178273
2023-01-03 10:25: Train Epoch 2: 603/634 Loss: 0.170305
2023-01-03 10:26: Train Epoch 2: 607/634 Loss: 0.193145
2023-01-03 10:26: Train Epoch 2: 611/634 Loss: 0.188376
2023-01-03 10:26: Train Epoch 2: 615/634 Loss: 0.162574
2023-01-03 10:26: Train Epoch 2: 619/634 Loss: 0.187086
2023-01-03 10:27: Train Epoch 2: 623/634 Loss: 0.154144
2023-01-03 10:27: Train Epoch 2: 627/634 Loss: 0.182329
2023-01-03 10:27: Train Epoch 2: 631/634 Loss: 0.205886
2023-01-03 10:27: Train Epoch 2: 633/634 Loss: 0.091318
2023-01-03 10:27: **********Train Epoch 2: averaged Loss: 0.196134 
2023-01-03 10:27: 
Epoch time elapsed: 3112.8969779014587

2023-01-03 10:29: 
 metrics validation: {'precision': 0.7457912457912458, 'recall': 0.6815384615384615, 'f1-score': 0.7122186495176849, 'support': 1300, 'AUC': 0.86265325443787, 'AUCPR': 0.7823473690946279, 'TP': 886, 'FP': 302, 'TN': 2298, 'FN': 414} 

2023-01-03 10:29: **********Val Epoch 2: average Loss: 0.213477
2023-01-03 10:29: *********************************Current best model saved!
2023-01-03 10:30: 
 Testing metrics {'precision': 0.7894736842105263, 'recall': 0.6596091205211726, 'f1-score': 0.7187222715173026, 'support': 1228, 'AUC': 0.8816469538138335, 'AUCPR': 0.8150364556951435, 'TP': 810, 'FP': 216, 'TN': 2240, 'FN': 418} 

2023-01-03 10:35: 
 Testing metrics {'precision': 0.8977272727272727, 'recall': 0.8963013387792149, 'f1-score': 0.8970137390711933, 'support': 4407, 'AUC': 0.9713902640295886, 'AUCPR': 0.944121267768684, 'TP': 3950, 'FP': 450, 'TN': 8364, 'FN': 457} 

2023-01-03 10:36: Train Epoch 3: 3/634 Loss: 0.181998
2023-01-03 10:36: Train Epoch 3: 7/634 Loss: 0.178398
2023-01-03 10:36: Train Epoch 3: 11/634 Loss: 0.191425
2023-01-03 10:37: Train Epoch 3: 15/634 Loss: 0.178934
2023-01-03 10:37: Train Epoch 3: 19/634 Loss: 0.157696
2023-01-03 10:37: Train Epoch 3: 23/634 Loss: 0.156867
2023-01-03 10:37: Train Epoch 3: 27/634 Loss: 0.179668
2023-01-03 10:38: Train Epoch 3: 31/634 Loss: 0.171864
2023-01-03 10:38: Train Epoch 3: 35/634 Loss: 0.205120
2023-01-03 10:38: Train Epoch 3: 39/634 Loss: 0.164416
2023-01-03 10:39: Train Epoch 3: 43/634 Loss: 0.189761
2023-01-03 10:39: Train Epoch 3: 47/634 Loss: 0.210071
2023-01-03 10:39: Train Epoch 3: 51/634 Loss: 0.180806
2023-01-03 10:39: Train Epoch 3: 55/634 Loss: 0.177568
2023-01-03 10:40: Train Epoch 3: 59/634 Loss: 0.213529
2023-01-03 10:40: Train Epoch 3: 63/634 Loss: 0.183361
2023-01-03 10:41: Train Epoch 3: 67/634 Loss: 0.167367
2023-01-03 10:41: Train Epoch 3: 71/634 Loss: 0.172064
2023-01-03 10:41: Train Epoch 3: 75/634 Loss: 0.171443
2023-01-03 10:41: Train Epoch 3: 79/634 Loss: 0.171385
2023-01-03 10:42: Train Epoch 3: 83/634 Loss: 0.195870
2023-01-03 10:42: Train Epoch 3: 87/634 Loss: 0.180805
2023-01-03 10:42: Train Epoch 3: 91/634 Loss: 0.170855
2023-01-03 10:43: Train Epoch 3: 95/634 Loss: 0.170782
2023-01-03 10:43: Train Epoch 3: 99/634 Loss: 0.186502
2023-01-03 10:43: Train Epoch 3: 103/634 Loss: 0.180357
2023-01-03 10:44: Train Epoch 3: 107/634 Loss: 0.223409
2023-01-03 10:44: Train Epoch 3: 111/634 Loss: 0.211792
2023-01-03 10:44: Train Epoch 3: 115/634 Loss: 0.186669
2023-01-03 10:44: Train Epoch 3: 119/634 Loss: 0.158977
2023-01-03 10:45: Train Epoch 3: 123/634 Loss: 0.171083
2023-01-03 10:45: Train Epoch 3: 127/634 Loss: 0.196494
2023-01-03 10:45: Train Epoch 3: 131/634 Loss: 0.200343
2023-01-03 10:46: Train Epoch 3: 135/634 Loss: 0.193583
2023-01-03 10:46: Train Epoch 3: 139/634 Loss: 0.227456
2023-01-03 10:46: Train Epoch 3: 143/634 Loss: 0.175171
2023-01-03 10:47: Train Epoch 3: 147/634 Loss: 0.204904
2023-01-03 10:47: Train Epoch 3: 151/634 Loss: 0.196445
2023-01-03 10:47: Train Epoch 3: 155/634 Loss: 0.187052
2023-01-03 10:48: Train Epoch 3: 159/634 Loss: 0.187707
2023-01-03 10:48: Train Epoch 3: 163/634 Loss: 0.173111
2023-01-03 10:48: Train Epoch 3: 167/634 Loss: 0.191814
2023-01-03 10:49: Train Epoch 3: 171/634 Loss: 0.163895
2023-01-03 10:49: Train Epoch 3: 175/634 Loss: 0.171435
2023-01-03 10:49: Train Epoch 3: 179/634 Loss: 0.181768
2023-01-03 10:49: Train Epoch 3: 183/634 Loss: 0.184594
2023-01-03 10:50: Train Epoch 3: 187/634 Loss: 0.165740
2023-01-03 10:50: Train Epoch 3: 191/634 Loss: 0.174412
2023-01-03 10:51: Train Epoch 3: 195/634 Loss: 0.193385
2023-01-03 10:51: Train Epoch 3: 199/634 Loss: 0.172669
2023-01-03 10:51: Train Epoch 3: 203/634 Loss: 0.185867
2023-01-03 10:51: Train Epoch 3: 207/634 Loss: 0.182421
2023-01-03 10:52: Train Epoch 3: 211/634 Loss: 0.181703
2023-01-03 10:52: Train Epoch 3: 215/634 Loss: 0.188052
2023-01-03 10:52: Train Epoch 3: 219/634 Loss: 0.170373
2023-01-03 10:53: Train Epoch 3: 223/634 Loss: 0.184069
2023-01-03 10:53: Train Epoch 3: 227/634 Loss: 0.164763
2023-01-03 10:53: Train Epoch 3: 231/634 Loss: 0.186253
2023-01-03 10:54: Train Epoch 3: 235/634 Loss: 0.182768
2023-01-03 10:54: Train Epoch 3: 239/634 Loss: 0.182048
2023-01-03 10:54: Train Epoch 3: 243/634 Loss: 0.174938
2023-01-03 10:55: Train Epoch 3: 247/634 Loss: 0.177587
2023-01-03 10:55: Train Epoch 3: 251/634 Loss: 0.178604
2023-01-03 10:55: Train Epoch 3: 255/634 Loss: 0.203814
2023-01-03 10:56: Train Epoch 3: 259/634 Loss: 0.166298
2023-01-03 10:56: Train Epoch 3: 263/634 Loss: 0.164979
2023-01-03 10:56: Train Epoch 3: 267/634 Loss: 0.168671
2023-01-03 10:56: Train Epoch 3: 271/634 Loss: 0.186540
2023-01-03 10:57: Train Epoch 3: 275/634 Loss: 0.160648
2023-01-03 10:57: Train Epoch 3: 279/634 Loss: 0.193148
2023-01-03 10:57: Train Epoch 3: 283/634 Loss: 0.165662
2023-01-03 10:58: Train Epoch 3: 287/634 Loss: 0.178842
2023-01-03 10:58: Train Epoch 3: 291/634 Loss: 0.162461
2023-01-03 10:58: Train Epoch 3: 295/634 Loss: 0.187665
2023-01-03 10:59: Train Epoch 3: 299/634 Loss: 0.181001
2023-01-03 10:59: Train Epoch 3: 303/634 Loss: 0.176422
2023-01-03 10:59: Train Epoch 3: 307/634 Loss: 0.202028
2023-01-03 10:59: Train Epoch 3: 311/634 Loss: 0.171525
2023-01-03 11:00: Train Epoch 3: 315/634 Loss: 0.200258
2023-01-03 11:00: Train Epoch 3: 319/634 Loss: 0.180860
2023-01-03 11:01: Train Epoch 3: 323/634 Loss: 0.171784
2023-01-03 11:01: Train Epoch 3: 327/634 Loss: 0.169434
2023-01-03 11:02: Train Epoch 3: 331/634 Loss: 0.177504
2023-01-03 11:02: Train Epoch 3: 335/634 Loss: 0.159006
2023-01-03 11:02: Train Epoch 3: 339/634 Loss: 0.161851
2023-01-03 11:03: Train Epoch 3: 343/634 Loss: 0.177602
2023-01-03 11:03: Train Epoch 3: 347/634 Loss: 0.161328
2023-01-03 11:04: Train Epoch 3: 351/634 Loss: 0.181897
2023-01-03 11:04: Train Epoch 3: 355/634 Loss: 0.183383
2023-01-03 11:05: Train Epoch 3: 359/634 Loss: 0.180884
2023-01-03 11:05: Train Epoch 3: 363/634 Loss: 0.200129
2023-01-03 11:06: Train Epoch 3: 367/634 Loss: 0.170067
2023-01-03 11:06: Train Epoch 3: 371/634 Loss: 0.241013
2023-01-03 11:06: Train Epoch 3: 375/634 Loss: 0.179593
2023-01-03 11:07: Train Epoch 3: 379/634 Loss: 0.208754
2023-01-03 11:07: Train Epoch 3: 383/634 Loss: 0.195714
2023-01-03 11:07: Train Epoch 3: 387/634 Loss: 0.214616
2023-01-03 11:07: Train Epoch 3: 391/634 Loss: 0.240502
2023-01-03 11:08: Train Epoch 3: 395/634 Loss: 0.153268
2023-01-03 11:08: Train Epoch 3: 399/634 Loss: 0.253238
2023-01-03 11:08: Train Epoch 3: 403/634 Loss: 0.282815
2023-01-03 11:09: Train Epoch 3: 407/634 Loss: 0.158501
2023-01-03 11:09: Train Epoch 3: 411/634 Loss: 0.261405
2023-01-03 11:09: Train Epoch 3: 415/634 Loss: 0.220281
2023-01-03 11:10: Train Epoch 3: 419/634 Loss: 0.200284
2023-01-03 11:10: Train Epoch 3: 423/634 Loss: 0.281988
2023-01-03 11:11: Train Epoch 3: 427/634 Loss: 0.249051
2023-01-03 11:11: Train Epoch 3: 431/634 Loss: 0.157198
2023-01-03 11:11: Train Epoch 3: 435/634 Loss: 0.225190
2023-01-03 11:11: Train Epoch 3: 439/634 Loss: 0.288605
2023-01-03 11:12: Train Epoch 3: 443/634 Loss: 0.204148
2023-01-03 11:12: Train Epoch 3: 447/634 Loss: 0.260958
2023-01-03 11:12: Train Epoch 3: 451/634 Loss: 0.321142
2023-01-03 11:13: Train Epoch 3: 455/634 Loss: 0.172429
2023-01-03 11:13: Train Epoch 3: 459/634 Loss: 0.179429
2023-01-03 11:13: Train Epoch 3: 463/634 Loss: 0.251319
2023-01-03 11:14: Train Epoch 3: 467/634 Loss: 0.209504
2023-01-03 11:14: Train Epoch 3: 471/634 Loss: 0.168025
2023-01-03 11:14: Train Epoch 3: 475/634 Loss: 0.195271
2023-01-03 11:14: Train Epoch 3: 479/634 Loss: 0.168591
2023-01-03 11:15: Train Epoch 3: 483/634 Loss: 0.192826
2023-01-03 11:15: Train Epoch 3: 487/634 Loss: 0.179406
2023-01-03 11:15: Train Epoch 3: 491/634 Loss: 0.232247
2023-01-03 11:16: Train Epoch 3: 495/634 Loss: 0.195910
2023-01-03 11:16: Train Epoch 3: 499/634 Loss: 0.159777
2023-01-03 11:16: Train Epoch 3: 503/634 Loss: 0.211547
2023-01-03 11:16: Train Epoch 3: 507/634 Loss: 0.216882
2023-01-03 11:17: Train Epoch 3: 511/634 Loss: 0.165607
2023-01-03 11:17: Train Epoch 3: 515/634 Loss: 0.190768
2023-01-03 11:17: Train Epoch 3: 519/634 Loss: 0.202967
2023-01-03 11:18: Train Epoch 3: 523/634 Loss: 0.186376
2023-01-03 11:18: Train Epoch 3: 527/634 Loss: 0.200486
2023-01-03 11:18: Train Epoch 3: 531/634 Loss: 0.213334
2023-01-03 11:19: Train Epoch 3: 535/634 Loss: 0.213397
2023-01-03 11:19: Train Epoch 3: 539/634 Loss: 0.200520
2023-01-03 11:19: Train Epoch 3: 543/634 Loss: 0.217576
2023-01-03 11:20: Train Epoch 3: 547/634 Loss: 0.172671
2023-01-03 11:20: Train Epoch 3: 551/634 Loss: 0.192836
2023-01-03 11:21: Train Epoch 3: 555/634 Loss: 0.179140
2023-01-03 11:21: Train Epoch 3: 559/634 Loss: 0.166945
2023-01-03 11:21: Train Epoch 3: 563/634 Loss: 0.211211
2023-01-03 11:21: Train Epoch 3: 567/634 Loss: 0.186018
2023-01-03 11:22: Train Epoch 3: 571/634 Loss: 0.184521
2023-01-03 11:22: Train Epoch 3: 575/634 Loss: 0.190275
2023-01-03 11:22: Train Epoch 3: 579/634 Loss: 0.185825
2023-01-03 11:23: Train Epoch 3: 583/634 Loss: 0.177818
2023-01-03 11:23: Train Epoch 3: 587/634 Loss: 0.162303
2023-01-03 11:23: Train Epoch 3: 591/634 Loss: 0.167746
2023-01-03 11:24: Train Epoch 3: 595/634 Loss: 0.144331
2023-01-03 11:24: Train Epoch 3: 599/634 Loss: 0.182758
2023-01-03 11:24: Train Epoch 3: 603/634 Loss: 0.196229
2023-01-03 11:25: Train Epoch 3: 607/634 Loss: 0.168967
2023-01-03 11:25: Train Epoch 3: 611/634 Loss: 0.174766
2023-01-03 11:25: Train Epoch 3: 615/634 Loss: 0.167350
2023-01-03 11:26: Train Epoch 3: 619/634 Loss: 0.175952
2023-01-03 11:26: Train Epoch 3: 623/634 Loss: 0.161115
2023-01-03 11:26: Train Epoch 3: 627/634 Loss: 0.203158
2023-01-03 11:26: Train Epoch 3: 631/634 Loss: 0.165219
2023-01-03 11:27: Train Epoch 3: 633/634 Loss: 0.066072
2023-01-03 11:27: **********Train Epoch 3: averaged Loss: 0.188513 
2023-01-03 11:27: 
Epoch time elapsed: 3075.0663805007935

2023-01-03 11:28: 
 metrics validation: {'precision': 0.7615947925142392, 'recall': 0.72, 'f1-score': 0.7402135231316727, 'support': 1300, 'AUC': 0.8833162721893492, 'AUCPR': 0.8011749286556515, 'TP': 936, 'FP': 293, 'TN': 2307, 'FN': 364} 

2023-01-03 11:28: **********Val Epoch 3: average Loss: 0.193651
2023-01-03 11:28: *********************************Current best model saved!
2023-01-03 11:29: 
 Testing metrics {'precision': 0.7794822627037392, 'recall': 0.6620521172638436, 'f1-score': 0.7159841479524438, 'support': 1228, 'AUC': 0.8882126733440142, 'AUCPR': 0.8190867980489814, 'TP': 813, 'FP': 230, 'TN': 2226, 'FN': 415} 

2023-01-03 11:34: 
 Testing metrics {'precision': 0.8893805309734514, 'recall': 0.9121851599727706, 'f1-score': 0.9006385123781785, 'support': 4407, 'AUC': 0.9716943962894191, 'AUCPR': 0.9437650629168364, 'TP': 4020, 'FP': 500, 'TN': 8314, 'FN': 387} 

2023-01-03 11:34: Train Epoch 4: 3/634 Loss: 0.191291
2023-01-03 11:35: Train Epoch 4: 7/634 Loss: 0.192402
2023-01-03 11:35: Train Epoch 4: 11/634 Loss: 0.174686
2023-01-03 11:35: Train Epoch 4: 15/634 Loss: 0.164932
2023-01-03 11:36: Train Epoch 4: 19/634 Loss: 0.167407
2023-01-03 11:36: Train Epoch 4: 23/634 Loss: 0.186629
2023-01-03 11:36: Train Epoch 4: 27/634 Loss: 0.171215
2023-01-03 11:37: Train Epoch 4: 31/634 Loss: 0.156831
2023-01-03 11:37: Train Epoch 4: 35/634 Loss: 0.178282
2023-01-03 11:37: Train Epoch 4: 39/634 Loss: 0.165653
2023-01-03 11:37: Train Epoch 4: 43/634 Loss: 0.174045
2023-01-03 11:38: Train Epoch 4: 47/634 Loss: 0.171379
2023-01-03 11:38: Train Epoch 4: 51/634 Loss: 0.152683
2023-01-03 11:38: Train Epoch 4: 55/634 Loss: 0.224412
2023-01-03 11:39: Train Epoch 4: 59/634 Loss: 0.180972
2023-01-03 11:39: Train Epoch 4: 63/634 Loss: 0.153652
2023-01-03 11:39: Train Epoch 4: 67/634 Loss: 0.174583
2023-01-03 11:40: Train Epoch 4: 71/634 Loss: 0.145050
2023-01-03 11:40: Train Epoch 4: 75/634 Loss: 0.154206
2023-01-03 11:40: Train Epoch 4: 79/634 Loss: 0.183104
2023-01-03 11:41: Train Epoch 4: 83/634 Loss: 0.186012
2023-01-03 11:41: Train Epoch 4: 87/634 Loss: 0.171407
2023-01-03 11:41: Train Epoch 4: 91/634 Loss: 0.149204
2023-01-03 11:42: Train Epoch 4: 95/634 Loss: 0.183527
2023-01-03 11:42: Train Epoch 4: 99/634 Loss: 0.173569
2023-01-03 11:42: Train Epoch 4: 103/634 Loss: 0.184336
2023-01-03 11:43: Train Epoch 4: 107/634 Loss: 0.169085
2023-01-03 11:43: Train Epoch 4: 111/634 Loss: 0.191728
2023-01-03 11:43: Train Epoch 4: 115/634 Loss: 0.190681
2023-01-03 11:44: Train Epoch 4: 119/634 Loss: 0.154823
2023-01-03 11:44: Train Epoch 4: 123/634 Loss: 0.188064
2023-01-03 11:44: Train Epoch 4: 127/634 Loss: 0.153307
2023-01-03 11:45: Train Epoch 4: 131/634 Loss: 0.176991
2023-01-03 11:45: Train Epoch 4: 135/634 Loss: 0.173618
2023-01-03 11:45: Train Epoch 4: 139/634 Loss: 0.174810
2023-01-03 11:46: Train Epoch 4: 143/634 Loss: 0.140646
2023-01-03 11:46: Train Epoch 4: 147/634 Loss: 0.199208
2023-01-03 11:46: Train Epoch 4: 151/634 Loss: 0.181597
2023-01-03 11:46: Train Epoch 4: 155/634 Loss: 0.203705
2023-01-03 11:47: Train Epoch 4: 159/634 Loss: 0.160314
2023-01-03 11:47: Train Epoch 4: 163/634 Loss: 0.155461
2023-01-03 11:48: Train Epoch 4: 167/634 Loss: 0.191283
2023-01-03 11:48: Train Epoch 4: 171/634 Loss: 0.176594
2023-01-03 11:49: Train Epoch 4: 175/634 Loss: 0.182192
2023-01-03 11:49: Train Epoch 4: 179/634 Loss: 0.185911
2023-01-03 11:49: Train Epoch 4: 183/634 Loss: 0.180435
2023-01-03 11:50: Train Epoch 4: 187/634 Loss: 0.179868
2023-01-03 11:50: Train Epoch 4: 191/634 Loss: 0.169215
2023-01-03 11:51: Train Epoch 4: 195/634 Loss: 0.181357
2023-01-03 11:51: Train Epoch 4: 199/634 Loss: 0.162313
2023-01-03 11:52: Train Epoch 4: 203/634 Loss: 0.160037
2023-01-03 11:52: Train Epoch 4: 207/634 Loss: 0.168355
2023-01-03 11:53: Train Epoch 4: 211/634 Loss: 0.188955
2023-01-03 11:53: Train Epoch 4: 215/634 Loss: 0.185164
2023-01-03 11:53: Train Epoch 4: 219/634 Loss: 0.195972
2023-01-03 11:54: Train Epoch 4: 223/634 Loss: 0.167111
2023-01-03 11:54: Train Epoch 4: 227/634 Loss: 0.163427
2023-01-03 11:54: Train Epoch 4: 231/634 Loss: 0.176288
2023-01-03 11:55: Train Epoch 4: 235/634 Loss: 0.181296
2023-01-03 11:55: Train Epoch 4: 239/634 Loss: 0.167087
2023-01-03 11:55: Train Epoch 4: 243/634 Loss: 0.195420
2023-01-03 11:56: Train Epoch 4: 247/634 Loss: 0.158305
2023-01-03 11:56: Train Epoch 4: 251/634 Loss: 0.154004
2023-01-03 11:56: Train Epoch 4: 255/634 Loss: 0.181454
2023-01-03 11:57: Train Epoch 4: 259/634 Loss: 0.189785
2023-01-03 11:57: Train Epoch 4: 263/634 Loss: 0.171405
2023-01-03 11:57: Train Epoch 4: 267/634 Loss: 0.178379
2023-01-03 11:57: Train Epoch 4: 271/634 Loss: 0.172451
2023-01-03 11:58: Train Epoch 4: 275/634 Loss: 0.187672
2023-01-03 11:58: Train Epoch 4: 279/634 Loss: 0.189188
2023-01-03 11:58: Train Epoch 4: 283/634 Loss: 0.197294
2023-01-03 11:59: Train Epoch 4: 287/634 Loss: 0.177240
2023-01-03 11:59: Train Epoch 4: 291/634 Loss: 0.151329
2023-01-03 11:59: Train Epoch 4: 295/634 Loss: 0.187158
2023-01-03 12:00: Train Epoch 4: 299/634 Loss: 0.197329
2023-01-03 12:00: Train Epoch 4: 303/634 Loss: 0.173310
2023-01-03 12:00: Train Epoch 4: 307/634 Loss: 0.180416
2023-01-03 12:01: Train Epoch 4: 311/634 Loss: 0.191137
2023-01-03 12:01: Train Epoch 4: 315/634 Loss: 0.180780
2023-01-03 12:01: Train Epoch 4: 319/634 Loss: 0.163533
2023-01-03 12:01: Train Epoch 4: 323/634 Loss: 0.175804
2023-01-03 12:02: Train Epoch 4: 327/634 Loss: 0.172201
2023-01-03 12:02: Train Epoch 4: 331/634 Loss: 0.152551
2023-01-03 12:02: Train Epoch 4: 335/634 Loss: 0.204534
2023-01-03 12:03: Train Epoch 4: 339/634 Loss: 0.154271
2023-01-03 12:03: Train Epoch 4: 343/634 Loss: 0.171234
2023-01-03 12:03: Train Epoch 4: 347/634 Loss: 0.206459
2023-01-03 12:04: Train Epoch 4: 351/634 Loss: 0.150478
2023-01-03 12:04: Train Epoch 4: 355/634 Loss: 0.175062
2023-01-03 12:04: Train Epoch 4: 359/634 Loss: 0.163354
2023-01-03 12:05: Train Epoch 4: 363/634 Loss: 0.176733
2023-01-03 12:05: Train Epoch 4: 367/634 Loss: 0.173054
2023-01-03 12:05: Train Epoch 4: 371/634 Loss: 0.181755
2023-01-03 12:06: Train Epoch 4: 375/634 Loss: 0.159122
2023-01-03 12:06: Train Epoch 4: 379/634 Loss: 0.163866
2023-01-03 12:06: Train Epoch 4: 383/634 Loss: 0.193424
2023-01-03 12:06: Train Epoch 4: 387/634 Loss: 0.185710
2023-01-03 12:07: Train Epoch 4: 391/634 Loss: 0.143410
2023-01-03 12:07: Train Epoch 4: 395/634 Loss: 0.186734
2023-01-03 12:07: Train Epoch 4: 399/634 Loss: 0.179626
2023-01-03 12:08: Train Epoch 4: 403/634 Loss: 0.184004
2023-01-03 12:08: Train Epoch 4: 407/634 Loss: 0.174381
2023-01-03 12:08: Train Epoch 4: 411/634 Loss: 0.151994
2023-01-03 12:09: Train Epoch 4: 415/634 Loss: 0.158946
2023-01-03 12:09: Train Epoch 4: 419/634 Loss: 0.168940
2023-01-03 12:09: Train Epoch 4: 423/634 Loss: 0.172472
2023-01-03 12:09: Train Epoch 4: 427/634 Loss: 0.171897
2023-01-03 12:10: Train Epoch 4: 431/634 Loss: 0.149064
2023-01-03 12:10: Train Epoch 4: 435/634 Loss: 0.154354
2023-01-03 12:11: Train Epoch 4: 439/634 Loss: 0.188851
2023-01-03 12:11: Train Epoch 4: 443/634 Loss: 0.152018
2023-01-03 12:11: Train Epoch 4: 447/634 Loss: 0.148765
2023-01-03 12:12: Train Epoch 4: 451/634 Loss: 0.173348
2023-01-03 12:12: Train Epoch 4: 455/634 Loss: 0.155780
2023-01-03 12:12: Train Epoch 4: 459/634 Loss: 0.172601
2023-01-03 12:12: Train Epoch 4: 463/634 Loss: 0.179884
2023-01-03 12:13: Train Epoch 4: 467/634 Loss: 0.148653
2023-01-03 12:13: Train Epoch 4: 471/634 Loss: 0.146911
2023-01-03 12:13: Train Epoch 4: 475/634 Loss: 0.156286
2023-01-03 12:14: Train Epoch 4: 479/634 Loss: 0.160877
2023-01-03 12:14: Train Epoch 4: 483/634 Loss: 0.202147
2023-01-03 12:14: Train Epoch 4: 487/634 Loss: 0.172936
2023-01-03 12:15: Train Epoch 4: 491/634 Loss: 0.180774
2023-01-03 12:15: Train Epoch 4: 495/634 Loss: 0.197781
2023-01-03 12:15: Train Epoch 4: 499/634 Loss: 0.176736
2023-01-03 12:16: Train Epoch 4: 503/634 Loss: 0.208297
2023-01-03 12:16: Train Epoch 4: 507/634 Loss: 0.171378
2023-01-03 12:16: Train Epoch 4: 511/634 Loss: 0.182472
2023-01-03 12:17: Train Epoch 4: 515/634 Loss: 0.196756
2023-01-03 12:17: Train Epoch 4: 519/634 Loss: 0.166995
2023-01-03 12:17: Train Epoch 4: 523/634 Loss: 0.150786
2023-01-03 12:18: Train Epoch 4: 527/634 Loss: 0.167238
2023-01-03 12:18: Train Epoch 4: 531/634 Loss: 0.181375
2023-01-03 12:18: Train Epoch 4: 535/634 Loss: 0.154017
2023-01-03 12:18: Train Epoch 4: 539/634 Loss: 0.181545
2023-01-03 12:19: Train Epoch 4: 543/634 Loss: 0.182311
2023-01-03 12:19: Train Epoch 4: 547/634 Loss: 0.206902
2023-01-03 12:19: Train Epoch 4: 551/634 Loss: 0.173217
2023-01-03 12:20: Train Epoch 4: 555/634 Loss: 0.176621
2023-01-03 12:20: Train Epoch 4: 559/634 Loss: 0.183448
2023-01-03 12:21: Train Epoch 4: 563/634 Loss: 0.171590
2023-01-03 12:21: Train Epoch 4: 567/634 Loss: 0.181346
2023-01-03 12:21: Train Epoch 4: 571/634 Loss: 0.165249
2023-01-03 12:22: Train Epoch 4: 575/634 Loss: 0.177360
2023-01-03 12:22: Train Epoch 4: 579/634 Loss: 0.167519
2023-01-03 12:22: Train Epoch 4: 583/634 Loss: 0.179603
2023-01-03 12:22: Train Epoch 4: 587/634 Loss: 0.167907
2023-01-03 12:23: Train Epoch 4: 591/634 Loss: 0.168894
2023-01-03 12:23: Train Epoch 4: 595/634 Loss: 0.154614
2023-01-03 12:23: Train Epoch 4: 599/634 Loss: 0.183569
2023-01-03 12:24: Train Epoch 4: 603/634 Loss: 0.189434
2023-01-03 12:24: Train Epoch 4: 607/634 Loss: 0.204666
2023-01-03 12:24: Train Epoch 4: 611/634 Loss: 0.210999
2023-01-03 12:25: Train Epoch 4: 615/634 Loss: 0.179007
2023-01-03 12:25: Train Epoch 4: 619/634 Loss: 0.207321
2023-01-03 12:25: Train Epoch 4: 623/634 Loss: 0.175711
2023-01-03 12:26: Train Epoch 4: 627/634 Loss: 0.185263
2023-01-03 12:26: Train Epoch 4: 631/634 Loss: 0.165017
2023-01-03 12:26: Train Epoch 4: 633/634 Loss: 0.070670
2023-01-03 12:26: **********Train Epoch 4: averaged Loss: 0.174370 
2023-01-03 12:26: 
Epoch time elapsed: 3111.764233827591

2023-01-03 12:27: 
 metrics validation: {'precision': 0.8331846565566459, 'recall': 0.7184615384615385, 'f1-score': 0.771581990912846, 'support': 1300, 'AUC': 0.9150162721893491, 'AUCPR': 0.854029415432061, 'TP': 934, 'FP': 187, 'TN': 2413, 'FN': 366} 

2023-01-03 12:27: **********Val Epoch 4: average Loss: 0.167736
2023-01-03 12:27: *********************************Current best model saved!
2023-01-03 12:29: 
 Testing metrics {'precision': 0.8466898954703833, 'recall': 0.5936482084690554, 'f1-score': 0.6979415988511251, 'support': 1228, 'AUC': 0.8956010143343697, 'AUCPR': 0.8308573753794558, 'TP': 729, 'FP': 132, 'TN': 2324, 'FN': 499} 

2023-01-03 12:34: 
 Testing metrics {'precision': 0.9149045899948427, 'recall': 0.8050828227819379, 'f1-score': 0.8564876282438142, 'support': 4407, 'AUC': 0.9684455217988955, 'AUCPR': 0.9373046018196902, 'TP': 3548, 'FP': 330, 'TN': 8484, 'FN': 859} 

2023-01-03 12:34: Train Epoch 5: 3/634 Loss: 0.165919
2023-01-03 12:35: Train Epoch 5: 7/634 Loss: 0.164615
2023-01-03 12:35: Train Epoch 5: 11/634 Loss: 0.174287
2023-01-03 12:35: Train Epoch 5: 15/634 Loss: 0.175259
2023-01-03 12:36: Train Epoch 5: 19/634 Loss: 0.197827
2023-01-03 12:36: Train Epoch 5: 23/634 Loss: 0.143906
2023-01-03 12:37: Train Epoch 5: 27/634 Loss: 0.159018
2023-01-03 12:37: Train Epoch 5: 31/634 Loss: 0.170444
2023-01-03 12:38: Train Epoch 5: 35/634 Loss: 0.138654
2023-01-03 12:38: Train Epoch 5: 39/634 Loss: 0.162788
2023-01-03 12:38: Train Epoch 5: 43/634 Loss: 0.152455
2023-01-03 12:39: Train Epoch 5: 47/634 Loss: 0.152190
2023-01-03 12:39: Train Epoch 5: 51/634 Loss: 0.172293
2023-01-03 12:39: Train Epoch 5: 55/634 Loss: 0.152437
2023-01-03 12:40: Train Epoch 5: 59/634 Loss: 0.159337
2023-01-03 12:40: Train Epoch 5: 63/634 Loss: 0.152438
2023-01-03 12:41: Train Epoch 5: 67/634 Loss: 0.150967
2023-01-03 12:41: Train Epoch 5: 71/634 Loss: 0.169127
2023-01-03 12:41: Train Epoch 5: 75/634 Loss: 0.147932
2023-01-03 12:41: Train Epoch 5: 79/634 Loss: 0.163725
2023-01-03 12:42: Train Epoch 5: 83/634 Loss: 0.169328
2023-01-03 12:42: Train Epoch 5: 87/634 Loss: 0.188614
2023-01-03 12:42: Train Epoch 5: 91/634 Loss: 0.184089
2023-01-03 12:43: Train Epoch 5: 95/634 Loss: 0.160413
2023-01-03 12:43: Train Epoch 5: 99/634 Loss: 0.183736
2023-01-03 12:43: Train Epoch 5: 103/634 Loss: 0.161725
2023-01-03 12:43: Train Epoch 5: 107/634 Loss: 0.188449
2023-01-03 12:44: Train Epoch 5: 111/634 Loss: 0.159459
2023-01-03 12:44: Train Epoch 5: 115/634 Loss: 0.165401
2023-01-03 12:44: Train Epoch 5: 119/634 Loss: 0.172808
2023-01-03 12:45: Train Epoch 5: 123/634 Loss: 0.166142
2023-01-03 12:45: Train Epoch 5: 127/634 Loss: 0.162501
2023-01-03 12:45: Train Epoch 5: 131/634 Loss: 0.149632
2023-01-03 12:46: Train Epoch 5: 135/634 Loss: 0.187739
2023-01-03 12:46: Train Epoch 5: 139/634 Loss: 0.160500
2023-01-03 12:46: Train Epoch 5: 143/634 Loss: 0.186556
2023-01-03 12:47: Train Epoch 5: 147/634 Loss: 0.193642
2023-01-03 12:47: Train Epoch 5: 151/634 Loss: 0.196836
2023-01-03 12:47: Train Epoch 5: 155/634 Loss: 0.148235
2023-01-03 12:48: Train Epoch 5: 159/634 Loss: 0.195988
2023-01-03 12:48: Train Epoch 5: 163/634 Loss: 0.196797
2023-01-03 12:48: Train Epoch 5: 167/634 Loss: 0.164410
2023-01-03 12:49: Train Epoch 5: 171/634 Loss: 0.176179
2023-01-03 12:49: Train Epoch 5: 175/634 Loss: 0.159917
2023-01-03 12:49: Train Epoch 5: 179/634 Loss: 0.166313
2023-01-03 12:50: Train Epoch 5: 183/634 Loss: 0.177272
2023-01-03 12:50: Train Epoch 5: 187/634 Loss: 0.153584
2023-01-03 12:50: Train Epoch 5: 191/634 Loss: 0.185893
2023-01-03 12:51: Train Epoch 5: 195/634 Loss: 0.148939
2023-01-03 12:51: Train Epoch 5: 199/634 Loss: 0.181478
2023-01-03 12:51: Train Epoch 5: 203/634 Loss: 0.181445
2023-01-03 12:52: Train Epoch 5: 207/634 Loss: 0.155090
2023-01-03 12:52: Train Epoch 5: 211/634 Loss: 0.206514
2023-01-03 12:52: Train Epoch 5: 215/634 Loss: 0.164723
2023-01-03 12:52: Train Epoch 5: 219/634 Loss: 0.164399
2023-01-03 12:53: Train Epoch 5: 223/634 Loss: 0.167240
2023-01-03 12:53: Train Epoch 5: 227/634 Loss: 0.168183
2023-01-03 12:53: Train Epoch 5: 231/634 Loss: 0.153429
2023-01-03 12:54: Train Epoch 5: 235/634 Loss: 0.177890
2023-01-03 12:54: Train Epoch 5: 239/634 Loss: 0.179479
2023-01-03 12:54: Train Epoch 5: 243/634 Loss: 0.152505
2023-01-03 12:55: Train Epoch 5: 247/634 Loss: 0.169216
2023-01-03 12:55: Train Epoch 5: 251/634 Loss: 0.162359
2023-01-03 12:55: Train Epoch 5: 255/634 Loss: 0.178455
2023-01-03 12:56: Train Epoch 5: 259/634 Loss: 0.152608
2023-01-03 12:56: Train Epoch 5: 263/634 Loss: 0.190517
2023-01-03 12:56: Train Epoch 5: 267/634 Loss: 0.152594
2023-01-03 12:57: Train Epoch 5: 271/634 Loss: 0.206236
2023-01-03 12:57: Train Epoch 5: 275/634 Loss: 0.169578
2023-01-03 12:57: Train Epoch 5: 279/634 Loss: 0.209729
2023-01-03 12:58: Train Epoch 5: 283/634 Loss: 0.174357
2023-01-03 12:58: Train Epoch 5: 287/634 Loss: 0.153018
2023-01-03 12:58: Train Epoch 5: 291/634 Loss: 0.180826
2023-01-03 12:58: Train Epoch 5: 295/634 Loss: 0.176241
2023-01-03 12:59: Train Epoch 5: 299/634 Loss: 0.166403
2023-01-03 12:59: Train Epoch 5: 303/634 Loss: 0.220436
2023-01-03 12:59: Train Epoch 5: 307/634 Loss: 0.165675
2023-01-03 13:00: Train Epoch 5: 311/634 Loss: 0.194859
2023-01-03 13:00: Train Epoch 5: 315/634 Loss: 0.162149
2023-01-03 13:01: Train Epoch 5: 319/634 Loss: 0.146577
2023-01-03 13:01: Train Epoch 5: 323/634 Loss: 0.166455
2023-01-03 13:01: Train Epoch 5: 327/634 Loss: 0.149005
2023-01-03 13:01: Train Epoch 5: 331/634 Loss: 0.202046
2023-01-03 13:02: Train Epoch 5: 335/634 Loss: 0.173532
2023-01-03 13:02: Train Epoch 5: 339/634 Loss: 0.178885
2023-01-03 13:02: Train Epoch 5: 343/634 Loss: 0.157401
2023-01-03 13:03: Train Epoch 5: 347/634 Loss: 0.181711
2023-01-03 13:03: Train Epoch 5: 351/634 Loss: 0.190171
2023-01-03 13:03: Train Epoch 5: 355/634 Loss: 0.161144
2023-01-03 13:04: Train Epoch 5: 359/634 Loss: 0.164535
2023-01-03 13:04: Train Epoch 5: 363/634 Loss: 0.163046
2023-01-03 13:04: Train Epoch 5: 367/634 Loss: 0.166006
2023-01-03 13:04: Train Epoch 5: 371/634 Loss: 0.169294
2023-01-03 13:05: Train Epoch 5: 375/634 Loss: 0.151883
2023-01-03 13:05: Train Epoch 5: 379/634 Loss: 0.168253
2023-01-03 13:05: Train Epoch 5: 383/634 Loss: 0.147415
2023-01-03 13:06: Train Epoch 5: 387/634 Loss: 0.162415
2023-01-03 13:06: Train Epoch 5: 391/634 Loss: 0.169812
2023-01-03 13:06: Train Epoch 5: 395/634 Loss: 0.161511
2023-01-03 13:07: Train Epoch 5: 399/634 Loss: 0.174222
2023-01-03 13:07: Train Epoch 5: 403/634 Loss: 0.192218
2023-01-03 13:07: Train Epoch 5: 407/634 Loss: 0.169886
2023-01-03 13:08: Train Epoch 5: 411/634 Loss: 0.172072
2023-01-03 13:08: Train Epoch 5: 415/634 Loss: 0.156549
2023-01-03 13:08: Train Epoch 5: 419/634 Loss: 0.162304
2023-01-03 13:09: Train Epoch 5: 423/634 Loss: 0.184826
2023-01-03 13:09: Train Epoch 5: 427/634 Loss: 0.153798
2023-01-03 13:09: Train Epoch 5: 431/634 Loss: 0.171126
2023-01-03 13:09: Train Epoch 5: 435/634 Loss: 0.161044
2023-01-03 13:10: Train Epoch 5: 439/634 Loss: 0.170658
2023-01-03 13:10: Train Epoch 5: 443/634 Loss: 0.188161
2023-01-03 13:10: Train Epoch 5: 447/634 Loss: 0.171019
2023-01-03 13:11: Train Epoch 5: 451/634 Loss: 0.182492
2023-01-03 13:11: Train Epoch 5: 455/634 Loss: 0.173337
2023-01-03 13:11: Train Epoch 5: 459/634 Loss: 0.207488
2023-01-03 13:12: Train Epoch 5: 463/634 Loss: 0.182381
2023-01-03 13:12: Train Epoch 5: 467/634 Loss: 0.173264
2023-01-03 13:12: Train Epoch 5: 471/634 Loss: 0.147572
2023-01-03 13:13: Train Epoch 5: 475/634 Loss: 0.196312
2023-01-03 13:13: Train Epoch 5: 479/634 Loss: 0.164832
2023-01-03 13:13: Train Epoch 5: 483/634 Loss: 0.152935
2023-01-03 13:14: Train Epoch 5: 487/634 Loss: 0.191410
2023-01-03 13:14: Train Epoch 5: 491/634 Loss: 0.152808
2023-01-03 13:14: Train Epoch 5: 495/634 Loss: 0.144754
2023-01-03 13:15: Train Epoch 5: 499/634 Loss: 0.146525
2023-01-03 13:15: Train Epoch 5: 503/634 Loss: 0.191654
2023-01-03 13:15: Train Epoch 5: 507/634 Loss: 0.190044
2023-01-03 13:15: Train Epoch 5: 511/634 Loss: 0.160771
2023-01-03 13:16: Train Epoch 5: 515/634 Loss: 0.194529
2023-01-03 13:16: Train Epoch 5: 519/634 Loss: 0.150789
2023-01-03 13:16: Train Epoch 5: 523/634 Loss: 0.177032
2023-01-03 13:16: Train Epoch 5: 527/634 Loss: 0.151900
2023-01-03 13:17: Train Epoch 5: 531/634 Loss: 0.173733
2023-01-03 13:17: Train Epoch 5: 535/634 Loss: 0.162288
2023-01-03 13:17: Train Epoch 5: 539/634 Loss: 0.166809
2023-01-03 13:18: Train Epoch 5: 543/634 Loss: 0.155997
2023-01-03 13:18: Train Epoch 5: 547/634 Loss: 0.165164
2023-01-03 13:18: Train Epoch 5: 551/634 Loss: 0.185096
2023-01-03 13:19: Train Epoch 5: 555/634 Loss: 0.164520
2023-01-03 13:19: Train Epoch 5: 559/634 Loss: 0.170312
2023-01-03 13:19: Train Epoch 5: 563/634 Loss: 0.185548
2023-01-03 13:19: Train Epoch 5: 567/634 Loss: 0.149700
2023-01-03 13:20: Train Epoch 5: 571/634 Loss: 0.180179
2023-01-03 13:20: Train Epoch 5: 575/634 Loss: 0.170054
2023-01-03 13:21: Train Epoch 5: 579/634 Loss: 0.186397
2023-01-03 13:21: Train Epoch 5: 583/634 Loss: 0.177786
2023-01-03 13:21: Train Epoch 5: 587/634 Loss: 0.177897
2023-01-03 13:22: Train Epoch 5: 591/634 Loss: 0.167849
2023-01-03 13:22: Train Epoch 5: 595/634 Loss: 0.198214
2023-01-03 13:22: Train Epoch 5: 599/634 Loss: 0.175563
2023-01-03 13:23: Train Epoch 5: 603/634 Loss: 0.184279
2023-01-03 13:23: Train Epoch 5: 607/634 Loss: 0.182585
2023-01-03 13:23: Train Epoch 5: 611/634 Loss: 0.170082
2023-01-03 13:24: Train Epoch 5: 615/634 Loss: 0.169637
2023-01-03 13:24: Train Epoch 5: 619/634 Loss: 0.187742
2023-01-03 13:24: Train Epoch 5: 623/634 Loss: 0.196848
2023-01-03 13:24: Train Epoch 5: 627/634 Loss: 0.165540
2023-01-03 13:25: Train Epoch 5: 631/634 Loss: 0.175689
2023-01-03 13:25: Train Epoch 5: 633/634 Loss: 0.076313
2023-01-03 13:25: **********Train Epoch 5: averaged Loss: 0.170365 
2023-01-03 13:25: 
Epoch time elapsed: 3061.433236837387

2023-01-03 13:26: 
 metrics validation: {'precision': 0.881508078994614, 'recall': 0.3776923076923077, 'f1-score': 0.5288099084544966, 'support': 1300, 'AUC': 0.9151905325443788, 'AUCPR': 0.8411035428394275, 'TP': 491, 'FP': 66, 'TN': 2534, 'FN': 809} 

2023-01-03 13:26: **********Val Epoch 5: average Loss: 0.214081
2023-01-03 13:28: 
 Testing metrics {'precision': 0.8466898954703833, 'recall': 0.5936482084690554, 'f1-score': 0.6979415988511251, 'support': 1228, 'AUC': 0.8956010143343697, 'AUCPR': 0.8308573753794558, 'TP': 729, 'FP': 132, 'TN': 2324, 'FN': 499} 

2023-01-03 13:33: 
 Testing metrics {'precision': 0.9149045899948427, 'recall': 0.8050828227819379, 'f1-score': 0.8564876282438142, 'support': 4407, 'AUC': 0.9684455217988955, 'AUCPR': 0.9373046018196902, 'TP': 3548, 'FP': 330, 'TN': 8484, 'FN': 859} 

2023-01-03 13:33: Train Epoch 6: 3/634 Loss: 0.182091
2023-01-03 13:34: Train Epoch 6: 7/634 Loss: 0.170829
2023-01-03 13:34: Train Epoch 6: 11/634 Loss: 0.172978
2023-01-03 13:34: Train Epoch 6: 15/634 Loss: 0.160086
2023-01-03 13:34: Train Epoch 6: 19/634 Loss: 0.158921
2023-01-03 13:35: Train Epoch 6: 23/634 Loss: 0.159957
2023-01-03 13:35: Train Epoch 6: 27/634 Loss: 0.153926
2023-01-03 13:35: Train Epoch 6: 31/634 Loss: 0.170535
2023-01-03 13:36: Train Epoch 6: 35/634 Loss: 0.181246
2023-01-03 13:36: Train Epoch 6: 39/634 Loss: 0.152743
2023-01-03 13:36: Train Epoch 6: 43/634 Loss: 0.202706
2023-01-03 13:37: Train Epoch 6: 47/634 Loss: 0.160751
2023-01-03 13:37: Train Epoch 6: 51/634 Loss: 0.171874
2023-01-03 13:37: Train Epoch 6: 55/634 Loss: 0.178046
2023-01-03 13:38: Train Epoch 6: 59/634 Loss: 0.181418
2023-01-03 13:38: Train Epoch 6: 63/634 Loss: 0.239839
2023-01-03 13:38: Train Epoch 6: 67/634 Loss: 0.181046
2023-01-03 13:39: Train Epoch 6: 71/634 Loss: 0.198478
2023-01-03 13:39: Train Epoch 6: 75/634 Loss: 0.190903
2023-01-03 13:39: Train Epoch 6: 79/634 Loss: 0.192216
2023-01-03 13:40: Train Epoch 6: 83/634 Loss: 0.185682
2023-01-03 13:40: Train Epoch 6: 87/634 Loss: 0.213205
2023-01-03 13:40: Train Epoch 6: 91/634 Loss: 0.205916
2023-01-03 13:41: Train Epoch 6: 95/634 Loss: 0.192236
2023-01-03 13:41: Train Epoch 6: 99/634 Loss: 0.213990
2023-01-03 13:41: Train Epoch 6: 103/634 Loss: 0.151528
2023-01-03 13:42: Train Epoch 6: 107/634 Loss: 0.176778
2023-01-03 13:42: Train Epoch 6: 111/634 Loss: 0.201059
2023-01-03 13:42: Train Epoch 6: 115/634 Loss: 0.189692
2023-01-03 13:43: Train Epoch 6: 119/634 Loss: 0.197541
2023-01-03 13:43: Train Epoch 6: 123/634 Loss: 0.151100
2023-01-03 13:43: Train Epoch 6: 127/634 Loss: 0.161235
2023-01-03 13:44: Train Epoch 6: 131/634 Loss: 0.171531
2023-01-03 13:44: Train Epoch 6: 135/634 Loss: 0.174673
2023-01-03 13:44: Train Epoch 6: 139/634 Loss: 0.157636
2023-01-03 13:45: Train Epoch 6: 143/634 Loss: 0.194023
2023-01-03 13:45: Train Epoch 6: 147/634 Loss: 0.176796
2023-01-03 13:46: Train Epoch 6: 151/634 Loss: 0.155856
2023-01-03 13:46: Train Epoch 6: 155/634 Loss: 0.174847
2023-01-03 13:47: Train Epoch 6: 159/634 Loss: 0.166918
2023-01-03 13:47: Train Epoch 6: 163/634 Loss: 0.190501
2023-01-03 13:48: Train Epoch 6: 167/634 Loss: 0.160561
2023-01-03 13:48: Train Epoch 6: 171/634 Loss: 0.149283
2023-01-03 13:49: Train Epoch 6: 175/634 Loss: 0.193336
2023-01-03 13:49: Train Epoch 6: 179/634 Loss: 0.169036
2023-01-03 13:49: Train Epoch 6: 183/634 Loss: 0.168026
2023-01-03 13:50: Train Epoch 6: 187/634 Loss: 0.168169
2023-01-03 13:51: Train Epoch 6: 191/634 Loss: 0.153582
2023-01-03 13:51: Train Epoch 6: 195/634 Loss: 0.131402
2023-01-03 13:52: Train Epoch 6: 199/634 Loss: 0.176265
2023-01-03 13:52: Train Epoch 6: 203/634 Loss: 0.193509
2023-01-03 13:53: Train Epoch 6: 207/634 Loss: 0.167076
2023-01-03 13:53: Train Epoch 6: 211/634 Loss: 0.184499
2023-01-03 13:54: Train Epoch 6: 215/634 Loss: 0.164975
2023-01-03 13:54: Train Epoch 6: 219/634 Loss: 0.162111
2023-01-03 13:55: Train Epoch 6: 223/634 Loss: 0.170008
2023-01-03 13:55: Train Epoch 6: 227/634 Loss: 0.169480
2023-01-03 13:55: Train Epoch 6: 231/634 Loss: 0.139510
2023-01-03 13:56: Train Epoch 6: 235/634 Loss: 0.186623
2023-01-03 13:56: Train Epoch 6: 239/634 Loss: 0.150791
2023-01-03 13:57: Train Epoch 6: 243/634 Loss: 0.185712
2023-01-03 13:57: Train Epoch 6: 247/634 Loss: 0.161375
2023-01-03 13:58: Train Epoch 6: 251/634 Loss: 0.198887
2023-01-03 13:58: Train Epoch 6: 255/634 Loss: 0.152350
2023-01-03 13:59: Train Epoch 6: 259/634 Loss: 0.193776
2023-01-03 13:59: Train Epoch 6: 263/634 Loss: 0.149263
2023-01-03 14:00: Train Epoch 6: 267/634 Loss: 0.153314
2023-01-03 14:00: Train Epoch 6: 271/634 Loss: 0.170125
2023-01-03 14:01: Train Epoch 6: 275/634 Loss: 0.163857
2023-01-03 14:01: Train Epoch 6: 279/634 Loss: 0.158125
2023-01-03 14:02: Train Epoch 6: 283/634 Loss: 0.179604
2023-01-03 14:02: Train Epoch 6: 287/634 Loss: 0.151651
2023-01-03 14:03: Train Epoch 6: 291/634 Loss: 0.150280
2023-01-03 14:03: Train Epoch 6: 295/634 Loss: 0.145981
2023-01-03 14:04: Train Epoch 6: 299/634 Loss: 0.151114
2023-01-03 14:04: Train Epoch 6: 303/634 Loss: 0.194725
2023-01-03 14:05: Train Epoch 6: 307/634 Loss: 0.172781
2023-01-03 14:05: Train Epoch 6: 311/634 Loss: 0.163998
2023-01-03 14:05: Train Epoch 6: 315/634 Loss: 0.160188
2023-01-03 14:06: Train Epoch 6: 319/634 Loss: 0.168022
2023-01-03 14:06: Train Epoch 6: 323/634 Loss: 0.185703
2023-01-03 14:07: Train Epoch 6: 327/634 Loss: 0.155173
2023-01-03 14:07: Train Epoch 6: 331/634 Loss: 0.154699
2023-01-03 14:08: Train Epoch 6: 335/634 Loss: 0.163902
2023-01-03 14:08: Train Epoch 6: 339/634 Loss: 0.163713
2023-01-03 14:09: Train Epoch 6: 343/634 Loss: 0.163078
2023-01-03 14:09: Train Epoch 6: 347/634 Loss: 0.175689
2023-01-03 14:09: Train Epoch 6: 351/634 Loss: 0.176379
2023-01-03 14:10: Train Epoch 6: 355/634 Loss: 0.186038
2023-01-03 14:11: Train Epoch 6: 359/634 Loss: 0.211078
2023-01-03 14:11: Train Epoch 6: 363/634 Loss: 0.192906
2023-01-03 14:12: Train Epoch 6: 367/634 Loss: 0.156599
2023-01-03 14:12: Train Epoch 6: 371/634 Loss: 0.165731
2023-01-03 14:12: Train Epoch 6: 375/634 Loss: 0.153795
2023-01-03 14:13: Train Epoch 6: 379/634 Loss: 0.186736
2023-01-03 14:13: Train Epoch 6: 383/634 Loss: 0.172388
2023-01-03 14:14: Train Epoch 6: 387/634 Loss: 0.211442
2023-01-03 14:14: Train Epoch 6: 391/634 Loss: 0.195647
2023-01-03 14:15: Train Epoch 6: 395/634 Loss: 0.189422
2023-01-03 14:15: Train Epoch 6: 399/634 Loss: 0.190953
2023-01-03 14:16: Train Epoch 6: 403/634 Loss: 0.182000
2023-01-03 14:16: Train Epoch 6: 407/634 Loss: 0.172689
2023-01-03 14:17: Train Epoch 6: 411/634 Loss: 0.131704
2023-01-03 14:17: Train Epoch 6: 415/634 Loss: 0.159634
2023-01-03 14:18: Train Epoch 6: 419/634 Loss: 0.167333
2023-01-03 14:18: Train Epoch 6: 423/634 Loss: 0.153573
2023-01-03 14:18: Train Epoch 6: 427/634 Loss: 0.157647
2023-01-03 14:19: Train Epoch 6: 431/634 Loss: 0.177850
2023-01-03 14:19: Train Epoch 6: 435/634 Loss: 0.160524
2023-01-03 14:20: Train Epoch 6: 439/634 Loss: 0.185619
2023-01-03 14:20: Train Epoch 6: 443/634 Loss: 0.164735
2023-01-03 14:21: Train Epoch 6: 447/634 Loss: 0.134898
2023-01-03 14:21: Train Epoch 6: 451/634 Loss: 0.173700
2023-01-03 14:22: Train Epoch 6: 455/634 Loss: 0.153610
2023-01-03 14:22: Train Epoch 6: 459/634 Loss: 0.155610
2023-01-03 14:23: Train Epoch 6: 463/634 Loss: 0.193241
2023-01-03 14:23: Train Epoch 6: 467/634 Loss: 0.156935
2023-01-03 14:24: Train Epoch 6: 471/634 Loss: 0.168731
2023-01-03 14:24: Train Epoch 6: 475/634 Loss: 0.170046
2023-01-03 14:24: Train Epoch 6: 479/634 Loss: 0.159688
2023-01-03 14:25: Train Epoch 6: 483/634 Loss: 0.165460
2023-01-03 14:25: Train Epoch 6: 487/634 Loss: 0.162103
2023-01-03 14:26: Train Epoch 6: 491/634 Loss: 0.160290
2023-01-03 14:26: Train Epoch 6: 495/634 Loss: 0.209624
2023-01-03 14:27: Train Epoch 6: 499/634 Loss: 0.188458
2023-01-03 14:27: Train Epoch 6: 503/634 Loss: 0.163304
2023-01-03 14:27: Train Epoch 6: 507/634 Loss: 0.200617
2023-01-03 14:28: Train Epoch 6: 511/634 Loss: 0.168816
2023-01-03 14:28: Train Epoch 6: 515/634 Loss: 0.145853
2023-01-03 14:29: Train Epoch 6: 519/634 Loss: 0.182829
2023-01-03 14:29: Train Epoch 6: 523/634 Loss: 0.208198
2023-01-03 14:30: Train Epoch 6: 527/634 Loss: 0.169953
2023-01-03 14:31: Train Epoch 6: 531/634 Loss: 0.238758
2023-01-03 14:31: Train Epoch 6: 535/634 Loss: 0.166290
2023-01-03 14:32: Train Epoch 6: 539/634 Loss: 0.174901
2023-01-03 14:32: Train Epoch 6: 543/634 Loss: 0.184114
2023-01-03 14:32: Train Epoch 6: 547/634 Loss: 0.151088
2023-01-03 14:33: Train Epoch 6: 551/634 Loss: 0.195468
2023-01-03 14:33: Train Epoch 6: 555/634 Loss: 0.191309
2023-01-03 14:34: Train Epoch 6: 559/634 Loss: 0.166495
2023-01-03 14:34: Train Epoch 6: 563/634 Loss: 0.181548
2023-01-03 14:35: Train Epoch 6: 567/634 Loss: 0.187294
2023-01-03 14:35: Train Epoch 6: 571/634 Loss: 0.171491
2023-01-03 14:36: Train Epoch 6: 575/634 Loss: 0.192481
2023-01-03 14:36: Train Epoch 6: 579/634 Loss: 0.155239
2023-01-03 14:36: Train Epoch 6: 583/634 Loss: 0.194845
2023-01-03 14:37: Train Epoch 6: 587/634 Loss: 0.169305
2023-01-03 14:37: Train Epoch 6: 591/634 Loss: 0.166999
2023-01-03 14:38: Train Epoch 6: 595/634 Loss: 0.145077
2023-01-03 14:38: Train Epoch 6: 599/634 Loss: 0.172054
2023-01-03 14:39: Train Epoch 6: 603/634 Loss: 0.168529
2023-01-03 14:39: Train Epoch 6: 607/634 Loss: 0.157087
2023-01-03 14:40: Train Epoch 6: 611/634 Loss: 0.163293
2023-01-03 14:40: Train Epoch 6: 615/634 Loss: 0.183688
2023-01-03 14:41: Train Epoch 6: 619/634 Loss: 0.148026
2023-01-03 14:41: Train Epoch 6: 623/634 Loss: 0.170748
2023-01-03 14:42: Train Epoch 6: 627/634 Loss: 0.143034
2023-01-03 14:42: Train Epoch 6: 631/634 Loss: 0.177484
2023-01-03 14:42: Train Epoch 6: 633/634 Loss: 0.064624
2023-01-03 14:42: **********Train Epoch 6: averaged Loss: 0.172228 
2023-01-03 14:42: 
Epoch time elapsed: 4158.435684919357

2023-01-03 14:44: 
 metrics validation: {'precision': 0.8273464658169177, 'recall': 0.5492307692307692, 'f1-score': 0.6601941747572816, 'support': 1300, 'AUC': 0.9065582840236686, 'AUCPR': 0.8237879164322636, 'TP': 714, 'FP': 149, 'TN': 2451, 'FN': 586} 

2023-01-03 14:44: **********Val Epoch 6: average Loss: 0.188956
2023-01-03 14:46: 
 Testing metrics {'precision': 0.8466898954703833, 'recall': 0.5936482084690554, 'f1-score': 0.6979415988511251, 'support': 1228, 'AUC': 0.8956010143343697, 'AUCPR': 0.8308573753794558, 'TP': 729, 'FP': 132, 'TN': 2324, 'FN': 499} 

2023-01-03 14:53: 
 Testing metrics {'precision': 0.9149045899948427, 'recall': 0.8050828227819379, 'f1-score': 0.8564876282438142, 'support': 4407, 'AUC': 0.9684455217988955, 'AUCPR': 0.9373046018196902, 'TP': 3548, 'FP': 330, 'TN': 8484, 'FN': 859} 

2023-01-03 14:54: Train Epoch 7: 3/634 Loss: 0.169297
2023-01-03 14:54: Train Epoch 7: 7/634 Loss: 0.154230
2023-01-03 14:54: Train Epoch 7: 11/634 Loss: 0.142700
2023-01-03 14:55: Train Epoch 7: 15/634 Loss: 0.153604
2023-01-03 14:55: Train Epoch 7: 19/634 Loss: 0.167313
2023-01-03 14:56: Train Epoch 7: 23/634 Loss: 0.158691
2023-01-03 14:56: Train Epoch 7: 27/634 Loss: 0.154935
2023-01-03 14:57: Train Epoch 7: 31/634 Loss: 0.183447
2023-01-03 14:57: Train Epoch 7: 35/634 Loss: 0.170462
2023-01-03 14:57: Train Epoch 7: 39/634 Loss: 0.181397
2023-01-03 14:58: Train Epoch 7: 43/634 Loss: 0.129554
2023-01-03 14:58: Train Epoch 7: 47/634 Loss: 0.156909
2023-01-03 14:59: Train Epoch 7: 51/634 Loss: 0.179289
2023-01-03 14:59: Train Epoch 7: 55/634 Loss: 0.177865
2023-01-03 15:00: Train Epoch 7: 59/634 Loss: 0.181566
2023-01-03 15:00: Train Epoch 7: 63/634 Loss: 0.166865
2023-01-03 15:01: Train Epoch 7: 67/634 Loss: 0.178148
2023-01-03 15:01: Train Epoch 7: 71/634 Loss: 0.210215
2023-01-03 15:02: Train Epoch 7: 75/634 Loss: 0.160719
2023-01-03 15:02: Train Epoch 7: 79/634 Loss: 0.163223
2023-01-03 15:02: Train Epoch 7: 83/634 Loss: 0.167419
2023-01-03 15:03: Train Epoch 7: 87/634 Loss: 0.164237
2023-01-03 15:03: Train Epoch 7: 91/634 Loss: 0.171522
2023-01-03 15:04: Train Epoch 7: 95/634 Loss: 0.167989
2023-01-03 15:04: Train Epoch 7: 99/634 Loss: 0.180397
2023-01-03 15:05: Train Epoch 7: 103/634 Loss: 0.201289
2023-01-03 15:05: Train Epoch 7: 107/634 Loss: 0.153298
2023-01-03 15:06: Train Epoch 7: 111/634 Loss: 0.180923
2023-01-03 15:06: Train Epoch 7: 115/634 Loss: 0.156371
2023-01-03 15:07: Train Epoch 7: 119/634 Loss: 0.163521
2023-01-03 15:07: Train Epoch 7: 123/634 Loss: 0.164361
2023-01-03 15:08: Train Epoch 7: 127/634 Loss: 0.170602
2023-01-03 15:08: Train Epoch 7: 131/634 Loss: 0.179686
2023-01-03 15:08: Train Epoch 7: 135/634 Loss: 0.148503
2023-01-03 15:09: Train Epoch 7: 139/634 Loss: 0.152256
2023-01-03 15:09: Train Epoch 7: 143/634 Loss: 0.167497
2023-01-03 15:10: Train Epoch 7: 147/634 Loss: 0.167222
2023-01-03 15:10: Train Epoch 7: 151/634 Loss: 0.190937
2023-01-03 15:11: Train Epoch 7: 155/634 Loss: 0.161377
2023-01-03 15:11: Train Epoch 7: 159/634 Loss: 0.191952
2023-01-03 15:12: Train Epoch 7: 163/634 Loss: 0.154859
2023-01-03 15:12: Train Epoch 7: 167/634 Loss: 0.161084
2023-01-03 15:13: Train Epoch 7: 171/634 Loss: 0.173125
2023-01-03 15:14: Train Epoch 7: 175/634 Loss: 0.194721
2023-01-03 15:14: Train Epoch 7: 179/634 Loss: 0.157433
2023-01-03 15:14: Train Epoch 7: 183/634 Loss: 0.179118
2023-01-03 15:15: Train Epoch 7: 187/634 Loss: 0.161750
2023-01-03 15:15: Train Epoch 7: 191/634 Loss: 0.163514
2023-01-03 15:16: Train Epoch 7: 195/634 Loss: 0.184219
2023-01-03 15:16: Train Epoch 7: 199/634 Loss: 0.154490
2023-01-03 15:17: Train Epoch 7: 203/634 Loss: 0.146949
2023-01-03 15:17: Train Epoch 7: 207/634 Loss: 0.154200
2023-01-03 15:18: Train Epoch 7: 211/634 Loss: 0.195692
2023-01-03 15:18: Train Epoch 7: 215/634 Loss: 0.156964
2023-01-03 15:19: Train Epoch 7: 219/634 Loss: 0.194491
2023-01-03 15:19: Train Epoch 7: 223/634 Loss: 0.180683
2023-01-03 15:19: Train Epoch 7: 227/634 Loss: 0.169712
2023-01-03 15:20: Train Epoch 7: 231/634 Loss: 0.197775
2023-01-03 15:20: Train Epoch 7: 235/634 Loss: 0.156288
2023-01-03 15:21: Train Epoch 7: 239/634 Loss: 0.153255
2023-01-03 15:21: Train Epoch 7: 243/634 Loss: 0.177702
2023-01-03 15:22: Train Epoch 7: 247/634 Loss: 0.173539
2023-01-03 15:22: Train Epoch 7: 251/634 Loss: 0.175884
2023-01-03 15:23: Train Epoch 7: 255/634 Loss: 0.181928
2023-01-03 15:23: Train Epoch 7: 259/634 Loss: 0.155564
2023-01-03 15:23: Train Epoch 7: 263/634 Loss: 0.185035
2023-01-03 15:24: Train Epoch 7: 267/634 Loss: 0.173820
2023-01-03 15:24: Train Epoch 7: 271/634 Loss: 0.155951
2023-01-03 15:25: Train Epoch 7: 275/634 Loss: 0.147064
2023-01-03 15:25: Train Epoch 7: 279/634 Loss: 0.161910
2023-01-03 15:26: Train Epoch 7: 283/634 Loss: 0.147718
2023-01-03 15:26: Train Epoch 7: 287/634 Loss: 0.156650
2023-01-03 15:26: Train Epoch 7: 291/634 Loss: 0.159231
2023-01-03 15:27: Train Epoch 7: 295/634 Loss: 0.162385
2023-01-03 15:27: Train Epoch 7: 299/634 Loss: 0.167311
2023-01-03 15:28: Train Epoch 7: 303/634 Loss: 0.181688
2023-01-03 15:28: Train Epoch 7: 307/634 Loss: 0.150678
2023-01-03 15:29: Train Epoch 7: 311/634 Loss: 0.154507
2023-01-03 15:29: Train Epoch 7: 315/634 Loss: 0.142128
2023-01-03 15:29: Train Epoch 7: 319/634 Loss: 0.163509
2023-01-03 15:30: Train Epoch 7: 323/634 Loss: 0.172459
2023-01-03 15:30: Train Epoch 7: 327/634 Loss: 0.169332
2023-01-03 15:31: Train Epoch 7: 331/634 Loss: 0.167363
2023-01-03 15:31: Train Epoch 7: 335/634 Loss: 0.116761
2023-01-03 15:32: Train Epoch 7: 339/634 Loss: 0.145700
2023-01-03 15:32: Train Epoch 7: 343/634 Loss: 0.147856
2023-01-03 15:33: Train Epoch 7: 347/634 Loss: 0.139482
2023-01-03 15:33: Train Epoch 7: 351/634 Loss: 0.156646
2023-01-03 15:33: Train Epoch 7: 355/634 Loss: 0.200347
2023-01-03 15:34: Train Epoch 7: 359/634 Loss: 0.186748
2023-01-03 15:34: Train Epoch 7: 363/634 Loss: 0.199718
2023-01-03 15:35: Train Epoch 7: 367/634 Loss: 0.148078
2023-01-03 15:35: Train Epoch 7: 371/634 Loss: 0.185336
2023-01-03 15:35: Train Epoch 7: 375/634 Loss: 0.200196
2023-01-03 15:36: Train Epoch 7: 379/634 Loss: 0.157668
2023-01-03 15:36: Train Epoch 7: 383/634 Loss: 0.163334
2023-01-03 15:37: Train Epoch 7: 387/634 Loss: 0.160450
2023-01-03 15:37: Train Epoch 7: 391/634 Loss: 0.159857
2023-01-03 15:38: Train Epoch 7: 395/634 Loss: 0.203333
2023-01-03 15:38: Train Epoch 7: 399/634 Loss: 0.148961
2023-01-03 15:38: Train Epoch 7: 403/634 Loss: 0.178062
2023-01-03 15:39: Train Epoch 7: 407/634 Loss: 0.180341
2023-01-03 15:39: Train Epoch 7: 411/634 Loss: 0.157034
2023-01-03 15:40: Train Epoch 7: 415/634 Loss: 0.166283
2023-01-03 15:40: Train Epoch 7: 419/634 Loss: 0.186135
2023-01-03 15:41: Train Epoch 7: 423/634 Loss: 0.179184
2023-01-03 15:41: Train Epoch 7: 427/634 Loss: 0.158967
2023-01-03 15:41: Train Epoch 7: 431/634 Loss: 0.159037
2023-01-03 15:42: Train Epoch 7: 435/634 Loss: 0.156044
2023-01-03 15:42: Train Epoch 7: 439/634 Loss: 0.148787
2023-01-03 15:43: Train Epoch 7: 443/634 Loss: 0.169010
2023-01-03 15:43: Train Epoch 7: 447/634 Loss: 0.191123
2023-01-03 15:43: Train Epoch 7: 451/634 Loss: 0.156588
2023-01-03 15:44: Train Epoch 7: 455/634 Loss: 0.200560
2023-01-03 15:44: Train Epoch 7: 459/634 Loss: 0.155860
2023-01-03 15:45: Train Epoch 7: 463/634 Loss: 0.180172
2023-01-03 15:45: Train Epoch 7: 467/634 Loss: 0.152463
2023-01-03 15:46: Train Epoch 7: 471/634 Loss: 0.208992
2023-01-03 15:46: Train Epoch 7: 475/634 Loss: 0.168216
2023-01-03 15:46: Train Epoch 7: 479/634 Loss: 0.167659
2023-01-03 15:47: Train Epoch 7: 483/634 Loss: 0.178286
2023-01-03 15:47: Train Epoch 7: 487/634 Loss: 0.180843
2023-01-03 15:48: Train Epoch 7: 491/634 Loss: 0.153046
2023-01-03 15:48: Train Epoch 7: 495/634 Loss: 0.152603
2023-01-03 15:48: Train Epoch 7: 499/634 Loss: 0.152456
2023-01-03 15:49: Train Epoch 7: 503/634 Loss: 0.197045
2023-01-03 15:49: Train Epoch 7: 507/634 Loss: 0.117323
2023-01-03 15:50: Train Epoch 7: 511/634 Loss: 0.207349
2023-01-03 15:51: Train Epoch 7: 515/634 Loss: 0.185400
2023-01-03 15:51: Train Epoch 7: 519/634 Loss: 0.185449
2023-01-03 15:52: Train Epoch 7: 523/634 Loss: 0.141018
2023-01-03 15:52: Train Epoch 7: 527/634 Loss: 0.138360
2023-01-03 15:52: Train Epoch 7: 531/634 Loss: 0.169726
2023-01-03 15:53: Train Epoch 7: 535/634 Loss: 0.173131
2023-01-03 15:53: Train Epoch 7: 539/634 Loss: 0.158662
2023-01-03 15:54: Train Epoch 7: 543/634 Loss: 0.166398
2023-01-03 15:54: Train Epoch 7: 547/634 Loss: 0.135936
2023-01-03 15:55: Train Epoch 7: 551/634 Loss: 0.154770
2023-01-03 15:55: Train Epoch 7: 555/634 Loss: 0.160605
2023-01-03 15:55: Train Epoch 7: 559/634 Loss: 0.178695
2023-01-03 15:56: Train Epoch 7: 563/634 Loss: 0.167441
2023-01-03 15:56: Train Epoch 7: 567/634 Loss: 0.154129
2023-01-03 15:56: Train Epoch 7: 571/634 Loss: 0.161044
2023-01-03 15:57: Train Epoch 7: 575/634 Loss: 0.175531
2023-01-03 15:57: Train Epoch 7: 579/634 Loss: 0.162194
2023-01-03 15:58: Train Epoch 7: 583/634 Loss: 0.158351
2023-01-03 15:58: Train Epoch 7: 587/634 Loss: 0.161409
2023-01-03 15:59: Train Epoch 7: 591/634 Loss: 0.173073
2023-01-03 15:59: Train Epoch 7: 595/634 Loss: 0.155024
2023-01-03 15:59: Train Epoch 7: 599/634 Loss: 0.154984
2023-01-03 16:00: Train Epoch 7: 603/634 Loss: 0.155756
2023-01-03 16:00: Train Epoch 7: 607/634 Loss: 0.140813
2023-01-03 16:01: Train Epoch 7: 611/634 Loss: 0.154921
2023-01-03 16:01: Train Epoch 7: 615/634 Loss: 0.162172
2023-01-03 16:02: Train Epoch 7: 619/634 Loss: 0.161746
2023-01-03 16:02: Train Epoch 7: 623/634 Loss: 0.147582
2023-01-03 16:02: Train Epoch 7: 627/634 Loss: 0.194950
2023-01-03 16:03: Train Epoch 7: 631/634 Loss: 0.156525
2023-01-03 16:03: Train Epoch 7: 633/634 Loss: 0.071425
2023-01-03 16:03: **********Train Epoch 7: averaged Loss: 0.166117 
2023-01-03 16:03: 
Epoch time elapsed: 4190.475709676743

2023-01-03 16:05: 
 metrics validation: {'precision': 0.8061224489795918, 'recall': 0.7292307692307692, 'f1-score': 0.7657512116316639, 'support': 1300, 'AUC': 0.9111843195266272, 'AUCPR': 0.8493572730426555, 'TP': 948, 'FP': 228, 'TN': 2372, 'FN': 352} 

2023-01-03 16:05: **********Val Epoch 7: average Loss: 0.172002
2023-01-03 16:06: 
 Testing metrics {'precision': 0.8466898954703833, 'recall': 0.5936482084690554, 'f1-score': 0.6979415988511251, 'support': 1228, 'AUC': 0.8956010143343697, 'AUCPR': 0.8308573753794558, 'TP': 729, 'FP': 132, 'TN': 2324, 'FN': 499} 

2023-01-03 16:12: 
 Testing metrics {'precision': 0.9149045899948427, 'recall': 0.8050828227819379, 'f1-score': 0.8564876282438142, 'support': 4407, 'AUC': 0.9684455217988955, 'AUCPR': 0.9373046018196902, 'TP': 3548, 'FP': 330, 'TN': 8484, 'FN': 859} 

2023-01-03 16:13: Train Epoch 8: 3/634 Loss: 0.174910
2023-01-03 16:13: Train Epoch 8: 7/634 Loss: 0.182300
2023-01-03 16:13: Train Epoch 8: 11/634 Loss: 0.178605
2023-01-03 16:14: Train Epoch 8: 15/634 Loss: 0.160332
2023-01-03 16:14: Train Epoch 8: 19/634 Loss: 0.159040
2023-01-03 16:15: Train Epoch 8: 23/634 Loss: 0.185881
2023-01-03 16:15: Train Epoch 8: 27/634 Loss: 0.162726
2023-01-03 16:15: Train Epoch 8: 31/634 Loss: 0.170091
2023-01-03 16:16: Train Epoch 8: 35/634 Loss: 0.175186
2023-01-03 16:16: Train Epoch 8: 39/634 Loss: 0.168061
2023-01-03 16:16: Train Epoch 8: 43/634 Loss: 0.181264
2023-01-03 16:17: Train Epoch 8: 47/634 Loss: 0.168621
2023-01-03 16:17: Train Epoch 8: 51/634 Loss: 0.156018
2023-01-03 16:17: Train Epoch 8: 55/634 Loss: 0.166634
2023-01-03 16:18: Train Epoch 8: 59/634 Loss: 0.192795
2023-01-03 16:18: Train Epoch 8: 63/634 Loss: 0.136273
2023-01-03 16:19: Train Epoch 8: 67/634 Loss: 0.183925
2023-01-03 16:19: Train Epoch 8: 71/634 Loss: 0.192120
2023-01-03 16:19: Train Epoch 8: 75/634 Loss: 0.193969
2023-01-03 16:20: Train Epoch 8: 79/634 Loss: 0.192004
2023-01-03 16:20: Train Epoch 8: 83/634 Loss: 0.184395
2023-01-03 16:21: Train Epoch 8: 87/634 Loss: 0.185557
2023-01-03 16:21: Train Epoch 8: 91/634 Loss: 0.212269
2023-01-03 16:21: Train Epoch 8: 95/634 Loss: 0.169111
2023-01-03 16:22: Train Epoch 8: 99/634 Loss: 0.173587
2023-01-03 16:22: Train Epoch 8: 103/634 Loss: 0.196855
2023-01-03 16:23: Train Epoch 8: 107/634 Loss: 0.151124
2023-01-03 16:23: Train Epoch 8: 111/634 Loss: 0.167445
2023-01-03 16:24: Train Epoch 8: 115/634 Loss: 0.194832
2023-01-03 16:24: Train Epoch 8: 119/634 Loss: 0.164092
2023-01-03 16:25: Train Epoch 8: 123/634 Loss: 0.183695
2023-01-03 16:25: Train Epoch 8: 127/634 Loss: 0.155040
2023-01-03 16:25: Train Epoch 8: 131/634 Loss: 0.134664
2023-01-03 16:26: Train Epoch 8: 135/634 Loss: 0.181972
2023-01-03 16:26: Train Epoch 8: 139/634 Loss: 0.150669
2023-01-03 16:27: Train Epoch 8: 143/634 Loss: 0.172739
2023-01-03 16:27: Train Epoch 8: 147/634 Loss: 0.155397
2023-01-03 16:27: Train Epoch 8: 151/634 Loss: 0.177418
2023-01-03 16:28: Train Epoch 8: 155/634 Loss: 0.192824
2023-01-03 16:28: Train Epoch 8: 159/634 Loss: 0.145551
2023-01-03 16:28: Train Epoch 8: 163/634 Loss: 0.176265
2023-01-03 16:29: Train Epoch 8: 167/634 Loss: 0.160298
2023-01-03 16:29: Train Epoch 8: 171/634 Loss: 0.145734
2023-01-03 16:29: Train Epoch 8: 175/634 Loss: 0.176818
2023-01-03 16:30: Train Epoch 8: 179/634 Loss: 0.186354
2023-01-03 16:30: Train Epoch 8: 183/634 Loss: 0.148791
2023-01-03 16:31: Train Epoch 8: 187/634 Loss: 0.162774
2023-01-03 16:31: Train Epoch 8: 191/634 Loss: 0.162141
2023-01-03 16:32: Train Epoch 8: 195/634 Loss: 0.166455
2023-01-03 16:32: Train Epoch 8: 199/634 Loss: 0.162674
2023-01-03 16:32: Train Epoch 8: 203/634 Loss: 0.160354
2023-01-03 16:33: Train Epoch 8: 207/634 Loss: 0.176695
2023-01-03 16:33: Train Epoch 8: 211/634 Loss: 0.162649
2023-01-03 16:33: Train Epoch 8: 215/634 Loss: 0.182597
2023-01-03 16:34: Train Epoch 8: 219/634 Loss: 0.166985
2023-01-03 16:34: Train Epoch 8: 223/634 Loss: 0.159730
2023-01-03 16:34: Train Epoch 8: 227/634 Loss: 0.162345
2023-01-03 16:35: Train Epoch 8: 231/634 Loss: 0.165072
2023-01-03 16:35: Train Epoch 8: 235/634 Loss: 0.159118
2023-01-03 16:36: Train Epoch 8: 239/634 Loss: 0.164821
2023-01-03 16:36: Train Epoch 8: 243/634 Loss: 0.175802
2023-01-03 16:36: Train Epoch 8: 247/634 Loss: 0.190565
2023-01-03 16:37: Train Epoch 8: 251/634 Loss: 0.172178
2023-01-03 16:37: Train Epoch 8: 255/634 Loss: 0.156857
2023-01-03 16:37: Train Epoch 8: 259/634 Loss: 0.139824
2023-01-03 16:38: Train Epoch 8: 263/634 Loss: 0.152875
2023-01-03 16:38: Train Epoch 8: 267/634 Loss: 0.156805
2023-01-03 16:39: Train Epoch 8: 271/634 Loss: 0.153958
2023-01-03 16:39: Train Epoch 8: 275/634 Loss: 0.169083
2023-01-03 16:39: Train Epoch 8: 279/634 Loss: 0.154854
2023-01-03 16:40: Train Epoch 8: 283/634 Loss: 0.206136
2023-01-03 16:40: Train Epoch 8: 287/634 Loss: 0.153939
2023-01-03 16:41: Train Epoch 8: 291/634 Loss: 0.159639
2023-01-03 16:41: Train Epoch 8: 295/634 Loss: 0.170699
2023-01-03 16:41: Train Epoch 8: 299/634 Loss: 0.139055
2023-01-03 16:42: Train Epoch 8: 303/634 Loss: 0.183594
2023-01-03 16:42: Train Epoch 8: 307/634 Loss: 0.199046
2023-01-03 16:42: Train Epoch 8: 311/634 Loss: 0.157723
2023-01-03 16:43: Train Epoch 8: 315/634 Loss: 0.211155
2023-01-03 16:43: Train Epoch 8: 319/634 Loss: 0.166381
2023-01-03 16:43: Train Epoch 8: 323/634 Loss: 0.143152
2023-01-03 16:44: Train Epoch 8: 327/634 Loss: 0.179117
2023-01-03 16:44: Train Epoch 8: 331/634 Loss: 0.167970
2023-01-03 16:45: Train Epoch 8: 335/634 Loss: 0.138262
2023-01-03 16:45: Train Epoch 8: 339/634 Loss: 0.162889
2023-01-03 16:45: Train Epoch 8: 343/634 Loss: 0.193212
2023-01-03 16:46: Train Epoch 8: 347/634 Loss: 0.165100
2023-01-03 16:46: Train Epoch 8: 351/634 Loss: 0.169899
2023-01-03 16:46: Train Epoch 8: 355/634 Loss: 0.196509
2023-01-03 16:47: Train Epoch 8: 359/634 Loss: 0.167860
2023-01-03 16:47: Train Epoch 8: 363/634 Loss: 0.188380
2023-01-03 16:47: Train Epoch 8: 367/634 Loss: 0.151403
2023-01-03 16:48: Train Epoch 8: 371/634 Loss: 0.144998
2023-01-03 16:48: Train Epoch 8: 375/634 Loss: 0.170482
2023-01-03 16:48: Train Epoch 8: 379/634 Loss: 0.174468
2023-01-03 16:49: Train Epoch 8: 383/634 Loss: 0.172986
2023-01-03 16:49: Train Epoch 8: 387/634 Loss: 0.174896
2023-01-03 16:50: Train Epoch 8: 391/634 Loss: 0.152751
2023-01-03 16:50: Train Epoch 8: 395/634 Loss: 0.180139
2023-01-03 16:51: Train Epoch 8: 399/634 Loss: 0.200856
2023-01-03 16:51: Train Epoch 8: 403/634 Loss: 0.139154
2023-01-03 16:52: Train Epoch 8: 407/634 Loss: 0.173112
2023-01-03 16:52: Train Epoch 8: 411/634 Loss: 0.186336
2023-01-03 16:52: Train Epoch 8: 415/634 Loss: 0.166718
2023-01-03 16:53: Train Epoch 8: 419/634 Loss: 0.158619
2023-01-03 16:53: Train Epoch 8: 423/634 Loss: 0.185366
2023-01-03 16:53: Train Epoch 8: 427/634 Loss: 0.144991
2023-01-03 16:54: Train Epoch 8: 431/634 Loss: 0.160995
2023-01-03 16:54: Train Epoch 8: 435/634 Loss: 0.211848
2023-01-03 16:54: Train Epoch 8: 439/634 Loss: 0.176331
2023-01-03 16:55: Train Epoch 8: 443/634 Loss: 0.173532
2023-01-03 16:55: Train Epoch 8: 447/634 Loss: 0.212664
2023-01-03 16:55: Train Epoch 8: 451/634 Loss: 0.181565
2023-01-03 16:56: Train Epoch 8: 455/634 Loss: 0.182940
2023-01-03 16:56: Train Epoch 8: 459/634 Loss: 0.199876
2023-01-03 16:56: Train Epoch 8: 463/634 Loss: 0.164491
2023-01-03 16:57: Train Epoch 8: 467/634 Loss: 0.184590
2023-01-03 16:57: Train Epoch 8: 471/634 Loss: 0.181237
2023-01-03 16:57: Train Epoch 8: 475/634 Loss: 0.150031
2023-01-03 16:58: Train Epoch 8: 479/634 Loss: 0.196701
2023-01-03 16:58: Train Epoch 8: 483/634 Loss: 0.155289
2023-01-03 16:58: Train Epoch 8: 487/634 Loss: 0.151881
2023-01-03 16:59: Train Epoch 8: 491/634 Loss: 0.172014
2023-01-03 16:59: Train Epoch 8: 495/634 Loss: 0.175353
2023-01-03 16:59: Train Epoch 8: 499/634 Loss: 0.176667
2023-01-03 17:00: Train Epoch 8: 503/634 Loss: 0.180919
2023-01-03 17:00: Train Epoch 8: 507/634 Loss: 0.178681
2023-01-03 17:00: Train Epoch 8: 511/634 Loss: 0.219910
2023-01-03 17:01: Train Epoch 8: 515/634 Loss: 0.178219
2023-01-03 17:01: Train Epoch 8: 519/634 Loss: 0.170939
2023-01-03 17:01: Train Epoch 8: 523/634 Loss: 0.153012
2023-01-03 17:02: Train Epoch 8: 527/634 Loss: 0.155694
2023-01-03 17:02: Train Epoch 8: 531/634 Loss: 0.184197
2023-01-03 17:02: Train Epoch 8: 535/634 Loss: 0.177271
2023-01-03 17:03: Train Epoch 8: 539/634 Loss: 0.185437
2023-01-03 17:03: Train Epoch 8: 543/634 Loss: 0.169210
2023-01-03 17:03: Train Epoch 8: 547/634 Loss: 0.165954
2023-01-03 17:04: Train Epoch 8: 551/634 Loss: 0.158887
2023-01-03 17:04: Train Epoch 8: 555/634 Loss: 0.181113
2023-01-03 17:05: Train Epoch 8: 559/634 Loss: 0.177769
2023-01-03 17:05: Train Epoch 8: 563/634 Loss: 0.181122
2023-01-03 17:05: Train Epoch 8: 567/634 Loss: 0.184632
2023-01-03 17:06: Train Epoch 8: 571/634 Loss: 0.173296
2023-01-03 17:06: Train Epoch 8: 575/634 Loss: 0.158667
2023-01-03 17:06: Train Epoch 8: 579/634 Loss: 0.164553
2023-01-03 17:07: Train Epoch 8: 583/634 Loss: 0.161077
2023-01-03 17:07: Train Epoch 8: 587/634 Loss: 0.149660
2023-01-03 17:07: Train Epoch 8: 591/634 Loss: 0.190014
2023-01-03 17:08: Train Epoch 8: 595/634 Loss: 0.172570
2023-01-03 17:08: Train Epoch 8: 599/634 Loss: 0.181901
2023-01-03 17:08: Train Epoch 8: 603/634 Loss: 0.170280
2023-01-03 17:09: Train Epoch 8: 607/634 Loss: 0.175499
2023-01-03 17:09: Train Epoch 8: 611/634 Loss: 0.153311
2023-01-03 17:09: Train Epoch 8: 615/634 Loss: 0.173556
2023-01-03 17:10: Train Epoch 8: 619/634 Loss: 0.171673
2023-01-03 17:10: Train Epoch 8: 623/634 Loss: 0.169143
2023-01-03 17:11: Train Epoch 8: 627/634 Loss: 0.167178
2023-01-03 17:11: Train Epoch 8: 631/634 Loss: 0.164907
2023-01-03 17:11: Train Epoch 8: 633/634 Loss: 0.056174
2023-01-03 17:11: **********Train Epoch 8: averaged Loss: 0.170584 
2023-01-03 17:11: 
Epoch time elapsed: 3516.6990115642548

2023-01-03 17:13: 
 metrics validation: {'precision': 0.7803557617942769, 'recall': 0.7761538461538462, 'f1-score': 0.7782491322792133, 'support': 1300, 'AUC': 0.9141210059171598, 'AUCPR': 0.8468406969449368, 'TP': 1009, 'FP': 284, 'TN': 2316, 'FN': 291} 

2023-01-03 17:13: **********Val Epoch 8: average Loss: 0.165176
2023-01-03 17:13: *********************************Current best model saved!
2023-01-03 17:14: 
 Testing metrics {'precision': 0.794392523364486, 'recall': 0.6921824104234527, 'f1-score': 0.7397737162750218, 'support': 1228, 'AUC': 0.9072529947267346, 'AUCPR': 0.844849145814325, 'TP': 850, 'FP': 220, 'TN': 2236, 'FN': 378} 

2023-01-03 17:20: 
 Testing metrics {'precision': 0.8853503184713376, 'recall': 0.9146811890174722, 'f1-score': 0.8997767857142857, 'support': 4407, 'AUC': 0.9764228567821405, 'AUCPR': 0.9573124224993674, 'TP': 4031, 'FP': 522, 'TN': 8292, 'FN': 376} 

2023-01-03 17:21: Train Epoch 9: 3/634 Loss: 0.164617
2023-01-03 17:21: Train Epoch 9: 7/634 Loss: 0.153431
2023-01-03 17:21: Train Epoch 9: 11/634 Loss: 0.161059
2023-01-03 17:21: Train Epoch 9: 15/634 Loss: 0.163449
2023-01-03 17:22: Train Epoch 9: 19/634 Loss: 0.153839
2023-01-03 17:22: Train Epoch 9: 23/634 Loss: 0.155502
2023-01-03 17:22: Train Epoch 9: 27/634 Loss: 0.166878
2023-01-03 17:23: Train Epoch 9: 31/634 Loss: 0.192037
2023-01-03 17:23: Train Epoch 9: 35/634 Loss: 0.185951
2023-01-03 17:23: Train Epoch 9: 39/634 Loss: 0.196942
2023-01-03 17:24: Train Epoch 9: 43/634 Loss: 0.144056
2023-01-03 17:24: Train Epoch 9: 47/634 Loss: 0.174900
2023-01-03 17:25: Train Epoch 9: 51/634 Loss: 0.181244
2023-01-03 17:25: Train Epoch 9: 55/634 Loss: 0.144824
2023-01-03 17:25: Train Epoch 9: 59/634 Loss: 0.186740
2023-01-03 17:26: Train Epoch 9: 63/634 Loss: 0.171438
2023-01-03 17:26: Train Epoch 9: 67/634 Loss: 0.165052
2023-01-03 17:26: Train Epoch 9: 71/634 Loss: 0.184386
2023-01-03 17:27: Train Epoch 9: 75/634 Loss: 0.162381
2023-01-03 17:27: Train Epoch 9: 79/634 Loss: 0.177027
2023-01-03 17:27: Train Epoch 9: 83/634 Loss: 0.146170
2023-01-03 17:28: Train Epoch 9: 87/634 Loss: 0.168839
2023-01-03 17:28: Train Epoch 9: 91/634 Loss: 0.174243
2023-01-03 17:28: Train Epoch 9: 95/634 Loss: 0.165085
2023-01-03 17:29: Train Epoch 9: 99/634 Loss: 0.200873
2023-01-03 17:29: Train Epoch 9: 103/634 Loss: 0.138699
2023-01-03 17:29: Train Epoch 9: 107/634 Loss: 0.161833
2023-01-03 17:30: Train Epoch 9: 111/634 Loss: 0.178438
2023-01-03 17:30: Train Epoch 9: 115/634 Loss: 0.156896
2023-01-03 17:31: Train Epoch 9: 119/634 Loss: 0.145774
2023-01-03 17:31: Train Epoch 9: 123/634 Loss: 0.164455
2023-01-03 17:31: Train Epoch 9: 127/634 Loss: 0.136012
2023-01-03 17:32: Train Epoch 9: 131/634 Loss: 0.164862
2023-01-03 17:32: Train Epoch 9: 135/634 Loss: 0.173681
2023-01-03 17:32: Train Epoch 9: 139/634 Loss: 0.180663
2023-01-03 17:33: Train Epoch 9: 143/634 Loss: 0.174324
2023-01-03 17:33: Train Epoch 9: 147/634 Loss: 0.178044
2023-01-03 17:33: Train Epoch 9: 151/634 Loss: 0.175739
2023-01-03 17:34: Train Epoch 9: 155/634 Loss: 0.186254
2023-01-03 17:34: Train Epoch 9: 159/634 Loss: 0.164338
2023-01-03 17:34: Train Epoch 9: 163/634 Loss: 0.180611
2023-01-03 17:35: Train Epoch 9: 167/634 Loss: 0.170585
2023-01-03 17:35: Train Epoch 9: 171/634 Loss: 0.154622
2023-01-03 17:35: Train Epoch 9: 175/634 Loss: 0.174681
2023-01-03 17:36: Train Epoch 9: 179/634 Loss: 0.205831
2023-01-03 17:36: Train Epoch 9: 183/634 Loss: 0.154115
2023-01-03 17:36: Train Epoch 9: 187/634 Loss: 0.173801
2023-01-03 17:37: Train Epoch 9: 191/634 Loss: 0.181334
2023-01-03 17:37: Train Epoch 9: 195/634 Loss: 0.157686
2023-01-03 17:38: Train Epoch 9: 199/634 Loss: 0.170156
2023-01-03 17:38: Train Epoch 9: 203/634 Loss: 0.138509
2023-01-03 17:38: Train Epoch 9: 207/634 Loss: 0.186783
2023-01-03 17:39: Train Epoch 9: 211/634 Loss: 0.150461
2023-01-03 17:39: Train Epoch 9: 215/634 Loss: 0.182697
2023-01-03 17:39: Train Epoch 9: 219/634 Loss: 0.173207
2023-01-03 17:40: Train Epoch 9: 223/634 Loss: 0.149266
2023-01-03 17:40: Train Epoch 9: 227/634 Loss: 0.131330
2023-01-03 17:40: Train Epoch 9: 231/634 Loss: 0.152976
2023-01-03 17:41: Train Epoch 9: 235/634 Loss: 0.168541
2023-01-03 17:41: Train Epoch 9: 239/634 Loss: 0.132272
2023-01-03 17:42: Train Epoch 9: 243/634 Loss: 0.170759
2023-01-03 17:42: Train Epoch 9: 247/634 Loss: 0.156902
2023-01-03 17:42: Train Epoch 9: 251/634 Loss: 0.139599
2023-01-03 17:43: Train Epoch 9: 255/634 Loss: 0.167639
2023-01-03 17:43: Train Epoch 9: 259/634 Loss: 0.155789
2023-01-03 17:43: Train Epoch 9: 263/634 Loss: 0.138815
2023-01-03 17:44: Train Epoch 9: 267/634 Loss: 0.186808
2023-01-03 17:44: Train Epoch 9: 271/634 Loss: 0.157848
2023-01-03 17:44: Train Epoch 9: 275/634 Loss: 0.148403
2023-01-03 17:45: Train Epoch 9: 279/634 Loss: 0.167673
2023-01-03 17:45: Train Epoch 9: 283/634 Loss: 0.157627
2023-01-03 17:46: Train Epoch 9: 287/634 Loss: 0.168583
2023-01-03 17:46: Train Epoch 9: 291/634 Loss: 0.150776
2023-01-03 17:46: Train Epoch 9: 295/634 Loss: 0.178043
2023-01-03 17:47: Train Epoch 9: 299/634 Loss: 0.167646
2023-01-03 17:47: Train Epoch 9: 303/634 Loss: 0.137101
2023-01-03 17:48: Train Epoch 9: 307/634 Loss: 0.163303
2023-01-03 17:48: Train Epoch 9: 311/634 Loss: 0.178667
2023-01-03 17:49: Train Epoch 9: 315/634 Loss: 0.176362
2023-01-03 17:49: Train Epoch 9: 319/634 Loss: 0.177836
2023-01-03 17:49: Train Epoch 9: 323/634 Loss: 0.155123
2023-01-03 17:50: Train Epoch 9: 327/634 Loss: 0.164525
2023-01-03 17:50: Train Epoch 9: 331/634 Loss: 0.162154
2023-01-03 17:51: Train Epoch 9: 335/634 Loss: 0.178168
2023-01-03 17:51: Train Epoch 9: 339/634 Loss: 0.180494
2023-01-03 17:51: Train Epoch 9: 343/634 Loss: 0.152085
2023-01-03 17:52: Train Epoch 9: 347/634 Loss: 0.170408
2023-01-03 17:52: Train Epoch 9: 351/634 Loss: 0.151710
2023-01-03 17:53: Train Epoch 9: 355/634 Loss: 0.179622
2023-01-03 17:53: Train Epoch 9: 359/634 Loss: 0.157679
2023-01-03 17:53: Train Epoch 9: 363/634 Loss: 0.134912
2023-01-03 17:54: Train Epoch 9: 367/634 Loss: 0.165291
2023-01-03 17:54: Train Epoch 9: 371/634 Loss: 0.173736
2023-01-03 17:54: Train Epoch 9: 375/634 Loss: 0.186961
2023-01-03 17:55: Train Epoch 9: 379/634 Loss: 0.159483
2023-01-03 17:55: Train Epoch 9: 383/634 Loss: 0.160681
2023-01-03 17:55: Train Epoch 9: 387/634 Loss: 0.144951
2023-01-03 17:56: Train Epoch 9: 391/634 Loss: 0.167768
2023-01-03 17:56: Train Epoch 9: 395/634 Loss: 0.156353
2023-01-03 17:56: Train Epoch 9: 399/634 Loss: 0.156892
2023-01-03 17:57: Train Epoch 9: 403/634 Loss: 0.144261
2023-01-03 17:57: Train Epoch 9: 407/634 Loss: 0.160645
2023-01-03 17:58: Train Epoch 9: 411/634 Loss: 0.178292
2023-01-03 17:58: Train Epoch 9: 415/634 Loss: 0.177225
2023-01-03 17:58: Train Epoch 9: 419/634 Loss: 0.173851
2023-01-03 17:59: Train Epoch 9: 423/634 Loss: 0.180142
2023-01-03 17:59: Train Epoch 9: 427/634 Loss: 0.173761
2023-01-03 17:59: Train Epoch 9: 431/634 Loss: 0.169363
2023-01-03 18:00: Train Epoch 9: 435/634 Loss: 0.166164
2023-01-03 18:00: Train Epoch 9: 439/634 Loss: 0.142026
2023-01-03 18:01: Train Epoch 9: 443/634 Loss: 0.171939
2023-01-03 18:01: Train Epoch 9: 447/634 Loss: 0.157285
2023-01-03 18:01: Train Epoch 9: 451/634 Loss: 0.149650
2023-01-03 18:02: Train Epoch 9: 455/634 Loss: 0.192785
2023-01-03 18:02: Train Epoch 9: 459/634 Loss: 0.141172
2023-01-03 18:03: Train Epoch 9: 463/634 Loss: 0.146747
2023-01-03 18:03: Train Epoch 9: 467/634 Loss: 0.175220
2023-01-03 18:03: Train Epoch 9: 471/634 Loss: 0.172682
2023-01-03 18:04: Train Epoch 9: 475/634 Loss: 0.159702
2023-01-03 18:04: Train Epoch 9: 479/634 Loss: 0.156864
2023-01-03 18:04: Train Epoch 9: 483/634 Loss: 0.142667
2023-01-03 18:05: Train Epoch 9: 487/634 Loss: 0.138318
2023-01-03 18:05: Train Epoch 9: 491/634 Loss: 0.151148
2023-01-03 18:06: Train Epoch 9: 495/634 Loss: 0.185178
2023-01-03 18:06: Train Epoch 9: 499/634 Loss: 0.138718
2023-01-03 18:06: Train Epoch 9: 503/634 Loss: 0.145260
2023-01-03 18:07: Train Epoch 9: 507/634 Loss: 0.165000
2023-01-03 18:07: Train Epoch 9: 511/634 Loss: 0.187504
2023-01-03 18:08: Train Epoch 9: 515/634 Loss: 0.143388
2023-01-03 18:08: Train Epoch 9: 519/634 Loss: 0.148142
2023-01-03 18:08: Train Epoch 9: 523/634 Loss: 0.182882
2023-01-03 18:09: Train Epoch 9: 527/634 Loss: 0.148832
2023-01-03 18:09: Train Epoch 9: 531/634 Loss: 0.165981
2023-01-03 18:09: Train Epoch 9: 535/634 Loss: 0.208029
2023-01-03 18:10: Train Epoch 9: 539/634 Loss: 0.147731
2023-01-03 18:10: Train Epoch 9: 543/634 Loss: 0.196057
2023-01-03 18:11: Train Epoch 9: 547/634 Loss: 0.187551
2023-01-03 18:11: Train Epoch 9: 551/634 Loss: 0.152470
2023-01-03 18:11: Train Epoch 9: 555/634 Loss: 0.175292
2023-01-03 18:12: Train Epoch 9: 559/634 Loss: 0.172906
2023-01-03 18:12: Train Epoch 9: 563/634 Loss: 0.143248
2023-01-03 18:12: Train Epoch 9: 567/634 Loss: 0.218062
2023-01-03 18:13: Train Epoch 9: 571/634 Loss: 0.159115
2023-01-03 18:13: Train Epoch 9: 575/634 Loss: 0.173315
2023-01-03 18:14: Train Epoch 9: 579/634 Loss: 0.168654
2023-01-03 18:14: Train Epoch 9: 583/634 Loss: 0.171630
2023-01-03 18:14: Train Epoch 9: 587/634 Loss: 0.143204
2023-01-03 18:15: Train Epoch 9: 591/634 Loss: 0.161332
2023-01-03 18:15: Train Epoch 9: 595/634 Loss: 0.155951
2023-01-03 18:16: Train Epoch 9: 599/634 Loss: 0.159734
2023-01-03 18:16: Train Epoch 9: 603/634 Loss: 0.169830
2023-01-03 18:17: Train Epoch 9: 607/634 Loss: 0.168540
2023-01-03 18:17: Train Epoch 9: 611/634 Loss: 0.169573
2023-01-03 18:17: Train Epoch 9: 615/634 Loss: 0.188580
2023-01-03 18:18: Train Epoch 9: 619/634 Loss: 0.148287
2023-01-03 18:18: Train Epoch 9: 623/634 Loss: 0.166192
2023-01-03 18:18: Train Epoch 9: 627/634 Loss: 0.149798
2023-01-03 18:19: Train Epoch 9: 631/634 Loss: 0.147584
2023-01-03 18:19: Train Epoch 9: 633/634 Loss: 0.054515
2023-01-03 18:19: **********Train Epoch 9: averaged Loss: 0.164186 
2023-01-03 18:19: 
Epoch time elapsed: 3523.934591770172

2023-01-03 18:21: 
 metrics validation: {'precision': 0.7888146911519198, 'recall': 0.7269230769230769, 'f1-score': 0.7566052842273819, 'support': 1300, 'AUC': 0.9146813609467455, 'AUCPR': 0.8339425381665407, 'TP': 945, 'FP': 253, 'TN': 2347, 'FN': 355} 

2023-01-03 18:21: **********Val Epoch 9: average Loss: 0.165683
2023-01-03 18:22: 
 Testing metrics {'precision': 0.794392523364486, 'recall': 0.6921824104234527, 'f1-score': 0.7397737162750218, 'support': 1228, 'AUC': 0.9072529947267346, 'AUCPR': 0.844849145814325, 'TP': 850, 'FP': 220, 'TN': 2236, 'FN': 378} 

2023-01-03 18:27: 
 Testing metrics {'precision': 0.8853503184713376, 'recall': 0.9146811890174722, 'f1-score': 0.8997767857142857, 'support': 4407, 'AUC': 0.9764228567821405, 'AUCPR': 0.9573124224993674, 'TP': 4031, 'FP': 522, 'TN': 8292, 'FN': 376} 

2023-01-03 18:28: Train Epoch 10: 3/634 Loss: 0.149129
2023-01-03 18:28: Train Epoch 10: 7/634 Loss: 0.154723
2023-01-03 18:28: Train Epoch 10: 11/634 Loss: 0.157184
2023-01-03 18:29: Train Epoch 10: 15/634 Loss: 0.166764
2023-01-03 18:29: Train Epoch 10: 19/634 Loss: 0.153949
2023-01-03 18:30: Train Epoch 10: 23/634 Loss: 0.146641
2023-01-03 18:30: Train Epoch 10: 27/634 Loss: 0.170098
2023-01-03 18:30: Train Epoch 10: 31/634 Loss: 0.157453
2023-01-03 18:31: Train Epoch 10: 35/634 Loss: 0.157541
2023-01-03 18:31: Train Epoch 10: 39/634 Loss: 0.204038
2023-01-03 18:31: Train Epoch 10: 43/634 Loss: 0.160519
2023-01-03 18:32: Train Epoch 10: 47/634 Loss: 0.181087
2023-01-03 18:32: Train Epoch 10: 51/634 Loss: 0.142961
2023-01-03 18:33: Train Epoch 10: 55/634 Loss: 0.132529
2023-01-03 18:33: Train Epoch 10: 59/634 Loss: 0.154501
2023-01-03 18:33: Train Epoch 10: 63/634 Loss: 0.153373
2023-01-03 18:34: Train Epoch 10: 67/634 Loss: 0.166297
2023-01-03 18:34: Train Epoch 10: 71/634 Loss: 0.170322
2023-01-03 18:34: Train Epoch 10: 75/634 Loss: 0.151618
2023-01-03 18:35: Train Epoch 10: 79/634 Loss: 0.193896
2023-01-03 18:35: Train Epoch 10: 83/634 Loss: 0.159470
2023-01-03 18:35: Train Epoch 10: 87/634 Loss: 0.152157
2023-01-03 18:36: Train Epoch 10: 91/634 Loss: 0.178520
2023-01-03 18:36: Train Epoch 10: 95/634 Loss: 0.175476
2023-01-03 18:37: Train Epoch 10: 99/634 Loss: 0.150678
2023-01-03 18:37: Train Epoch 10: 103/634 Loss: 0.144918
2023-01-03 18:37: Train Epoch 10: 107/634 Loss: 0.167989
2023-01-03 18:38: Train Epoch 10: 111/634 Loss: 0.165902
2023-01-03 18:38: Train Epoch 10: 115/634 Loss: 0.167914
2023-01-03 18:38: Train Epoch 10: 119/634 Loss: 0.166700
2023-01-03 18:39: Train Epoch 10: 123/634 Loss: 0.155739
2023-01-03 18:39: Train Epoch 10: 127/634 Loss: 0.146175
2023-01-03 18:40: Train Epoch 10: 131/634 Loss: 0.156201
2023-01-03 18:40: Train Epoch 10: 135/634 Loss: 0.167025
2023-01-03 18:40: Train Epoch 10: 139/634 Loss: 0.177615
2023-01-03 18:41: Train Epoch 10: 143/634 Loss: 0.173206
2023-01-03 18:41: Train Epoch 10: 147/634 Loss: 0.157432
2023-01-03 18:42: Train Epoch 10: 151/634 Loss: 0.152173
2023-01-03 18:42: Train Epoch 10: 155/634 Loss: 0.199093
2023-01-03 18:42: Train Epoch 10: 159/634 Loss: 0.187051
2023-01-03 18:43: Train Epoch 10: 163/634 Loss: 0.177770
2023-01-03 18:43: Train Epoch 10: 167/634 Loss: 0.149730
2023-01-03 18:43: Train Epoch 10: 171/634 Loss: 0.132296
2023-01-03 18:44: Train Epoch 10: 175/634 Loss: 0.184665
2023-01-03 18:44: Train Epoch 10: 179/634 Loss: 0.158602
2023-01-03 18:45: Train Epoch 10: 183/634 Loss: 0.215406
2023-01-03 18:46: Train Epoch 10: 187/634 Loss: 0.157020
2023-01-03 18:46: Train Epoch 10: 191/634 Loss: 0.157808
2023-01-03 18:46: Train Epoch 10: 195/634 Loss: 0.185496
2023-01-03 18:47: Train Epoch 10: 199/634 Loss: 0.170781
2023-01-03 18:47: Train Epoch 10: 203/634 Loss: 0.145892
2023-01-03 18:47: Train Epoch 10: 207/634 Loss: 0.153191
2023-01-03 18:48: Train Epoch 10: 211/634 Loss: 0.142137
2023-01-03 18:48: Train Epoch 10: 215/634 Loss: 0.182462
2023-01-03 18:48: Train Epoch 10: 219/634 Loss: 0.186878
2023-01-03 18:49: Train Epoch 10: 223/634 Loss: 0.156198
2023-01-03 18:49: Train Epoch 10: 227/634 Loss: 0.170074
2023-01-03 18:49: Train Epoch 10: 231/634 Loss: 0.151205
2023-01-03 18:50: Train Epoch 10: 235/634 Loss: 0.142360
2023-01-03 18:50: Train Epoch 10: 239/634 Loss: 0.153337
2023-01-03 18:51: Train Epoch 10: 243/634 Loss: 0.142788
2023-01-03 18:51: Train Epoch 10: 247/634 Loss: 0.160284
2023-01-03 18:51: Train Epoch 10: 251/634 Loss: 0.147450
2023-01-03 18:52: Train Epoch 10: 255/634 Loss: 0.153845
2023-01-03 18:52: Train Epoch 10: 259/634 Loss: 0.155514
2023-01-03 18:53: Train Epoch 10: 263/634 Loss: 0.146708
2023-01-03 18:53: Train Epoch 10: 267/634 Loss: 0.135509
2023-01-03 18:53: Train Epoch 10: 271/634 Loss: 0.151004
2023-01-03 18:54: Train Epoch 10: 275/634 Loss: 0.163608
2023-01-03 18:54: Train Epoch 10: 279/634 Loss: 0.174260
2023-01-03 18:54: Train Epoch 10: 283/634 Loss: 0.163698
2023-01-03 18:55: Train Epoch 10: 287/634 Loss: 0.155743
2023-01-03 18:55: Train Epoch 10: 291/634 Loss: 0.177717
2023-01-03 18:56: Train Epoch 10: 295/634 Loss: 0.157671
2023-01-03 18:56: Train Epoch 10: 299/634 Loss: 0.157671
2023-01-03 18:56: Train Epoch 10: 303/634 Loss: 0.161700
2023-01-03 18:57: Train Epoch 10: 307/634 Loss: 0.144011
2023-01-03 18:57: Train Epoch 10: 311/634 Loss: 0.179363
2023-01-03 18:57: Train Epoch 10: 315/634 Loss: 0.179883
2023-01-03 18:58: Train Epoch 10: 319/634 Loss: 0.174558
2023-01-03 18:58: Train Epoch 10: 323/634 Loss: 0.168841
2023-01-03 18:59: Train Epoch 10: 327/634 Loss: 0.149354
2023-01-03 18:59: Train Epoch 10: 331/634 Loss: 0.160759
2023-01-03 18:59: Train Epoch 10: 335/634 Loss: 0.181090
2023-01-03 19:00: Train Epoch 10: 339/634 Loss: 0.155087
2023-01-03 19:00: Train Epoch 10: 343/634 Loss: 0.156853
2023-01-03 19:01: Train Epoch 10: 347/634 Loss: 0.166982
2023-01-03 19:01: Train Epoch 10: 351/634 Loss: 0.187418
2023-01-03 19:01: Train Epoch 10: 355/634 Loss: 0.161874
2023-01-03 19:02: Train Epoch 10: 359/634 Loss: 0.167612
2023-01-03 19:02: Train Epoch 10: 363/634 Loss: 0.161974
2023-01-03 19:03: Train Epoch 10: 367/634 Loss: 0.149811
2023-01-03 19:03: Train Epoch 10: 371/634 Loss: 0.163154
2023-01-03 19:03: Train Epoch 10: 375/634 Loss: 0.206943
2023-01-03 19:04: Train Epoch 10: 379/634 Loss: 0.169699
2023-01-03 19:04: Train Epoch 10: 383/634 Loss: 0.155813
2023-01-03 19:05: Train Epoch 10: 387/634 Loss: 0.197110
2023-01-03 19:05: Train Epoch 10: 391/634 Loss: 0.172212
2023-01-03 19:05: Train Epoch 10: 395/634 Loss: 0.171116
2023-01-03 19:06: Train Epoch 10: 399/634 Loss: 0.179998
2023-01-03 19:06: Train Epoch 10: 403/634 Loss: 0.157778
2023-01-03 19:06: Train Epoch 10: 407/634 Loss: 0.169197
2023-01-03 19:07: Train Epoch 10: 411/634 Loss: 0.157496
2023-01-03 19:07: Train Epoch 10: 415/634 Loss: 0.211824
2023-01-03 19:07: Train Epoch 10: 419/634 Loss: 0.170054
2023-01-03 19:08: Train Epoch 10: 423/634 Loss: 0.161173
2023-01-03 19:08: Train Epoch 10: 427/634 Loss: 0.177789
2023-01-03 19:09: Train Epoch 10: 431/634 Loss: 0.179351
2023-01-03 19:09: Train Epoch 10: 435/634 Loss: 0.154780
2023-01-03 19:09: Train Epoch 10: 439/634 Loss: 0.139270
2023-01-03 19:10: Train Epoch 10: 443/634 Loss: 0.165564
2023-01-03 19:10: Train Epoch 10: 447/634 Loss: 0.173340
2023-01-03 19:11: Train Epoch 10: 451/634 Loss: 0.170347
2023-01-03 19:11: Train Epoch 10: 455/634 Loss: 0.174885
2023-01-03 19:12: Train Epoch 10: 459/634 Loss: 0.157081
2023-01-03 19:12: Train Epoch 10: 463/634 Loss: 0.178092
2023-01-03 19:12: Train Epoch 10: 467/634 Loss: 0.177541
2023-01-03 19:13: Train Epoch 10: 471/634 Loss: 0.174856
2023-01-03 19:13: Train Epoch 10: 475/634 Loss: 0.157674
2023-01-03 19:14: Train Epoch 10: 479/634 Loss: 0.166534
2023-01-03 19:14: Train Epoch 10: 483/634 Loss: 0.147489
2023-01-03 19:15: Train Epoch 10: 487/634 Loss: 0.145642
2023-01-03 19:15: Train Epoch 10: 491/634 Loss: 0.175392
2023-01-03 19:16: Train Epoch 10: 495/634 Loss: 0.157645
2023-01-03 19:16: Train Epoch 10: 499/634 Loss: 0.151288
2023-01-03 19:16: Train Epoch 10: 503/634 Loss: 0.161388
2023-01-03 19:17: Train Epoch 10: 507/634 Loss: 0.176267
2023-01-03 19:17: Train Epoch 10: 511/634 Loss: 0.162968
2023-01-03 19:17: Train Epoch 10: 515/634 Loss: 0.149888
2023-01-03 19:18: Train Epoch 10: 519/634 Loss: 0.156981
2023-01-03 19:18: Train Epoch 10: 523/634 Loss: 0.159488
2023-01-03 19:19: Train Epoch 10: 527/634 Loss: 0.142244
2023-01-03 19:19: Train Epoch 10: 531/634 Loss: 0.159105
2023-01-03 19:19: Train Epoch 10: 535/634 Loss: 0.127886
2023-01-03 19:20: Train Epoch 10: 539/634 Loss: 0.153880
2023-01-03 19:20: Train Epoch 10: 543/634 Loss: 0.156900
2023-01-03 19:21: Train Epoch 10: 547/634 Loss: 0.195844
2023-01-03 19:21: Train Epoch 10: 551/634 Loss: 0.152049
2023-01-03 19:22: Train Epoch 10: 555/634 Loss: 0.140548
2023-01-03 19:22: Train Epoch 10: 559/634 Loss: 0.145465
2023-01-03 19:23: Train Epoch 10: 563/634 Loss: 0.155065
2023-01-03 19:23: Train Epoch 10: 567/634 Loss: 0.157242
2023-01-03 19:23: Train Epoch 10: 571/634 Loss: 0.161626
2023-01-03 19:24: Train Epoch 10: 575/634 Loss: 0.159159
2023-01-03 19:24: Train Epoch 10: 579/634 Loss: 0.152176
2023-01-03 19:24: Train Epoch 10: 583/634 Loss: 0.163034
2023-01-03 19:25: Train Epoch 10: 587/634 Loss: 0.178501
2023-01-03 19:25: Train Epoch 10: 591/634 Loss: 0.165231
2023-01-03 19:26: Train Epoch 10: 595/634 Loss: 0.176762
2023-01-03 19:26: Train Epoch 10: 599/634 Loss: 0.154528
2023-01-03 19:26: Train Epoch 10: 603/634 Loss: 0.140201
2023-01-03 19:27: Train Epoch 10: 607/634 Loss: 0.131561
2023-01-03 19:27: Train Epoch 10: 611/634 Loss: 0.183847
2023-01-03 19:27: Train Epoch 10: 615/634 Loss: 0.129816
2023-01-03 19:28: Train Epoch 10: 619/634 Loss: 0.212120
2023-01-03 19:28: Train Epoch 10: 623/634 Loss: 0.160807
2023-01-03 19:28: Train Epoch 10: 627/634 Loss: 0.166423
2023-01-03 19:29: Train Epoch 10: 631/634 Loss: 0.157507
2023-01-03 19:29: Train Epoch 10: 633/634 Loss: 0.057502
2023-01-03 19:29: **********Train Epoch 10: averaged Loss: 0.162403 
2023-01-03 19:29: 
Epoch time elapsed: 3693.0921444892883

2023-01-03 19:31: 
 metrics validation: {'precision': 0.8982511923688394, 'recall': 0.4346153846153846, 'f1-score': 0.5857957490927942, 'support': 1300, 'AUC': 0.9227156804733726, 'AUCPR': 0.8544116239095978, 'TP': 565, 'FP': 64, 'TN': 2536, 'FN': 735} 

2023-01-03 19:31: **********Val Epoch 10: average Loss: 0.200946
2023-01-03 19:32: 
 Testing metrics {'precision': 0.794392523364486, 'recall': 0.6921824104234527, 'f1-score': 0.7397737162750218, 'support': 1228, 'AUC': 0.9072529947267346, 'AUCPR': 0.844849145814325, 'TP': 850, 'FP': 220, 'TN': 2236, 'FN': 378} 

2023-01-03 19:38: 
 Testing metrics {'precision': 0.8853503184713376, 'recall': 0.9146811890174722, 'f1-score': 0.8997767857142857, 'support': 4407, 'AUC': 0.9764228567821405, 'AUCPR': 0.9573124224993674, 'TP': 4031, 'FP': 522, 'TN': 8292, 'FN': 376} 

2023-01-03 19:38: Train Epoch 11: 3/634 Loss: 0.152601
2023-01-03 19:38: Train Epoch 11: 7/634 Loss: 0.178779
2023-01-03 19:39: Train Epoch 11: 11/634 Loss: 0.155334
2023-01-03 19:39: Train Epoch 11: 15/634 Loss: 0.154139
2023-01-03 19:40: Train Epoch 11: 19/634 Loss: 0.155990
2023-01-03 19:40: Train Epoch 11: 23/634 Loss: 0.145688
2023-01-03 19:40: Train Epoch 11: 27/634 Loss: 0.159025
2023-01-03 19:41: Train Epoch 11: 31/634 Loss: 0.168786
2023-01-03 19:41: Train Epoch 11: 35/634 Loss: 0.170397
2023-01-03 19:42: Train Epoch 11: 39/634 Loss: 0.176578
2023-01-03 19:42: Train Epoch 11: 43/634 Loss: 0.178924
2023-01-03 19:43: Train Epoch 11: 47/634 Loss: 0.183903
2023-01-03 19:43: Train Epoch 11: 51/634 Loss: 0.156143
2023-01-03 19:44: Train Epoch 11: 55/634 Loss: 0.169769
2023-01-03 19:44: Train Epoch 11: 59/634 Loss: 0.153747
2023-01-03 19:44: Train Epoch 11: 63/634 Loss: 0.145169
2023-01-03 19:45: Train Epoch 11: 67/634 Loss: 0.172111
2023-01-03 19:45: Train Epoch 11: 71/634 Loss: 0.123452
2023-01-03 19:46: Train Epoch 11: 75/634 Loss: 0.151082
2023-01-03 19:46: Train Epoch 11: 79/634 Loss: 0.177312
2023-01-03 19:46: Train Epoch 11: 83/634 Loss: 0.160451
2023-01-03 19:47: Train Epoch 11: 87/634 Loss: 0.165938
2023-01-03 19:47: Train Epoch 11: 91/634 Loss: 0.158342
2023-01-03 19:48: Train Epoch 11: 95/634 Loss: 0.180275
2023-01-03 19:48: Train Epoch 11: 99/634 Loss: 0.138033
2023-01-03 19:48: Train Epoch 11: 103/634 Loss: 0.181619
2023-01-03 19:49: Train Epoch 11: 107/634 Loss: 0.143569
2023-01-03 19:49: Train Epoch 11: 111/634 Loss: 0.203345
2023-01-03 19:50: Train Epoch 11: 115/634 Loss: 0.155228
2023-01-03 19:50: Train Epoch 11: 119/634 Loss: 0.201216
2023-01-03 19:50: Train Epoch 11: 123/634 Loss: 0.161661
2023-01-03 19:51: Train Epoch 11: 127/634 Loss: 0.207182
2023-01-03 19:51: Train Epoch 11: 131/634 Loss: 0.197658
2023-01-03 19:52: Train Epoch 11: 135/634 Loss: 0.184911
2023-01-03 19:52: Train Epoch 11: 139/634 Loss: 0.191913
2023-01-03 19:52: Train Epoch 11: 143/634 Loss: 0.157769
2023-01-03 19:53: Train Epoch 11: 147/634 Loss: 0.161149
2023-01-03 19:53: Train Epoch 11: 151/634 Loss: 0.206897
2023-01-03 19:54: Train Epoch 11: 155/634 Loss: 0.180921
2023-01-03 19:54: Train Epoch 11: 159/634 Loss: 0.185969
2023-01-03 19:54: Train Epoch 11: 163/634 Loss: 0.181987
2023-01-03 19:55: Train Epoch 11: 167/634 Loss: 0.169028
2023-01-03 19:55: Train Epoch 11: 171/634 Loss: 0.138162
2023-01-03 19:56: Train Epoch 11: 175/634 Loss: 0.182618
