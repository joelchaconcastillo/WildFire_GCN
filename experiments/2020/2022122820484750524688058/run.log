2022-12-28 20:48: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122820484750524688058
2022-12-28 20:48: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122820484750524688058
2022-12-28 20:48: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=128, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122820484750524688058', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0005, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-28 20:48: Argument batch_size: 256
2022-12-28 20:48: Argument clc: 'vec'
2022-12-28 20:48: Argument cuda: True
2022-12-28 20:48: Argument dataset: '2020'
2022-12-28 20:48: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-28 20:48: Argument debug: False
2022-12-28 20:48: Argument default_graph: True
2022-12-28 20:48: Argument device: 'cpu'
2022-12-28 20:48: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-28 20:48: Argument early_stop: True
2022-12-28 20:48: Argument early_stop_patience: 8
2022-12-28 20:48: Argument embed_dim: 128
2022-12-28 20:48: Argument epochs: 30
2022-12-28 20:48: Argument grad_norm: False
2022-12-28 20:48: Argument horizon: 1
2022-12-28 20:48: Argument input_dim: 25
2022-12-28 20:48: Argument lag: 10
2022-12-28 20:48: Argument link_len: 2
2022-12-28 20:48: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122820484750524688058'
2022-12-28 20:48: Argument log_step: 1
2022-12-28 20:48: Argument loss_func: 'nllloss'
2022-12-28 20:48: Argument lr_decay: True
2022-12-28 20:48: Argument lr_decay_rate: 0.1
2022-12-28 20:48: Argument lr_decay_step: '15, 20'
2022-12-28 20:48: Argument lr_init: 0.0005
2022-12-28 20:48: Argument max_grad_norm: 5
2022-12-28 20:48: Argument minbatch_size: 64
2022-12-28 20:48: Argument mode: 'train'
2022-12-28 20:48: Argument model: 'fire_GCN'
2022-12-28 20:48: Argument nan_fill: 0.5
2022-12-28 20:48: Argument num_layers: 1
2022-12-28 20:48: Argument num_nodes: 625
2022-12-28 20:48: Argument num_workers: 20
2022-12-28 20:48: Argument output_dim: 2
2022-12-28 20:48: Argument patch_height: 25
2022-12-28 20:48: Argument patch_width: 25
2022-12-28 20:48: Argument persistent_workers: True
2022-12-28 20:48: Argument pin_memory: True
2022-12-28 20:48: Argument plot: False
2022-12-28 20:48: Argument positive_weight: 0.5
2022-12-28 20:48: Argument prefetch_factor: 2
2022-12-28 20:48: Argument real_value: True
2022-12-28 20:48: Argument rnn_units: 16
2022-12-28 20:48: Argument seed: 10000
2022-12-28 20:48: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-28 20:48: Argument teacher_forcing: False
2022-12-28 20:48: Argument weight_decay: 0.0
2022-12-28 20:48: Argument window_len: 10
2022-12-28 20:48: Train Epoch 1: 3/634 Loss: 2.473038
2022-12-28 20:48: Train Epoch 1: 7/634 Loss: 0.629751
2022-12-28 20:49: Train Epoch 1: 11/634 Loss: 0.595303
2022-12-28 20:49: Train Epoch 1: 15/634 Loss: 0.585725
2022-12-28 20:49: Train Epoch 1: 19/634 Loss: 0.587641
2022-12-28 20:49: Train Epoch 1: 23/634 Loss: 0.549770
2022-12-28 20:49: Train Epoch 1: 27/634 Loss: 0.544765
2022-12-28 20:49: Train Epoch 1: 31/634 Loss: 0.471212
2022-12-28 20:49: Train Epoch 1: 35/634 Loss: 0.510193
2022-12-28 20:49: Train Epoch 1: 39/634 Loss: 0.500019
2022-12-28 20:49: Train Epoch 1: 43/634 Loss: 0.557121
2022-12-28 20:49: Train Epoch 1: 47/634 Loss: 0.491959
2022-12-28 20:49: Train Epoch 1: 51/634 Loss: 0.491606
2022-12-28 20:50: Train Epoch 1: 55/634 Loss: 0.445985
2022-12-28 20:50: Train Epoch 1: 59/634 Loss: 0.487477
2022-12-28 20:50: Train Epoch 1: 63/634 Loss: 0.415782
2022-12-28 20:50: Train Epoch 1: 67/634 Loss: 0.400070
2022-12-28 20:50: Train Epoch 1: 71/634 Loss: 0.538250
2022-12-28 20:50: Train Epoch 1: 75/634 Loss: 0.450402
2022-12-28 20:50: Train Epoch 1: 79/634 Loss: 0.502760
2022-12-28 20:50: Train Epoch 1: 83/634 Loss: 0.461343
2022-12-28 20:50: Train Epoch 1: 87/634 Loss: 0.435146
2022-12-28 20:50: Train Epoch 1: 91/634 Loss: 0.387646
2022-12-28 20:50: Train Epoch 1: 95/634 Loss: 0.360980
2022-12-28 20:50: Train Epoch 1: 99/634 Loss: 0.406857
2022-12-28 20:51: Train Epoch 1: 103/634 Loss: 0.423946
2022-12-28 20:51: Train Epoch 1: 107/634 Loss: 0.372129
2022-12-28 20:51: Train Epoch 1: 111/634 Loss: 0.425849
2022-12-28 20:51: Train Epoch 1: 115/634 Loss: 0.435773
2022-12-28 20:51: Train Epoch 1: 119/634 Loss: 0.374647
2022-12-28 20:51: Train Epoch 1: 123/634 Loss: 0.488849
2022-12-28 20:51: Train Epoch 1: 127/634 Loss: 0.302328
2022-12-28 20:51: Train Epoch 1: 131/634 Loss: 0.344906
2022-12-28 20:51: Train Epoch 1: 135/634 Loss: 0.352347
2022-12-28 20:51: Train Epoch 1: 139/634 Loss: 0.338553
2022-12-28 20:51: Train Epoch 1: 143/634 Loss: 0.363489
2022-12-28 20:52: Train Epoch 1: 147/634 Loss: 0.418773
2022-12-28 20:52: Train Epoch 1: 151/634 Loss: 0.303465
2022-12-28 20:52: Train Epoch 1: 155/634 Loss: 0.395889
2022-12-28 20:52: Train Epoch 1: 159/634 Loss: 0.342568
2022-12-28 20:52: Train Epoch 1: 163/634 Loss: 0.271739
2022-12-28 20:52: Train Epoch 1: 167/634 Loss: 0.337368
2022-12-28 20:52: Train Epoch 1: 171/634 Loss: 0.298055
2022-12-28 20:52: Train Epoch 1: 175/634 Loss: 0.357553
2022-12-28 20:52: Train Epoch 1: 179/634 Loss: 0.329906
2022-12-28 20:52: Train Epoch 1: 183/634 Loss: 0.319453
2022-12-28 20:52: Train Epoch 1: 187/634 Loss: 0.348311
2022-12-28 20:53: Train Epoch 1: 191/634 Loss: 0.338378
2022-12-28 20:53: Train Epoch 1: 195/634 Loss: 0.277264
2022-12-28 20:53: Train Epoch 1: 199/634 Loss: 0.367239
2022-12-28 20:53: Train Epoch 1: 203/634 Loss: 0.269309
2022-12-28 20:53: Train Epoch 1: 207/634 Loss: 0.368927
2022-12-28 20:53: Train Epoch 1: 211/634 Loss: 0.275171
2022-12-28 20:53: Train Epoch 1: 215/634 Loss: 0.307965
2022-12-28 20:53: Train Epoch 1: 219/634 Loss: 0.286743
2022-12-28 20:53: Train Epoch 1: 223/634 Loss: 0.349520
2022-12-28 20:53: Train Epoch 1: 227/634 Loss: 0.345220
2022-12-28 20:53: Train Epoch 1: 231/634 Loss: 0.324150
2022-12-28 20:54: Train Epoch 1: 235/634 Loss: 0.266434
2022-12-28 20:54: Train Epoch 1: 239/634 Loss: 0.298437
2022-12-28 20:54: Train Epoch 1: 243/634 Loss: 0.277970
2022-12-28 20:54: Train Epoch 1: 247/634 Loss: 0.334046
2022-12-28 20:54: Train Epoch 1: 251/634 Loss: 0.321794
2022-12-28 20:54: Train Epoch 1: 255/634 Loss: 0.331469
2022-12-28 20:54: Train Epoch 1: 259/634 Loss: 0.305793
2022-12-28 20:54: Train Epoch 1: 263/634 Loss: 0.310025
2022-12-28 20:54: Train Epoch 1: 267/634 Loss: 0.332497
2022-12-28 20:54: Train Epoch 1: 271/634 Loss: 0.316007
2022-12-28 20:54: Train Epoch 1: 275/634 Loss: 0.271363
2022-12-28 20:55: Train Epoch 1: 279/634 Loss: 0.306448
2022-12-28 20:55: Train Epoch 1: 283/634 Loss: 0.251949
2022-12-28 20:55: Train Epoch 1: 287/634 Loss: 0.284861
2022-12-28 20:55: Train Epoch 1: 291/634 Loss: 0.225932
2022-12-28 20:55: Train Epoch 1: 295/634 Loss: 0.272292
2022-12-28 20:55: Train Epoch 1: 299/634 Loss: 0.263497
2022-12-28 20:55: Train Epoch 1: 303/634 Loss: 0.365493
2022-12-28 20:55: Train Epoch 1: 307/634 Loss: 0.306050
2022-12-28 20:55: Train Epoch 1: 311/634 Loss: 0.359931
2022-12-28 20:55: Train Epoch 1: 315/634 Loss: 0.293298
2022-12-28 20:55: Train Epoch 1: 319/634 Loss: 0.413156
2022-12-28 20:56: Train Epoch 1: 323/634 Loss: 0.267194
2022-12-28 20:56: Train Epoch 1: 327/634 Loss: 0.366528
2022-12-28 20:56: Train Epoch 1: 331/634 Loss: 0.342010
2022-12-28 20:56: Train Epoch 1: 335/634 Loss: 0.331920
2022-12-28 20:56: Train Epoch 1: 339/634 Loss: 0.319259
2022-12-28 20:56: Train Epoch 1: 343/634 Loss: 0.317842
2022-12-28 20:56: Train Epoch 1: 347/634 Loss: 0.300113
2022-12-28 20:56: Train Epoch 1: 351/634 Loss: 0.318649
2022-12-28 20:56: Train Epoch 1: 355/634 Loss: 0.268263
2022-12-28 20:56: Train Epoch 1: 359/634 Loss: 0.291756
2022-12-28 20:56: Train Epoch 1: 363/634 Loss: 0.303652
2022-12-28 20:56: Train Epoch 1: 367/634 Loss: 0.312834
2022-12-28 20:57: Train Epoch 1: 371/634 Loss: 0.324028
2022-12-28 20:57: Train Epoch 1: 375/634 Loss: 0.260355
2022-12-28 20:57: Train Epoch 1: 379/634 Loss: 0.275192
2022-12-28 20:57: Train Epoch 1: 383/634 Loss: 0.308319
2022-12-28 20:57: Train Epoch 1: 387/634 Loss: 0.430213
2022-12-28 20:57: Train Epoch 1: 391/634 Loss: 0.361647
2022-12-28 20:57: Train Epoch 1: 395/634 Loss: 0.261905
2022-12-28 20:57: Train Epoch 1: 399/634 Loss: 0.335189
2022-12-28 20:57: Train Epoch 1: 403/634 Loss: 0.255914
2022-12-28 20:57: Train Epoch 1: 407/634 Loss: 0.347240
2022-12-28 20:57: Train Epoch 1: 411/634 Loss: 0.329175
2022-12-28 20:58: Train Epoch 1: 415/634 Loss: 0.333124
2022-12-28 20:58: Train Epoch 1: 419/634 Loss: 0.459520
2022-12-28 20:58: Train Epoch 1: 423/634 Loss: 0.234475
2022-12-28 20:58: Train Epoch 1: 427/634 Loss: 0.382081
2022-12-28 20:58: Train Epoch 1: 431/634 Loss: 0.352272
2022-12-28 20:58: Train Epoch 1: 435/634 Loss: 0.312371
2022-12-28 20:58: Train Epoch 1: 439/634 Loss: 0.307811
2022-12-28 20:58: Train Epoch 1: 443/634 Loss: 0.273889
2022-12-28 20:58: Train Epoch 1: 447/634 Loss: 0.277890
2022-12-28 20:58: Train Epoch 1: 451/634 Loss: 0.388455
2022-12-28 20:59: Train Epoch 1: 455/634 Loss: 0.336518
2022-12-28 20:59: Train Epoch 1: 459/634 Loss: 0.296907
2022-12-28 20:59: Train Epoch 1: 463/634 Loss: 0.264128
2022-12-28 20:59: Train Epoch 1: 467/634 Loss: 0.303638
2022-12-28 20:59: Train Epoch 1: 471/634 Loss: 0.263269
2022-12-28 20:59: Train Epoch 1: 475/634 Loss: 0.364022
2022-12-28 20:59: Train Epoch 1: 479/634 Loss: 0.390215
2022-12-28 20:59: Train Epoch 1: 483/634 Loss: 0.310890
2022-12-28 20:59: Train Epoch 1: 487/634 Loss: 0.316812
2022-12-28 20:59: Train Epoch 1: 491/634 Loss: 0.254664
2022-12-28 20:59: Train Epoch 1: 495/634 Loss: 0.267626
2022-12-28 20:59: Train Epoch 1: 499/634 Loss: 0.310039
2022-12-28 21:00: Train Epoch 1: 503/634 Loss: 0.310800
2022-12-28 21:00: Train Epoch 1: 507/634 Loss: 0.347661
2022-12-28 21:00: Train Epoch 1: 511/634 Loss: 0.366354
2022-12-28 21:00: Train Epoch 1: 515/634 Loss: 0.283211
2022-12-28 21:00: Train Epoch 1: 519/634 Loss: 0.271660
2022-12-28 21:00: Train Epoch 1: 523/634 Loss: 0.289031
2022-12-28 21:00: Train Epoch 1: 527/634 Loss: 0.297057
2022-12-28 21:00: Train Epoch 1: 531/634 Loss: 0.264025
2022-12-28 21:00: Train Epoch 1: 535/634 Loss: 0.306690
2022-12-28 21:00: Train Epoch 1: 539/634 Loss: 0.302375
2022-12-28 21:01: Train Epoch 1: 543/634 Loss: 0.267829
2022-12-28 21:01: Train Epoch 1: 547/634 Loss: 0.276524
2022-12-28 21:01: Train Epoch 1: 551/634 Loss: 0.304422
2022-12-28 21:01: Train Epoch 1: 555/634 Loss: 0.287143
2022-12-28 21:01: Train Epoch 1: 559/634 Loss: 0.316450
2022-12-28 21:01: Train Epoch 1: 563/634 Loss: 0.295110
2022-12-28 21:01: Train Epoch 1: 567/634 Loss: 0.310401
2022-12-28 21:01: Train Epoch 1: 571/634 Loss: 0.341903
2022-12-28 21:01: Train Epoch 1: 575/634 Loss: 0.292180
2022-12-28 21:01: Train Epoch 1: 579/634 Loss: 0.307597
2022-12-28 21:01: Train Epoch 1: 583/634 Loss: 0.318952
2022-12-28 21:02: Train Epoch 1: 587/634 Loss: 0.300066
2022-12-28 21:02: Train Epoch 1: 591/634 Loss: 0.317776
2022-12-28 21:02: Train Epoch 1: 595/634 Loss: 0.366919
2022-12-28 21:02: Train Epoch 1: 599/634 Loss: 0.322008
2022-12-28 21:02: Train Epoch 1: 603/634 Loss: 0.277912
2022-12-28 21:02: Train Epoch 1: 607/634 Loss: 0.316568
2022-12-28 21:02: Train Epoch 1: 611/634 Loss: 0.290433
2022-12-28 21:02: Train Epoch 1: 615/634 Loss: 0.275609
2022-12-28 21:02: Train Epoch 1: 619/634 Loss: 0.309044
2022-12-28 21:02: Train Epoch 1: 623/634 Loss: 0.301114
2022-12-28 21:02: Train Epoch 1: 627/634 Loss: 0.300810
2022-12-28 21:02: Train Epoch 1: 631/634 Loss: 0.229530
2022-12-28 21:02: Train Epoch 1: 633/634 Loss: 0.129125
2022-12-28 21:02: **********Train Epoch 1: averaged Loss: 0.357040 
2022-12-28 21:02: 
Epoch time elapsed: 850.3456881046295

2022-12-28 21:03: 
 metrics validation: {'precision': 0.7609756097560976, 'recall': 0.6, 'f1-score': 0.6709677419354839, 'support': 1300, 'AUC': 0.840675, 'AUCPR': 0.7408165703288292, 'TP': 780, 'FP': 245, 'TN': 2355, 'FN': 520} 

2022-12-28 21:03: **********Val Epoch 1: average Loss: 0.493626
2022-12-28 21:03: *********************************Current best model saved!
2022-12-28 21:03: 
 Testing metrics {'precision': 0.828693790149893, 'recall': 0.6302931596091205, 'f1-score': 0.7160037002775207, 'support': 1228, 'AUC': 0.878200962344428, 'AUCPR': 0.8118166130858415, 'TP': 774, 'FP': 160, 'TN': 2296, 'FN': 454} 

2022-12-28 21:03: Train Epoch 2: 3/634 Loss: 0.292744
2022-12-28 21:03: Train Epoch 2: 7/634 Loss: 0.269059
2022-12-28 21:04: Train Epoch 2: 11/634 Loss: 0.260556
2022-12-28 21:04: Train Epoch 2: 15/634 Loss: 0.248941
2022-12-28 21:04: Train Epoch 2: 19/634 Loss: 0.249076
2022-12-28 21:04: Train Epoch 2: 23/634 Loss: 0.296388
2022-12-28 21:04: Train Epoch 2: 27/634 Loss: 0.271193
2022-12-28 21:04: Train Epoch 2: 31/634 Loss: 0.250989
2022-12-28 21:04: Train Epoch 2: 35/634 Loss: 0.273250
2022-12-28 21:04: Train Epoch 2: 39/634 Loss: 0.349143
2022-12-28 21:04: Train Epoch 2: 43/634 Loss: 0.226717
2022-12-28 21:04: Train Epoch 2: 47/634 Loss: 0.197385
2022-12-28 21:04: Train Epoch 2: 51/634 Loss: 0.270067
2022-12-28 21:05: Train Epoch 2: 55/634 Loss: 0.260415
2022-12-28 21:05: Train Epoch 2: 59/634 Loss: 0.250078
2022-12-28 21:05: Train Epoch 2: 63/634 Loss: 0.239622
2022-12-28 21:05: Train Epoch 2: 67/634 Loss: 0.273422
2022-12-28 21:05: Train Epoch 2: 71/634 Loss: 0.220619
2022-12-28 21:05: Train Epoch 2: 75/634 Loss: 0.312190
2022-12-28 21:05: Train Epoch 2: 79/634 Loss: 0.218674
2022-12-28 21:05: Train Epoch 2: 83/634 Loss: 0.264489
2022-12-28 21:05: Train Epoch 2: 87/634 Loss: 0.337738
2022-12-28 21:05: Train Epoch 2: 91/634 Loss: 0.225494
2022-12-28 21:05: Train Epoch 2: 95/634 Loss: 0.299027
2022-12-28 21:06: Train Epoch 2: 99/634 Loss: 0.319576
2022-12-28 21:06: Train Epoch 2: 103/634 Loss: 0.208800
2022-12-28 21:06: Train Epoch 2: 107/634 Loss: 0.254952
2022-12-28 21:06: Train Epoch 2: 111/634 Loss: 0.282825
2022-12-28 21:06: Train Epoch 2: 115/634 Loss: 0.266442
2022-12-28 21:06: Train Epoch 2: 119/634 Loss: 0.311818
2022-12-28 21:06: Train Epoch 2: 123/634 Loss: 0.247942
2022-12-28 21:06: Train Epoch 2: 127/634 Loss: 0.371275
2022-12-28 21:06: Train Epoch 2: 131/634 Loss: 0.228283
2022-12-28 21:06: Train Epoch 2: 135/634 Loss: 0.252668
2022-12-28 21:06: Train Epoch 2: 139/634 Loss: 0.245426
2022-12-28 21:07: Train Epoch 2: 143/634 Loss: 0.231478
2022-12-28 21:07: Train Epoch 2: 147/634 Loss: 0.308706
2022-12-28 21:07: Train Epoch 2: 151/634 Loss: 0.258103
2022-12-28 21:07: Train Epoch 2: 155/634 Loss: 0.252507
2022-12-28 21:07: Train Epoch 2: 159/634 Loss: 0.290337
2022-12-28 21:07: Train Epoch 2: 163/634 Loss: 0.216145
2022-12-28 21:07: Train Epoch 2: 167/634 Loss: 0.194652
2022-12-28 21:07: Train Epoch 2: 171/634 Loss: 0.285898
