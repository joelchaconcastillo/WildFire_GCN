2022-12-29 15:42: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122915421269493369118
2022-12-29 15:42: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122915421269493369118
2022-12-29 15:42: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=128, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122915421269493369118', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0005, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-29 15:42: Argument batch_size: 256
2022-12-29 15:42: Argument clc: 'vec'
2022-12-29 15:42: Argument cuda: True
2022-12-29 15:42: Argument dataset: '2020'
2022-12-29 15:42: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-29 15:42: Argument debug: False
2022-12-29 15:42: Argument default_graph: True
2022-12-29 15:42: Argument device: 'cpu'
2022-12-29 15:42: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-29 15:42: Argument early_stop: True
2022-12-29 15:42: Argument early_stop_patience: 8
2022-12-29 15:42: Argument embed_dim: 128
2022-12-29 15:42: Argument epochs: 30
2022-12-29 15:42: Argument grad_norm: False
2022-12-29 15:42: Argument horizon: 1
2022-12-29 15:42: Argument input_dim: 25
2022-12-29 15:42: Argument lag: 10
2022-12-29 15:42: Argument link_len: 2
2022-12-29 15:42: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122915421269493369118'
2022-12-29 15:42: Argument log_step: 1
2022-12-29 15:42: Argument loss_func: 'nllloss'
2022-12-29 15:42: Argument lr_decay: True
2022-12-29 15:42: Argument lr_decay_rate: 0.1
2022-12-29 15:42: Argument lr_decay_step: '15, 20'
2022-12-29 15:42: Argument lr_init: 0.0005
2022-12-29 15:42: Argument max_grad_norm: 5
2022-12-29 15:42: Argument minbatch_size: 64
2022-12-29 15:42: Argument mode: 'train'
2022-12-29 15:42: Argument model: 'fire_GCN'
2022-12-29 15:42: Argument nan_fill: 0.5
2022-12-29 15:42: Argument num_layers: 1
2022-12-29 15:42: Argument num_nodes: 625
2022-12-29 15:42: Argument num_workers: 20
2022-12-29 15:42: Argument output_dim: 2
2022-12-29 15:42: Argument patch_height: 25
2022-12-29 15:42: Argument patch_width: 25
2022-12-29 15:42: Argument persistent_workers: True
2022-12-29 15:42: Argument pin_memory: True
2022-12-29 15:42: Argument plot: False
2022-12-29 15:42: Argument positive_weight: 0.5
2022-12-29 15:42: Argument prefetch_factor: 2
2022-12-29 15:42: Argument real_value: True
2022-12-29 15:42: Argument rnn_units: 16
2022-12-29 15:42: Argument seed: 10000
2022-12-29 15:42: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-29 15:42: Argument teacher_forcing: False
2022-12-29 15:42: Argument weight_decay: 0.0
2022-12-29 15:42: Argument window_len: 10
2022-12-29 15:42: Train Epoch 1: 3/244 Loss: 1.375843
2022-12-29 15:42: Train Epoch 1: 7/244 Loss: 0.648312
2022-12-29 15:42: Train Epoch 1: 11/244 Loss: 0.508353
2022-12-29 15:42: Train Epoch 1: 15/244 Loss: 0.420918
2022-12-29 15:42: Train Epoch 1: 19/244 Loss: 0.419413
2022-12-29 15:42: Train Epoch 1: 23/244 Loss: 0.460123
2022-12-29 15:42: Train Epoch 1: 27/244 Loss: 0.495519
2022-12-29 15:43: Train Epoch 1: 31/244 Loss: 0.418935
2022-12-29 15:43: Train Epoch 1: 35/244 Loss: 0.372442
2022-12-29 15:43: Train Epoch 1: 39/244 Loss: 0.406167
2022-12-29 15:43: Train Epoch 1: 43/244 Loss: 0.378689
2022-12-29 15:43: Train Epoch 1: 47/244 Loss: 0.333670
2022-12-29 15:43: Train Epoch 1: 51/244 Loss: 0.403964
2022-12-29 15:43: Train Epoch 1: 55/244 Loss: 0.385531
2022-12-29 15:43: Train Epoch 1: 59/244 Loss: 0.402268
2022-12-29 15:43: Train Epoch 1: 63/244 Loss: 0.372099
2022-12-29 15:43: Train Epoch 1: 67/244 Loss: 0.365524
2022-12-29 15:44: Train Epoch 1: 71/244 Loss: 0.376743
2022-12-29 15:44: Train Epoch 1: 75/244 Loss: 0.357327
2022-12-29 15:44: Train Epoch 1: 79/244 Loss: 0.346789
2022-12-29 15:44: Train Epoch 1: 83/244 Loss: 0.344650
2022-12-29 15:44: Train Epoch 1: 87/244 Loss: 0.391701
2022-12-29 15:44: Train Epoch 1: 91/244 Loss: 0.329778
2022-12-29 15:44: Train Epoch 1: 95/244 Loss: 0.360893
2022-12-29 15:44: Train Epoch 1: 99/244 Loss: 0.329866
2022-12-29 15:44: Train Epoch 1: 103/244 Loss: 0.334711
2022-12-29 15:44: Train Epoch 1: 107/244 Loss: 0.340479
2022-12-29 15:45: Train Epoch 1: 111/244 Loss: 0.337749
2022-12-29 15:45: Train Epoch 1: 115/244 Loss: 0.359266
2022-12-29 15:45: Train Epoch 1: 119/244 Loss: 0.342937
2022-12-29 15:45: Train Epoch 1: 123/244 Loss: 0.319669
2022-12-29 15:45: Train Epoch 1: 127/244 Loss: 0.322104
2022-12-29 15:45: Train Epoch 1: 131/244 Loss: 0.323775
2022-12-29 15:45: Train Epoch 1: 135/244 Loss: 0.326844
2022-12-29 15:45: Train Epoch 1: 139/244 Loss: 0.306727
2022-12-29 15:45: Train Epoch 1: 143/244 Loss: 0.312459
2022-12-29 15:45: Train Epoch 1: 147/244 Loss: 0.311069
2022-12-29 15:46: Train Epoch 1: 151/244 Loss: 0.314560
2022-12-29 15:46: Train Epoch 1: 155/244 Loss: 0.311169
2022-12-29 15:46: Train Epoch 1: 159/244 Loss: 0.315759
2022-12-29 15:46: Train Epoch 1: 163/244 Loss: 0.297292
2022-12-29 15:46: Train Epoch 1: 167/244 Loss: 0.293232
2022-12-29 15:46: Train Epoch 1: 171/244 Loss: 0.312029
2022-12-29 15:46: Train Epoch 1: 175/244 Loss: 0.295746
2022-12-29 15:46: Train Epoch 1: 179/244 Loss: 0.286948
2022-12-29 15:46: Train Epoch 1: 183/244 Loss: 0.289339
2022-12-29 15:46: Train Epoch 1: 187/244 Loss: 0.262074
2022-12-29 15:46: Train Epoch 1: 191/244 Loss: 0.298087
2022-12-29 15:47: Train Epoch 1: 195/244 Loss: 0.294090
2022-12-29 15:47: Train Epoch 1: 199/244 Loss: 0.295929
2022-12-29 15:47: Train Epoch 1: 203/244 Loss: 0.263709
2022-12-29 15:47: Train Epoch 1: 207/244 Loss: 0.265390
2022-12-29 15:47: Train Epoch 1: 211/244 Loss: 0.248648
2022-12-29 15:47: Train Epoch 1: 215/244 Loss: 0.309364
2022-12-29 15:47: Train Epoch 1: 219/244 Loss: 0.253697
2022-12-29 15:47: Train Epoch 1: 223/244 Loss: 0.255346
2022-12-29 15:47: Train Epoch 1: 227/244 Loss: 0.248316
2022-12-29 15:47: Train Epoch 1: 231/244 Loss: 0.237132
2022-12-29 15:47: Train Epoch 1: 235/244 Loss: 0.258868
2022-12-29 15:47: Train Epoch 1: 239/244 Loss: 0.264937
2022-12-29 15:48: Train Epoch 1: 243/244 Loss: 0.236509
2022-12-29 15:48: **********Train Epoch 1: averaged Loss: 0.354942 
2022-12-29 15:48: 
Epoch time elapsed: 348.5301592350006

2022-12-29 15:48: 
 metrics validation: {'precision': 0.6558441558441559, 'recall': 0.6215384615384615, 'f1-score': 0.6382306477093208, 'support': 1300, 'AUC': 0.7606038461538462, 'AUCPR': 0.627679843454987, 'TP': 808, 'FP': 424, 'TN': 2176, 'FN': 492} 

2022-12-29 15:48: **********Val Epoch 1: average Loss: 0.254333
2022-12-29 15:48: *********************************Current best model saved!
2022-12-29 15:48: 
 Testing metrics {'precision': 0.7136894824707847, 'recall': 0.6962540716612378, 'f1-score': 0.7048639736191261, 'support': 1228, 'AUC': 0.8495126606117837, 'AUCPR': 0.7465300160135264, 'TP': 855, 'FP': 343, 'TN': 2113, 'FN': 373} 

2022-12-29 15:49: Train Epoch 2: 3/244 Loss: 0.297947
2022-12-29 15:49: Train Epoch 2: 7/244 Loss: 0.263077
2022-12-29 15:49: Train Epoch 2: 11/244 Loss: 0.254056
2022-12-29 15:49: Train Epoch 2: 15/244 Loss: 0.253457
2022-12-29 15:49: Train Epoch 2: 19/244 Loss: 0.255225
2022-12-29 15:49: Train Epoch 2: 23/244 Loss: 0.259450
2022-12-29 15:49: Train Epoch 2: 27/244 Loss: 0.236540
2022-12-29 15:49: Train Epoch 2: 31/244 Loss: 0.239172
2022-12-29 15:49: Train Epoch 2: 35/244 Loss: 0.215788
2022-12-29 15:49: Train Epoch 2: 39/244 Loss: 0.219141
2022-12-29 15:50: Train Epoch 2: 43/244 Loss: 0.235170
2022-12-29 15:50: Train Epoch 2: 47/244 Loss: 0.254410
2022-12-29 15:50: Train Epoch 2: 51/244 Loss: 0.205451
2022-12-29 15:50: Train Epoch 2: 55/244 Loss: 0.218939
2022-12-29 15:50: Train Epoch 2: 59/244 Loss: 0.226677
2022-12-29 15:50: Train Epoch 2: 63/244 Loss: 0.256947
2022-12-29 15:50: Train Epoch 2: 67/244 Loss: 0.243579
2022-12-29 15:50: Train Epoch 2: 71/244 Loss: 0.221296
2022-12-29 15:50: Train Epoch 2: 75/244 Loss: 0.255661
2022-12-29 15:50: Train Epoch 2: 79/244 Loss: 0.254666
2022-12-29 15:50: Train Epoch 2: 83/244 Loss: 0.188629
2022-12-29 15:51: Train Epoch 2: 87/244 Loss: 0.194146
2022-12-29 15:51: Train Epoch 2: 91/244 Loss: 0.219023
2022-12-29 15:51: Train Epoch 2: 95/244 Loss: 0.239990
2022-12-29 15:51: Train Epoch 2: 99/244 Loss: 0.238228
2022-12-29 15:51: Train Epoch 2: 103/244 Loss: 0.209699
2022-12-29 15:51: Train Epoch 2: 107/244 Loss: 0.240964
2022-12-29 15:51: Train Epoch 2: 111/244 Loss: 0.258618
2022-12-29 15:51: Train Epoch 2: 115/244 Loss: 0.222468
2022-12-29 15:51: Train Epoch 2: 119/244 Loss: 0.211875
2022-12-29 15:52: Train Epoch 2: 123/244 Loss: 0.240831
2022-12-29 15:52: Train Epoch 2: 127/244 Loss: 0.187851
2022-12-29 15:52: Train Epoch 2: 131/244 Loss: 0.259647
2022-12-29 15:52: Train Epoch 2: 135/244 Loss: 0.248618
2022-12-29 15:52: Train Epoch 2: 139/244 Loss: 0.179934
2022-12-29 15:52: Train Epoch 2: 143/244 Loss: 0.188024
2022-12-29 15:52: Train Epoch 2: 147/244 Loss: 0.198238
2022-12-29 15:52: Train Epoch 2: 151/244 Loss: 0.191384
2022-12-29 15:52: Train Epoch 2: 155/244 Loss: 0.214976
2022-12-29 15:52: Train Epoch 2: 159/244 Loss: 0.187805
2022-12-29 15:52: Train Epoch 2: 163/244 Loss: 0.209162
2022-12-29 15:53: Train Epoch 2: 167/244 Loss: 0.240223
2022-12-29 15:53: Train Epoch 2: 171/244 Loss: 0.215682
2022-12-29 15:53: Train Epoch 2: 175/244 Loss: 0.182824
2022-12-29 15:53: Train Epoch 2: 179/244 Loss: 0.226196
2022-12-29 15:53: Train Epoch 2: 183/244 Loss: 0.185269
2022-12-29 15:53: Train Epoch 2: 187/244 Loss: 0.203842
2022-12-29 15:53: Train Epoch 2: 191/244 Loss: 0.198800
2022-12-29 15:53: Train Epoch 2: 195/244 Loss: 0.224150
2022-12-29 15:53: Train Epoch 2: 199/244 Loss: 0.196460
2022-12-29 15:53: Train Epoch 2: 203/244 Loss: 0.199526
2022-12-29 15:53: Train Epoch 2: 207/244 Loss: 0.199548
2022-12-29 15:54: Train Epoch 2: 211/244 Loss: 0.244193
2022-12-29 15:54: Train Epoch 2: 215/244 Loss: 0.262245
2022-12-29 15:54: Train Epoch 2: 219/244 Loss: 0.210565
2022-12-29 15:54: Train Epoch 2: 223/244 Loss: 0.219751
2022-12-29 15:54: Train Epoch 2: 227/244 Loss: 0.194959
2022-12-29 15:54: Train Epoch 2: 231/244 Loss: 0.210205
2022-12-29 15:54: Train Epoch 2: 235/244 Loss: 0.244435
2022-12-29 15:54: Train Epoch 2: 239/244 Loss: 0.218351
2022-12-29 15:54: Train Epoch 2: 243/244 Loss: 0.189315
2022-12-29 15:54: **********Train Epoch 2: averaged Loss: 0.223989 
2022-12-29 15:54: 
Epoch time elapsed: 350.0751631259918

2022-12-29 15:55: 
 metrics validation: {'precision': 0.746583850931677, 'recall': 0.4623076923076923, 'f1-score': 0.571021377672209, 'support': 1300, 'AUC': 0.8052958579881657, 'AUCPR': 0.6831462127410883, 'TP': 601, 'FP': 204, 'TN': 2396, 'FN': 699} 

2022-12-29 15:55: **********Val Epoch 2: average Loss: 0.256738
2022-12-29 15:55: 
 Testing metrics {'precision': 0.7136894824707847, 'recall': 0.6962540716612378, 'f1-score': 0.7048639736191261, 'support': 1228, 'AUC': 0.8495126606117837, 'AUCPR': 0.7465300160135264, 'TP': 855, 'FP': 343, 'TN': 2113, 'FN': 373} 

2022-12-29 15:55: Train Epoch 3: 3/244 Loss: 0.255936
2022-12-29 15:55: Train Epoch 3: 7/244 Loss: 0.264729
2022-12-29 15:55: Train Epoch 3: 11/244 Loss: 0.273836
2022-12-29 15:56: Train Epoch 3: 15/244 Loss: 0.250167
2022-12-29 15:56: Train Epoch 3: 19/244 Loss: 0.210870
2022-12-29 15:56: Train Epoch 3: 23/244 Loss: 0.208614
2022-12-29 15:56: Train Epoch 3: 27/244 Loss: 0.225688
2022-12-29 15:56: Train Epoch 3: 31/244 Loss: 0.254491
2022-12-29 15:56: Train Epoch 3: 35/244 Loss: 0.239446
2022-12-29 15:56: Train Epoch 3: 39/244 Loss: 0.242205
2022-12-29 15:56: Train Epoch 3: 43/244 Loss: 0.231846
2022-12-29 15:56: Train Epoch 3: 47/244 Loss: 0.240640
2022-12-29 15:56: Train Epoch 3: 51/244 Loss: 0.228409
2022-12-29 15:56: Train Epoch 3: 55/244 Loss: 0.213211
2022-12-29 15:57: Train Epoch 3: 59/244 Loss: 0.227361
2022-12-29 15:57: Train Epoch 3: 63/244 Loss: 0.235398
2022-12-29 15:57: Train Epoch 3: 67/244 Loss: 0.215015
2022-12-29 15:57: Train Epoch 3: 71/244 Loss: 0.215682
2022-12-29 15:57: Train Epoch 3: 75/244 Loss: 0.206105
2022-12-29 15:57: Train Epoch 3: 79/244 Loss: 0.251758
2022-12-29 15:57: Train Epoch 3: 83/244 Loss: 0.219943
2022-12-29 15:57: Train Epoch 3: 87/244 Loss: 0.242728
2022-12-29 15:57: Train Epoch 3: 91/244 Loss: 0.247554
2022-12-29 15:57: Train Epoch 3: 95/244 Loss: 0.256926
2022-12-29 15:57: Train Epoch 3: 99/244 Loss: 0.216750
2022-12-29 15:58: Train Epoch 3: 103/244 Loss: 0.231820
2022-12-29 15:58: Train Epoch 3: 107/244 Loss: 0.203228
2022-12-29 15:58: Train Epoch 3: 111/244 Loss: 0.236992
2022-12-29 15:58: Train Epoch 3: 115/244 Loss: 0.249266
2022-12-29 15:58: Train Epoch 3: 119/244 Loss: 0.209720
2022-12-29 15:58: Train Epoch 3: 123/244 Loss: 0.224553
2022-12-29 15:58: Train Epoch 3: 127/244 Loss: 0.212019
2022-12-29 15:58: Train Epoch 3: 131/244 Loss: 0.207872
2022-12-29 15:58: Train Epoch 3: 135/244 Loss: 0.236064
2022-12-29 15:58: Train Epoch 3: 139/244 Loss: 0.227509
2022-12-29 15:59: Train Epoch 3: 143/244 Loss: 0.205215
2022-12-29 15:59: Train Epoch 3: 147/244 Loss: 0.222231
2022-12-29 15:59: Train Epoch 3: 151/244 Loss: 0.193708
2022-12-29 15:59: Train Epoch 3: 155/244 Loss: 0.245043
2022-12-29 15:59: Train Epoch 3: 159/244 Loss: 0.221196
2022-12-29 15:59: Train Epoch 3: 163/244 Loss: 0.192739
2022-12-29 15:59: Train Epoch 3: 167/244 Loss: 0.228006
2022-12-29 15:59: Train Epoch 3: 171/244 Loss: 0.227132
2022-12-29 15:59: Train Epoch 3: 175/244 Loss: 0.261475
2022-12-29 15:59: Train Epoch 3: 179/244 Loss: 0.181142
2022-12-29 15:59: Train Epoch 3: 183/244 Loss: 0.208120
2022-12-29 16:00: Train Epoch 3: 187/244 Loss: 0.210558
2022-12-29 16:00: Train Epoch 3: 191/244 Loss: 0.194482
2022-12-29 16:00: Train Epoch 3: 195/244 Loss: 0.204791
2022-12-29 16:00: Train Epoch 3: 199/244 Loss: 0.193600
2022-12-29 16:00: Train Epoch 3: 203/244 Loss: 0.185179
2022-12-29 16:00: Train Epoch 3: 207/244 Loss: 0.224487
2022-12-29 16:00: Train Epoch 3: 211/244 Loss: 0.151108
2022-12-29 16:00: Train Epoch 3: 215/244 Loss: 0.218788
2022-12-29 16:00: Train Epoch 3: 219/244 Loss: 0.220398
2022-12-29 16:00: Train Epoch 3: 223/244 Loss: 0.196166
2022-12-29 16:01: Train Epoch 3: 227/244 Loss: 0.180116
2022-12-29 16:01: Train Epoch 3: 231/244 Loss: 0.207341
2022-12-29 16:01: Train Epoch 3: 235/244 Loss: 0.221520
2022-12-29 16:01: Train Epoch 3: 239/244 Loss: 0.207602
2022-12-29 16:01: Train Epoch 3: 243/244 Loss: 0.201187
2022-12-29 16:01: **********Train Epoch 3: averaged Loss: 0.221601 
2022-12-29 16:01: 
Epoch time elapsed: 344.93064403533936

2022-12-29 16:01: 
 metrics validation: {'precision': 0.7306889352818372, 'recall': 0.5384615384615384, 'f1-score': 0.6200177147918512, 'support': 1300, 'AUC': 0.8025782544378698, 'AUCPR': 0.673830896828858, 'TP': 700, 'FP': 258, 'TN': 2342, 'FN': 600} 

2022-12-29 16:01: **********Val Epoch 3: average Loss: 0.256365
2022-12-29 16:02: 
 Testing metrics {'precision': 0.7136894824707847, 'recall': 0.6962540716612378, 'f1-score': 0.7048639736191261, 'support': 1228, 'AUC': 0.8495126606117837, 'AUCPR': 0.7465300160135264, 'TP': 855, 'FP': 343, 'TN': 2113, 'FN': 373} 

2022-12-29 16:02: Train Epoch 4: 3/244 Loss: 0.247810
2022-12-29 16:02: Train Epoch 4: 7/244 Loss: 0.256878
2022-12-29 16:02: Train Epoch 4: 11/244 Loss: 0.237216
2022-12-29 16:02: Train Epoch 4: 15/244 Loss: 0.228967
2022-12-29 16:02: Train Epoch 4: 19/244 Loss: 0.241679
2022-12-29 16:02: Train Epoch 4: 23/244 Loss: 0.263175
2022-12-29 16:02: Train Epoch 4: 27/244 Loss: 0.220335
2022-12-29 16:03: Train Epoch 4: 31/244 Loss: 0.284359
2022-12-29 16:03: Train Epoch 4: 35/244 Loss: 0.258079
2022-12-29 16:03: Train Epoch 4: 39/244 Loss: 0.245180
2022-12-29 16:03: Train Epoch 4: 43/244 Loss: 0.214233
2022-12-29 16:03: Train Epoch 4: 47/244 Loss: 0.257464
2022-12-29 16:03: Train Epoch 4: 51/244 Loss: 0.240724
2022-12-29 16:03: Train Epoch 4: 55/244 Loss: 0.247881
2022-12-29 16:03: Train Epoch 4: 59/244 Loss: 0.237687
2022-12-29 16:03: Train Epoch 4: 63/244 Loss: 0.221201
2022-12-29 16:03: Train Epoch 4: 67/244 Loss: 0.202029
2022-12-29 16:04: Train Epoch 4: 71/244 Loss: 0.208108
2022-12-29 16:04: Train Epoch 4: 75/244 Loss: 0.213385
2022-12-29 16:04: Train Epoch 4: 79/244 Loss: 0.221090
2022-12-29 16:04: Train Epoch 4: 83/244 Loss: 0.253482
2022-12-29 16:04: Train Epoch 4: 87/244 Loss: 0.226000
2022-12-29 16:04: Train Epoch 4: 91/244 Loss: 0.197781
2022-12-29 16:04: Train Epoch 4: 95/244 Loss: 0.225428
2022-12-29 16:04: Train Epoch 4: 99/244 Loss: 0.204363
2022-12-29 16:04: Train Epoch 4: 103/244 Loss: 0.198495
2022-12-29 16:04: Train Epoch 4: 107/244 Loss: 0.217240
2022-12-29 16:04: Train Epoch 4: 111/244 Loss: 0.211219
2022-12-29 16:05: Train Epoch 4: 115/244 Loss: 0.213209
2022-12-29 16:05: Train Epoch 4: 119/244 Loss: 0.221153
2022-12-29 16:05: Train Epoch 4: 123/244 Loss: 0.205142
2022-12-29 16:05: Train Epoch 4: 127/244 Loss: 0.212860
2022-12-29 16:05: Train Epoch 4: 131/244 Loss: 0.226306
2022-12-29 16:05: Train Epoch 4: 135/244 Loss: 0.204083
2022-12-29 16:05: Train Epoch 4: 139/244 Loss: 0.232668
2022-12-29 16:05: Train Epoch 4: 143/244 Loss: 0.236163
2022-12-29 16:05: Train Epoch 4: 147/244 Loss: 0.217635
2022-12-29 16:05: Train Epoch 4: 151/244 Loss: 0.193318
2022-12-29 16:05: Train Epoch 4: 155/244 Loss: 0.219764
2022-12-29 16:06: Train Epoch 4: 159/244 Loss: 0.217186
2022-12-29 16:06: Train Epoch 4: 163/244 Loss: 0.182912
2022-12-29 16:06: Train Epoch 4: 167/244 Loss: 0.234592
2022-12-29 16:06: Train Epoch 4: 171/244 Loss: 0.201134
2022-12-29 16:06: Train Epoch 4: 175/244 Loss: 0.222075
2022-12-29 16:06: Train Epoch 4: 179/244 Loss: 0.218998
2022-12-29 16:06: Train Epoch 4: 183/244 Loss: 0.186531
2022-12-29 16:06: Train Epoch 4: 187/244 Loss: 0.269049
2022-12-29 16:06: Train Epoch 4: 191/244 Loss: 0.209931
2022-12-29 16:06: Train Epoch 4: 195/244 Loss: 0.207632
2022-12-29 16:07: Train Epoch 4: 199/244 Loss: 0.287421
2022-12-29 16:07: Train Epoch 4: 203/244 Loss: 0.207764
2022-12-29 16:07: Train Epoch 4: 207/244 Loss: 0.211525
2022-12-29 16:07: Train Epoch 4: 211/244 Loss: 0.231851
2022-12-29 16:07: Train Epoch 4: 215/244 Loss: 0.240097
2022-12-29 16:07: Train Epoch 4: 219/244 Loss: 0.273895
2022-12-29 16:07: Train Epoch 4: 223/244 Loss: 0.215700
2022-12-29 16:07: Train Epoch 4: 227/244 Loss: 0.231458
2022-12-29 16:07: Train Epoch 4: 231/244 Loss: 0.190129
2022-12-29 16:07: Train Epoch 4: 235/244 Loss: 0.178352
2022-12-29 16:07: Train Epoch 4: 239/244 Loss: 0.256843
2022-12-29 16:07: Train Epoch 4: 243/244 Loss: 0.219711
2022-12-29 16:07: **********Train Epoch 4: averaged Loss: 0.225550 
2022-12-29 16:07: 
Epoch time elapsed: 342.0157380104065

2022-12-29 16:08: 
 metrics validation: {'precision': 0.7033450704225352, 'recall': 0.6146153846153846, 'f1-score': 0.6559934318555009, 'support': 1300, 'AUC': 0.8050399408284025, 'AUCPR': 0.6759575129953593, 'TP': 799, 'FP': 337, 'TN': 2263, 'FN': 501} 

2022-12-29 16:08: **********Val Epoch 4: average Loss: 0.246174
2022-12-29 16:08: *********************************Current best model saved!
2022-12-29 16:08: 
 Testing metrics {'precision': 0.7702464788732394, 'recall': 0.7125407166123778, 'f1-score': 0.7402707275803722, 'support': 1228, 'AUC': 0.8570087613661683, 'AUCPR': 0.7623862044949633, 'TP': 875, 'FP': 261, 'TN': 2195, 'FN': 353} 

2022-12-29 16:08: Train Epoch 5: 3/244 Loss: 0.203293
2022-12-29 16:09: Train Epoch 5: 7/244 Loss: 0.221664
2022-12-29 16:09: Train Epoch 5: 11/244 Loss: 0.206948
2022-12-29 16:09: Train Epoch 5: 15/244 Loss: 0.221118
2022-12-29 16:09: Train Epoch 5: 19/244 Loss: 0.228595
2022-12-29 16:09: Train Epoch 5: 23/244 Loss: 0.210139
2022-12-29 16:09: Train Epoch 5: 27/244 Loss: 0.202879
2022-12-29 16:09: Train Epoch 5: 31/244 Loss: 0.227374
2022-12-29 16:09: Train Epoch 5: 35/244 Loss: 0.178625
2022-12-29 16:09: Train Epoch 5: 39/244 Loss: 0.203894
2022-12-29 16:09: Train Epoch 5: 43/244 Loss: 0.235850
2022-12-29 16:10: Train Epoch 5: 47/244 Loss: 0.244241
2022-12-29 16:10: Train Epoch 5: 51/244 Loss: 0.228079
2022-12-29 16:10: Train Epoch 5: 55/244 Loss: 0.194415
2022-12-29 16:10: Train Epoch 5: 59/244 Loss: 0.218800
2022-12-29 16:10: Train Epoch 5: 63/244 Loss: 0.221413
2022-12-29 16:10: Train Epoch 5: 67/244 Loss: 0.200464
2022-12-29 16:10: Train Epoch 5: 71/244 Loss: 0.235308
2022-12-29 16:10: Train Epoch 5: 75/244 Loss: 0.192233
2022-12-29 16:10: Train Epoch 5: 79/244 Loss: 0.153904
2022-12-29 16:11: Train Epoch 5: 83/244 Loss: 0.169598
2022-12-29 16:11: Train Epoch 5: 87/244 Loss: 0.199869
2022-12-29 16:11: Train Epoch 5: 91/244 Loss: 0.193370
2022-12-29 16:11: Train Epoch 5: 95/244 Loss: 0.175562
2022-12-29 16:11: Train Epoch 5: 99/244 Loss: 0.210983
2022-12-29 16:11: Train Epoch 5: 103/244 Loss: 0.225885
2022-12-29 16:11: Train Epoch 5: 107/244 Loss: 0.208373
2022-12-29 16:11: Train Epoch 5: 111/244 Loss: 0.159403
2022-12-29 16:11: Train Epoch 5: 115/244 Loss: 0.225582
2022-12-29 16:11: Train Epoch 5: 119/244 Loss: 0.234446
2022-12-29 16:12: Train Epoch 5: 123/244 Loss: 0.248591
2022-12-29 16:12: Train Epoch 5: 127/244 Loss: 0.170841
2022-12-29 16:12: Train Epoch 5: 131/244 Loss: 0.217699
2022-12-29 16:12: Train Epoch 5: 135/244 Loss: 0.212629
2022-12-29 16:12: Train Epoch 5: 139/244 Loss: 0.209818
2022-12-29 16:12: Train Epoch 5: 143/244 Loss: 0.186209
2022-12-29 16:12: Train Epoch 5: 147/244 Loss: 0.189362
2022-12-29 16:12: Train Epoch 5: 151/244 Loss: 0.245794
2022-12-29 16:12: Train Epoch 5: 155/244 Loss: 0.198316
2022-12-29 16:12: Train Epoch 5: 159/244 Loss: 0.189727
2022-12-29 16:12: Train Epoch 5: 163/244 Loss: 0.166727
2022-12-29 16:13: Train Epoch 5: 167/244 Loss: 0.211480
2022-12-29 16:13: Train Epoch 5: 171/244 Loss: 0.189453
2022-12-29 16:13: Train Epoch 5: 175/244 Loss: 0.233845
2022-12-29 16:13: Train Epoch 5: 179/244 Loss: 0.210260
2022-12-29 16:13: Train Epoch 5: 183/244 Loss: 0.233847
2022-12-29 16:13: Train Epoch 5: 187/244 Loss: 0.182418
2022-12-29 16:13: Train Epoch 5: 191/244 Loss: 0.192530
2022-12-29 16:13: Train Epoch 5: 195/244 Loss: 0.184171
2022-12-29 16:13: Train Epoch 5: 199/244 Loss: 0.202785
2022-12-29 16:13: Train Epoch 5: 203/244 Loss: 0.201761
2022-12-29 16:14: Train Epoch 5: 207/244 Loss: 0.208738
2022-12-29 16:14: Train Epoch 5: 211/244 Loss: 0.191042
2022-12-29 16:14: Train Epoch 5: 215/244 Loss: 0.201217
2022-12-29 16:14: Train Epoch 5: 219/244 Loss: 0.193092
2022-12-29 16:14: Train Epoch 5: 223/244 Loss: 0.180448
2022-12-29 16:14: Train Epoch 5: 227/244 Loss: 0.184674
2022-12-29 16:14: Train Epoch 5: 231/244 Loss: 0.170489
2022-12-29 16:14: Train Epoch 5: 235/244 Loss: 0.235812
2022-12-29 16:14: Train Epoch 5: 239/244 Loss: 0.185317
2022-12-29 16:14: Train Epoch 5: 243/244 Loss: 0.146943
2022-12-29 16:14: **********Train Epoch 5: averaged Loss: 0.203415 
2022-12-29 16:14: 
Epoch time elapsed: 354.0325565338135

2022-12-29 16:15: 
 metrics validation: {'precision': 0.6864910790144435, 'recall': 0.6215384615384615, 'f1-score': 0.6524020993136859, 'support': 1300, 'AUC': 0.8065718934911242, 'AUCPR': 0.6724649365819315, 'TP': 808, 'FP': 369, 'TN': 2231, 'FN': 492} 

2022-12-29 16:15: **********Val Epoch 5: average Loss: 0.266121
2022-12-29 16:15: 
 Testing metrics {'precision': 0.7702464788732394, 'recall': 0.7125407166123778, 'f1-score': 0.7402707275803722, 'support': 1228, 'AUC': 0.8570087613661683, 'AUCPR': 0.7623862044949633, 'TP': 875, 'FP': 261, 'TN': 2195, 'FN': 353} 

2022-12-29 16:15: Train Epoch 6: 3/244 Loss: 0.211499
2022-12-29 16:15: Train Epoch 6: 7/244 Loss: 0.188517
2022-12-29 16:15: Train Epoch 6: 11/244 Loss: 0.224084
2022-12-29 16:16: Train Epoch 6: 15/244 Loss: 0.227310
2022-12-29 16:16: Train Epoch 6: 19/244 Loss: 0.191253
2022-12-29 16:16: Train Epoch 6: 23/244 Loss: 0.200989
2022-12-29 16:16: Train Epoch 6: 27/244 Loss: 0.186430
2022-12-29 16:16: Train Epoch 6: 31/244 Loss: 0.213988
2022-12-29 16:16: Train Epoch 6: 35/244 Loss: 0.230378
2022-12-29 16:16: Train Epoch 6: 39/244 Loss: 0.249661
2022-12-29 16:16: Train Epoch 6: 43/244 Loss: 0.198853
2022-12-29 16:16: Train Epoch 6: 47/244 Loss: 0.225140
2022-12-29 16:16: Train Epoch 6: 51/244 Loss: 0.207397
2022-12-29 16:16: Train Epoch 6: 55/244 Loss: 0.196165
2022-12-29 16:17: Train Epoch 6: 59/244 Loss: 0.193193
2022-12-29 16:17: Train Epoch 6: 63/244 Loss: 0.208513
2022-12-29 16:17: Train Epoch 6: 67/244 Loss: 0.204358
2022-12-29 16:17: Train Epoch 6: 71/244 Loss: 0.208962
2022-12-29 16:17: Train Epoch 6: 75/244 Loss: 0.196932
2022-12-29 16:17: Train Epoch 6: 79/244 Loss: 0.222480
2022-12-29 16:17: Train Epoch 6: 83/244 Loss: 0.196626
2022-12-29 16:17: Train Epoch 6: 87/244 Loss: 0.198646
2022-12-29 16:17: Train Epoch 6: 91/244 Loss: 0.202183
2022-12-29 16:17: Train Epoch 6: 95/244 Loss: 0.233714
2022-12-29 16:17: Train Epoch 6: 99/244 Loss: 0.206089
2022-12-29 16:18: Train Epoch 6: 103/244 Loss: 0.203663
2022-12-29 16:18: Train Epoch 6: 107/244 Loss: 0.221034
2022-12-29 16:18: Train Epoch 6: 111/244 Loss: 0.238281
2022-12-29 16:18: Train Epoch 6: 115/244 Loss: 0.256218
2022-12-29 16:18: Train Epoch 6: 119/244 Loss: 0.208997
2022-12-29 16:18: Train Epoch 6: 123/244 Loss: 0.254748
2022-12-29 16:18: Train Epoch 6: 127/244 Loss: 0.224159
2022-12-29 16:18: Train Epoch 6: 131/244 Loss: 0.174032
2022-12-29 16:18: Train Epoch 6: 135/244 Loss: 0.230716
2022-12-29 16:18: Train Epoch 6: 139/244 Loss: 0.183685
2022-12-29 16:19: Train Epoch 6: 143/244 Loss: 0.204742
2022-12-29 16:19: Train Epoch 6: 147/244 Loss: 0.195829
2022-12-29 16:19: Train Epoch 6: 151/244 Loss: 0.180655
2022-12-29 16:19: Train Epoch 6: 155/244 Loss: 0.194032
2022-12-29 16:19: Train Epoch 6: 159/244 Loss: 0.220800
2022-12-29 16:19: Train Epoch 6: 163/244 Loss: 0.187100
2022-12-29 16:19: Train Epoch 6: 167/244 Loss: 0.199686
2022-12-29 16:19: Train Epoch 6: 171/244 Loss: 0.177902
2022-12-29 16:19: Train Epoch 6: 175/244 Loss: 0.183183
2022-12-29 16:19: Train Epoch 6: 179/244 Loss: 0.193462
2022-12-29 16:20: Train Epoch 6: 183/244 Loss: 0.226169
2022-12-29 16:20: Train Epoch 6: 187/244 Loss: 0.199941
2022-12-29 16:20: Train Epoch 6: 191/244 Loss: 0.212487
2022-12-29 16:20: Train Epoch 6: 195/244 Loss: 0.170517
2022-12-29 16:20: Train Epoch 6: 199/244 Loss: 0.218938
2022-12-29 16:20: Train Epoch 6: 203/244 Loss: 0.205950
2022-12-29 16:20: Train Epoch 6: 207/244 Loss: 0.228566
2022-12-29 16:20: Train Epoch 6: 211/244 Loss: 0.223301
2022-12-29 16:20: Train Epoch 6: 215/244 Loss: 0.194455
2022-12-29 16:21: Train Epoch 6: 219/244 Loss: 0.176246
2022-12-29 16:21: Train Epoch 6: 223/244 Loss: 0.208021
2022-12-29 16:21: Train Epoch 6: 227/244 Loss: 0.207578
2022-12-29 16:21: Train Epoch 6: 231/244 Loss: 0.187170
2022-12-29 16:21: Train Epoch 6: 235/244 Loss: 0.217615
2022-12-29 16:21: Train Epoch 6: 239/244 Loss: 0.176350
2022-12-29 16:21: Train Epoch 6: 243/244 Loss: 0.184752
2022-12-29 16:21: **********Train Epoch 6: averaged Loss: 0.206465 
2022-12-29 16:21: 
Epoch time elapsed: 356.35809659957886

2022-12-29 16:22: 
 metrics validation: {'precision': 0.6859296482412061, 'recall': 0.63, 'f1-score': 0.656776263031275, 'support': 1300, 'AUC': 0.7998693786982247, 'AUCPR': 0.658087330414161, 'TP': 819, 'FP': 375, 'TN': 2225, 'FN': 481} 

2022-12-29 16:22: **********Val Epoch 6: average Loss: 0.282280
2022-12-29 16:22: 
 Testing metrics {'precision': 0.7702464788732394, 'recall': 0.7125407166123778, 'f1-score': 0.7402707275803722, 'support': 1228, 'AUC': 0.8570087613661683, 'AUCPR': 0.7623862044949633, 'TP': 875, 'FP': 261, 'TN': 2195, 'FN': 353} 

2022-12-29 16:22: Train Epoch 7: 3/244 Loss: 0.170285
2022-12-29 16:22: Train Epoch 7: 7/244 Loss: 0.237973
2022-12-29 16:22: Train Epoch 7: 11/244 Loss: 0.162249
2022-12-29 16:22: Train Epoch 7: 15/244 Loss: 0.224884
2022-12-29 16:22: Train Epoch 7: 19/244 Loss: 0.188625
2022-12-29 16:23: Train Epoch 7: 23/244 Loss: 0.189559
2022-12-29 16:23: Train Epoch 7: 27/244 Loss: 0.209960
2022-12-29 16:23: Train Epoch 7: 31/244 Loss: 0.190881
2022-12-29 16:23: Train Epoch 7: 35/244 Loss: 0.214139
2022-12-29 16:23: Train Epoch 7: 39/244 Loss: 0.202578
2022-12-29 16:23: Train Epoch 7: 43/244 Loss: 0.194483
2022-12-29 16:23: Train Epoch 7: 47/244 Loss: 0.224235
2022-12-29 16:23: Train Epoch 7: 51/244 Loss: 0.175270
2022-12-29 16:23: Train Epoch 7: 55/244 Loss: 0.196289
2022-12-29 16:23: Train Epoch 7: 59/244 Loss: 0.195943
2022-12-29 16:23: Train Epoch 7: 63/244 Loss: 0.210274
2022-12-29 16:24: Train Epoch 7: 67/244 Loss: 0.202399
2022-12-29 16:24: Train Epoch 7: 71/244 Loss: 0.196553
2022-12-29 16:24: Train Epoch 7: 75/244 Loss: 0.198871
2022-12-29 16:24: Train Epoch 7: 79/244 Loss: 0.207471
2022-12-29 16:24: Train Epoch 7: 83/244 Loss: 0.262938
2022-12-29 16:24: Train Epoch 7: 87/244 Loss: 0.208966
2022-12-29 16:24: Train Epoch 7: 91/244 Loss: 0.210327
2022-12-29 16:24: Train Epoch 7: 95/244 Loss: 0.230438
2022-12-29 16:24: Train Epoch 7: 99/244 Loss: 0.213228
2022-12-29 16:24: Train Epoch 7: 103/244 Loss: 0.201255
2022-12-29 16:25: Train Epoch 7: 107/244 Loss: 0.237062
2022-12-29 16:25: Train Epoch 7: 111/244 Loss: 0.198772
2022-12-29 16:25: Train Epoch 7: 115/244 Loss: 0.165552
2022-12-29 16:25: Train Epoch 7: 119/244 Loss: 0.216837
2022-12-29 16:25: Train Epoch 7: 123/244 Loss: 0.198377
2022-12-29 16:25: Train Epoch 7: 127/244 Loss: 0.202217
2022-12-29 16:25: Train Epoch 7: 131/244 Loss: 0.220375
2022-12-29 16:25: Train Epoch 7: 135/244 Loss: 0.182889
2022-12-29 16:25: Train Epoch 7: 139/244 Loss: 0.212339
2022-12-29 16:25: Train Epoch 7: 143/244 Loss: 0.238564
2022-12-29 16:25: Train Epoch 7: 147/244 Loss: 0.263045
2022-12-29 16:26: Train Epoch 7: 151/244 Loss: 0.194658
2022-12-29 16:26: Train Epoch 7: 155/244 Loss: 0.219194
2022-12-29 16:26: Train Epoch 7: 159/244 Loss: 0.217996
2022-12-29 16:26: Train Epoch 7: 163/244 Loss: 0.222635
2022-12-29 16:26: Train Epoch 7: 167/244 Loss: 0.183588
2022-12-29 16:26: Train Epoch 7: 171/244 Loss: 0.219562
2022-12-29 16:26: Train Epoch 7: 175/244 Loss: 0.163645
2022-12-29 16:26: Train Epoch 7: 179/244 Loss: 0.213841
2022-12-29 16:26: Train Epoch 7: 183/244 Loss: 0.234193
2022-12-29 16:26: Train Epoch 7: 187/244 Loss: 0.199013
2022-12-29 16:27: Train Epoch 7: 191/244 Loss: 0.205130
2022-12-29 16:27: Train Epoch 7: 195/244 Loss: 0.205820
2022-12-29 16:27: Train Epoch 7: 199/244 Loss: 0.250154
2022-12-29 16:27: Train Epoch 7: 203/244 Loss: 0.239704
2022-12-29 16:27: Train Epoch 7: 207/244 Loss: 0.182287
2022-12-29 16:27: Train Epoch 7: 211/244 Loss: 0.186614
2022-12-29 16:27: Train Epoch 7: 215/244 Loss: 0.198719
2022-12-29 16:27: Train Epoch 7: 219/244 Loss: 0.226213
2022-12-29 16:27: Train Epoch 7: 223/244 Loss: 0.183365
2022-12-29 16:27: Train Epoch 7: 227/244 Loss: 0.241953
2022-12-29 16:27: Train Epoch 7: 231/244 Loss: 0.162366
2022-12-29 16:27: Train Epoch 7: 235/244 Loss: 0.187169
2022-12-29 16:28: Train Epoch 7: 239/244 Loss: 0.226879
2022-12-29 16:28: Train Epoch 7: 243/244 Loss: 0.204464
2022-12-29 16:28: **********Train Epoch 7: averaged Loss: 0.206972 
2022-12-29 16:28: 
Epoch time elapsed: 342.59470558166504

2022-12-29 16:28: 
 metrics validation: {'precision': 0.684870188003581, 'recall': 0.5884615384615385, 'f1-score': 0.63301613570542, 'support': 1300, 'AUC': 0.7950139053254439, 'AUCPR': 0.6504293140511878, 'TP': 765, 'FP': 352, 'TN': 2248, 'FN': 535} 

2022-12-29 16:28: **********Val Epoch 7: average Loss: 0.282430
2022-12-29 16:29: 
 Testing metrics {'precision': 0.7702464788732394, 'recall': 0.7125407166123778, 'f1-score': 0.7402707275803722, 'support': 1228, 'AUC': 0.8570087613661683, 'AUCPR': 0.7623862044949633, 'TP': 875, 'FP': 261, 'TN': 2195, 'FN': 353} 

2022-12-29 16:29: Train Epoch 8: 3/244 Loss: 0.180247
2022-12-29 16:29: Train Epoch 8: 7/244 Loss: 0.191594
2022-12-29 16:29: Train Epoch 8: 11/244 Loss: 0.214150
2022-12-29 16:29: Train Epoch 8: 15/244 Loss: 0.213108
2022-12-29 16:29: Train Epoch 8: 19/244 Loss: 0.191316
2022-12-29 16:29: Train Epoch 8: 23/244 Loss: 0.202240
2022-12-29 16:29: Train Epoch 8: 27/244 Loss: 0.200819
2022-12-29 16:29: Train Epoch 8: 31/244 Loss: 0.180980
2022-12-29 16:30: Train Epoch 8: 35/244 Loss: 0.196405
2022-12-29 16:30: Train Epoch 8: 39/244 Loss: 0.188412
2022-12-29 16:30: Train Epoch 8: 43/244 Loss: 0.240134
2022-12-29 16:30: Train Epoch 8: 47/244 Loss: 0.241692
2022-12-29 16:30: Train Epoch 8: 51/244 Loss: 0.199049
2022-12-29 16:30: Train Epoch 8: 55/244 Loss: 0.217638
2022-12-29 16:30: Train Epoch 8: 59/244 Loss: 0.243387
2022-12-29 16:30: Train Epoch 8: 63/244 Loss: 0.228850
2022-12-29 16:30: Train Epoch 8: 67/244 Loss: 0.181874
2022-12-29 16:31: Train Epoch 8: 71/244 Loss: 0.208625
2022-12-29 16:31: Train Epoch 8: 75/244 Loss: 0.193785
2022-12-29 16:31: Train Epoch 8: 79/244 Loss: 0.229705
2022-12-29 16:31: Train Epoch 8: 83/244 Loss: 0.160103
2022-12-29 16:31: Train Epoch 8: 87/244 Loss: 0.179656
2022-12-29 16:31: Train Epoch 8: 91/244 Loss: 0.188486
2022-12-29 16:31: Train Epoch 8: 95/244 Loss: 0.222318
2022-12-29 16:31: Train Epoch 8: 99/244 Loss: 0.212245
2022-12-29 16:31: Train Epoch 8: 103/244 Loss: 0.214366
2022-12-29 16:31: Train Epoch 8: 107/244 Loss: 0.225320
2022-12-29 16:31: Train Epoch 8: 111/244 Loss: 0.214214
2022-12-29 16:32: Train Epoch 8: 115/244 Loss: 0.182427
2022-12-29 16:32: Train Epoch 8: 119/244 Loss: 0.204420
2022-12-29 16:32: Train Epoch 8: 123/244 Loss: 0.191173
2022-12-29 16:32: Train Epoch 8: 127/244 Loss: 0.212565
2022-12-29 16:32: Train Epoch 8: 131/244 Loss: 0.186693
2022-12-29 16:32: Train Epoch 8: 135/244 Loss: 0.220388
2022-12-29 16:32: Train Epoch 8: 139/244 Loss: 0.176358
2022-12-29 16:32: Train Epoch 8: 143/244 Loss: 0.192987
2022-12-29 16:32: Train Epoch 8: 147/244 Loss: 0.212640
2022-12-29 16:32: Train Epoch 8: 151/244 Loss: 0.225028
2022-12-29 16:32: Train Epoch 8: 155/244 Loss: 0.185664
2022-12-29 16:33: Train Epoch 8: 159/244 Loss: 0.246230
2022-12-29 16:33: Train Epoch 8: 163/244 Loss: 0.208081
2022-12-29 16:33: Train Epoch 8: 167/244 Loss: 0.179492
2022-12-29 16:33: Train Epoch 8: 171/244 Loss: 0.218714
2022-12-29 16:33: Train Epoch 8: 175/244 Loss: 0.195869
2022-12-29 16:33: Train Epoch 8: 179/244 Loss: 0.191885
2022-12-29 16:33: Train Epoch 8: 183/244 Loss: 0.186293
2022-12-29 16:33: Train Epoch 8: 187/244 Loss: 0.190848
2022-12-29 16:33: Train Epoch 8: 191/244 Loss: 0.188336
2022-12-29 16:33: Train Epoch 8: 195/244 Loss: 0.256339
2022-12-29 16:34: Train Epoch 8: 199/244 Loss: 0.211037
2022-12-29 16:34: Train Epoch 8: 203/244 Loss: 0.216604
2022-12-29 16:34: Train Epoch 8: 207/244 Loss: 0.236246
2022-12-29 16:34: Train Epoch 8: 211/244 Loss: 0.195096
2022-12-29 16:34: Train Epoch 8: 215/244 Loss: 0.232205
2022-12-29 16:34: Train Epoch 8: 219/244 Loss: 0.205636
2022-12-29 16:34: Train Epoch 8: 223/244 Loss: 0.215304
2022-12-29 16:34: Train Epoch 8: 227/244 Loss: 0.177043
2022-12-29 16:34: Train Epoch 8: 231/244 Loss: 0.164077
2022-12-29 16:34: Train Epoch 8: 235/244 Loss: 0.184109
2022-12-29 16:34: Train Epoch 8: 239/244 Loss: 0.176028
2022-12-29 16:34: Train Epoch 8: 243/244 Loss: 0.234004
2022-12-29 16:34: **********Train Epoch 8: averaged Loss: 0.204271 
2022-12-29 16:34: 
Epoch time elapsed: 351.00036787986755

2022-12-29 16:35: 
 metrics validation: {'precision': 0.7792553191489362, 'recall': 0.22538461538461538, 'f1-score': 0.34964200477326973, 'support': 1300, 'AUC': 0.8101048816568047, 'AUCPR': 0.6959158273336934, 'TP': 293, 'FP': 83, 'TN': 2517, 'FN': 1007} 

2022-12-29 16:35: **********Val Epoch 8: average Loss: 0.326949
2022-12-29 16:35: 
 Testing metrics {'precision': 0.7702464788732394, 'recall': 0.7125407166123778, 'f1-score': 0.7402707275803722, 'support': 1228, 'AUC': 0.8570087613661683, 'AUCPR': 0.7623862044949633, 'TP': 875, 'FP': 261, 'TN': 2195, 'FN': 353} 

2022-12-29 16:35: Train Epoch 9: 3/244 Loss: 0.207382
2022-12-29 16:36: Train Epoch 9: 7/244 Loss: 0.186483
2022-12-29 16:36: Train Epoch 9: 11/244 Loss: 0.179111
2022-12-29 16:36: Train Epoch 9: 15/244 Loss: 0.185746
2022-12-29 16:36: Train Epoch 9: 19/244 Loss: 0.221019
2022-12-29 16:36: Train Epoch 9: 23/244 Loss: 0.188120
2022-12-29 16:36: Train Epoch 9: 27/244 Loss: 0.188832
2022-12-29 16:36: Train Epoch 9: 31/244 Loss: 0.209037
2022-12-29 16:36: Train Epoch 9: 35/244 Loss: 0.214147
2022-12-29 16:36: Train Epoch 9: 39/244 Loss: 0.220919
2022-12-29 16:36: Train Epoch 9: 43/244 Loss: 0.228624
2022-12-29 16:37: Train Epoch 9: 47/244 Loss: 0.226665
2022-12-29 16:37: Train Epoch 9: 51/244 Loss: 0.238551
2022-12-29 16:37: Train Epoch 9: 55/244 Loss: 0.217361
2022-12-29 16:37: Train Epoch 9: 59/244 Loss: 0.219961
2022-12-29 16:37: Train Epoch 9: 63/244 Loss: 0.225388
2022-12-29 16:37: Train Epoch 9: 67/244 Loss: 0.151994
2022-12-29 16:37: Train Epoch 9: 71/244 Loss: 0.213977
2022-12-29 16:37: Train Epoch 9: 75/244 Loss: 0.213529
2022-12-29 16:37: Train Epoch 9: 79/244 Loss: 0.191829
2022-12-29 16:37: Train Epoch 9: 83/244 Loss: 0.229114
2022-12-29 16:38: Train Epoch 9: 87/244 Loss: 0.217830
2022-12-29 16:38: Train Epoch 9: 91/244 Loss: 0.221651
2022-12-29 16:38: Train Epoch 9: 95/244 Loss: 0.196729
2022-12-29 16:38: Train Epoch 9: 99/244 Loss: 0.229567
2022-12-29 16:38: Train Epoch 9: 103/244 Loss: 0.181218
2022-12-29 16:38: Train Epoch 9: 107/244 Loss: 0.221471
2022-12-29 16:38: Train Epoch 9: 111/244 Loss: 0.198209
2022-12-29 16:38: Train Epoch 9: 115/244 Loss: 0.190902
2022-12-29 16:38: Train Epoch 9: 119/244 Loss: 0.226102
2022-12-29 16:38: Train Epoch 9: 123/244 Loss: 0.196057
2022-12-29 16:39: Train Epoch 9: 127/244 Loss: 0.194197
2022-12-29 16:39: Train Epoch 9: 131/244 Loss: 0.203780
2022-12-29 16:39: Train Epoch 9: 135/244 Loss: 0.185356
2022-12-29 16:39: Train Epoch 9: 139/244 Loss: 0.229446
2022-12-29 16:39: Train Epoch 9: 143/244 Loss: 0.209119
2022-12-29 16:39: Train Epoch 9: 147/244 Loss: 0.195193
2022-12-29 16:39: Train Epoch 9: 151/244 Loss: 0.191432
2022-12-29 16:39: Train Epoch 9: 155/244 Loss: 0.200653
2022-12-29 16:39: Train Epoch 9: 159/244 Loss: 0.175401
2022-12-29 16:39: Train Epoch 9: 163/244 Loss: 0.231857
2022-12-29 16:40: Train Epoch 9: 167/244 Loss: 0.152095
2022-12-29 16:40: Train Epoch 9: 171/244 Loss: 0.224985
2022-12-29 16:40: Train Epoch 9: 175/244 Loss: 0.211473
2022-12-29 16:40: Train Epoch 9: 179/244 Loss: 0.202473
2022-12-29 16:40: Train Epoch 9: 183/244 Loss: 0.207186
2022-12-29 16:40: Train Epoch 9: 187/244 Loss: 0.195474
2022-12-29 16:40: Train Epoch 9: 191/244 Loss: 0.168032
2022-12-29 16:40: Train Epoch 9: 195/244 Loss: 0.174628
2022-12-29 16:41: Train Epoch 9: 199/244 Loss: 0.178620
2022-12-29 16:41: Train Epoch 9: 203/244 Loss: 0.223162
2022-12-29 16:41: Train Epoch 9: 207/244 Loss: 0.205454
2022-12-29 16:41: Train Epoch 9: 211/244 Loss: 0.191044
2022-12-29 16:41: Train Epoch 9: 215/244 Loss: 0.170280
2022-12-29 16:41: Train Epoch 9: 219/244 Loss: 0.178145
2022-12-29 16:41: Train Epoch 9: 223/244 Loss: 0.185846
2022-12-29 16:41: Train Epoch 9: 227/244 Loss: 0.198923
2022-12-29 16:41: Train Epoch 9: 231/244 Loss: 0.190402
2022-12-29 16:41: Train Epoch 9: 235/244 Loss: 0.172548
2022-12-29 16:41: Train Epoch 9: 239/244 Loss: 0.180560
2022-12-29 16:42: Train Epoch 9: 243/244 Loss: 0.193462
2022-12-29 16:42: **********Train Epoch 9: averaged Loss: 0.200963 
2022-12-29 16:42: 
Epoch time elapsed: 367.55032110214233

2022-12-29 16:42: 
 metrics validation: {'precision': 0.7779960707269156, 'recall': 0.3046153846153846, 'f1-score': 0.4378109452736318, 'support': 1300, 'AUC': 0.8107942307692307, 'AUCPR': 0.7034426654355641, 'TP': 396, 'FP': 113, 'TN': 2487, 'FN': 904} 

2022-12-29 16:42: **********Val Epoch 9: average Loss: 0.295022
2022-12-29 16:42: 
 Testing metrics {'precision': 0.7702464788732394, 'recall': 0.7125407166123778, 'f1-score': 0.7402707275803722, 'support': 1228, 'AUC': 0.8570087613661683, 'AUCPR': 0.7623862044949633, 'TP': 875, 'FP': 261, 'TN': 2195, 'FN': 353} 

2022-12-29 16:43: Train Epoch 10: 3/244 Loss: 0.188639
2022-12-29 16:43: Train Epoch 10: 7/244 Loss: 0.220972
2022-12-29 16:43: Train Epoch 10: 11/244 Loss: 0.178643
2022-12-29 16:43: Train Epoch 10: 15/244 Loss: 0.194532
2022-12-29 16:43: Train Epoch 10: 19/244 Loss: 0.201930
2022-12-29 16:43: Train Epoch 10: 23/244 Loss: 0.209019
2022-12-29 16:43: Train Epoch 10: 27/244 Loss: 0.188941
2022-12-29 16:43: Train Epoch 10: 31/244 Loss: 0.220108
2022-12-29 16:43: Train Epoch 10: 35/244 Loss: 0.277992
2022-12-29 16:43: Train Epoch 10: 39/244 Loss: 0.207470
2022-12-29 16:43: Train Epoch 10: 43/244 Loss: 0.196950
2022-12-29 16:44: Train Epoch 10: 47/244 Loss: 0.236279
2022-12-29 16:44: Train Epoch 10: 51/244 Loss: 0.236721
2022-12-29 16:44: Train Epoch 10: 55/244 Loss: 0.223350
2022-12-29 16:44: Train Epoch 10: 59/244 Loss: 0.209303
2022-12-29 16:44: Train Epoch 10: 63/244 Loss: 0.272393
2022-12-29 16:44: Train Epoch 10: 67/244 Loss: 0.223439
2022-12-29 16:44: Train Epoch 10: 71/244 Loss: 0.211908
2022-12-29 16:44: Train Epoch 10: 75/244 Loss: 0.239547
2022-12-29 16:44: Train Epoch 10: 79/244 Loss: 0.201070
2022-12-29 16:44: Train Epoch 10: 83/244 Loss: 0.239253
2022-12-29 16:44: Train Epoch 10: 87/244 Loss: 0.197925
2022-12-29 16:45: Train Epoch 10: 91/244 Loss: 0.275371
2022-12-29 16:45: Train Epoch 10: 95/244 Loss: 0.188385
2022-12-29 16:45: Train Epoch 10: 99/244 Loss: 0.185818
2022-12-29 16:45: Train Epoch 10: 103/244 Loss: 0.195441
2022-12-29 16:45: Train Epoch 10: 107/244 Loss: 0.163073
2022-12-29 16:45: Train Epoch 10: 111/244 Loss: 0.175763
2022-12-29 16:45: Train Epoch 10: 115/244 Loss: 0.210587
2022-12-29 16:45: Train Epoch 10: 119/244 Loss: 0.207031
2022-12-29 16:45: Train Epoch 10: 123/244 Loss: 0.231236
2022-12-29 16:45: Train Epoch 10: 127/244 Loss: 0.254010
2022-12-29 16:46: Train Epoch 10: 131/244 Loss: 0.158644
2022-12-29 16:46: Train Epoch 10: 135/244 Loss: 0.244231
2022-12-29 16:46: Train Epoch 10: 139/244 Loss: 0.182725
2022-12-29 16:46: Train Epoch 10: 143/244 Loss: 0.202221
2022-12-29 16:46: Train Epoch 10: 147/244 Loss: 0.205249
2022-12-29 16:46: Train Epoch 10: 151/244 Loss: 0.200808
2022-12-29 16:46: Train Epoch 10: 155/244 Loss: 0.210321
2022-12-29 16:46: Train Epoch 10: 159/244 Loss: 0.175132
2022-12-29 16:46: Train Epoch 10: 163/244 Loss: 0.189168
2022-12-29 16:46: Train Epoch 10: 167/244 Loss: 0.181667
2022-12-29 16:47: Train Epoch 10: 171/244 Loss: 0.236228
2022-12-29 16:47: Train Epoch 10: 175/244 Loss: 0.267151
2022-12-29 16:47: Train Epoch 10: 179/244 Loss: 0.217079
2022-12-29 16:47: Train Epoch 10: 183/244 Loss: 0.198157
2022-12-29 16:47: Train Epoch 10: 187/244 Loss: 0.229064
2022-12-29 16:47: Train Epoch 10: 191/244 Loss: 0.221152
2022-12-29 16:47: Train Epoch 10: 195/244 Loss: 0.205734
2022-12-29 16:47: Train Epoch 10: 199/244 Loss: 0.183628
2022-12-29 16:47: Train Epoch 10: 203/244 Loss: 0.219830
2022-12-29 16:47: Train Epoch 10: 207/244 Loss: 0.209711
2022-12-29 16:48: Train Epoch 10: 211/244 Loss: 0.172313
2022-12-29 16:48: Train Epoch 10: 215/244 Loss: 0.210560
2022-12-29 16:48: Train Epoch 10: 219/244 Loss: 0.199914
2022-12-29 16:48: Train Epoch 10: 223/244 Loss: 0.191457
2022-12-29 16:48: Train Epoch 10: 227/244 Loss: 0.202615
2022-12-29 16:48: Train Epoch 10: 231/244 Loss: 0.213931
2022-12-29 16:48: Train Epoch 10: 235/244 Loss: 0.201850
2022-12-29 16:48: Train Epoch 10: 239/244 Loss: 0.252232
2022-12-29 16:48: Train Epoch 10: 243/244 Loss: 0.163215
2022-12-29 16:48: **********Train Epoch 10: averaged Loss: 0.209985 
2022-12-29 16:48: 
Epoch time elapsed: 350.41656255722046

2022-12-29 16:49: 
 metrics validation: {'precision': 0.7074569789674953, 'recall': 0.5692307692307692, 'f1-score': 0.6308610400682011, 'support': 1300, 'AUC': 0.8008121301775148, 'AUCPR': 0.664376374687996, 'TP': 740, 'FP': 306, 'TN': 2294, 'FN': 560} 

2022-12-29 16:49: **********Val Epoch 10: average Loss: 0.264731
2022-12-29 16:49: 
 Testing metrics {'precision': 0.7702464788732394, 'recall': 0.7125407166123778, 'f1-score': 0.7402707275803722, 'support': 1228, 'AUC': 0.8570087613661683, 'AUCPR': 0.7623862044949633, 'TP': 875, 'FP': 261, 'TN': 2195, 'FN': 353} 

2022-12-29 16:49: Train Epoch 11: 3/244 Loss: 0.207006
2022-12-29 16:49: Train Epoch 11: 7/244 Loss: 0.186534
2022-12-29 16:49: Train Epoch 11: 11/244 Loss: 0.241070
2022-12-29 16:50: Train Epoch 11: 15/244 Loss: 0.164535
2022-12-29 16:50: Train Epoch 11: 19/244 Loss: 0.167982
2022-12-29 16:50: Train Epoch 11: 23/244 Loss: 0.226457
2022-12-29 16:50: Train Epoch 11: 27/244 Loss: 0.204563
2022-12-29 16:50: Train Epoch 11: 31/244 Loss: 0.206280
2022-12-29 16:50: Train Epoch 11: 35/244 Loss: 0.195343
2022-12-29 16:50: Train Epoch 11: 39/244 Loss: 0.180259
2022-12-29 16:50: Train Epoch 11: 43/244 Loss: 0.206928
2022-12-29 16:50: Train Epoch 11: 47/244 Loss: 0.161804
2022-12-29 16:51: Train Epoch 11: 51/244 Loss: 0.226994
2022-12-29 16:51: Train Epoch 11: 55/244 Loss: 0.200887
2022-12-29 16:51: Train Epoch 11: 59/244 Loss: 0.277986
2022-12-29 16:51: Train Epoch 11: 63/244 Loss: 0.174824
2022-12-29 16:51: Train Epoch 11: 67/244 Loss: 0.182277
2022-12-29 16:51: Train Epoch 11: 71/244 Loss: 0.198608
2022-12-29 16:51: Train Epoch 11: 75/244 Loss: 0.204123
2022-12-29 16:51: Train Epoch 11: 79/244 Loss: 0.189974
2022-12-29 16:51: Train Epoch 11: 83/244 Loss: 0.218018
2022-12-29 16:51: Train Epoch 11: 87/244 Loss: 0.201943
2022-12-29 16:51: Train Epoch 11: 91/244 Loss: 0.247890
2022-12-29 16:52: Train Epoch 11: 95/244 Loss: 0.208861
2022-12-29 16:52: Train Epoch 11: 99/244 Loss: 0.196614
2022-12-29 16:52: Train Epoch 11: 103/244 Loss: 0.168773
2022-12-29 16:52: Train Epoch 11: 107/244 Loss: 0.191846
2022-12-29 16:52: Train Epoch 11: 111/244 Loss: 0.193021
2022-12-29 16:52: Train Epoch 11: 115/244 Loss: 0.172134
2022-12-29 16:52: Train Epoch 11: 119/244 Loss: 0.168568
2022-12-29 16:52: Train Epoch 11: 123/244 Loss: 0.184495
2022-12-29 16:52: Train Epoch 11: 127/244 Loss: 0.219147
2022-12-29 16:52: Train Epoch 11: 131/244 Loss: 0.206186
2022-12-29 16:52: Train Epoch 11: 135/244 Loss: 0.206216
2022-12-29 16:53: Train Epoch 11: 139/244 Loss: 0.182991
2022-12-29 16:53: Train Epoch 11: 143/244 Loss: 0.198449
2022-12-29 16:53: Train Epoch 11: 147/244 Loss: 0.198269
2022-12-29 16:53: Train Epoch 11: 151/244 Loss: 0.191535
2022-12-29 16:53: Train Epoch 11: 155/244 Loss: 0.196370
2022-12-29 16:53: Train Epoch 11: 159/244 Loss: 0.204671
2022-12-29 16:53: Train Epoch 11: 163/244 Loss: 0.226827
2022-12-29 16:53: Train Epoch 11: 167/244 Loss: 0.219230
2022-12-29 16:53: Train Epoch 11: 171/244 Loss: 0.256126
2022-12-29 16:53: Train Epoch 11: 175/244 Loss: 0.219437
2022-12-29 16:54: Train Epoch 11: 179/244 Loss: 0.195466
2022-12-29 16:54: Train Epoch 11: 183/244 Loss: 0.238080
2022-12-29 16:54: Train Epoch 11: 187/244 Loss: 0.211257
2022-12-29 16:54: Train Epoch 11: 191/244 Loss: 0.239504
2022-12-29 16:54: Train Epoch 11: 195/244 Loss: 0.235554
2022-12-29 16:54: Train Epoch 11: 199/244 Loss: 0.197018
2022-12-29 16:54: Train Epoch 11: 203/244 Loss: 0.249561
2022-12-29 16:54: Train Epoch 11: 207/244 Loss: 0.203573
2022-12-29 16:54: Train Epoch 11: 211/244 Loss: 0.246816
2022-12-29 16:54: Train Epoch 11: 215/244 Loss: 0.207010
2022-12-29 16:54: Train Epoch 11: 219/244 Loss: 0.169212
2022-12-29 16:55: Train Epoch 11: 223/244 Loss: 0.211872
2022-12-29 16:55: Train Epoch 11: 227/244 Loss: 0.186440
2022-12-29 16:55: Train Epoch 11: 231/244 Loss: 0.205648
2022-12-29 16:55: Train Epoch 11: 235/244 Loss: 0.176570
2022-12-29 16:55: Train Epoch 11: 239/244 Loss: 0.273776
2022-12-29 16:55: Train Epoch 11: 243/244 Loss: 0.130231
2022-12-29 16:55: **********Train Epoch 11: averaged Loss: 0.204256 
2022-12-29 16:55: 
Epoch time elapsed: 347.78156208992004

2022-12-29 16:55: 
 metrics validation: {'precision': 0.7324902723735408, 'recall': 0.5792307692307692, 'f1-score': 0.6469072164948453, 'support': 1300, 'AUC': 0.8095869822485208, 'AUCPR': 0.685153053733593, 'TP': 753, 'FP': 275, 'TN': 2325, 'FN': 547} 

2022-12-29 16:55: **********Val Epoch 11: average Loss: 0.286244
2022-12-29 16:56: 
 Testing metrics {'precision': 0.7702464788732394, 'recall': 0.7125407166123778, 'f1-score': 0.7402707275803722, 'support': 1228, 'AUC': 0.8570087613661683, 'AUCPR': 0.7623862044949633, 'TP': 875, 'FP': 261, 'TN': 2195, 'FN': 353} 

2022-12-29 16:56: Train Epoch 12: 3/244 Loss: 0.210110
2022-12-29 16:56: Train Epoch 12: 7/244 Loss: 0.194853
2022-12-29 16:56: Train Epoch 12: 11/244 Loss: 0.223242
2022-12-29 16:56: Train Epoch 12: 15/244 Loss: 0.178496
2022-12-29 16:56: Train Epoch 12: 19/244 Loss: 0.183729
2022-12-29 16:57: Train Epoch 12: 23/244 Loss: 0.195431
2022-12-29 16:57: Train Epoch 12: 27/244 Loss: 0.170700
2022-12-29 16:57: Train Epoch 12: 31/244 Loss: 0.212595
2022-12-29 16:57: Train Epoch 12: 35/244 Loss: 0.209330
2022-12-29 16:57: Train Epoch 12: 39/244 Loss: 0.192565
2022-12-29 16:57: Train Epoch 12: 43/244 Loss: 0.198440
2022-12-29 16:57: Train Epoch 12: 47/244 Loss: 0.183836
2022-12-29 16:57: Train Epoch 12: 51/244 Loss: 0.221224
2022-12-29 16:57: Train Epoch 12: 55/244 Loss: 0.200110
2022-12-29 16:57: Train Epoch 12: 59/244 Loss: 0.201520
2022-12-29 16:57: Train Epoch 12: 63/244 Loss: 0.182540
2022-12-29 16:58: Train Epoch 12: 67/244 Loss: 0.169271
2022-12-29 16:58: Train Epoch 12: 71/244 Loss: 0.200501
2022-12-29 16:58: Train Epoch 12: 75/244 Loss: 0.188866
2022-12-29 16:58: Train Epoch 12: 79/244 Loss: 0.187694
2022-12-29 16:58: Train Epoch 12: 83/244 Loss: 0.231905
2022-12-29 16:58: Train Epoch 12: 87/244 Loss: 0.211259
2022-12-29 16:58: Train Epoch 12: 91/244 Loss: 0.241737
2022-12-29 16:58: Train Epoch 12: 95/244 Loss: 0.180062
2022-12-29 16:58: Train Epoch 12: 99/244 Loss: 0.189274
2022-12-29 16:58: Train Epoch 12: 103/244 Loss: 0.217043
2022-12-29 16:59: Train Epoch 12: 107/244 Loss: 0.217149
2022-12-29 16:59: Train Epoch 12: 111/244 Loss: 0.241237
2022-12-29 16:59: Train Epoch 12: 115/244 Loss: 0.192018
2022-12-29 16:59: Train Epoch 12: 119/244 Loss: 0.202551
2022-12-29 16:59: Train Epoch 12: 123/244 Loss: 0.213723
2022-12-29 16:59: Train Epoch 12: 127/244 Loss: 0.216339
2022-12-29 16:59: Train Epoch 12: 131/244 Loss: 0.216019
2022-12-29 16:59: Train Epoch 12: 135/244 Loss: 0.220453
2022-12-29 16:59: Train Epoch 12: 139/244 Loss: 0.228165
2022-12-29 16:59: Train Epoch 12: 143/244 Loss: 0.216006
2022-12-29 17:00: Train Epoch 12: 147/244 Loss: 0.189289
2022-12-29 17:00: Train Epoch 12: 151/244 Loss: 0.195640
2022-12-29 17:00: Train Epoch 12: 155/244 Loss: 0.257901
2022-12-29 17:00: Train Epoch 12: 159/244 Loss: 0.197154
2022-12-29 17:00: Train Epoch 12: 163/244 Loss: 0.182441
2022-12-29 17:00: Train Epoch 12: 167/244 Loss: 0.243867
2022-12-29 17:00: Train Epoch 12: 171/244 Loss: 0.194323
2022-12-29 17:00: Train Epoch 12: 175/244 Loss: 0.225800
2022-12-29 17:00: Train Epoch 12: 179/244 Loss: 0.218628
2022-12-29 17:00: Train Epoch 12: 183/244 Loss: 0.194385
2022-12-29 17:01: Train Epoch 12: 187/244 Loss: 0.201117
2022-12-29 17:01: Train Epoch 12: 191/244 Loss: 0.193991
2022-12-29 17:01: Train Epoch 12: 195/244 Loss: 0.221202
2022-12-29 17:01: Train Epoch 12: 199/244 Loss: 0.187871
2022-12-29 17:01: Train Epoch 12: 203/244 Loss: 0.189481
2022-12-29 17:01: Train Epoch 12: 207/244 Loss: 0.182076
2022-12-29 17:01: Train Epoch 12: 211/244 Loss: 0.194694
2022-12-29 17:01: Train Epoch 12: 215/244 Loss: 0.220880
2022-12-29 17:01: Train Epoch 12: 219/244 Loss: 0.200243
2022-12-29 17:01: Train Epoch 12: 223/244 Loss: 0.218060
2022-12-29 17:01: Train Epoch 12: 227/244 Loss: 0.220182
2022-12-29 17:02: Train Epoch 12: 231/244 Loss: 0.216581
2022-12-29 17:02: Train Epoch 12: 235/244 Loss: 0.224161
2022-12-29 17:02: Train Epoch 12: 239/244 Loss: 0.231705
2022-12-29 17:02: Train Epoch 12: 243/244 Loss: 0.167077
2022-12-29 17:02: **********Train Epoch 12: averaged Loss: 0.205061 
2022-12-29 17:02: 
Epoch time elapsed: 351.03795075416565

2022-12-29 17:02: 
 metrics validation: {'precision': 0.7137614678899082, 'recall': 0.5984615384615385, 'f1-score': 0.6510460251046025, 'support': 1300, 'AUC': 0.8060321005917159, 'AUCPR': 0.6666912778588854, 'TP': 778, 'FP': 312, 'TN': 2288, 'FN': 522} 

2022-12-29 17:02: **********Val Epoch 12: average Loss: 0.277415
2022-12-29 17:02: Validation performance didn't improve for 8 epochs. Training stops.
2022-12-29 17:02: Total training time: 80.5169min, best loss: 0.246174
2022-12-29 17:02: Saving current best model to /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122915421269493369118/best_model.pth
2022-12-29 17:03: 
 Testing metrics {'precision': 0.7702464788732394, 'recall': 0.7125407166123778, 'f1-score': 0.7402707275803722, 'support': 1228, 'AUC': 0.8570087613661683, 'AUCPR': 0.7623862044949633, 'TP': 875, 'FP': 261, 'TN': 2195, 'FN': 353} 

