2022-12-28 00:10: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103610689247889
2022-12-28 00:10: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103610689247889
2022-12-28 00:10: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=32, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103610689247889', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0005, max_grad_norm=5, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=32, seed=1, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-28 00:10: Argument batch_size: 256
2022-12-28 00:10: Argument clc: 'vec'
2022-12-28 00:10: Argument cuda: True
2022-12-28 00:10: Argument dataset: '2020'
2022-12-28 00:10: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-28 00:10: Argument debug: False
2022-12-28 00:10: Argument default_graph: True
2022-12-28 00:10: Argument device: 'cpu'
2022-12-28 00:10: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-28 00:10: Argument early_stop: True
2022-12-28 00:10: Argument early_stop_patience: 8
2022-12-28 00:10: Argument embed_dim: 32
2022-12-28 00:10: Argument epochs: 30
2022-12-28 00:10: Argument grad_norm: False
2022-12-28 00:10: Argument horizon: 1
2022-12-28 00:10: Argument input_dim: 25
2022-12-28 00:10: Argument lag: 10
2022-12-28 00:10: Argument link_len: 2
2022-12-28 00:10: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103610689247889'
2022-12-28 00:10: Argument log_step: 1
2022-12-28 00:10: Argument loss_func: 'nllloss'
2022-12-28 00:10: Argument lr_decay: True
2022-12-28 00:10: Argument lr_decay_rate: 0.1
2022-12-28 00:10: Argument lr_decay_step: '15, 20'
2022-12-28 00:10: Argument lr_init: 0.0005
2022-12-28 00:10: Argument max_grad_norm: 5
2022-12-28 00:10: Argument mode: 'train'
2022-12-28 00:10: Argument model: 'fire_GCN'
2022-12-28 00:10: Argument nan_fill: 0.5
2022-12-28 00:10: Argument num_layers: 1
2022-12-28 00:10: Argument num_nodes: 625
2022-12-28 00:10: Argument num_workers: 20
2022-12-28 00:10: Argument output_dim: 2
2022-12-28 00:10: Argument patch_height: 25
2022-12-28 00:10: Argument patch_width: 25
2022-12-28 00:10: Argument persistent_workers: True
2022-12-28 00:10: Argument pin_memory: True
2022-12-28 00:10: Argument plot: False
2022-12-28 00:10: Argument positive_weight: 0.5
2022-12-28 00:10: Argument prefetch_factor: 2
2022-12-28 00:10: Argument real_value: True
2022-12-28 00:10: Argument rnn_units: 32
2022-12-28 00:10: Argument seed: 1
2022-12-28 00:10: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-28 00:10: Argument teacher_forcing: False
2022-12-28 00:10: Argument weight_decay: 0.0
2022-12-28 00:10: Argument window_len: 10
2022-12-28 00:12: Train Epoch 1: 0/159 Loss: 0.653446
2022-12-28 00:13: Train Epoch 1: 1/159 Loss: 2.690017
2022-12-28 00:14: Train Epoch 1: 2/159 Loss: 0.831943
2022-12-28 00:16: Train Epoch 1: 3/159 Loss: 1.693934
2022-12-28 00:17: Train Epoch 1: 4/159 Loss: 1.430120
2022-12-28 00:18: Train Epoch 1: 5/159 Loss: 0.584582
2022-12-28 00:19: Train Epoch 1: 6/159 Loss: 1.072297
2022-12-28 00:21: Train Epoch 1: 7/159 Loss: 1.435821
2022-12-28 00:22: Train Epoch 1: 8/159 Loss: 1.502805
2022-12-28 00:23: Train Epoch 1: 9/159 Loss: 1.235385
2022-12-28 00:25: Train Epoch 1: 10/159 Loss: 0.682214
2022-12-28 00:26: Train Epoch 1: 11/159 Loss: 0.676800
2022-12-28 00:27: Train Epoch 1: 12/159 Loss: 1.014396
2022-12-28 00:28: Train Epoch 1: 13/159 Loss: 1.096696
2022-12-28 00:30: Train Epoch 1: 14/159 Loss: 0.731930
2022-12-28 00:31: Train Epoch 1: 15/159 Loss: 0.677462
2022-12-28 00:32: Train Epoch 1: 16/159 Loss: 0.876412
2022-12-28 00:34: Train Epoch 1: 17/159 Loss: 0.773004
2022-12-28 00:35: Train Epoch 1: 18/159 Loss: 0.780131
2022-12-28 00:36: Train Epoch 1: 19/159 Loss: 0.666367
2022-12-28 00:38: Train Epoch 1: 20/159 Loss: 0.617850
2022-12-28 00:39: Train Epoch 1: 21/159 Loss: 0.691195
2022-12-28 00:41: Train Epoch 1: 22/159 Loss: 0.770287
2022-12-28 00:42: Train Epoch 1: 23/159 Loss: 0.707151
2022-12-28 00:43: Train Epoch 1: 24/159 Loss: 0.617531
2022-12-28 00:45: Train Epoch 1: 25/159 Loss: 0.657927
2022-12-28 00:46: Train Epoch 1: 26/159 Loss: 0.672928
2022-12-28 00:47: Train Epoch 1: 27/159 Loss: 0.776672
2022-12-28 00:49: Train Epoch 1: 28/159 Loss: 0.567079
2022-12-28 00:50: Train Epoch 1: 29/159 Loss: 0.606916
2022-12-28 00:51: Train Epoch 1: 30/159 Loss: 0.621776
2022-12-28 00:53: Train Epoch 1: 31/159 Loss: 0.655580
2022-12-28 00:54: Train Epoch 1: 32/159 Loss: 0.655443
2022-12-28 00:55: Train Epoch 1: 33/159 Loss: 0.593972
2022-12-28 00:57: Train Epoch 1: 34/159 Loss: 0.593137
2022-12-28 00:58: Train Epoch 1: 35/159 Loss: 0.679792
2022-12-28 00:59: Train Epoch 1: 36/159 Loss: 0.712033
2022-12-28 01:01: Train Epoch 1: 37/159 Loss: 0.571125
2022-12-28 01:02: Train Epoch 1: 38/159 Loss: 0.582695
2022-12-28 01:03: Train Epoch 1: 39/159 Loss: 0.607354
2022-12-28 01:05: Train Epoch 1: 40/159 Loss: 0.612064
2022-12-28 01:06: Train Epoch 1: 41/159 Loss: 0.601457
2022-12-28 01:07: Train Epoch 1: 42/159 Loss: 0.552780
2022-12-28 01:09: Train Epoch 1: 43/159 Loss: 0.584777
2022-12-28 01:10: Train Epoch 1: 44/159 Loss: 0.532675
2022-12-28 01:11: Train Epoch 1: 45/159 Loss: 0.571551
2022-12-28 01:13: Train Epoch 1: 46/159 Loss: 0.549648
2022-12-28 01:14: Train Epoch 1: 47/159 Loss: 0.537970
2022-12-28 01:15: Train Epoch 1: 48/159 Loss: 0.554492
2022-12-28 01:17: Train Epoch 1: 49/159 Loss: 0.546280
2022-12-28 01:18: Train Epoch 1: 50/159 Loss: 0.524592
2022-12-28 01:19: Train Epoch 1: 51/159 Loss: 0.543434
2022-12-28 01:21: Train Epoch 1: 52/159 Loss: 0.559220
2022-12-28 01:22: Train Epoch 1: 53/159 Loss: 0.521076
2022-12-28 01:23: Train Epoch 1: 54/159 Loss: 0.578253
2022-12-28 01:25: Train Epoch 1: 55/159 Loss: 0.517811
2022-12-28 01:26: Train Epoch 1: 56/159 Loss: 0.520590
2022-12-28 01:27: Train Epoch 1: 57/159 Loss: 0.581314
2022-12-28 01:29: Train Epoch 1: 58/159 Loss: 0.517081
2022-12-28 01:30: Train Epoch 1: 59/159 Loss: 0.516489
2022-12-28 01:31: Train Epoch 1: 60/159 Loss: 0.574579
2022-12-28 01:33: Train Epoch 1: 61/159 Loss: 0.505779
2022-12-28 01:34: Train Epoch 1: 62/159 Loss: 0.500516
2022-12-28 01:35: Train Epoch 1: 63/159 Loss: 0.542208
2022-12-28 01:37: Train Epoch 1: 64/159 Loss: 0.515565
2022-12-28 01:38: Train Epoch 1: 65/159 Loss: 0.543686
2022-12-28 01:39: Train Epoch 1: 66/159 Loss: 0.498126
2022-12-28 01:41: Train Epoch 1: 67/159 Loss: 0.524908
2022-12-28 01:42: Train Epoch 1: 68/159 Loss: 0.525266
2022-12-28 01:44: Train Epoch 1: 69/159 Loss: 0.489883
2022-12-28 01:45: Train Epoch 1: 70/159 Loss: 0.480577
2022-12-28 01:46: Train Epoch 1: 71/159 Loss: 0.454332
2022-12-28 01:47: Train Epoch 1: 72/159 Loss: 0.480475
2022-12-28 01:49: Train Epoch 1: 73/159 Loss: 0.465612
2022-12-28 01:50: Train Epoch 1: 74/159 Loss: 0.463357
2022-12-28 01:52: Train Epoch 1: 75/159 Loss: 0.440656
2022-12-28 01:53: Train Epoch 1: 76/159 Loss: 0.473211
2022-12-28 01:54: Train Epoch 1: 77/159 Loss: 0.401256
2022-12-28 01:56: Train Epoch 1: 78/159 Loss: 0.435820
2022-12-28 01:57: Train Epoch 1: 79/159 Loss: 0.444142
2022-12-28 01:58: Train Epoch 1: 80/159 Loss: 0.427678
2022-12-28 02:00: Train Epoch 1: 81/159 Loss: 0.408329
2022-12-28 02:01: Train Epoch 1: 82/159 Loss: 0.443057
2022-12-28 02:02: Train Epoch 1: 83/159 Loss: 0.387101
2022-12-28 02:04: Train Epoch 1: 84/159 Loss: 0.438337
2022-12-28 02:05: Train Epoch 1: 85/159 Loss: 0.432562
2022-12-28 02:06: Train Epoch 1: 86/159 Loss: 0.446668
2022-12-28 02:08: Train Epoch 1: 87/159 Loss: 0.397053
2022-12-28 02:09: Train Epoch 1: 88/159 Loss: 0.432476
2022-12-28 02:10: Train Epoch 1: 89/159 Loss: 0.342119
2022-12-28 02:12: Train Epoch 1: 90/159 Loss: 0.432132
2022-12-28 02:13: Train Epoch 1: 91/159 Loss: 0.430681
2022-12-28 02:14: Train Epoch 1: 92/159 Loss: 0.398767
2022-12-28 02:16: Train Epoch 1: 93/159 Loss: 0.401817
2022-12-28 02:17: Train Epoch 1: 94/159 Loss: 0.395588
2022-12-28 02:18: Train Epoch 1: 95/159 Loss: 0.403499
2022-12-28 02:20: Train Epoch 1: 96/159 Loss: 0.434772
2022-12-28 02:21: Train Epoch 1: 97/159 Loss: 0.383811
2022-12-28 02:22: Train Epoch 1: 98/159 Loss: 0.348024
2022-12-28 02:24: Train Epoch 1: 99/159 Loss: 0.356713
2022-12-28 02:25: Train Epoch 1: 100/159 Loss: 0.384436
2022-12-28 02:26: Train Epoch 1: 101/159 Loss: 0.364825
2022-12-28 02:28: Train Epoch 1: 102/159 Loss: 0.339828
2022-12-28 02:29: Train Epoch 1: 103/159 Loss: 0.356153
2022-12-28 02:30: Train Epoch 1: 104/159 Loss: 0.339282
2022-12-28 02:32: Train Epoch 1: 105/159 Loss: 0.320574
2022-12-28 02:33: Train Epoch 1: 106/159 Loss: 0.356043
2022-12-28 02:34: Train Epoch 1: 107/159 Loss: 0.325703
2022-12-28 02:36: Train Epoch 1: 108/159 Loss: 0.322362
2022-12-28 02:37: Train Epoch 1: 109/159 Loss: 0.354876
2022-12-28 02:38: Train Epoch 1: 110/159 Loss: 0.345055
2022-12-28 02:40: Train Epoch 1: 111/159 Loss: 0.348583
2022-12-28 02:41: Train Epoch 1: 112/159 Loss: 0.336584
2022-12-28 02:42: Train Epoch 1: 113/159 Loss: 0.283560
2022-12-28 02:44: Train Epoch 1: 114/159 Loss: 0.319663
2022-12-28 02:45: Train Epoch 1: 115/159 Loss: 0.312518
2022-12-28 02:46: Train Epoch 1: 116/159 Loss: 0.333901
2022-12-28 02:48: Train Epoch 1: 117/159 Loss: 0.337431
2022-12-28 02:49: Train Epoch 1: 118/159 Loss: 0.291294
2022-12-28 02:50: Train Epoch 1: 119/159 Loss: 0.285825
2022-12-28 02:52: Train Epoch 1: 120/159 Loss: 0.348617
2022-12-28 02:53: Train Epoch 1: 121/159 Loss: 0.318833
2022-12-28 02:54: Train Epoch 1: 122/159 Loss: 0.278667
2022-12-28 02:56: Train Epoch 1: 123/159 Loss: 0.296884
2022-12-28 02:57: Train Epoch 1: 124/159 Loss: 0.312392
2022-12-28 02:58: Train Epoch 1: 125/159 Loss: 0.343600
2022-12-28 03:00: Train Epoch 1: 126/159 Loss: 0.330745
2022-12-28 03:01: Train Epoch 1: 127/159 Loss: 0.355726
2022-12-28 03:02: Train Epoch 1: 128/159 Loss: 0.357906
2022-12-28 03:03: Train Epoch 1: 129/159 Loss: 0.344867
2022-12-28 03:05: Train Epoch 1: 130/159 Loss: 0.322591
2022-12-28 03:06: Train Epoch 1: 131/159 Loss: 0.325406
2022-12-28 03:07: Train Epoch 1: 132/159 Loss: 0.327234
2022-12-28 03:09: Train Epoch 1: 133/159 Loss: 0.290539
2022-12-28 03:10: Train Epoch 1: 134/159 Loss: 0.346325
2022-12-28 03:11: Train Epoch 1: 135/159 Loss: 0.363947
2022-12-28 03:13: Train Epoch 1: 136/159 Loss: 0.241050
2022-12-28 03:14: Train Epoch 1: 137/159 Loss: 0.334743
2022-12-28 03:15: Train Epoch 1: 138/159 Loss: 0.307283
2022-12-28 03:16: Train Epoch 1: 139/159 Loss: 0.267247
2022-12-28 03:18: Train Epoch 1: 140/159 Loss: 0.257499
2022-12-28 03:19: Train Epoch 1: 141/159 Loss: 0.362952
2022-12-28 03:20: Train Epoch 1: 142/159 Loss: 0.278188
2022-12-28 03:22: Train Epoch 1: 143/159 Loss: 0.287636
2022-12-28 03:23: Train Epoch 1: 144/159 Loss: 0.339347
2022-12-28 03:24: Train Epoch 1: 145/159 Loss: 0.302282
2022-12-28 03:26: Train Epoch 1: 146/159 Loss: 0.309532
2022-12-28 03:27: Train Epoch 1: 147/159 Loss: 0.377442
2022-12-28 03:28: Train Epoch 1: 148/159 Loss: 0.274481
2022-12-28 03:29: Train Epoch 1: 149/159 Loss: 0.335846
2022-12-28 03:31: Train Epoch 1: 150/159 Loss: 0.346981
2022-12-28 03:32: Train Epoch 1: 151/159 Loss: 0.309655
2022-12-28 03:33: Train Epoch 1: 152/159 Loss: 0.260833
2022-12-28 03:35: Train Epoch 1: 153/159 Loss: 0.349494
2022-12-28 03:36: Train Epoch 1: 154/159 Loss: 0.312415
2022-12-28 03:37: Train Epoch 1: 155/159 Loss: 0.319569
2022-12-28 03:39: Train Epoch 1: 156/159 Loss: 0.328324
2022-12-28 03:40: Train Epoch 1: 157/159 Loss: 0.263484
2022-12-28 03:40: Train Epoch 1: 158/159 Loss: 0.310567
2022-12-28 03:40: **********Train Epoch 1: averaged Loss: 0.515651 
2022-12-28 03:40: 
Epoch time elapsed: 12609.937386274338

2022-12-28 03:47: 
 metrics validation: {'precision': 0.7170506912442396, 'recall': 0.5984615384615385, 'f1-score': 0.6524109014675052, 'support': 1300, 'AUC': 0.8472754437869823, 'AUCPR': 0.7525308569634739, 'TP': 778, 'FP': 307, 'TN': 2293, 'FN': 522} 

2022-12-28 03:47: **********Val Epoch 1: average Loss: 0.469413
2022-12-28 03:47: *********************************Current best model saved!
2022-12-28 03:52: 
 Testing metrics {'precision': 0.7785171102661597, 'recall': 0.6669381107491856, 'f1-score': 0.718421052631579, 'support': 1228, 'AUC': 0.8708487623210857, 'AUCPR': 0.7856498000673995, 'TP': 819, 'FP': 233, 'TN': 2223, 'FN': 409} 

2022-12-28 03:54: Train Epoch 2: 0/159 Loss: 0.275646
2022-12-28 03:55: Train Epoch 2: 1/159 Loss: 0.283649
2022-12-28 03:57: Train Epoch 2: 2/159 Loss: 0.294846
2022-12-28 03:58: Train Epoch 2: 3/159 Loss: 0.364392
2022-12-28 03:59: Train Epoch 2: 4/159 Loss: 0.259407
2022-12-28 04:01: Train Epoch 2: 5/159 Loss: 0.252458
2022-12-28 04:02: Train Epoch 2: 6/159 Loss: 0.296190
2022-12-28 04:03: Train Epoch 2: 7/159 Loss: 0.258554
2022-12-28 04:05: Train Epoch 2: 8/159 Loss: 0.250431
2022-12-28 04:06: Train Epoch 2: 9/159 Loss: 0.309802
2022-12-28 04:07: Train Epoch 2: 10/159 Loss: 0.285532
2022-12-28 04:09: Train Epoch 2: 11/159 Loss: 0.303766
2022-12-28 04:10: Train Epoch 2: 12/159 Loss: 0.282520
2022-12-28 04:12: Train Epoch 2: 13/159 Loss: 0.291851
2022-12-28 04:13: Train Epoch 2: 14/159 Loss: 0.256325
2022-12-28 04:14: Train Epoch 2: 15/159 Loss: 0.334034
2022-12-28 04:16: Train Epoch 2: 16/159 Loss: 0.251771
2022-12-28 04:17: Train Epoch 2: 17/159 Loss: 0.287924
2022-12-28 04:18: Train Epoch 2: 18/159 Loss: 0.257580
2022-12-28 04:20: Train Epoch 2: 19/159 Loss: 0.263237
2022-12-28 04:21: Train Epoch 2: 20/159 Loss: 0.284019
2022-12-28 04:22: Train Epoch 2: 21/159 Loss: 0.255154
2022-12-28 04:24: Train Epoch 2: 22/159 Loss: 0.318827
2022-12-28 04:25: Train Epoch 2: 23/159 Loss: 0.297739
2022-12-28 04:26: Train Epoch 2: 24/159 Loss: 0.290926
2022-12-28 04:28: Train Epoch 2: 25/159 Loss: 0.296766
2022-12-28 04:29: Train Epoch 2: 26/159 Loss: 0.255189
2022-12-28 04:30: Train Epoch 2: 27/159 Loss: 0.273166
2022-12-28 04:32: Train Epoch 2: 28/159 Loss: 0.294787
2022-12-28 04:33: Train Epoch 2: 29/159 Loss: 0.337781
2022-12-28 04:34: Train Epoch 2: 30/159 Loss: 0.296591
2022-12-28 04:36: Train Epoch 2: 31/159 Loss: 0.295788
2022-12-28 04:37: Train Epoch 2: 32/159 Loss: 0.273120
2022-12-28 04:38: Train Epoch 2: 33/159 Loss: 0.329484
2022-12-28 04:40: Train Epoch 2: 34/159 Loss: 0.328051
2022-12-28 04:41: Train Epoch 2: 35/159 Loss: 0.298315
2022-12-28 04:42: Train Epoch 2: 36/159 Loss: 0.277641
2022-12-28 04:44: Train Epoch 2: 37/159 Loss: 0.250297
2022-12-28 04:45: Train Epoch 2: 38/159 Loss: 0.290232
2022-12-28 04:46: Train Epoch 2: 39/159 Loss: 0.339853
2022-12-28 04:48: Train Epoch 2: 40/159 Loss: 0.286388
2022-12-28 04:49: Train Epoch 2: 41/159 Loss: 0.312669
2022-12-28 04:50: Train Epoch 2: 42/159 Loss: 0.305217
2022-12-28 04:52: Train Epoch 2: 43/159 Loss: 0.288431
2022-12-28 04:53: Train Epoch 2: 44/159 Loss: 0.271573
2022-12-28 04:54: Train Epoch 2: 45/159 Loss: 0.268186
2022-12-28 04:56: Train Epoch 2: 46/159 Loss: 0.318893
2022-12-28 04:57: Train Epoch 2: 47/159 Loss: 0.286807
2022-12-28 04:58: Train Epoch 2: 48/159 Loss: 0.267602
2022-12-28 05:00: Train Epoch 2: 49/159 Loss: 0.296793
2022-12-28 05:01: Train Epoch 2: 50/159 Loss: 0.242335
2022-12-28 05:03: Train Epoch 2: 51/159 Loss: 0.305020
2022-12-28 05:04: Train Epoch 2: 52/159 Loss: 0.270599
2022-12-28 05:05: Train Epoch 2: 53/159 Loss: 0.281541
2022-12-28 05:07: Train Epoch 2: 54/159 Loss: 0.242179
2022-12-28 05:08: Train Epoch 2: 55/159 Loss: 0.318746
2022-12-28 05:09: Train Epoch 2: 56/159 Loss: 0.260149
2022-12-28 05:11: Train Epoch 2: 57/159 Loss: 0.346158
2022-12-28 05:12: Train Epoch 2: 58/159 Loss: 0.304336
2022-12-28 05:13: Train Epoch 2: 59/159 Loss: 0.256439
2022-12-28 05:15: Train Epoch 2: 60/159 Loss: 0.273400
2022-12-28 05:16: Train Epoch 2: 61/159 Loss: 0.322935
2022-12-28 05:17: Train Epoch 2: 62/159 Loss: 0.313090
2022-12-28 05:19: Train Epoch 2: 63/159 Loss: 0.219366
2022-12-28 05:20: Train Epoch 2: 64/159 Loss: 0.312274
2022-12-28 05:21: Train Epoch 2: 65/159 Loss: 0.304896
2022-12-28 05:23: Train Epoch 2: 66/159 Loss: 0.273743
2022-12-28 05:24: Train Epoch 2: 67/159 Loss: 0.272320
2022-12-28 05:25: Train Epoch 2: 68/159 Loss: 0.230390
2022-12-28 05:27: Train Epoch 2: 69/159 Loss: 0.318813
2022-12-28 05:28: Train Epoch 2: 70/159 Loss: 0.317888
2022-12-28 05:29: Train Epoch 2: 71/159 Loss: 0.316744
2022-12-28 05:31: Train Epoch 2: 72/159 Loss: 0.278149
2022-12-28 05:32: Train Epoch 2: 73/159 Loss: 0.255190
2022-12-28 05:33: Train Epoch 2: 74/159 Loss: 0.369229
2022-12-28 05:35: Train Epoch 2: 75/159 Loss: 0.274694
2022-12-28 05:36: Train Epoch 2: 76/159 Loss: 0.348129
2022-12-28 05:37: Train Epoch 2: 77/159 Loss: 0.289509
2022-12-28 05:39: Train Epoch 2: 78/159 Loss: 0.263324
2022-12-28 05:40: Train Epoch 2: 79/159 Loss: 0.277303
2022-12-28 05:41: Train Epoch 2: 80/159 Loss: 0.328851
2022-12-28 05:43: Train Epoch 2: 81/159 Loss: 0.275754
2022-12-28 05:44: Train Epoch 2: 82/159 Loss: 0.255691
2022-12-28 05:45: Train Epoch 2: 83/159 Loss: 0.263304
2022-12-28 05:47: Train Epoch 2: 84/159 Loss: 0.258265
2022-12-28 05:48: Train Epoch 2: 85/159 Loss: 0.270104
2022-12-28 05:49: Train Epoch 2: 86/159 Loss: 0.265953
2022-12-28 05:51: Train Epoch 2: 87/159 Loss: 0.262217
2022-12-28 05:52: Train Epoch 2: 88/159 Loss: 0.297965
2022-12-28 05:53: Train Epoch 2: 89/159 Loss: 0.259213
2022-12-28 05:55: Train Epoch 2: 90/159 Loss: 0.328636
2022-12-28 05:56: Train Epoch 2: 91/159 Loss: 0.255253
2022-12-28 05:57: Train Epoch 2: 92/159 Loss: 0.237580
2022-12-28 05:59: Train Epoch 2: 93/159 Loss: 0.305407
2022-12-28 06:00: Train Epoch 2: 94/159 Loss: 0.258773
2022-12-28 06:01: Train Epoch 2: 95/159 Loss: 0.318410
2022-12-28 06:03: Train Epoch 2: 96/159 Loss: 0.242226
2022-12-28 06:04: Train Epoch 2: 97/159 Loss: 0.221541
2022-12-28 06:05: Train Epoch 2: 98/159 Loss: 0.311531
2022-12-28 06:07: Train Epoch 2: 99/159 Loss: 0.238219
2022-12-28 06:08: Train Epoch 2: 100/159 Loss: 0.310451
2022-12-28 06:09: Train Epoch 2: 101/159 Loss: 0.290089
2022-12-28 06:11: Train Epoch 2: 102/159 Loss: 0.223652
2022-12-28 06:12: Train Epoch 2: 103/159 Loss: 0.364960
2022-12-28 06:13: Train Epoch 2: 104/159 Loss: 0.245694
2022-12-28 06:15: Train Epoch 2: 105/159 Loss: 0.298004
2022-12-28 06:16: Train Epoch 2: 106/159 Loss: 0.283654
2022-12-28 06:17: Train Epoch 2: 107/159 Loss: 0.294540
2022-12-28 06:19: Train Epoch 2: 108/159 Loss: 0.219545
2022-12-28 06:20: Train Epoch 2: 109/159 Loss: 0.261123
2022-12-28 06:21: Train Epoch 2: 110/159 Loss: 0.229651
2022-12-28 06:23: Train Epoch 2: 111/159 Loss: 0.262852
2022-12-28 06:24: Train Epoch 2: 112/159 Loss: 0.265426
2022-12-28 06:25: Train Epoch 2: 113/159 Loss: 0.254498
2022-12-28 06:27: Train Epoch 2: 114/159 Loss: 0.272826
2022-12-28 06:28: Train Epoch 2: 115/159 Loss: 0.247666
2022-12-28 06:29: Train Epoch 2: 116/159 Loss: 0.313428
2022-12-28 06:31: Train Epoch 2: 117/159 Loss: 0.189555
2022-12-28 06:32: Train Epoch 2: 118/159 Loss: 0.247931
2022-12-28 06:33: Train Epoch 2: 119/159 Loss: 0.335055
2022-12-28 06:35: Train Epoch 2: 120/159 Loss: 0.278955
2022-12-28 06:36: Train Epoch 2: 121/159 Loss: 0.237947
2022-12-28 06:37: Train Epoch 2: 122/159 Loss: 0.337784
2022-12-28 06:38: Train Epoch 2: 123/159 Loss: 0.386974
2022-12-28 06:40: Train Epoch 2: 124/159 Loss: 0.267189
2022-12-28 06:41: Train Epoch 2: 125/159 Loss: 0.333241
2022-12-28 06:42: Train Epoch 2: 126/159 Loss: 0.259189
2022-12-28 06:44: Train Epoch 2: 127/159 Loss: 0.254693
2022-12-28 06:45: Train Epoch 2: 128/159 Loss: 0.305660
2022-12-28 06:46: Train Epoch 2: 129/159 Loss: 0.296243
2022-12-28 06:48: Train Epoch 2: 130/159 Loss: 0.249371
2022-12-28 06:49: Train Epoch 2: 131/159 Loss: 0.278873
2022-12-28 06:50: Train Epoch 2: 132/159 Loss: 0.278155
2022-12-28 06:52: Train Epoch 2: 133/159 Loss: 0.246025
2022-12-28 06:53: Train Epoch 2: 134/159 Loss: 0.244805
2022-12-28 06:54: Train Epoch 2: 135/159 Loss: 0.339661
2022-12-28 06:56: Train Epoch 2: 136/159 Loss: 0.256634
2022-12-28 06:57: Train Epoch 2: 137/159 Loss: 0.302367
2022-12-28 06:58: Train Epoch 2: 138/159 Loss: 0.310504
2022-12-28 07:00: Train Epoch 2: 139/159 Loss: 0.308223
2022-12-28 07:01: Train Epoch 2: 140/159 Loss: 0.233619
2022-12-28 07:02: Train Epoch 2: 141/159 Loss: 0.274733
2022-12-28 07:04: Train Epoch 2: 142/159 Loss: 0.249890
2022-12-28 07:05: Train Epoch 2: 143/159 Loss: 0.261340
2022-12-28 07:06: Train Epoch 2: 144/159 Loss: 0.199110
2022-12-28 07:08: Train Epoch 2: 145/159 Loss: 0.300656
2022-12-28 07:09: Train Epoch 2: 146/159 Loss: 0.340876
2022-12-28 07:10: Train Epoch 2: 147/159 Loss: 0.226044
2022-12-28 07:12: Train Epoch 2: 148/159 Loss: 0.268362
2022-12-28 07:13: Train Epoch 2: 149/159 Loss: 0.341767
2022-12-28 07:14: Train Epoch 2: 150/159 Loss: 0.293058
2022-12-28 07:16: Train Epoch 2: 151/159 Loss: 0.306799
2022-12-28 07:17: Train Epoch 2: 152/159 Loss: 0.231500
2022-12-28 07:18: Train Epoch 2: 153/159 Loss: 0.280497
2022-12-28 07:20: Train Epoch 2: 154/159 Loss: 0.233591
2022-12-28 07:21: Train Epoch 2: 155/159 Loss: 0.320284
2022-12-28 07:22: Train Epoch 2: 156/159 Loss: 0.276482
2022-12-28 07:24: Train Epoch 2: 157/159 Loss: 0.194540
2022-12-28 07:24: Train Epoch 2: 158/159 Loss: 0.249225
2022-12-28 07:24: **********Train Epoch 2: averaged Loss: 0.281921 
2022-12-28 07:24: 
Epoch time elapsed: 12710.505223274231

2022-12-28 07:30: 
 metrics validation: {'precision': 0.7316636851520573, 'recall': 0.6292307692307693, 'f1-score': 0.6765922249793217, 'support': 1300, 'AUC': 0.8563849112426036, 'AUCPR': 0.7690861094553303, 'TP': 818, 'FP': 300, 'TN': 2300, 'FN': 482} 

2022-12-28 07:30: **********Val Epoch 2: average Loss: 0.479962
2022-12-28 07:35: 
 Testing metrics {'precision': 0.7785171102661597, 'recall': 0.6669381107491856, 'f1-score': 0.718421052631579, 'support': 1228, 'AUC': 0.8708487623210857, 'AUCPR': 0.7856498000673995, 'TP': 819, 'FP': 233, 'TN': 2223, 'FN': 409} 

2022-12-28 07:36: Train Epoch 3: 0/159 Loss: 0.286843
2022-12-28 07:38: Train Epoch 3: 1/159 Loss: 0.328713
2022-12-28 07:39: Train Epoch 3: 2/159 Loss: 0.227343
2022-12-28 07:40: Train Epoch 3: 3/159 Loss: 0.351073
2022-12-28 07:42: Train Epoch 3: 4/159 Loss: 0.295364
2022-12-28 07:43: Train Epoch 3: 5/159 Loss: 0.327969
2022-12-28 07:44: Train Epoch 3: 6/159 Loss: 0.278262
2022-12-28 07:46: Train Epoch 3: 7/159 Loss: 0.258683
2022-12-28 07:47: Train Epoch 3: 8/159 Loss: 0.258283
2022-12-28 07:48: Train Epoch 3: 9/159 Loss: 0.284576
2022-12-28 07:50: Train Epoch 3: 10/159 Loss: 0.254336
2022-12-28 07:51: Train Epoch 3: 11/159 Loss: 0.341451
2022-12-28 07:53: Train Epoch 3: 12/159 Loss: 0.295140
2022-12-28 07:54: Train Epoch 3: 13/159 Loss: 0.311677
2022-12-28 07:55: Train Epoch 3: 14/159 Loss: 0.305075
2022-12-28 07:57: Train Epoch 3: 15/159 Loss: 0.278684
2022-12-28 07:58: Train Epoch 3: 16/159 Loss: 0.231570
2022-12-28 07:59: Train Epoch 3: 17/159 Loss: 0.280809
2022-12-28 08:01: Train Epoch 3: 18/159 Loss: 0.343485
2022-12-28 08:02: Train Epoch 3: 19/159 Loss: 0.250951
2022-12-28 08:03: Train Epoch 3: 20/159 Loss: 0.326207
2022-12-28 08:05: Train Epoch 3: 21/159 Loss: 0.343702
2022-12-28 08:06: Train Epoch 3: 22/159 Loss: 0.291220
2022-12-28 08:07: Train Epoch 3: 23/159 Loss: 0.287266
2022-12-28 08:09: Train Epoch 3: 24/159 Loss: 0.399183
2022-12-28 08:10: Train Epoch 3: 25/159 Loss: 0.247347
2022-12-28 08:12: Train Epoch 3: 26/159 Loss: 0.301411
2022-12-28 08:13: Train Epoch 3: 27/159 Loss: 0.338633
2022-12-28 08:14: Train Epoch 3: 28/159 Loss: 0.309191
2022-12-28 08:16: Train Epoch 3: 29/159 Loss: 0.316180
2022-12-28 08:17: Train Epoch 3: 30/159 Loss: 0.302333
2022-12-28 08:18: Train Epoch 3: 31/159 Loss: 0.212339
2022-12-28 08:20: Train Epoch 3: 32/159 Loss: 0.335184
2022-12-28 08:21: Train Epoch 3: 33/159 Loss: 0.318193
2022-12-28 08:22: Train Epoch 3: 34/159 Loss: 0.350993
2022-12-28 08:24: Train Epoch 3: 35/159 Loss: 0.291684
2022-12-28 08:25: Train Epoch 3: 36/159 Loss: 0.298827
2022-12-28 08:26: Train Epoch 3: 37/159 Loss: 0.316635
2022-12-28 08:28: Train Epoch 3: 38/159 Loss: 0.273407
2022-12-28 08:29: Train Epoch 3: 39/159 Loss: 0.321558
2022-12-28 08:31: Train Epoch 3: 40/159 Loss: 0.270377
2022-12-28 08:32: Train Epoch 3: 41/159 Loss: 0.305250
2022-12-28 08:33: Train Epoch 3: 42/159 Loss: 0.333923
2022-12-28 08:35: Train Epoch 3: 43/159 Loss: 0.297110
2022-12-28 08:36: Train Epoch 3: 44/159 Loss: 0.266937
2022-12-28 08:37: Train Epoch 3: 45/159 Loss: 0.268876
2022-12-28 08:39: Train Epoch 3: 46/159 Loss: 0.272034
2022-12-28 08:40: Train Epoch 3: 47/159 Loss: 0.272181
2022-12-28 08:41: Train Epoch 3: 48/159 Loss: 0.307960
2022-12-28 08:43: Train Epoch 3: 49/159 Loss: 0.345603
2022-12-28 08:44: Train Epoch 3: 50/159 Loss: 0.272933
2022-12-28 08:45: Train Epoch 3: 51/159 Loss: 0.286999
2022-12-28 08:47: Train Epoch 3: 52/159 Loss: 0.315276
2022-12-28 08:48: Train Epoch 3: 53/159 Loss: 0.295021
2022-12-28 08:49: Train Epoch 3: 54/159 Loss: 0.238648
2022-12-28 08:51: Train Epoch 3: 55/159 Loss: 0.283715
2022-12-28 08:52: Train Epoch 3: 56/159 Loss: 0.301363
2022-12-28 08:53: Train Epoch 3: 57/159 Loss: 0.302708
2022-12-28 08:54: Train Epoch 3: 58/159 Loss: 0.253522
2022-12-28 08:56: Train Epoch 3: 59/159 Loss: 0.286986
2022-12-28 08:57: Train Epoch 3: 60/159 Loss: 0.306463
2022-12-28 08:58: Train Epoch 3: 61/159 Loss: 0.232492
2022-12-28 09:00: Train Epoch 3: 62/159 Loss: 0.337853
2022-12-28 09:01: Train Epoch 3: 63/159 Loss: 0.326112
2022-12-28 09:02: Train Epoch 3: 64/159 Loss: 0.224460
2022-12-28 09:04: Train Epoch 3: 65/159 Loss: 0.337677
2022-12-28 09:05: Train Epoch 3: 66/159 Loss: 0.262007
2022-12-28 09:06: Train Epoch 3: 67/159 Loss: 0.296412
2022-12-28 09:08: Train Epoch 3: 68/159 Loss: 0.257976
2022-12-28 09:09: Train Epoch 3: 69/159 Loss: 0.255067
2022-12-28 09:10: Train Epoch 3: 70/159 Loss: 0.303721
2022-12-28 09:12: Train Epoch 3: 71/159 Loss: 0.319346
2022-12-28 09:13: Train Epoch 3: 72/159 Loss: 0.245352
2022-12-28 09:14: Train Epoch 3: 73/159 Loss: 0.285092
2022-12-28 09:16: Train Epoch 3: 74/159 Loss: 0.371166
2022-12-28 09:17: Train Epoch 3: 75/159 Loss: 0.264360
2022-12-28 09:18: Train Epoch 3: 76/159 Loss: 0.289138
2022-12-28 09:20: Train Epoch 3: 77/159 Loss: 0.276854
2022-12-28 09:21: Train Epoch 3: 78/159 Loss: 0.270800
2022-12-28 09:22: Train Epoch 3: 79/159 Loss: 0.269356
2022-12-28 09:24: Train Epoch 3: 80/159 Loss: 0.323252
2022-12-28 09:25: Train Epoch 3: 81/159 Loss: 0.317718
2022-12-28 09:26: Train Epoch 3: 82/159 Loss: 0.236470
2022-12-28 09:28: Train Epoch 3: 83/159 Loss: 0.270030
2022-12-28 09:29: Train Epoch 3: 84/159 Loss: 0.234071
2022-12-28 09:30: Train Epoch 3: 85/159 Loss: 0.234085
2022-12-28 09:32: Train Epoch 3: 86/159 Loss: 0.315676
2022-12-28 09:33: Train Epoch 3: 87/159 Loss: 0.252588
2022-12-28 09:34: Train Epoch 3: 88/159 Loss: 0.238114
2022-12-28 09:36: Train Epoch 3: 89/159 Loss: 0.239130
2022-12-28 09:37: Train Epoch 3: 90/159 Loss: 0.310327
2022-12-28 09:38: Train Epoch 3: 91/159 Loss: 0.268016
2022-12-28 09:40: Train Epoch 3: 92/159 Loss: 0.259275
2022-12-28 09:41: Train Epoch 3: 93/159 Loss: 0.291539
2022-12-28 09:42: Train Epoch 3: 94/159 Loss: 0.306104
2022-12-28 09:44: Train Epoch 3: 95/159 Loss: 0.256291
2022-12-28 09:45: Train Epoch 3: 96/159 Loss: 0.299125
2022-12-28 09:46: Train Epoch 3: 97/159 Loss: 0.317945
2022-12-28 09:48: Train Epoch 3: 98/159 Loss: 0.300041
2022-12-28 09:49: Train Epoch 3: 99/159 Loss: 0.278616
2022-12-28 09:50: Train Epoch 3: 100/159 Loss: 0.343816
2022-12-28 09:52: Train Epoch 3: 101/159 Loss: 0.352536
2022-12-28 09:53: Train Epoch 3: 102/159 Loss: 0.187524
2022-12-28 09:54: Train Epoch 3: 103/159 Loss: 0.282090
2022-12-28 09:56: Train Epoch 3: 104/159 Loss: 0.229986
2022-12-28 09:57: Train Epoch 3: 105/159 Loss: 0.308594
2022-12-28 09:58: Train Epoch 3: 106/159 Loss: 0.264155
2022-12-28 10:00: Train Epoch 3: 107/159 Loss: 0.302596
2022-12-28 10:01: Train Epoch 3: 108/159 Loss: 0.306693
2022-12-28 10:02: Train Epoch 3: 109/159 Loss: 0.322402
2022-12-28 10:04: Train Epoch 3: 110/159 Loss: 0.294623
2022-12-28 10:05: Train Epoch 3: 111/159 Loss: 0.306088
2022-12-28 10:06: Train Epoch 3: 112/159 Loss: 0.249835
2022-12-28 10:08: Train Epoch 3: 113/159 Loss: 0.229450
2022-12-28 10:09: Train Epoch 3: 114/159 Loss: 0.278461
2022-12-28 10:10: Train Epoch 3: 115/159 Loss: 0.261488
2022-12-28 10:11: Train Epoch 3: 116/159 Loss: 0.259525
2022-12-28 10:13: Train Epoch 3: 117/159 Loss: 0.301445
2022-12-28 10:14: Train Epoch 3: 118/159 Loss: 0.284615
2022-12-28 10:15: Train Epoch 3: 119/159 Loss: 0.289384
2022-12-28 10:17: Train Epoch 3: 120/159 Loss: 0.346166
2022-12-28 10:18: Train Epoch 3: 121/159 Loss: 0.251959
2022-12-28 10:19: Train Epoch 3: 122/159 Loss: 0.265615
2022-12-28 10:21: Train Epoch 3: 123/159 Loss: 0.251649
2022-12-28 10:22: Train Epoch 3: 124/159 Loss: 0.291356
2022-12-28 10:24: Train Epoch 3: 125/159 Loss: 0.268425
2022-12-28 10:25: Train Epoch 3: 126/159 Loss: 0.304742
2022-12-28 10:26: Train Epoch 3: 127/159 Loss: 0.301472
2022-12-28 10:28: Train Epoch 3: 128/159 Loss: 0.337990
2022-12-28 10:29: Train Epoch 3: 129/159 Loss: 0.258265
2022-12-28 10:30: Train Epoch 3: 130/159 Loss: 0.291567
2022-12-28 10:32: Train Epoch 3: 131/159 Loss: 0.232171
2022-12-28 10:33: Train Epoch 3: 132/159 Loss: 0.258146
2022-12-28 10:34: Train Epoch 3: 133/159 Loss: 0.301178
2022-12-28 10:36: Train Epoch 3: 134/159 Loss: 0.281298
2022-12-28 10:37: Train Epoch 3: 135/159 Loss: 0.337302
2022-12-28 10:38: Train Epoch 3: 136/159 Loss: 0.304075
2022-12-28 10:40: Train Epoch 3: 137/159 Loss: 0.255526
2022-12-28 10:41: Train Epoch 3: 138/159 Loss: 0.419840
2022-12-28 10:42: Train Epoch 3: 139/159 Loss: 0.222931
2022-12-28 10:44: Train Epoch 3: 140/159 Loss: 0.345214
2022-12-28 10:45: Train Epoch 3: 141/159 Loss: 0.296381
2022-12-28 10:46: Train Epoch 3: 142/159 Loss: 0.228301
2022-12-28 10:48: Train Epoch 3: 143/159 Loss: 0.291579
2022-12-28 10:49: Train Epoch 3: 144/159 Loss: 0.294894
2022-12-28 10:50: Train Epoch 3: 145/159 Loss: 0.269608
2022-12-28 10:52: Train Epoch 3: 146/159 Loss: 0.306086
2022-12-28 10:53: Train Epoch 3: 147/159 Loss: 0.250512
2022-12-28 10:54: Train Epoch 3: 148/159 Loss: 0.266604
2022-12-28 10:56: Train Epoch 3: 149/159 Loss: 0.233638
2022-12-28 10:57: Train Epoch 3: 150/159 Loss: 0.295410
2022-12-28 10:58: Train Epoch 3: 151/159 Loss: 0.287280
2022-12-28 11:00: Train Epoch 3: 152/159 Loss: 0.290522
2022-12-28 11:01: Train Epoch 3: 153/159 Loss: 0.259323
2022-12-28 11:02: Train Epoch 3: 154/159 Loss: 0.275504
2022-12-28 11:04: Train Epoch 3: 155/159 Loss: 0.304235
2022-12-28 11:05: Train Epoch 3: 156/159 Loss: 0.230865
2022-12-28 11:06: Train Epoch 3: 157/159 Loss: 0.247270
2022-12-28 11:07: Train Epoch 3: 158/159 Loss: 0.246899
2022-12-28 11:07: **********Train Epoch 3: averaged Loss: 0.287336 
2022-12-28 11:07: 
Epoch time elapsed: 12708.079890012741

2022-12-28 11:12: 
 metrics validation: {'precision': 0.7151114781172585, 'recall': 0.6661538461538462, 'f1-score': 0.6897650338510555, 'support': 1300, 'AUC': 0.854503550295858, 'AUCPR': 0.7674104850029687, 'TP': 866, 'FP': 345, 'TN': 2255, 'FN': 434} 

2022-12-28 11:12: **********Val Epoch 3: average Loss: 0.484997
2022-12-28 11:18: 
 Testing metrics {'precision': 0.7785171102661597, 'recall': 0.6669381107491856, 'f1-score': 0.718421052631579, 'support': 1228, 'AUC': 0.8708487623210857, 'AUCPR': 0.7856498000673995, 'TP': 819, 'FP': 233, 'TN': 2223, 'FN': 409} 

2022-12-28 11:19: Train Epoch 4: 0/159 Loss: 0.267523
2022-12-28 11:21: Train Epoch 4: 1/159 Loss: 0.216665
2022-12-28 11:22: Train Epoch 4: 2/159 Loss: 0.314144
2022-12-28 11:24: Train Epoch 4: 3/159 Loss: 0.265918
2022-12-28 11:25: Train Epoch 4: 4/159 Loss: 0.266554
2022-12-28 11:26: Train Epoch 4: 5/159 Loss: 0.243271
2022-12-28 11:27: Train Epoch 4: 6/159 Loss: 0.291280
2022-12-28 11:29: Train Epoch 4: 7/159 Loss: 0.368210
2022-12-28 11:30: Train Epoch 4: 8/159 Loss: 0.228442
2022-12-28 11:31: Train Epoch 4: 9/159 Loss: 0.335958
2022-12-28 11:33: Train Epoch 4: 10/159 Loss: 0.309875
2022-12-28 11:34: Train Epoch 4: 11/159 Loss: 0.391007
2022-12-28 11:35: Train Epoch 4: 12/159 Loss: 0.301218
2022-12-28 11:37: Train Epoch 4: 13/159 Loss: 0.316490
2022-12-28 11:38: Train Epoch 4: 14/159 Loss: 0.289606
2022-12-28 11:40: Train Epoch 4: 15/159 Loss: 0.244133
2022-12-28 11:41: Train Epoch 4: 16/159 Loss: 0.340752
2022-12-28 11:42: Train Epoch 4: 17/159 Loss: 0.317750
2022-12-28 11:44: Train Epoch 4: 18/159 Loss: 0.286627
2022-12-28 11:45: Train Epoch 4: 19/159 Loss: 0.350643
2022-12-28 11:46: Train Epoch 4: 20/159 Loss: 0.293317
2022-12-28 11:48: Train Epoch 4: 21/159 Loss: 0.284378
2022-12-28 11:49: Train Epoch 4: 22/159 Loss: 0.388162
2022-12-28 11:50: Train Epoch 4: 23/159 Loss: 0.274073
2022-12-28 11:52: Train Epoch 4: 24/159 Loss: 0.307927
2022-12-28 11:53: Train Epoch 4: 25/159 Loss: 0.243169
2022-12-28 11:54: Train Epoch 4: 26/159 Loss: 0.260173
2022-12-28 11:56: Train Epoch 4: 27/159 Loss: 0.275752
2022-12-28 11:57: Train Epoch 4: 28/159 Loss: 0.300115
2022-12-28 11:58: Train Epoch 4: 29/159 Loss: 0.321397
2022-12-28 12:00: Train Epoch 4: 30/159 Loss: 0.251768
2022-12-28 12:01: Train Epoch 4: 31/159 Loss: 0.310751
2022-12-28 12:02: Train Epoch 4: 32/159 Loss: 0.256171
2022-12-28 12:04: Train Epoch 4: 33/159 Loss: 0.277999
2022-12-28 12:05: Train Epoch 4: 34/159 Loss: 0.309391
2022-12-28 12:06: Train Epoch 4: 35/159 Loss: 0.323574
2022-12-28 12:08: Train Epoch 4: 36/159 Loss: 0.299467
2022-12-28 12:09: Train Epoch 4: 37/159 Loss: 0.271645
2022-12-28 12:10: Train Epoch 4: 38/159 Loss: 0.318569
2022-12-28 12:12: Train Epoch 4: 39/159 Loss: 0.301421
2022-12-28 12:13: Train Epoch 4: 40/159 Loss: 0.363279
