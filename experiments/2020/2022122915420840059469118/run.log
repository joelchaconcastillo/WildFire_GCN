2022-12-29 15:42: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122915420840059469118
2022-12-29 15:42: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122915420840059469118
2022-12-29 15:42: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=128, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122915420840059469118', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0005, max_grad_norm=5, minbatch_size=256, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-29 15:42: Argument batch_size: 256
2022-12-29 15:42: Argument clc: 'vec'
2022-12-29 15:42: Argument cuda: True
2022-12-29 15:42: Argument dataset: '2020'
2022-12-29 15:42: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-29 15:42: Argument debug: False
2022-12-29 15:42: Argument default_graph: True
2022-12-29 15:42: Argument device: 'cpu'
2022-12-29 15:42: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-29 15:42: Argument early_stop: True
2022-12-29 15:42: Argument early_stop_patience: 8
2022-12-29 15:42: Argument embed_dim: 128
2022-12-29 15:42: Argument epochs: 30
2022-12-29 15:42: Argument grad_norm: False
2022-12-29 15:42: Argument horizon: 1
2022-12-29 15:42: Argument input_dim: 25
2022-12-29 15:42: Argument lag: 10
2022-12-29 15:42: Argument link_len: 2
2022-12-29 15:42: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122915420840059469118'
2022-12-29 15:42: Argument log_step: 1
2022-12-29 15:42: Argument loss_func: 'nllloss'
2022-12-29 15:42: Argument lr_decay: True
2022-12-29 15:42: Argument lr_decay_rate: 0.1
2022-12-29 15:42: Argument lr_decay_step: '15, 20'
2022-12-29 15:42: Argument lr_init: 0.0005
2022-12-29 15:42: Argument max_grad_norm: 5
2022-12-29 15:42: Argument minbatch_size: 256
2022-12-29 15:42: Argument mode: 'train'
2022-12-29 15:42: Argument model: 'fire_GCN'
2022-12-29 15:42: Argument nan_fill: 0.5
2022-12-29 15:42: Argument num_layers: 1
2022-12-29 15:42: Argument num_nodes: 625
2022-12-29 15:42: Argument num_workers: 20
2022-12-29 15:42: Argument output_dim: 2
2022-12-29 15:42: Argument patch_height: 25
2022-12-29 15:42: Argument patch_width: 25
2022-12-29 15:42: Argument persistent_workers: True
2022-12-29 15:42: Argument pin_memory: True
2022-12-29 15:42: Argument plot: False
2022-12-29 15:42: Argument positive_weight: 0.5
2022-12-29 15:42: Argument prefetch_factor: 2
2022-12-29 15:42: Argument real_value: True
2022-12-29 15:42: Argument rnn_units: 16
2022-12-29 15:42: Argument seed: 10000
2022-12-29 15:42: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-29 15:42: Argument teacher_forcing: False
2022-12-29 15:42: Argument weight_decay: 0.0
2022-12-29 15:42: Argument window_len: 10
2022-12-29 15:42: Train Epoch 1: 0/61 Loss: 1.374444
2022-12-29 15:42: Train Epoch 1: 1/61 Loss: 0.506093
2022-12-29 15:42: Train Epoch 1: 2/61 Loss: 0.541934
2022-12-29 15:42: Train Epoch 1: 3/61 Loss: 0.445890
2022-12-29 15:42: Train Epoch 1: 4/61 Loss: 0.445355
2022-12-29 15:43: Train Epoch 1: 5/61 Loss: 0.501949
2022-12-29 15:43: Train Epoch 1: 6/61 Loss: 0.456958
2022-12-29 15:43: Train Epoch 1: 7/61 Loss: 0.426534
2022-12-29 15:43: Train Epoch 1: 8/61 Loss: 0.409192
2022-12-29 15:43: Train Epoch 1: 9/61 Loss: 0.425212
2022-12-29 15:43: Train Epoch 1: 10/61 Loss: 0.433179
2022-12-29 15:43: Train Epoch 1: 11/61 Loss: 0.393670
2022-12-29 15:44: Train Epoch 1: 12/61 Loss: 0.389930
2022-12-29 15:44: Train Epoch 1: 13/61 Loss: 0.369758
2022-12-29 15:44: Train Epoch 1: 14/61 Loss: 0.346878
2022-12-29 15:44: Train Epoch 1: 15/61 Loss: 0.351708
2022-12-29 15:44: Train Epoch 1: 16/61 Loss: 0.342548
2022-12-29 15:44: Train Epoch 1: 17/61 Loss: 0.362406
2022-12-29 15:45: Train Epoch 1: 18/61 Loss: 0.346183
2022-12-29 15:45: Train Epoch 1: 19/61 Loss: 0.351254
2022-12-29 15:45: Train Epoch 1: 20/61 Loss: 0.340455
2022-12-29 15:45: Train Epoch 1: 21/61 Loss: 0.336903
2022-12-29 15:45: Train Epoch 1: 22/61 Loss: 0.370898
2022-12-29 15:45: Train Epoch 1: 23/61 Loss: 0.331997
2022-12-29 15:45: Train Epoch 1: 24/61 Loss: 0.329403
2022-12-29 15:45: Train Epoch 1: 25/61 Loss: 0.340777
2022-12-29 15:46: Train Epoch 1: 26/61 Loss: 0.331949
2022-12-29 15:46: Train Epoch 1: 27/61 Loss: 0.342928
2022-12-29 15:46: Train Epoch 1: 28/61 Loss: 0.339084
2022-12-29 15:46: Train Epoch 1: 29/61 Loss: 0.345264
2022-12-29 15:46: Train Epoch 1: 30/61 Loss: 0.323659
2022-12-29 15:46: Train Epoch 1: 31/61 Loss: 0.319684
2022-12-29 15:46: Train Epoch 1: 32/61 Loss: 0.321155
2022-12-29 15:47: Train Epoch 1: 33/61 Loss: 0.317793
2022-12-29 15:47: Train Epoch 1: 34/61 Loss: 0.325462
2022-12-29 15:47: Train Epoch 1: 35/61 Loss: 0.308600
2022-12-29 15:47: Train Epoch 1: 36/61 Loss: 0.316294
2022-12-29 15:47: Train Epoch 1: 37/61 Loss: 0.312657
2022-12-29 15:47: Train Epoch 1: 38/61 Loss: 0.318171
2022-12-29 15:47: Train Epoch 1: 39/61 Loss: 0.290798
2022-12-29 15:47: Train Epoch 1: 40/61 Loss: 0.278552
2022-12-29 15:48: Train Epoch 1: 41/61 Loss: 0.301682
2022-12-29 15:48: Train Epoch 1: 42/61 Loss: 0.305998
2022-12-29 15:48: Train Epoch 1: 43/61 Loss: 0.326485
2022-12-29 15:48: Train Epoch 1: 44/61 Loss: 0.268627
2022-12-29 15:48: Train Epoch 1: 45/61 Loss: 0.299572
2022-12-29 15:48: Train Epoch 1: 46/61 Loss: 0.291402
2022-12-29 15:48: Train Epoch 1: 47/61 Loss: 0.286130
2022-12-29 15:49: Train Epoch 1: 48/61 Loss: 0.300742
2022-12-29 15:49: Train Epoch 1: 49/61 Loss: 0.322601
2022-12-29 15:49: Train Epoch 1: 50/61 Loss: 0.314106
2022-12-29 15:49: Train Epoch 1: 51/61 Loss: 0.270309
2022-12-29 15:49: Train Epoch 1: 52/61 Loss: 0.277373
2022-12-29 15:49: Train Epoch 1: 53/61 Loss: 0.263373
2022-12-29 15:49: Train Epoch 1: 54/61 Loss: 0.278140
2022-12-29 15:49: Train Epoch 1: 55/61 Loss: 0.248127
2022-12-29 15:50: Train Epoch 1: 56/61 Loss: 0.253451
2022-12-29 15:50: Train Epoch 1: 57/61 Loss: 0.252193
2022-12-29 15:50: Train Epoch 1: 58/61 Loss: 0.255608
2022-12-29 15:50: Train Epoch 1: 59/61 Loss: 0.284524
2022-12-29 15:50: Train Epoch 1: 60/61 Loss: 0.219083
2022-12-29 15:50: **********Train Epoch 1: averaged Loss: 0.355460 
2022-12-29 15:50: 
Epoch time elapsed: 514.5795955657959

2022-12-29 15:51: 
 metrics validation: {'precision': 0.6828193832599119, 'recall': 0.3576923076923077, 'f1-score': 0.469459868753155, 'support': 1300, 'AUC': 0.7716204142011834, 'AUCPR': 0.6383223205403296, 'TP': 465, 'FP': 216, 'TN': 2384, 'FN': 835} 

2022-12-29 15:51: **********Val Epoch 1: average Loss: 0.252539
2022-12-29 15:51: *********************************Current best model saved!
2022-12-29 15:51: 
 Testing metrics {'precision': 0.7974828375286042, 'recall': 0.5675895765472313, 'f1-score': 0.6631779257849667, 'support': 1228, 'AUC': 0.8489272764167258, 'AUCPR': 0.7444598981778607, 'TP': 697, 'FP': 177, 'TN': 2279, 'FN': 531} 

2022-12-29 15:51: Train Epoch 2: 0/61 Loss: 0.251116
2022-12-29 15:52: Train Epoch 2: 1/61 Loss: 0.241008
2022-12-29 15:52: Train Epoch 2: 2/61 Loss: 0.233916
2022-12-29 15:52: Train Epoch 2: 3/61 Loss: 0.246215
2022-12-29 15:52: Train Epoch 2: 4/61 Loss: 0.225176
2022-12-29 15:52: Train Epoch 2: 5/61 Loss: 0.240702
2022-12-29 15:52: Train Epoch 2: 6/61 Loss: 0.244117
2022-12-29 15:52: Train Epoch 2: 7/61 Loss: 0.238025
2022-12-29 15:53: Train Epoch 2: 8/61 Loss: 0.239826
2022-12-29 15:53: Train Epoch 2: 9/61 Loss: 0.221454
2022-12-29 15:53: Train Epoch 2: 10/61 Loss: 0.236594
2022-12-29 15:53: Train Epoch 2: 11/61 Loss: 0.253961
2022-12-29 15:53: Train Epoch 2: 12/61 Loss: 0.236922
2022-12-29 15:53: Train Epoch 2: 13/61 Loss: 0.263033
2022-12-29 15:54: Train Epoch 2: 14/61 Loss: 0.208732
2022-12-29 15:54: Train Epoch 2: 15/61 Loss: 0.226099
2022-12-29 15:54: Train Epoch 2: 16/61 Loss: 0.227901
2022-12-29 15:54: Train Epoch 2: 17/61 Loss: 0.237100
2022-12-29 15:54: Train Epoch 2: 18/61 Loss: 0.252808
2022-12-29 15:54: Train Epoch 2: 19/61 Loss: 0.221948
2022-12-29 15:54: Train Epoch 2: 20/61 Loss: 0.253466
2022-12-29 15:54: Train Epoch 2: 21/61 Loss: 0.240188
2022-12-29 15:55: Train Epoch 2: 22/61 Loss: 0.214905
2022-12-29 15:55: Train Epoch 2: 23/61 Loss: 0.246822
2022-12-29 15:55: Train Epoch 2: 24/61 Loss: 0.270033
2022-12-29 15:55: Train Epoch 2: 25/61 Loss: 0.235388
2022-12-29 15:55: Train Epoch 2: 26/61 Loss: 0.230609
2022-12-29 15:55: Train Epoch 2: 27/61 Loss: 0.227752
2022-12-29 15:55: Train Epoch 2: 28/61 Loss: 0.267034
2022-12-29 15:56: Train Epoch 2: 29/61 Loss: 0.230889
2022-12-29 15:56: Train Epoch 2: 30/61 Loss: 0.222127
2022-12-29 15:56: Train Epoch 2: 31/61 Loss: 0.184527
2022-12-29 15:56: Train Epoch 2: 32/61 Loss: 0.204810
2022-12-29 15:56: Train Epoch 2: 33/61 Loss: 0.185568
2022-12-29 15:56: Train Epoch 2: 34/61 Loss: 0.193468
2022-12-29 15:56: Train Epoch 2: 35/61 Loss: 0.184989
2022-12-29 15:56: Train Epoch 2: 36/61 Loss: 0.171510
2022-12-29 15:57: Train Epoch 2: 37/61 Loss: 0.207038
2022-12-29 15:57: Train Epoch 2: 38/61 Loss: 0.245165
2022-12-29 15:57: Train Epoch 2: 39/61 Loss: 0.235519
2022-12-29 15:57: Train Epoch 2: 40/61 Loss: 0.243150
2022-12-29 15:57: Train Epoch 2: 41/61 Loss: 0.229746
2022-12-29 15:57: Train Epoch 2: 42/61 Loss: 0.216280
2022-12-29 15:57: Train Epoch 2: 43/61 Loss: 0.224043
2022-12-29 15:57: Train Epoch 2: 44/61 Loss: 0.221760
2022-12-29 15:58: Train Epoch 2: 45/61 Loss: 0.174983
2022-12-29 15:58: Train Epoch 2: 46/61 Loss: 0.225671
2022-12-29 15:58: Train Epoch 2: 47/61 Loss: 0.239184
2022-12-29 15:58: Train Epoch 2: 48/61 Loss: 0.212717
2022-12-29 15:58: Train Epoch 2: 49/61 Loss: 0.211039
2022-12-29 15:58: Train Epoch 2: 50/61 Loss: 0.257681
2022-12-29 15:58: Train Epoch 2: 51/61 Loss: 0.216591
2022-12-29 15:59: Train Epoch 2: 52/61 Loss: 0.239361
2022-12-29 15:59: Train Epoch 2: 53/61 Loss: 0.219782
2022-12-29 15:59: Train Epoch 2: 54/61 Loss: 0.229867
2022-12-29 15:59: Train Epoch 2: 55/61 Loss: 0.201387
2022-12-29 15:59: Train Epoch 2: 56/61 Loss: 0.178978
2022-12-29 15:59: Train Epoch 2: 57/61 Loss: 0.268816
2022-12-29 15:59: Train Epoch 2: 58/61 Loss: 0.221240
2022-12-29 15:59: Train Epoch 2: 59/61 Loss: 0.194778
2022-12-29 16:00: Train Epoch 2: 60/61 Loss: 0.171105
2022-12-29 16:00: **********Train Epoch 2: averaged Loss: 0.226174 
2022-12-29 16:00: 
Epoch time elapsed: 499.2576553821564

2022-12-29 16:00: 
 metrics validation: {'precision': 0.7383798140770252, 'recall': 0.4276923076923077, 'f1-score': 0.54164637116415, 'support': 1300, 'AUC': 0.7995532544378698, 'AUCPR': 0.674831613709736, 'TP': 556, 'FP': 197, 'TN': 2403, 'FN': 744} 

2022-12-29 16:00: **********Val Epoch 2: average Loss: 0.265794
2022-12-29 16:01: 
 Testing metrics {'precision': 0.7974828375286042, 'recall': 0.5675895765472313, 'f1-score': 0.6631779257849667, 'support': 1228, 'AUC': 0.8489272764167258, 'AUCPR': 0.7444598981778607, 'TP': 697, 'FP': 177, 'TN': 2279, 'FN': 531} 

2022-12-29 16:01: Train Epoch 3: 0/61 Loss: 0.227209
2022-12-29 16:01: Train Epoch 3: 1/61 Loss: 0.237707
2022-12-29 16:01: Train Epoch 3: 2/61 Loss: 0.263862
2022-12-29 16:01: Train Epoch 3: 3/61 Loss: 0.248548
2022-12-29 16:01: Train Epoch 3: 4/61 Loss: 0.233504
2022-12-29 16:02: Train Epoch 3: 5/61 Loss: 0.243691
2022-12-29 16:02: Train Epoch 3: 6/61 Loss: 0.218000
2022-12-29 16:02: Train Epoch 3: 7/61 Loss: 0.233060
2022-12-29 16:02: Train Epoch 3: 8/61 Loss: 0.248623
2022-12-29 16:02: Train Epoch 3: 9/61 Loss: 0.286908
2022-12-29 16:02: Train Epoch 3: 10/61 Loss: 0.218171
2022-12-29 16:02: Train Epoch 3: 11/61 Loss: 0.234420
2022-12-29 16:03: Train Epoch 3: 12/61 Loss: 0.214930
2022-12-29 16:03: Train Epoch 3: 13/61 Loss: 0.264475
2022-12-29 16:03: Train Epoch 3: 14/61 Loss: 0.243350
2022-12-29 16:03: Train Epoch 3: 15/61 Loss: 0.240515
2022-12-29 16:03: Train Epoch 3: 16/61 Loss: 0.232495
2022-12-29 16:03: Train Epoch 3: 17/61 Loss: 0.240172
2022-12-29 16:03: Train Epoch 3: 18/61 Loss: 0.262035
2022-12-29 16:04: Train Epoch 3: 19/61 Loss: 0.246089
2022-12-29 16:04: Train Epoch 3: 20/61 Loss: 0.216632
2022-12-29 16:04: Train Epoch 3: 21/61 Loss: 0.263300
2022-12-29 16:04: Train Epoch 3: 22/61 Loss: 0.262340
2022-12-29 16:04: Train Epoch 3: 23/61 Loss: 0.194758
2022-12-29 16:04: Train Epoch 3: 24/61 Loss: 0.218472
2022-12-29 16:04: Train Epoch 3: 25/61 Loss: 0.221182
2022-12-29 16:05: Train Epoch 3: 26/61 Loss: 0.204668
2022-12-29 16:05: Train Epoch 3: 27/61 Loss: 0.210536
2022-12-29 16:05: Train Epoch 3: 28/61 Loss: 0.213516
2022-12-29 16:05: Train Epoch 3: 29/61 Loss: 0.213210
2022-12-29 16:05: Train Epoch 3: 30/61 Loss: 0.205071
2022-12-29 16:05: Train Epoch 3: 31/61 Loss: 0.208423
2022-12-29 16:05: Train Epoch 3: 32/61 Loss: 0.195647
2022-12-29 16:05: Train Epoch 3: 33/61 Loss: 0.219937
2022-12-29 16:06: Train Epoch 3: 34/61 Loss: 0.189593
2022-12-29 16:06: Train Epoch 3: 35/61 Loss: 0.240734
2022-12-29 16:06: Train Epoch 3: 36/61 Loss: 0.204860
2022-12-29 16:06: Train Epoch 3: 37/61 Loss: 0.192949
2022-12-29 16:06: Train Epoch 3: 38/61 Loss: 0.233045
2022-12-29 16:06: Train Epoch 3: 39/61 Loss: 0.233307
2022-12-29 16:06: Train Epoch 3: 40/61 Loss: 0.222431
2022-12-29 16:07: Train Epoch 3: 41/61 Loss: 0.235567
2022-12-29 16:07: Train Epoch 3: 42/61 Loss: 0.226405
2022-12-29 16:07: Train Epoch 3: 43/61 Loss: 0.208351
2022-12-29 16:07: Train Epoch 3: 44/61 Loss: 0.190775
2022-12-29 16:07: Train Epoch 3: 45/61 Loss: 0.238297
2022-12-29 16:07: Train Epoch 3: 46/61 Loss: 0.202761
2022-12-29 16:07: Train Epoch 3: 47/61 Loss: 0.212810
2022-12-29 16:07: Train Epoch 3: 48/61 Loss: 0.188893
2022-12-29 16:07: Train Epoch 3: 49/61 Loss: 0.269694
2022-12-29 16:07: Train Epoch 3: 50/61 Loss: 0.198495
2022-12-29 16:08: Train Epoch 3: 51/61 Loss: 0.207644
2022-12-29 16:08: Train Epoch 3: 52/61 Loss: 0.184309
2022-12-29 16:08: Train Epoch 3: 53/61 Loss: 0.221721
2022-12-29 16:08: Train Epoch 3: 54/61 Loss: 0.209037
2022-12-29 16:08: Train Epoch 3: 55/61 Loss: 0.226956
2022-12-29 16:08: Train Epoch 3: 56/61 Loss: 0.216141
2022-12-29 16:08: Train Epoch 3: 57/61 Loss: 0.176769
2022-12-29 16:09: Train Epoch 3: 58/61 Loss: 0.181795
2022-12-29 16:09: Train Epoch 3: 59/61 Loss: 0.240299
2022-12-29 16:09: Train Epoch 3: 60/61 Loss: 0.208444
2022-12-29 16:09: **********Train Epoch 3: averaged Loss: 0.223730 
2022-12-29 16:09: 
Epoch time elapsed: 495.2122321128845

2022-12-29 16:09: 
 metrics validation: {'precision': 0.6636568848758465, 'recall': 0.6784615384615384, 'f1-score': 0.6709775580068468, 'support': 1300, 'AUC': 0.7957190828402367, 'AUCPR': 0.656956125812558, 'TP': 882, 'FP': 447, 'TN': 2153, 'FN': 418} 

2022-12-29 16:09: **********Val Epoch 3: average Loss: 0.249245
2022-12-29 16:09: *********************************Current best model saved!
2022-12-29 16:10: 
 Testing metrics {'precision': 0.7259083728278041, 'recall': 0.748371335504886, 'f1-score': 0.7369687249398557, 'support': 1228, 'AUC': 0.8511579035321329, 'AUCPR': 0.7431647365562918, 'TP': 919, 'FP': 347, 'TN': 2109, 'FN': 309} 

2022-12-29 16:10: Train Epoch 4: 0/61 Loss: 0.207367
2022-12-29 16:10: Train Epoch 4: 1/61 Loss: 0.218270
2022-12-29 16:10: Train Epoch 4: 2/61 Loss: 0.182230
2022-12-29 16:10: Train Epoch 4: 3/61 Loss: 0.200891
2022-12-29 16:11: Train Epoch 4: 4/61 Loss: 0.236176
2022-12-29 16:11: Train Epoch 4: 5/61 Loss: 0.217562
2022-12-29 16:11: Train Epoch 4: 6/61 Loss: 0.248807
2022-12-29 16:11: Train Epoch 4: 7/61 Loss: 0.212597
2022-12-29 16:11: Train Epoch 4: 8/61 Loss: 0.201107
2022-12-29 16:11: Train Epoch 4: 9/61 Loss: 0.214186
2022-12-29 16:11: Train Epoch 4: 10/61 Loss: 0.204554
2022-12-29 16:12: Train Epoch 4: 11/61 Loss: 0.227015
2022-12-29 16:12: Train Epoch 4: 12/61 Loss: 0.229958
2022-12-29 16:12: Train Epoch 4: 13/61 Loss: 0.193578
2022-12-29 16:12: Train Epoch 4: 14/61 Loss: 0.190775
2022-12-29 16:12: Train Epoch 4: 15/61 Loss: 0.168871
2022-12-29 16:12: Train Epoch 4: 16/61 Loss: 0.206271
2022-12-29 16:12: Train Epoch 4: 17/61 Loss: 0.219771
2022-12-29 16:13: Train Epoch 4: 18/61 Loss: 0.171998
2022-12-29 16:13: Train Epoch 4: 19/61 Loss: 0.251302
2022-12-29 16:13: Train Epoch 4: 20/61 Loss: 0.212081
2022-12-29 16:13: Train Epoch 4: 21/61 Loss: 0.198258
2022-12-29 16:13: Train Epoch 4: 22/61 Loss: 0.192169
2022-12-29 16:13: Train Epoch 4: 23/61 Loss: 0.204777
2022-12-29 16:13: Train Epoch 4: 24/61 Loss: 0.193069
2022-12-29 16:14: Train Epoch 4: 25/61 Loss: 0.196768
2022-12-29 16:14: Train Epoch 4: 26/61 Loss: 0.197094
2022-12-29 16:14: Train Epoch 4: 27/61 Loss: 0.222665
2022-12-29 16:14: Train Epoch 4: 28/61 Loss: 0.234285
2022-12-29 16:14: Train Epoch 4: 29/61 Loss: 0.218871
2022-12-29 16:14: Train Epoch 4: 30/61 Loss: 0.199641
2022-12-29 16:14: Train Epoch 4: 31/61 Loss: 0.162784
2022-12-29 16:14: Train Epoch 4: 32/61 Loss: 0.206564
2022-12-29 16:14: Train Epoch 4: 33/61 Loss: 0.174047
2022-12-29 16:15: Train Epoch 4: 34/61 Loss: 0.226391
2022-12-29 16:15: Train Epoch 4: 35/61 Loss: 0.157650
2022-12-29 16:15: Train Epoch 4: 36/61 Loss: 0.223930
2022-12-29 16:15: Train Epoch 4: 37/61 Loss: 0.190880
2022-12-29 16:15: Train Epoch 4: 38/61 Loss: 0.164753
2022-12-29 16:15: Train Epoch 4: 39/61 Loss: 0.185480
2022-12-29 16:15: Train Epoch 4: 40/61 Loss: 0.185132
2022-12-29 16:16: Train Epoch 4: 41/61 Loss: 0.214304
2022-12-29 16:16: Train Epoch 4: 42/61 Loss: 0.213918
2022-12-29 16:16: Train Epoch 4: 43/61 Loss: 0.174416
2022-12-29 16:16: Train Epoch 4: 44/61 Loss: 0.248082
2022-12-29 16:16: Train Epoch 4: 45/61 Loss: 0.228110
2022-12-29 16:16: Train Epoch 4: 46/61 Loss: 0.199452
2022-12-29 16:16: Train Epoch 4: 47/61 Loss: 0.220442
2022-12-29 16:16: Train Epoch 4: 48/61 Loss: 0.245649
2022-12-29 16:17: Train Epoch 4: 49/61 Loss: 0.217321
2022-12-29 16:17: Train Epoch 4: 50/61 Loss: 0.197498
2022-12-29 16:17: Train Epoch 4: 51/61 Loss: 0.171342
2022-12-29 16:17: Train Epoch 4: 52/61 Loss: 0.249501
2022-12-29 16:17: Train Epoch 4: 53/61 Loss: 0.199818
2022-12-29 16:17: Train Epoch 4: 54/61 Loss: 0.221581
2022-12-29 16:17: Train Epoch 4: 55/61 Loss: 0.192510
2022-12-29 16:17: Train Epoch 4: 56/61 Loss: 0.226682
2022-12-29 16:18: Train Epoch 4: 57/61 Loss: 0.188284
2022-12-29 16:18: Train Epoch 4: 58/61 Loss: 0.223589
2022-12-29 16:18: Train Epoch 4: 59/61 Loss: 0.152835
2022-12-29 16:18: Train Epoch 4: 60/61 Loss: 0.195026
2022-12-29 16:18: **********Train Epoch 4: averaged Loss: 0.205425 
2022-12-29 16:18: 
Epoch time elapsed: 492.44811153411865

2022-12-29 16:19: 
 metrics validation: {'precision': 0.7426376440460948, 'recall': 0.4461538461538462, 'f1-score': 0.557424315233061, 'support': 1300, 'AUC': 0.8071656804733728, 'AUCPR': 0.6712035050227793, 'TP': 580, 'FP': 201, 'TN': 2399, 'FN': 720} 

2022-12-29 16:19: **********Val Epoch 4: average Loss: 0.305708
2022-12-29 16:19: 
 Testing metrics {'precision': 0.7259083728278041, 'recall': 0.748371335504886, 'f1-score': 0.7369687249398557, 'support': 1228, 'AUC': 0.8511579035321329, 'AUCPR': 0.7431647365562918, 'TP': 919, 'FP': 347, 'TN': 2109, 'FN': 309} 

2022-12-29 16:19: Train Epoch 5: 0/61 Loss: 0.189495
2022-12-29 16:19: Train Epoch 5: 1/61 Loss: 0.205507
2022-12-29 16:20: Train Epoch 5: 2/61 Loss: 0.229437
2022-12-29 16:20: Train Epoch 5: 3/61 Loss: 0.181593
2022-12-29 16:20: Train Epoch 5: 4/61 Loss: 0.199781
2022-12-29 16:20: Train Epoch 5: 5/61 Loss: 0.207646
2022-12-29 16:20: Train Epoch 5: 6/61 Loss: 0.207235
2022-12-29 16:20: Train Epoch 5: 7/61 Loss: 0.178047
2022-12-29 16:20: Train Epoch 5: 8/61 Loss: 0.197484
2022-12-29 16:20: Train Epoch 5: 9/61 Loss: 0.186383
2022-12-29 16:21: Train Epoch 5: 10/61 Loss: 0.200436
2022-12-29 16:21: Train Epoch 5: 11/61 Loss: 0.228113
2022-12-29 16:21: Train Epoch 5: 12/61 Loss: 0.183857
2022-12-29 16:21: Train Epoch 5: 13/61 Loss: 0.182405
2022-12-29 16:21: Train Epoch 5: 14/61 Loss: 0.190355
2022-12-29 16:21: Train Epoch 5: 15/61 Loss: 0.173882
2022-12-29 16:21: Train Epoch 5: 16/61 Loss: 0.225501
2022-12-29 16:22: Train Epoch 5: 17/61 Loss: 0.218098
2022-12-29 16:22: Train Epoch 5: 18/61 Loss: 0.200100
2022-12-29 16:22: Train Epoch 5: 19/61 Loss: 0.197890
2022-12-29 16:22: Train Epoch 5: 20/61 Loss: 0.199348
2022-12-29 16:22: Train Epoch 5: 21/61 Loss: 0.216281
2022-12-29 16:22: Train Epoch 5: 22/61 Loss: 0.208854
2022-12-29 16:22: Train Epoch 5: 23/61 Loss: 0.214534
2022-12-29 16:22: Train Epoch 5: 24/61 Loss: 0.208426
2022-12-29 16:23: Train Epoch 5: 25/61 Loss: 0.233876
2022-12-29 16:23: Train Epoch 5: 26/61 Loss: 0.198102
2022-12-29 16:23: Train Epoch 5: 27/61 Loss: 0.198036
2022-12-29 16:23: Train Epoch 5: 28/61 Loss: 0.219539
2022-12-29 16:23: Train Epoch 5: 29/61 Loss: 0.218913
2022-12-29 16:23: Train Epoch 5: 30/61 Loss: 0.201038
2022-12-29 16:23: Train Epoch 5: 31/61 Loss: 0.250117
2022-12-29 16:24: Train Epoch 5: 32/61 Loss: 0.169751
2022-12-29 16:24: Train Epoch 5: 33/61 Loss: 0.209498
2022-12-29 16:24: Train Epoch 5: 34/61 Loss: 0.185086
2022-12-29 16:24: Train Epoch 5: 35/61 Loss: 0.202779
2022-12-29 16:24: Train Epoch 5: 36/61 Loss: 0.227388
2022-12-29 16:24: Train Epoch 5: 37/61 Loss: 0.218817
2022-12-29 16:24: Train Epoch 5: 38/61 Loss: 0.232717
2022-12-29 16:24: Train Epoch 5: 39/61 Loss: 0.185948
2022-12-29 16:25: Train Epoch 5: 40/61 Loss: 0.219008
2022-12-29 16:25: Train Epoch 5: 41/61 Loss: 0.200112
2022-12-29 16:25: Train Epoch 5: 42/61 Loss: 0.207810
2022-12-29 16:25: Train Epoch 5: 43/61 Loss: 0.207540
2022-12-29 16:25: Train Epoch 5: 44/61 Loss: 0.194871
2022-12-29 16:25: Train Epoch 5: 45/61 Loss: 0.211371
2022-12-29 16:25: Train Epoch 5: 46/61 Loss: 0.209579
2022-12-29 16:25: Train Epoch 5: 47/61 Loss: 0.173340
2022-12-29 16:26: Train Epoch 5: 48/61 Loss: 0.181043
2022-12-29 16:26: Train Epoch 5: 49/61 Loss: 0.212561
2022-12-29 16:26: Train Epoch 5: 50/61 Loss: 0.189123
2022-12-29 16:26: Train Epoch 5: 51/61 Loss: 0.174116
2022-12-29 16:26: Train Epoch 5: 52/61 Loss: 0.176509
2022-12-29 16:26: Train Epoch 5: 53/61 Loss: 0.193113
2022-12-29 16:26: Train Epoch 5: 54/61 Loss: 0.194137
2022-12-29 16:26: Train Epoch 5: 55/61 Loss: 0.175942
2022-12-29 16:27: Train Epoch 5: 56/61 Loss: 0.189851
2022-12-29 16:27: Train Epoch 5: 57/61 Loss: 0.221939
2022-12-29 16:27: Train Epoch 5: 58/61 Loss: 0.204642
2022-12-29 16:27: Train Epoch 5: 59/61 Loss: 0.189781
2022-12-29 16:27: Train Epoch 5: 60/61 Loss: 0.198906
2022-12-29 16:27: **********Train Epoch 5: averaged Loss: 0.201764 
2022-12-29 16:27: 
Epoch time elapsed: 479.2365782260895

2022-12-29 16:28: 
 metrics validation: {'precision': 0.7417380660954712, 'recall': 0.46615384615384614, 'f1-score': 0.5725082664147378, 'support': 1300, 'AUC': 0.8018520710059172, 'AUCPR': 0.6911151307733125, 'TP': 606, 'FP': 211, 'TN': 2389, 'FN': 694} 

2022-12-29 16:28: **********Val Epoch 5: average Loss: 0.294536
2022-12-29 16:28: 
 Testing metrics {'precision': 0.7259083728278041, 'recall': 0.748371335504886, 'f1-score': 0.7369687249398557, 'support': 1228, 'AUC': 0.8511579035321329, 'AUCPR': 0.7431647365562918, 'TP': 919, 'FP': 347, 'TN': 2109, 'FN': 309} 

2022-12-29 16:28: Train Epoch 6: 0/61 Loss: 0.221678
2022-12-29 16:28: Train Epoch 6: 1/61 Loss: 0.182199
2022-12-29 16:29: Train Epoch 6: 2/61 Loss: 0.241921
2022-12-29 16:29: Train Epoch 6: 3/61 Loss: 0.193981
2022-12-29 16:29: Train Epoch 6: 4/61 Loss: 0.173805
2022-12-29 16:29: Train Epoch 6: 5/61 Loss: 0.204602
2022-12-29 16:29: Train Epoch 6: 6/61 Loss: 0.254629
2022-12-29 16:29: Train Epoch 6: 7/61 Loss: 0.194355
2022-12-29 16:29: Train Epoch 6: 8/61 Loss: 0.190648
2022-12-29 16:29: Train Epoch 6: 9/61 Loss: 0.170981
2022-12-29 16:30: Train Epoch 6: 10/61 Loss: 0.203181
2022-12-29 16:30: Train Epoch 6: 11/61 Loss: 0.218003
2022-12-29 16:30: Train Epoch 6: 12/61 Loss: 0.213096
2022-12-29 16:30: Train Epoch 6: 13/61 Loss: 0.193637
2022-12-29 16:30: Train Epoch 6: 14/61 Loss: 0.192941
2022-12-29 16:30: Train Epoch 6: 15/61 Loss: 0.209794
2022-12-29 16:30: Train Epoch 6: 16/61 Loss: 0.156397
2022-12-29 16:31: Train Epoch 6: 17/61 Loss: 0.189330
2022-12-29 16:31: Train Epoch 6: 18/61 Loss: 0.231794
2022-12-29 16:31: Train Epoch 6: 19/61 Loss: 0.172505
2022-12-29 16:31: Train Epoch 6: 20/61 Loss: 0.216127
2022-12-29 16:31: Train Epoch 6: 21/61 Loss: 0.160147
2022-12-29 16:31: Train Epoch 6: 22/61 Loss: 0.226515
2022-12-29 16:31: Train Epoch 6: 23/61 Loss: 0.223661
2022-12-29 16:32: Train Epoch 6: 24/61 Loss: 0.192902
2022-12-29 16:32: Train Epoch 6: 25/61 Loss: 0.190781
2022-12-29 16:32: Train Epoch 6: 26/61 Loss: 0.188100
2022-12-29 16:32: Train Epoch 6: 27/61 Loss: 0.191488
2022-12-29 16:32: Train Epoch 6: 28/61 Loss: 0.224838
2022-12-29 16:32: Train Epoch 6: 29/61 Loss: 0.196000
2022-12-29 16:32: Train Epoch 6: 30/61 Loss: 0.197635
2022-12-29 16:33: Train Epoch 6: 31/61 Loss: 0.177915
2022-12-29 16:33: Train Epoch 6: 32/61 Loss: 0.210768
2022-12-29 16:33: Train Epoch 6: 33/61 Loss: 0.194703
2022-12-29 16:33: Train Epoch 6: 34/61 Loss: 0.214501
2022-12-29 16:33: Train Epoch 6: 35/61 Loss: 0.189022
2022-12-29 16:33: Train Epoch 6: 36/61 Loss: 0.160829
2022-12-29 16:33: Train Epoch 6: 37/61 Loss: 0.236485
2022-12-29 16:33: Train Epoch 6: 38/61 Loss: 0.224925
2022-12-29 16:34: Train Epoch 6: 39/61 Loss: 0.198730
2022-12-29 16:34: Train Epoch 6: 40/61 Loss: 0.175702
2022-12-29 16:34: Train Epoch 6: 41/61 Loss: 0.146047
2022-12-29 16:34: Train Epoch 6: 42/61 Loss: 0.201431
2022-12-29 16:34: Train Epoch 6: 43/61 Loss: 0.185544
2022-12-29 16:34: Train Epoch 6: 44/61 Loss: 0.219078
2022-12-29 16:34: Train Epoch 6: 45/61 Loss: 0.187712
2022-12-29 16:34: Train Epoch 6: 46/61 Loss: 0.231273
2022-12-29 16:34: Train Epoch 6: 47/61 Loss: 0.188729
2022-12-29 16:35: Train Epoch 6: 48/61 Loss: 0.225195
2022-12-29 16:35: Train Epoch 6: 49/61 Loss: 0.190280
2022-12-29 16:35: Train Epoch 6: 50/61 Loss: 0.169714
2022-12-29 16:35: Train Epoch 6: 51/61 Loss: 0.259340
2022-12-29 16:35: Train Epoch 6: 52/61 Loss: 0.217086
2022-12-29 16:35: Train Epoch 6: 53/61 Loss: 0.178683
2022-12-29 16:35: Train Epoch 6: 54/61 Loss: 0.201943
2022-12-29 16:36: Train Epoch 6: 55/61 Loss: 0.196068
2022-12-29 16:36: Train Epoch 6: 56/61 Loss: 0.196430
2022-12-29 16:36: Train Epoch 6: 57/61 Loss: 0.190654
2022-12-29 16:36: Train Epoch 6: 58/61 Loss: 0.210300
2022-12-29 16:36: Train Epoch 6: 59/61 Loss: 0.171986
2022-12-29 16:36: Train Epoch 6: 60/61 Loss: 0.177991
2022-12-29 16:36: **********Train Epoch 6: averaged Loss: 0.199127 
2022-12-29 16:36: 
Epoch time elapsed: 486.66902589797974

2022-12-29 16:37: 
 metrics validation: {'precision': 0.6502428868841083, 'recall': 0.7207692307692307, 'f1-score': 0.6836920831813207, 'support': 1300, 'AUC': 0.8116273668639054, 'AUCPR': 0.7156716318204086, 'TP': 937, 'FP': 504, 'TN': 2096, 'FN': 363} 

2022-12-29 16:37: **********Val Epoch 6: average Loss: 0.269922
2022-12-29 16:37: 
 Testing metrics {'precision': 0.7259083728278041, 'recall': 0.748371335504886, 'f1-score': 0.7369687249398557, 'support': 1228, 'AUC': 0.8511579035321329, 'AUCPR': 0.7431647365562918, 'TP': 919, 'FP': 347, 'TN': 2109, 'FN': 309} 

2022-12-29 16:37: Train Epoch 7: 0/61 Loss: 0.224081
2022-12-29 16:38: Train Epoch 7: 1/61 Loss: 0.238989
2022-12-29 16:38: Train Epoch 7: 2/61 Loss: 0.222932
2022-12-29 16:38: Train Epoch 7: 3/61 Loss: 0.227925
2022-12-29 16:38: Train Epoch 7: 4/61 Loss: 0.191674
2022-12-29 16:38: Train Epoch 7: 5/61 Loss: 0.227777
2022-12-29 16:38: Train Epoch 7: 6/61 Loss: 0.209678
2022-12-29 16:38: Train Epoch 7: 7/61 Loss: 0.199042
2022-12-29 16:39: Train Epoch 7: 8/61 Loss: 0.239500
2022-12-29 16:39: Train Epoch 7: 9/61 Loss: 0.231389
2022-12-29 16:39: Train Epoch 7: 10/61 Loss: 0.160377
2022-12-29 16:39: Train Epoch 7: 11/61 Loss: 0.198903
2022-12-29 16:39: Train Epoch 7: 12/61 Loss: 0.233383
2022-12-29 16:39: Train Epoch 7: 13/61 Loss: 0.196072
2022-12-29 16:39: Train Epoch 7: 14/61 Loss: 0.224461
2022-12-29 16:40: Train Epoch 7: 15/61 Loss: 0.246703
2022-12-29 16:40: Train Epoch 7: 16/61 Loss: 0.203447
2022-12-29 16:40: Train Epoch 7: 17/61 Loss: 0.200045
2022-12-29 16:40: Train Epoch 7: 18/61 Loss: 0.228540
2022-12-29 16:40: Train Epoch 7: 19/61 Loss: 0.222263
2022-12-29 16:40: Train Epoch 7: 20/61 Loss: 0.208793
2022-12-29 16:40: Train Epoch 7: 21/61 Loss: 0.184806
2022-12-29 16:40: Train Epoch 7: 22/61 Loss: 0.201063
2022-12-29 16:41: Train Epoch 7: 23/61 Loss: 0.215977
2022-12-29 16:41: Train Epoch 7: 24/61 Loss: 0.199250
2022-12-29 16:41: Train Epoch 7: 25/61 Loss: 0.219214
2022-12-29 16:41: Train Epoch 7: 26/61 Loss: 0.183938
2022-12-29 16:41: Train Epoch 7: 27/61 Loss: 0.196616
2022-12-29 16:41: Train Epoch 7: 28/61 Loss: 0.200903
2022-12-29 16:41: Train Epoch 7: 29/61 Loss: 0.203576
2022-12-29 16:41: Train Epoch 7: 30/61 Loss: 0.222794
2022-12-29 16:41: Train Epoch 7: 31/61 Loss: 0.224462
2022-12-29 16:42: Train Epoch 7: 32/61 Loss: 0.199696
2022-12-29 16:42: Train Epoch 7: 33/61 Loss: 0.191159
2022-12-29 16:42: Train Epoch 7: 34/61 Loss: 0.174745
2022-12-29 16:42: Train Epoch 7: 35/61 Loss: 0.205358
2022-12-29 16:42: Train Epoch 7: 36/61 Loss: 0.210425
2022-12-29 16:42: Train Epoch 7: 37/61 Loss: 0.179510
2022-12-29 16:42: Train Epoch 7: 38/61 Loss: 0.212918
2022-12-29 16:42: Train Epoch 7: 39/61 Loss: 0.215977
2022-12-29 16:43: Train Epoch 7: 40/61 Loss: 0.169831
2022-12-29 16:43: Train Epoch 7: 41/61 Loss: 0.242833
2022-12-29 16:43: Train Epoch 7: 42/61 Loss: 0.203229
2022-12-29 16:43: Train Epoch 7: 43/61 Loss: 0.171473
2022-12-29 16:43: Train Epoch 7: 44/61 Loss: 0.210116
2022-12-29 16:43: Train Epoch 7: 45/61 Loss: 0.194937
2022-12-29 16:43: Train Epoch 7: 46/61 Loss: 0.203442
2022-12-29 16:43: Train Epoch 7: 47/61 Loss: 0.214227
2022-12-29 16:44: Train Epoch 7: 48/61 Loss: 0.181112
2022-12-29 16:44: Train Epoch 7: 49/61 Loss: 0.182035
2022-12-29 16:44: Train Epoch 7: 50/61 Loss: 0.200446
2022-12-29 16:44: Train Epoch 7: 51/61 Loss: 0.194691
2022-12-29 16:44: Train Epoch 7: 52/61 Loss: 0.204548
2022-12-29 16:44: Train Epoch 7: 53/61 Loss: 0.228938
2022-12-29 16:44: Train Epoch 7: 54/61 Loss: 0.188134
2022-12-29 16:45: Train Epoch 7: 55/61 Loss: 0.166580
2022-12-29 16:45: Train Epoch 7: 56/61 Loss: 0.178414
2022-12-29 16:45: Train Epoch 7: 57/61 Loss: 0.207202
2022-12-29 16:45: Train Epoch 7: 58/61 Loss: 0.182245
2022-12-29 16:45: Train Epoch 7: 59/61 Loss: 0.177719
2022-12-29 16:45: Train Epoch 7: 60/61 Loss: 0.147800
2022-12-29 16:45: **********Train Epoch 7: averaged Loss: 0.203743 
2022-12-29 16:45: 
Epoch time elapsed: 480.5416634082794

2022-12-29 16:46: 
 metrics validation: {'precision': 0.7216014897579144, 'recall': 0.5961538461538461, 'f1-score': 0.6529064869418703, 'support': 1300, 'AUC': 0.8071431952662722, 'AUCPR': 0.7034079203661835, 'TP': 775, 'FP': 299, 'TN': 2301, 'FN': 525} 

2022-12-29 16:46: **********Val Epoch 7: average Loss: 0.265316
2022-12-29 16:46: 
 Testing metrics {'precision': 0.7259083728278041, 'recall': 0.748371335504886, 'f1-score': 0.7369687249398557, 'support': 1228, 'AUC': 0.8511579035321329, 'AUCPR': 0.7431647365562918, 'TP': 919, 'FP': 347, 'TN': 2109, 'FN': 309} 

2022-12-29 16:47: Train Epoch 8: 0/61 Loss: 0.205225
2022-12-29 16:47: Train Epoch 8: 1/61 Loss: 0.205756
2022-12-29 16:47: Train Epoch 8: 2/61 Loss: 0.197571
2022-12-29 16:47: Train Epoch 8: 3/61 Loss: 0.199055
2022-12-29 16:47: Train Epoch 8: 4/61 Loss: 0.172871
2022-12-29 16:47: Train Epoch 8: 5/61 Loss: 0.190516
2022-12-29 16:47: Train Epoch 8: 6/61 Loss: 0.180350
2022-12-29 16:47: Train Epoch 8: 7/61 Loss: 0.210872
2022-12-29 16:48: Train Epoch 8: 8/61 Loss: 0.204753
2022-12-29 16:48: Train Epoch 8: 9/61 Loss: 0.203052
2022-12-29 16:48: Train Epoch 8: 10/61 Loss: 0.215169
2022-12-29 16:48: Train Epoch 8: 11/61 Loss: 0.190651
2022-12-29 16:48: Train Epoch 8: 12/61 Loss: 0.201207
2022-12-29 16:48: Train Epoch 8: 13/61 Loss: 0.214223
2022-12-29 16:48: Train Epoch 8: 14/61 Loss: 0.209700
2022-12-29 16:49: Train Epoch 8: 15/61 Loss: 0.206603
2022-12-29 16:49: Train Epoch 8: 16/61 Loss: 0.224701
2022-12-29 16:49: Train Epoch 8: 17/61 Loss: 0.193553
2022-12-29 16:49: Train Epoch 8: 18/61 Loss: 0.220167
2022-12-29 16:49: Train Epoch 8: 19/61 Loss: 0.196337
2022-12-29 16:49: Train Epoch 8: 20/61 Loss: 0.229395
2022-12-29 16:49: Train Epoch 8: 21/61 Loss: 0.214288
2022-12-29 16:50: Train Epoch 8: 22/61 Loss: 0.190794
2022-12-29 16:50: Train Epoch 8: 23/61 Loss: 0.225074
2022-12-29 16:50: Train Epoch 8: 24/61 Loss: 0.191372
2022-12-29 16:50: Train Epoch 8: 25/61 Loss: 0.193953
2022-12-29 16:50: Train Epoch 8: 26/61 Loss: 0.187816
2022-12-29 16:50: Train Epoch 8: 27/61 Loss: 0.227188
2022-12-29 16:50: Train Epoch 8: 28/61 Loss: 0.214283
2022-12-29 16:50: Train Epoch 8: 29/61 Loss: 0.223918
2022-12-29 16:51: Train Epoch 8: 30/61 Loss: 0.214383
2022-12-29 16:51: Train Epoch 8: 31/61 Loss: 0.207562
2022-12-29 16:51: Train Epoch 8: 32/61 Loss: 0.200630
2022-12-29 16:51: Train Epoch 8: 33/61 Loss: 0.191195
2022-12-29 16:51: Train Epoch 8: 34/61 Loss: 0.171464
2022-12-29 16:51: Train Epoch 8: 35/61 Loss: 0.208190
2022-12-29 16:51: Train Epoch 8: 36/61 Loss: 0.177796
2022-12-29 16:52: Train Epoch 8: 37/61 Loss: 0.183367
2022-12-29 16:52: Train Epoch 8: 38/61 Loss: 0.214239
2022-12-29 16:52: Train Epoch 8: 39/61 Loss: 0.190737
2022-12-29 16:52: Train Epoch 8: 40/61 Loss: 0.166352
2022-12-29 16:52: Train Epoch 8: 41/61 Loss: 0.198366
2022-12-29 16:52: Train Epoch 8: 42/61 Loss: 0.180318
2022-12-29 16:52: Train Epoch 8: 43/61 Loss: 0.165051
2022-12-29 16:52: Train Epoch 8: 44/61 Loss: 0.174996
2022-12-29 16:53: Train Epoch 8: 45/61 Loss: 0.187009
