2022-12-21 12:39: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221221123912
2022-12-21 12:39: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221221123912
2022-12-21 12:39: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=16, epochs=30, gamma=1.0, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221221123912', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='10, 15, 20, 25', lr_init=0.0001, mae_thresh=None, mape_thresh=0.0, max_grad_norm=5, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=32, seed=1992, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, test_ratio=0.2, val_ratio=0.2, weight_decay=0.01, window_len=10)
2022-12-21 12:39: Argument batch_size: 256
2022-12-21 12:39: Argument clc: 'vec'
2022-12-21 12:39: Argument cuda: True
2022-12-21 12:39: Argument dataset: '2020'
2022-12-21 12:39: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-21 12:39: Argument debug: False
2022-12-21 12:39: Argument default_graph: True
2022-12-21 12:39: Argument device: 'cpu'
2022-12-21 12:39: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-21 12:39: Argument early_stop: True
2022-12-21 12:39: Argument early_stop_patience: 8
2022-12-21 12:39: Argument embed_dim: 16
2022-12-21 12:39: Argument epochs: 30
2022-12-21 12:39: Argument gamma: 1.0
2022-12-21 12:39: Argument grad_norm: False
2022-12-21 12:39: Argument horizon: 1
2022-12-21 12:39: Argument input_dim: 25
2022-12-21 12:39: Argument lag: 10
2022-12-21 12:39: Argument link_len: 2
2022-12-21 12:39: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221221123912'
2022-12-21 12:39: Argument log_step: 1
2022-12-21 12:39: Argument loss_func: 'nllloss'
2022-12-21 12:39: Argument lr_decay: True
2022-12-21 12:39: Argument lr_decay_rate: 0.1
2022-12-21 12:39: Argument lr_decay_step: '10, 15, 20, 25'
2022-12-21 12:39: Argument lr_init: 0.0001
2022-12-21 12:39: Argument mae_thresh: None
2022-12-21 12:39: Argument mape_thresh: 0.0
2022-12-21 12:39: Argument max_grad_norm: 5
2022-12-21 12:39: Argument mode: 'train'
2022-12-21 12:39: Argument model: 'fire_GCN'
2022-12-21 12:39: Argument nan_fill: 0.5
2022-12-21 12:39: Argument num_layers: 1
2022-12-21 12:39: Argument num_nodes: 625
2022-12-21 12:39: Argument num_workers: 12
2022-12-21 12:39: Argument output_dim: 2
2022-12-21 12:39: Argument patch_height: 25
2022-12-21 12:39: Argument patch_width: 25
2022-12-21 12:39: Argument persistent_workers: True
2022-12-21 12:39: Argument pin_memory: True
2022-12-21 12:39: Argument plot: False
2022-12-21 12:39: Argument positive_weight: 0.5
2022-12-21 12:39: Argument prefetch_factor: 2
2022-12-21 12:39: Argument real_value: True
2022-12-21 12:39: Argument rnn_units: 32
2022-12-21 12:39: Argument seed: 1992
2022-12-21 12:39: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-21 12:39: Argument teacher_forcing: False
2022-12-21 12:39: Argument test_ratio: 0.2
2022-12-21 12:39: Argument val_ratio: 0.2
2022-12-21 12:39: Argument weight_decay: 0.01
2022-12-21 12:39: Argument window_len: 10
2022-12-21 12:39: Train Epoch 1: 0/159 Loss: 0.883079
2022-12-21 12:39: Train Epoch 1: 1/159 Loss: 0.650339
2022-12-21 12:40: Train Epoch 1: 2/159 Loss: 0.713986
2022-12-21 12:40: Train Epoch 1: 3/159 Loss: 0.680541
2022-12-21 12:40: Train Epoch 1: 4/159 Loss: 0.764112
2022-12-21 12:40: Train Epoch 1: 5/159 Loss: 0.716093
2022-12-21 12:40: Train Epoch 1: 6/159 Loss: 0.612760
2022-12-21 12:41: Train Epoch 1: 7/159 Loss: 0.671130
2022-12-21 12:41: Train Epoch 1: 8/159 Loss: 0.704875
2022-12-21 12:41: Train Epoch 1: 9/159 Loss: 0.694381
2022-12-21 12:41: Train Epoch 1: 10/159 Loss: 0.656284
2022-12-21 12:42: Train Epoch 1: 11/159 Loss: 0.644797
2022-12-21 12:42: Train Epoch 1: 12/159 Loss: 0.616041
2022-12-21 12:42: Train Epoch 1: 13/159 Loss: 0.671970
2022-12-21 12:42: Train Epoch 1: 14/159 Loss: 0.670130
2022-12-21 12:43: Train Epoch 1: 15/159 Loss: 0.663452
2022-12-21 12:43: Train Epoch 1: 16/159 Loss: 0.606896
2022-12-21 12:43: Train Epoch 1: 17/159 Loss: 0.673040
2022-12-21 12:43: Train Epoch 1: 18/159 Loss: 0.641617
2022-12-21 12:44: Train Epoch 1: 19/159 Loss: 0.653702
2022-12-21 12:44: Train Epoch 1: 20/159 Loss: 0.660151
2022-12-21 12:44: Train Epoch 1: 21/159 Loss: 0.658736
2022-12-21 12:45: Train Epoch 1: 22/159 Loss: 0.619494
2022-12-21 12:45: Train Epoch 1: 23/159 Loss: 0.594880
2022-12-21 12:45: Train Epoch 1: 24/159 Loss: 0.676022
2022-12-21 12:45: Train Epoch 1: 25/159 Loss: 0.633515
2022-12-21 12:46: Train Epoch 1: 26/159 Loss: 0.621063
2022-12-21 12:46: Train Epoch 1: 27/159 Loss: 0.646902
2022-12-21 12:46: Train Epoch 1: 28/159 Loss: 0.648941
2022-12-21 12:46: Train Epoch 1: 29/159 Loss: 0.641925
2022-12-21 12:47: Train Epoch 1: 30/159 Loss: 0.587858
2022-12-21 12:47: Train Epoch 1: 31/159 Loss: 0.621165
2022-12-21 12:47: Train Epoch 1: 32/159 Loss: 0.648610
2022-12-21 12:47: Train Epoch 1: 33/159 Loss: 0.642118
2022-12-21 12:48: Train Epoch 1: 34/159 Loss: 0.611557
2022-12-21 12:48: Train Epoch 1: 35/159 Loss: 0.633002
2022-12-21 12:48: Train Epoch 1: 36/159 Loss: 0.619737
2022-12-21 12:48: Train Epoch 1: 37/159 Loss: 0.594652
2022-12-21 12:49: Train Epoch 1: 38/159 Loss: 0.646433
2022-12-21 12:49: Train Epoch 1: 39/159 Loss: 0.592834
2022-12-21 12:49: Train Epoch 1: 40/159 Loss: 0.652105
2022-12-21 12:49: Train Epoch 1: 41/159 Loss: 0.611872
2022-12-21 12:50: Train Epoch 1: 42/159 Loss: 0.602715
2022-12-21 12:50: Train Epoch 1: 43/159 Loss: 0.624313
2022-12-21 12:50: Train Epoch 1: 44/159 Loss: 0.609701
2022-12-21 12:51: Train Epoch 1: 45/159 Loss: 0.600877
2022-12-21 12:51: Train Epoch 1: 46/159 Loss: 0.601808
2022-12-21 12:51: Train Epoch 1: 47/159 Loss: 0.627912
2022-12-21 12:51: Train Epoch 1: 48/159 Loss: 0.644324
2022-12-21 12:52: Train Epoch 1: 49/159 Loss: 0.586905
2022-12-21 12:52: Train Epoch 1: 50/159 Loss: 0.606328
2022-12-21 12:52: Train Epoch 1: 51/159 Loss: 0.605195
2022-12-21 12:52: Train Epoch 1: 52/159 Loss: 0.614014
2022-12-21 12:53: Train Epoch 1: 53/159 Loss: 0.598457
2022-12-21 12:53: Train Epoch 1: 54/159 Loss: 0.595874
2022-12-21 12:53: Train Epoch 1: 55/159 Loss: 0.587966
2022-12-21 12:53: Train Epoch 1: 56/159 Loss: 0.588353
2022-12-21 12:54: Train Epoch 1: 57/159 Loss: 0.597939
2022-12-21 12:54: Train Epoch 1: 58/159 Loss: 0.610126
2022-12-21 12:54: Train Epoch 1: 59/159 Loss: 0.596726
2022-12-21 12:54: Train Epoch 1: 60/159 Loss: 0.567533
2022-12-21 12:55: Train Epoch 1: 61/159 Loss: 0.564828
2022-12-21 12:55: Train Epoch 1: 62/159 Loss: 0.625589
2022-12-21 12:55: Train Epoch 1: 63/159 Loss: 0.579724
2022-12-21 12:55: Train Epoch 1: 64/159 Loss: 0.562588
2022-12-21 12:56: Train Epoch 1: 65/159 Loss: 0.586837
2022-12-21 12:56: Train Epoch 1: 66/159 Loss: 0.581395
2022-12-21 12:56: Train Epoch 1: 67/159 Loss: 0.602006
2022-12-21 12:57: Train Epoch 1: 68/159 Loss: 0.597428
2022-12-21 12:57: Train Epoch 1: 69/159 Loss: 0.588548
2022-12-21 12:57: Train Epoch 1: 70/159 Loss: 0.558655
2022-12-21 12:57: Train Epoch 1: 71/159 Loss: 0.570307
2022-12-21 12:58: Train Epoch 1: 72/159 Loss: 0.550732
2022-12-21 12:58: Train Epoch 1: 73/159 Loss: 0.635532
2022-12-21 12:58: Train Epoch 1: 74/159 Loss: 0.550482
2022-12-21 12:58: Train Epoch 1: 75/159 Loss: 0.567543
2022-12-21 12:59: Train Epoch 1: 76/159 Loss: 0.577648
2022-12-21 12:59: Train Epoch 1: 77/159 Loss: 0.573627
2022-12-21 12:59: Train Epoch 1: 78/159 Loss: 0.564745
2022-12-21 12:59: Train Epoch 1: 79/159 Loss: 0.567422
2022-12-21 13:00: Train Epoch 1: 80/159 Loss: 0.548795
2022-12-21 13:00: Train Epoch 1: 81/159 Loss: 0.525876
2022-12-21 13:00: Train Epoch 1: 82/159 Loss: 0.537965
2022-12-21 13:00: Train Epoch 1: 83/159 Loss: 0.568389
2022-12-21 13:01: Train Epoch 1: 84/159 Loss: 0.534151
2022-12-21 13:01: Train Epoch 1: 85/159 Loss: 0.563290
2022-12-21 13:01: Train Epoch 1: 86/159 Loss: 0.546186
2022-12-21 13:01: Train Epoch 1: 87/159 Loss: 0.515723
2022-12-21 13:02: Train Epoch 1: 88/159 Loss: 0.533865
2022-12-21 13:02: Train Epoch 1: 89/159 Loss: 0.516099
2022-12-21 13:02: Train Epoch 1: 90/159 Loss: 0.554596
2022-12-21 13:03: Train Epoch 1: 91/159 Loss: 0.548192
2022-12-21 13:03: Train Epoch 1: 92/159 Loss: 0.556950
2022-12-21 13:03: Train Epoch 1: 93/159 Loss: 0.520494
2022-12-21 13:03: Train Epoch 1: 94/159 Loss: 0.521861
2022-12-21 13:04: Train Epoch 1: 95/159 Loss: 0.529710
2022-12-21 13:04: Train Epoch 1: 96/159 Loss: 0.489413
2022-12-21 13:04: Train Epoch 1: 97/159 Loss: 0.507377
2022-12-21 13:04: Train Epoch 1: 98/159 Loss: 0.504562
2022-12-21 13:05: Train Epoch 1: 99/159 Loss: 0.510608
2022-12-21 13:05: Train Epoch 1: 100/159 Loss: 0.513434
2022-12-21 13:05: Train Epoch 1: 101/159 Loss: 0.468243
2022-12-21 13:05: Train Epoch 1: 102/159 Loss: 0.498503
2022-12-21 13:06: Train Epoch 1: 103/159 Loss: 0.497596
2022-12-21 13:06: Train Epoch 1: 104/159 Loss: 0.490797
2022-12-21 13:06: Train Epoch 1: 105/159 Loss: 0.485324
2022-12-21 13:06: Train Epoch 1: 106/159 Loss: 0.505031
2022-12-21 13:07: Train Epoch 1: 107/159 Loss: 0.486969
2022-12-21 13:07: Train Epoch 1: 108/159 Loss: 0.465594
2022-12-21 13:07: Train Epoch 1: 109/159 Loss: 0.441499
2022-12-21 13:07: Train Epoch 1: 110/159 Loss: 0.492830
2022-12-21 13:08: Train Epoch 1: 111/159 Loss: 0.439001
2022-12-21 13:08: Train Epoch 1: 112/159 Loss: 0.467684
2022-12-21 13:08: Train Epoch 1: 113/159 Loss: 0.451055
2022-12-21 13:08: Train Epoch 1: 114/159 Loss: 0.465313
2022-12-21 13:09: Train Epoch 1: 115/159 Loss: 0.498300
2022-12-21 13:09: Train Epoch 1: 116/159 Loss: 0.491569
2022-12-21 13:09: Train Epoch 1: 117/159 Loss: 0.470801
2022-12-21 13:09: Train Epoch 1: 118/159 Loss: 0.478639
2022-12-21 13:10: Train Epoch 1: 119/159 Loss: 0.428230
2022-12-21 13:10: Train Epoch 1: 120/159 Loss: 0.429951
2022-12-21 13:10: Train Epoch 1: 121/159 Loss: 0.443739
2022-12-21 13:11: Train Epoch 1: 122/159 Loss: 0.440761
2022-12-21 13:11: Train Epoch 1: 123/159 Loss: 0.443413
2022-12-21 13:11: Train Epoch 1: 124/159 Loss: 0.414650
2022-12-21 13:11: Train Epoch 1: 125/159 Loss: 0.455246
2022-12-21 13:12: Train Epoch 1: 126/159 Loss: 0.434089
2022-12-21 13:12: Train Epoch 1: 127/159 Loss: 0.447296
2022-12-21 13:12: Train Epoch 1: 128/159 Loss: 0.422496
2022-12-21 13:12: Train Epoch 1: 129/159 Loss: 0.420832
2022-12-21 13:13: Train Epoch 1: 130/159 Loss: 0.430155
2022-12-21 13:13: Train Epoch 1: 131/159 Loss: 0.424937
2022-12-21 13:13: Train Epoch 1: 132/159 Loss: 0.419914
2022-12-21 13:13: Train Epoch 1: 133/159 Loss: 0.428025
2022-12-21 13:14: Train Epoch 1: 134/159 Loss: 0.396399
2022-12-21 13:14: Train Epoch 1: 135/159 Loss: 0.438485
2022-12-21 13:14: Train Epoch 1: 136/159 Loss: 0.441050
2022-12-21 13:14: Train Epoch 1: 137/159 Loss: 0.442298
2022-12-21 13:15: Train Epoch 1: 138/159 Loss: 0.402383
2022-12-21 13:15: Train Epoch 1: 139/159 Loss: 0.425032
2022-12-21 13:15: Train Epoch 1: 140/159 Loss: 0.388330
2022-12-21 13:15: Train Epoch 1: 141/159 Loss: 0.448959
2022-12-21 13:16: Train Epoch 1: 142/159 Loss: 0.402117
