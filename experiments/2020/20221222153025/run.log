2022-12-22 15:30: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221222153025
2022-12-22 15:30: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221222153025
2022-12-22 15:30: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, gamma=1.0, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221222153025', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='10, 15, 20, 25', lr_init=0.0005, mae_thresh=None, mape_thresh=0.0, max_grad_norm=5, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=32, seed=1992, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, test_ratio=0.2, val_ratio=0.2, weight_decay=0.01, window_len=10)
2022-12-22 15:30: Argument batch_size: 256
2022-12-22 15:30: Argument clc: 'vec'
2022-12-22 15:30: Argument cuda: True
2022-12-22 15:30: Argument dataset: '2020'
2022-12-22 15:30: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-22 15:30: Argument debug: False
2022-12-22 15:30: Argument default_graph: True
2022-12-22 15:30: Argument device: 'cpu'
2022-12-22 15:30: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-22 15:30: Argument early_stop: True
2022-12-22 15:30: Argument early_stop_patience: 8
2022-12-22 15:30: Argument embed_dim: 64
2022-12-22 15:30: Argument epochs: 30
2022-12-22 15:30: Argument gamma: 1.0
2022-12-22 15:30: Argument grad_norm: False
2022-12-22 15:30: Argument horizon: 1
2022-12-22 15:30: Argument input_dim: 25
2022-12-22 15:30: Argument lag: 10
2022-12-22 15:30: Argument link_len: 2
2022-12-22 15:30: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221222153025'
2022-12-22 15:30: Argument log_step: 1
2022-12-22 15:30: Argument loss_func: 'nllloss'
2022-12-22 15:30: Argument lr_decay: True
2022-12-22 15:30: Argument lr_decay_rate: 0.1
2022-12-22 15:30: Argument lr_decay_step: '10, 15, 20, 25'
2022-12-22 15:30: Argument lr_init: 0.0005
2022-12-22 15:30: Argument mae_thresh: None
2022-12-22 15:30: Argument mape_thresh: 0.0
2022-12-22 15:30: Argument max_grad_norm: 5
2022-12-22 15:30: Argument mode: 'train'
2022-12-22 15:30: Argument model: 'fire_GCN'
2022-12-22 15:30: Argument nan_fill: 0.5
2022-12-22 15:30: Argument num_layers: 1
2022-12-22 15:30: Argument num_nodes: 625
2022-12-22 15:30: Argument num_workers: 20
2022-12-22 15:30: Argument output_dim: 2
2022-12-22 15:30: Argument patch_height: 25
2022-12-22 15:30: Argument patch_width: 25
2022-12-22 15:30: Argument persistent_workers: True
2022-12-22 15:30: Argument pin_memory: True
2022-12-22 15:30: Argument plot: False
2022-12-22 15:30: Argument positive_weight: 0.5
2022-12-22 15:30: Argument prefetch_factor: 2
2022-12-22 15:30: Argument real_value: True
2022-12-22 15:30: Argument rnn_units: 32
2022-12-22 15:30: Argument seed: 1992
2022-12-22 15:30: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-22 15:30: Argument teacher_forcing: False
2022-12-22 15:30: Argument test_ratio: 0.2
2022-12-22 15:30: Argument val_ratio: 0.2
2022-12-22 15:30: Argument weight_decay: 0.01
2022-12-22 15:30: Argument window_len: 10
2022-12-22 15:30: Train Epoch 1: 0/159 Loss: 0.662151
2022-12-22 15:31: Train Epoch 1: 1/159 Loss: 2.746418
2022-12-22 15:31: Train Epoch 1: 2/159 Loss: 1.361832
2022-12-22 15:31: Train Epoch 1: 3/159 Loss: 1.901669
2022-12-22 15:31: Train Epoch 1: 4/159 Loss: 1.678867
2022-12-22 15:31: Train Epoch 1: 5/159 Loss: 0.619336
2022-12-22 15:32: Train Epoch 1: 6/159 Loss: 1.121050
2022-12-22 15:32: Train Epoch 1: 7/159 Loss: 1.674808
2022-12-22 15:32: Train Epoch 1: 8/159 Loss: 1.330333
2022-12-22 15:32: Train Epoch 1: 9/159 Loss: 0.836095
2022-12-22 15:32: Train Epoch 1: 10/159 Loss: 0.654304
2022-12-22 15:33: Train Epoch 1: 11/159 Loss: 1.103432
2022-12-22 15:33: Train Epoch 1: 12/159 Loss: 1.173270
2022-12-22 15:33: Train Epoch 1: 13/159 Loss: 0.757131
2022-12-22 15:33: Train Epoch 1: 14/159 Loss: 0.648821
2022-12-22 15:34: Train Epoch 1: 15/159 Loss: 1.040539
2022-12-22 15:34: Train Epoch 1: 16/159 Loss: 0.907504
2022-12-22 15:34: Train Epoch 1: 17/159 Loss: 0.996196
2022-12-22 15:34: Train Epoch 1: 18/159 Loss: 0.716965
2022-12-22 15:35: Train Epoch 1: 19/159 Loss: 0.615971
2022-12-22 15:35: Train Epoch 1: 20/159 Loss: 0.829771
2022-12-22 15:35: Train Epoch 1: 21/159 Loss: 0.859615
2022-12-22 15:35: Train Epoch 1: 22/159 Loss: 0.653373
2022-12-22 15:35: Train Epoch 1: 23/159 Loss: 0.647906
2022-12-22 15:36: Train Epoch 1: 24/159 Loss: 0.687520
2022-12-22 15:36: Train Epoch 1: 25/159 Loss: 0.793113
2022-12-22 15:36: Train Epoch 1: 26/159 Loss: 0.690844
2022-12-22 15:36: Train Epoch 1: 27/159 Loss: 0.619236
2022-12-22 15:37: Train Epoch 1: 28/159 Loss: 0.658030
2022-12-22 15:37: Train Epoch 1: 29/159 Loss: 0.736198
2022-12-22 15:37: Train Epoch 1: 30/159 Loss: 0.655628
2022-12-22 15:37: Train Epoch 1: 31/159 Loss: 0.625646
2022-12-22 15:38: Train Epoch 1: 32/159 Loss: 0.573608
2022-12-22 15:38: Train Epoch 1: 33/159 Loss: 0.660944
2022-12-22 15:38: Train Epoch 1: 34/159 Loss: 0.659702
2022-12-22 15:38: Train Epoch 1: 35/159 Loss: 0.596287
2022-12-22 15:38: Train Epoch 1: 36/159 Loss: 0.591833
2022-12-22 15:39: Train Epoch 1: 37/159 Loss: 0.629338
2022-12-22 15:39: Train Epoch 1: 38/159 Loss: 0.607997
2022-12-22 15:39: Train Epoch 1: 39/159 Loss: 0.544084
2022-12-22 15:39: Train Epoch 1: 40/159 Loss: 0.612463
2022-12-22 15:40: Train Epoch 1: 41/159 Loss: 0.556402
2022-12-22 15:40: Train Epoch 1: 42/159 Loss: 0.618713
2022-12-22 15:40: Train Epoch 1: 43/159 Loss: 0.526514
2022-12-22 15:40: Train Epoch 1: 44/159 Loss: 0.570638
2022-12-22 15:41: Train Epoch 1: 45/159 Loss: 0.581809
2022-12-22 15:41: Train Epoch 1: 46/159 Loss: 0.567790
2022-12-22 15:41: Train Epoch 1: 47/159 Loss: 0.573779
2022-12-22 15:41: Train Epoch 1: 48/159 Loss: 0.541527
2022-12-22 15:42: Train Epoch 1: 49/159 Loss: 0.547734
2022-12-22 15:42: Train Epoch 1: 50/159 Loss: 0.509806
2022-12-22 15:42: Train Epoch 1: 51/159 Loss: 0.533495
2022-12-22 15:42: Train Epoch 1: 52/159 Loss: 0.501278
2022-12-22 15:43: Train Epoch 1: 53/159 Loss: 0.528100
2022-12-22 15:43: Train Epoch 1: 54/159 Loss: 0.492047
2022-12-22 15:43: Train Epoch 1: 55/159 Loss: 0.530915
2022-12-22 15:43: Train Epoch 1: 56/159 Loss: 0.506541
2022-12-22 15:44: Train Epoch 1: 57/159 Loss: 0.490611
2022-12-22 15:44: Train Epoch 1: 58/159 Loss: 0.498722
2022-12-22 15:44: Train Epoch 1: 59/159 Loss: 0.504080
2022-12-22 15:44: Train Epoch 1: 60/159 Loss: 0.476651
2022-12-22 15:45: Train Epoch 1: 61/159 Loss: 0.503165
2022-12-22 15:45: Train Epoch 1: 62/159 Loss: 0.433837
2022-12-22 15:45: Train Epoch 1: 63/159 Loss: 0.458794
2022-12-22 15:45: Train Epoch 1: 64/159 Loss: 0.459379
2022-12-22 15:46: Train Epoch 1: 65/159 Loss: 0.463400
2022-12-22 15:46: Train Epoch 1: 66/159 Loss: 0.480610
2022-12-22 15:46: Train Epoch 1: 67/159 Loss: 0.447221
2022-12-22 15:46: Train Epoch 1: 68/159 Loss: 0.455446
2022-12-22 15:46: Train Epoch 1: 69/159 Loss: 0.419704
2022-12-22 15:47: Train Epoch 1: 70/159 Loss: 0.451284
2022-12-22 15:47: Train Epoch 1: 71/159 Loss: 0.443142
2022-12-22 15:47: Train Epoch 1: 72/159 Loss: 0.416996
2022-12-22 15:47: Train Epoch 1: 73/159 Loss: 0.397637
2022-12-22 15:48: Train Epoch 1: 74/159 Loss: 0.438776
2022-12-22 15:48: Train Epoch 1: 75/159 Loss: 0.388693
2022-12-22 15:48: Train Epoch 1: 76/159 Loss: 0.399553
2022-12-22 15:48: Train Epoch 1: 77/159 Loss: 0.347431
2022-12-22 15:49: Train Epoch 1: 78/159 Loss: 0.374910
2022-12-22 15:49: Train Epoch 1: 79/159 Loss: 0.357030
2022-12-22 15:49: Train Epoch 1: 80/159 Loss: 0.395948
2022-12-22 15:49: Train Epoch 1: 81/159 Loss: 0.364354
2022-12-22 15:50: Train Epoch 1: 82/159 Loss: 0.383610
2022-12-22 15:50: Train Epoch 1: 83/159 Loss: 0.354076
2022-12-22 15:50: Train Epoch 1: 84/159 Loss: 0.347387
2022-12-22 15:50: Train Epoch 1: 85/159 Loss: 0.344087
2022-12-22 15:51: Train Epoch 1: 86/159 Loss: 0.377599
2022-12-22 15:51: Train Epoch 1: 87/159 Loss: 0.383504
2022-12-22 15:51: Train Epoch 1: 88/159 Loss: 0.347097
2022-12-22 15:51: Train Epoch 1: 89/159 Loss: 0.327516
2022-12-22 15:52: Train Epoch 1: 90/159 Loss: 0.380781
2022-12-22 15:52: Train Epoch 1: 91/159 Loss: 0.354954
2022-12-22 15:52: Train Epoch 1: 92/159 Loss: 0.366904
2022-12-22 15:52: Train Epoch 1: 93/159 Loss: 0.391822
2022-12-22 15:52: Train Epoch 1: 94/159 Loss: 0.353874
2022-12-22 15:53: Train Epoch 1: 95/159 Loss: 0.407945
2022-12-22 15:53: Train Epoch 1: 96/159 Loss: 0.351368
2022-12-22 15:53: Train Epoch 1: 97/159 Loss: 0.376302
2022-12-22 15:53: Train Epoch 1: 98/159 Loss: 0.354000
2022-12-22 15:54: Train Epoch 1: 99/159 Loss: 0.330845
2022-12-22 15:54: Train Epoch 1: 100/159 Loss: 0.378726
2022-12-22 15:54: Train Epoch 1: 101/159 Loss: 0.383635
2022-12-22 15:54: Train Epoch 1: 102/159 Loss: 0.315849
2022-12-22 15:55: Train Epoch 1: 103/159 Loss: 0.307867
2022-12-22 15:55: Train Epoch 1: 104/159 Loss: 0.309955
2022-12-22 15:55: Train Epoch 1: 105/159 Loss: 0.390979
2022-12-22 15:55: Train Epoch 1: 106/159 Loss: 0.279375
2022-12-22 15:55: Train Epoch 1: 107/159 Loss: 0.348094
2022-12-22 15:56: Train Epoch 1: 108/159 Loss: 0.352366
2022-12-22 15:56: Train Epoch 1: 109/159 Loss: 0.368330
2022-12-22 15:56: Train Epoch 1: 110/159 Loss: 0.458465
2022-12-22 15:56: Train Epoch 1: 111/159 Loss: 0.326256
2022-12-22 15:57: Train Epoch 1: 112/159 Loss: 0.340545
2022-12-22 15:57: Train Epoch 1: 113/159 Loss: 0.406266
2022-12-22 15:57: Train Epoch 1: 114/159 Loss: 0.327933
2022-12-22 15:57: Train Epoch 1: 115/159 Loss: 0.357940
2022-12-22 15:58: Train Epoch 1: 116/159 Loss: 0.395024
2022-12-22 15:58: Train Epoch 1: 117/159 Loss: 0.322163
2022-12-22 15:58: Train Epoch 1: 118/159 Loss: 0.319536
2022-12-22 15:58: Train Epoch 1: 119/159 Loss: 0.355632
2022-12-22 15:59: Train Epoch 1: 120/159 Loss: 0.352198
2022-12-22 15:59: Train Epoch 1: 121/159 Loss: 0.332423
2022-12-22 15:59: Train Epoch 1: 122/159 Loss: 0.358156
2022-12-22 15:59: Train Epoch 1: 123/159 Loss: 0.341716
2022-12-22 16:00: Train Epoch 1: 124/159 Loss: 0.359780
2022-12-22 16:00: Train Epoch 1: 125/159 Loss: 0.303056
2022-12-22 16:00: Train Epoch 1: 126/159 Loss: 0.338854
2022-12-22 16:00: Train Epoch 1: 127/159 Loss: 0.335555
2022-12-22 16:01: Train Epoch 1: 128/159 Loss: 0.344441
2022-12-22 16:01: Train Epoch 1: 129/159 Loss: 0.301312
2022-12-22 16:01: Train Epoch 1: 130/159 Loss: 0.338701
2022-12-22 16:02: Train Epoch 1: 131/159 Loss: 0.342969
2022-12-22 16:02: Train Epoch 1: 132/159 Loss: 0.288052
2022-12-22 16:02: Train Epoch 1: 133/159 Loss: 0.382357
2022-12-22 16:02: Train Epoch 1: 134/159 Loss: 0.334794
2022-12-22 16:02: Train Epoch 1: 135/159 Loss: 0.316913
2022-12-22 16:03: Train Epoch 1: 136/159 Loss: 0.332372
2022-12-22 16:03: Train Epoch 1: 137/159 Loss: 0.312820
2022-12-22 16:03: Train Epoch 1: 138/159 Loss: 0.345004
2022-12-22 16:03: Train Epoch 1: 139/159 Loss: 0.335567
2022-12-22 16:04: Train Epoch 1: 140/159 Loss: 0.331086
2022-12-22 16:04: Train Epoch 1: 141/159 Loss: 0.299702
2022-12-22 16:04: Train Epoch 1: 142/159 Loss: 0.315230
2022-12-22 16:04: Train Epoch 1: 143/159 Loss: 0.344134
2022-12-22 16:05: Train Epoch 1: 144/159 Loss: 0.298351
2022-12-22 16:05: Train Epoch 1: 145/159 Loss: 0.309561
2022-12-22 16:05: Train Epoch 1: 146/159 Loss: 0.292459
2022-12-22 16:05: Train Epoch 1: 147/159 Loss: 0.361948
2022-12-22 16:06: Train Epoch 1: 148/159 Loss: 0.308620
2022-12-22 16:06: Train Epoch 1: 149/159 Loss: 0.332476
2022-12-22 16:06: Train Epoch 1: 150/159 Loss: 0.369579
2022-12-22 16:06: Train Epoch 1: 151/159 Loss: 0.325747
2022-12-22 16:07: Train Epoch 1: 152/159 Loss: 0.372075
2022-12-22 16:07: Train Epoch 1: 153/159 Loss: 0.372701
2022-12-22 16:07: Train Epoch 1: 154/159 Loss: 0.330440
2022-12-22 16:07: Train Epoch 1: 155/159 Loss: 0.370430
2022-12-22 16:08: Train Epoch 1: 156/159 Loss: 0.308127
2022-12-22 16:08: Train Epoch 1: 157/159 Loss: 0.328172
2022-12-22 16:08: Train Epoch 1: 158/159 Loss: 0.329341
2022-12-22 16:08: **********Train Epoch 1: averaged Loss: 0.519560 
2022-12-22 16:08: 
Epoch time elapsed: 2279.8714406490326

2022-12-22 16:09: 
 metrics validation: {'precision': 0.6039473684210527, 'recall': 0.7061538461538461, 'f1-score': 0.6510638297872341, 'support': 1300, 'AUC': 0.7894291420118343, 'AUCPR': 0.6920190454384334, 'TP': 918, 'FP': 602, 'TN': 1998, 'FN': 382} 

2022-12-22 16:09: **********Val Epoch 1: average Loss: 0.601264
2022-12-22 16:09: *********************************Current best model saved!
2022-12-22 16:09: ========current best model==============
