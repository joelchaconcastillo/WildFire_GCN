2023-01-06 18:26: log dir: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010618265813519969386
2023-01-06 18:26: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010618265813519969386
2023-01-06 18:26: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=4, log_dir='/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010618265813519969386', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=48, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-06 18:26: Argument batch_size: 256
2023-01-06 18:26: Argument clc: 'vec'
2023-01-06 18:26: Argument cuda: True
2023-01-06 18:26: Argument dataset: '2020'
2023-01-06 18:26: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-06 18:26: Argument debug: False
2023-01-06 18:26: Argument default_graph: True
2023-01-06 18:26: Argument device: 'cpu'
2023-01-06 18:26: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-06 18:26: Argument early_stop: True
2023-01-06 18:26: Argument early_stop_patience: 8
2023-01-06 18:26: Argument embed_dim: 64
2023-01-06 18:26: Argument epochs: 30
2023-01-06 18:26: Argument grad_norm: False
2023-01-06 18:26: Argument horizon: 1
2023-01-06 18:26: Argument input_dim: 25
2023-01-06 18:26: Argument lag: 10
2023-01-06 18:26: Argument link_len: 4
2023-01-06 18:26: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010618265813519969386'
2023-01-06 18:26: Argument log_step: 1
2023-01-06 18:26: Argument loss_func: 'nllloss'
2023-01-06 18:26: Argument lr_decay: True
2023-01-06 18:26: Argument lr_decay_rate: 0.1
2023-01-06 18:26: Argument lr_decay_step: '20'
2023-01-06 18:26: Argument lr_init: 0.0001
2023-01-06 18:26: Argument max_grad_norm: 5
2023-01-06 18:26: Argument minbatch_size: 64
2023-01-06 18:26: Argument mode: 'train'
2023-01-06 18:26: Argument model: 'fire_GCN'
2023-01-06 18:26: Argument nan_fill: -1.0
2023-01-06 18:26: Argument num_layers: 1
2023-01-06 18:26: Argument num_nodes: 625
2023-01-06 18:26: Argument num_workers: 12
2023-01-06 18:26: Argument output_dim: 2
2023-01-06 18:26: Argument patch_height: 25
2023-01-06 18:26: Argument patch_width: 25
2023-01-06 18:26: Argument persistent_workers: True
2023-01-06 18:26: Argument pin_memory: True
2023-01-06 18:26: Argument plot: False
2023-01-06 18:26: Argument positive_weight: 0.5
2023-01-06 18:26: Argument prefetch_factor: 2
2023-01-06 18:26: Argument real_value: True
2023-01-06 18:26: Argument rnn_units: 48
2023-01-06 18:26: Argument seed: 10000
2023-01-06 18:26: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-06 18:26: Argument teacher_forcing: False
2023-01-06 18:26: Argument weight_decay: 0.0
2023-01-06 18:26: Argument window_len: 10
2023-01-06 18:27: Train Epoch 1: 3/24 Loss: 0.586916
2023-01-06 18:27: Train Epoch 1: 7/24 Loss: 0.452986
2023-01-06 18:28: Train Epoch 1: 11/24 Loss: 0.427728
2023-01-06 18:28: Train Epoch 1: 15/24 Loss: 0.335120
2023-01-06 18:28: Train Epoch 1: 19/24 Loss: 0.382618
2023-01-06 18:28: Train Epoch 1: 23/24 Loss: 0.291860
2023-01-06 18:28: **********Train Epoch 1: averaged Loss: 0.412871 
2023-01-06 18:28: 
Epoch time elapsed: 116.81227040290833

2023-01-06 18:29: 
 metrics validation: {'precision': 0.5084525357607282, 'recall': 0.782, 'f1-score': 0.6162332545311268, 'support': 500, 'AUC': 0.7543219999999999, 'AUCPR': 0.6239925680930809, 'TP': 391, 'FP': 378, 'TN': 622, 'FN': 109} 

2023-01-06 18:29: **********Val Epoch 1: average Loss: 0.300363
2023-01-06 18:29: *********************************Current best model saved!
2023-01-06 18:30: 
 Testing metrics {'precision': 0.5403645833333334, 'recall': 0.83, 'f1-score': 0.6545741324921135, 'support': 500, 'AUC': 0.8543019999999999, 'AUCPR': 0.7564649712407273, 'TP': 415, 'FP': 353, 'TN': 647, 'FN': 85} 

2023-01-06 18:30: 
 Testing metrics {'precision': 0.6643159379407616, 'recall': 0.942, 'f1-score': 0.7791563275434242, 'support': 500, 'AUC': 0.9425260000000001, 'AUCPR': 0.8963297983721764, 'TP': 471, 'FP': 238, 'TN': 762, 'FN': 29} 

2023-01-06 18:31: Train Epoch 2: 3/24 Loss: 0.287058
2023-01-06 18:31: Train Epoch 2: 7/24 Loss: 0.255882
2023-01-06 18:32: Train Epoch 2: 11/24 Loss: 0.245788
2023-01-06 18:32: Train Epoch 2: 15/24 Loss: 0.252450
2023-01-06 18:32: Train Epoch 2: 19/24 Loss: 0.271884
2023-01-06 18:32: Train Epoch 2: 23/24 Loss: 0.219850
2023-01-06 18:32: **********Train Epoch 2: averaged Loss: 0.255485 
2023-01-06 18:32: 
Epoch time elapsed: 121.69317483901978

2023-01-06 18:33: 
 metrics validation: {'precision': 0.7389705882352942, 'recall': 0.402, 'f1-score': 0.5207253886010363, 'support': 500, 'AUC': 0.77016, 'AUCPR': 0.6434809166887259, 'TP': 201, 'FP': 71, 'TN': 929, 'FN': 299} 

2023-01-06 18:33: **********Val Epoch 2: average Loss: 0.288592
2023-01-06 18:33: *********************************Current best model saved!
2023-01-06 18:34: 
 Testing metrics {'precision': 0.8298507462686567, 'recall': 0.556, 'f1-score': 0.665868263473054, 'support': 500, 'AUC': 0.862368, 'AUCPR': 0.7789909367291816, 'TP': 278, 'FP': 57, 'TN': 943, 'FN': 222} 

