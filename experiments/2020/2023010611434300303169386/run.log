2023-01-06 11:43: log dir: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611434300303169386
2023-01-06 11:43: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611434300303169386
2023-01-06 11:43: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611434300303169386', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=48, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-06 11:43: Argument batch_size: 256
2023-01-06 11:43: Argument clc: 'vec'
2023-01-06 11:43: Argument cuda: True
2023-01-06 11:43: Argument dataset: '2020'
2023-01-06 11:43: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-06 11:43: Argument debug: False
2023-01-06 11:43: Argument default_graph: True
2023-01-06 11:43: Argument device: 'cpu'
2023-01-06 11:43: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-06 11:43: Argument early_stop: True
2023-01-06 11:43: Argument early_stop_patience: 8
2023-01-06 11:43: Argument embed_dim: 64
2023-01-06 11:43: Argument epochs: 30
2023-01-06 11:43: Argument grad_norm: False
2023-01-06 11:43: Argument horizon: 1
2023-01-06 11:43: Argument input_dim: 25
2023-01-06 11:43: Argument lag: 10
2023-01-06 11:43: Argument link_len: 2
2023-01-06 11:43: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611434300303169386'
2023-01-06 11:43: Argument log_step: 1
2023-01-06 11:43: Argument loss_func: 'nllloss'
2023-01-06 11:43: Argument lr_decay: True
2023-01-06 11:43: Argument lr_decay_rate: 0.1
2023-01-06 11:43: Argument lr_decay_step: '20'
2023-01-06 11:43: Argument lr_init: 0.0001
2023-01-06 11:43: Argument max_grad_norm: 5
2023-01-06 11:43: Argument minbatch_size: 64
2023-01-06 11:43: Argument mode: 'train'
2023-01-06 11:43: Argument model: 'fire_GCN'
2023-01-06 11:43: Argument nan_fill: -1.0
2023-01-06 11:43: Argument num_layers: 1
2023-01-06 11:43: Argument num_nodes: 625
2023-01-06 11:43: Argument num_workers: 12
2023-01-06 11:43: Argument output_dim: 2
2023-01-06 11:43: Argument patch_height: 25
2023-01-06 11:43: Argument patch_width: 25
2023-01-06 11:43: Argument persistent_workers: True
2023-01-06 11:43: Argument pin_memory: True
2023-01-06 11:43: Argument plot: False
2023-01-06 11:43: Argument positive_weight: 0.5
2023-01-06 11:43: Argument prefetch_factor: 2
2023-01-06 11:43: Argument real_value: True
2023-01-06 11:43: Argument rnn_units: 48
2023-01-06 11:43: Argument seed: 10000
2023-01-06 11:43: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-06 11:43: Argument teacher_forcing: False
2023-01-06 11:43: Argument weight_decay: 0.0
2023-01-06 11:43: Argument window_len: 10
2023-01-06 11:43: Train Epoch 1: 3/24 Loss: 0.441037
2023-01-06 11:44: Train Epoch 1: 7/24 Loss: 0.333377
2023-01-06 11:44: Train Epoch 1: 11/24 Loss: 0.345617
2023-01-06 11:44: Train Epoch 1: 15/24 Loss: 0.329607
2023-01-06 11:44: Train Epoch 1: 19/24 Loss: 0.256056
2023-01-06 11:44: Train Epoch 1: 23/24 Loss: 0.205043
2023-01-06 11:44: **********Train Epoch 1: averaged Loss: 0.318456 
2023-01-06 11:44: 
Epoch time elapsed: 72.65604591369629

2023-01-06 11:45: 
 metrics validation: {'precision': 0.6230248306997742, 'recall': 0.552, 'f1-score': 0.5853658536585366, 'support': 500, 'AUC': 0.780718, 'AUCPR': 0.6453977719544531, 'TP': 276, 'FP': 167, 'TN': 833, 'FN': 224} 

2023-01-06 11:45: **********Val Epoch 1: average Loss: 0.255789
2023-01-06 11:45: *********************************Current best model saved!
2023-01-06 11:45: 
 Testing metrics {'precision': 0.7415506958250497, 'recall': 0.746, 'f1-score': 0.7437686939182453, 'support': 500, 'AUC': 0.8581620000000001, 'AUCPR': 0.7767193646787602, 'TP': 373, 'FP': 130, 'TN': 870, 'FN': 127} 

2023-01-06 11:46: 
 Testing metrics {'precision': 0.8421052631578947, 'recall': 0.896, 'f1-score': 0.868217054263566, 'support': 500, 'AUC': 0.9507700000000001, 'AUCPR': 0.9238997759224046, 'TP': 448, 'FP': 84, 'TN': 916, 'FN': 52} 

2023-01-06 11:46: Train Epoch 2: 3/24 Loss: 0.271901
2023-01-06 11:46: Train Epoch 2: 7/24 Loss: 0.281430
2023-01-06 11:46: Train Epoch 2: 11/24 Loss: 0.233421
2023-01-06 11:47: Train Epoch 2: 15/24 Loss: 0.230941
2023-01-06 11:47: Train Epoch 2: 19/24 Loss: 0.220815
2023-01-06 11:47: Train Epoch 2: 23/24 Loss: 0.165835
2023-01-06 11:47: **********Train Epoch 2: averaged Loss: 0.234057 
2023-01-06 11:47: 
Epoch time elapsed: 72.85843086242676

2023-01-06 11:47: 
 metrics validation: {'precision': 0.6532066508313539, 'recall': 0.55, 'f1-score': 0.5971769815418024, 'support': 500, 'AUC': 0.789214, 'AUCPR': 0.6590942030146564, 'TP': 275, 'FP': 146, 'TN': 854, 'FN': 225} 

2023-01-06 11:47: **********Val Epoch 2: average Loss: 0.266061
2023-01-06 11:48: Train Epoch 3: 3/24 Loss: 0.241715
2023-01-06 11:48: Train Epoch 3: 7/24 Loss: 0.263591
2023-01-06 11:48: Train Epoch 3: 11/24 Loss: 0.227270
2023-01-06 11:48: Train Epoch 3: 15/24 Loss: 0.239197
2023-01-06 11:48: Train Epoch 3: 19/24 Loss: 0.248818
2023-01-06 11:49: Train Epoch 3: 23/24 Loss: 0.201038
2023-01-06 11:49: **********Train Epoch 3: averaged Loss: 0.236938 
2023-01-06 11:49: 
Epoch time elapsed: 68.45536184310913

2023-01-06 11:49: 
 metrics validation: {'precision': 0.6375, 'recall': 0.612, 'f1-score': 0.6244897959183673, 'support': 500, 'AUC': 0.79778, 'AUCPR': 0.6701680319142488, 'TP': 306, 'FP': 174, 'TN': 826, 'FN': 194} 

2023-01-06 11:49: **********Val Epoch 3: average Loss: 0.252453
2023-01-06 11:49: *********************************Current best model saved!
2023-01-06 11:49: 
 Testing metrics {'precision': 0.7529880478087649, 'recall': 0.756, 'f1-score': 0.7544910179640718, 'support': 500, 'AUC': 0.864948, 'AUCPR': 0.7869182250335844, 'TP': 378, 'FP': 124, 'TN': 876, 'FN': 122} 

2023-01-06 11:50: 
 Testing metrics {'precision': 0.8355140186915888, 'recall': 0.894, 'f1-score': 0.8637681159420291, 'support': 500, 'AUC': 0.9594419999999998, 'AUCPR': 0.9374726032857359, 'TP': 447, 'FP': 88, 'TN': 912, 'FN': 53} 

2023-01-06 11:50: Train Epoch 4: 3/24 Loss: 0.231213
2023-01-06 11:50: Train Epoch 4: 7/24 Loss: 0.210483
2023-01-06 11:51: Train Epoch 4: 11/24 Loss: 0.209686
2023-01-06 11:51: Train Epoch 4: 15/24 Loss: 0.232204
2023-01-06 11:51: Train Epoch 4: 19/24 Loss: 0.205069
2023-01-06 11:51: Train Epoch 4: 23/24 Loss: 0.182196
2023-01-06 11:51: **********Train Epoch 4: averaged Loss: 0.211809 
2023-01-06 11:51: 
Epoch time elapsed: 73.94614243507385

2023-01-06 11:52: 
 metrics validation: {'precision': 0.7060439560439561, 'recall': 0.514, 'f1-score': 0.5949074074074074, 'support': 500, 'AUC': 0.806812, 'AUCPR': 0.6867269666397202, 'TP': 257, 'FP': 107, 'TN': 893, 'FN': 243} 

2023-01-06 11:52: **********Val Epoch 4: average Loss: 0.257836
2023-01-06 11:52: Train Epoch 5: 3/24 Loss: 0.220243
2023-01-06 11:52: Train Epoch 5: 7/24 Loss: 0.217027
2023-01-06 11:52: Train Epoch 5: 11/24 Loss: 0.233728
2023-01-06 11:52: Train Epoch 5: 15/24 Loss: 0.208862
2023-01-06 11:53: Train Epoch 5: 19/24 Loss: 0.207363
2023-01-06 11:53: Train Epoch 5: 23/24 Loss: 0.208464
2023-01-06 11:53: **********Train Epoch 5: averaged Loss: 0.215948 
2023-01-06 11:53: 
Epoch time elapsed: 72.56736874580383

2023-01-06 11:53: 
 metrics validation: {'precision': 0.6862745098039216, 'recall': 0.63, 'f1-score': 0.656934306569343, 'support': 500, 'AUC': 0.8052520000000001, 'AUCPR': 0.6861946981157708, 'TP': 315, 'FP': 144, 'TN': 856, 'FN': 185} 

2023-01-06 11:53: **********Val Epoch 5: average Loss: 0.251823
2023-01-06 11:53: *********************************Current best model saved!
2023-01-06 11:54: 
 Testing metrics {'precision': 0.7830802603036876, 'recall': 0.722, 'f1-score': 0.7513007284079084, 'support': 500, 'AUC': 0.8687320000000001, 'AUCPR': 0.7918978450236898, 'TP': 361, 'FP': 100, 'TN': 900, 'FN': 139} 

2023-01-06 11:54: 
 Testing metrics {'precision': 0.8587786259541985, 'recall': 0.9, 'f1-score': 0.87890625, 'support': 500, 'AUC': 0.963184, 'AUCPR': 0.9410595600527998, 'TP': 450, 'FP': 74, 'TN': 926, 'FN': 50} 

2023-01-06 11:54: Train Epoch 6: 3/24 Loss: 0.183971
2023-01-06 11:54: Train Epoch 6: 7/24 Loss: 0.210078
2023-01-06 11:55: Train Epoch 6: 11/24 Loss: 0.211444
2023-01-06 11:55: Train Epoch 6: 15/24 Loss: 0.210763
2023-01-06 11:55: Train Epoch 6: 19/24 Loss: 0.205855
2023-01-06 11:55: Train Epoch 6: 23/24 Loss: 0.177933
2023-01-06 11:55: **********Train Epoch 6: averaged Loss: 0.200007 
2023-01-06 11:55: 
Epoch time elapsed: 70.9716100692749

2023-01-06 11:56: 
 metrics validation: {'precision': 0.7342857142857143, 'recall': 0.514, 'f1-score': 0.6047058823529412, 'support': 500, 'AUC': 0.808356, 'AUCPR': 0.6989836313720058, 'TP': 257, 'FP': 93, 'TN': 907, 'FN': 243} 

2023-01-06 11:56: **********Val Epoch 6: average Loss: 0.260040
2023-01-06 11:56: Train Epoch 7: 3/24 Loss: 0.214637
2023-01-06 11:56: Train Epoch 7: 7/24 Loss: 0.200365
2023-01-06 11:56: Train Epoch 7: 11/24 Loss: 0.189423
2023-01-06 11:56: Train Epoch 7: 15/24 Loss: 0.201831
2023-01-06 11:57: Train Epoch 7: 19/24 Loss: 0.214695
2023-01-06 11:57: Train Epoch 7: 23/24 Loss: 0.187644
2023-01-06 11:57: **********Train Epoch 7: averaged Loss: 0.201432 
2023-01-06 11:57: 
Epoch time elapsed: 69.98459386825562

2023-01-06 11:57: 
 metrics validation: {'precision': 0.6981891348088531, 'recall': 0.694, 'f1-score': 0.6960882647943831, 'support': 500, 'AUC': 0.80731, 'AUCPR': 0.6972651744907808, 'TP': 347, 'FP': 150, 'TN': 850, 'FN': 153} 

2023-01-06 11:57: **********Val Epoch 7: average Loss: 0.253129
2023-01-06 11:57: Train Epoch 8: 3/24 Loss: 0.206204
2023-01-06 11:58: Train Epoch 8: 7/24 Loss: 0.215915
2023-01-06 11:58: Train Epoch 8: 11/24 Loss: 0.198241
2023-01-06 11:58: Train Epoch 8: 15/24 Loss: 0.217498
2023-01-06 11:58: Train Epoch 8: 19/24 Loss: 0.219233
2023-01-06 11:58: Train Epoch 8: 23/24 Loss: 0.174190
2023-01-06 11:58: **********Train Epoch 8: averaged Loss: 0.205214 
2023-01-06 11:58: 
Epoch time elapsed: 74.3821210861206

2023-01-06 11:59: 
 metrics validation: {'precision': 0.6855983772819473, 'recall': 0.676, 'f1-score': 0.6807653575025177, 'support': 500, 'AUC': 0.802692, 'AUCPR': 0.6945259759183792, 'TP': 338, 'FP': 155, 'TN': 845, 'FN': 162} 

2023-01-06 11:59: **********Val Epoch 8: average Loss: 0.255166
2023-01-06 11:59: Train Epoch 9: 3/24 Loss: 0.199489
2023-01-06 11:59: Train Epoch 9: 7/24 Loss: 0.210231
2023-01-06 11:59: Train Epoch 9: 11/24 Loss: 0.225504
2023-01-06 12:00: Train Epoch 9: 15/24 Loss: 0.257959
2023-01-06 12:00: Train Epoch 9: 19/24 Loss: 0.183907
2023-01-06 12:00: Train Epoch 9: 23/24 Loss: 0.183443
2023-01-06 12:00: **********Train Epoch 9: averaged Loss: 0.210089 
2023-01-06 12:00: 
Epoch time elapsed: 77.1260027885437

2023-01-06 12:01: 
 metrics validation: {'precision': 0.6522522522522523, 'recall': 0.724, 'f1-score': 0.6862559241706161, 'support': 500, 'AUC': 0.8045180000000001, 'AUCPR': 0.6965461868695125, 'TP': 362, 'FP': 193, 'TN': 807, 'FN': 138} 

2023-01-06 12:01: **********Val Epoch 9: average Loss: 0.253874
2023-01-06 12:01: Train Epoch 10: 3/24 Loss: 0.220301
2023-01-06 12:01: Train Epoch 10: 7/24 Loss: 0.222501
2023-01-06 12:01: Train Epoch 10: 11/24 Loss: 0.221058
2023-01-06 12:01: Train Epoch 10: 15/24 Loss: 0.201185
2023-01-06 12:02: Train Epoch 10: 19/24 Loss: 0.192222
2023-01-06 12:02: Train Epoch 10: 23/24 Loss: 0.185431
2023-01-06 12:02: **********Train Epoch 10: averaged Loss: 0.207116 
2023-01-06 12:02: 
Epoch time elapsed: 70.92065954208374

2023-01-06 12:02: 
 metrics validation: {'precision': 0.7548387096774194, 'recall': 0.468, 'f1-score': 0.5777777777777778, 'support': 500, 'AUC': 0.8046800000000001, 'AUCPR': 0.6972617876947282, 'TP': 234, 'FP': 76, 'TN': 924, 'FN': 266} 

2023-01-06 12:02: **********Val Epoch 10: average Loss: 0.262397
2023-01-06 12:02: Train Epoch 11: 3/24 Loss: 0.207916
2023-01-06 12:03: Train Epoch 11: 7/24 Loss: 0.222950
2023-01-06 12:03: Train Epoch 11: 11/24 Loss: 0.205818
2023-01-06 12:03: Train Epoch 11: 15/24 Loss: 0.200907
2023-01-06 12:03: Train Epoch 11: 19/24 Loss: 0.204617
2023-01-06 12:03: Train Epoch 11: 23/24 Loss: 0.197488
2023-01-06 12:03: **********Train Epoch 11: averaged Loss: 0.206616 
2023-01-06 12:03: 
Epoch time elapsed: 68.89006781578064

2023-01-06 12:04: 
 metrics validation: {'precision': 0.6560150375939849, 'recall': 0.698, 'f1-score': 0.6763565891472869, 'support': 500, 'AUC': 0.800276, 'AUCPR': 0.692410915336264, 'TP': 349, 'FP': 183, 'TN': 817, 'FN': 151} 

2023-01-06 12:04: **********Val Epoch 11: average Loss: 0.256461
2023-01-06 12:04: Train Epoch 12: 3/24 Loss: 0.213430
2023-01-06 12:04: Train Epoch 12: 7/24 Loss: 0.206284
2023-01-06 12:04: Train Epoch 12: 11/24 Loss: 0.207319
2023-01-06 12:05: Train Epoch 12: 15/24 Loss: 0.213159
2023-01-06 12:05: Train Epoch 12: 19/24 Loss: 0.221126
2023-01-06 12:05: Train Epoch 12: 23/24 Loss: 0.166180
2023-01-06 12:05: **********Train Epoch 12: averaged Loss: 0.204583 
2023-01-06 12:05: 
Epoch time elapsed: 71.93415474891663

2023-01-06 12:05: 
 metrics validation: {'precision': 0.7277486910994765, 'recall': 0.556, 'f1-score': 0.6303854875283448, 'support': 500, 'AUC': 0.7993960000000001, 'AUCPR': 0.6925890715033518, 'TP': 278, 'FP': 104, 'TN': 896, 'FN': 222} 

2023-01-06 12:05: **********Val Epoch 12: average Loss: 0.257892
2023-01-06 12:06: Train Epoch 13: 3/24 Loss: 0.212197
2023-01-06 12:06: Train Epoch 13: 7/24 Loss: 0.208034
2023-01-06 12:06: Train Epoch 13: 11/24 Loss: 0.219569
2023-01-06 12:06: Train Epoch 13: 15/24 Loss: 0.207287
2023-01-06 12:06: Train Epoch 13: 19/24 Loss: 0.215651
2023-01-06 12:07: Train Epoch 13: 23/24 Loss: 0.171665
2023-01-06 12:07: **********Train Epoch 13: averaged Loss: 0.205734 
2023-01-06 12:07: 
Epoch time elapsed: 72.0663571357727

2023-01-06 12:07: 
 metrics validation: {'precision': 0.7731958762886598, 'recall': 0.45, 'f1-score': 0.5689001264222503, 'support': 500, 'AUC': 0.801936, 'AUCPR': 0.696222767752233, 'TP': 225, 'FP': 66, 'TN': 934, 'FN': 275} 

2023-01-06 12:07: **********Val Epoch 13: average Loss: 0.268216
2023-01-06 12:07: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-06 12:07: Total training time: 23.7048min, best loss: 0.251823
2023-01-06 12:07: Saving current best model to /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010611434300303169386/best_model.pth
2023-01-06 12:07: 
 Testing metrics {'precision': 0.7830802603036876, 'recall': 0.722, 'f1-score': 0.7513007284079084, 'support': 500, 'AUC': 0.8687320000000001, 'AUCPR': 0.7918978450236898, 'TP': 361, 'FP': 100, 'TN': 900, 'FN': 139} 

2023-01-06 12:08: 
 Testing metrics {'precision': 0.8587786259541985, 'recall': 0.9, 'f1-score': 0.87890625, 'support': 500, 'AUC': 0.963184, 'AUCPR': 0.9410595600527998, 'TP': 450, 'FP': 74, 'TN': 926, 'FN': 50} 

