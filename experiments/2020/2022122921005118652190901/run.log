2022-12-29 21:00: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122921005118652190901
2022-12-29 21:00: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122921005118652190901
2022-12-29 21:00: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=32, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122921005118652190901', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=2, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-29 21:00: Argument batch_size: 256
2022-12-29 21:00: Argument clc: 'vec'
2022-12-29 21:00: Argument cuda: True
2022-12-29 21:00: Argument dataset: '2020'
2022-12-29 21:00: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-29 21:00: Argument debug: False
2022-12-29 21:00: Argument default_graph: True
2022-12-29 21:00: Argument device: 'cpu'
2022-12-29 21:00: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-29 21:00: Argument early_stop: True
2022-12-29 21:00: Argument early_stop_patience: 8
2022-12-29 21:00: Argument embed_dim: 32
2022-12-29 21:00: Argument epochs: 30
2022-12-29 21:00: Argument grad_norm: False
2022-12-29 21:00: Argument horizon: 1
2022-12-29 21:00: Argument input_dim: 25
2022-12-29 21:00: Argument lag: 10
2022-12-29 21:00: Argument link_len: 2
2022-12-29 21:00: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122921005118652190901'
2022-12-29 21:00: Argument log_step: 1
2022-12-29 21:00: Argument loss_func: 'nllloss'
2022-12-29 21:00: Argument lr_decay: True
2022-12-29 21:00: Argument lr_decay_rate: 0.1
2022-12-29 21:00: Argument lr_decay_step: '15, 20'
2022-12-29 21:00: Argument lr_init: 0.0001
2022-12-29 21:00: Argument max_grad_norm: 5
2022-12-29 21:00: Argument minbatch_size: 64
2022-12-29 21:00: Argument mode: 'train'
2022-12-29 21:00: Argument model: 'fire_GCN'
2022-12-29 21:00: Argument nan_fill: -1.0
2022-12-29 21:00: Argument num_layers: 2
2022-12-29 21:00: Argument num_nodes: 625
2022-12-29 21:00: Argument num_workers: 20
2022-12-29 21:00: Argument output_dim: 2
2022-12-29 21:00: Argument patch_height: 25
2022-12-29 21:00: Argument patch_width: 25
2022-12-29 21:00: Argument persistent_workers: True
2022-12-29 21:00: Argument pin_memory: True
2022-12-29 21:00: Argument plot: False
2022-12-29 21:00: Argument positive_weight: 0.5
2022-12-29 21:00: Argument prefetch_factor: 2
2022-12-29 21:00: Argument real_value: True
2022-12-29 21:00: Argument rnn_units: 16
2022-12-29 21:00: Argument seed: 10000
2022-12-29 21:00: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-29 21:00: Argument teacher_forcing: False
2022-12-29 21:00: Argument weight_decay: 0.0
2022-12-29 21:00: Argument window_len: 10
2022-12-29 21:01: Train Epoch 1: 3/244 Loss: 0.462687
2022-12-29 21:01: Train Epoch 1: 7/244 Loss: 0.390681
2022-12-29 21:01: Train Epoch 1: 11/244 Loss: 0.408197
2022-12-29 21:01: Train Epoch 1: 15/244 Loss: 0.338922
2022-12-29 21:01: Train Epoch 1: 19/244 Loss: 0.295033
2022-12-29 21:02: Train Epoch 1: 23/244 Loss: 0.280223
2022-12-29 21:02: Train Epoch 1: 27/244 Loss: 0.244901
2022-12-29 21:02: Train Epoch 1: 31/244 Loss: 0.250656
2022-12-29 21:02: Train Epoch 1: 35/244 Loss: 0.245833
2022-12-29 21:02: Train Epoch 1: 39/244 Loss: 0.238274
2022-12-29 21:02: Train Epoch 1: 43/244 Loss: 0.221231
2022-12-29 21:03: Train Epoch 1: 47/244 Loss: 0.222162
2022-12-29 21:03: Train Epoch 1: 51/244 Loss: 0.218123
2022-12-29 21:03: Train Epoch 1: 55/244 Loss: 0.241817
2022-12-29 21:03: Train Epoch 1: 59/244 Loss: 0.236505
2022-12-29 21:03: Train Epoch 1: 63/244 Loss: 0.222169
2022-12-29 21:04: Train Epoch 1: 67/244 Loss: 0.204419
2022-12-29 21:04: Train Epoch 1: 71/244 Loss: 0.222601
2022-12-29 21:04: Train Epoch 1: 75/244 Loss: 0.194356
2022-12-29 21:04: Train Epoch 1: 79/244 Loss: 0.224749
2022-12-29 21:04: Train Epoch 1: 83/244 Loss: 0.196116
2022-12-29 21:04: Train Epoch 1: 87/244 Loss: 0.202321
2022-12-29 21:05: Train Epoch 1: 91/244 Loss: 0.213822
2022-12-29 21:05: Train Epoch 1: 95/244 Loss: 0.207888
2022-12-29 21:05: Train Epoch 1: 99/244 Loss: 0.241300
2022-12-29 21:05: Train Epoch 1: 103/244 Loss: 0.196875
2022-12-29 21:05: Train Epoch 1: 107/244 Loss: 0.176817
2022-12-29 21:06: Train Epoch 1: 111/244 Loss: 0.206785
2022-12-29 21:06: Train Epoch 1: 115/244 Loss: 0.191345
2022-12-29 21:06: Train Epoch 1: 119/244 Loss: 0.229773
2022-12-29 21:06: Train Epoch 1: 123/244 Loss: 0.195929
2022-12-29 21:06: Train Epoch 1: 127/244 Loss: 0.190590
2022-12-29 21:06: Train Epoch 1: 131/244 Loss: 0.210331
2022-12-29 21:07: Train Epoch 1: 135/244 Loss: 0.237437
2022-12-29 21:07: Train Epoch 1: 139/244 Loss: 0.197961
2022-12-29 21:07: Train Epoch 1: 143/244 Loss: 0.220367
2022-12-29 21:07: Train Epoch 1: 147/244 Loss: 0.198147
2022-12-29 21:07: Train Epoch 1: 151/244 Loss: 0.180560
2022-12-29 21:07: Train Epoch 1: 155/244 Loss: 0.230700
2022-12-29 21:08: Train Epoch 1: 159/244 Loss: 0.206591
2022-12-29 21:08: Train Epoch 1: 163/244 Loss: 0.223417
2022-12-29 21:08: Train Epoch 1: 167/244 Loss: 0.206608
2022-12-29 21:08: Train Epoch 1: 171/244 Loss: 0.211995
2022-12-29 21:08: Train Epoch 1: 175/244 Loss: 0.207761
2022-12-29 21:08: Train Epoch 1: 179/244 Loss: 0.185188
2022-12-29 21:09: Train Epoch 1: 183/244 Loss: 0.185219
2022-12-29 21:09: Train Epoch 1: 187/244 Loss: 0.175317
2022-12-29 21:09: Train Epoch 1: 191/244 Loss: 0.201509
2022-12-29 21:09: Train Epoch 1: 195/244 Loss: 0.195186
2022-12-29 21:09: Train Epoch 1: 199/244 Loss: 0.216227
2022-12-29 21:09: Train Epoch 1: 203/244 Loss: 0.195630
2022-12-29 21:10: Train Epoch 1: 207/244 Loss: 0.179765
2022-12-29 21:10: Train Epoch 1: 211/244 Loss: 0.201674
2022-12-29 21:10: Train Epoch 1: 215/244 Loss: 0.177201
2022-12-29 21:10: Train Epoch 1: 219/244 Loss: 0.184525
2022-12-29 21:10: Train Epoch 1: 223/244 Loss: 0.198142
2022-12-29 21:11: Train Epoch 1: 227/244 Loss: 0.205699
2022-12-29 21:11: Train Epoch 1: 231/244 Loss: 0.181290
2022-12-29 21:11: Train Epoch 1: 235/244 Loss: 0.247172
2022-12-29 21:11: Train Epoch 1: 239/244 Loss: 0.200892
2022-12-29 21:11: Train Epoch 1: 243/244 Loss: 0.183525
2022-12-29 21:11: **********Train Epoch 1: averaged Loss: 0.223920 
2022-12-29 21:11: 
Epoch time elapsed: 654.9644315242767

2022-12-29 21:13: 
 metrics validation: {'precision': 0.6808510638297872, 'recall': 0.5907692307692308, 'f1-score': 0.6326194398682043, 'support': 1300, 'AUC': 0.8094269230769231, 'AUCPR': 0.6906913753048347, 'TP': 768, 'FP': 360, 'TN': 2240, 'FN': 532} 

2022-12-29 21:13: **********Val Epoch 1: average Loss: 0.256078
2022-12-29 21:13: *********************************Current best model saved!
2022-12-29 21:13: 
 Testing metrics {'precision': 0.757679180887372, 'recall': 0.7231270358306189, 'f1-score': 0.7399999999999999, 'support': 1228, 'AUC': 0.8554195535231143, 'AUCPR': 0.7859597644551333, 'TP': 888, 'FP': 284, 'TN': 2172, 'FN': 340} 

2022-12-29 21:17: 
 Testing metrics {'precision': 0.8918918918918919, 'recall': 0.8835942818243703, 'f1-score': 0.8877236977088795, 'support': 4407, 'AUC': 0.9634872404500772, 'AUCPR': 0.925227219054773, 'TP': 3894, 'FP': 472, 'TN': 8342, 'FN': 513} 

2022-12-29 21:17: Train Epoch 2: 3/244 Loss: 0.183763
2022-12-29 21:17: Train Epoch 2: 7/244 Loss: 0.186231
2022-12-29 21:17: Train Epoch 2: 11/244 Loss: 0.190937
2022-12-29 21:17: Train Epoch 2: 15/244 Loss: 0.207934
2022-12-29 21:18: Train Epoch 2: 19/244 Loss: 0.218028
2022-12-29 21:18: Train Epoch 2: 23/244 Loss: 0.179134
2022-12-29 21:18: Train Epoch 2: 27/244 Loss: 0.159417
2022-12-29 21:18: Train Epoch 2: 31/244 Loss: 0.169663
2022-12-29 21:18: Train Epoch 2: 35/244 Loss: 0.171815
2022-12-29 21:19: Train Epoch 2: 39/244 Loss: 0.190486
2022-12-29 21:19: Train Epoch 2: 43/244 Loss: 0.198567
2022-12-29 21:19: Train Epoch 2: 47/244 Loss: 0.186948
2022-12-29 21:19: Train Epoch 2: 51/244 Loss: 0.175022
2022-12-29 21:19: Train Epoch 2: 55/244 Loss: 0.176788
2022-12-29 21:19: Train Epoch 2: 59/244 Loss: 0.187302
2022-12-29 21:20: Train Epoch 2: 63/244 Loss: 0.172180
2022-12-29 21:20: Train Epoch 2: 67/244 Loss: 0.175659
2022-12-29 21:20: Train Epoch 2: 71/244 Loss: 0.157177
2022-12-29 21:20: Train Epoch 2: 75/244 Loss: 0.210245
2022-12-29 21:20: Train Epoch 2: 79/244 Loss: 0.168095
2022-12-29 21:21: Train Epoch 2: 83/244 Loss: 0.179645
2022-12-29 21:21: Train Epoch 2: 87/244 Loss: 0.191589
2022-12-29 21:21: Train Epoch 2: 91/244 Loss: 0.186657
2022-12-29 21:21: Train Epoch 2: 95/244 Loss: 0.179835
2022-12-29 21:21: Train Epoch 2: 99/244 Loss: 0.194832
2022-12-29 21:22: Train Epoch 2: 103/244 Loss: 0.187276
2022-12-29 21:22: Train Epoch 2: 107/244 Loss: 0.165799
2022-12-29 21:22: Train Epoch 2: 111/244 Loss: 0.186436
2022-12-29 21:22: Train Epoch 2: 115/244 Loss: 0.217728
2022-12-29 21:22: Train Epoch 2: 119/244 Loss: 0.162907
2022-12-29 21:22: Train Epoch 2: 123/244 Loss: 0.178590
2022-12-29 21:23: Train Epoch 2: 127/244 Loss: 0.198905
2022-12-29 21:23: Train Epoch 2: 131/244 Loss: 0.161594
2022-12-29 21:23: Train Epoch 2: 135/244 Loss: 0.168747
2022-12-29 21:23: Train Epoch 2: 139/244 Loss: 0.182634
2022-12-29 21:23: Train Epoch 2: 143/244 Loss: 0.184852
2022-12-29 21:23: Train Epoch 2: 147/244 Loss: 0.157415
2022-12-29 21:24: Train Epoch 2: 151/244 Loss: 0.166850
2022-12-29 21:24: Train Epoch 2: 155/244 Loss: 0.177302
2022-12-29 21:24: Train Epoch 2: 159/244 Loss: 0.158830
2022-12-29 21:24: Train Epoch 2: 163/244 Loss: 0.181976
2022-12-29 21:24: Train Epoch 2: 167/244 Loss: 0.182884
2022-12-29 21:24: Train Epoch 2: 171/244 Loss: 0.164232
2022-12-29 21:25: Train Epoch 2: 175/244 Loss: 0.163010
2022-12-29 21:25: Train Epoch 2: 179/244 Loss: 0.155060
2022-12-29 21:25: Train Epoch 2: 183/244 Loss: 0.167019
2022-12-29 21:25: Train Epoch 2: 187/244 Loss: 0.170151
2022-12-29 21:25: Train Epoch 2: 191/244 Loss: 0.180741
2022-12-29 21:26: Train Epoch 2: 195/244 Loss: 0.175354
2022-12-29 21:26: Train Epoch 2: 199/244 Loss: 0.184283
2022-12-29 21:26: Train Epoch 2: 203/244 Loss: 0.187738
2022-12-29 21:26: Train Epoch 2: 207/244 Loss: 0.177919
2022-12-29 21:26: Train Epoch 2: 211/244 Loss: 0.181854
2022-12-29 21:26: Train Epoch 2: 215/244 Loss: 0.176402
2022-12-29 21:27: Train Epoch 2: 219/244 Loss: 0.175985
2022-12-29 21:27: Train Epoch 2: 223/244 Loss: 0.170378
2022-12-29 21:27: Train Epoch 2: 227/244 Loss: 0.162769
2022-12-29 21:27: Train Epoch 2: 231/244 Loss: 0.166620
2022-12-29 21:28: Train Epoch 2: 235/244 Loss: 0.204040
2022-12-29 21:28: Train Epoch 2: 239/244 Loss: 0.184875
2022-12-29 21:28: Train Epoch 2: 243/244 Loss: 0.189015
2022-12-29 21:28: **********Train Epoch 2: averaged Loss: 0.179608 
2022-12-29 21:28: 
Epoch time elapsed: 686.5927653312683

2022-12-29 21:29: 
 metrics validation: {'precision': 0.9057750759878419, 'recall': 0.22923076923076924, 'f1-score': 0.36586863106200124, 'support': 1300, 'AUC': 0.8420943786982248, 'AUCPR': 0.7592377402651387, 'TP': 298, 'FP': 31, 'TN': 2569, 'FN': 1002} 

2022-12-29 21:29: **********Val Epoch 2: average Loss: 0.297318
2022-12-29 21:30: 
 Testing metrics {'precision': 0.757679180887372, 'recall': 0.7231270358306189, 'f1-score': 0.7399999999999999, 'support': 1228, 'AUC': 0.8554195535231143, 'AUCPR': 0.7859597644551333, 'TP': 888, 'FP': 284, 'TN': 2172, 'FN': 340} 

2022-12-29 21:33: 
 Testing metrics {'precision': 0.8918918918918919, 'recall': 0.8835942818243703, 'f1-score': 0.8877236977088795, 'support': 4407, 'AUC': 0.9634872404500772, 'AUCPR': 0.925227219054773, 'TP': 3894, 'FP': 472, 'TN': 8342, 'FN': 513} 

2022-12-29 21:33: Train Epoch 3: 3/244 Loss: 0.175105
2022-12-29 21:33: Train Epoch 3: 7/244 Loss: 0.196275
2022-12-29 21:33: Train Epoch 3: 11/244 Loss: 0.196767
2022-12-29 21:34: Train Epoch 3: 15/244 Loss: 0.189851
2022-12-29 21:34: Train Epoch 3: 19/244 Loss: 0.177537
2022-12-29 21:34: Train Epoch 3: 23/244 Loss: 0.151661
2022-12-29 21:34: Train Epoch 3: 27/244 Loss: 0.173154
2022-12-29 21:34: Train Epoch 3: 31/244 Loss: 0.204127
2022-12-29 21:34: Train Epoch 3: 35/244 Loss: 0.176802
2022-12-29 21:35: Train Epoch 3: 39/244 Loss: 0.186781
2022-12-29 21:35: Train Epoch 3: 43/244 Loss: 0.211647
2022-12-29 21:35: Train Epoch 3: 47/244 Loss: 0.189545
2022-12-29 21:35: Train Epoch 3: 51/244 Loss: 0.209130
2022-12-29 21:35: Train Epoch 3: 55/244 Loss: 0.177334
2022-12-29 21:36: Train Epoch 3: 59/244 Loss: 0.179645
2022-12-29 21:36: Train Epoch 3: 63/244 Loss: 0.183259
2022-12-29 21:36: Train Epoch 3: 67/244 Loss: 0.186000
2022-12-29 21:36: Train Epoch 3: 71/244 Loss: 0.195671
2022-12-29 21:36: Train Epoch 3: 75/244 Loss: 0.201496
2022-12-29 21:36: Train Epoch 3: 79/244 Loss: 0.179659
2022-12-29 21:37: Train Epoch 3: 83/244 Loss: 0.193757
2022-12-29 21:37: Train Epoch 3: 87/244 Loss: 0.177875
2022-12-29 21:37: Train Epoch 3: 91/244 Loss: 0.217294
2022-12-29 21:37: Train Epoch 3: 95/244 Loss: 0.152503
2022-12-29 21:37: Train Epoch 3: 99/244 Loss: 0.211601
2022-12-29 21:37: Train Epoch 3: 103/244 Loss: 0.173707
2022-12-29 21:38: Train Epoch 3: 107/244 Loss: 0.203652
2022-12-29 21:38: Train Epoch 3: 111/244 Loss: 0.188501
2022-12-29 21:38: Train Epoch 3: 115/244 Loss: 0.182687
2022-12-29 21:38: Train Epoch 3: 119/244 Loss: 0.182572
2022-12-29 21:38: Train Epoch 3: 123/244 Loss: 0.193495
2022-12-29 21:39: Train Epoch 3: 127/244 Loss: 0.208942
2022-12-29 21:39: Train Epoch 3: 131/244 Loss: 0.168553
2022-12-29 21:39: Train Epoch 3: 135/244 Loss: 0.171872
2022-12-29 21:39: Train Epoch 3: 139/244 Loss: 0.205582
2022-12-29 21:39: Train Epoch 3: 143/244 Loss: 0.170416
2022-12-29 21:39: Train Epoch 3: 147/244 Loss: 0.164843
2022-12-29 21:39: Train Epoch 3: 151/244 Loss: 0.163322
2022-12-29 21:40: Train Epoch 3: 155/244 Loss: 0.183916
2022-12-29 21:40: Train Epoch 3: 159/244 Loss: 0.186123
2022-12-29 21:40: Train Epoch 3: 163/244 Loss: 0.173676
2022-12-29 21:40: Train Epoch 3: 167/244 Loss: 0.194046
2022-12-29 21:40: Train Epoch 3: 171/244 Loss: 0.176067
2022-12-29 21:41: Train Epoch 3: 175/244 Loss: 0.169108
2022-12-29 21:41: Train Epoch 3: 179/244 Loss: 0.167449
2022-12-29 21:41: Train Epoch 3: 183/244 Loss: 0.192082
2022-12-29 21:41: Train Epoch 3: 187/244 Loss: 0.167358
2022-12-29 21:41: Train Epoch 3: 191/244 Loss: 0.200967
2022-12-29 21:42: Train Epoch 3: 195/244 Loss: 0.164530
2022-12-29 21:42: Train Epoch 3: 199/244 Loss: 0.180336
2022-12-29 21:42: Train Epoch 3: 203/244 Loss: 0.158726
2022-12-29 21:42: Train Epoch 3: 207/244 Loss: 0.182523
2022-12-29 21:42: Train Epoch 3: 211/244 Loss: 0.180806
2022-12-29 21:43: Train Epoch 3: 215/244 Loss: 0.181036
2022-12-29 21:43: Train Epoch 3: 219/244 Loss: 0.178174
2022-12-29 21:43: Train Epoch 3: 223/244 Loss: 0.180595
2022-12-29 21:43: Train Epoch 3: 227/244 Loss: 0.230557
2022-12-29 21:44: Train Epoch 3: 231/244 Loss: 0.173555
2022-12-29 21:44: Train Epoch 3: 235/244 Loss: 0.143488
2022-12-29 21:44: Train Epoch 3: 239/244 Loss: 0.186026
2022-12-29 21:44: Train Epoch 3: 243/244 Loss: 0.158187
2022-12-29 21:44: **********Train Epoch 3: averaged Loss: 0.183311 
2022-12-29 21:44: 
Epoch time elapsed: 683.4191420078278

2022-12-29 21:45: 
 metrics validation: {'precision': 0.8095238095238095, 'recall': 0.4969230769230769, 'f1-score': 0.6158245948522403, 'support': 1300, 'AUC': 0.8313600591715976, 'AUCPR': 0.7409605975887406, 'TP': 646, 'FP': 152, 'TN': 2448, 'FN': 654} 

2022-12-29 21:45: **********Val Epoch 3: average Loss: 0.269424
2022-12-29 21:46: 
 Testing metrics {'precision': 0.757679180887372, 'recall': 0.7231270358306189, 'f1-score': 0.7399999999999999, 'support': 1228, 'AUC': 0.8554195535231143, 'AUCPR': 0.7859597644551333, 'TP': 888, 'FP': 284, 'TN': 2172, 'FN': 340} 

2022-12-29 21:49: 
 Testing metrics {'precision': 0.8918918918918919, 'recall': 0.8835942818243703, 'f1-score': 0.8877236977088795, 'support': 4407, 'AUC': 0.9634872404500772, 'AUCPR': 0.925227219054773, 'TP': 3894, 'FP': 472, 'TN': 8342, 'FN': 513} 

2022-12-29 21:49: Train Epoch 4: 3/244 Loss: 0.195514
2022-12-29 21:49: Train Epoch 4: 7/244 Loss: 0.206462
2022-12-29 21:49: Train Epoch 4: 11/244 Loss: 0.189212
2022-12-29 21:50: Train Epoch 4: 15/244 Loss: 0.187454
2022-12-29 21:50: Train Epoch 4: 19/244 Loss: 0.186285
2022-12-29 21:50: Train Epoch 4: 23/244 Loss: 0.188685
2022-12-29 21:50: Train Epoch 4: 27/244 Loss: 0.175172
2022-12-29 21:50: Train Epoch 4: 31/244 Loss: 0.209740
2022-12-29 21:51: Train Epoch 4: 35/244 Loss: 0.135676
2022-12-29 21:51: Train Epoch 4: 39/244 Loss: 0.171248
2022-12-29 21:51: Train Epoch 4: 43/244 Loss: 0.192657
2022-12-29 21:51: Train Epoch 4: 47/244 Loss: 0.191851
2022-12-29 21:51: Train Epoch 4: 51/244 Loss: 0.170410
2022-12-29 21:52: Train Epoch 4: 55/244 Loss: 0.189669
2022-12-29 21:52: Train Epoch 4: 59/244 Loss: 0.188560
2022-12-29 21:52: Train Epoch 4: 63/244 Loss: 0.193148
2022-12-29 21:52: Train Epoch 4: 67/244 Loss: 0.188118
2022-12-29 21:52: Train Epoch 4: 71/244 Loss: 0.176641
2022-12-29 21:52: Train Epoch 4: 75/244 Loss: 0.170707
2022-12-29 21:53: Train Epoch 4: 79/244 Loss: 0.225719
2022-12-29 21:53: Train Epoch 4: 83/244 Loss: 0.212838
2022-12-29 21:53: Train Epoch 4: 87/244 Loss: 0.172076
2022-12-29 21:53: Train Epoch 4: 91/244 Loss: 0.202232
2022-12-29 21:53: Train Epoch 4: 95/244 Loss: 0.209709
2022-12-29 21:53: Train Epoch 4: 99/244 Loss: 0.180510
2022-12-29 21:54: Train Epoch 4: 103/244 Loss: 0.186240
2022-12-29 21:54: Train Epoch 4: 107/244 Loss: 0.161785
2022-12-29 21:54: Train Epoch 4: 111/244 Loss: 0.188086
2022-12-29 21:54: Train Epoch 4: 115/244 Loss: 0.207726
2022-12-29 21:54: Train Epoch 4: 119/244 Loss: 0.181395
2022-12-29 21:55: Train Epoch 4: 123/244 Loss: 0.193989
2022-12-29 21:55: Train Epoch 4: 127/244 Loss: 0.166436
2022-12-29 21:55: Train Epoch 4: 131/244 Loss: 0.195660
2022-12-29 21:55: Train Epoch 4: 135/244 Loss: 0.163144
2022-12-29 21:55: Train Epoch 4: 139/244 Loss: 0.181490
2022-12-29 21:55: Train Epoch 4: 143/244 Loss: 0.174366
2022-12-29 21:55: Train Epoch 4: 147/244 Loss: 0.180262
2022-12-29 21:56: Train Epoch 4: 151/244 Loss: 0.176584
2022-12-29 21:56: Train Epoch 4: 155/244 Loss: 0.192222
2022-12-29 21:56: Train Epoch 4: 159/244 Loss: 0.171065
2022-12-29 21:56: Train Epoch 4: 163/244 Loss: 0.160677
2022-12-29 21:56: Train Epoch 4: 167/244 Loss: 0.168620
2022-12-29 21:57: Train Epoch 4: 171/244 Loss: 0.166043
2022-12-29 21:57: Train Epoch 4: 175/244 Loss: 0.161765
2022-12-29 21:57: Train Epoch 4: 179/244 Loss: 0.216618
2022-12-29 21:57: Train Epoch 4: 183/244 Loss: 0.177544
2022-12-29 21:57: Train Epoch 4: 187/244 Loss: 0.184216
2022-12-29 21:57: Train Epoch 4: 191/244 Loss: 0.166142
2022-12-29 21:58: Train Epoch 4: 195/244 Loss: 0.211972
2022-12-29 21:58: Train Epoch 4: 199/244 Loss: 0.193209
2022-12-29 21:58: Train Epoch 4: 203/244 Loss: 0.142670
2022-12-29 21:58: Train Epoch 4: 207/244 Loss: 0.237325
2022-12-29 21:59: Train Epoch 4: 211/244 Loss: 0.190772
2022-12-29 21:59: Train Epoch 4: 215/244 Loss: 0.176593
2022-12-29 21:59: Train Epoch 4: 219/244 Loss: 0.147455
2022-12-29 21:59: Train Epoch 4: 223/244 Loss: 0.188399
2022-12-29 22:00: Train Epoch 4: 227/244 Loss: 0.171606
2022-12-29 22:00: Train Epoch 4: 231/244 Loss: 0.172623
2022-12-29 22:00: Train Epoch 4: 235/244 Loss: 0.197932
2022-12-29 22:00: Train Epoch 4: 239/244 Loss: 0.150528
2022-12-29 22:00: Train Epoch 4: 243/244 Loss: 0.189093
2022-12-29 22:00: **********Train Epoch 4: averaged Loss: 0.183648 
2022-12-29 22:00: 
Epoch time elapsed: 685.3020594120026

2022-12-29 22:01: 
 metrics validation: {'precision': 0.8809523809523809, 'recall': 0.2561538461538462, 'f1-score': 0.39690107270560193, 'support': 1300, 'AUC': 0.8377218934911244, 'AUCPR': 0.7514106779977554, 'TP': 333, 'FP': 45, 'TN': 2555, 'FN': 967} 

2022-12-29 22:01: **********Val Epoch 4: average Loss: 0.297292
2022-12-29 22:02: 
 Testing metrics {'precision': 0.757679180887372, 'recall': 0.7231270358306189, 'f1-score': 0.7399999999999999, 'support': 1228, 'AUC': 0.8554195535231143, 'AUCPR': 0.7859597644551333, 'TP': 888, 'FP': 284, 'TN': 2172, 'FN': 340} 

2022-12-29 22:05: 
 Testing metrics {'precision': 0.8918918918918919, 'recall': 0.8835942818243703, 'f1-score': 0.8877236977088795, 'support': 4407, 'AUC': 0.9634872404500772, 'AUCPR': 0.925227219054773, 'TP': 3894, 'FP': 472, 'TN': 8342, 'FN': 513} 

2022-12-29 22:05: Train Epoch 5: 3/244 Loss: 0.170703
2022-12-29 22:06: Train Epoch 5: 7/244 Loss: 0.175810
2022-12-29 22:06: Train Epoch 5: 11/244 Loss: 0.170716
2022-12-29 22:06: Train Epoch 5: 15/244 Loss: 0.203917
2022-12-29 22:06: Train Epoch 5: 19/244 Loss: 0.188347
2022-12-29 22:06: Train Epoch 5: 23/244 Loss: 0.224864
2022-12-29 22:06: Train Epoch 5: 27/244 Loss: 0.196835
2022-12-29 22:07: Train Epoch 5: 31/244 Loss: 0.174669
2022-12-29 22:07: Train Epoch 5: 35/244 Loss: 0.159341
2022-12-29 22:07: Train Epoch 5: 39/244 Loss: 0.209737
2022-12-29 22:07: Train Epoch 5: 43/244 Loss: 0.179417
2022-12-29 22:07: Train Epoch 5: 47/244 Loss: 0.180647
2022-12-29 22:07: Train Epoch 5: 51/244 Loss: 0.190933
2022-12-29 22:08: Train Epoch 5: 55/244 Loss: 0.183620
2022-12-29 22:08: Train Epoch 5: 59/244 Loss: 0.164703
2022-12-29 22:08: Train Epoch 5: 63/244 Loss: 0.183845
2022-12-29 22:08: Train Epoch 5: 67/244 Loss: 0.182713
2022-12-29 22:08: Train Epoch 5: 71/244 Loss: 0.181585
2022-12-29 22:09: Train Epoch 5: 75/244 Loss: 0.204116
2022-12-29 22:09: Train Epoch 5: 79/244 Loss: 0.194205
2022-12-29 22:09: Train Epoch 5: 83/244 Loss: 0.182273
2022-12-29 22:09: Train Epoch 5: 87/244 Loss: 0.224458
2022-12-29 22:09: Train Epoch 5: 91/244 Loss: 0.154931
2022-12-29 22:09: Train Epoch 5: 95/244 Loss: 0.171772
2022-12-29 22:10: Train Epoch 5: 99/244 Loss: 0.193322
2022-12-29 22:10: Train Epoch 5: 103/244 Loss: 0.188903
2022-12-29 22:10: Train Epoch 5: 107/244 Loss: 0.172803
2022-12-29 22:10: Train Epoch 5: 111/244 Loss: 0.173151
2022-12-29 22:10: Train Epoch 5: 115/244 Loss: 0.166278
2022-12-29 22:10: Train Epoch 5: 119/244 Loss: 0.146173
2022-12-29 22:11: Train Epoch 5: 123/244 Loss: 0.179379
2022-12-29 22:11: Train Epoch 5: 127/244 Loss: 0.159965
2022-12-29 22:11: Train Epoch 5: 131/244 Loss: 0.155293
2022-12-29 22:11: Train Epoch 5: 135/244 Loss: 0.173218
2022-12-29 22:11: Train Epoch 5: 139/244 Loss: 0.195152
2022-12-29 22:11: Train Epoch 5: 143/244 Loss: 0.237880
2022-12-29 22:12: Train Epoch 5: 147/244 Loss: 0.181245
2022-12-29 22:12: Train Epoch 5: 151/244 Loss: 0.182806
2022-12-29 22:12: Train Epoch 5: 155/244 Loss: 0.148435
2022-12-29 22:12: Train Epoch 5: 159/244 Loss: 0.171366
2022-12-29 22:12: Train Epoch 5: 163/244 Loss: 0.195213
2022-12-29 22:12: Train Epoch 5: 167/244 Loss: 0.195498
2022-12-29 22:13: Train Epoch 5: 171/244 Loss: 0.169337
2022-12-29 22:13: Train Epoch 5: 175/244 Loss: 0.186632
2022-12-29 22:13: Train Epoch 5: 179/244 Loss: 0.153150
2022-12-29 22:13: Train Epoch 5: 183/244 Loss: 0.190782
2022-12-29 22:13: Train Epoch 5: 187/244 Loss: 0.192218
2022-12-29 22:14: Train Epoch 5: 191/244 Loss: 0.182765
2022-12-29 22:14: Train Epoch 5: 195/244 Loss: 0.167928
2022-12-29 22:14: Train Epoch 5: 199/244 Loss: 0.170195
2022-12-29 22:14: Train Epoch 5: 203/244 Loss: 0.177746
2022-12-29 22:14: Train Epoch 5: 207/244 Loss: 0.172473
2022-12-29 22:15: Train Epoch 5: 211/244 Loss: 0.157441
2022-12-29 22:15: Train Epoch 5: 215/244 Loss: 0.182211
2022-12-29 22:15: Train Epoch 5: 219/244 Loss: 0.197932
2022-12-29 22:15: Train Epoch 5: 223/244 Loss: 0.156302
2022-12-29 22:16: Train Epoch 5: 227/244 Loss: 0.156963
2022-12-29 22:16: Train Epoch 5: 231/244 Loss: 0.175578
2022-12-29 22:16: Train Epoch 5: 235/244 Loss: 0.165858
2022-12-29 22:16: Train Epoch 5: 239/244 Loss: 0.165402
2022-12-29 22:16: Train Epoch 5: 243/244 Loss: 0.173889
2022-12-29 22:16: **********Train Epoch 5: averaged Loss: 0.179755 
2022-12-29 22:16: 
Epoch time elapsed: 662.0186657905579

2022-12-29 22:17: 
 metrics validation: {'precision': 0.8155583437892095, 'recall': 0.5, 'f1-score': 0.619933237958989, 'support': 1300, 'AUC': 0.8377236686390532, 'AUCPR': 0.7525212767402748, 'TP': 650, 'FP': 147, 'TN': 2453, 'FN': 650} 

2022-12-29 22:17: **********Val Epoch 5: average Loss: 0.259144
2022-12-29 22:18: 
 Testing metrics {'precision': 0.757679180887372, 'recall': 0.7231270358306189, 'f1-score': 0.7399999999999999, 'support': 1228, 'AUC': 0.8554195535231143, 'AUCPR': 0.7859597644551333, 'TP': 888, 'FP': 284, 'TN': 2172, 'FN': 340} 

2022-12-29 22:21: 
 Testing metrics {'precision': 0.8918918918918919, 'recall': 0.8835942818243703, 'f1-score': 0.8877236977088795, 'support': 4407, 'AUC': 0.9634872404500772, 'AUCPR': 0.925227219054773, 'TP': 3894, 'FP': 472, 'TN': 8342, 'FN': 513} 

2022-12-29 22:21: Train Epoch 6: 3/244 Loss: 0.166851
2022-12-29 22:21: Train Epoch 6: 7/244 Loss: 0.174134
2022-12-29 22:21: Train Epoch 6: 11/244 Loss: 0.186986
2022-12-29 22:22: Train Epoch 6: 15/244 Loss: 0.179342
2022-12-29 22:22: Train Epoch 6: 19/244 Loss: 0.203742
2022-12-29 22:22: Train Epoch 6: 23/244 Loss: 0.182725
2022-12-29 22:22: Train Epoch 6: 27/244 Loss: 0.180552
2022-12-29 22:22: Train Epoch 6: 31/244 Loss: 0.215525
2022-12-29 22:23: Train Epoch 6: 35/244 Loss: 0.215533
2022-12-29 22:23: Train Epoch 6: 39/244 Loss: 0.186371
2022-12-29 22:23: Train Epoch 6: 43/244 Loss: 0.167779
2022-12-29 22:23: Train Epoch 6: 47/244 Loss: 0.178560
2022-12-29 22:23: Train Epoch 6: 51/244 Loss: 0.187576
2022-12-29 22:23: Train Epoch 6: 55/244 Loss: 0.154143
2022-12-29 22:24: Train Epoch 6: 59/244 Loss: 0.213723
2022-12-29 22:24: Train Epoch 6: 63/244 Loss: 0.169021
2022-12-29 22:24: Train Epoch 6: 67/244 Loss: 0.187528
2022-12-29 22:24: Train Epoch 6: 71/244 Loss: 0.166769
2022-12-29 22:24: Train Epoch 6: 75/244 Loss: 0.168327
2022-12-29 22:24: Train Epoch 6: 79/244 Loss: 0.177314
2022-12-29 22:25: Train Epoch 6: 83/244 Loss: 0.189741
2022-12-29 22:25: Train Epoch 6: 87/244 Loss: 0.156307
2022-12-29 22:25: Train Epoch 6: 91/244 Loss: 0.167615
2022-12-29 22:25: Train Epoch 6: 95/244 Loss: 0.210959
2022-12-29 22:25: Train Epoch 6: 99/244 Loss: 0.162179
2022-12-29 22:25: Train Epoch 6: 103/244 Loss: 0.150393
2022-12-29 22:26: Train Epoch 6: 107/244 Loss: 0.174867
2022-12-29 22:26: Train Epoch 6: 111/244 Loss: 0.201412
2022-12-29 22:26: Train Epoch 6: 115/244 Loss: 0.173259
2022-12-29 22:26: Train Epoch 6: 119/244 Loss: 0.187651
2022-12-29 22:26: Train Epoch 6: 123/244 Loss: 0.168943
2022-12-29 22:27: Train Epoch 6: 127/244 Loss: 0.174123
2022-12-29 22:27: Train Epoch 6: 131/244 Loss: 0.168372
2022-12-29 22:27: Train Epoch 6: 135/244 Loss: 0.194037
2022-12-29 22:27: Train Epoch 6: 139/244 Loss: 0.202758
2022-12-29 22:27: Train Epoch 6: 143/244 Loss: 0.206377
2022-12-29 22:27: Train Epoch 6: 147/244 Loss: 0.180518
2022-12-29 22:27: Train Epoch 6: 151/244 Loss: 0.155451
2022-12-29 22:28: Train Epoch 6: 155/244 Loss: 0.211430
2022-12-29 22:28: Train Epoch 6: 159/244 Loss: 0.179935
2022-12-29 22:28: Train Epoch 6: 163/244 Loss: 0.174756
2022-12-29 22:28: Train Epoch 6: 167/244 Loss: 0.195146
2022-12-29 22:28: Train Epoch 6: 171/244 Loss: 0.187074
2022-12-29 22:29: Train Epoch 6: 175/244 Loss: 0.187475
2022-12-29 22:29: Train Epoch 6: 179/244 Loss: 0.230545
2022-12-29 22:29: Train Epoch 6: 183/244 Loss: 0.212037
2022-12-29 22:29: Train Epoch 6: 187/244 Loss: 0.181437
2022-12-29 22:29: Train Epoch 6: 191/244 Loss: 0.175030
2022-12-29 22:29: Train Epoch 6: 195/244 Loss: 0.176827
2022-12-29 22:30: Train Epoch 6: 199/244 Loss: 0.163594
2022-12-29 22:30: Train Epoch 6: 203/244 Loss: 0.157454
2022-12-29 22:30: Train Epoch 6: 207/244 Loss: 0.196673
2022-12-29 22:30: Train Epoch 6: 211/244 Loss: 0.175768
2022-12-29 22:31: Train Epoch 6: 215/244 Loss: 0.166079
2022-12-29 22:31: Train Epoch 6: 219/244 Loss: 0.171320
2022-12-29 22:31: Train Epoch 6: 223/244 Loss: 0.147526
2022-12-29 22:31: Train Epoch 6: 227/244 Loss: 0.185715
2022-12-29 22:32: Train Epoch 6: 231/244 Loss: 0.174232
2022-12-29 22:32: Train Epoch 6: 235/244 Loss: 0.238909
2022-12-29 22:32: Train Epoch 6: 239/244 Loss: 0.158450
2022-12-29 22:32: Train Epoch 6: 243/244 Loss: 0.173292
2022-12-29 22:32: **********Train Epoch 6: averaged Loss: 0.182101 
2022-12-29 22:32: 
Epoch time elapsed: 670.4617283344269

2022-12-29 22:33: 
 metrics validation: {'precision': 0.8947368421052632, 'recall': 0.2353846153846154, 'f1-score': 0.37271619975639464, 'support': 1300, 'AUC': 0.8461349112426035, 'AUCPR': 0.7568502403097668, 'TP': 306, 'FP': 36, 'TN': 2564, 'FN': 994} 

2022-12-29 22:33: **********Val Epoch 6: average Loss: 0.306930
2022-12-29 22:34: 
 Testing metrics {'precision': 0.757679180887372, 'recall': 0.7231270358306189, 'f1-score': 0.7399999999999999, 'support': 1228, 'AUC': 0.8554195535231143, 'AUCPR': 0.7859597644551333, 'TP': 888, 'FP': 284, 'TN': 2172, 'FN': 340} 

2022-12-29 22:37: 
 Testing metrics {'precision': 0.8918918918918919, 'recall': 0.8835942818243703, 'f1-score': 0.8877236977088795, 'support': 4407, 'AUC': 0.9634872404500772, 'AUCPR': 0.925227219054773, 'TP': 3894, 'FP': 472, 'TN': 8342, 'FN': 513} 

2022-12-29 22:37: Train Epoch 7: 3/244 Loss: 0.184803
2022-12-29 22:37: Train Epoch 7: 7/244 Loss: 0.201778
2022-12-29 22:37: Train Epoch 7: 11/244 Loss: 0.190933
2022-12-29 22:38: Train Epoch 7: 15/244 Loss: 0.163535
2022-12-29 22:38: Train Epoch 7: 19/244 Loss: 0.209802
2022-12-29 22:38: Train Epoch 7: 23/244 Loss: 0.188782
2022-12-29 22:38: Train Epoch 7: 27/244 Loss: 0.199577
2022-12-29 22:38: Train Epoch 7: 31/244 Loss: 0.191677
2022-12-29 22:38: Train Epoch 7: 35/244 Loss: 0.149658
2022-12-29 22:39: Train Epoch 7: 39/244 Loss: 0.176618
2022-12-29 22:39: Train Epoch 7: 43/244 Loss: 0.206063
2022-12-29 22:39: Train Epoch 7: 47/244 Loss: 0.221176
2022-12-29 22:39: Train Epoch 7: 51/244 Loss: 0.190450
2022-12-29 22:39: Train Epoch 7: 55/244 Loss: 0.182451
2022-12-29 22:40: Train Epoch 7: 59/244 Loss: 0.181053
2022-12-29 22:40: Train Epoch 7: 63/244 Loss: 0.169220
2022-12-29 22:40: Train Epoch 7: 67/244 Loss: 0.184712
2022-12-29 22:40: Train Epoch 7: 71/244 Loss: 0.160350
2022-12-29 22:40: Train Epoch 7: 75/244 Loss: 0.188282
2022-12-29 22:40: Train Epoch 7: 79/244 Loss: 0.190377
2022-12-29 22:41: Train Epoch 7: 83/244 Loss: 0.200876
2022-12-29 22:41: Train Epoch 7: 87/244 Loss: 0.190841
2022-12-29 22:41: Train Epoch 7: 91/244 Loss: 0.144460
2022-12-29 22:41: Train Epoch 7: 95/244 Loss: 0.190893
2022-12-29 22:41: Train Epoch 7: 99/244 Loss: 0.197773
2022-12-29 22:42: Train Epoch 7: 103/244 Loss: 0.200379
2022-12-29 22:42: Train Epoch 7: 107/244 Loss: 0.187514
2022-12-29 22:42: Train Epoch 7: 111/244 Loss: 0.179487
2022-12-29 22:42: Train Epoch 7: 115/244 Loss: 0.161890
2022-12-29 22:42: Train Epoch 7: 119/244 Loss: 0.188126
2022-12-29 22:42: Train Epoch 7: 123/244 Loss: 0.199358
2022-12-29 22:43: Train Epoch 7: 127/244 Loss: 0.168751
2022-12-29 22:43: Train Epoch 7: 131/244 Loss: 0.175561
2022-12-29 22:43: Train Epoch 7: 135/244 Loss: 0.196385
2022-12-29 22:43: Train Epoch 7: 139/244 Loss: 0.188845
2022-12-29 22:43: Train Epoch 7: 143/244 Loss: 0.183279
2022-12-29 22:43: Train Epoch 7: 147/244 Loss: 0.189118
2022-12-29 22:44: Train Epoch 7: 151/244 Loss: 0.161712
2022-12-29 22:44: Train Epoch 7: 155/244 Loss: 0.176712
2022-12-29 22:44: Train Epoch 7: 159/244 Loss: 0.207339
2022-12-29 22:44: Train Epoch 7: 163/244 Loss: 0.185422
2022-12-29 22:44: Train Epoch 7: 167/244 Loss: 0.175716
2022-12-29 22:44: Train Epoch 7: 171/244 Loss: 0.167896
2022-12-29 22:45: Train Epoch 7: 175/244 Loss: 0.181069
2022-12-29 22:45: Train Epoch 7: 179/244 Loss: 0.170737
2022-12-29 22:45: Train Epoch 7: 183/244 Loss: 0.166066
2022-12-29 22:45: Train Epoch 7: 187/244 Loss: 0.216010
2022-12-29 22:45: Train Epoch 7: 191/244 Loss: 0.142768
2022-12-29 22:46: Train Epoch 7: 195/244 Loss: 0.144598
2022-12-29 22:46: Train Epoch 7: 199/244 Loss: 0.179130
2022-12-29 22:46: Train Epoch 7: 203/244 Loss: 0.194838
2022-12-29 22:46: Train Epoch 7: 207/244 Loss: 0.169699
2022-12-29 22:46: Train Epoch 7: 211/244 Loss: 0.183412
2022-12-29 22:47: Train Epoch 7: 215/244 Loss: 0.141209
2022-12-29 22:47: Train Epoch 7: 219/244 Loss: 0.166107
2022-12-29 22:47: Train Epoch 7: 223/244 Loss: 0.184317
2022-12-29 22:47: Train Epoch 7: 227/244 Loss: 0.190658
2022-12-29 22:48: Train Epoch 7: 231/244 Loss: 0.167599
2022-12-29 22:48: Train Epoch 7: 235/244 Loss: 0.172004
2022-12-29 22:48: Train Epoch 7: 239/244 Loss: 0.173827
2022-12-29 22:48: Train Epoch 7: 243/244 Loss: 0.181725
2022-12-29 22:48: **********Train Epoch 7: averaged Loss: 0.181564 
2022-12-29 22:48: 
Epoch time elapsed: 675.2901644706726

2022-12-29 22:49: 
 metrics validation: {'precision': 0.7144120247568524, 'recall': 0.6215384615384615, 'f1-score': 0.6647470176881942, 'support': 1300, 'AUC': 0.834562426035503, 'AUCPR': 0.745027425859355, 'TP': 808, 'FP': 323, 'TN': 2277, 'FN': 492} 

2022-12-29 22:49: **********Val Epoch 7: average Loss: 0.244294
2022-12-29 22:49: *********************************Current best model saved!
2022-12-29 22:50: 
 Testing metrics {'precision': 0.7763041556145004, 'recall': 0.7149837133550488, 'f1-score': 0.7443832132259431, 'support': 1228, 'AUC': 0.8656912142303897, 'AUCPR': 0.8076391425298943, 'TP': 878, 'FP': 253, 'TN': 2203, 'FN': 350} 

2022-12-29 22:53: 
 Testing metrics {'precision': 0.8987542468856172, 'recall': 0.900385749943272, 'f1-score': 0.899569258671503, 'support': 4407, 'AUC': 0.9660541697566463, 'AUCPR': 0.9336442926568685, 'TP': 3968, 'FP': 447, 'TN': 8367, 'FN': 439} 

2022-12-29 22:53: Train Epoch 8: 3/244 Loss: 0.175525
2022-12-29 22:53: Train Epoch 8: 7/244 Loss: 0.174966
2022-12-29 22:53: Train Epoch 8: 11/244 Loss: 0.154700
2022-12-29 22:53: Train Epoch 8: 15/244 Loss: 0.153924
2022-12-29 22:54: Train Epoch 8: 19/244 Loss: 0.194185
2022-12-29 22:54: Train Epoch 8: 23/244 Loss: 0.177147
2022-12-29 22:54: Train Epoch 8: 27/244 Loss: 0.181425
2022-12-29 22:54: Train Epoch 8: 31/244 Loss: 0.206409
2022-12-29 22:54: Train Epoch 8: 35/244 Loss: 0.150710
2022-12-29 22:54: Train Epoch 8: 39/244 Loss: 0.158548
2022-12-29 22:55: Train Epoch 8: 43/244 Loss: 0.187828
2022-12-29 22:55: Train Epoch 8: 47/244 Loss: 0.165603
2022-12-29 22:55: Train Epoch 8: 51/244 Loss: 0.187489
2022-12-29 22:55: Train Epoch 8: 55/244 Loss: 0.165874
2022-12-29 22:55: Train Epoch 8: 59/244 Loss: 0.164409
2022-12-29 22:55: Train Epoch 8: 63/244 Loss: 0.192232
2022-12-29 22:56: Train Epoch 8: 67/244 Loss: 0.195341
2022-12-29 22:56: Train Epoch 8: 71/244 Loss: 0.164024
2022-12-29 22:56: Train Epoch 8: 75/244 Loss: 0.179835
2022-12-29 22:56: Train Epoch 8: 79/244 Loss: 0.186990
2022-12-29 22:56: Train Epoch 8: 83/244 Loss: 0.164969
2022-12-29 22:57: Train Epoch 8: 87/244 Loss: 0.181147
2022-12-29 22:57: Train Epoch 8: 91/244 Loss: 0.142574
2022-12-29 22:57: Train Epoch 8: 95/244 Loss: 0.173729
2022-12-29 22:57: Train Epoch 8: 99/244 Loss: 0.165424
2022-12-29 22:57: Train Epoch 8: 103/244 Loss: 0.159419
2022-12-29 22:57: Train Epoch 8: 107/244 Loss: 0.156882
2022-12-29 22:58: Train Epoch 8: 111/244 Loss: 0.178544
2022-12-29 22:58: Train Epoch 8: 115/244 Loss: 0.158171
2022-12-29 22:58: Train Epoch 8: 119/244 Loss: 0.159045
2022-12-29 22:58: Train Epoch 8: 123/244 Loss: 0.162856
2022-12-29 22:58: Train Epoch 8: 127/244 Loss: 0.171626
2022-12-29 22:58: Train Epoch 8: 131/244 Loss: 0.156722
2022-12-29 22:59: Train Epoch 8: 135/244 Loss: 0.200484
2022-12-29 22:59: Train Epoch 8: 139/244 Loss: 0.134876
2022-12-29 22:59: Train Epoch 8: 143/244 Loss: 0.157775
2022-12-29 22:59: Train Epoch 8: 147/244 Loss: 0.181046
2022-12-29 22:59: Train Epoch 8: 151/244 Loss: 0.145127
2022-12-29 22:59: Train Epoch 8: 155/244 Loss: 0.147761
2022-12-29 23:00: Train Epoch 8: 159/244 Loss: 0.191568
2022-12-29 23:00: Train Epoch 8: 163/244 Loss: 0.147130
2022-12-29 23:00: Train Epoch 8: 167/244 Loss: 0.163156
2022-12-29 23:00: Train Epoch 8: 171/244 Loss: 0.174732
2022-12-29 23:00: Train Epoch 8: 175/244 Loss: 0.178096
2022-12-29 23:01: Train Epoch 8: 179/244 Loss: 0.158629
2022-12-29 23:01: Train Epoch 8: 183/244 Loss: 0.180754
2022-12-29 23:01: Train Epoch 8: 187/244 Loss: 0.175651
2022-12-29 23:01: Train Epoch 8: 191/244 Loss: 0.168610
2022-12-29 23:01: Train Epoch 8: 195/244 Loss: 0.183388
2022-12-29 23:01: Train Epoch 8: 199/244 Loss: 0.170301
2022-12-29 23:02: Train Epoch 8: 203/244 Loss: 0.202896
2022-12-29 23:02: Train Epoch 8: 207/244 Loss: 0.175104
2022-12-29 23:02: Train Epoch 8: 211/244 Loss: 0.178401
2022-12-29 23:02: Train Epoch 8: 215/244 Loss: 0.157561
2022-12-29 23:02: Train Epoch 8: 219/244 Loss: 0.192192
2022-12-29 23:03: Train Epoch 8: 223/244 Loss: 0.169257
2022-12-29 23:03: Train Epoch 8: 227/244 Loss: 0.157225
2022-12-29 23:03: Train Epoch 8: 231/244 Loss: 0.160451
2022-12-29 23:04: Train Epoch 8: 235/244 Loss: 0.167831
2022-12-29 23:04: Train Epoch 8: 239/244 Loss: 0.164972
2022-12-29 23:04: Train Epoch 8: 243/244 Loss: 0.158835
2022-12-29 23:04: **********Train Epoch 8: averaged Loss: 0.170362 
2022-12-29 23:04: 
Epoch time elapsed: 677.2673897743225

2022-12-29 23:05: 
 metrics validation: {'precision': 0.8389261744966443, 'recall': 0.4807692307692308, 'f1-score': 0.6112469437652812, 'support': 1300, 'AUC': 0.8579443786982248, 'AUCPR': 0.7788813426833219, 'TP': 625, 'FP': 120, 'TN': 2480, 'FN': 675} 

2022-12-29 23:05: **********Val Epoch 8: average Loss: 0.249221
2022-12-29 23:06: 
 Testing metrics {'precision': 0.7763041556145004, 'recall': 0.7149837133550488, 'f1-score': 0.7443832132259431, 'support': 1228, 'AUC': 0.8656912142303897, 'AUCPR': 0.8076391425298943, 'TP': 878, 'FP': 253, 'TN': 2203, 'FN': 350} 

2022-12-29 23:09: 
 Testing metrics {'precision': 0.8987542468856172, 'recall': 0.900385749943272, 'f1-score': 0.899569258671503, 'support': 4407, 'AUC': 0.9660541697566463, 'AUCPR': 0.9336442926568685, 'TP': 3968, 'FP': 447, 'TN': 8367, 'FN': 439} 

2022-12-29 23:09: Train Epoch 9: 3/244 Loss: 0.178765
2022-12-29 23:09: Train Epoch 9: 7/244 Loss: 0.153761
2022-12-29 23:09: Train Epoch 9: 11/244 Loss: 0.196696
2022-12-29 23:09: Train Epoch 9: 15/244 Loss: 0.223177
2022-12-29 23:10: Train Epoch 9: 19/244 Loss: 0.185374
2022-12-29 23:10: Train Epoch 9: 23/244 Loss: 0.171481
2022-12-29 23:10: Train Epoch 9: 27/244 Loss: 0.166770
2022-12-29 23:10: Train Epoch 9: 31/244 Loss: 0.162888
2022-12-29 23:10: Train Epoch 9: 35/244 Loss: 0.165663
2022-12-29 23:11: Train Epoch 9: 39/244 Loss: 0.195238
2022-12-29 23:11: Train Epoch 9: 43/244 Loss: 0.199350
2022-12-29 23:11: Train Epoch 9: 47/244 Loss: 0.192321
2022-12-29 23:11: Train Epoch 9: 51/244 Loss: 0.174746
2022-12-29 23:11: Train Epoch 9: 55/244 Loss: 0.209386
2022-12-29 23:11: Train Epoch 9: 59/244 Loss: 0.165218
2022-12-29 23:12: Train Epoch 9: 63/244 Loss: 0.185916
2022-12-29 23:12: Train Epoch 9: 67/244 Loss: 0.204136
2022-12-29 23:12: Train Epoch 9: 71/244 Loss: 0.171052
2022-12-29 23:12: Train Epoch 9: 75/244 Loss: 0.199866
2022-12-29 23:12: Train Epoch 9: 79/244 Loss: 0.198152
2022-12-29 23:12: Train Epoch 9: 83/244 Loss: 0.159916
2022-12-29 23:13: Train Epoch 9: 87/244 Loss: 0.167097
2022-12-29 23:13: Train Epoch 9: 91/244 Loss: 0.194617
2022-12-29 23:13: Train Epoch 9: 95/244 Loss: 0.170586
2022-12-29 23:13: Train Epoch 9: 99/244 Loss: 0.172155
2022-12-29 23:13: Train Epoch 9: 103/244 Loss: 0.175790
2022-12-29 23:13: Train Epoch 9: 107/244 Loss: 0.172933
2022-12-29 23:14: Train Epoch 9: 111/244 Loss: 0.230264
2022-12-29 23:14: Train Epoch 9: 115/244 Loss: 0.172452
2022-12-29 23:14: Train Epoch 9: 119/244 Loss: 0.180860
2022-12-29 23:14: Train Epoch 9: 123/244 Loss: 0.181870
2022-12-29 23:14: Train Epoch 9: 127/244 Loss: 0.151456
2022-12-29 23:15: Train Epoch 9: 131/244 Loss: 0.201648
2022-12-29 23:15: Train Epoch 9: 135/244 Loss: 0.203648
2022-12-29 23:15: Train Epoch 9: 139/244 Loss: 0.179753
2022-12-29 23:15: Train Epoch 9: 143/244 Loss: 0.169459
2022-12-29 23:15: Train Epoch 9: 147/244 Loss: 0.174414
2022-12-29 23:15: Train Epoch 9: 151/244 Loss: 0.144827
2022-12-29 23:15: Train Epoch 9: 155/244 Loss: 0.196452
2022-12-29 23:16: Train Epoch 9: 159/244 Loss: 0.142933
2022-12-29 23:16: Train Epoch 9: 163/244 Loss: 0.184494
2022-12-29 23:16: Train Epoch 9: 167/244 Loss: 0.161030
2022-12-29 23:16: Train Epoch 9: 171/244 Loss: 0.154219
2022-12-29 23:16: Train Epoch 9: 175/244 Loss: 0.160470
2022-12-29 23:17: Train Epoch 9: 179/244 Loss: 0.148592
2022-12-29 23:17: Train Epoch 9: 183/244 Loss: 0.171523
2022-12-29 23:17: Train Epoch 9: 187/244 Loss: 0.170198
2022-12-29 23:17: Train Epoch 9: 191/244 Loss: 0.172733
2022-12-29 23:17: Train Epoch 9: 195/244 Loss: 0.164595
2022-12-29 23:17: Train Epoch 9: 199/244 Loss: 0.196242
2022-12-29 23:18: Train Epoch 9: 203/244 Loss: 0.198060
2022-12-29 23:18: Train Epoch 9: 207/244 Loss: 0.159740
2022-12-29 23:18: Train Epoch 9: 211/244 Loss: 0.161623
2022-12-29 23:18: Train Epoch 9: 215/244 Loss: 0.180500
2022-12-29 23:19: Train Epoch 9: 219/244 Loss: 0.173106
2022-12-29 23:19: Train Epoch 9: 223/244 Loss: 0.166826
2022-12-29 23:19: Train Epoch 9: 227/244 Loss: 0.165342
2022-12-29 23:19: Train Epoch 9: 231/244 Loss: 0.145018
2022-12-29 23:20: Train Epoch 9: 235/244 Loss: 0.189726
2022-12-29 23:20: Train Epoch 9: 239/244 Loss: 0.150689
2022-12-29 23:20: Train Epoch 9: 243/244 Loss: 0.146473
2022-12-29 23:20: **********Train Epoch 9: averaged Loss: 0.176464 
2022-12-29 23:20: 
Epoch time elapsed: 680.4061608314514

2022-12-29 23:21: 
 metrics validation: {'precision': 0.7790110998990918, 'recall': 0.5938461538461538, 'f1-score': 0.6739415102575295, 'support': 1300, 'AUC': 0.8576784023668639, 'AUCPR': 0.7771612165523002, 'TP': 772, 'FP': 219, 'TN': 2381, 'FN': 528} 

2022-12-29 23:21: **********Val Epoch 9: average Loss: 0.233404
2022-12-29 23:21: *********************************Current best model saved!
2022-12-29 23:22: 
 Testing metrics {'precision': 0.8191011235955056, 'recall': 0.5936482084690554, 'f1-score': 0.688385269121813, 'support': 1228, 'AUC': 0.8697807801674289, 'AUCPR': 0.8136169024251845, 'TP': 729, 'FP': 161, 'TN': 2295, 'FN': 499} 

2022-12-29 23:25: 
 Testing metrics {'precision': 0.923915737298637, 'recall': 0.8459269344225097, 'f1-score': 0.8832030324567638, 'support': 4407, 'AUC': 0.9665923578373802, 'AUCPR': 0.9346082934582454, 'TP': 3728, 'FP': 307, 'TN': 8507, 'FN': 679} 

2022-12-29 23:25: Train Epoch 10: 3/244 Loss: 0.169741
2022-12-29 23:25: Train Epoch 10: 7/244 Loss: 0.185665
2022-12-29 23:25: Train Epoch 10: 11/244 Loss: 0.155479
2022-12-29 23:25: Train Epoch 10: 15/244 Loss: 0.166192
2022-12-29 23:26: Train Epoch 10: 19/244 Loss: 0.157302
2022-12-29 23:26: Train Epoch 10: 23/244 Loss: 0.173377
2022-12-29 23:26: Train Epoch 10: 27/244 Loss: 0.177294
2022-12-29 23:26: Train Epoch 10: 31/244 Loss: 0.172062
2022-12-29 23:26: Train Epoch 10: 35/244 Loss: 0.194195
2022-12-29 23:26: Train Epoch 10: 39/244 Loss: 0.157936
2022-12-29 23:27: Train Epoch 10: 43/244 Loss: 0.175258
2022-12-29 23:27: Train Epoch 10: 47/244 Loss: 0.146612
2022-12-29 23:27: Train Epoch 10: 51/244 Loss: 0.188199
2022-12-29 23:27: Train Epoch 10: 55/244 Loss: 0.163988
2022-12-29 23:27: Train Epoch 10: 59/244 Loss: 0.167213
2022-12-29 23:27: Train Epoch 10: 63/244 Loss: 0.167123
2022-12-29 23:28: Train Epoch 10: 67/244 Loss: 0.168728
2022-12-29 23:28: Train Epoch 10: 71/244 Loss: 0.162062
2022-12-29 23:28: Train Epoch 10: 75/244 Loss: 0.202308
2022-12-29 23:28: Train Epoch 10: 79/244 Loss: 0.174274
2022-12-29 23:28: Train Epoch 10: 83/244 Loss: 0.144961
2022-12-29 23:29: Train Epoch 10: 87/244 Loss: 0.177848
2022-12-29 23:29: Train Epoch 10: 91/244 Loss: 0.176467
2022-12-29 23:29: Train Epoch 10: 95/244 Loss: 0.166639
2022-12-29 23:29: Train Epoch 10: 99/244 Loss: 0.158922
2022-12-29 23:29: Train Epoch 10: 103/244 Loss: 0.156853
2022-12-29 23:29: Train Epoch 10: 107/244 Loss: 0.154074
2022-12-29 23:30: Train Epoch 10: 111/244 Loss: 0.144282
2022-12-29 23:30: Train Epoch 10: 115/244 Loss: 0.150904
2022-12-29 23:30: Train Epoch 10: 119/244 Loss: 0.205979
2022-12-29 23:30: Train Epoch 10: 123/244 Loss: 0.190207
2022-12-29 23:30: Train Epoch 10: 127/244 Loss: 0.153114
2022-12-29 23:31: Train Epoch 10: 131/244 Loss: 0.185043
2022-12-29 23:31: Train Epoch 10: 135/244 Loss: 0.176074
2022-12-29 23:31: Train Epoch 10: 139/244 Loss: 0.152704
2022-12-29 23:31: Train Epoch 10: 143/244 Loss: 0.138954
2022-12-29 23:31: Train Epoch 10: 147/244 Loss: 0.159970
2022-12-29 23:31: Train Epoch 10: 151/244 Loss: 0.129254
2022-12-29 23:31: Train Epoch 10: 155/244 Loss: 0.158950
2022-12-29 23:32: Train Epoch 10: 159/244 Loss: 0.149057
2022-12-29 23:32: Train Epoch 10: 163/244 Loss: 0.165385
2022-12-29 23:32: Train Epoch 10: 167/244 Loss: 0.179948
2022-12-29 23:32: Train Epoch 10: 171/244 Loss: 0.168821
2022-12-29 23:32: Train Epoch 10: 175/244 Loss: 0.167457
2022-12-29 23:33: Train Epoch 10: 179/244 Loss: 0.184374
2022-12-29 23:33: Train Epoch 10: 183/244 Loss: 0.166642
2022-12-29 23:33: Train Epoch 10: 187/244 Loss: 0.123692
2022-12-29 23:33: Train Epoch 10: 191/244 Loss: 0.180667
2022-12-29 23:33: Train Epoch 10: 195/244 Loss: 0.148086
2022-12-29 23:33: Train Epoch 10: 199/244 Loss: 0.153431
2022-12-29 23:34: Train Epoch 10: 203/244 Loss: 0.168895
2022-12-29 23:34: Train Epoch 10: 207/244 Loss: 0.166017
2022-12-29 23:34: Train Epoch 10: 211/244 Loss: 0.165240
2022-12-29 23:34: Train Epoch 10: 215/244 Loss: 0.164253
2022-12-29 23:35: Train Epoch 10: 219/244 Loss: 0.167412
2022-12-29 23:35: Train Epoch 10: 223/244 Loss: 0.134409
2022-12-29 23:35: Train Epoch 10: 227/244 Loss: 0.178800
2022-12-29 23:35: Train Epoch 10: 231/244 Loss: 0.205066
2022-12-29 23:35: Train Epoch 10: 235/244 Loss: 0.146177
2022-12-29 23:36: Train Epoch 10: 239/244 Loss: 0.178041
2022-12-29 23:36: Train Epoch 10: 243/244 Loss: 0.143437
2022-12-29 23:36: **********Train Epoch 10: averaged Loss: 0.165763 
2022-12-29 23:36: 
Epoch time elapsed: 666.0234224796295

2022-12-29 23:37: 
 metrics validation: {'precision': 0.7756729810568295, 'recall': 0.5984615384615385, 'f1-score': 0.6756404689535388, 'support': 1300, 'AUC': 0.8580473372781066, 'AUCPR': 0.7747158116597523, 'TP': 778, 'FP': 225, 'TN': 2375, 'FN': 522} 

2022-12-29 23:37: **********Val Epoch 10: average Loss: 0.235845
2022-12-29 23:37: 
 Testing metrics {'precision': 0.8191011235955056, 'recall': 0.5936482084690554, 'f1-score': 0.688385269121813, 'support': 1228, 'AUC': 0.8697807801674289, 'AUCPR': 0.8136169024251845, 'TP': 729, 'FP': 161, 'TN': 2295, 'FN': 499} 

2022-12-29 23:40: 
 Testing metrics {'precision': 0.923915737298637, 'recall': 0.8459269344225097, 'f1-score': 0.8832030324567638, 'support': 4407, 'AUC': 0.9665923578373802, 'AUCPR': 0.9346082934582454, 'TP': 3728, 'FP': 307, 'TN': 8507, 'FN': 679} 

2022-12-29 23:41: Train Epoch 11: 3/244 Loss: 0.172495
2022-12-29 23:41: Train Epoch 11: 7/244 Loss: 0.244658
2022-12-29 23:41: Train Epoch 11: 11/244 Loss: 0.182067
2022-12-29 23:41: Train Epoch 11: 15/244 Loss: 0.183857
2022-12-29 23:41: Train Epoch 11: 19/244 Loss: 0.160699
2022-12-29 23:41: Train Epoch 11: 23/244 Loss: 0.200752
2022-12-29 23:42: Train Epoch 11: 27/244 Loss: 0.189644
2022-12-29 23:42: Train Epoch 11: 31/244 Loss: 0.153732
2022-12-29 23:42: Train Epoch 11: 35/244 Loss: 0.155160
2022-12-29 23:42: Train Epoch 11: 39/244 Loss: 0.135433
2022-12-29 23:42: Train Epoch 11: 43/244 Loss: 0.170313
2022-12-29 23:43: Train Epoch 11: 47/244 Loss: 0.153218
2022-12-29 23:43: Train Epoch 11: 51/244 Loss: 0.159465
2022-12-29 23:43: Train Epoch 11: 55/244 Loss: 0.153366
2022-12-29 23:43: Train Epoch 11: 59/244 Loss: 0.135619
2022-12-29 23:43: Train Epoch 11: 63/244 Loss: 0.165529
2022-12-29 23:43: Train Epoch 11: 67/244 Loss: 0.185362
2022-12-29 23:44: Train Epoch 11: 71/244 Loss: 0.140256
2022-12-29 23:44: Train Epoch 11: 75/244 Loss: 0.166102
2022-12-29 23:44: Train Epoch 11: 79/244 Loss: 0.169965
2022-12-29 23:44: Train Epoch 11: 83/244 Loss: 0.137680
2022-12-29 23:44: Train Epoch 11: 87/244 Loss: 0.184619
2022-12-29 23:44: Train Epoch 11: 91/244 Loss: 0.180281
2022-12-29 23:45: Train Epoch 11: 95/244 Loss: 0.149578
2022-12-29 23:45: Train Epoch 11: 99/244 Loss: 0.157029
2022-12-29 23:45: Train Epoch 11: 103/244 Loss: 0.173736
2022-12-29 23:45: Train Epoch 11: 107/244 Loss: 0.161776
2022-12-29 23:45: Train Epoch 11: 111/244 Loss: 0.161489
2022-12-29 23:45: Train Epoch 11: 115/244 Loss: 0.156104
2022-12-29 23:46: Train Epoch 11: 119/244 Loss: 0.161074
2022-12-29 23:46: Train Epoch 11: 123/244 Loss: 0.162652
2022-12-29 23:46: Train Epoch 11: 127/244 Loss: 0.164511
2022-12-29 23:46: Train Epoch 11: 131/244 Loss: 0.175224
2022-12-29 23:46: Train Epoch 11: 135/244 Loss: 0.178871
2022-12-29 23:46: Train Epoch 11: 139/244 Loss: 0.167600
2022-12-29 23:47: Train Epoch 11: 143/244 Loss: 0.147745
2022-12-29 23:47: Train Epoch 11: 147/244 Loss: 0.148094
2022-12-29 23:47: Train Epoch 11: 151/244 Loss: 0.141374
2022-12-29 23:47: Train Epoch 11: 155/244 Loss: 0.156335
