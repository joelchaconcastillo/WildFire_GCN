2023-01-05 00:33: log dir: /home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010500332345480554013
2023-01-05 00:33: Experiment log path in: /home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010500332345480554013
2023-01-05 00:33: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=5, embed_dim=32, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010500332345480554013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=32, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.01, window_len=10)
2023-01-05 00:33: Argument batch_size: 256
2023-01-05 00:33: Argument clc: 'vec'
2023-01-05 00:33: Argument cuda: True
2023-01-05 00:33: Argument dataset: '2020'
2023-01-05 00:33: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-05 00:33: Argument debug: False
2023-01-05 00:33: Argument default_graph: True
2023-01-05 00:33: Argument device: 'cpu'
2023-01-05 00:33: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-05 00:33: Argument early_stop: True
2023-01-05 00:33: Argument early_stop_patience: 5
2023-01-05 00:33: Argument embed_dim: 32
2023-01-05 00:33: Argument epochs: 30
2023-01-05 00:33: Argument grad_norm: False
2023-01-05 00:33: Argument horizon: 1
2023-01-05 00:33: Argument input_dim: 25
2023-01-05 00:33: Argument lag: 10
2023-01-05 00:33: Argument link_len: 2
2023-01-05 00:33: Argument log_dir: '/home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010500332345480554013'
2023-01-05 00:33: Argument log_step: 1
2023-01-05 00:33: Argument loss_func: 'nllloss'
2023-01-05 00:33: Argument lr_decay: True
2023-01-05 00:33: Argument lr_decay_rate: 0.1
2023-01-05 00:33: Argument lr_decay_step: '15'
2023-01-05 00:33: Argument lr_init: 0.0001
2023-01-05 00:33: Argument max_grad_norm: 5
2023-01-05 00:33: Argument minbatch_size: 64
2023-01-05 00:33: Argument mode: 'train'
2023-01-05 00:33: Argument model: 'fire_GCN'
2023-01-05 00:33: Argument nan_fill: -1.0
2023-01-05 00:33: Argument num_layers: 1
2023-01-05 00:33: Argument num_nodes: 625
2023-01-05 00:33: Argument num_workers: 12
2023-01-05 00:33: Argument output_dim: 2
2023-01-05 00:33: Argument patch_height: 25
2023-01-05 00:33: Argument patch_width: 25
2023-01-05 00:33: Argument persistent_workers: True
2023-01-05 00:33: Argument pin_memory: True
2023-01-05 00:33: Argument plot: False
2023-01-05 00:33: Argument positive_weight: 0.5
2023-01-05 00:33: Argument prefetch_factor: 2
2023-01-05 00:33: Argument real_value: True
2023-01-05 00:33: Argument rnn_units: 32
2023-01-05 00:33: Argument seed: 10000
2023-01-05 00:33: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-05 00:33: Argument teacher_forcing: False
2023-01-05 00:33: Argument weight_decay: 0.01
2023-01-05 00:33: Argument window_len: 10
2023-01-05 00:33: Train Epoch 1: 3/634 Loss: 0.579101
2023-01-05 00:33: Train Epoch 1: 7/634 Loss: 0.486579
2023-01-05 00:33: Train Epoch 1: 11/634 Loss: 0.542404
2023-01-05 00:33: Train Epoch 1: 15/634 Loss: 0.369011
2023-01-05 00:33: Train Epoch 1: 19/634 Loss: 0.433430
2023-01-05 00:34: Train Epoch 1: 23/634 Loss: 0.411564
2023-01-05 00:34: Train Epoch 1: 27/634 Loss: 0.390981
2023-01-05 00:34: Train Epoch 1: 31/634 Loss: 0.387907
2023-01-05 00:34: Train Epoch 1: 35/634 Loss: 0.411320
2023-01-05 00:34: Train Epoch 1: 39/634 Loss: 0.400181
2023-01-05 00:34: Train Epoch 1: 43/634 Loss: 0.363180
2023-01-05 00:34: Train Epoch 1: 47/634 Loss: 0.346128
2023-01-05 00:34: Train Epoch 1: 51/634 Loss: 0.342212
2023-01-05 00:34: Train Epoch 1: 55/634 Loss: 0.357941
2023-01-05 00:35: Train Epoch 1: 59/634 Loss: 0.338717
2023-01-05 00:35: Train Epoch 1: 63/634 Loss: 0.335377
2023-01-05 00:35: Train Epoch 1: 67/634 Loss: 0.322068
2023-01-05 00:35: Train Epoch 1: 71/634 Loss: 0.350267
2023-01-05 00:35: Train Epoch 1: 75/634 Loss: 0.336681
2023-01-05 00:35: Train Epoch 1: 79/634 Loss: 0.317612
2023-01-05 00:35: Train Epoch 1: 83/634 Loss: 0.315373
2023-01-05 00:35: Train Epoch 1: 87/634 Loss: 0.304412
2023-01-05 00:35: Train Epoch 1: 91/634 Loss: 0.333386
2023-01-05 00:35: Train Epoch 1: 95/634 Loss: 0.277450
2023-01-05 00:36: Train Epoch 1: 99/634 Loss: 0.285324
2023-01-05 00:36: Train Epoch 1: 103/634 Loss: 0.273812
2023-01-05 00:36: Train Epoch 1: 107/634 Loss: 0.300656
2023-01-05 00:36: Train Epoch 1: 111/634 Loss: 0.275155
2023-01-05 00:36: Train Epoch 1: 115/634 Loss: 0.282281
2023-01-05 00:36: Train Epoch 1: 119/634 Loss: 0.269416
2023-01-05 00:36: Train Epoch 1: 123/634 Loss: 0.267810
2023-01-05 00:36: Train Epoch 1: 127/634 Loss: 0.277311
2023-01-05 00:36: Train Epoch 1: 131/634 Loss: 0.253937
2023-01-05 00:36: Train Epoch 1: 135/634 Loss: 0.254571
2023-01-05 00:37: Train Epoch 1: 139/634 Loss: 0.298717
2023-01-05 00:37: Train Epoch 1: 143/634 Loss: 0.255474
2023-01-05 00:37: Train Epoch 1: 147/634 Loss: 0.249604
2023-01-05 00:37: Train Epoch 1: 151/634 Loss: 0.241610
2023-01-05 00:37: Train Epoch 1: 155/634 Loss: 0.244616
2023-01-05 00:37: Train Epoch 1: 159/634 Loss: 0.248493
2023-01-05 00:37: Train Epoch 1: 163/634 Loss: 0.248440
2023-01-05 00:37: Train Epoch 1: 167/634 Loss: 0.224074
2023-01-05 00:37: Train Epoch 1: 171/634 Loss: 0.247327
2023-01-05 00:37: Train Epoch 1: 175/634 Loss: 0.242889
2023-01-05 00:38: Train Epoch 1: 179/634 Loss: 0.229059
2023-01-05 00:38: Train Epoch 1: 183/634 Loss: 0.192865
2023-01-05 00:38: Train Epoch 1: 187/634 Loss: 0.220134
2023-01-05 00:38: Train Epoch 1: 191/634 Loss: 0.223264
2023-01-05 00:38: Train Epoch 1: 195/634 Loss: 0.241960
2023-01-05 00:38: Train Epoch 1: 199/634 Loss: 0.226496
2023-01-05 00:38: Train Epoch 1: 203/634 Loss: 0.202608
2023-01-05 00:38: Train Epoch 1: 207/634 Loss: 0.230492
2023-01-05 00:38: Train Epoch 1: 211/634 Loss: 0.205148
2023-01-05 00:38: Train Epoch 1: 215/634 Loss: 0.192030
2023-01-05 00:39: Train Epoch 1: 219/634 Loss: 0.209645
2023-01-05 00:39: Train Epoch 1: 223/634 Loss: 0.218946
2023-01-05 00:39: Train Epoch 1: 227/634 Loss: 0.244421
2023-01-05 00:39: Train Epoch 1: 231/634 Loss: 0.210689
2023-01-05 00:39: Train Epoch 1: 235/634 Loss: 0.236375
2023-01-05 00:39: Train Epoch 1: 239/634 Loss: 0.196054
2023-01-05 00:39: Train Epoch 1: 243/634 Loss: 0.230242
2023-01-05 00:39: Train Epoch 1: 247/634 Loss: 0.219928
2023-01-05 00:39: Train Epoch 1: 251/634 Loss: 0.220460
2023-01-05 00:39: Train Epoch 1: 255/634 Loss: 0.212174
2023-01-05 00:39: Train Epoch 1: 259/634 Loss: 0.225829
2023-01-05 00:40: Train Epoch 1: 263/634 Loss: 0.192813
2023-01-05 00:40: Train Epoch 1: 267/634 Loss: 0.220818
2023-01-05 00:40: Train Epoch 1: 271/634 Loss: 0.211003
2023-01-05 00:40: Train Epoch 1: 275/634 Loss: 0.202484
2023-01-05 00:40: Train Epoch 1: 279/634 Loss: 0.227736
2023-01-05 00:40: Train Epoch 1: 283/634 Loss: 0.194384
2023-01-05 00:40: Train Epoch 1: 287/634 Loss: 0.207267
2023-01-05 00:40: Train Epoch 1: 291/634 Loss: 0.239198
2023-01-05 00:40: Train Epoch 1: 295/634 Loss: 0.202149
2023-01-05 00:41: Train Epoch 1: 299/634 Loss: 0.224774
2023-01-05 00:41: Train Epoch 1: 303/634 Loss: 0.224896
2023-01-05 00:41: Train Epoch 1: 307/634 Loss: 0.255936
2023-01-05 00:41: Train Epoch 1: 311/634 Loss: 0.213400
2023-01-05 00:41: Train Epoch 1: 315/634 Loss: 0.245508
2023-01-05 00:41: Train Epoch 1: 319/634 Loss: 0.202057
2023-01-05 00:41: Train Epoch 1: 323/634 Loss: 0.229819
2023-01-05 00:41: Train Epoch 1: 327/634 Loss: 0.208691
2023-01-05 00:41: Train Epoch 1: 331/634 Loss: 0.234328
2023-01-05 00:41: Train Epoch 1: 335/634 Loss: 0.186541
2023-01-05 00:42: Train Epoch 1: 339/634 Loss: 0.200705
2023-01-05 00:42: Train Epoch 1: 343/634 Loss: 0.205988
2023-01-05 00:42: Train Epoch 1: 347/634 Loss: 0.190332
2023-01-05 00:42: Train Epoch 1: 351/634 Loss: 0.231079
2023-01-05 00:42: Train Epoch 1: 355/634 Loss: 0.222028
2023-01-05 00:42: Train Epoch 1: 359/634 Loss: 0.200281
2023-01-05 00:42: Train Epoch 1: 363/634 Loss: 0.211472
2023-01-05 00:42: Train Epoch 1: 367/634 Loss: 0.184826
2023-01-05 00:42: Train Epoch 1: 371/634 Loss: 0.220141
2023-01-05 00:42: Train Epoch 1: 375/634 Loss: 0.200798
2023-01-05 00:42: Train Epoch 1: 379/634 Loss: 0.215253
2023-01-05 00:43: Train Epoch 1: 383/634 Loss: 0.212685
2023-01-05 00:43: Train Epoch 1: 387/634 Loss: 0.169644
2023-01-05 00:43: Train Epoch 1: 391/634 Loss: 0.197001
2023-01-05 00:43: Train Epoch 1: 395/634 Loss: 0.221030
2023-01-05 00:43: Train Epoch 1: 399/634 Loss: 0.229743
2023-01-05 00:43: Train Epoch 1: 403/634 Loss: 0.231176
2023-01-05 00:43: Train Epoch 1: 407/634 Loss: 0.189317
2023-01-05 00:43: Train Epoch 1: 411/634 Loss: 0.198088
2023-01-05 00:43: Train Epoch 1: 415/634 Loss: 0.188938
2023-01-05 00:43: Train Epoch 1: 419/634 Loss: 0.190902
2023-01-05 00:44: Train Epoch 1: 423/634 Loss: 0.236891
2023-01-05 00:44: Train Epoch 1: 427/634 Loss: 0.168862
2023-01-05 00:44: Train Epoch 1: 431/634 Loss: 0.245534
2023-01-05 00:44: Train Epoch 1: 435/634 Loss: 0.197579
2023-01-05 00:44: Train Epoch 1: 439/634 Loss: 0.206078
2023-01-05 00:44: Train Epoch 1: 443/634 Loss: 0.221065
2023-01-05 00:44: Train Epoch 1: 447/634 Loss: 0.192261
2023-01-05 00:44: Train Epoch 1: 451/634 Loss: 0.197457
2023-01-05 00:44: Train Epoch 1: 455/634 Loss: 0.196533
2023-01-05 00:44: Train Epoch 1: 459/634 Loss: 0.199111
2023-01-05 00:45: Train Epoch 1: 463/634 Loss: 0.233468
2023-01-05 00:45: Train Epoch 1: 467/634 Loss: 0.216450
2023-01-05 00:45: Train Epoch 1: 471/634 Loss: 0.197206
2023-01-05 00:45: Train Epoch 1: 475/634 Loss: 0.231330
2023-01-05 00:45: Train Epoch 1: 479/634 Loss: 0.210238
2023-01-05 00:45: Train Epoch 1: 483/634 Loss: 0.208205
2023-01-05 00:45: Train Epoch 1: 487/634 Loss: 0.205182
2023-01-05 00:45: Train Epoch 1: 491/634 Loss: 0.216496
2023-01-05 00:45: Train Epoch 1: 495/634 Loss: 0.199761
2023-01-05 00:45: Train Epoch 1: 499/634 Loss: 0.214393
2023-01-05 00:45: Train Epoch 1: 503/634 Loss: 0.212642
2023-01-05 00:46: Train Epoch 1: 507/634 Loss: 0.213548
2023-01-05 00:46: Train Epoch 1: 511/634 Loss: 0.160256
2023-01-05 00:46: Train Epoch 1: 515/634 Loss: 0.221625
2023-01-05 00:46: Train Epoch 1: 519/634 Loss: 0.219535
2023-01-05 00:46: Train Epoch 1: 523/634 Loss: 0.190463
2023-01-05 00:46: Train Epoch 1: 527/634 Loss: 0.220693
2023-01-05 00:46: Train Epoch 1: 531/634 Loss: 0.179395
2023-01-05 00:46: Train Epoch 1: 535/634 Loss: 0.199651
2023-01-05 00:46: Train Epoch 1: 539/634 Loss: 0.235902
2023-01-05 00:47: Train Epoch 1: 543/634 Loss: 0.204356
2023-01-05 00:47: Train Epoch 1: 547/634 Loss: 0.242506
2023-01-05 00:47: Train Epoch 1: 551/634 Loss: 0.153439
2023-01-05 00:47: Train Epoch 1: 555/634 Loss: 0.189752
2023-01-05 00:47: Train Epoch 1: 559/634 Loss: 0.224013
2023-01-05 00:47: Train Epoch 1: 563/634 Loss: 0.176931
2023-01-05 00:47: Train Epoch 1: 567/634 Loss: 0.224181
2023-01-05 00:47: Train Epoch 1: 571/634 Loss: 0.196982
2023-01-05 00:47: Train Epoch 1: 575/634 Loss: 0.170596
2023-01-05 00:47: Train Epoch 1: 579/634 Loss: 0.206012
2023-01-05 00:47: Train Epoch 1: 583/634 Loss: 0.258942
2023-01-05 00:48: Train Epoch 1: 587/634 Loss: 0.219603
2023-01-05 00:48: Train Epoch 1: 591/634 Loss: 0.207840
2023-01-05 00:48: Train Epoch 1: 595/634 Loss: 0.187616
2023-01-05 00:48: Train Epoch 1: 599/634 Loss: 0.209770
2023-01-05 00:48: Train Epoch 1: 603/634 Loss: 0.212848
2023-01-05 00:48: Train Epoch 1: 607/634 Loss: 0.219836
2023-01-05 00:48: Train Epoch 1: 611/634 Loss: 0.214707
2023-01-05 00:48: Train Epoch 1: 615/634 Loss: 0.212015
2023-01-05 00:48: Train Epoch 1: 619/634 Loss: 0.208581
2023-01-05 00:48: Train Epoch 1: 623/634 Loss: 0.186165
2023-01-05 00:49: Train Epoch 1: 627/634 Loss: 0.186177
2023-01-05 00:49: Train Epoch 1: 631/634 Loss: 0.178315
2023-01-05 00:49: Train Epoch 1: 633/634 Loss: 0.069465
2023-01-05 00:49: **********Train Epoch 1: averaged Loss: 0.241052 
2023-01-05 00:49: 
Epoch time elapsed: 949.4282879829407

2023-01-05 00:50: 
 metrics validation: {'precision': 0.674933569530558, 'recall': 0.5861538461538461, 'f1-score': 0.6274186908192673, 'support': 1300, 'AUC': 0.8106386094674556, 'AUCPR': 0.6751787973996074, 'TP': 762, 'FP': 367, 'TN': 2233, 'FN': 538} 

2023-01-05 00:50: **********Val Epoch 1: average Loss: 0.253651
2023-01-05 00:50: *********************************Current best model saved!
2023-01-05 00:51: 
 Testing metrics {'precision': 0.7801608579088471, 'recall': 0.7109120521172638, 'f1-score': 0.7439284192586281, 'support': 1228, 'AUC': 0.8553457795308173, 'AUCPR': 0.7565554582941824, 'TP': 873, 'FP': 246, 'TN': 2210, 'FN': 355} 

2023-01-05 00:53: 
 Testing metrics {'precision': 0.889959659345585, 'recall': 0.9010664851372816, 'f1-score': 0.8954786334423273, 'support': 4407, 'AUC': 0.9665027928370037, 'AUCPR': 0.9311616903513606, 'TP': 3971, 'FP': 491, 'TN': 8323, 'FN': 436} 

2023-01-05 00:54: Train Epoch 2: 3/634 Loss: 0.166267
2023-01-05 00:54: Train Epoch 2: 7/634 Loss: 0.193522
2023-01-05 00:54: Train Epoch 2: 11/634 Loss: 0.188262
2023-01-05 00:54: Train Epoch 2: 15/634 Loss: 0.170027
2023-01-05 00:54: Train Epoch 2: 19/634 Loss: 0.195222
2023-01-05 00:54: Train Epoch 2: 23/634 Loss: 0.194953
2023-01-05 00:54: Train Epoch 2: 27/634 Loss: 0.226184
2023-01-05 00:54: Train Epoch 2: 31/634 Loss: 0.200954
2023-01-05 00:54: Train Epoch 2: 35/634 Loss: 0.194199
2023-01-05 00:54: Train Epoch 2: 39/634 Loss: 0.170269
2023-01-05 00:55: Train Epoch 2: 43/634 Loss: 0.194462
2023-01-05 00:55: Train Epoch 2: 47/634 Loss: 0.182951
2023-01-05 00:55: Train Epoch 2: 51/634 Loss: 0.206313
2023-01-05 00:55: Train Epoch 2: 55/634 Loss: 0.178549
2023-01-05 00:55: Train Epoch 2: 59/634 Loss: 0.184144
2023-01-05 00:55: Train Epoch 2: 63/634 Loss: 0.198280
2023-01-05 00:55: Train Epoch 2: 67/634 Loss: 0.199534
2023-01-05 00:55: Train Epoch 2: 71/634 Loss: 0.245169
2023-01-05 00:55: Train Epoch 2: 75/634 Loss: 0.203492
2023-01-05 00:55: Train Epoch 2: 79/634 Loss: 0.169768
2023-01-05 00:56: Train Epoch 2: 83/634 Loss: 0.175561
2023-01-05 00:56: Train Epoch 2: 87/634 Loss: 0.220718
2023-01-05 00:56: Train Epoch 2: 91/634 Loss: 0.188100
2023-01-05 00:56: Train Epoch 2: 95/634 Loss: 0.199733
2023-01-05 00:56: Train Epoch 2: 99/634 Loss: 0.177965
2023-01-05 00:56: Train Epoch 2: 103/634 Loss: 0.190328
2023-01-05 00:56: Train Epoch 2: 107/634 Loss: 0.170456
2023-01-05 00:56: Train Epoch 2: 111/634 Loss: 0.224114
2023-01-05 00:56: Train Epoch 2: 115/634 Loss: 0.215861
2023-01-05 00:56: Train Epoch 2: 119/634 Loss: 0.204610
2023-01-05 00:57: Train Epoch 2: 123/634 Loss: 0.218668
2023-01-05 00:57: Train Epoch 2: 127/634 Loss: 0.243696
2023-01-05 00:57: Train Epoch 2: 131/634 Loss: 0.183815
2023-01-05 00:57: Train Epoch 2: 135/634 Loss: 0.200060
2023-01-05 00:57: Train Epoch 2: 139/634 Loss: 0.178955
2023-01-05 00:57: Train Epoch 2: 143/634 Loss: 0.161306
2023-01-05 00:57: Train Epoch 2: 147/634 Loss: 0.245636
2023-01-05 00:57: Train Epoch 2: 151/634 Loss: 0.167610
2023-01-05 00:57: Train Epoch 2: 155/634 Loss: 0.173524
2023-01-05 00:58: Train Epoch 2: 159/634 Loss: 0.228253
2023-01-05 00:58: Train Epoch 2: 163/634 Loss: 0.191787
2023-01-05 00:58: Train Epoch 2: 167/634 Loss: 0.188481
2023-01-05 00:58: Train Epoch 2: 171/634 Loss: 0.212078
2023-01-05 00:58: Train Epoch 2: 175/634 Loss: 0.189014
2023-01-05 00:58: Train Epoch 2: 179/634 Loss: 0.156261
2023-01-05 00:58: Train Epoch 2: 183/634 Loss: 0.167495
2023-01-05 00:58: Train Epoch 2: 187/634 Loss: 0.187221
2023-01-05 00:58: Train Epoch 2: 191/634 Loss: 0.202909
2023-01-05 00:58: Train Epoch 2: 195/634 Loss: 0.177188
2023-01-05 00:58: Train Epoch 2: 199/634 Loss: 0.215550
2023-01-05 00:59: Train Epoch 2: 203/634 Loss: 0.203289
2023-01-05 00:59: Train Epoch 2: 207/634 Loss: 0.212304
2023-01-05 00:59: Train Epoch 2: 211/634 Loss: 0.180454
2023-01-05 00:59: Train Epoch 2: 215/634 Loss: 0.154102
2023-01-05 00:59: Train Epoch 2: 219/634 Loss: 0.172523
2023-01-05 00:59: Train Epoch 2: 223/634 Loss: 0.174693
2023-01-05 00:59: Train Epoch 2: 227/634 Loss: 0.182620
2023-01-05 00:59: Train Epoch 2: 231/634 Loss: 0.223775
2023-01-05 00:59: Train Epoch 2: 235/634 Loss: 0.199339
2023-01-05 00:59: Train Epoch 2: 239/634 Loss: 0.174164
2023-01-05 01:00: Train Epoch 2: 243/634 Loss: 0.205349
2023-01-05 01:00: Train Epoch 2: 247/634 Loss: 0.194843
2023-01-05 01:00: Train Epoch 2: 251/634 Loss: 0.213230
2023-01-05 01:00: Train Epoch 2: 255/634 Loss: 0.180566
2023-01-05 01:00: Train Epoch 2: 259/634 Loss: 0.179750
2023-01-05 01:00: Train Epoch 2: 263/634 Loss: 0.199060
2023-01-05 01:00: Train Epoch 2: 267/634 Loss: 0.214012
2023-01-05 01:00: Train Epoch 2: 271/634 Loss: 0.205325
2023-01-05 01:00: Train Epoch 2: 275/634 Loss: 0.188007
2023-01-05 01:01: Train Epoch 2: 279/634 Loss: 0.184215
2023-01-05 01:01: Train Epoch 2: 283/634 Loss: 0.170643
2023-01-05 01:01: Train Epoch 2: 287/634 Loss: 0.196363
2023-01-05 01:01: Train Epoch 2: 291/634 Loss: 0.218439
2023-01-05 01:01: Train Epoch 2: 295/634 Loss: 0.163294
2023-01-05 01:01: Train Epoch 2: 299/634 Loss: 0.174048
2023-01-05 01:01: Train Epoch 2: 303/634 Loss: 0.195943
2023-01-05 01:01: Train Epoch 2: 307/634 Loss: 0.176967
2023-01-05 01:01: Train Epoch 2: 311/634 Loss: 0.205155
2023-01-05 01:01: Train Epoch 2: 315/634 Loss: 0.163502
2023-01-05 01:01: Train Epoch 2: 319/634 Loss: 0.190872
2023-01-05 01:02: Train Epoch 2: 323/634 Loss: 0.206906
2023-01-05 01:02: Train Epoch 2: 327/634 Loss: 0.222807
2023-01-05 01:02: Train Epoch 2: 331/634 Loss: 0.167740
2023-01-05 01:02: Train Epoch 2: 335/634 Loss: 0.197219
2023-01-05 01:02: Train Epoch 2: 339/634 Loss: 0.193648
2023-01-05 01:02: Train Epoch 2: 343/634 Loss: 0.187896
2023-01-05 01:02: Train Epoch 2: 347/634 Loss: 0.176979
2023-01-05 01:02: Train Epoch 2: 351/634 Loss: 0.170795
2023-01-05 01:02: Train Epoch 2: 355/634 Loss: 0.182778
2023-01-05 01:03: Train Epoch 2: 359/634 Loss: 0.210884
2023-01-05 01:03: Train Epoch 2: 363/634 Loss: 0.213526
2023-01-05 01:03: Train Epoch 2: 367/634 Loss: 0.190833
2023-01-05 01:03: Train Epoch 2: 371/634 Loss: 0.175336
2023-01-05 01:03: Train Epoch 2: 375/634 Loss: 0.199088
2023-01-05 01:03: Train Epoch 2: 379/634 Loss: 0.189336
2023-01-05 01:03: Train Epoch 2: 383/634 Loss: 0.180914
2023-01-05 01:03: Train Epoch 2: 387/634 Loss: 0.173535
2023-01-05 01:03: Train Epoch 2: 391/634 Loss: 0.190210
2023-01-05 01:03: Train Epoch 2: 395/634 Loss: 0.169416
2023-01-05 01:03: Train Epoch 2: 399/634 Loss: 0.184539
2023-01-05 01:04: Train Epoch 2: 403/634 Loss: 0.192736
2023-01-05 01:04: Train Epoch 2: 407/634 Loss: 0.170884
2023-01-05 01:04: Train Epoch 2: 411/634 Loss: 0.208768
2023-01-05 01:04: Train Epoch 2: 415/634 Loss: 0.141743
2023-01-05 01:04: Train Epoch 2: 419/634 Loss: 0.188486
2023-01-05 01:04: Train Epoch 2: 423/634 Loss: 0.166180
2023-01-05 01:04: Train Epoch 2: 427/634 Loss: 0.176402
2023-01-05 01:04: Train Epoch 2: 431/634 Loss: 0.209033
2023-01-05 01:04: Train Epoch 2: 435/634 Loss: 0.199429
2023-01-05 01:04: Train Epoch 2: 439/634 Loss: 0.175389
2023-01-05 01:04: Train Epoch 2: 443/634 Loss: 0.189582
2023-01-05 01:05: Train Epoch 2: 447/634 Loss: 0.172598
2023-01-05 01:05: Train Epoch 2: 451/634 Loss: 0.163534
2023-01-05 01:05: Train Epoch 2: 455/634 Loss: 0.203419
2023-01-05 01:05: Train Epoch 2: 459/634 Loss: 0.160297
2023-01-05 01:05: Train Epoch 2: 463/634 Loss: 0.197322
2023-01-05 01:05: Train Epoch 2: 467/634 Loss: 0.193717
2023-01-05 01:05: Train Epoch 2: 471/634 Loss: 0.187406
2023-01-05 01:05: Train Epoch 2: 475/634 Loss: 0.191080
2023-01-05 01:05: Train Epoch 2: 479/634 Loss: 0.185643
2023-01-05 01:05: Train Epoch 2: 483/634 Loss: 0.197167
2023-01-05 01:06: Train Epoch 2: 487/634 Loss: 0.180653
2023-01-05 01:06: Train Epoch 2: 491/634 Loss: 0.145997
2023-01-05 01:06: Train Epoch 2: 495/634 Loss: 0.161238
2023-01-05 01:06: Train Epoch 2: 499/634 Loss: 0.189076
2023-01-05 01:06: Train Epoch 2: 503/634 Loss: 0.173949
2023-01-05 01:06: Train Epoch 2: 507/634 Loss: 0.179523
2023-01-05 01:06: Train Epoch 2: 511/634 Loss: 0.167249
2023-01-05 01:06: Train Epoch 2: 515/634 Loss: 0.181605
2023-01-05 01:06: Train Epoch 2: 519/634 Loss: 0.178756
2023-01-05 01:06: Train Epoch 2: 523/634 Loss: 0.176349
2023-01-05 01:06: Train Epoch 2: 527/634 Loss: 0.195151
2023-01-05 01:07: Train Epoch 2: 531/634 Loss: 0.207347
2023-01-05 01:07: Train Epoch 2: 535/634 Loss: 0.155560
2023-01-05 01:07: Train Epoch 2: 539/634 Loss: 0.194093
2023-01-05 01:07: Train Epoch 2: 543/634 Loss: 0.180740
2023-01-05 01:07: Train Epoch 2: 547/634 Loss: 0.162144
2023-01-05 01:07: Train Epoch 2: 551/634 Loss: 0.180025
2023-01-05 01:07: Train Epoch 2: 555/634 Loss: 0.187827
2023-01-05 01:07: Train Epoch 2: 559/634 Loss: 0.176216
2023-01-05 01:08: Train Epoch 2: 563/634 Loss: 0.196118
2023-01-05 01:08: Train Epoch 2: 567/634 Loss: 0.207452
2023-01-05 01:08: Train Epoch 2: 571/634 Loss: 0.167149
2023-01-05 01:08: Train Epoch 2: 575/634 Loss: 0.159354
2023-01-05 01:08: Train Epoch 2: 579/634 Loss: 0.194619
2023-01-05 01:08: Train Epoch 2: 583/634 Loss: 0.168163
2023-01-05 01:08: Train Epoch 2: 587/634 Loss: 0.153332
2023-01-05 01:08: Train Epoch 2: 591/634 Loss: 0.167468
2023-01-05 01:09: Train Epoch 2: 595/634 Loss: 0.160362
2023-01-05 01:09: Train Epoch 2: 599/634 Loss: 0.146259
2023-01-05 01:09: Train Epoch 2: 603/634 Loss: 0.162454
2023-01-05 01:09: Train Epoch 2: 607/634 Loss: 0.148617
2023-01-05 01:09: Train Epoch 2: 611/634 Loss: 0.182513
2023-01-05 01:09: Train Epoch 2: 615/634 Loss: 0.167261
2023-01-05 01:09: Train Epoch 2: 619/634 Loss: 0.173786
2023-01-05 01:09: Train Epoch 2: 623/634 Loss: 0.176354
2023-01-05 01:10: Train Epoch 2: 627/634 Loss: 0.192745
2023-01-05 01:10: Train Epoch 2: 631/634 Loss: 0.222843
2023-01-05 01:10: Train Epoch 2: 633/634 Loss: 0.078662
2023-01-05 01:10: **********Train Epoch 2: averaged Loss: 0.186607 
2023-01-05 01:10: 
Epoch time elapsed: 979.5968747138977

2023-01-05 01:11: 
 metrics validation: {'precision': 0.6981627296587927, 'recall': 0.6138461538461538, 'f1-score': 0.653295128939828, 'support': 1300, 'AUC': 0.8165334319526627, 'AUCPR': 0.7217318194431075, 'TP': 798, 'FP': 345, 'TN': 2255, 'FN': 502} 

2023-01-05 01:11: **********Val Epoch 2: average Loss: 0.277996
2023-01-05 01:12: 
 Testing metrics {'precision': 0.7801608579088471, 'recall': 0.7109120521172638, 'f1-score': 0.7439284192586281, 'support': 1228, 'AUC': 0.8553457795308173, 'AUCPR': 0.7565554582941824, 'TP': 873, 'FP': 246, 'TN': 2210, 'FN': 355} 

2023-01-05 01:16: 
 Testing metrics {'precision': 0.889959659345585, 'recall': 0.9010664851372816, 'f1-score': 0.8954786334423273, 'support': 4407, 'AUC': 0.9665027928370037, 'AUCPR': 0.9311616903513606, 'TP': 3971, 'FP': 491, 'TN': 8323, 'FN': 436} 

2023-01-05 01:16: Train Epoch 3: 3/634 Loss: 0.184786
2023-01-05 01:16: Train Epoch 3: 7/634 Loss: 0.226131
2023-01-05 01:16: Train Epoch 3: 11/634 Loss: 0.212026
2023-01-05 01:16: Train Epoch 3: 15/634 Loss: 0.190303
2023-01-05 01:16: Train Epoch 3: 19/634 Loss: 0.216835
2023-01-05 01:16: Train Epoch 3: 23/634 Loss: 0.200941
2023-01-05 01:16: Train Epoch 3: 27/634 Loss: 0.176072
2023-01-05 01:16: Train Epoch 3: 31/634 Loss: 0.182252
2023-01-05 01:16: Train Epoch 3: 35/634 Loss: 0.200802
2023-01-05 01:16: Train Epoch 3: 39/634 Loss: 0.197669
2023-01-05 01:17: Train Epoch 3: 43/634 Loss: 0.192169
2023-01-05 01:17: Train Epoch 3: 47/634 Loss: 0.180834
2023-01-05 01:17: Train Epoch 3: 51/634 Loss: 0.197765
2023-01-05 01:17: Train Epoch 3: 55/634 Loss: 0.153859
2023-01-05 01:17: Train Epoch 3: 59/634 Loss: 0.173170
2023-01-05 01:17: Train Epoch 3: 63/634 Loss: 0.220514
2023-01-05 01:17: Train Epoch 3: 67/634 Loss: 0.183602
2023-01-05 01:17: Train Epoch 3: 71/634 Loss: 0.222172
2023-01-05 01:17: Train Epoch 3: 75/634 Loss: 0.176924
2023-01-05 01:17: Train Epoch 3: 79/634 Loss: 0.181889
2023-01-05 01:18: Train Epoch 3: 83/634 Loss: 0.202609
2023-01-05 01:18: Train Epoch 3: 87/634 Loss: 0.206800
2023-01-05 01:18: Train Epoch 3: 91/634 Loss: 0.207006
2023-01-05 01:18: Train Epoch 3: 95/634 Loss: 0.176644
2023-01-05 01:18: Train Epoch 3: 99/634 Loss: 0.175307
2023-01-05 01:18: Train Epoch 3: 103/634 Loss: 0.162251
2023-01-05 01:18: Train Epoch 3: 107/634 Loss: 0.181721
2023-01-05 01:18: Train Epoch 3: 111/634 Loss: 0.182447
2023-01-05 01:18: Train Epoch 3: 115/634 Loss: 0.235252
2023-01-05 01:18: Train Epoch 3: 119/634 Loss: 0.206835
2023-01-05 01:19: Train Epoch 3: 123/634 Loss: 0.207095
2023-01-05 01:19: Train Epoch 3: 127/634 Loss: 0.191807
2023-01-05 01:19: Train Epoch 3: 131/634 Loss: 0.191371
2023-01-05 01:19: Train Epoch 3: 135/634 Loss: 0.185890
2023-01-05 01:19: Train Epoch 3: 139/634 Loss: 0.208608
2023-01-05 01:19: Train Epoch 3: 143/634 Loss: 0.183022
2023-01-05 01:19: Train Epoch 3: 147/634 Loss: 0.164780
2023-01-05 01:19: Train Epoch 3: 151/634 Loss: 0.167829
2023-01-05 01:19: Train Epoch 3: 155/634 Loss: 0.200683
2023-01-05 01:19: Train Epoch 3: 159/634 Loss: 0.204145
2023-01-05 01:19: Train Epoch 3: 163/634 Loss: 0.208801
2023-01-05 01:20: Train Epoch 3: 167/634 Loss: 0.182827
2023-01-05 01:20: Train Epoch 3: 171/634 Loss: 0.191082
2023-01-05 01:20: Train Epoch 3: 175/634 Loss: 0.168609
2023-01-05 01:20: Train Epoch 3: 179/634 Loss: 0.212565
2023-01-05 01:20: Train Epoch 3: 183/634 Loss: 0.188365
2023-01-05 01:20: Train Epoch 3: 187/634 Loss: 0.175967
2023-01-05 01:20: Train Epoch 3: 191/634 Loss: 0.202471
2023-01-05 01:20: Train Epoch 3: 195/634 Loss: 0.211012
2023-01-05 01:20: Train Epoch 3: 199/634 Loss: 0.180062
2023-01-05 01:20: Train Epoch 3: 203/634 Loss: 0.203012
2023-01-05 01:21: Train Epoch 3: 207/634 Loss: 0.185922
2023-01-05 01:21: Train Epoch 3: 211/634 Loss: 0.182429
2023-01-05 01:21: Train Epoch 3: 215/634 Loss: 0.180972
2023-01-05 01:21: Train Epoch 3: 219/634 Loss: 0.181087
2023-01-05 01:21: Train Epoch 3: 223/634 Loss: 0.188728
2023-01-05 01:21: Train Epoch 3: 227/634 Loss: 0.193840
2023-01-05 01:21: Train Epoch 3: 231/634 Loss: 0.215197
2023-01-05 01:21: Train Epoch 3: 235/634 Loss: 0.205497
2023-01-05 01:21: Train Epoch 3: 239/634 Loss: 0.153118
2023-01-05 01:21: Train Epoch 3: 243/634 Loss: 0.165742
2023-01-05 01:21: Train Epoch 3: 247/634 Loss: 0.174656
2023-01-05 01:22: Train Epoch 3: 251/634 Loss: 0.188447
2023-01-05 01:22: Train Epoch 3: 255/634 Loss: 0.182094
2023-01-05 01:22: Train Epoch 3: 259/634 Loss: 0.184725
2023-01-05 01:22: Train Epoch 3: 263/634 Loss: 0.232301
2023-01-05 01:22: Train Epoch 3: 267/634 Loss: 0.219556
2023-01-05 01:22: Train Epoch 3: 271/634 Loss: 0.201838
2023-01-05 01:22: Train Epoch 3: 275/634 Loss: 0.177530
2023-01-05 01:22: Train Epoch 3: 279/634 Loss: 0.191427
2023-01-05 01:22: Train Epoch 3: 283/634 Loss: 0.156618
2023-01-05 01:22: Train Epoch 3: 287/634 Loss: 0.177916
2023-01-05 01:23: Train Epoch 3: 291/634 Loss: 0.208449
2023-01-05 01:23: Train Epoch 3: 295/634 Loss: 0.194873
2023-01-05 01:23: Train Epoch 3: 299/634 Loss: 0.205794
2023-01-05 01:23: Train Epoch 3: 303/634 Loss: 0.199931
2023-01-05 01:23: Train Epoch 3: 307/634 Loss: 0.210965
2023-01-05 01:23: Train Epoch 3: 311/634 Loss: 0.175111
2023-01-05 01:23: Train Epoch 3: 315/634 Loss: 0.222143
2023-01-05 01:23: Train Epoch 3: 319/634 Loss: 0.195058
2023-01-05 01:23: Train Epoch 3: 323/634 Loss: 0.156011
2023-01-05 01:23: Train Epoch 3: 327/634 Loss: 0.195915
2023-01-05 01:23: Train Epoch 3: 331/634 Loss: 0.197198
2023-01-05 01:24: Train Epoch 3: 335/634 Loss: 0.210698
2023-01-05 01:24: Train Epoch 3: 339/634 Loss: 0.232162
2023-01-05 01:24: Train Epoch 3: 343/634 Loss: 0.179388
2023-01-05 01:24: Train Epoch 3: 347/634 Loss: 0.193353
2023-01-05 01:24: Train Epoch 3: 351/634 Loss: 0.186266
2023-01-05 01:24: Train Epoch 3: 355/634 Loss: 0.204836
2023-01-05 01:24: Train Epoch 3: 359/634 Loss: 0.169869
2023-01-05 01:24: Train Epoch 3: 363/634 Loss: 0.173432
2023-01-05 01:24: Train Epoch 3: 367/634 Loss: 0.223087
2023-01-05 01:24: Train Epoch 3: 371/634 Loss: 0.198398
2023-01-05 01:25: Train Epoch 3: 375/634 Loss: 0.198532
2023-01-05 01:25: Train Epoch 3: 379/634 Loss: 0.188993
2023-01-05 01:25: Train Epoch 3: 383/634 Loss: 0.209604
2023-01-05 01:25: Train Epoch 3: 387/634 Loss: 0.156446
2023-01-05 01:25: Train Epoch 3: 391/634 Loss: 0.177794
2023-01-05 01:25: Train Epoch 3: 395/634 Loss: 0.194472
2023-01-05 01:25: Train Epoch 3: 399/634 Loss: 0.190813
2023-01-05 01:25: Train Epoch 3: 403/634 Loss: 0.178653
2023-01-05 01:25: Train Epoch 3: 407/634 Loss: 0.210298
2023-01-05 01:25: Train Epoch 3: 411/634 Loss: 0.162631
2023-01-05 01:26: Train Epoch 3: 415/634 Loss: 0.212757
2023-01-05 01:26: Train Epoch 3: 419/634 Loss: 0.198592
2023-01-05 01:26: Train Epoch 3: 423/634 Loss: 0.191917
2023-01-05 01:26: Train Epoch 3: 427/634 Loss: 0.208131
2023-01-05 01:26: Train Epoch 3: 431/634 Loss: 0.180217
2023-01-05 01:26: Train Epoch 3: 435/634 Loss: 0.162248
2023-01-05 01:26: Train Epoch 3: 439/634 Loss: 0.208957
2023-01-05 01:26: Train Epoch 3: 443/634 Loss: 0.175721
2023-01-05 01:26: Train Epoch 3: 447/634 Loss: 0.157450
2023-01-05 01:26: Train Epoch 3: 451/634 Loss: 0.162773
2023-01-05 01:27: Train Epoch 3: 455/634 Loss: 0.179532
2023-01-05 01:27: Train Epoch 3: 459/634 Loss: 0.179151
2023-01-05 01:27: Train Epoch 3: 463/634 Loss: 0.185565
2023-01-05 01:27: Train Epoch 3: 467/634 Loss: 0.187411
2023-01-05 01:27: Train Epoch 3: 471/634 Loss: 0.213035
2023-01-05 01:27: Train Epoch 3: 475/634 Loss: 0.140961
2023-01-05 01:27: Train Epoch 3: 479/634 Loss: 0.179183
2023-01-05 01:27: Train Epoch 3: 483/634 Loss: 0.186070
2023-01-05 01:27: Train Epoch 3: 487/634 Loss: 0.234097
2023-01-05 01:27: Train Epoch 3: 491/634 Loss: 0.196403
2023-01-05 01:27: Train Epoch 3: 495/634 Loss: 0.203570
2023-01-05 01:28: Train Epoch 3: 499/634 Loss: 0.164549
2023-01-05 01:28: Train Epoch 3: 503/634 Loss: 0.169392
2023-01-05 01:28: Train Epoch 3: 507/634 Loss: 0.170690
2023-01-05 01:28: Train Epoch 3: 511/634 Loss: 0.233597
2023-01-05 01:28: Train Epoch 3: 515/634 Loss: 0.177783
2023-01-05 01:28: Train Epoch 3: 519/634 Loss: 0.178194
2023-01-05 01:28: Train Epoch 3: 523/634 Loss: 0.189444
2023-01-05 01:28: Train Epoch 3: 527/634 Loss: 0.167583
2023-01-05 01:28: Train Epoch 3: 531/634 Loss: 0.184315
2023-01-05 01:28: Train Epoch 3: 535/634 Loss: 0.200192
2023-01-05 01:29: Train Epoch 3: 539/634 Loss: 0.166711
2023-01-05 01:29: Train Epoch 3: 543/634 Loss: 0.193840
2023-01-05 01:29: Train Epoch 3: 547/634 Loss: 0.166661
2023-01-05 01:29: Train Epoch 3: 551/634 Loss: 0.201831
2023-01-05 01:29: Train Epoch 3: 555/634 Loss: 0.187055
2023-01-05 01:29: Train Epoch 3: 559/634 Loss: 0.207922
2023-01-05 01:29: Train Epoch 3: 563/634 Loss: 0.174603
2023-01-05 01:29: Train Epoch 3: 567/634 Loss: 0.153034
2023-01-05 01:29: Train Epoch 3: 571/634 Loss: 0.197773
2023-01-05 01:29: Train Epoch 3: 575/634 Loss: 0.171835
2023-01-05 01:29: Train Epoch 3: 579/634 Loss: 0.171750
2023-01-05 01:30: Train Epoch 3: 583/634 Loss: 0.179075
2023-01-05 01:30: Train Epoch 3: 587/634 Loss: 0.192020
2023-01-05 01:30: Train Epoch 3: 591/634 Loss: 0.191533
2023-01-05 01:30: Train Epoch 3: 595/634 Loss: 0.156306
2023-01-05 01:30: Train Epoch 3: 599/634 Loss: 0.189878
2023-01-05 01:30: Train Epoch 3: 603/634 Loss: 0.143829
2023-01-05 01:30: Train Epoch 3: 607/634 Loss: 0.194509
2023-01-05 01:30: Train Epoch 3: 611/634 Loss: 0.164315
2023-01-05 01:30: Train Epoch 3: 615/634 Loss: 0.178430
2023-01-05 01:30: Train Epoch 3: 619/634 Loss: 0.191078
2023-01-05 01:31: Train Epoch 3: 623/634 Loss: 0.177488
2023-01-05 01:31: Train Epoch 3: 627/634 Loss: 0.213283
2023-01-05 01:31: Train Epoch 3: 631/634 Loss: 0.163571
2023-01-05 01:31: Train Epoch 3: 633/634 Loss: 0.082791
2023-01-05 01:31: **********Train Epoch 3: averaged Loss: 0.188484 
2023-01-05 01:31: 
Epoch time elapsed: 916.6393029689789

2023-01-05 01:32: 
 metrics validation: {'precision': 0.6519421172886519, 'recall': 0.6584615384615384, 'f1-score': 0.655185610409491, 'support': 1300, 'AUC': 0.8138159763313609, 'AUCPR': 0.717695684495975, 'TP': 856, 'FP': 457, 'TN': 2143, 'FN': 444} 

2023-01-05 01:32: **********Val Epoch 3: average Loss: 0.261665
2023-01-05 01:32: 
 Testing metrics {'precision': 0.7801608579088471, 'recall': 0.7109120521172638, 'f1-score': 0.7439284192586281, 'support': 1228, 'AUC': 0.8553457795308173, 'AUCPR': 0.7565554582941824, 'TP': 873, 'FP': 246, 'TN': 2210, 'FN': 355} 

2023-01-05 01:35: 
 Testing metrics {'precision': 0.889959659345585, 'recall': 0.9010664851372816, 'f1-score': 0.8954786334423273, 'support': 4407, 'AUC': 0.9665027928370037, 'AUCPR': 0.9311616903513606, 'TP': 3971, 'FP': 491, 'TN': 8323, 'FN': 436} 

2023-01-05 01:35: Train Epoch 4: 3/634 Loss: 0.186844
2023-01-05 01:35: Train Epoch 4: 7/634 Loss: 0.201922
2023-01-05 01:35: Train Epoch 4: 11/634 Loss: 0.187368
2023-01-05 01:36: Train Epoch 4: 15/634 Loss: 0.183553
2023-01-05 01:36: Train Epoch 4: 19/634 Loss: 0.175828
2023-01-05 01:36: Train Epoch 4: 23/634 Loss: 0.220003
2023-01-05 01:36: Train Epoch 4: 27/634 Loss: 0.197244
2023-01-05 01:36: Train Epoch 4: 31/634 Loss: 0.209103
2023-01-05 01:36: Train Epoch 4: 35/634 Loss: 0.180004
2023-01-05 01:36: Train Epoch 4: 39/634 Loss: 0.173566
2023-01-05 01:36: Train Epoch 4: 43/634 Loss: 0.203101
2023-01-05 01:36: Train Epoch 4: 47/634 Loss: 0.217741
2023-01-05 01:36: Train Epoch 4: 51/634 Loss: 0.214892
2023-01-05 01:37: Train Epoch 4: 55/634 Loss: 0.203149
2023-01-05 01:37: Train Epoch 4: 59/634 Loss: 0.192605
2023-01-05 01:37: Train Epoch 4: 63/634 Loss: 0.207112
2023-01-05 01:37: Train Epoch 4: 67/634 Loss: 0.236974
2023-01-05 01:37: Train Epoch 4: 71/634 Loss: 0.203203
2023-01-05 01:37: Train Epoch 4: 75/634 Loss: 0.221497
2023-01-05 01:37: Train Epoch 4: 79/634 Loss: 0.226660
2023-01-05 01:37: Train Epoch 4: 83/634 Loss: 0.210529
2023-01-05 01:37: Train Epoch 4: 87/634 Loss: 0.186609
2023-01-05 01:37: Train Epoch 4: 91/634 Loss: 0.177759
2023-01-05 01:38: Train Epoch 4: 95/634 Loss: 0.227269
2023-01-05 01:38: Train Epoch 4: 99/634 Loss: 0.217538
2023-01-05 01:38: Train Epoch 4: 103/634 Loss: 0.254090
2023-01-05 01:38: Train Epoch 4: 107/634 Loss: 0.200500
2023-01-05 01:38: Train Epoch 4: 111/634 Loss: 0.205883
2023-01-05 01:38: Train Epoch 4: 115/634 Loss: 0.222609
2023-01-05 01:38: Train Epoch 4: 119/634 Loss: 0.241570
2023-01-05 01:38: Train Epoch 4: 123/634 Loss: 0.243280
2023-01-05 01:38: Train Epoch 4: 127/634 Loss: 0.190070
2023-01-05 01:38: Train Epoch 4: 131/634 Loss: 0.179815
2023-01-05 01:38: Train Epoch 4: 135/634 Loss: 0.177565
2023-01-05 01:38: Train Epoch 4: 139/634 Loss: 0.195609
2023-01-05 01:39: Train Epoch 4: 143/634 Loss: 0.198953
2023-01-05 01:39: Train Epoch 4: 147/634 Loss: 0.203880
2023-01-05 01:39: Train Epoch 4: 151/634 Loss: 0.192351
2023-01-05 01:39: Train Epoch 4: 155/634 Loss: 0.198460
2023-01-05 01:39: Train Epoch 4: 159/634 Loss: 0.200743
2023-01-05 01:39: Train Epoch 4: 163/634 Loss: 0.190754
2023-01-05 01:39: Train Epoch 4: 167/634 Loss: 0.179381
2023-01-05 01:39: Train Epoch 4: 171/634 Loss: 0.176541
2023-01-05 01:39: Train Epoch 4: 175/634 Loss: 0.191883
2023-01-05 01:39: Train Epoch 4: 179/634 Loss: 0.207512
2023-01-05 01:39: Train Epoch 4: 183/634 Loss: 0.182005
2023-01-05 01:40: Train Epoch 4: 187/634 Loss: 0.207185
2023-01-05 01:40: Train Epoch 4: 191/634 Loss: 0.172590
2023-01-05 01:40: Train Epoch 4: 195/634 Loss: 0.190416
2023-01-05 01:40: Train Epoch 4: 199/634 Loss: 0.192635
2023-01-05 01:40: Train Epoch 4: 203/634 Loss: 0.185155
2023-01-05 01:40: Train Epoch 4: 207/634 Loss: 0.208794
2023-01-05 01:40: Train Epoch 4: 211/634 Loss: 0.207833
2023-01-05 01:40: Train Epoch 4: 215/634 Loss: 0.237049
2023-01-05 01:40: Train Epoch 4: 219/634 Loss: 0.190013
2023-01-05 01:40: Train Epoch 4: 223/634 Loss: 0.179570
2023-01-05 01:41: Train Epoch 4: 227/634 Loss: 0.178493
2023-01-05 01:41: Train Epoch 4: 231/634 Loss: 0.166498
2023-01-05 01:41: Train Epoch 4: 235/634 Loss: 0.178218
2023-01-05 01:41: Train Epoch 4: 239/634 Loss: 0.209527
2023-01-05 01:41: Train Epoch 4: 243/634 Loss: 0.213092
2023-01-05 01:41: Train Epoch 4: 247/634 Loss: 0.203128
2023-01-05 01:41: Train Epoch 4: 251/634 Loss: 0.172108
2023-01-05 01:41: Train Epoch 4: 255/634 Loss: 0.199619
2023-01-05 01:41: Train Epoch 4: 259/634 Loss: 0.249107
2023-01-05 01:41: Train Epoch 4: 263/634 Loss: 0.196604
2023-01-05 01:41: Train Epoch 4: 267/634 Loss: 0.206872
2023-01-05 01:42: Train Epoch 4: 271/634 Loss: 0.191188
2023-01-05 01:42: Train Epoch 4: 275/634 Loss: 0.216824
2023-01-05 01:42: Train Epoch 4: 279/634 Loss: 0.180291
2023-01-05 01:42: Train Epoch 4: 283/634 Loss: 0.153170
2023-01-05 01:42: Train Epoch 4: 287/634 Loss: 0.157497
2023-01-05 01:42: Train Epoch 4: 291/634 Loss: 0.149523
2023-01-05 01:42: Train Epoch 4: 295/634 Loss: 0.198862
2023-01-05 01:42: Train Epoch 4: 299/634 Loss: 0.205288
2023-01-05 01:42: Train Epoch 4: 303/634 Loss: 0.162585
2023-01-05 01:42: Train Epoch 4: 307/634 Loss: 0.177676
2023-01-05 01:43: Train Epoch 4: 311/634 Loss: 0.156673
2023-01-05 01:43: Train Epoch 4: 315/634 Loss: 0.225855
2023-01-05 01:43: Train Epoch 4: 319/634 Loss: 0.173752
2023-01-05 01:43: Train Epoch 4: 323/634 Loss: 0.194344
2023-01-05 01:43: Train Epoch 4: 327/634 Loss: 0.191112
2023-01-05 01:43: Train Epoch 4: 331/634 Loss: 0.195813
2023-01-05 01:43: Train Epoch 4: 335/634 Loss: 0.186316
2023-01-05 01:43: Train Epoch 4: 339/634 Loss: 0.185927
2023-01-05 01:43: Train Epoch 4: 343/634 Loss: 0.173622
2023-01-05 01:43: Train Epoch 4: 347/634 Loss: 0.199722
2023-01-05 01:43: Train Epoch 4: 351/634 Loss: 0.183005
2023-01-05 01:44: Train Epoch 4: 355/634 Loss: 0.192892
2023-01-05 01:44: Train Epoch 4: 359/634 Loss: 0.174777
2023-01-05 01:44: Train Epoch 4: 363/634 Loss: 0.154942
2023-01-05 01:44: Train Epoch 4: 367/634 Loss: 0.174824
2023-01-05 01:44: Train Epoch 4: 371/634 Loss: 0.170685
2023-01-05 01:44: Train Epoch 4: 375/634 Loss: 0.156502
2023-01-05 01:44: Train Epoch 4: 379/634 Loss: 0.140652
2023-01-05 01:44: Train Epoch 4: 383/634 Loss: 0.218193
2023-01-05 01:44: Train Epoch 4: 387/634 Loss: 0.170905
2023-01-05 01:44: Train Epoch 4: 391/634 Loss: 0.184956
2023-01-05 01:45: Train Epoch 4: 395/634 Loss: 0.216698
2023-01-05 01:45: Train Epoch 4: 399/634 Loss: 0.196976
2023-01-05 01:45: Train Epoch 4: 403/634 Loss: 0.192385
2023-01-05 01:45: Train Epoch 4: 407/634 Loss: 0.196513
2023-01-05 01:45: Train Epoch 4: 411/634 Loss: 0.170945
2023-01-05 01:45: Train Epoch 4: 415/634 Loss: 0.178367
2023-01-05 01:45: Train Epoch 4: 419/634 Loss: 0.143691
2023-01-05 01:45: Train Epoch 4: 423/634 Loss: 0.179592
2023-01-05 01:45: Train Epoch 4: 427/634 Loss: 0.158757
2023-01-05 01:45: Train Epoch 4: 431/634 Loss: 0.145737
2023-01-05 01:45: Train Epoch 4: 435/634 Loss: 0.188856
2023-01-05 01:46: Train Epoch 4: 439/634 Loss: 0.216631
2023-01-05 01:46: Train Epoch 4: 443/634 Loss: 0.177550
2023-01-05 01:46: Train Epoch 4: 447/634 Loss: 0.185765
2023-01-05 01:46: Train Epoch 4: 451/634 Loss: 0.168975
2023-01-05 01:46: Train Epoch 4: 455/634 Loss: 0.204127
2023-01-05 01:46: Train Epoch 4: 459/634 Loss: 0.187142
2023-01-05 01:46: Train Epoch 4: 463/634 Loss: 0.199081
2023-01-05 01:46: Train Epoch 4: 467/634 Loss: 0.173191
2023-01-05 01:46: Train Epoch 4: 471/634 Loss: 0.186646
2023-01-05 01:46: Train Epoch 4: 475/634 Loss: 0.208120
2023-01-05 01:46: Train Epoch 4: 479/634 Loss: 0.169394
2023-01-05 01:47: Train Epoch 4: 483/634 Loss: 0.170231
2023-01-05 01:47: Train Epoch 4: 487/634 Loss: 0.186676
2023-01-05 01:47: Train Epoch 4: 491/634 Loss: 0.185734
2023-01-05 01:47: Train Epoch 4: 495/634 Loss: 0.177403
2023-01-05 01:47: Train Epoch 4: 499/634 Loss: 0.174120
2023-01-05 01:47: Train Epoch 4: 503/634 Loss: 0.182096
2023-01-05 01:47: Train Epoch 4: 507/634 Loss: 0.181693
2023-01-05 01:47: Train Epoch 4: 511/634 Loss: 0.170532
2023-01-05 01:47: Train Epoch 4: 515/634 Loss: 0.178938
2023-01-05 01:47: Train Epoch 4: 519/634 Loss: 0.179445
2023-01-05 01:48: Train Epoch 4: 523/634 Loss: 0.177930
2023-01-05 01:48: Train Epoch 4: 527/634 Loss: 0.160265
2023-01-05 01:48: Train Epoch 4: 531/634 Loss: 0.185362
2023-01-05 01:48: Train Epoch 4: 535/634 Loss: 0.195429
2023-01-05 01:48: Train Epoch 4: 539/634 Loss: 0.159522
2023-01-05 01:48: Train Epoch 4: 543/634 Loss: 0.160738
2023-01-05 01:48: Train Epoch 4: 547/634 Loss: 0.153083
2023-01-05 01:48: Train Epoch 4: 551/634 Loss: 0.180820
2023-01-05 01:48: Train Epoch 4: 555/634 Loss: 0.200478
2023-01-05 01:48: Train Epoch 4: 559/634 Loss: 0.177993
2023-01-05 01:48: Train Epoch 4: 563/634 Loss: 0.172243
2023-01-05 01:49: Train Epoch 4: 567/634 Loss: 0.165461
2023-01-05 01:49: Train Epoch 4: 571/634 Loss: 0.190404
2023-01-05 01:49: Train Epoch 4: 575/634 Loss: 0.193856
2023-01-05 01:49: Train Epoch 4: 579/634 Loss: 0.134595
2023-01-05 01:49: Train Epoch 4: 583/634 Loss: 0.195265
2023-01-05 01:49: Train Epoch 4: 587/634 Loss: 0.177714
2023-01-05 01:49: Train Epoch 4: 591/634 Loss: 0.172369
2023-01-05 01:49: Train Epoch 4: 595/634 Loss: 0.201146
2023-01-05 01:49: Train Epoch 4: 599/634 Loss: 0.174686
2023-01-05 01:49: Train Epoch 4: 603/634 Loss: 0.166175
2023-01-05 01:49: Train Epoch 4: 607/634 Loss: 0.234007
2023-01-05 01:50: Train Epoch 4: 611/634 Loss: 0.178584
2023-01-05 01:50: Train Epoch 4: 615/634 Loss: 0.197367
2023-01-05 01:50: Train Epoch 4: 619/634 Loss: 0.201593
2023-01-05 01:50: Train Epoch 4: 623/634 Loss: 0.144094
2023-01-05 01:50: Train Epoch 4: 627/634 Loss: 0.208024
2023-01-05 01:50: Train Epoch 4: 631/634 Loss: 0.189027
2023-01-05 01:50: Train Epoch 4: 633/634 Loss: 0.060102
2023-01-05 01:50: **********Train Epoch 4: averaged Loss: 0.188546 
2023-01-05 01:50: 
Epoch time elapsed: 897.6146905422211

2023-01-05 01:51: 
 metrics validation: {'precision': 0.6768488745980707, 'recall': 0.6476923076923077, 'f1-score': 0.6619496855345913, 'support': 1300, 'AUC': 0.8192597633136095, 'AUCPR': 0.727221435445189, 'TP': 842, 'FP': 402, 'TN': 2198, 'FN': 458} 

2023-01-05 01:51: **********Val Epoch 4: average Loss: 0.252498
2023-01-05 01:51: *********************************Current best model saved!
2023-01-05 01:52: 
 Testing metrics {'precision': 0.7536988685813751, 'recall': 0.7052117263843648, 'f1-score': 0.7286495582667227, 'support': 1228, 'AUC': 0.8602604536918164, 'AUCPR': 0.7778531993833362, 'TP': 866, 'FP': 283, 'TN': 2173, 'FN': 362} 

2023-01-05 01:55: 
 Testing metrics {'precision': 0.8729917498914459, 'recall': 0.9124120717041071, 'f1-score': 0.8922667258404526, 'support': 4407, 'AUC': 0.967051381682369, 'AUCPR': 0.937167093817868, 'TP': 4021, 'FP': 585, 'TN': 8229, 'FN': 386} 

2023-01-05 01:55: Train Epoch 5: 3/634 Loss: 0.150641
2023-01-05 01:55: Train Epoch 5: 7/634 Loss: 0.197784
2023-01-05 01:55: Train Epoch 5: 11/634 Loss: 0.204778
2023-01-05 01:55: Train Epoch 5: 15/634 Loss: 0.182978
2023-01-05 01:55: Train Epoch 5: 19/634 Loss: 0.163324
2023-01-05 01:55: Train Epoch 5: 23/634 Loss: 0.183384
2023-01-05 01:55: Train Epoch 5: 27/634 Loss: 0.164239
2023-01-05 01:55: Train Epoch 5: 31/634 Loss: 0.165600
2023-01-05 01:56: Train Epoch 5: 35/634 Loss: 0.158707
2023-01-05 01:56: Train Epoch 5: 39/634 Loss: 0.190311
2023-01-05 01:56: Train Epoch 5: 43/634 Loss: 0.195398
2023-01-05 01:56: Train Epoch 5: 47/634 Loss: 0.154019
2023-01-05 01:56: Train Epoch 5: 51/634 Loss: 0.187001
2023-01-05 01:56: Train Epoch 5: 55/634 Loss: 0.194744
2023-01-05 01:56: Train Epoch 5: 59/634 Loss: 0.218354
2023-01-05 01:56: Train Epoch 5: 63/634 Loss: 0.197225
2023-01-05 01:56: Train Epoch 5: 67/634 Loss: 0.194865
2023-01-05 01:56: Train Epoch 5: 71/634 Loss: 0.193211
2023-01-05 01:56: Train Epoch 5: 75/634 Loss: 0.167360
2023-01-05 01:57: Train Epoch 5: 79/634 Loss: 0.155977
2023-01-05 01:57: Train Epoch 5: 83/634 Loss: 0.198129
2023-01-05 01:57: Train Epoch 5: 87/634 Loss: 0.164141
2023-01-05 01:57: Train Epoch 5: 91/634 Loss: 0.148598
2023-01-05 01:57: Train Epoch 5: 95/634 Loss: 0.164655
2023-01-05 01:57: Train Epoch 5: 99/634 Loss: 0.192019
2023-01-05 01:57: Train Epoch 5: 103/634 Loss: 0.170877
2023-01-05 01:57: Train Epoch 5: 107/634 Loss: 0.203426
2023-01-05 01:57: Train Epoch 5: 111/634 Loss: 0.169081
2023-01-05 01:57: Train Epoch 5: 115/634 Loss: 0.188914
2023-01-05 01:57: Train Epoch 5: 119/634 Loss: 0.186084
2023-01-05 01:58: Train Epoch 5: 123/634 Loss: 0.149573
2023-01-05 01:58: Train Epoch 5: 127/634 Loss: 0.160210
2023-01-05 01:58: Train Epoch 5: 131/634 Loss: 0.150524
2023-01-05 01:58: Train Epoch 5: 135/634 Loss: 0.184516
2023-01-05 01:58: Train Epoch 5: 139/634 Loss: 0.176755
2023-01-05 01:58: Train Epoch 5: 143/634 Loss: 0.154611
2023-01-05 01:58: Train Epoch 5: 147/634 Loss: 0.183407
2023-01-05 01:58: Train Epoch 5: 151/634 Loss: 0.151174
2023-01-05 01:58: Train Epoch 5: 155/634 Loss: 0.156719
2023-01-05 01:58: Train Epoch 5: 159/634 Loss: 0.165512
2023-01-05 01:59: Train Epoch 5: 163/634 Loss: 0.199878
2023-01-05 01:59: Train Epoch 5: 167/634 Loss: 0.175198
2023-01-05 01:59: Train Epoch 5: 171/634 Loss: 0.211447
2023-01-05 01:59: Train Epoch 5: 175/634 Loss: 0.147036
2023-01-05 01:59: Train Epoch 5: 179/634 Loss: 0.128390
2023-01-05 01:59: Train Epoch 5: 183/634 Loss: 0.191077
2023-01-05 01:59: Train Epoch 5: 187/634 Loss: 0.137832
2023-01-05 01:59: Train Epoch 5: 191/634 Loss: 0.166906
2023-01-05 01:59: Train Epoch 5: 195/634 Loss: 0.163948
2023-01-05 01:59: Train Epoch 5: 199/634 Loss: 0.157604
2023-01-05 01:59: Train Epoch 5: 203/634 Loss: 0.180444
2023-01-05 02:00: Train Epoch 5: 207/634 Loss: 0.159427
2023-01-05 02:00: Train Epoch 5: 211/634 Loss: 0.147313
2023-01-05 02:00: Train Epoch 5: 215/634 Loss: 0.185697
2023-01-05 02:00: Train Epoch 5: 219/634 Loss: 0.190059
2023-01-05 02:00: Train Epoch 5: 223/634 Loss: 0.173363
2023-01-05 02:00: Train Epoch 5: 227/634 Loss: 0.178598
2023-01-05 02:00: Train Epoch 5: 231/634 Loss: 0.210494
2023-01-05 02:00: Train Epoch 5: 235/634 Loss: 0.199596
2023-01-05 02:00: Train Epoch 5: 239/634 Loss: 0.149112
2023-01-05 02:01: Train Epoch 5: 243/634 Loss: 0.170945
2023-01-05 02:01: Train Epoch 5: 247/634 Loss: 0.150207
2023-01-05 02:01: Train Epoch 5: 251/634 Loss: 0.192892
2023-01-05 02:01: Train Epoch 5: 255/634 Loss: 0.197017
2023-01-05 02:01: Train Epoch 5: 259/634 Loss: 0.186236
2023-01-05 02:01: Train Epoch 5: 263/634 Loss: 0.172467
2023-01-05 02:01: Train Epoch 5: 267/634 Loss: 0.150383
2023-01-05 02:01: Train Epoch 5: 271/634 Loss: 0.178707
2023-01-05 02:01: Train Epoch 5: 275/634 Loss: 0.165085
2023-01-05 02:01: Train Epoch 5: 279/634 Loss: 0.167533
2023-01-05 02:02: Train Epoch 5: 283/634 Loss: 0.176973
2023-01-05 02:02: Train Epoch 5: 287/634 Loss: 0.170716
2023-01-05 02:02: Train Epoch 5: 291/634 Loss: 0.133401
2023-01-05 02:02: Train Epoch 5: 295/634 Loss: 0.173849
2023-01-05 02:02: Train Epoch 5: 299/634 Loss: 0.140576
2023-01-05 02:02: Train Epoch 5: 303/634 Loss: 0.205305
2023-01-05 02:02: Train Epoch 5: 307/634 Loss: 0.160548
2023-01-05 02:02: Train Epoch 5: 311/634 Loss: 0.197686
2023-01-05 02:02: Train Epoch 5: 315/634 Loss: 0.130898
2023-01-05 02:02: Train Epoch 5: 319/634 Loss: 0.144710
2023-01-05 02:02: Train Epoch 5: 323/634 Loss: 0.205931
2023-01-05 02:03: Train Epoch 5: 327/634 Loss: 0.134335
2023-01-05 02:03: Train Epoch 5: 331/634 Loss: 0.157535
2023-01-05 02:03: Train Epoch 5: 335/634 Loss: 0.161229
2023-01-05 02:03: Train Epoch 5: 339/634 Loss: 0.148238
2023-01-05 02:03: Train Epoch 5: 343/634 Loss: 0.180001
2023-01-05 02:03: Train Epoch 5: 347/634 Loss: 0.204986
2023-01-05 02:03: Train Epoch 5: 351/634 Loss: 0.162159
2023-01-05 02:03: Train Epoch 5: 355/634 Loss: 0.166152
2023-01-05 02:03: Train Epoch 5: 359/634 Loss: 0.140676
2023-01-05 02:03: Train Epoch 5: 363/634 Loss: 0.200116
2023-01-05 02:04: Train Epoch 5: 367/634 Loss: 0.170232
2023-01-05 02:04: Train Epoch 5: 371/634 Loss: 0.184085
2023-01-05 02:04: Train Epoch 5: 375/634 Loss: 0.170705
2023-01-05 02:04: Train Epoch 5: 379/634 Loss: 0.179291
2023-01-05 02:04: Train Epoch 5: 383/634 Loss: 0.156249
2023-01-05 02:04: Train Epoch 5: 387/634 Loss: 0.170690
2023-01-05 02:04: Train Epoch 5: 391/634 Loss: 0.187197
2023-01-05 02:04: Train Epoch 5: 395/634 Loss: 0.184953
2023-01-05 02:04: Train Epoch 5: 399/634 Loss: 0.169333
2023-01-05 02:04: Train Epoch 5: 403/634 Loss: 0.193283
2023-01-05 02:05: Train Epoch 5: 407/634 Loss: 0.166793
2023-01-05 02:05: Train Epoch 5: 411/634 Loss: 0.161910
2023-01-05 02:05: Train Epoch 5: 415/634 Loss: 0.197140
2023-01-05 02:05: Train Epoch 5: 419/634 Loss: 0.237774
2023-01-05 02:05: Train Epoch 5: 423/634 Loss: 0.196947
2023-01-05 02:05: Train Epoch 5: 427/634 Loss: 0.183686
2023-01-05 02:05: Train Epoch 5: 431/634 Loss: 0.173991
2023-01-05 02:05: Train Epoch 5: 435/634 Loss: 0.162997
2023-01-05 02:05: Train Epoch 5: 439/634 Loss: 0.165066
2023-01-05 02:05: Train Epoch 5: 443/634 Loss: 0.156102
2023-01-05 02:05: Train Epoch 5: 447/634 Loss: 0.149658
2023-01-05 02:06: Train Epoch 5: 451/634 Loss: 0.171049
2023-01-05 02:06: Train Epoch 5: 455/634 Loss: 0.143445
2023-01-05 02:06: Train Epoch 5: 459/634 Loss: 0.175950
2023-01-05 02:06: Train Epoch 5: 463/634 Loss: 0.181500
2023-01-05 02:06: Train Epoch 5: 467/634 Loss: 0.171724
2023-01-05 02:06: Train Epoch 5: 471/634 Loss: 0.165985
2023-01-05 02:06: Train Epoch 5: 475/634 Loss: 0.179248
2023-01-05 02:06: Train Epoch 5: 479/634 Loss: 0.157429
2023-01-05 02:06: Train Epoch 5: 483/634 Loss: 0.162765
2023-01-05 02:06: Train Epoch 5: 487/634 Loss: 0.182373
2023-01-05 02:06: Train Epoch 5: 491/634 Loss: 0.178132
2023-01-05 02:07: Train Epoch 5: 495/634 Loss: 0.161106
2023-01-05 02:07: Train Epoch 5: 499/634 Loss: 0.219161
2023-01-05 02:07: Train Epoch 5: 503/634 Loss: 0.158857
2023-01-05 02:07: Train Epoch 5: 507/634 Loss: 0.165157
2023-01-05 02:07: Train Epoch 5: 511/634 Loss: 0.175114
2023-01-05 02:07: Train Epoch 5: 515/634 Loss: 0.183511
2023-01-05 02:07: Train Epoch 5: 519/634 Loss: 0.198312
2023-01-05 02:07: Train Epoch 5: 523/634 Loss: 0.156278
2023-01-05 02:07: Train Epoch 5: 527/634 Loss: 0.166561
2023-01-05 02:07: Train Epoch 5: 531/634 Loss: 0.141041
2023-01-05 02:08: Train Epoch 5: 535/634 Loss: 0.187495
2023-01-05 02:08: Train Epoch 5: 539/634 Loss: 0.210255
2023-01-05 02:08: Train Epoch 5: 543/634 Loss: 0.179172
2023-01-05 02:08: Train Epoch 5: 547/634 Loss: 0.179404
2023-01-05 02:08: Train Epoch 5: 551/634 Loss: 0.172610
2023-01-05 02:08: Train Epoch 5: 555/634 Loss: 0.175376
2023-01-05 02:08: Train Epoch 5: 559/634 Loss: 0.162009
2023-01-05 02:08: Train Epoch 5: 563/634 Loss: 0.149945
2023-01-05 02:08: Train Epoch 5: 567/634 Loss: 0.156433
2023-01-05 02:08: Train Epoch 5: 571/634 Loss: 0.160334
2023-01-05 02:09: Train Epoch 5: 575/634 Loss: 0.132335
2023-01-05 02:09: Train Epoch 5: 579/634 Loss: 0.153744
2023-01-05 02:09: Train Epoch 5: 583/634 Loss: 0.190199
2023-01-05 02:09: Train Epoch 5: 587/634 Loss: 0.117226
2023-01-05 02:09: Train Epoch 5: 591/634 Loss: 0.154523
2023-01-05 02:09: Train Epoch 5: 595/634 Loss: 0.173856
2023-01-05 02:09: Train Epoch 5: 599/634 Loss: 0.170937
2023-01-05 02:09: Train Epoch 5: 603/634 Loss: 0.152715
2023-01-05 02:09: Train Epoch 5: 607/634 Loss: 0.184247
2023-01-05 02:09: Train Epoch 5: 611/634 Loss: 0.155155
2023-01-05 02:09: Train Epoch 5: 615/634 Loss: 0.194836
2023-01-05 02:10: Train Epoch 5: 619/634 Loss: 0.166982
2023-01-05 02:10: Train Epoch 5: 623/634 Loss: 0.186399
2023-01-05 02:10: Train Epoch 5: 627/634 Loss: 0.175318
2023-01-05 02:10: Train Epoch 5: 631/634 Loss: 0.165833
2023-01-05 02:10: Train Epoch 5: 633/634 Loss: 0.066457
2023-01-05 02:10: **********Train Epoch 5: averaged Loss: 0.171738 
2023-01-05 02:10: 
Epoch time elapsed: 918.3472354412079

2023-01-05 02:11: 
 metrics validation: {'precision': 0.6703125, 'recall': 0.66, 'f1-score': 0.6651162790697674, 'support': 1300, 'AUC': 0.822669822485207, 'AUCPR': 0.7434494680592819, 'TP': 858, 'FP': 422, 'TN': 2178, 'FN': 442} 

2023-01-05 02:11: **********Val Epoch 5: average Loss: 0.258604
2023-01-05 02:12: 
 Testing metrics {'precision': 0.7536988685813751, 'recall': 0.7052117263843648, 'f1-score': 0.7286495582667227, 'support': 1228, 'AUC': 0.8602604536918164, 'AUCPR': 0.7778531993833362, 'TP': 866, 'FP': 283, 'TN': 2173, 'FN': 362} 

2023-01-05 02:14: 
 Testing metrics {'precision': 0.8729917498914459, 'recall': 0.9124120717041071, 'f1-score': 0.8922667258404526, 'support': 4407, 'AUC': 0.967051381682369, 'AUCPR': 0.937167093817868, 'TP': 4021, 'FP': 585, 'TN': 8229, 'FN': 386} 

2023-01-05 02:15: Train Epoch 6: 3/634 Loss: 0.162576
2023-01-05 02:15: Train Epoch 6: 7/634 Loss: 0.171922
2023-01-05 02:15: Train Epoch 6: 11/634 Loss: 0.155691
2023-01-05 02:15: Train Epoch 6: 15/634 Loss: 0.184327
2023-01-05 02:15: Train Epoch 6: 19/634 Loss: 0.186423
2023-01-05 02:15: Train Epoch 6: 23/634 Loss: 0.173704
2023-01-05 02:15: Train Epoch 6: 27/634 Loss: 0.188430
2023-01-05 02:15: Train Epoch 6: 31/634 Loss: 0.204001
2023-01-05 02:15: Train Epoch 6: 35/634 Loss: 0.179072
2023-01-05 02:15: Train Epoch 6: 39/634 Loss: 0.158486
2023-01-05 02:15: Train Epoch 6: 43/634 Loss: 0.215497
2023-01-05 02:16: Train Epoch 6: 47/634 Loss: 0.162982
2023-01-05 02:16: Train Epoch 6: 51/634 Loss: 0.210433
2023-01-05 02:16: Train Epoch 6: 55/634 Loss: 0.137919
2023-01-05 02:16: Train Epoch 6: 59/634 Loss: 0.165508
2023-01-05 02:16: Train Epoch 6: 63/634 Loss: 0.176241
2023-01-05 02:16: Train Epoch 6: 67/634 Loss: 0.188072
2023-01-05 02:16: Train Epoch 6: 71/634 Loss: 0.187159
2023-01-05 02:16: Train Epoch 6: 75/634 Loss: 0.188795
2023-01-05 02:16: Train Epoch 6: 79/634 Loss: 0.173478
2023-01-05 02:16: Train Epoch 6: 83/634 Loss: 0.179453
2023-01-05 02:17: Train Epoch 6: 87/634 Loss: 0.198107
2023-01-05 02:17: Train Epoch 6: 91/634 Loss: 0.158521
2023-01-05 02:17: Train Epoch 6: 95/634 Loss: 0.197597
2023-01-05 02:17: Train Epoch 6: 99/634 Loss: 0.134468
2023-01-05 02:17: Train Epoch 6: 103/634 Loss: 0.165951
2023-01-05 02:17: Train Epoch 6: 107/634 Loss: 0.220004
2023-01-05 02:17: Train Epoch 6: 111/634 Loss: 0.168414
2023-01-05 02:17: Train Epoch 6: 115/634 Loss: 0.208366
2023-01-05 02:17: Train Epoch 6: 119/634 Loss: 0.173474
2023-01-05 02:17: Train Epoch 6: 123/634 Loss: 0.199024
2023-01-05 02:18: Train Epoch 6: 127/634 Loss: 0.166847
2023-01-05 02:18: Train Epoch 6: 131/634 Loss: 0.179715
2023-01-05 02:18: Train Epoch 6: 135/634 Loss: 0.208481
2023-01-05 02:18: Train Epoch 6: 139/634 Loss: 0.175787
2023-01-05 02:18: Train Epoch 6: 143/634 Loss: 0.150842
2023-01-05 02:18: Train Epoch 6: 147/634 Loss: 0.156607
2023-01-05 02:18: Train Epoch 6: 151/634 Loss: 0.199119
2023-01-05 02:18: Train Epoch 6: 155/634 Loss: 0.153691
2023-01-05 02:18: Train Epoch 6: 159/634 Loss: 0.151009
2023-01-05 02:18: Train Epoch 6: 163/634 Loss: 0.205924
2023-01-05 02:18: Train Epoch 6: 167/634 Loss: 0.147621
2023-01-05 02:19: Train Epoch 6: 171/634 Loss: 0.179566
2023-01-05 02:19: Train Epoch 6: 175/634 Loss: 0.173465
2023-01-05 02:19: Train Epoch 6: 179/634 Loss: 0.190902
2023-01-05 02:19: Train Epoch 6: 183/634 Loss: 0.155970
2023-01-05 02:19: Train Epoch 6: 187/634 Loss: 0.205285
2023-01-05 02:19: Train Epoch 6: 191/634 Loss: 0.198776
2023-01-05 02:19: Train Epoch 6: 195/634 Loss: 0.135868
2023-01-05 02:19: Train Epoch 6: 199/634 Loss: 0.162981
2023-01-05 02:19: Train Epoch 6: 203/634 Loss: 0.200832
2023-01-05 02:19: Train Epoch 6: 207/634 Loss: 0.162975
2023-01-05 02:20: Train Epoch 6: 211/634 Loss: 0.154224
2023-01-05 02:20: Train Epoch 6: 215/634 Loss: 0.159238
2023-01-05 02:20: Train Epoch 6: 219/634 Loss: 0.186110
2023-01-05 02:20: Train Epoch 6: 223/634 Loss: 0.195461
2023-01-05 02:20: Train Epoch 6: 227/634 Loss: 0.180939
2023-01-05 02:20: Train Epoch 6: 231/634 Loss: 0.170837
2023-01-05 02:20: Train Epoch 6: 235/634 Loss: 0.156716
2023-01-05 02:20: Train Epoch 6: 239/634 Loss: 0.203387
2023-01-05 02:20: Train Epoch 6: 243/634 Loss: 0.177250
2023-01-05 02:21: Train Epoch 6: 247/634 Loss: 0.185140
2023-01-05 02:21: Train Epoch 6: 251/634 Loss: 0.187796
2023-01-05 02:21: Train Epoch 6: 255/634 Loss: 0.174880
2023-01-05 02:21: Train Epoch 6: 259/634 Loss: 0.177453
2023-01-05 02:21: Train Epoch 6: 263/634 Loss: 0.187784
2023-01-05 02:21: Train Epoch 6: 267/634 Loss: 0.202837
2023-01-05 02:21: Train Epoch 6: 271/634 Loss: 0.171306
2023-01-05 02:21: Train Epoch 6: 275/634 Loss: 0.142227
2023-01-05 02:21: Train Epoch 6: 279/634 Loss: 0.178218
2023-01-05 02:21: Train Epoch 6: 283/634 Loss: 0.177755
2023-01-05 02:21: Train Epoch 6: 287/634 Loss: 0.201672
2023-01-05 02:22: Train Epoch 6: 291/634 Loss: 0.167992
2023-01-05 02:22: Train Epoch 6: 295/634 Loss: 0.153210
2023-01-05 02:22: Train Epoch 6: 299/634 Loss: 0.212534
2023-01-05 02:22: Train Epoch 6: 303/634 Loss: 0.139935
2023-01-05 02:22: Train Epoch 6: 307/634 Loss: 0.174386
2023-01-05 02:22: Train Epoch 6: 311/634 Loss: 0.215599
2023-01-05 02:22: Train Epoch 6: 315/634 Loss: 0.153236
2023-01-05 02:22: Train Epoch 6: 319/634 Loss: 0.162693
2023-01-05 02:22: Train Epoch 6: 323/634 Loss: 0.189956
2023-01-05 02:22: Train Epoch 6: 327/634 Loss: 0.126455
2023-01-05 02:23: Train Epoch 6: 331/634 Loss: 0.162319
2023-01-05 02:23: Train Epoch 6: 335/634 Loss: 0.189534
2023-01-05 02:23: Train Epoch 6: 339/634 Loss: 0.154195
2023-01-05 02:23: Train Epoch 6: 343/634 Loss: 0.180870
2023-01-05 02:23: Train Epoch 6: 347/634 Loss: 0.184457
2023-01-05 02:23: Train Epoch 6: 351/634 Loss: 0.159082
2023-01-05 02:23: Train Epoch 6: 355/634 Loss: 0.185916
2023-01-05 02:23: Train Epoch 6: 359/634 Loss: 0.157845
2023-01-05 02:23: Train Epoch 6: 363/634 Loss: 0.173092
2023-01-05 02:23: Train Epoch 6: 367/634 Loss: 0.142859
2023-01-05 02:24: Train Epoch 6: 371/634 Loss: 0.159387
2023-01-05 02:24: Train Epoch 6: 375/634 Loss: 0.203760
2023-01-05 02:24: Train Epoch 6: 379/634 Loss: 0.184068
2023-01-05 02:24: Train Epoch 6: 383/634 Loss: 0.170865
2023-01-05 02:24: Train Epoch 6: 387/634 Loss: 0.168845
2023-01-05 02:24: Train Epoch 6: 391/634 Loss: 0.151386
2023-01-05 02:24: Train Epoch 6: 395/634 Loss: 0.195932
2023-01-05 02:24: Train Epoch 6: 399/634 Loss: 0.171725
2023-01-05 02:24: Train Epoch 6: 403/634 Loss: 0.126498
2023-01-05 02:24: Train Epoch 6: 407/634 Loss: 0.147410
2023-01-05 02:25: Train Epoch 6: 411/634 Loss: 0.183183
2023-01-05 02:25: Train Epoch 6: 415/634 Loss: 0.157634
2023-01-05 02:25: Train Epoch 6: 419/634 Loss: 0.171554
2023-01-05 02:25: Train Epoch 6: 423/634 Loss: 0.165537
2023-01-05 02:25: Train Epoch 6: 427/634 Loss: 0.141145
2023-01-05 02:25: Train Epoch 6: 431/634 Loss: 0.132376
2023-01-05 02:25: Train Epoch 6: 435/634 Loss: 0.143001
2023-01-05 02:25: Train Epoch 6: 439/634 Loss: 0.179394
2023-01-05 02:25: Train Epoch 6: 443/634 Loss: 0.171748
2023-01-05 02:25: Train Epoch 6: 447/634 Loss: 0.174700
2023-01-05 02:25: Train Epoch 6: 451/634 Loss: 0.192612
2023-01-05 02:26: Train Epoch 6: 455/634 Loss: 0.149640
2023-01-05 02:26: Train Epoch 6: 459/634 Loss: 0.151328
2023-01-05 02:26: Train Epoch 6: 463/634 Loss: 0.197555
2023-01-05 02:26: Train Epoch 6: 467/634 Loss: 0.125418
2023-01-05 02:26: Train Epoch 6: 471/634 Loss: 0.172930
2023-01-05 02:26: Train Epoch 6: 475/634 Loss: 0.177778
2023-01-05 02:26: Train Epoch 6: 479/634 Loss: 0.201024
2023-01-05 02:26: Train Epoch 6: 483/634 Loss: 0.196644
2023-01-05 02:26: Train Epoch 6: 487/634 Loss: 0.216793
2023-01-05 02:26: Train Epoch 6: 491/634 Loss: 0.144695
2023-01-05 02:27: Train Epoch 6: 495/634 Loss: 0.186041
2023-01-05 02:27: Train Epoch 6: 499/634 Loss: 0.154412
2023-01-05 02:27: Train Epoch 6: 503/634 Loss: 0.171456
2023-01-05 02:27: Train Epoch 6: 507/634 Loss: 0.154694
2023-01-05 02:27: Train Epoch 6: 511/634 Loss: 0.160798
2023-01-05 02:27: Train Epoch 6: 515/634 Loss: 0.223927
2023-01-05 02:27: Train Epoch 6: 519/634 Loss: 0.148535
2023-01-05 02:27: Train Epoch 6: 523/634 Loss: 0.191370
2023-01-05 02:27: Train Epoch 6: 527/634 Loss: 0.188923
2023-01-05 02:28: Train Epoch 6: 531/634 Loss: 0.195470
2023-01-05 02:28: Train Epoch 6: 535/634 Loss: 0.217900
2023-01-05 02:28: Train Epoch 6: 539/634 Loss: 0.156201
2023-01-05 02:28: Train Epoch 6: 543/634 Loss: 0.160496
2023-01-05 02:28: Train Epoch 6: 547/634 Loss: 0.151661
2023-01-05 02:28: Train Epoch 6: 551/634 Loss: 0.173827
2023-01-05 02:28: Train Epoch 6: 555/634 Loss: 0.189561
2023-01-05 02:28: Train Epoch 6: 559/634 Loss: 0.154577
2023-01-05 02:29: Train Epoch 6: 563/634 Loss: 0.203500
2023-01-05 02:29: Train Epoch 6: 567/634 Loss: 0.170927
2023-01-05 02:29: Train Epoch 6: 571/634 Loss: 0.220823
2023-01-05 02:29: Train Epoch 6: 575/634 Loss: 0.177620
2023-01-05 02:29: Train Epoch 6: 579/634 Loss: 0.171043
2023-01-05 02:29: Train Epoch 6: 583/634 Loss: 0.168935
2023-01-05 02:29: Train Epoch 6: 587/634 Loss: 0.179619
2023-01-05 02:30: Train Epoch 6: 591/634 Loss: 0.164858
2023-01-05 02:30: Train Epoch 6: 595/634 Loss: 0.173312
2023-01-05 02:30: Train Epoch 6: 599/634 Loss: 0.140937
2023-01-05 02:30: Train Epoch 6: 603/634 Loss: 0.150290
2023-01-05 02:30: Train Epoch 6: 607/634 Loss: 0.163990
2023-01-05 02:30: Train Epoch 6: 611/634 Loss: 0.151951
2023-01-05 02:30: Train Epoch 6: 615/634 Loss: 0.158537
2023-01-05 02:30: Train Epoch 6: 619/634 Loss: 0.117896
2023-01-05 02:31: Train Epoch 6: 623/634 Loss: 0.154707
2023-01-05 02:31: Train Epoch 6: 627/634 Loss: 0.163626
2023-01-05 02:31: Train Epoch 6: 631/634 Loss: 0.175468
2023-01-05 02:31: Train Epoch 6: 633/634 Loss: 0.072242
2023-01-05 02:31: **********Train Epoch 6: averaged Loss: 0.172833 
2023-01-05 02:31: 
Epoch time elapsed: 986.2018949985504

2023-01-05 02:32: 
 metrics validation: {'precision': 0.7253649635036497, 'recall': 0.6115384615384616, 'f1-score': 0.6636060100166945, 'support': 1300, 'AUC': 0.825719526627219, 'AUCPR': 0.7434150482573443, 'TP': 795, 'FP': 301, 'TN': 2299, 'FN': 505} 

2023-01-05 02:32: **********Val Epoch 6: average Loss: 0.282969
2023-01-05 02:33: 
 Testing metrics {'precision': 0.7536988685813751, 'recall': 0.7052117263843648, 'f1-score': 0.7286495582667227, 'support': 1228, 'AUC': 0.8602604536918164, 'AUCPR': 0.7778531993833362, 'TP': 866, 'FP': 283, 'TN': 2173, 'FN': 362} 

2023-01-05 02:36: 
 Testing metrics {'precision': 0.8729917498914459, 'recall': 0.9124120717041071, 'f1-score': 0.8922667258404526, 'support': 4407, 'AUC': 0.967051381682369, 'AUCPR': 0.937167093817868, 'TP': 4021, 'FP': 585, 'TN': 8229, 'FN': 386} 

2023-01-05 02:36: Train Epoch 7: 3/634 Loss: 0.154485
2023-01-05 02:37: Train Epoch 7: 7/634 Loss: 0.167306
2023-01-05 02:37: Train Epoch 7: 11/634 Loss: 0.186317
2023-01-05 02:37: Train Epoch 7: 15/634 Loss: 0.179784
2023-01-05 02:37: Train Epoch 7: 19/634 Loss: 0.233069
2023-01-05 02:37: Train Epoch 7: 23/634 Loss: 0.177547
2023-01-05 02:37: Train Epoch 7: 27/634 Loss: 0.196001
2023-01-05 02:37: Train Epoch 7: 31/634 Loss: 0.190023
2023-01-05 02:37: Train Epoch 7: 35/634 Loss: 0.150204
2023-01-05 02:37: Train Epoch 7: 39/634 Loss: 0.168984
2023-01-05 02:37: Train Epoch 7: 43/634 Loss: 0.165036
2023-01-05 02:38: Train Epoch 7: 47/634 Loss: 0.190718
2023-01-05 02:38: Train Epoch 7: 51/634 Loss: 0.154197
2023-01-05 02:38: Train Epoch 7: 55/634 Loss: 0.189456
2023-01-05 02:38: Train Epoch 7: 59/634 Loss: 0.177025
2023-01-05 02:38: Train Epoch 7: 63/634 Loss: 0.167933
2023-01-05 02:38: Train Epoch 7: 67/634 Loss: 0.182816
2023-01-05 02:38: Train Epoch 7: 71/634 Loss: 0.163439
2023-01-05 02:38: Train Epoch 7: 75/634 Loss: 0.172060
2023-01-05 02:38: Train Epoch 7: 79/634 Loss: 0.161148
2023-01-05 02:38: Train Epoch 7: 83/634 Loss: 0.172721
2023-01-05 02:38: Train Epoch 7: 87/634 Loss: 0.181055
2023-01-05 02:39: Train Epoch 7: 91/634 Loss: 0.185297
2023-01-05 02:39: Train Epoch 7: 95/634 Loss: 0.156973
2023-01-05 02:39: Train Epoch 7: 99/634 Loss: 0.206907
2023-01-05 02:39: Train Epoch 7: 103/634 Loss: 0.166517
2023-01-05 02:39: Train Epoch 7: 107/634 Loss: 0.149709
2023-01-05 02:39: Train Epoch 7: 111/634 Loss: 0.197019
2023-01-05 02:39: Train Epoch 7: 115/634 Loss: 0.140434
2023-01-05 02:39: Train Epoch 7: 119/634 Loss: 0.176438
2023-01-05 02:39: Train Epoch 7: 123/634 Loss: 0.164490
2023-01-05 02:39: Train Epoch 7: 127/634 Loss: 0.180379
2023-01-05 02:40: Train Epoch 7: 131/634 Loss: 0.216477
2023-01-05 02:40: Train Epoch 7: 135/634 Loss: 0.226467
2023-01-05 02:40: Train Epoch 7: 139/634 Loss: 0.138755
2023-01-05 02:40: Train Epoch 7: 143/634 Loss: 0.174294
2023-01-05 02:40: Train Epoch 7: 147/634 Loss: 0.152167
2023-01-05 02:40: Train Epoch 7: 151/634 Loss: 0.164880
2023-01-05 02:40: Train Epoch 7: 155/634 Loss: 0.224488
2023-01-05 02:40: Train Epoch 7: 159/634 Loss: 0.161364
2023-01-05 02:40: Train Epoch 7: 163/634 Loss: 0.171547
2023-01-05 02:40: Train Epoch 7: 167/634 Loss: 0.172985
2023-01-05 02:41: Train Epoch 7: 171/634 Loss: 0.169969
2023-01-05 02:41: Train Epoch 7: 175/634 Loss: 0.170480
2023-01-05 02:41: Train Epoch 7: 179/634 Loss: 0.196672
2023-01-05 02:41: Train Epoch 7: 183/634 Loss: 0.168359
2023-01-05 02:41: Train Epoch 7: 187/634 Loss: 0.190038
2023-01-05 02:41: Train Epoch 7: 191/634 Loss: 0.166292
2023-01-05 02:41: Train Epoch 7: 195/634 Loss: 0.161833
2023-01-05 02:41: Train Epoch 7: 199/634 Loss: 0.173919
2023-01-05 02:41: Train Epoch 7: 203/634 Loss: 0.179100
2023-01-05 02:41: Train Epoch 7: 207/634 Loss: 0.147032
2023-01-05 02:41: Train Epoch 7: 211/634 Loss: 0.189294
2023-01-05 02:42: Train Epoch 7: 215/634 Loss: 0.163030
2023-01-05 02:42: Train Epoch 7: 219/634 Loss: 0.174976
2023-01-05 02:42: Train Epoch 7: 223/634 Loss: 0.154603
2023-01-05 02:42: Train Epoch 7: 227/634 Loss: 0.155134
2023-01-05 02:42: Train Epoch 7: 231/634 Loss: 0.166627
2023-01-05 02:42: Train Epoch 7: 235/634 Loss: 0.172873
2023-01-05 02:42: Train Epoch 7: 239/634 Loss: 0.146697
2023-01-05 02:42: Train Epoch 7: 243/634 Loss: 0.185305
2023-01-05 02:42: Train Epoch 7: 247/634 Loss: 0.165757
2023-01-05 02:42: Train Epoch 7: 251/634 Loss: 0.145060
2023-01-05 02:43: Train Epoch 7: 255/634 Loss: 0.168167
2023-01-05 02:43: Train Epoch 7: 259/634 Loss: 0.184645
2023-01-05 02:43: Train Epoch 7: 263/634 Loss: 0.174149
2023-01-05 02:43: Train Epoch 7: 267/634 Loss: 0.184103
2023-01-05 02:43: Train Epoch 7: 271/634 Loss: 0.196276
2023-01-05 02:43: Train Epoch 7: 275/634 Loss: 0.156471
2023-01-05 02:43: Train Epoch 7: 279/634 Loss: 0.163181
2023-01-05 02:43: Train Epoch 7: 283/634 Loss: 0.148047
2023-01-05 02:43: Train Epoch 7: 287/634 Loss: 0.184091
2023-01-05 02:43: Train Epoch 7: 291/634 Loss: 0.145180
2023-01-05 02:43: Train Epoch 7: 295/634 Loss: 0.216620
2023-01-05 02:44: Train Epoch 7: 299/634 Loss: 0.159935
2023-01-05 02:44: Train Epoch 7: 303/634 Loss: 0.172612
2023-01-05 02:44: Train Epoch 7: 307/634 Loss: 0.192934
2023-01-05 02:44: Train Epoch 7: 311/634 Loss: 0.176554
2023-01-05 02:44: Train Epoch 7: 315/634 Loss: 0.161273
2023-01-05 02:44: Train Epoch 7: 319/634 Loss: 0.164003
2023-01-05 02:44: Train Epoch 7: 323/634 Loss: 0.192212
2023-01-05 02:44: Train Epoch 7: 327/634 Loss: 0.139349
2023-01-05 02:44: Train Epoch 7: 331/634 Loss: 0.191468
2023-01-05 02:44: Train Epoch 7: 335/634 Loss: 0.141064
2023-01-05 02:44: Train Epoch 7: 339/634 Loss: 0.155241
2023-01-05 02:45: Train Epoch 7: 343/634 Loss: 0.186404
2023-01-05 02:45: Train Epoch 7: 347/634 Loss: 0.150818
2023-01-05 02:45: Train Epoch 7: 351/634 Loss: 0.145765
2023-01-05 02:45: Train Epoch 7: 355/634 Loss: 0.162079
2023-01-05 02:45: Train Epoch 7: 359/634 Loss: 0.158940
2023-01-05 02:45: Train Epoch 7: 363/634 Loss: 0.183771
2023-01-05 02:45: Train Epoch 7: 367/634 Loss: 0.163112
2023-01-05 02:45: Train Epoch 7: 371/634 Loss: 0.135507
2023-01-05 02:45: Train Epoch 7: 375/634 Loss: 0.145969
2023-01-05 02:45: Train Epoch 7: 379/634 Loss: 0.159402
2023-01-05 02:46: Train Epoch 7: 383/634 Loss: 0.149835
2023-01-05 02:46: Train Epoch 7: 387/634 Loss: 0.189184
2023-01-05 02:46: Train Epoch 7: 391/634 Loss: 0.178086
2023-01-05 02:46: Train Epoch 7: 395/634 Loss: 0.212868
2023-01-05 02:46: Train Epoch 7: 399/634 Loss: 0.154504
2023-01-05 02:46: Train Epoch 7: 403/634 Loss: 0.203763
2023-01-05 02:46: Train Epoch 7: 407/634 Loss: 0.127260
2023-01-05 02:46: Train Epoch 7: 411/634 Loss: 0.148647
2023-01-05 02:46: Train Epoch 7: 415/634 Loss: 0.196056
2023-01-05 02:46: Train Epoch 7: 419/634 Loss: 0.174339
2023-01-05 02:46: Train Epoch 7: 423/634 Loss: 0.128463
2023-01-05 02:47: Train Epoch 7: 427/634 Loss: 0.188986
2023-01-05 02:47: Train Epoch 7: 431/634 Loss: 0.148869
2023-01-05 02:47: Train Epoch 7: 435/634 Loss: 0.165645
2023-01-05 02:47: Train Epoch 7: 439/634 Loss: 0.203931
2023-01-05 02:47: Train Epoch 7: 443/634 Loss: 0.138809
2023-01-05 02:47: Train Epoch 7: 447/634 Loss: 0.189215
2023-01-05 02:47: Train Epoch 7: 451/634 Loss: 0.154451
2023-01-05 02:47: Train Epoch 7: 455/634 Loss: 0.160436
2023-01-05 02:47: Train Epoch 7: 459/634 Loss: 0.164772
2023-01-05 02:47: Train Epoch 7: 463/634 Loss: 0.166980
2023-01-05 02:48: Train Epoch 7: 467/634 Loss: 0.169310
2023-01-05 02:48: Train Epoch 7: 471/634 Loss: 0.187545
2023-01-05 02:48: Train Epoch 7: 475/634 Loss: 0.157695
2023-01-05 02:48: Train Epoch 7: 479/634 Loss: 0.161926
2023-01-05 02:48: Train Epoch 7: 483/634 Loss: 0.138566
2023-01-05 02:48: Train Epoch 7: 487/634 Loss: 0.158534
2023-01-05 02:48: Train Epoch 7: 491/634 Loss: 0.176478
2023-01-05 02:48: Train Epoch 7: 495/634 Loss: 0.197757
2023-01-05 02:48: Train Epoch 7: 499/634 Loss: 0.184031
2023-01-05 02:48: Train Epoch 7: 503/634 Loss: 0.219966
2023-01-05 02:48: Train Epoch 7: 507/634 Loss: 0.150286
2023-01-05 02:49: Train Epoch 7: 511/634 Loss: 0.171454
2023-01-05 02:49: Train Epoch 7: 515/634 Loss: 0.158851
2023-01-05 02:49: Train Epoch 7: 519/634 Loss: 0.156483
2023-01-05 02:49: Train Epoch 7: 523/634 Loss: 0.168789
2023-01-05 02:49: Train Epoch 7: 527/634 Loss: 0.171389
2023-01-05 02:49: Train Epoch 7: 531/634 Loss: 0.165210
2023-01-05 02:49: Train Epoch 7: 535/634 Loss: 0.186257
2023-01-05 02:49: Train Epoch 7: 539/634 Loss: 0.157380
2023-01-05 02:49: Train Epoch 7: 543/634 Loss: 0.178657
2023-01-05 02:49: Train Epoch 7: 547/634 Loss: 0.172022
2023-01-05 02:50: Train Epoch 7: 551/634 Loss: 0.165871
2023-01-05 02:50: Train Epoch 7: 555/634 Loss: 0.185246
2023-01-05 02:50: Train Epoch 7: 559/634 Loss: 0.179801
2023-01-05 02:50: Train Epoch 7: 563/634 Loss: 0.158126
2023-01-05 02:50: Train Epoch 7: 567/634 Loss: 0.206482
2023-01-05 02:50: Train Epoch 7: 571/634 Loss: 0.174340
2023-01-05 02:50: Train Epoch 7: 575/634 Loss: 0.164119
2023-01-05 02:50: Train Epoch 7: 579/634 Loss: 0.161011
2023-01-05 02:50: Train Epoch 7: 583/634 Loss: 0.211790
2023-01-05 02:50: Train Epoch 7: 587/634 Loss: 0.121744
2023-01-05 02:51: Train Epoch 7: 591/634 Loss: 0.167429
2023-01-05 02:51: Train Epoch 7: 595/634 Loss: 0.163007
2023-01-05 02:51: Train Epoch 7: 599/634 Loss: 0.188726
2023-01-05 02:51: Train Epoch 7: 603/634 Loss: 0.189226
2023-01-05 02:51: Train Epoch 7: 607/634 Loss: 0.188533
2023-01-05 02:51: Train Epoch 7: 611/634 Loss: 0.163772
2023-01-05 02:51: Train Epoch 7: 615/634 Loss: 0.165095
2023-01-05 02:51: Train Epoch 7: 619/634 Loss: 0.172483
2023-01-05 02:51: Train Epoch 7: 623/634 Loss: 0.191791
2023-01-05 02:51: Train Epoch 7: 627/634 Loss: 0.137324
2023-01-05 02:51: Train Epoch 7: 631/634 Loss: 0.169462
2023-01-05 02:52: Train Epoch 7: 633/634 Loss: 0.071610
2023-01-05 02:52: **********Train Epoch 7: averaged Loss: 0.170704 
2023-01-05 02:52: 
Epoch time elapsed: 908.5692493915558

2023-01-05 02:52: 
 metrics validation: {'precision': 0.6467195385724586, 'recall': 0.69, 'f1-score': 0.667659099367324, 'support': 1300, 'AUC': 0.8249860946745562, 'AUCPR': 0.7437993003151284, 'TP': 897, 'FP': 490, 'TN': 2110, 'FN': 403} 

2023-01-05 02:52: **********Val Epoch 7: average Loss: 0.267333
2023-01-05 02:53: 
 Testing metrics {'precision': 0.7536988685813751, 'recall': 0.7052117263843648, 'f1-score': 0.7286495582667227, 'support': 1228, 'AUC': 0.8602604536918164, 'AUCPR': 0.7778531993833362, 'TP': 866, 'FP': 283, 'TN': 2173, 'FN': 362} 

2023-01-05 02:56: 
 Testing metrics {'precision': 0.8729917498914459, 'recall': 0.9124120717041071, 'f1-score': 0.8922667258404526, 'support': 4407, 'AUC': 0.967051381682369, 'AUCPR': 0.937167093817868, 'TP': 4021, 'FP': 585, 'TN': 8229, 'FN': 386} 

2023-01-05 02:56: Train Epoch 8: 3/634 Loss: 0.162111
2023-01-05 02:56: Train Epoch 8: 7/634 Loss: 0.189055
2023-01-05 02:56: Train Epoch 8: 11/634 Loss: 0.184711
2023-01-05 02:56: Train Epoch 8: 15/634 Loss: 0.148579
2023-01-05 02:56: Train Epoch 8: 19/634 Loss: 0.167263
2023-01-05 02:57: Train Epoch 8: 23/634 Loss: 0.137377
2023-01-05 02:57: Train Epoch 8: 27/634 Loss: 0.179429
2023-01-05 02:57: Train Epoch 8: 31/634 Loss: 0.227330
2023-01-05 02:57: Train Epoch 8: 35/634 Loss: 0.220315
2023-01-05 02:57: Train Epoch 8: 39/634 Loss: 0.165166
2023-01-05 02:57: Train Epoch 8: 43/634 Loss: 0.198601
2023-01-05 02:57: Train Epoch 8: 47/634 Loss: 0.182397
2023-01-05 02:57: Train Epoch 8: 51/634 Loss: 0.170108
2023-01-05 02:57: Train Epoch 8: 55/634 Loss: 0.184375
2023-01-05 02:57: Train Epoch 8: 59/634 Loss: 0.169159
2023-01-05 02:58: Train Epoch 8: 63/634 Loss: 0.161633
2023-01-05 02:58: Train Epoch 8: 67/634 Loss: 0.209387
2023-01-05 02:58: Train Epoch 8: 71/634 Loss: 0.172763
2023-01-05 02:58: Train Epoch 8: 75/634 Loss: 0.162386
2023-01-05 02:58: Train Epoch 8: 79/634 Loss: 0.194365
2023-01-05 02:58: Train Epoch 8: 83/634 Loss: 0.192341
2023-01-05 02:58: Train Epoch 8: 87/634 Loss: 0.159154
2023-01-05 02:58: Train Epoch 8: 91/634 Loss: 0.162542
2023-01-05 02:58: Train Epoch 8: 95/634 Loss: 0.182890
2023-01-05 02:58: Train Epoch 8: 99/634 Loss: 0.150563
2023-01-05 02:59: Train Epoch 8: 103/634 Loss: 0.230474
2023-01-05 02:59: Train Epoch 8: 107/634 Loss: 0.156960
2023-01-05 02:59: Train Epoch 8: 111/634 Loss: 0.193982
2023-01-05 02:59: Train Epoch 8: 115/634 Loss: 0.160786
2023-01-05 02:59: Train Epoch 8: 119/634 Loss: 0.147393
2023-01-05 02:59: Train Epoch 8: 123/634 Loss: 0.182532
2023-01-05 02:59: Train Epoch 8: 127/634 Loss: 0.140569
2023-01-05 02:59: Train Epoch 8: 131/634 Loss: 0.157699
2023-01-05 02:59: Train Epoch 8: 135/634 Loss: 0.161678
2023-01-05 02:59: Train Epoch 8: 139/634 Loss: 0.162870
2023-01-05 02:59: Train Epoch 8: 143/634 Loss: 0.164494
2023-01-05 03:00: Train Epoch 8: 147/634 Loss: 0.165113
2023-01-05 03:00: Train Epoch 8: 151/634 Loss: 0.177325
2023-01-05 03:00: Train Epoch 8: 155/634 Loss: 0.226534
2023-01-05 03:00: Train Epoch 8: 159/634 Loss: 0.198446
2023-01-05 03:00: Train Epoch 8: 163/634 Loss: 0.121077
2023-01-05 03:00: Train Epoch 8: 167/634 Loss: 0.190468
2023-01-05 03:00: Train Epoch 8: 171/634 Loss: 0.191647
2023-01-05 03:00: Train Epoch 8: 175/634 Loss: 0.203272
2023-01-05 03:00: Train Epoch 8: 179/634 Loss: 0.172212
2023-01-05 03:00: Train Epoch 8: 183/634 Loss: 0.151422
2023-01-05 03:01: Train Epoch 8: 187/634 Loss: 0.163698
2023-01-05 03:01: Train Epoch 8: 191/634 Loss: 0.157367
2023-01-05 03:01: Train Epoch 8: 195/634 Loss: 0.198562
2023-01-05 03:01: Train Epoch 8: 199/634 Loss: 0.155582
2023-01-05 03:01: Train Epoch 8: 203/634 Loss: 0.156663
2023-01-05 03:01: Train Epoch 8: 207/634 Loss: 0.181547
2023-01-05 03:01: Train Epoch 8: 211/634 Loss: 0.172771
2023-01-05 03:01: Train Epoch 8: 215/634 Loss: 0.153093
2023-01-05 03:01: Train Epoch 8: 219/634 Loss: 0.155490
2023-01-05 03:01: Train Epoch 8: 223/634 Loss: 0.172760
2023-01-05 03:02: Train Epoch 8: 227/634 Loss: 0.161650
2023-01-05 03:02: Train Epoch 8: 231/634 Loss: 0.176247
2023-01-05 03:02: Train Epoch 8: 235/634 Loss: 0.169810
2023-01-05 03:02: Train Epoch 8: 239/634 Loss: 0.184101
2023-01-05 03:02: Train Epoch 8: 243/634 Loss: 0.166516
2023-01-05 03:02: Train Epoch 8: 247/634 Loss: 0.174940
2023-01-05 03:02: Train Epoch 8: 251/634 Loss: 0.203546
2023-01-05 03:02: Train Epoch 8: 255/634 Loss: 0.190698
2023-01-05 03:02: Train Epoch 8: 259/634 Loss: 0.200111
2023-01-05 03:02: Train Epoch 8: 263/634 Loss: 0.188419
2023-01-05 03:02: Train Epoch 8: 267/634 Loss: 0.159642
2023-01-05 03:03: Train Epoch 8: 271/634 Loss: 0.186642
2023-01-05 03:03: Train Epoch 8: 275/634 Loss: 0.160327
2023-01-05 03:03: Train Epoch 8: 279/634 Loss: 0.179689
2023-01-05 03:03: Train Epoch 8: 283/634 Loss: 0.167172
2023-01-05 03:03: Train Epoch 8: 287/634 Loss: 0.182057
2023-01-05 03:03: Train Epoch 8: 291/634 Loss: 0.166798
2023-01-05 03:03: Train Epoch 8: 295/634 Loss: 0.143026
2023-01-05 03:03: Train Epoch 8: 299/634 Loss: 0.150191
2023-01-05 03:03: Train Epoch 8: 303/634 Loss: 0.138512
2023-01-05 03:03: Train Epoch 8: 307/634 Loss: 0.131906
2023-01-05 03:04: Train Epoch 8: 311/634 Loss: 0.192924
2023-01-05 03:04: Train Epoch 8: 315/634 Loss: 0.156686
2023-01-05 03:04: Train Epoch 8: 319/634 Loss: 0.199448
2023-01-05 03:04: Train Epoch 8: 323/634 Loss: 0.156317
2023-01-05 03:04: Train Epoch 8: 327/634 Loss: 0.131504
2023-01-05 03:04: Train Epoch 8: 331/634 Loss: 0.133176
2023-01-05 03:04: Train Epoch 8: 335/634 Loss: 0.168452
2023-01-05 03:04: Train Epoch 8: 339/634 Loss: 0.149566
2023-01-05 03:04: Train Epoch 8: 343/634 Loss: 0.158848
2023-01-05 03:04: Train Epoch 8: 347/634 Loss: 0.203722
2023-01-05 03:04: Train Epoch 8: 351/634 Loss: 0.167281
2023-01-05 03:05: Train Epoch 8: 355/634 Loss: 0.153725
2023-01-05 03:05: Train Epoch 8: 359/634 Loss: 0.195328
2023-01-05 03:05: Train Epoch 8: 363/634 Loss: 0.179714
2023-01-05 03:05: Train Epoch 8: 367/634 Loss: 0.175929
2023-01-05 03:05: Train Epoch 8: 371/634 Loss: 0.155077
2023-01-05 03:05: Train Epoch 8: 375/634 Loss: 0.158093
2023-01-05 03:05: Train Epoch 8: 379/634 Loss: 0.174555
2023-01-05 03:05: Train Epoch 8: 383/634 Loss: 0.181450
2023-01-05 03:05: Train Epoch 8: 387/634 Loss: 0.174896
2023-01-05 03:05: Train Epoch 8: 391/634 Loss: 0.174860
2023-01-05 03:06: Train Epoch 8: 395/634 Loss: 0.160395
2023-01-05 03:06: Train Epoch 8: 399/634 Loss: 0.183908
2023-01-05 03:06: Train Epoch 8: 403/634 Loss: 0.180594
2023-01-05 03:06: Train Epoch 8: 407/634 Loss: 0.196261
2023-01-05 03:06: Train Epoch 8: 411/634 Loss: 0.151610
2023-01-05 03:06: Train Epoch 8: 415/634 Loss: 0.158193
2023-01-05 03:06: Train Epoch 8: 419/634 Loss: 0.172558
2023-01-05 03:06: Train Epoch 8: 423/634 Loss: 0.173713
2023-01-05 03:06: Train Epoch 8: 427/634 Loss: 0.166358
2023-01-05 03:06: Train Epoch 8: 431/634 Loss: 0.174613
2023-01-05 03:07: Train Epoch 8: 435/634 Loss: 0.174306
2023-01-05 03:07: Train Epoch 8: 439/634 Loss: 0.158309
2023-01-05 03:07: Train Epoch 8: 443/634 Loss: 0.201681
2023-01-05 03:07: Train Epoch 8: 447/634 Loss: 0.160426
2023-01-05 03:07: Train Epoch 8: 451/634 Loss: 0.160867
2023-01-05 03:07: Train Epoch 8: 455/634 Loss: 0.176906
2023-01-05 03:07: Train Epoch 8: 459/634 Loss: 0.159592
2023-01-05 03:07: Train Epoch 8: 463/634 Loss: 0.222290
2023-01-05 03:07: Train Epoch 8: 467/634 Loss: 0.180879
2023-01-05 03:07: Train Epoch 8: 471/634 Loss: 0.163290
2023-01-05 03:07: Train Epoch 8: 475/634 Loss: 0.172333
2023-01-05 03:08: Train Epoch 8: 479/634 Loss: 0.173385
2023-01-05 03:08: Train Epoch 8: 483/634 Loss: 0.146525
2023-01-05 03:08: Train Epoch 8: 487/634 Loss: 0.149323
2023-01-05 03:08: Train Epoch 8: 491/634 Loss: 0.156493
2023-01-05 03:08: Train Epoch 8: 495/634 Loss: 0.163837
2023-01-05 03:08: Train Epoch 8: 499/634 Loss: 0.151649
2023-01-05 03:08: Train Epoch 8: 503/634 Loss: 0.184316
2023-01-05 03:08: Train Epoch 8: 507/634 Loss: 0.186218
2023-01-05 03:08: Train Epoch 8: 511/634 Loss: 0.188419
2023-01-05 03:08: Train Epoch 8: 515/634 Loss: 0.191942
2023-01-05 03:09: Train Epoch 8: 519/634 Loss: 0.207589
2023-01-05 03:09: Train Epoch 8: 523/634 Loss: 0.187198
2023-01-05 03:09: Train Epoch 8: 527/634 Loss: 0.181450
2023-01-05 03:09: Train Epoch 8: 531/634 Loss: 0.168882
2023-01-05 03:09: Train Epoch 8: 535/634 Loss: 0.145287
2023-01-05 03:09: Train Epoch 8: 539/634 Loss: 0.169058
2023-01-05 03:09: Train Epoch 8: 543/634 Loss: 0.168181
2023-01-05 03:09: Train Epoch 8: 547/634 Loss: 0.219880
2023-01-05 03:09: Train Epoch 8: 551/634 Loss: 0.183017
2023-01-05 03:09: Train Epoch 8: 555/634 Loss: 0.142182
2023-01-05 03:10: Train Epoch 8: 559/634 Loss: 0.133200
2023-01-05 03:10: Train Epoch 8: 563/634 Loss: 0.132315
2023-01-05 03:10: Train Epoch 8: 567/634 Loss: 0.176434
2023-01-05 03:10: Train Epoch 8: 571/634 Loss: 0.170595
2023-01-05 03:10: Train Epoch 8: 575/634 Loss: 0.145954
2023-01-05 03:10: Train Epoch 8: 579/634 Loss: 0.175012
2023-01-05 03:10: Train Epoch 8: 583/634 Loss: 0.173013
2023-01-05 03:10: Train Epoch 8: 587/634 Loss: 0.153991
2023-01-05 03:10: Train Epoch 8: 591/634 Loss: 0.160046
2023-01-05 03:10: Train Epoch 8: 595/634 Loss: 0.163679
2023-01-05 03:11: Train Epoch 8: 599/634 Loss: 0.201398
2023-01-05 03:11: Train Epoch 8: 603/634 Loss: 0.200826
2023-01-05 03:11: Train Epoch 8: 607/634 Loss: 0.167858
2023-01-05 03:11: Train Epoch 8: 611/634 Loss: 0.139257
2023-01-05 03:11: Train Epoch 8: 615/634 Loss: 0.198098
2023-01-05 03:11: Train Epoch 8: 619/634 Loss: 0.217990
2023-01-05 03:11: Train Epoch 8: 623/634 Loss: 0.156423
2023-01-05 03:11: Train Epoch 8: 627/634 Loss: 0.142322
2023-01-05 03:11: Train Epoch 8: 631/634 Loss: 0.182956
2023-01-05 03:11: Train Epoch 8: 633/634 Loss: 0.049504
2023-01-05 03:11: **********Train Epoch 8: averaged Loss: 0.171301 
2023-01-05 03:11: 
Epoch time elapsed: 922.9488961696625

2023-01-05 03:12: 
 metrics validation: {'precision': 0.7130281690140845, 'recall': 0.6230769230769231, 'f1-score': 0.665024630541872, 'support': 1300, 'AUC': 0.8238857988165681, 'AUCPR': 0.7455365451949556, 'TP': 810, 'FP': 326, 'TN': 2274, 'FN': 490} 

2023-01-05 03:12: **********Val Epoch 8: average Loss: 0.253728
2023-01-05 03:13: 
 Testing metrics {'precision': 0.7536988685813751, 'recall': 0.7052117263843648, 'f1-score': 0.7286495582667227, 'support': 1228, 'AUC': 0.8602604536918164, 'AUCPR': 0.7778531993833362, 'TP': 866, 'FP': 283, 'TN': 2173, 'FN': 362} 

2023-01-05 03:16: 
 Testing metrics {'precision': 0.8729917498914459, 'recall': 0.9124120717041071, 'f1-score': 0.8922667258404526, 'support': 4407, 'AUC': 0.967051381682369, 'AUCPR': 0.937167093817868, 'TP': 4021, 'FP': 585, 'TN': 8229, 'FN': 386} 

2023-01-05 03:16: Train Epoch 9: 3/634 Loss: 0.219216
2023-01-05 03:16: Train Epoch 9: 7/634 Loss: 0.179890
2023-01-05 03:16: Train Epoch 9: 11/634 Loss: 0.164233
2023-01-05 03:16: Train Epoch 9: 15/634 Loss: 0.167215
2023-01-05 03:16: Train Epoch 9: 19/634 Loss: 0.166650
2023-01-05 03:16: Train Epoch 9: 23/634 Loss: 0.190644
2023-01-05 03:17: Train Epoch 9: 27/634 Loss: 0.148999
2023-01-05 03:17: Train Epoch 9: 31/634 Loss: 0.173733
2023-01-05 03:17: Train Epoch 9: 35/634 Loss: 0.161127
2023-01-05 03:17: Train Epoch 9: 39/634 Loss: 0.195670
2023-01-05 03:17: Train Epoch 9: 43/634 Loss: 0.169332
2023-01-05 03:17: Train Epoch 9: 47/634 Loss: 0.167656
2023-01-05 03:17: Train Epoch 9: 51/634 Loss: 0.234116
2023-01-05 03:17: Train Epoch 9: 55/634 Loss: 0.148303
2023-01-05 03:17: Train Epoch 9: 59/634 Loss: 0.189346
2023-01-05 03:17: Train Epoch 9: 63/634 Loss: 0.171612
2023-01-05 03:17: Train Epoch 9: 67/634 Loss: 0.212039
2023-01-05 03:18: Train Epoch 9: 71/634 Loss: 0.173256
2023-01-05 03:18: Train Epoch 9: 75/634 Loss: 0.161725
2023-01-05 03:18: Train Epoch 9: 79/634 Loss: 0.151563
2023-01-05 03:18: Train Epoch 9: 83/634 Loss: 0.174202
2023-01-05 03:18: Train Epoch 9: 87/634 Loss: 0.169370
2023-01-05 03:18: Train Epoch 9: 91/634 Loss: 0.223409
2023-01-05 03:18: Train Epoch 9: 95/634 Loss: 0.179777
2023-01-05 03:18: Train Epoch 9: 99/634 Loss: 0.204112
2023-01-05 03:18: Train Epoch 9: 103/634 Loss: 0.185473
2023-01-05 03:18: Train Epoch 9: 107/634 Loss: 0.163611
2023-01-05 03:18: Train Epoch 9: 111/634 Loss: 0.181253
2023-01-05 03:19: Train Epoch 9: 115/634 Loss: 0.197877
2023-01-05 03:19: Train Epoch 9: 119/634 Loss: 0.224663
2023-01-05 03:19: Train Epoch 9: 123/634 Loss: 0.153629
2023-01-05 03:19: Train Epoch 9: 127/634 Loss: 0.165197
2023-01-05 03:19: Train Epoch 9: 131/634 Loss: 0.172014
2023-01-05 03:19: Train Epoch 9: 135/634 Loss: 0.152835
2023-01-05 03:19: Train Epoch 9: 139/634 Loss: 0.206096
2023-01-05 03:19: Train Epoch 9: 143/634 Loss: 0.193281
2023-01-05 03:19: Train Epoch 9: 147/634 Loss: 0.163705
2023-01-05 03:19: Train Epoch 9: 151/634 Loss: 0.206653
2023-01-05 03:20: Train Epoch 9: 155/634 Loss: 0.142948
2023-01-05 03:20: Train Epoch 9: 159/634 Loss: 0.154510
2023-01-05 03:20: Train Epoch 9: 163/634 Loss: 0.181517
2023-01-05 03:20: Train Epoch 9: 167/634 Loss: 0.153300
2023-01-05 03:20: Train Epoch 9: 171/634 Loss: 0.152486
2023-01-05 03:20: Train Epoch 9: 175/634 Loss: 0.157985
2023-01-05 03:20: Train Epoch 9: 179/634 Loss: 0.137162
2023-01-05 03:20: Train Epoch 9: 183/634 Loss: 0.170454
2023-01-05 03:20: Train Epoch 9: 187/634 Loss: 0.156084
2023-01-05 03:20: Train Epoch 9: 191/634 Loss: 0.187287
2023-01-05 03:21: Train Epoch 9: 195/634 Loss: 0.166642
2023-01-05 03:21: Train Epoch 9: 199/634 Loss: 0.183787
2023-01-05 03:21: Train Epoch 9: 203/634 Loss: 0.175825
2023-01-05 03:21: Train Epoch 9: 207/634 Loss: 0.150859
2023-01-05 03:21: Train Epoch 9: 211/634 Loss: 0.149612
2023-01-05 03:21: Train Epoch 9: 215/634 Loss: 0.169335
2023-01-05 03:21: Train Epoch 9: 219/634 Loss: 0.176777
2023-01-05 03:21: Train Epoch 9: 223/634 Loss: 0.192909
2023-01-05 03:21: Train Epoch 9: 227/634 Loss: 0.148066
2023-01-05 03:21: Train Epoch 9: 231/634 Loss: 0.153918
2023-01-05 03:22: Train Epoch 9: 235/634 Loss: 0.152067
2023-01-05 03:22: Train Epoch 9: 239/634 Loss: 0.208656
2023-01-05 03:22: Train Epoch 9: 243/634 Loss: 0.192444
2023-01-05 03:22: Train Epoch 9: 247/634 Loss: 0.149458
2023-01-05 03:22: Train Epoch 9: 251/634 Loss: 0.179662
2023-01-05 03:22: Train Epoch 9: 255/634 Loss: 0.142617
2023-01-05 03:22: Train Epoch 9: 259/634 Loss: 0.141677
2023-01-05 03:22: Train Epoch 9: 263/634 Loss: 0.154621
2023-01-05 03:22: Train Epoch 9: 267/634 Loss: 0.165959
2023-01-05 03:22: Train Epoch 9: 271/634 Loss: 0.175299
2023-01-05 03:23: Train Epoch 9: 275/634 Loss: 0.193093
2023-01-05 03:23: Train Epoch 9: 279/634 Loss: 0.168909
2023-01-05 03:23: Train Epoch 9: 283/634 Loss: 0.160733
2023-01-05 03:23: Train Epoch 9: 287/634 Loss: 0.183767
2023-01-05 03:23: Train Epoch 9: 291/634 Loss: 0.147748
2023-01-05 03:23: Train Epoch 9: 295/634 Loss: 0.202189
2023-01-05 03:23: Train Epoch 9: 299/634 Loss: 0.169579
2023-01-05 03:23: Train Epoch 9: 303/634 Loss: 0.146881
2023-01-05 03:23: Train Epoch 9: 307/634 Loss: 0.153828
2023-01-05 03:23: Train Epoch 9: 311/634 Loss: 0.176241
2023-01-05 03:24: Train Epoch 9: 315/634 Loss: 0.162927
2023-01-05 03:24: Train Epoch 9: 319/634 Loss: 0.181031
2023-01-05 03:24: Train Epoch 9: 323/634 Loss: 0.188871
2023-01-05 03:24: Train Epoch 9: 327/634 Loss: 0.188143
2023-01-05 03:24: Train Epoch 9: 331/634 Loss: 0.193194
2023-01-05 03:24: Train Epoch 9: 335/634 Loss: 0.153025
2023-01-05 03:24: Train Epoch 9: 339/634 Loss: 0.166705
2023-01-05 03:24: Train Epoch 9: 343/634 Loss: 0.185428
2023-01-05 03:24: Train Epoch 9: 347/634 Loss: 0.166357
2023-01-05 03:24: Train Epoch 9: 351/634 Loss: 0.173855
2023-01-05 03:24: Train Epoch 9: 355/634 Loss: 0.147866
2023-01-05 03:25: Train Epoch 9: 359/634 Loss: 0.189885
2023-01-05 03:25: Train Epoch 9: 363/634 Loss: 0.169419
2023-01-05 03:25: Train Epoch 9: 367/634 Loss: 0.153403
2023-01-05 03:25: Train Epoch 9: 371/634 Loss: 0.157452
2023-01-05 03:25: Train Epoch 9: 375/634 Loss: 0.171655
2023-01-05 03:25: Train Epoch 9: 379/634 Loss: 0.201385
2023-01-05 03:25: Train Epoch 9: 383/634 Loss: 0.195948
2023-01-05 03:25: Train Epoch 9: 387/634 Loss: 0.187362
2023-01-05 03:25: Train Epoch 9: 391/634 Loss: 0.153834
2023-01-05 03:25: Train Epoch 9: 395/634 Loss: 0.159023
2023-01-05 03:26: Train Epoch 9: 399/634 Loss: 0.160478
2023-01-05 03:26: Train Epoch 9: 403/634 Loss: 0.186640
2023-01-05 03:26: Train Epoch 9: 407/634 Loss: 0.192286
2023-01-05 03:26: Train Epoch 9: 411/634 Loss: 0.163105
2023-01-05 03:26: Train Epoch 9: 415/634 Loss: 0.173455
2023-01-05 03:26: Train Epoch 9: 419/634 Loss: 0.154650
2023-01-05 03:26: Train Epoch 9: 423/634 Loss: 0.154351
2023-01-05 03:26: Train Epoch 9: 427/634 Loss: 0.185465
2023-01-05 03:26: Train Epoch 9: 431/634 Loss: 0.152335
2023-01-05 03:26: Train Epoch 9: 435/634 Loss: 0.200846
2023-01-05 03:27: Train Epoch 9: 439/634 Loss: 0.167374
2023-01-05 03:27: Train Epoch 9: 443/634 Loss: 0.156148
2023-01-05 03:27: Train Epoch 9: 447/634 Loss: 0.152400
2023-01-05 03:27: Train Epoch 9: 451/634 Loss: 0.165349
2023-01-05 03:27: Train Epoch 9: 455/634 Loss: 0.183168
2023-01-05 03:27: Train Epoch 9: 459/634 Loss: 0.188575
2023-01-05 03:27: Train Epoch 9: 463/634 Loss: 0.158348
2023-01-05 03:27: Train Epoch 9: 467/634 Loss: 0.187912
2023-01-05 03:27: Train Epoch 9: 471/634 Loss: 0.205999
2023-01-05 03:27: Train Epoch 9: 475/634 Loss: 0.137687
2023-01-05 03:28: Train Epoch 9: 479/634 Loss: 0.169813
2023-01-05 03:28: Train Epoch 9: 483/634 Loss: 0.138496
2023-01-05 03:28: Train Epoch 9: 487/634 Loss: 0.182723
2023-01-05 03:28: Train Epoch 9: 491/634 Loss: 0.151511
2023-01-05 03:28: Train Epoch 9: 495/634 Loss: 0.159084
2023-01-05 03:28: Train Epoch 9: 499/634 Loss: 0.174496
2023-01-05 03:28: Train Epoch 9: 503/634 Loss: 0.157764
2023-01-05 03:28: Train Epoch 9: 507/634 Loss: 0.194569
2023-01-05 03:28: Train Epoch 9: 511/634 Loss: 0.184475
2023-01-05 03:28: Train Epoch 9: 515/634 Loss: 0.154426
2023-01-05 03:29: Train Epoch 9: 519/634 Loss: 0.142305
2023-01-05 03:29: Train Epoch 9: 523/634 Loss: 0.213357
2023-01-05 03:29: Train Epoch 9: 527/634 Loss: 0.177160
2023-01-05 03:29: Train Epoch 9: 531/634 Loss: 0.188342
2023-01-05 03:29: Train Epoch 9: 535/634 Loss: 0.173635
2023-01-05 03:29: Train Epoch 9: 539/634 Loss: 0.147789
2023-01-05 03:29: Train Epoch 9: 543/634 Loss: 0.145916
2023-01-05 03:29: Train Epoch 9: 547/634 Loss: 0.151056
2023-01-05 03:29: Train Epoch 9: 551/634 Loss: 0.161617
2023-01-05 03:29: Train Epoch 9: 555/634 Loss: 0.177060
2023-01-05 03:29: Train Epoch 9: 559/634 Loss: 0.163413
2023-01-05 03:30: Train Epoch 9: 563/634 Loss: 0.180966
2023-01-05 03:30: Train Epoch 9: 567/634 Loss: 0.205350
2023-01-05 03:30: Train Epoch 9: 571/634 Loss: 0.200494
2023-01-05 03:30: Train Epoch 9: 575/634 Loss: 0.136784
2023-01-05 03:30: Train Epoch 9: 579/634 Loss: 0.150686
2023-01-05 03:30: Train Epoch 9: 583/634 Loss: 0.177083
2023-01-05 03:30: Train Epoch 9: 587/634 Loss: 0.157805
2023-01-05 03:30: Train Epoch 9: 591/634 Loss: 0.170293
2023-01-05 03:30: Train Epoch 9: 595/634 Loss: 0.133230
2023-01-05 03:31: Train Epoch 9: 599/634 Loss: 0.200327
2023-01-05 03:31: Train Epoch 9: 603/634 Loss: 0.160374
2023-01-05 03:31: Train Epoch 9: 607/634 Loss: 0.190789
2023-01-05 03:31: Train Epoch 9: 611/634 Loss: 0.144676
2023-01-05 03:31: Train Epoch 9: 615/634 Loss: 0.170772
2023-01-05 03:31: Train Epoch 9: 619/634 Loss: 0.177348
2023-01-05 03:31: Train Epoch 9: 623/634 Loss: 0.165034
2023-01-05 03:31: Train Epoch 9: 627/634 Loss: 0.168551
2023-01-05 03:31: Train Epoch 9: 631/634 Loss: 0.165361
2023-01-05 03:31: Train Epoch 9: 633/634 Loss: 0.060328
2023-01-05 03:31: **********Train Epoch 9: averaged Loss: 0.171000 
2023-01-05 03:31: 
Epoch time elapsed: 933.7886538505554

2023-01-05 03:32: 
 metrics validation: {'precision': 0.7587939698492462, 'recall': 0.5807692307692308, 'f1-score': 0.6579520697167757, 'support': 1300, 'AUC': 0.8287745562130178, 'AUCPR': 0.749570900261314, 'TP': 755, 'FP': 240, 'TN': 2360, 'FN': 545} 

2023-01-05 03:32: **********Val Epoch 9: average Loss: 0.259781
2023-01-05 03:32: Validation performance didn't improve for 5 epochs. Training stops.
2023-01-05 03:32: Total training time: 179.3892min, best loss: 0.252498
2023-01-05 03:32: Saving current best model to /home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010500332345480554013/best_model.pth
2023-01-05 03:33: 
 Testing metrics {'precision': 0.7536988685813751, 'recall': 0.7052117263843648, 'f1-score': 0.7286495582667227, 'support': 1228, 'AUC': 0.8602604536918164, 'AUCPR': 0.7778531993833362, 'TP': 866, 'FP': 283, 'TN': 2173, 'FN': 362} 

2023-01-05 03:36: 
 Testing metrics {'precision': 0.8729917498914459, 'recall': 0.9124120717041071, 'f1-score': 0.8922667258404526, 'support': 4407, 'AUC': 0.967051381682369, 'AUCPR': 0.937167093817868, 'TP': 4021, 'FP': 585, 'TN': 8229, 'FN': 386} 

