2022-12-21 15:13: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221221151309
2022-12-21 15:13: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221221151309
2022-12-21 15:13: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=5, embed_dim=64, epochs=30, gamma=1.0, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221221151309', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='10, 15, 20, 25', lr_init=0.0005, mae_thresh=None, mape_thresh=0.0, max_grad_norm=5, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=32, seed=1992, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, test_ratio=0.2, val_ratio=0.2, weight_decay=0.01, window_len=10)
2022-12-21 15:13: Argument batch_size: 256
2022-12-21 15:13: Argument clc: 'vec'
2022-12-21 15:13: Argument cuda: True
2022-12-21 15:13: Argument dataset: '2020'
2022-12-21 15:13: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-21 15:13: Argument debug: False
2022-12-21 15:13: Argument default_graph: True
2022-12-21 15:13: Argument device: 'cpu'
2022-12-21 15:13: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-21 15:13: Argument early_stop: True
2022-12-21 15:13: Argument early_stop_patience: 5
2022-12-21 15:13: Argument embed_dim: 64
2022-12-21 15:13: Argument epochs: 30
2022-12-21 15:13: Argument gamma: 1.0
2022-12-21 15:13: Argument grad_norm: False
2022-12-21 15:13: Argument horizon: 1
2022-12-21 15:13: Argument input_dim: 25
2022-12-21 15:13: Argument lag: 10
2022-12-21 15:13: Argument link_len: 2
2022-12-21 15:13: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/20221221151309'
2022-12-21 15:13: Argument log_step: 1
2022-12-21 15:13: Argument loss_func: 'nllloss'
2022-12-21 15:13: Argument lr_decay: True
2022-12-21 15:13: Argument lr_decay_rate: 0.1
2022-12-21 15:13: Argument lr_decay_step: '10, 15, 20, 25'
2022-12-21 15:13: Argument lr_init: 0.0005
2022-12-21 15:13: Argument mae_thresh: None
2022-12-21 15:13: Argument mape_thresh: 0.0
2022-12-21 15:13: Argument max_grad_norm: 5
2022-12-21 15:13: Argument mode: 'train'
2022-12-21 15:13: Argument model: 'fire_GCN'
2022-12-21 15:13: Argument nan_fill: 0.5
2022-12-21 15:13: Argument num_layers: 1
2022-12-21 15:13: Argument num_nodes: 625
2022-12-21 15:13: Argument num_workers: 12
2022-12-21 15:13: Argument output_dim: 2
2022-12-21 15:13: Argument patch_height: 25
2022-12-21 15:13: Argument patch_width: 25
2022-12-21 15:13: Argument persistent_workers: True
2022-12-21 15:13: Argument pin_memory: True
2022-12-21 15:13: Argument plot: False
2022-12-21 15:13: Argument positive_weight: 0.5
2022-12-21 15:13: Argument prefetch_factor: 2
2022-12-21 15:13: Argument real_value: True
2022-12-21 15:13: Argument rnn_units: 32
2022-12-21 15:13: Argument seed: 1992
2022-12-21 15:13: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-21 15:13: Argument teacher_forcing: False
2022-12-21 15:13: Argument test_ratio: 0.2
2022-12-21 15:13: Argument val_ratio: 0.2
2022-12-21 15:13: Argument weight_decay: 0.01
2022-12-21 15:13: Argument window_len: 10
2022-12-21 15:13: Train Epoch 1: 0/159 Loss: 1.293336
2022-12-21 15:13: Train Epoch 1: 1/159 Loss: 1.179925
2022-12-21 15:13: Train Epoch 1: 2/159 Loss: 1.112553
2022-12-21 15:13: Train Epoch 1: 3/159 Loss: 0.934544
2022-12-21 15:13: Train Epoch 1: 4/159 Loss: 0.855705
2022-12-21 15:14: Train Epoch 1: 5/159 Loss: 0.795357
2022-12-21 15:14: Train Epoch 1: 6/159 Loss: 0.814124
2022-12-21 15:14: Train Epoch 1: 7/159 Loss: 0.782888
2022-12-21 15:14: Train Epoch 1: 8/159 Loss: 0.780959
2022-12-21 15:14: Train Epoch 1: 9/159 Loss: 0.862875
2022-12-21 15:14: Train Epoch 1: 10/159 Loss: 0.730115
2022-12-21 15:15: Train Epoch 1: 11/159 Loss: 0.787829
2022-12-21 15:15: Train Epoch 1: 12/159 Loss: 0.798243
2022-12-21 15:15: Train Epoch 1: 13/159 Loss: 0.696012
2022-12-21 15:15: Train Epoch 1: 14/159 Loss: 0.736815
2022-12-21 15:15: Train Epoch 1: 15/159 Loss: 0.748478
2022-12-21 15:15: Train Epoch 1: 16/159 Loss: 0.719359
2022-12-21 15:16: Train Epoch 1: 17/159 Loss: 0.716663
2022-12-21 15:16: Train Epoch 1: 18/159 Loss: 0.706589
2022-12-21 15:16: Train Epoch 1: 19/159 Loss: 0.701128
2022-12-21 15:16: Train Epoch 1: 20/159 Loss: 0.763758
2022-12-21 15:16: Train Epoch 1: 21/159 Loss: 0.755942
2022-12-21 15:16: Train Epoch 1: 22/159 Loss: 0.796265
2022-12-21 15:16: Train Epoch 1: 23/159 Loss: 0.799305
2022-12-21 15:17: Train Epoch 1: 24/159 Loss: 0.714379
2022-12-21 15:17: Train Epoch 1: 25/159 Loss: 0.738666
2022-12-21 15:17: Train Epoch 1: 26/159 Loss: 0.736095
2022-12-21 15:17: Train Epoch 1: 27/159 Loss: 0.746350
2022-12-21 15:17: Train Epoch 1: 28/159 Loss: 0.754328
2022-12-21 15:17: Train Epoch 1: 29/159 Loss: 0.749012
2022-12-21 15:18: Train Epoch 1: 30/159 Loss: 0.725123
2022-12-21 15:18: Train Epoch 1: 31/159 Loss: 0.700214
2022-12-21 15:18: Train Epoch 1: 32/159 Loss: 0.773238
2022-12-21 15:18: Train Epoch 1: 33/159 Loss: 0.717402
2022-12-21 15:18: Train Epoch 1: 34/159 Loss: 0.762525
2022-12-21 15:18: Train Epoch 1: 35/159 Loss: 0.726259
2022-12-21 15:19: Train Epoch 1: 36/159 Loss: 0.727671
2022-12-21 15:19: Train Epoch 1: 37/159 Loss: 0.672585
2022-12-21 15:19: Train Epoch 1: 38/159 Loss: 0.704552
2022-12-21 15:19: Train Epoch 1: 39/159 Loss: 0.690095
2022-12-21 15:19: Train Epoch 1: 40/159 Loss: 0.744744
2022-12-21 15:19: Train Epoch 1: 41/159 Loss: 0.739684
2022-12-21 15:20: Train Epoch 1: 42/159 Loss: 0.690343
2022-12-21 15:20: Train Epoch 1: 43/159 Loss: 0.745742
2022-12-21 15:20: Train Epoch 1: 44/159 Loss: 0.743624
2022-12-21 15:20: Train Epoch 1: 45/159 Loss: 0.717772
2022-12-21 15:20: Train Epoch 1: 46/159 Loss: 0.735519
2022-12-21 15:20: Train Epoch 1: 47/159 Loss: 0.693789
2022-12-21 15:21: Train Epoch 1: 48/159 Loss: 0.702432
2022-12-21 15:21: Train Epoch 1: 49/159 Loss: 0.683238
2022-12-21 15:21: Train Epoch 1: 50/159 Loss: 0.676371
2022-12-21 15:21: Train Epoch 1: 51/159 Loss: 0.695831
2022-12-21 15:21: Train Epoch 1: 52/159 Loss: 0.708386
2022-12-21 15:21: Train Epoch 1: 53/159 Loss: 0.708634
2022-12-21 15:22: Train Epoch 1: 54/159 Loss: 0.717261
2022-12-21 15:22: Train Epoch 1: 55/159 Loss: 0.714342
2022-12-21 15:22: Train Epoch 1: 56/159 Loss: 0.720556
2022-12-21 15:22: Train Epoch 1: 57/159 Loss: 0.743382
2022-12-21 15:22: Train Epoch 1: 58/159 Loss: 0.668700
2022-12-21 15:22: Train Epoch 1: 59/159 Loss: 0.714524
2022-12-21 15:23: Train Epoch 1: 60/159 Loss: 0.738513
2022-12-21 15:23: Train Epoch 1: 61/159 Loss: 0.675508
2022-12-21 15:23: Train Epoch 1: 62/159 Loss: 0.691665
2022-12-21 15:23: Train Epoch 1: 63/159 Loss: 0.740566
2022-12-21 15:23: Train Epoch 1: 64/159 Loss: 0.680630
2022-12-21 15:23: Train Epoch 1: 65/159 Loss: 0.720743
2022-12-21 15:24: Train Epoch 1: 66/159 Loss: 0.686588
2022-12-21 15:24: Train Epoch 1: 67/159 Loss: 0.695446
2022-12-21 15:24: Train Epoch 1: 68/159 Loss: 0.755200
2022-12-21 15:24: Train Epoch 1: 69/159 Loss: 0.644902
2022-12-21 15:24: Train Epoch 1: 70/159 Loss: 0.648438
2022-12-21 15:24: Train Epoch 1: 71/159 Loss: 0.703537
2022-12-21 15:25: Train Epoch 1: 72/159 Loss: 0.683089
2022-12-21 15:25: Train Epoch 1: 73/159 Loss: 0.697139
2022-12-21 15:25: Train Epoch 1: 74/159 Loss: 0.705088
2022-12-21 15:25: Train Epoch 1: 75/159 Loss: 0.667573
2022-12-21 15:25: Train Epoch 1: 76/159 Loss: 0.703371
2022-12-21 15:25: Train Epoch 1: 77/159 Loss: 0.628703
2022-12-21 15:26: Train Epoch 1: 78/159 Loss: 0.750867
2022-12-21 15:26: Train Epoch 1: 79/159 Loss: 0.680477
2022-12-21 15:26: Train Epoch 1: 80/159 Loss: 0.727687
2022-12-21 15:26: Train Epoch 1: 81/159 Loss: 0.734189
2022-12-21 15:26: Train Epoch 1: 82/159 Loss: 0.759284
2022-12-21 15:26: Train Epoch 1: 83/159 Loss: 0.689107
2022-12-21 15:27: Train Epoch 1: 84/159 Loss: 0.705054
2022-12-21 15:27: Train Epoch 1: 85/159 Loss: 0.683381
2022-12-21 15:27: Train Epoch 1: 86/159 Loss: 0.726895
2022-12-21 15:27: Train Epoch 1: 87/159 Loss: 0.695940
2022-12-21 15:27: Train Epoch 1: 88/159 Loss: 0.662198
2022-12-21 15:28: Train Epoch 1: 89/159 Loss: 0.708851
2022-12-21 15:28: Train Epoch 1: 90/159 Loss: 0.663757
2022-12-21 15:28: Train Epoch 1: 91/159 Loss: 0.691334
2022-12-21 15:28: Train Epoch 1: 92/159 Loss: 0.780660
2022-12-21 15:28: Train Epoch 1: 93/159 Loss: 0.652835
2022-12-21 15:28: Train Epoch 1: 94/159 Loss: 0.667386
2022-12-21 15:29: Train Epoch 1: 95/159 Loss: 0.722983
2022-12-21 15:29: Train Epoch 1: 96/159 Loss: 0.714688
2022-12-21 15:29: Train Epoch 1: 97/159 Loss: 0.714742
2022-12-21 15:29: Train Epoch 1: 98/159 Loss: 0.731934
2022-12-21 15:29: Train Epoch 1: 99/159 Loss: 0.699168
2022-12-21 15:29: Train Epoch 1: 100/159 Loss: 0.677304
2022-12-21 15:30: Train Epoch 1: 101/159 Loss: 0.684321
2022-12-21 15:30: Train Epoch 1: 102/159 Loss: 0.726976
2022-12-21 15:30: Train Epoch 1: 103/159 Loss: 0.629022
2022-12-21 15:30: Train Epoch 1: 104/159 Loss: 0.661795
2022-12-21 15:30: Train Epoch 1: 105/159 Loss: 0.666955
2022-12-21 15:30: Train Epoch 1: 106/159 Loss: 0.643063
2022-12-21 15:31: Train Epoch 1: 107/159 Loss: 0.676573
2022-12-21 15:31: Train Epoch 1: 108/159 Loss: 0.685144
2022-12-21 15:31: Train Epoch 1: 109/159 Loss: 0.676509
2022-12-21 15:31: Train Epoch 1: 110/159 Loss: 0.737299
2022-12-21 15:31: Train Epoch 1: 111/159 Loss: 0.721754
2022-12-21 15:31: Train Epoch 1: 112/159 Loss: 0.713852
2022-12-21 15:32: Train Epoch 1: 113/159 Loss: 0.683346
2022-12-21 15:32: Train Epoch 1: 114/159 Loss: 0.712839
2022-12-21 15:32: Train Epoch 1: 115/159 Loss: 0.675715
2022-12-21 15:32: Train Epoch 1: 116/159 Loss: 0.677296
2022-12-21 15:32: Train Epoch 1: 117/159 Loss: 0.715683
2022-12-21 15:32: Train Epoch 1: 118/159 Loss: 0.666104
2022-12-21 15:33: Train Epoch 1: 119/159 Loss: 0.698341
2022-12-21 15:33: Train Epoch 1: 120/159 Loss: 0.733662
2022-12-21 15:33: Train Epoch 1: 121/159 Loss: 0.714390
2022-12-21 15:33: Train Epoch 1: 122/159 Loss: 0.652462
2022-12-21 15:33: Train Epoch 1: 123/159 Loss: 0.724033
2022-12-21 15:33: Train Epoch 1: 124/159 Loss: 0.619587
2022-12-21 15:34: Train Epoch 1: 125/159 Loss: 0.716984
2022-12-21 15:34: Train Epoch 1: 126/159 Loss: 0.697042
2022-12-21 15:34: Train Epoch 1: 127/159 Loss: 0.666913
2022-12-21 15:34: Train Epoch 1: 128/159 Loss: 0.684329
2022-12-21 15:34: Train Epoch 1: 129/159 Loss: 0.682070
2022-12-21 15:34: Train Epoch 1: 130/159 Loss: 0.698907
2022-12-21 15:35: Train Epoch 1: 131/159 Loss: 0.715533
2022-12-21 15:35: Train Epoch 1: 132/159 Loss: 0.684957
2022-12-21 15:35: Train Epoch 1: 133/159 Loss: 0.701840
2022-12-21 15:35: Train Epoch 1: 134/159 Loss: 0.710699
2022-12-21 15:35: Train Epoch 1: 135/159 Loss: 0.686685
2022-12-21 15:35: Train Epoch 1: 136/159 Loss: 0.641805
2022-12-21 15:36: Train Epoch 1: 137/159 Loss: 0.679619
2022-12-21 15:36: Train Epoch 1: 138/159 Loss: 0.688858
2022-12-21 15:36: Train Epoch 1: 139/159 Loss: 0.673251
2022-12-21 15:36: Train Epoch 1: 140/159 Loss: 0.653918
2022-12-21 15:36: Train Epoch 1: 141/159 Loss: 0.663816
2022-12-21 15:36: Train Epoch 1: 142/159 Loss: 0.644476
2022-12-21 15:37: Train Epoch 1: 143/159 Loss: 0.740886
2022-12-21 15:37: Train Epoch 1: 144/159 Loss: 0.647888
2022-12-21 15:37: Train Epoch 1: 145/159 Loss: 0.726757
2022-12-21 15:37: Train Epoch 1: 146/159 Loss: 0.689216
2022-12-21 15:37: Train Epoch 1: 147/159 Loss: 0.644142
2022-12-21 15:38: Train Epoch 1: 148/159 Loss: 0.703098
2022-12-21 15:38: Train Epoch 1: 149/159 Loss: 0.683526
2022-12-21 15:38: Train Epoch 1: 150/159 Loss: 0.669438
2022-12-21 15:38: Train Epoch 1: 151/159 Loss: 0.659206
2022-12-21 15:38: Train Epoch 1: 152/159 Loss: 0.681755
2022-12-21 15:38: Train Epoch 1: 153/159 Loss: 0.671318
2022-12-21 15:39: Train Epoch 1: 154/159 Loss: 0.689124
2022-12-21 15:39: Train Epoch 1: 155/159 Loss: 0.693013
2022-12-21 15:39: Train Epoch 1: 156/159 Loss: 0.690941
2022-12-21 15:39: Train Epoch 1: 157/159 Loss: 0.715696
2022-12-21 15:39: Train Epoch 1: 158/159 Loss: 0.703406
2022-12-21 15:39: **********Train Epoch 1: averaged Loss: 0.718726 
2022-12-21 15:39: 
Epoch time elapsed: 1585.4933876991272

2022-12-21 15:40: 
 metrics validation: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1300, 'AUC': 0.5661349112426035, 'AUCPR': 0.3717168315222317, 'TP': 0, 'FP': 0, 'TN': 2600, 'FN': 1300} 

2022-12-21 15:40: **********Val Epoch 1: average Loss: 0.637519
2022-12-21 15:40: *********************************Current best model saved!
2022-12-21 15:40: 
 Testing metrics {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1228, 'AUC': 0.7370608706723679, 'AUCPR': 0.5211002955574486, 'TP': 0, 'FP': 0, 'TN': 2456, 'FN': 1228} 

