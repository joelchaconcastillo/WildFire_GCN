2023-01-06 10:52: log dir: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010610525075780969386
2023-01-06 10:52: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010610525075780969386
2023-01-06 10:52: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010610525075780969386', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=48, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-06 10:52: Argument batch_size: 256
2023-01-06 10:52: Argument clc: 'vec'
2023-01-06 10:52: Argument cuda: True
2023-01-06 10:52: Argument dataset: '2020'
2023-01-06 10:52: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-06 10:52: Argument debug: False
2023-01-06 10:52: Argument default_graph: True
2023-01-06 10:52: Argument device: 'cpu'
2023-01-06 10:52: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-06 10:52: Argument early_stop: True
2023-01-06 10:52: Argument early_stop_patience: 8
2023-01-06 10:52: Argument embed_dim: 64
2023-01-06 10:52: Argument epochs: 30
2023-01-06 10:52: Argument grad_norm: False
2023-01-06 10:52: Argument horizon: 1
2023-01-06 10:52: Argument input_dim: 25
2023-01-06 10:52: Argument lag: 10
2023-01-06 10:52: Argument link_len: 2
2023-01-06 10:52: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010610525075780969386'
2023-01-06 10:52: Argument log_step: 1
2023-01-06 10:52: Argument loss_func: 'nllloss'
2023-01-06 10:52: Argument lr_decay: True
2023-01-06 10:52: Argument lr_decay_rate: 0.1
2023-01-06 10:52: Argument lr_decay_step: '20'
2023-01-06 10:52: Argument lr_init: 0.0001
2023-01-06 10:52: Argument max_grad_norm: 5
2023-01-06 10:52: Argument minbatch_size: 64
2023-01-06 10:52: Argument mode: 'train'
2023-01-06 10:52: Argument model: 'fire_GCN'
2023-01-06 10:52: Argument nan_fill: -1.0
2023-01-06 10:52: Argument num_layers: 1
2023-01-06 10:52: Argument num_nodes: 625
2023-01-06 10:52: Argument num_workers: 12
2023-01-06 10:52: Argument output_dim: 2
2023-01-06 10:52: Argument patch_height: 25
2023-01-06 10:52: Argument patch_width: 25
2023-01-06 10:52: Argument persistent_workers: True
2023-01-06 10:52: Argument pin_memory: True
2023-01-06 10:52: Argument plot: False
2023-01-06 10:52: Argument positive_weight: 0.5
2023-01-06 10:52: Argument prefetch_factor: 2
2023-01-06 10:52: Argument real_value: True
2023-01-06 10:52: Argument rnn_units: 48
2023-01-06 10:52: Argument seed: 10000
2023-01-06 10:52: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-06 10:52: Argument teacher_forcing: False
2023-01-06 10:52: Argument weight_decay: 0.0
2023-01-06 10:52: Argument window_len: 10
2023-01-06 10:53: Train Epoch 1: 3/24 Loss: 0.412767
2023-01-06 10:53: Train Epoch 1: 7/24 Loss: 0.319933
2023-01-06 10:53: Train Epoch 1: 11/24 Loss: 0.389886
2023-01-06 10:53: Train Epoch 1: 15/24 Loss: 0.322588
2023-01-06 10:53: Train Epoch 1: 19/24 Loss: 0.246719
2023-01-06 10:54: Train Epoch 1: 23/24 Loss: 0.213302
2023-01-06 10:54: **********Train Epoch 1: averaged Loss: 0.317532 
2023-01-06 10:54: 
Epoch time elapsed: 71.31727576255798

2023-01-06 10:54: 
 metrics validation: {'precision': 0.6025369978858351, 'recall': 0.57, 'f1-score': 0.5858170606372045, 'support': 500, 'AUC': 0.78518, 'AUCPR': 0.6541547456794975, 'TP': 285, 'FP': 188, 'TN': 812, 'FN': 215} 

2023-01-06 10:54: **********Val Epoch 1: average Loss: 0.253903
2023-01-06 10:54: *********************************Current best model saved!
2023-01-06 10:55: 
 Testing metrics {'precision': 0.7166979362101313, 'recall': 0.764, 'f1-score': 0.739593417231365, 'support': 500, 'AUC': 0.859084, 'AUCPR': 0.777894527670912, 'TP': 382, 'FP': 151, 'TN': 849, 'FN': 118} 

2023-01-06 10:55: 
 Testing metrics {'precision': 0.8206521739130435, 'recall': 0.906, 'f1-score': 0.8612167300380228, 'support': 500, 'AUC': 0.9528199999999999, 'AUCPR': 0.9303670171229059, 'TP': 453, 'FP': 99, 'TN': 901, 'FN': 47} 

2023-01-06 10:55: Train Epoch 2: 3/24 Loss: 0.284527
2023-01-06 10:56: Train Epoch 2: 7/24 Loss: 0.297179
2023-01-06 10:56: Train Epoch 2: 11/24 Loss: 0.234224
2023-01-06 10:56: Train Epoch 2: 15/24 Loss: 0.225580
2023-01-06 10:56: Train Epoch 2: 19/24 Loss: 0.223887
2023-01-06 10:56: Train Epoch 2: 23/24 Loss: 0.166124
2023-01-06 10:56: **********Train Epoch 2: averaged Loss: 0.238587 
2023-01-06 10:56: 
Epoch time elapsed: 72.68886137008667

2023-01-06 10:57: 
 metrics validation: {'precision': 0.6829268292682927, 'recall': 0.504, 'f1-score': 0.5799769850402762, 'support': 500, 'AUC': 0.7901199999999999, 'AUCPR': 0.6616848947767343, 'TP': 252, 'FP': 117, 'TN': 883, 'FN': 248} 

2023-01-06 10:57: **********Val Epoch 2: average Loss: 0.270767
2023-01-06 10:57: 
 Testing metrics {'precision': 0.7166979362101313, 'recall': 0.764, 'f1-score': 0.739593417231365, 'support': 500, 'AUC': 0.859084, 'AUCPR': 0.777894527670912, 'TP': 382, 'FP': 151, 'TN': 849, 'FN': 118} 

2023-01-06 10:58: 
 Testing metrics {'precision': 0.8206521739130435, 'recall': 0.906, 'f1-score': 0.8612167300380228, 'support': 500, 'AUC': 0.9528199999999999, 'AUCPR': 0.9303670171229059, 'TP': 453, 'FP': 99, 'TN': 901, 'FN': 47} 

2023-01-06 10:58: Train Epoch 3: 3/24 Loss: 0.253650
2023-01-06 10:58: Train Epoch 3: 7/24 Loss: 0.266317
2023-01-06 10:58: Train Epoch 3: 11/24 Loss: 0.225468
2023-01-06 10:59: Train Epoch 3: 15/24 Loss: 0.239409
2023-01-06 10:59: Train Epoch 3: 19/24 Loss: 0.253895
2023-01-06 10:59: Train Epoch 3: 23/24 Loss: 0.208258
2023-01-06 10:59: **********Train Epoch 3: averaged Loss: 0.241166 
2023-01-06 10:59: 
Epoch time elapsed: 70.58337783813477

2023-01-06 10:59: 
 metrics validation: {'precision': 0.6359832635983264, 'recall': 0.608, 'f1-score': 0.621676891615542, 'support': 500, 'AUC': 0.799324, 'AUCPR': 0.6729224042329459, 'TP': 304, 'FP': 174, 'TN': 826, 'FN': 196} 

2023-01-06 10:59: **********Val Epoch 3: average Loss: 0.251688
2023-01-06 10:59: *********************************Current best model saved!
2023-01-06 11:00: 
 Testing metrics {'precision': 0.7534791252485089, 'recall': 0.758, 'f1-score': 0.7557328015952143, 'support': 500, 'AUC': 0.865202, 'AUCPR': 0.7869672893264475, 'TP': 379, 'FP': 124, 'TN': 876, 'FN': 121} 

2023-01-06 11:00: 
 Testing metrics {'precision': 0.8392523364485981, 'recall': 0.898, 'f1-score': 0.8676328502415458, 'support': 500, 'AUC': 0.95986, 'AUCPR': 0.9394477231557545, 'TP': 449, 'FP': 86, 'TN': 914, 'FN': 51} 

2023-01-06 11:01: Train Epoch 4: 3/24 Loss: 0.242851
2023-01-06 11:01: Train Epoch 4: 7/24 Loss: 0.216921
2023-01-06 11:01: Train Epoch 4: 11/24 Loss: 0.211485
2023-01-06 11:01: Train Epoch 4: 15/24 Loss: 0.231864
2023-01-06 11:01: Train Epoch 4: 19/24 Loss: 0.201510
2023-01-06 11:02: Train Epoch 4: 23/24 Loss: 0.185861
2023-01-06 11:02: **********Train Epoch 4: averaged Loss: 0.215082 
2023-01-06 11:02: 
Epoch time elapsed: 73.30170726776123

2023-01-06 11:02: 
 metrics validation: {'precision': 0.7214076246334311, 'recall': 0.492, 'f1-score': 0.5850178359096314, 'support': 500, 'AUC': 0.808222, 'AUCPR': 0.6883996701116225, 'TP': 246, 'FP': 95, 'TN': 905, 'FN': 254} 

2023-01-06 11:02: **********Val Epoch 4: average Loss: 0.258837
2023-01-06 11:02: 
 Testing metrics {'precision': 0.7534791252485089, 'recall': 0.758, 'f1-score': 0.7557328015952143, 'support': 500, 'AUC': 0.865202, 'AUCPR': 0.7869672893264475, 'TP': 379, 'FP': 124, 'TN': 876, 'FN': 121} 

2023-01-06 11:03: 
 Testing metrics {'precision': 0.8392523364485981, 'recall': 0.898, 'f1-score': 0.8676328502415458, 'support': 500, 'AUC': 0.95986, 'AUCPR': 0.9394477231557545, 'TP': 449, 'FP': 86, 'TN': 914, 'FN': 51} 

2023-01-06 11:03: Train Epoch 5: 3/24 Loss: 0.225275
2023-01-06 11:03: Train Epoch 5: 7/24 Loss: 0.219631
2023-01-06 11:04: Train Epoch 5: 11/24 Loss: 0.234187
2023-01-06 11:04: Train Epoch 5: 15/24 Loss: 0.207566
2023-01-06 11:04: Train Epoch 5: 19/24 Loss: 0.209165
2023-01-06 11:04: Train Epoch 5: 23/24 Loss: 0.212160
2023-01-06 11:04: **********Train Epoch 5: averaged Loss: 0.217997 
2023-01-06 11:04: 
Epoch time elapsed: 74.85474181175232

2023-01-06 11:05: 
 metrics validation: {'precision': 0.6918103448275862, 'recall': 0.642, 'f1-score': 0.6659751037344398, 'support': 500, 'AUC': 0.80757, 'AUCPR': 0.6890152084427289, 'TP': 321, 'FP': 143, 'TN': 857, 'FN': 179} 

2023-01-06 11:05: **********Val Epoch 5: average Loss: 0.249935
2023-01-06 11:05: *********************************Current best model saved!
2023-01-06 11:05: 
 Testing metrics {'precision': 0.7854077253218884, 'recall': 0.732, 'f1-score': 0.7577639751552796, 'support': 500, 'AUC': 0.868873, 'AUCPR': 0.7914681660721394, 'TP': 366, 'FP': 100, 'TN': 900, 'FN': 134} 

2023-01-06 11:06: 
 Testing metrics {'precision': 0.857685009487666, 'recall': 0.904, 'f1-score': 0.8802336903602725, 'support': 500, 'AUC': 0.963496, 'AUCPR': 0.9425511143439993, 'TP': 452, 'FP': 75, 'TN': 925, 'FN': 48} 

2023-01-06 11:06: Train Epoch 6: 3/24 Loss: 0.189496
2023-01-06 11:06: Train Epoch 6: 7/24 Loss: 0.214541
2023-01-06 11:06: Train Epoch 6: 11/24 Loss: 0.212526
2023-01-06 11:06: Train Epoch 6: 15/24 Loss: 0.210811
2023-01-06 11:07: Train Epoch 6: 19/24 Loss: 0.206842
2023-01-06 11:07: Train Epoch 6: 23/24 Loss: 0.178156
2023-01-06 11:07: **********Train Epoch 6: averaged Loss: 0.202062 
2023-01-06 11:07: 
Epoch time elapsed: 73.84354972839355

2023-01-06 11:07: 
 metrics validation: {'precision': 0.7413793103448276, 'recall': 0.516, 'f1-score': 0.6084905660377359, 'support': 500, 'AUC': 0.810824, 'AUCPR': 0.7016173953807538, 'TP': 258, 'FP': 90, 'TN': 910, 'FN': 242} 

2023-01-06 11:07: **********Val Epoch 6: average Loss: 0.258094
2023-01-06 11:08: 
 Testing metrics {'precision': 0.7854077253218884, 'recall': 0.732, 'f1-score': 0.7577639751552796, 'support': 500, 'AUC': 0.868873, 'AUCPR': 0.7914681660721394, 'TP': 366, 'FP': 100, 'TN': 900, 'FN': 134} 

2023-01-06 11:08: 
 Testing metrics {'precision': 0.857685009487666, 'recall': 0.904, 'f1-score': 0.8802336903602725, 'support': 500, 'AUC': 0.963496, 'AUCPR': 0.9425511143439993, 'TP': 452, 'FP': 75, 'TN': 925, 'FN': 48} 

2023-01-06 11:08: Train Epoch 7: 3/24 Loss: 0.219674
2023-01-06 11:09: Train Epoch 7: 7/24 Loss: 0.204666
2023-01-06 11:09: Train Epoch 7: 11/24 Loss: 0.188840
2023-01-06 11:09: Train Epoch 7: 15/24 Loss: 0.202585
2023-01-06 11:09: Train Epoch 7: 19/24 Loss: 0.216971
2023-01-06 11:09: Train Epoch 7: 23/24 Loss: 0.191559
2023-01-06 11:09: **********Train Epoch 7: averaged Loss: 0.204049 
2023-01-06 11:09: 
Epoch time elapsed: 68.7354507446289

2023-01-06 11:10: 
 metrics validation: {'precision': 0.6941176470588235, 'recall': 0.708, 'f1-score': 0.700990099009901, 'support': 500, 'AUC': 0.8090020000000001, 'AUCPR': 0.6989845329652282, 'TP': 354, 'FP': 156, 'TN': 844, 'FN': 146} 

2023-01-06 11:10: **********Val Epoch 7: average Loss: 0.251187
2023-01-06 11:10: 
 Testing metrics {'precision': 0.7854077253218884, 'recall': 0.732, 'f1-score': 0.7577639751552796, 'support': 500, 'AUC': 0.868873, 'AUCPR': 0.7914681660721394, 'TP': 366, 'FP': 100, 'TN': 900, 'FN': 134} 

2023-01-06 11:11: 
 Testing metrics {'precision': 0.857685009487666, 'recall': 0.904, 'f1-score': 0.8802336903602725, 'support': 500, 'AUC': 0.963496, 'AUCPR': 0.9425511143439993, 'TP': 452, 'FP': 75, 'TN': 925, 'FN': 48} 

2023-01-06 11:11: Train Epoch 8: 3/24 Loss: 0.212337
2023-01-06 11:11: Train Epoch 8: 7/24 Loss: 0.216732
2023-01-06 11:11: Train Epoch 8: 11/24 Loss: 0.201150
2023-01-06 11:12: Train Epoch 8: 15/24 Loss: 0.215323
2023-01-06 11:12: Train Epoch 8: 19/24 Loss: 0.218983
2023-01-06 11:12: Train Epoch 8: 23/24 Loss: 0.175856
2023-01-06 11:12: **********Train Epoch 8: averaged Loss: 0.206730 
2023-01-06 11:12: 
Epoch time elapsed: 68.96921610832214

2023-01-06 11:12: 
 metrics validation: {'precision': 0.6904761904761905, 'recall': 0.638, 'f1-score': 0.6632016632016632, 'support': 500, 'AUC': 0.8047019999999999, 'AUCPR': 0.6973825920612658, 'TP': 319, 'FP': 143, 'TN': 857, 'FN': 181} 

2023-01-06 11:12: **********Val Epoch 8: average Loss: 0.253335
2023-01-06 11:13: 
 Testing metrics {'precision': 0.7854077253218884, 'recall': 0.732, 'f1-score': 0.7577639751552796, 'support': 500, 'AUC': 0.868873, 'AUCPR': 0.7914681660721394, 'TP': 366, 'FP': 100, 'TN': 900, 'FN': 134} 

2023-01-06 11:13: 
 Testing metrics {'precision': 0.857685009487666, 'recall': 0.904, 'f1-score': 0.8802336903602725, 'support': 500, 'AUC': 0.963496, 'AUCPR': 0.9425511143439993, 'TP': 452, 'FP': 75, 'TN': 925, 'FN': 48} 

2023-01-06 11:13: Train Epoch 9: 3/24 Loss: 0.205140
2023-01-06 11:14: Train Epoch 9: 7/24 Loss: 0.208763
2023-01-06 11:14: Train Epoch 9: 11/24 Loss: 0.225662
2023-01-06 11:14: Train Epoch 9: 15/24 Loss: 0.260018
2023-01-06 11:14: Train Epoch 9: 19/24 Loss: 0.185336
2023-01-06 11:14: Train Epoch 9: 23/24 Loss: 0.184455
2023-01-06 11:14: **********Train Epoch 9: averaged Loss: 0.211562 
2023-01-06 11:14: 
Epoch time elapsed: 70.35678219795227

2023-01-06 11:15: 
 metrics validation: {'precision': 0.6521739130434783, 'recall': 0.72, 'f1-score': 0.6844106463878327, 'support': 500, 'AUC': 0.8061459999999999, 'AUCPR': 0.6993570745625213, 'TP': 360, 'FP': 192, 'TN': 808, 'FN': 140} 

2023-01-06 11:15: **********Val Epoch 9: average Loss: 0.251997
2023-01-06 11:15: 
 Testing metrics {'precision': 0.7854077253218884, 'recall': 0.732, 'f1-score': 0.7577639751552796, 'support': 500, 'AUC': 0.868873, 'AUCPR': 0.7914681660721394, 'TP': 366, 'FP': 100, 'TN': 900, 'FN': 134} 

2023-01-06 11:16: 
 Testing metrics {'precision': 0.857685009487666, 'recall': 0.904, 'f1-score': 0.8802336903602725, 'support': 500, 'AUC': 0.963496, 'AUCPR': 0.9425511143439993, 'TP': 452, 'FP': 75, 'TN': 925, 'FN': 48} 

2023-01-06 11:16: Train Epoch 10: 3/24 Loss: 0.226859
2023-01-06 11:16: Train Epoch 10: 7/24 Loss: 0.225980
2023-01-06 11:16: Train Epoch 10: 11/24 Loss: 0.221504
2023-01-06 11:17: Train Epoch 10: 15/24 Loss: 0.202072
2023-01-06 11:17: Train Epoch 10: 19/24 Loss: 0.194403
2023-01-06 11:17: Train Epoch 10: 23/24 Loss: 0.190061
2023-01-06 11:17: **********Train Epoch 10: averaged Loss: 0.210146 
2023-01-06 11:17: 
Epoch time elapsed: 71.4864890575409

2023-01-06 11:17: 
 metrics validation: {'precision': 0.7436708860759493, 'recall': 0.47, 'f1-score': 0.5759803921568627, 'support': 500, 'AUC': 0.8066319999999999, 'AUCPR': 0.699293428318591, 'TP': 235, 'FP': 81, 'TN': 919, 'FN': 265} 

2023-01-06 11:17: **********Val Epoch 10: average Loss: 0.259893
2023-01-06 11:18: 
 Testing metrics {'precision': 0.7854077253218884, 'recall': 0.732, 'f1-score': 0.7577639751552796, 'support': 500, 'AUC': 0.868873, 'AUCPR': 0.7914681660721394, 'TP': 366, 'FP': 100, 'TN': 900, 'FN': 134} 

2023-01-06 11:18: 
 Testing metrics {'precision': 0.857685009487666, 'recall': 0.904, 'f1-score': 0.8802336903602725, 'support': 500, 'AUC': 0.963496, 'AUCPR': 0.9425511143439993, 'TP': 452, 'FP': 75, 'TN': 925, 'FN': 48} 

2023-01-06 11:19: Train Epoch 11: 3/24 Loss: 0.214653
2023-01-06 11:19: Train Epoch 11: 7/24 Loss: 0.231095
2023-01-06 11:19: Train Epoch 11: 11/24 Loss: 0.205902
2023-01-06 11:19: Train Epoch 11: 15/24 Loss: 0.201858
2023-01-06 11:19: Train Epoch 11: 19/24 Loss: 0.207344
2023-01-06 11:20: Train Epoch 11: 23/24 Loss: 0.199892
2023-01-06 11:20: **********Train Epoch 11: averaged Loss: 0.210124 
2023-01-06 11:20: 
Epoch time elapsed: 70.5117540359497

2023-01-06 11:20: 
 metrics validation: {'precision': 0.6568265682656826, 'recall': 0.712, 'f1-score': 0.6833013435700576, 'support': 500, 'AUC': 0.8021659999999999, 'AUCPR': 0.694904095340531, 'TP': 356, 'FP': 186, 'TN': 814, 'FN': 144} 

2023-01-06 11:20: **********Val Epoch 11: average Loss: 0.255030
2023-01-06 11:20: 
 Testing metrics {'precision': 0.7854077253218884, 'recall': 0.732, 'f1-score': 0.7577639751552796, 'support': 500, 'AUC': 0.868873, 'AUCPR': 0.7914681660721394, 'TP': 366, 'FP': 100, 'TN': 900, 'FN': 134} 

2023-01-06 11:21: 
 Testing metrics {'precision': 0.857685009487666, 'recall': 0.904, 'f1-score': 0.8802336903602725, 'support': 500, 'AUC': 0.963496, 'AUCPR': 0.9425511143439993, 'TP': 452, 'FP': 75, 'TN': 925, 'FN': 48} 

2023-01-06 11:21: Train Epoch 12: 3/24 Loss: 0.219303
2023-01-06 11:21: Train Epoch 12: 7/24 Loss: 0.207206
2023-01-06 11:22: Train Epoch 12: 11/24 Loss: 0.209258
2023-01-06 11:22: Train Epoch 12: 15/24 Loss: 0.213718
2023-01-06 11:22: Train Epoch 12: 19/24 Loss: 0.222826
2023-01-06 11:22: Train Epoch 12: 23/24 Loss: 0.167555
2023-01-06 11:22: **********Train Epoch 12: averaged Loss: 0.206644 
2023-01-06 11:22: 
Epoch time elapsed: 72.20826959609985

2023-01-06 11:23: 
 metrics validation: {'precision': 0.7220779220779221, 'recall': 0.556, 'f1-score': 0.6282485875706215, 'support': 500, 'AUC': 0.801732, 'AUCPR': 0.6956775583780183, 'TP': 278, 'FP': 107, 'TN': 893, 'FN': 222} 

2023-01-06 11:23: **********Val Epoch 12: average Loss: 0.255982
2023-01-06 11:23: 
 Testing metrics {'precision': 0.7854077253218884, 'recall': 0.732, 'f1-score': 0.7577639751552796, 'support': 500, 'AUC': 0.868873, 'AUCPR': 0.7914681660721394, 'TP': 366, 'FP': 100, 'TN': 900, 'FN': 134} 

2023-01-06 11:24: 
 Testing metrics {'precision': 0.857685009487666, 'recall': 0.904, 'f1-score': 0.8802336903602725, 'support': 500, 'AUC': 0.963496, 'AUCPR': 0.9425511143439993, 'TP': 452, 'FP': 75, 'TN': 925, 'FN': 48} 

2023-01-06 11:24: Train Epoch 13: 3/24 Loss: 0.218627
2023-01-06 11:24: Train Epoch 13: 7/24 Loss: 0.210139
2023-01-06 11:24: Train Epoch 13: 11/24 Loss: 0.219813
2023-01-06 11:24: Train Epoch 13: 15/24 Loss: 0.208553
2023-01-06 11:25: Train Epoch 13: 19/24 Loss: 0.221039
2023-01-06 11:25: Train Epoch 13: 23/24 Loss: 0.172289
2023-01-06 11:25: **********Train Epoch 13: averaged Loss: 0.208410 
2023-01-06 11:25: 
Epoch time elapsed: 69.74007606506348

2023-01-06 11:25: 
 metrics validation: {'precision': 0.7721088435374149, 'recall': 0.454, 'f1-score': 0.5717884130982368, 'support': 500, 'AUC': 0.804364, 'AUCPR': 0.6984106533854202, 'TP': 227, 'FP': 67, 'TN': 933, 'FN': 273} 

2023-01-06 11:25: **********Val Epoch 13: average Loss: 0.265245
2023-01-06 11:25: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-06 11:25: Total training time: 32.8142min, best loss: 0.249935
2023-01-06 11:25: Saving current best model to /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010610525075780969386/best_model.pth
2023-01-06 11:26: 
 Testing metrics {'precision': 0.7854077253218884, 'recall': 0.732, 'f1-score': 0.7577639751552796, 'support': 500, 'AUC': 0.868873, 'AUCPR': 0.7914681660721394, 'TP': 366, 'FP': 100, 'TN': 900, 'FN': 134} 

2023-01-06 11:26: 
 Testing metrics {'precision': 0.857685009487666, 'recall': 0.904, 'f1-score': 0.8802336903602725, 'support': 500, 'AUC': 0.963496, 'AUCPR': 0.9425511143439993, 'TP': 452, 'FP': 75, 'TN': 925, 'FN': 48} 

