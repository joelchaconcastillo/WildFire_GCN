2023-01-04 11:33: log dir: /home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010411331666204319251
2023-01-04 11:33: Experiment log path in: /home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010411331666204319251
2023-01-04 11:33: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=5, embed_dim=32, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010411331666204319251', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=32, seed=100000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.01, window_len=10)
2023-01-04 11:33: Argument batch_size: 256
2023-01-04 11:33: Argument clc: 'vec'
2023-01-04 11:33: Argument cuda: True
2023-01-04 11:33: Argument dataset: '2020'
2023-01-04 11:33: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-04 11:33: Argument debug: False
2023-01-04 11:33: Argument default_graph: True
2023-01-04 11:33: Argument device: 'cpu'
2023-01-04 11:33: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-04 11:33: Argument early_stop: True
2023-01-04 11:33: Argument early_stop_patience: 5
2023-01-04 11:33: Argument embed_dim: 32
2023-01-04 11:33: Argument epochs: 30
2023-01-04 11:33: Argument grad_norm: False
2023-01-04 11:33: Argument horizon: 1
2023-01-04 11:33: Argument input_dim: 25
2023-01-04 11:33: Argument lag: 10
2023-01-04 11:33: Argument link_len: 2
2023-01-04 11:33: Argument log_dir: '/home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010411331666204319251'
2023-01-04 11:33: Argument log_step: 1
2023-01-04 11:33: Argument loss_func: 'nllloss'
2023-01-04 11:33: Argument lr_decay: True
2023-01-04 11:33: Argument lr_decay_rate: 0.1
2023-01-04 11:33: Argument lr_decay_step: '15'
2023-01-04 11:33: Argument lr_init: 0.0001
2023-01-04 11:33: Argument max_grad_norm: 5
2023-01-04 11:33: Argument minbatch_size: 64
2023-01-04 11:33: Argument mode: 'train'
2023-01-04 11:33: Argument model: 'fire_GCN'
2023-01-04 11:33: Argument nan_fill: -1.0
2023-01-04 11:33: Argument num_layers: 1
2023-01-04 11:33: Argument num_nodes: 625
2023-01-04 11:33: Argument num_workers: 12
2023-01-04 11:33: Argument output_dim: 2
2023-01-04 11:33: Argument patch_height: 25
2023-01-04 11:33: Argument patch_width: 25
2023-01-04 11:33: Argument persistent_workers: True
2023-01-04 11:33: Argument pin_memory: True
2023-01-04 11:33: Argument plot: False
2023-01-04 11:33: Argument positive_weight: 0.5
2023-01-04 11:33: Argument prefetch_factor: 2
2023-01-04 11:33: Argument real_value: True
2023-01-04 11:33: Argument rnn_units: 32
2023-01-04 11:33: Argument seed: 100000
2023-01-04 11:33: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-04 11:33: Argument teacher_forcing: False
2023-01-04 11:33: Argument weight_decay: 0.01
2023-01-04 11:33: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
convlstm.cell_list.0.conv.weight torch.Size([128, 57, 3, 3]) True
convlstm.cell_list.0.conv.bias torch.Size([128]) True
conv1.weight torch.Size([32, 32, 3, 3]) True
conv1.bias torch.Size([32]) True
fc1.weight torch.Size([64, 4608]) True
fc1.bias torch.Size([64]) True
fc2.weight torch.Size([32, 64]) True
fc2.bias torch.Size([32]) True
fc3.weight torch.Size([2, 32]) True
fc3.bias torch.Size([2]) True
Total params num: 372212
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010411331666204319251/run.log
2023-01-04 11:33: Train Epoch 1: 3/634 Loss: 0.801095
2023-01-04 11:33: Train Epoch 1: 7/634 Loss: 0.565864
2023-01-04 11:33: Train Epoch 1: 11/634 Loss: 0.552264
2023-01-04 11:33: Train Epoch 1: 15/634 Loss: 0.489522
2023-01-04 11:33: Train Epoch 1: 19/634 Loss: 0.472999
2023-01-04 11:33: Train Epoch 1: 23/634 Loss: 0.456004
2023-01-04 11:33: Train Epoch 1: 27/634 Loss: 0.432423
2023-01-04 11:33: Train Epoch 1: 31/634 Loss: 0.445115
2023-01-04 11:33: Train Epoch 1: 35/634 Loss: 0.398052
2023-01-04 11:33: Train Epoch 1: 39/634 Loss: 0.385801
2023-01-04 11:33: Train Epoch 1: 43/634 Loss: 0.394034
2023-01-04 11:33: Train Epoch 1: 47/634 Loss: 0.354069
2023-01-04 11:34: Train Epoch 1: 51/634 Loss: 0.381828
2023-01-04 11:34: Train Epoch 1: 55/634 Loss: 0.359993
2023-01-04 11:34: Train Epoch 1: 59/634 Loss: 0.383136
2023-01-04 11:34: Train Epoch 1: 63/634 Loss: 0.320703
2023-01-04 11:34: Train Epoch 1: 67/634 Loss: 0.329521
2023-01-04 11:34: Train Epoch 1: 71/634 Loss: 0.310840
2023-01-04 11:34: Train Epoch 1: 75/634 Loss: 0.299715
2023-01-04 11:34: Train Epoch 1: 79/634 Loss: 0.337885
2023-01-04 11:34: Train Epoch 1: 83/634 Loss: 0.308924
2023-01-04 11:34: Train Epoch 1: 87/634 Loss: 0.293841
2023-01-04 11:34: Train Epoch 1: 91/634 Loss: 0.287840
2023-01-04 11:34: Train Epoch 1: 95/634 Loss: 0.289089
2023-01-04 11:34: Train Epoch 1: 99/634 Loss: 0.288055
2023-01-04 11:34: Train Epoch 1: 103/634 Loss: 0.253459
2023-01-04 11:34: Train Epoch 1: 107/634 Loss: 0.286733
2023-01-04 11:34: Train Epoch 1: 111/634 Loss: 0.280797
2023-01-04 11:34: Train Epoch 1: 115/634 Loss: 0.270817
2023-01-04 11:34: Train Epoch 1: 119/634 Loss: 0.309305
2023-01-04 11:35: Train Epoch 1: 123/634 Loss: 0.284727
2023-01-04 11:35: Train Epoch 1: 127/634 Loss: 0.289017
2023-01-04 11:35: Train Epoch 1: 131/634 Loss: 0.239924
2023-01-04 11:35: Train Epoch 1: 135/634 Loss: 0.261877
2023-01-04 11:35: Train Epoch 1: 139/634 Loss: 0.262505
2023-01-04 11:35: Train Epoch 1: 143/634 Loss: 0.257527
2023-01-04 11:35: Train Epoch 1: 147/634 Loss: 0.230753
2023-01-04 11:35: Train Epoch 1: 151/634 Loss: 0.245536
2023-01-04 11:35: Train Epoch 1: 155/634 Loss: 0.227032
2023-01-04 11:35: Train Epoch 1: 159/634 Loss: 0.211030
2023-01-04 11:35: Train Epoch 1: 163/634 Loss: 0.230060
2023-01-04 11:35: Train Epoch 1: 167/634 Loss: 0.241282
2023-01-04 11:35: Train Epoch 1: 171/634 Loss: 0.256328
2023-01-04 11:35: Train Epoch 1: 175/634 Loss: 0.225556
2023-01-04 11:35: Train Epoch 1: 179/634 Loss: 0.211281
2023-01-04 11:35: Train Epoch 1: 183/634 Loss: 0.174014
2023-01-04 11:35: Train Epoch 1: 187/634 Loss: 0.222955
2023-01-04 11:35: Train Epoch 1: 191/634 Loss: 0.229798
2023-01-04 11:36: Train Epoch 1: 195/634 Loss: 0.234075
2023-01-04 11:36: Train Epoch 1: 199/634 Loss: 0.236792
2023-01-04 11:36: Train Epoch 1: 203/634 Loss: 0.189607
2023-01-04 11:36: Train Epoch 1: 207/634 Loss: 0.234748
2023-01-04 11:36: Train Epoch 1: 211/634 Loss: 0.226437
2023-01-04 11:36: Train Epoch 1: 215/634 Loss: 0.205717
2023-01-04 11:36: Train Epoch 1: 219/634 Loss: 0.301518
2023-01-04 11:36: Train Epoch 1: 223/634 Loss: 0.228777
2023-01-04 11:36: Train Epoch 1: 227/634 Loss: 0.200561
2023-01-04 11:36: Train Epoch 1: 231/634 Loss: 0.204883
2023-01-04 11:36: Train Epoch 1: 235/634 Loss: 0.198533
2023-01-04 11:36: Train Epoch 1: 239/634 Loss: 0.229090
2023-01-04 11:36: Train Epoch 1: 243/634 Loss: 0.232294
2023-01-04 11:36: Train Epoch 1: 247/634 Loss: 0.231760
2023-01-04 11:36: Train Epoch 1: 251/634 Loss: 0.199755
2023-01-04 11:36: Train Epoch 1: 255/634 Loss: 0.230073
2023-01-04 11:36: Train Epoch 1: 259/634 Loss: 0.226676
2023-01-04 11:36: Train Epoch 1: 263/634 Loss: 0.224431
2023-01-04 11:37: Train Epoch 1: 267/634 Loss: 0.262839
2023-01-04 11:37: Train Epoch 1: 271/634 Loss: 0.271945
2023-01-04 11:37: Train Epoch 1: 275/634 Loss: 0.247461
2023-01-04 11:37: Train Epoch 1: 279/634 Loss: 0.219207
2023-01-04 11:37: Train Epoch 1: 283/634 Loss: 0.210776
2023-01-04 11:37: Train Epoch 1: 287/634 Loss: 0.223864
2023-01-04 11:37: Train Epoch 1: 291/634 Loss: 0.214952
2023-01-04 11:37: Train Epoch 1: 295/634 Loss: 0.208287
2023-01-04 11:37: Train Epoch 1: 299/634 Loss: 0.221795
2023-01-04 11:37: Train Epoch 1: 303/634 Loss: 0.223841
2023-01-04 11:37: Train Epoch 1: 307/634 Loss: 0.223824
2023-01-04 11:37: Train Epoch 1: 311/634 Loss: 0.218934
2023-01-04 11:37: Train Epoch 1: 315/634 Loss: 0.192670
2023-01-04 11:37: Train Epoch 1: 319/634 Loss: 0.234696
2023-01-04 11:37: Train Epoch 1: 323/634 Loss: 0.221185
2023-01-04 11:37: Train Epoch 1: 327/634 Loss: 0.219028
2023-01-04 11:37: Train Epoch 1: 331/634 Loss: 0.223783
2023-01-04 11:37: Train Epoch 1: 335/634 Loss: 0.219232
2023-01-04 11:37: Train Epoch 1: 339/634 Loss: 0.251713
2023-01-04 11:38: Train Epoch 1: 343/634 Loss: 0.217335
2023-01-04 11:38: Train Epoch 1: 347/634 Loss: 0.189659
2023-01-04 11:38: Train Epoch 1: 351/634 Loss: 0.202106
2023-01-04 11:38: Train Epoch 1: 355/634 Loss: 0.229158
2023-01-04 11:38: Train Epoch 1: 359/634 Loss: 0.204871
2023-01-04 11:38: Train Epoch 1: 363/634 Loss: 0.235064
2023-01-04 11:38: Train Epoch 1: 367/634 Loss: 0.218407
2023-01-04 11:38: Train Epoch 1: 371/634 Loss: 0.211951
2023-01-04 11:38: Train Epoch 1: 375/634 Loss: 0.234883
2023-01-04 11:38: Train Epoch 1: 379/634 Loss: 0.180292
2023-01-04 11:38: Train Epoch 1: 383/634 Loss: 0.191681
2023-01-04 11:38: Train Epoch 1: 387/634 Loss: 0.185536
2023-01-04 11:38: Train Epoch 1: 391/634 Loss: 0.209249
2023-01-04 11:38: Train Epoch 1: 395/634 Loss: 0.197844
2023-01-04 11:38: Train Epoch 1: 399/634 Loss: 0.214339
2023-01-04 11:38: Train Epoch 1: 403/634 Loss: 0.175799
2023-01-04 11:38: Train Epoch 1: 407/634 Loss: 0.215136
2023-01-04 11:38: Train Epoch 1: 411/634 Loss: 0.220258
2023-01-04 11:39: Train Epoch 1: 415/634 Loss: 0.206743
2023-01-04 11:39: Train Epoch 1: 419/634 Loss: 0.205777
2023-01-04 11:39: Train Epoch 1: 423/634 Loss: 0.212209
2023-01-04 11:39: Train Epoch 1: 427/634 Loss: 0.227239
2023-01-04 11:39: Train Epoch 1: 431/634 Loss: 0.206230
2023-01-04 11:39: Train Epoch 1: 435/634 Loss: 0.174498
2023-01-04 11:39: Train Epoch 1: 439/634 Loss: 0.169717
2023-01-04 11:39: Train Epoch 1: 443/634 Loss: 0.237424
2023-01-04 11:39: Train Epoch 1: 447/634 Loss: 0.172910
2023-01-04 11:39: Train Epoch 1: 451/634 Loss: 0.242430
2023-01-04 11:39: Train Epoch 1: 455/634 Loss: 0.176963
2023-01-04 11:39: Train Epoch 1: 459/634 Loss: 0.205353
2023-01-04 11:39: Train Epoch 1: 463/634 Loss: 0.202152
2023-01-04 11:39: Train Epoch 1: 467/634 Loss: 0.259588
2023-01-04 11:39: Train Epoch 1: 471/634 Loss: 0.261419
2023-01-04 11:39: Train Epoch 1: 475/634 Loss: 0.201148
2023-01-04 11:39: Train Epoch 1: 479/634 Loss: 0.208340
2023-01-04 11:39: Train Epoch 1: 483/634 Loss: 0.181599
2023-01-04 11:40: Train Epoch 1: 487/634 Loss: 0.203063
2023-01-04 11:40: Train Epoch 1: 491/634 Loss: 0.191701
2023-01-04 11:40: Train Epoch 1: 495/634 Loss: 0.217639
2023-01-04 11:40: Train Epoch 1: 499/634 Loss: 0.191863
2023-01-04 11:40: Train Epoch 1: 503/634 Loss: 0.192533
2023-01-04 11:40: Train Epoch 1: 507/634 Loss: 0.162464
2023-01-04 11:40: Train Epoch 1: 511/634 Loss: 0.183134
2023-01-04 11:40: Train Epoch 1: 515/634 Loss: 0.215696
2023-01-04 11:40: Train Epoch 1: 519/634 Loss: 0.213951
2023-01-04 11:40: Train Epoch 1: 523/634 Loss: 0.205446
2023-01-04 11:40: Train Epoch 1: 527/634 Loss: 0.197495
2023-01-04 11:40: Train Epoch 1: 531/634 Loss: 0.189539
2023-01-04 11:40: Train Epoch 1: 535/634 Loss: 0.236316
2023-01-04 11:40: Train Epoch 1: 539/634 Loss: 0.215769
2023-01-04 11:40: Train Epoch 1: 543/634 Loss: 0.215596
2023-01-04 11:40: Train Epoch 1: 547/634 Loss: 0.196580
2023-01-04 11:40: Train Epoch 1: 551/634 Loss: 0.199312
2023-01-04 11:40: Train Epoch 1: 555/634 Loss: 0.222248
2023-01-04 11:41: Train Epoch 1: 559/634 Loss: 0.201495
2023-01-04 11:41: Train Epoch 1: 563/634 Loss: 0.199299
2023-01-04 11:41: Train Epoch 1: 567/634 Loss: 0.198722
2023-01-04 11:41: Train Epoch 1: 571/634 Loss: 0.248410
2023-01-04 11:41: Train Epoch 1: 575/634 Loss: 0.207807
2023-01-04 11:41: Train Epoch 1: 579/634 Loss: 0.214499
2023-01-04 11:41: Train Epoch 1: 583/634 Loss: 0.187965
2023-01-04 11:41: Train Epoch 1: 587/634 Loss: 0.200262
2023-01-04 11:41: Train Epoch 1: 591/634 Loss: 0.213099
2023-01-04 11:41: Train Epoch 1: 595/634 Loss: 0.206827
2023-01-04 11:41: Train Epoch 1: 599/634 Loss: 0.178081
2023-01-04 11:41: Train Epoch 1: 603/634 Loss: 0.234406
2023-01-04 11:41: Train Epoch 1: 607/634 Loss: 0.171864
2023-01-04 11:41: Train Epoch 1: 611/634 Loss: 0.197292
2023-01-04 11:41: Train Epoch 1: 615/634 Loss: 0.214258
2023-01-04 11:41: Train Epoch 1: 619/634 Loss: 0.199576
2023-01-04 11:41: Train Epoch 1: 623/634 Loss: 0.196511
2023-01-04 11:41: Train Epoch 1: 627/634 Loss: 0.212342
2023-01-04 11:42: Train Epoch 1: 631/634 Loss: 0.198646
2023-01-04 11:42: Train Epoch 1: 633/634 Loss: 0.084440
2023-01-04 11:42: **********Train Epoch 1: averaged Loss: 0.245837 
2023-01-04 11:42: 
Epoch time elapsed: 525.2396471500397

2023-01-04 11:42: 
 metrics validation: {'precision': 0.663358147229115, 'recall': 0.6169230769230769, 'f1-score': 0.639298525308888, 'support': 1300, 'AUC': 0.8158650887573965, 'AUCPR': 0.6937326132134394, 'TP': 802, 'FP': 407, 'TN': 2193, 'FN': 498} 

2023-01-04 11:42: **********Val Epoch 1: average Loss: 0.271148
2023-01-04 11:42: *********************************Current best model saved!
2023-01-04 11:43: 
 Testing metrics {'precision': 0.76, 'recall': 0.7117263843648208, 'f1-score': 0.735071488645921, 'support': 1228, 'AUC': 0.862291144998886, 'AUCPR': 0.7756626713766921, 'TP': 874, 'FP': 276, 'TN': 2180, 'FN': 354} 

2023-01-04 11:44: 
 Testing metrics {'precision': 0.8704304564135843, 'recall': 0.9130928068981167, 'f1-score': 0.8912513842746401, 'support': 4407, 'AUC': 0.965334302972935, 'AUCPR': 0.926972446337667, 'TP': 4024, 'FP': 599, 'TN': 8215, 'FN': 383} 

2023-01-04 11:44: Train Epoch 2: 3/634 Loss: 0.228526
2023-01-04 11:45: Train Epoch 2: 7/634 Loss: 0.184728
2023-01-04 11:45: Train Epoch 2: 11/634 Loss: 0.191573
2023-01-04 11:45: Train Epoch 2: 15/634 Loss: 0.183957
2023-01-04 11:45: Train Epoch 2: 19/634 Loss: 0.159586
2023-01-04 11:45: Train Epoch 2: 23/634 Loss: 0.177804
2023-01-04 11:45: Train Epoch 2: 27/634 Loss: 0.205704
2023-01-04 11:45: Train Epoch 2: 31/634 Loss: 0.205917
2023-01-04 11:45: Train Epoch 2: 35/634 Loss: 0.210186
2023-01-04 11:45: Train Epoch 2: 39/634 Loss: 0.192379
2023-01-04 11:45: Train Epoch 2: 43/634 Loss: 0.183685
2023-01-04 11:45: Train Epoch 2: 47/634 Loss: 0.208719
2023-01-04 11:45: Train Epoch 2: 51/634 Loss: 0.192829
2023-01-04 11:45: Train Epoch 2: 55/634 Loss: 0.204674
2023-01-04 11:46: Train Epoch 2: 59/634 Loss: 0.173699
2023-01-04 11:46: Train Epoch 2: 63/634 Loss: 0.185506
2023-01-04 11:46: Train Epoch 2: 67/634 Loss: 0.181163
2023-01-04 11:46: Train Epoch 2: 71/634 Loss: 0.183395
2023-01-04 11:46: Train Epoch 2: 75/634 Loss: 0.194519
2023-01-04 11:46: Train Epoch 2: 79/634 Loss: 0.264539
2023-01-04 11:46: Train Epoch 2: 83/634 Loss: 0.206095
2023-01-04 11:46: Train Epoch 2: 87/634 Loss: 0.159578
2023-01-04 11:46: Train Epoch 2: 91/634 Loss: 0.164753
2023-01-04 11:46: Train Epoch 2: 95/634 Loss: 0.229145
2023-01-04 11:46: Train Epoch 2: 99/634 Loss: 0.220476
2023-01-04 11:46: Train Epoch 2: 103/634 Loss: 0.174638
2023-01-04 11:46: Train Epoch 2: 107/634 Loss: 0.207371
2023-01-04 11:47: Train Epoch 2: 111/634 Loss: 0.228744
2023-01-04 11:47: Train Epoch 2: 115/634 Loss: 0.162186
2023-01-04 11:47: Train Epoch 2: 119/634 Loss: 0.209314
2023-01-04 11:47: Train Epoch 2: 123/634 Loss: 0.219822
2023-01-04 11:47: Train Epoch 2: 127/634 Loss: 0.192762
2023-01-04 11:47: Train Epoch 2: 131/634 Loss: 0.189528
2023-01-04 11:47: Train Epoch 2: 135/634 Loss: 0.212920
2023-01-04 11:47: Train Epoch 2: 139/634 Loss: 0.246978
2023-01-04 11:47: Train Epoch 2: 143/634 Loss: 0.173008
2023-01-04 11:47: Train Epoch 2: 147/634 Loss: 0.198543
2023-01-04 11:47: Train Epoch 2: 151/634 Loss: 0.199453
2023-01-04 11:47: Train Epoch 2: 155/634 Loss: 0.136590
2023-01-04 11:47: Train Epoch 2: 159/634 Loss: 0.214179
2023-01-04 11:47: Train Epoch 2: 163/634 Loss: 0.198232
2023-01-04 11:48: Train Epoch 2: 167/634 Loss: 0.192312
2023-01-04 11:48: Train Epoch 2: 171/634 Loss: 0.201233
2023-01-04 11:48: Train Epoch 2: 175/634 Loss: 0.196815
2023-01-04 11:48: Train Epoch 2: 179/634 Loss: 0.166005
2023-01-04 11:48: Train Epoch 2: 183/634 Loss: 0.171319
2023-01-04 11:48: Train Epoch 2: 187/634 Loss: 0.212985
2023-01-04 11:48: Train Epoch 2: 191/634 Loss: 0.219671
2023-01-04 11:48: Train Epoch 2: 195/634 Loss: 0.192710
2023-01-04 11:48: Train Epoch 2: 199/634 Loss: 0.214089
2023-01-04 11:48: Train Epoch 2: 203/634 Loss: 0.152756
2023-01-04 11:48: Train Epoch 2: 207/634 Loss: 0.190340
2023-01-04 11:48: Train Epoch 2: 211/634 Loss: 0.171675
2023-01-04 11:48: Train Epoch 2: 215/634 Loss: 0.210180
2023-01-04 11:48: Train Epoch 2: 219/634 Loss: 0.178335
2023-01-04 11:48: Train Epoch 2: 223/634 Loss: 0.199022
2023-01-04 11:49: Train Epoch 2: 227/634 Loss: 0.220650
2023-01-04 11:49: Train Epoch 2: 231/634 Loss: 0.183768
2023-01-04 11:49: Train Epoch 2: 235/634 Loss: 0.198393
2023-01-04 11:49: Train Epoch 2: 239/634 Loss: 0.208178
2023-01-04 11:49: Train Epoch 2: 243/634 Loss: 0.194097
2023-01-04 11:49: Train Epoch 2: 247/634 Loss: 0.206770
2023-01-04 11:49: Train Epoch 2: 251/634 Loss: 0.161459
2023-01-04 11:49: Train Epoch 2: 255/634 Loss: 0.211781
2023-01-04 11:49: Train Epoch 2: 259/634 Loss: 0.199785
2023-01-04 11:49: Train Epoch 2: 263/634 Loss: 0.195830
2023-01-04 11:49: Train Epoch 2: 267/634 Loss: 0.175116
2023-01-04 11:49: Train Epoch 2: 271/634 Loss: 0.195696
2023-01-04 11:49: Train Epoch 2: 275/634 Loss: 0.220355
2023-01-04 11:49: Train Epoch 2: 279/634 Loss: 0.187749
2023-01-04 11:49: Train Epoch 2: 283/634 Loss: 0.206402
2023-01-04 11:50: Train Epoch 2: 287/634 Loss: 0.170982
2023-01-04 11:50: Train Epoch 2: 291/634 Loss: 0.169712
2023-01-04 11:50: Train Epoch 2: 295/634 Loss: 0.176333
2023-01-04 11:50: Train Epoch 2: 299/634 Loss: 0.201175
2023-01-04 11:50: Train Epoch 2: 303/634 Loss: 0.187364
2023-01-04 11:50: Train Epoch 2: 307/634 Loss: 0.206013
2023-01-04 11:50: Train Epoch 2: 311/634 Loss: 0.201021
2023-01-04 11:50: Train Epoch 2: 315/634 Loss: 0.194421
2023-01-04 11:50: Train Epoch 2: 319/634 Loss: 0.173854
2023-01-04 11:50: Train Epoch 2: 323/634 Loss: 0.183848
2023-01-04 11:50: Train Epoch 2: 327/634 Loss: 0.172210
2023-01-04 11:50: Train Epoch 2: 331/634 Loss: 0.225359
2023-01-04 11:51: Train Epoch 2: 335/634 Loss: 0.179256
2023-01-04 11:51: Train Epoch 2: 339/634 Loss: 0.200471
2023-01-04 11:51: Train Epoch 2: 343/634 Loss: 0.175527
2023-01-04 11:51: Train Epoch 2: 347/634 Loss: 0.241872
2023-01-04 11:51: Train Epoch 2: 351/634 Loss: 0.200177
2023-01-04 11:51: Train Epoch 2: 355/634 Loss: 0.203269
2023-01-04 11:51: Train Epoch 2: 359/634 Loss: 0.208473
2023-01-04 11:51: Train Epoch 2: 363/634 Loss: 0.211460
2023-01-04 11:51: Train Epoch 2: 367/634 Loss: 0.172675
2023-01-04 11:51: Train Epoch 2: 371/634 Loss: 0.205553
2023-01-04 11:51: Train Epoch 2: 375/634 Loss: 0.198404
2023-01-04 11:51: Train Epoch 2: 379/634 Loss: 0.178799
2023-01-04 11:51: Train Epoch 2: 383/634 Loss: 0.154443
2023-01-04 11:52: Train Epoch 2: 387/634 Loss: 0.217362
2023-01-04 11:52: Train Epoch 2: 391/634 Loss: 0.168455
2023-01-04 11:52: Train Epoch 2: 395/634 Loss: 0.213360
2023-01-04 11:52: Train Epoch 2: 399/634 Loss: 0.221434
2023-01-04 11:52: Train Epoch 2: 403/634 Loss: 0.185402
2023-01-04 11:52: Train Epoch 2: 407/634 Loss: 0.138227
2023-01-04 11:52: Train Epoch 2: 411/634 Loss: 0.176410
2023-01-04 11:52: Train Epoch 2: 415/634 Loss: 0.202114
2023-01-04 11:52: Train Epoch 2: 419/634 Loss: 0.201289
2023-01-04 11:52: Train Epoch 2: 423/634 Loss: 0.171917
2023-01-04 11:52: Train Epoch 2: 427/634 Loss: 0.207841
2023-01-04 11:52: Train Epoch 2: 431/634 Loss: 0.183898
2023-01-04 11:52: Train Epoch 2: 435/634 Loss: 0.197271
2023-01-04 11:52: Train Epoch 2: 439/634 Loss: 0.203512
2023-01-04 11:53: Train Epoch 2: 443/634 Loss: 0.228896
2023-01-04 11:53: Train Epoch 2: 447/634 Loss: 0.181196
2023-01-04 11:53: Train Epoch 2: 451/634 Loss: 0.154125
2023-01-04 11:53: Train Epoch 2: 455/634 Loss: 0.171732
2023-01-04 11:53: Train Epoch 2: 459/634 Loss: 0.193409
2023-01-04 11:53: Train Epoch 2: 463/634 Loss: 0.165775
2023-01-04 11:53: Train Epoch 2: 467/634 Loss: 0.168867
2023-01-04 11:53: Train Epoch 2: 471/634 Loss: 0.218905
2023-01-04 11:53: Train Epoch 2: 475/634 Loss: 0.176328
2023-01-04 11:53: Train Epoch 2: 479/634 Loss: 0.200329
2023-01-04 11:53: Train Epoch 2: 483/634 Loss: 0.169875
2023-01-04 11:53: Train Epoch 2: 487/634 Loss: 0.187365
2023-01-04 11:53: Train Epoch 2: 491/634 Loss: 0.191991
2023-01-04 11:53: Train Epoch 2: 495/634 Loss: 0.183854
2023-01-04 11:54: Train Epoch 2: 499/634 Loss: 0.181782
2023-01-04 11:54: Train Epoch 2: 503/634 Loss: 0.174272
2023-01-04 11:54: Train Epoch 2: 507/634 Loss: 0.170740
2023-01-04 11:54: Train Epoch 2: 511/634 Loss: 0.190812
2023-01-04 11:54: Train Epoch 2: 515/634 Loss: 0.209815
2023-01-04 11:54: Train Epoch 2: 519/634 Loss: 0.185956
2023-01-04 11:54: Train Epoch 2: 523/634 Loss: 0.159359
2023-01-04 11:54: Train Epoch 2: 527/634 Loss: 0.181514
2023-01-04 11:54: Train Epoch 2: 531/634 Loss: 0.165902
2023-01-04 11:54: Train Epoch 2: 535/634 Loss: 0.172943
2023-01-04 11:54: Train Epoch 2: 539/634 Loss: 0.161526
2023-01-04 11:54: Train Epoch 2: 543/634 Loss: 0.192975
2023-01-04 11:54: Train Epoch 2: 547/634 Loss: 0.222651
2023-01-04 11:54: Train Epoch 2: 551/634 Loss: 0.158449
2023-01-04 11:54: Train Epoch 2: 555/634 Loss: 0.192132
2023-01-04 11:54: Train Epoch 2: 559/634 Loss: 0.175951
2023-01-04 11:54: Train Epoch 2: 563/634 Loss: 0.200850
2023-01-04 11:54: Train Epoch 2: 567/634 Loss: 0.182922
2023-01-04 11:54: Train Epoch 2: 571/634 Loss: 0.175040
2023-01-04 11:54: Train Epoch 2: 575/634 Loss: 0.164761
2023-01-04 11:54: Train Epoch 2: 579/634 Loss: 0.168553
2023-01-04 11:54: Train Epoch 2: 583/634 Loss: 0.169638
2023-01-04 11:54: Train Epoch 2: 587/634 Loss: 0.236745
2023-01-04 11:54: Train Epoch 2: 591/634 Loss: 0.169363
2023-01-04 11:54: Train Epoch 2: 595/634 Loss: 0.163730
2023-01-04 11:55: Train Epoch 2: 599/634 Loss: 0.186170
2023-01-04 11:55: Train Epoch 2: 603/634 Loss: 0.141500
2023-01-04 11:55: Train Epoch 2: 607/634 Loss: 0.193469
2023-01-04 11:55: Train Epoch 2: 611/634 Loss: 0.164450
2023-01-04 11:55: Train Epoch 2: 615/634 Loss: 0.202262
2023-01-04 11:55: Train Epoch 2: 619/634 Loss: 0.183671
2023-01-04 11:55: Train Epoch 2: 623/634 Loss: 0.165681
2023-01-04 11:55: Train Epoch 2: 627/634 Loss: 0.175379
2023-01-04 11:55: Train Epoch 2: 631/634 Loss: 0.179314
2023-01-04 11:55: Train Epoch 2: 633/634 Loss: 0.059157
2023-01-04 11:55: **********Train Epoch 2: averaged Loss: 0.189598 
2023-01-04 11:55: 
Epoch time elapsed: 625.585382938385

2023-01-04 11:55: 
 metrics validation: {'precision': 0.696113074204947, 'recall': 0.6061538461538462, 'f1-score': 0.6480263157894737, 'support': 1300, 'AUC': 0.8229970414201184, 'AUCPR': 0.7342489152210572, 'TP': 788, 'FP': 344, 'TN': 2256, 'FN': 512} 

2023-01-04 11:55: **********Val Epoch 2: average Loss: 0.268143
2023-01-04 11:55: *********************************Current best model saved!
2023-01-04 11:55: 
 Testing metrics {'precision': 0.7822349570200573, 'recall': 0.6669381107491856, 'f1-score': 0.72, 'support': 1228, 'AUC': 0.8673444147948519, 'AUCPR': 0.7971429893107026, 'TP': 819, 'FP': 228, 'TN': 2228, 'FN': 409} 

2023-01-04 11:56: 
 Testing metrics {'precision': 0.8774798343143667, 'recall': 0.9133197186294532, 'f1-score': 0.8950411385368023, 'support': 4407, 'AUC': 0.9664342353216249, 'AUCPR': 0.9343197387452312, 'TP': 4025, 'FP': 562, 'TN': 8252, 'FN': 382} 

2023-01-04 11:56: Train Epoch 3: 3/634 Loss: 0.159474
2023-01-04 11:56: Train Epoch 3: 7/634 Loss: 0.162037
2023-01-04 11:56: Train Epoch 3: 11/634 Loss: 0.196378
2023-01-04 11:56: Train Epoch 3: 15/634 Loss: 0.169518
2023-01-04 11:56: Train Epoch 3: 19/634 Loss: 0.169190
2023-01-04 11:56: Train Epoch 3: 23/634 Loss: 0.220151
2023-01-04 11:56: Train Epoch 3: 27/634 Loss: 0.180479
2023-01-04 11:56: Train Epoch 3: 31/634 Loss: 0.175482
2023-01-04 11:56: Train Epoch 3: 35/634 Loss: 0.204468
2023-01-04 11:56: Train Epoch 3: 39/634 Loss: 0.238308
2023-01-04 11:57: Train Epoch 3: 43/634 Loss: 0.165181
2023-01-04 11:57: Train Epoch 3: 47/634 Loss: 0.188419
2023-01-04 11:57: Train Epoch 3: 51/634 Loss: 0.188469
2023-01-04 11:57: Train Epoch 3: 55/634 Loss: 0.213645
2023-01-04 11:57: Train Epoch 3: 59/634 Loss: 0.221917
2023-01-04 11:57: Train Epoch 3: 63/634 Loss: 0.190270
2023-01-04 11:57: Train Epoch 3: 67/634 Loss: 0.190947
2023-01-04 11:57: Train Epoch 3: 71/634 Loss: 0.148413
2023-01-04 11:57: Train Epoch 3: 75/634 Loss: 0.178887
2023-01-04 11:57: Train Epoch 3: 79/634 Loss: 0.145786
2023-01-04 11:57: Train Epoch 3: 83/634 Loss: 0.189576
2023-01-04 11:57: Train Epoch 3: 87/634 Loss: 0.182966
2023-01-04 11:57: Train Epoch 3: 91/634 Loss: 0.168925
2023-01-04 11:57: Train Epoch 3: 95/634 Loss: 0.203684
2023-01-04 11:57: Train Epoch 3: 99/634 Loss: 0.143029
2023-01-04 11:57: Train Epoch 3: 103/634 Loss: 0.201324
2023-01-04 11:57: Train Epoch 3: 107/634 Loss: 0.179168
2023-01-04 11:57: Train Epoch 3: 111/634 Loss: 0.193185
2023-01-04 11:57: Train Epoch 3: 115/634 Loss: 0.177003
2023-01-04 11:57: Train Epoch 3: 119/634 Loss: 0.188245
2023-01-04 11:57: Train Epoch 3: 123/634 Loss: 0.192614
2023-01-04 11:57: Train Epoch 3: 127/634 Loss: 0.160491
2023-01-04 11:57: Train Epoch 3: 131/634 Loss: 0.181528
2023-01-04 11:57: Train Epoch 3: 135/634 Loss: 0.193162
2023-01-04 11:57: Train Epoch 3: 139/634 Loss: 0.188864
2023-01-04 11:57: Train Epoch 3: 143/634 Loss: 0.208646
2023-01-04 11:57: Train Epoch 3: 147/634 Loss: 0.175248
2023-01-04 11:58: Train Epoch 3: 151/634 Loss: 0.179669
2023-01-04 11:58: Train Epoch 3: 155/634 Loss: 0.178826
2023-01-04 11:58: Train Epoch 3: 159/634 Loss: 0.171787
2023-01-04 11:58: Train Epoch 3: 163/634 Loss: 0.155092
2023-01-04 11:58: Train Epoch 3: 167/634 Loss: 0.155251
2023-01-04 11:58: Train Epoch 3: 171/634 Loss: 0.182594
2023-01-04 11:58: Train Epoch 3: 175/634 Loss: 0.189293
2023-01-04 11:58: Train Epoch 3: 179/634 Loss: 0.195056
2023-01-04 11:58: Train Epoch 3: 183/634 Loss: 0.226844
2023-01-04 11:58: Train Epoch 3: 187/634 Loss: 0.184067
2023-01-04 11:58: Train Epoch 3: 191/634 Loss: 0.174028
2023-01-04 11:58: Train Epoch 3: 195/634 Loss: 0.186897
2023-01-04 11:58: Train Epoch 3: 199/634 Loss: 0.181684
2023-01-04 11:58: Train Epoch 3: 203/634 Loss: 0.191369
2023-01-04 11:58: Train Epoch 3: 207/634 Loss: 0.172091
2023-01-04 11:58: Train Epoch 3: 211/634 Loss: 0.183086
2023-01-04 11:58: Train Epoch 3: 215/634 Loss: 0.202367
2023-01-04 11:58: Train Epoch 3: 219/634 Loss: 0.170775
2023-01-04 11:58: Train Epoch 3: 223/634 Loss: 0.167241
2023-01-04 11:58: Train Epoch 3: 227/634 Loss: 0.161402
2023-01-04 11:58: Train Epoch 3: 231/634 Loss: 0.160399
2023-01-04 11:58: Train Epoch 3: 235/634 Loss: 0.147953
2023-01-04 11:58: Train Epoch 3: 239/634 Loss: 0.159990
2023-01-04 11:58: Train Epoch 3: 243/634 Loss: 0.190778
2023-01-04 11:58: Train Epoch 3: 247/634 Loss: 0.189127
2023-01-04 11:58: Train Epoch 3: 251/634 Loss: 0.171943
2023-01-04 11:59: Train Epoch 3: 255/634 Loss: 0.191375
2023-01-04 11:59: Train Epoch 3: 259/634 Loss: 0.200884
2023-01-04 11:59: Train Epoch 3: 263/634 Loss: 0.215660
2023-01-04 11:59: Train Epoch 3: 267/634 Loss: 0.142315
2023-01-04 11:59: Train Epoch 3: 271/634 Loss: 0.147658
2023-01-04 11:59: Train Epoch 3: 275/634 Loss: 0.196317
2023-01-04 11:59: Train Epoch 3: 279/634 Loss: 0.159225
2023-01-04 11:59: Train Epoch 3: 283/634 Loss: 0.195753
2023-01-04 11:59: Train Epoch 3: 287/634 Loss: 0.176288
2023-01-04 11:59: Train Epoch 3: 291/634 Loss: 0.172921
2023-01-04 11:59: Train Epoch 3: 295/634 Loss: 0.146979
2023-01-04 11:59: Train Epoch 3: 299/634 Loss: 0.204125
2023-01-04 11:59: Train Epoch 3: 303/634 Loss: 0.168483
2023-01-04 11:59: Train Epoch 3: 307/634 Loss: 0.166750
2023-01-04 11:59: Train Epoch 3: 311/634 Loss: 0.194174
2023-01-04 11:59: Train Epoch 3: 315/634 Loss: 0.175484
2023-01-04 11:59: Train Epoch 3: 319/634 Loss: 0.159313
2023-01-04 11:59: Train Epoch 3: 323/634 Loss: 0.192104
2023-01-04 11:59: Train Epoch 3: 327/634 Loss: 0.183378
2023-01-04 11:59: Train Epoch 3: 331/634 Loss: 0.174031
2023-01-04 11:59: Train Epoch 3: 335/634 Loss: 0.183620
2023-01-04 11:59: Train Epoch 3: 339/634 Loss: 0.171709
2023-01-04 11:59: Train Epoch 3: 343/634 Loss: 0.189257
2023-01-04 11:59: Train Epoch 3: 347/634 Loss: 0.143789
2023-01-04 11:59: Train Epoch 3: 351/634 Loss: 0.182796
2023-01-04 11:59: Train Epoch 3: 355/634 Loss: 0.181912
2023-01-04 11:59: Train Epoch 3: 359/634 Loss: 0.181374
2023-01-04 12:00: Train Epoch 3: 363/634 Loss: 0.185178
2023-01-04 12:00: Train Epoch 3: 367/634 Loss: 0.198323
2023-01-04 12:00: Train Epoch 3: 371/634 Loss: 0.192560
2023-01-04 12:00: Train Epoch 3: 375/634 Loss: 0.172162
2023-01-04 12:00: Train Epoch 3: 379/634 Loss: 0.184102
2023-01-04 12:00: Train Epoch 3: 383/634 Loss: 0.153788
2023-01-04 12:00: Train Epoch 3: 387/634 Loss: 0.230661
2023-01-04 12:00: Train Epoch 3: 391/634 Loss: 0.185105
2023-01-04 12:00: Train Epoch 3: 395/634 Loss: 0.170303
2023-01-04 12:00: Train Epoch 3: 399/634 Loss: 0.203874
2023-01-04 12:00: Train Epoch 3: 403/634 Loss: 0.199386
2023-01-04 12:00: Train Epoch 3: 407/634 Loss: 0.158712
2023-01-04 12:00: Train Epoch 3: 411/634 Loss: 0.150651
2023-01-04 12:00: Train Epoch 3: 415/634 Loss: 0.199946
2023-01-04 12:00: Train Epoch 3: 419/634 Loss: 0.179409
2023-01-04 12:00: Train Epoch 3: 423/634 Loss: 0.149939
2023-01-04 12:00: Train Epoch 3: 427/634 Loss: 0.162458
2023-01-04 12:00: Train Epoch 3: 431/634 Loss: 0.141033
2023-01-04 12:00: Train Epoch 3: 435/634 Loss: 0.172463
2023-01-04 12:00: Train Epoch 3: 439/634 Loss: 0.161557
2023-01-04 12:00: Train Epoch 3: 443/634 Loss: 0.152416
2023-01-04 12:00: Train Epoch 3: 447/634 Loss: 0.180353
2023-01-04 12:00: Train Epoch 3: 451/634 Loss: 0.146701
2023-01-04 12:00: Train Epoch 3: 455/634 Loss: 0.149669
2023-01-04 12:00: Train Epoch 3: 459/634 Loss: 0.180217
2023-01-04 12:00: Train Epoch 3: 463/634 Loss: 0.195908
2023-01-04 12:00: Train Epoch 3: 467/634 Loss: 0.148039
2023-01-04 12:00: Train Epoch 3: 471/634 Loss: 0.183169
2023-01-04 12:01: Train Epoch 3: 475/634 Loss: 0.140187
2023-01-04 12:01: Train Epoch 3: 479/634 Loss: 0.176606
2023-01-04 12:01: Train Epoch 3: 483/634 Loss: 0.177940
2023-01-04 12:01: Train Epoch 3: 487/634 Loss: 0.154920
2023-01-04 12:01: Train Epoch 3: 491/634 Loss: 0.181936
2023-01-04 12:01: Train Epoch 3: 495/634 Loss: 0.188132
2023-01-04 12:01: Train Epoch 3: 499/634 Loss: 0.176519
2023-01-04 12:01: Train Epoch 3: 503/634 Loss: 0.141007
2023-01-04 12:01: Train Epoch 3: 507/634 Loss: 0.152388
2023-01-04 12:01: Train Epoch 3: 511/634 Loss: 0.160339
2023-01-04 12:01: Train Epoch 3: 515/634 Loss: 0.158883
2023-01-04 12:01: Train Epoch 3: 519/634 Loss: 0.160365
2023-01-04 12:01: Train Epoch 3: 523/634 Loss: 0.173535
2023-01-04 12:01: Train Epoch 3: 527/634 Loss: 0.156244
2023-01-04 12:01: Train Epoch 3: 531/634 Loss: 0.173904
2023-01-04 12:01: Train Epoch 3: 535/634 Loss: 0.139632
2023-01-04 12:01: Train Epoch 3: 539/634 Loss: 0.132386
2023-01-04 12:01: Train Epoch 3: 543/634 Loss: 0.156244
2023-01-04 12:01: Train Epoch 3: 547/634 Loss: 0.188752
2023-01-04 12:01: Train Epoch 3: 551/634 Loss: 0.160056
2023-01-04 12:01: Train Epoch 3: 555/634 Loss: 0.158223
2023-01-04 12:01: Train Epoch 3: 559/634 Loss: 0.154127
2023-01-04 12:01: Train Epoch 3: 563/634 Loss: 0.167017
2023-01-04 12:01: Train Epoch 3: 567/634 Loss: 0.164889
2023-01-04 12:01: Train Epoch 3: 571/634 Loss: 0.157830
2023-01-04 12:01: Train Epoch 3: 575/634 Loss: 0.155972
2023-01-04 12:01: Train Epoch 3: 579/634 Loss: 0.173737
2023-01-04 12:02: Train Epoch 3: 583/634 Loss: 0.168193
2023-01-04 12:02: Train Epoch 3: 587/634 Loss: 0.193298
2023-01-04 12:02: Train Epoch 3: 591/634 Loss: 0.146651
2023-01-04 12:02: Train Epoch 3: 595/634 Loss: 0.192074
2023-01-04 12:02: Train Epoch 3: 599/634 Loss: 0.141200
2023-01-04 12:02: Train Epoch 3: 603/634 Loss: 0.189335
2023-01-04 12:02: Train Epoch 3: 607/634 Loss: 0.173519
2023-01-04 12:02: Train Epoch 3: 611/634 Loss: 0.145167
2023-01-04 12:02: Train Epoch 3: 615/634 Loss: 0.180027
2023-01-04 12:02: Train Epoch 3: 619/634 Loss: 0.149999
2023-01-04 12:02: Train Epoch 3: 623/634 Loss: 0.210484
2023-01-04 12:02: Train Epoch 3: 627/634 Loss: 0.156105
2023-01-04 12:02: Train Epoch 3: 631/634 Loss: 0.124100
2023-01-04 12:02: Train Epoch 3: 633/634 Loss: 0.057096
2023-01-04 12:02: **********Train Epoch 3: averaged Loss: 0.174588 
2023-01-04 12:02: 
Epoch time elapsed: 352.220844745636

2023-01-04 12:02: 
 metrics validation: {'precision': 0.6674025018395879, 'recall': 0.6976923076923077, 'f1-score': 0.6822113576532531, 'support': 1300, 'AUC': 0.8314511834319527, 'AUCPR': 0.7532589816531271, 'TP': 907, 'FP': 452, 'TN': 2148, 'FN': 393} 

2023-01-04 12:02: **********Val Epoch 3: average Loss: 0.268560
2023-01-04 12:02: 
 Testing metrics {'precision': 0.7822349570200573, 'recall': 0.6669381107491856, 'f1-score': 0.72, 'support': 1228, 'AUC': 0.8673444147948519, 'AUCPR': 0.7971429893107026, 'TP': 819, 'FP': 228, 'TN': 2228, 'FN': 409} 

2023-01-04 12:03: 
 Testing metrics {'precision': 0.8774798343143667, 'recall': 0.9133197186294532, 'f1-score': 0.8950411385368023, 'support': 4407, 'AUC': 0.9664342353216249, 'AUCPR': 0.9343197387452312, 'TP': 4025, 'FP': 562, 'TN': 8252, 'FN': 382} 

2023-01-04 12:03: Train Epoch 4: 3/634 Loss: 0.144969
2023-01-04 12:03: Train Epoch 4: 7/634 Loss: 0.167692
2023-01-04 12:03: Train Epoch 4: 11/634 Loss: 0.158141
2023-01-04 12:03: Train Epoch 4: 15/634 Loss: 0.206946
2023-01-04 12:03: Train Epoch 4: 19/634 Loss: 0.209789
2023-01-04 12:03: Train Epoch 4: 23/634 Loss: 0.177756
2023-01-04 12:04: Train Epoch 4: 27/634 Loss: 0.180972
2023-01-04 12:04: Train Epoch 4: 31/634 Loss: 0.172514
2023-01-04 12:04: Train Epoch 4: 35/634 Loss: 0.159691
2023-01-04 12:04: Train Epoch 4: 39/634 Loss: 0.164222
2023-01-04 12:04: Train Epoch 4: 43/634 Loss: 0.182856
2023-01-04 12:04: Train Epoch 4: 47/634 Loss: 0.149940
2023-01-04 12:04: Train Epoch 4: 51/634 Loss: 0.151359
2023-01-04 12:04: Train Epoch 4: 55/634 Loss: 0.192520
2023-01-04 12:04: Train Epoch 4: 59/634 Loss: 0.165610
2023-01-04 12:04: Train Epoch 4: 63/634 Loss: 0.226881
2023-01-04 12:04: Train Epoch 4: 67/634 Loss: 0.182908
2023-01-04 12:04: Train Epoch 4: 71/634 Loss: 0.156151
2023-01-04 12:04: Train Epoch 4: 75/634 Loss: 0.176585
2023-01-04 12:04: Train Epoch 4: 79/634 Loss: 0.213679
2023-01-04 12:04: Train Epoch 4: 83/634 Loss: 0.168807
2023-01-04 12:04: Train Epoch 4: 87/634 Loss: 0.145248
2023-01-04 12:04: Train Epoch 4: 91/634 Loss: 0.178379
2023-01-04 12:04: Train Epoch 4: 95/634 Loss: 0.163659
2023-01-04 12:04: Train Epoch 4: 99/634 Loss: 0.184742
2023-01-04 12:04: Train Epoch 4: 103/634 Loss: 0.170092
2023-01-04 12:04: Train Epoch 4: 107/634 Loss: 0.152491
2023-01-04 12:04: Train Epoch 4: 111/634 Loss: 0.181797
2023-01-04 12:04: Train Epoch 4: 115/634 Loss: 0.194076
2023-01-04 12:04: Train Epoch 4: 119/634 Loss: 0.193064
2023-01-04 12:04: Train Epoch 4: 123/634 Loss: 0.215265
2023-01-04 12:04: Train Epoch 4: 127/634 Loss: 0.183279
2023-01-04 12:04: Train Epoch 4: 131/634 Loss: 0.165669
2023-01-04 12:05: Train Epoch 4: 135/634 Loss: 0.210894
2023-01-04 12:05: Train Epoch 4: 139/634 Loss: 0.162704
2023-01-04 12:05: Train Epoch 4: 143/634 Loss: 0.193130
2023-01-04 12:05: Train Epoch 4: 147/634 Loss: 0.183263
2023-01-04 12:05: Train Epoch 4: 151/634 Loss: 0.170744
2023-01-04 12:05: Train Epoch 4: 155/634 Loss: 0.164127
2023-01-04 12:05: Train Epoch 4: 159/634 Loss: 0.189365
2023-01-04 12:05: Train Epoch 4: 163/634 Loss: 0.195453
2023-01-04 12:05: Train Epoch 4: 167/634 Loss: 0.156770
2023-01-04 12:05: Train Epoch 4: 171/634 Loss: 0.181521
2023-01-04 12:05: Train Epoch 4: 175/634 Loss: 0.170445
2023-01-04 12:05: Train Epoch 4: 179/634 Loss: 0.180815
2023-01-04 12:05: Train Epoch 4: 183/634 Loss: 0.173670
2023-01-04 12:05: Train Epoch 4: 187/634 Loss: 0.186657
2023-01-04 12:05: Train Epoch 4: 191/634 Loss: 0.195299
2023-01-04 12:05: Train Epoch 4: 195/634 Loss: 0.150767
2023-01-04 12:05: Train Epoch 4: 199/634 Loss: 0.189224
2023-01-04 12:05: Train Epoch 4: 203/634 Loss: 0.215652
2023-01-04 12:05: Train Epoch 4: 207/634 Loss: 0.279459
2023-01-04 12:05: Train Epoch 4: 211/634 Loss: 0.176655
2023-01-04 12:05: Train Epoch 4: 215/634 Loss: 0.191790
2023-01-04 12:05: Train Epoch 4: 219/634 Loss: 0.183942
2023-01-04 12:05: Train Epoch 4: 223/634 Loss: 0.189419
2023-01-04 12:05: Train Epoch 4: 227/634 Loss: 0.193362
2023-01-04 12:05: Train Epoch 4: 231/634 Loss: 0.145202
2023-01-04 12:05: Train Epoch 4: 235/634 Loss: 0.164790
2023-01-04 12:05: Train Epoch 4: 239/634 Loss: 0.206929
2023-01-04 12:06: Train Epoch 4: 243/634 Loss: 0.184774
2023-01-04 12:06: Train Epoch 4: 247/634 Loss: 0.169708
2023-01-04 12:06: Train Epoch 4: 251/634 Loss: 0.174005
2023-01-04 12:06: Train Epoch 4: 255/634 Loss: 0.188594
2023-01-04 12:06: Train Epoch 4: 259/634 Loss: 0.165153
2023-01-04 12:06: Train Epoch 4: 263/634 Loss: 0.188469
2023-01-04 12:06: Train Epoch 4: 267/634 Loss: 0.164666
2023-01-04 12:06: Train Epoch 4: 271/634 Loss: 0.203016
2023-01-04 12:06: Train Epoch 4: 275/634 Loss: 0.192579
2023-01-04 12:06: Train Epoch 4: 279/634 Loss: 0.149028
2023-01-04 12:06: Train Epoch 4: 283/634 Loss: 0.199759
2023-01-04 12:06: Train Epoch 4: 287/634 Loss: 0.168410
2023-01-04 12:06: Train Epoch 4: 291/634 Loss: 0.188611
2023-01-04 12:06: Train Epoch 4: 295/634 Loss: 0.131513
2023-01-04 12:06: Train Epoch 4: 299/634 Loss: 0.192841
2023-01-04 12:06: Train Epoch 4: 303/634 Loss: 0.160620
2023-01-04 12:06: Train Epoch 4: 307/634 Loss: 0.214255
2023-01-04 12:06: Train Epoch 4: 311/634 Loss: 0.175452
2023-01-04 12:06: Train Epoch 4: 315/634 Loss: 0.177650
2023-01-04 12:06: Train Epoch 4: 319/634 Loss: 0.195649
2023-01-04 12:06: Train Epoch 4: 323/634 Loss: 0.162207
2023-01-04 12:06: Train Epoch 4: 327/634 Loss: 0.188300
2023-01-04 12:06: Train Epoch 4: 331/634 Loss: 0.172259
2023-01-04 12:06: Train Epoch 4: 335/634 Loss: 0.153502
2023-01-04 12:06: Train Epoch 4: 339/634 Loss: 0.196212
2023-01-04 12:06: Train Epoch 4: 343/634 Loss: 0.163757
2023-01-04 12:06: Train Epoch 4: 347/634 Loss: 0.208748
2023-01-04 12:07: Train Epoch 4: 351/634 Loss: 0.164952
2023-01-04 12:07: Train Epoch 4: 355/634 Loss: 0.181102
2023-01-04 12:07: Train Epoch 4: 359/634 Loss: 0.160830
2023-01-04 12:07: Train Epoch 4: 363/634 Loss: 0.214124
2023-01-04 12:07: Train Epoch 4: 367/634 Loss: 0.195425
2023-01-04 12:07: Train Epoch 4: 371/634 Loss: 0.177341
2023-01-04 12:07: Train Epoch 4: 375/634 Loss: 0.189079
2023-01-04 12:07: Train Epoch 4: 379/634 Loss: 0.199540
2023-01-04 12:07: Train Epoch 4: 383/634 Loss: 0.167330
2023-01-04 12:07: Train Epoch 4: 387/634 Loss: 0.192606
2023-01-04 12:07: Train Epoch 4: 391/634 Loss: 0.180340
2023-01-04 12:07: Train Epoch 4: 395/634 Loss: 0.148558
2023-01-04 12:07: Train Epoch 4: 399/634 Loss: 0.210294
2023-01-04 12:07: Train Epoch 4: 403/634 Loss: 0.202462
2023-01-04 12:07: Train Epoch 4: 407/634 Loss: 0.193596
2023-01-04 12:07: Train Epoch 4: 411/634 Loss: 0.181021
2023-01-04 12:07: Train Epoch 4: 415/634 Loss: 0.161306
2023-01-04 12:07: Train Epoch 4: 419/634 Loss: 0.160578
2023-01-04 12:07: Train Epoch 4: 423/634 Loss: 0.170213
2023-01-04 12:07: Train Epoch 4: 427/634 Loss: 0.163633
2023-01-04 12:07: Train Epoch 4: 431/634 Loss: 0.167037
2023-01-04 12:07: Train Epoch 4: 435/634 Loss: 0.153184
2023-01-04 12:07: Train Epoch 4: 439/634 Loss: 0.202198
2023-01-04 12:07: Train Epoch 4: 443/634 Loss: 0.149790
2023-01-04 12:07: Train Epoch 4: 447/634 Loss: 0.168066
2023-01-04 12:07: Train Epoch 4: 451/634 Loss: 0.181458
2023-01-04 12:07: Train Epoch 4: 455/634 Loss: 0.171599
2023-01-04 12:08: Train Epoch 4: 459/634 Loss: 0.181642
2023-01-04 12:08: Train Epoch 4: 463/634 Loss: 0.146581
2023-01-04 12:08: Train Epoch 4: 467/634 Loss: 0.146599
2023-01-04 12:08: Train Epoch 4: 471/634 Loss: 0.200503
2023-01-04 12:08: Train Epoch 4: 475/634 Loss: 0.167168
2023-01-04 12:08: Train Epoch 4: 479/634 Loss: 0.162009
2023-01-04 12:08: Train Epoch 4: 483/634 Loss: 0.157150
2023-01-04 12:08: Train Epoch 4: 487/634 Loss: 0.150942
2023-01-04 12:08: Train Epoch 4: 491/634 Loss: 0.168735
2023-01-04 12:08: Train Epoch 4: 495/634 Loss: 0.205358
2023-01-04 12:08: Train Epoch 4: 499/634 Loss: 0.162608
2023-01-04 12:08: Train Epoch 4: 503/634 Loss: 0.181521
2023-01-04 12:08: Train Epoch 4: 507/634 Loss: 0.168790
2023-01-04 12:08: Train Epoch 4: 511/634 Loss: 0.210339
2023-01-04 12:08: Train Epoch 4: 515/634 Loss: 0.148376
2023-01-04 12:08: Train Epoch 4: 519/634 Loss: 0.168851
2023-01-04 12:08: Train Epoch 4: 523/634 Loss: 0.147119
2023-01-04 12:08: Train Epoch 4: 527/634 Loss: 0.140854
2023-01-04 12:08: Train Epoch 4: 531/634 Loss: 0.173313
2023-01-04 12:08: Train Epoch 4: 535/634 Loss: 0.140189
2023-01-04 12:08: Train Epoch 4: 539/634 Loss: 0.150117
2023-01-04 12:08: Train Epoch 4: 543/634 Loss: 0.180117
2023-01-04 12:08: Train Epoch 4: 547/634 Loss: 0.222559
2023-01-04 12:08: Train Epoch 4: 551/634 Loss: 0.140775
2023-01-04 12:08: Train Epoch 4: 555/634 Loss: 0.160468
2023-01-04 12:08: Train Epoch 4: 559/634 Loss: 0.145809
2023-01-04 12:08: Train Epoch 4: 563/634 Loss: 0.151645
2023-01-04 12:09: Train Epoch 4: 567/634 Loss: 0.178760
2023-01-04 12:09: Train Epoch 4: 571/634 Loss: 0.143209
2023-01-04 12:09: Train Epoch 4: 575/634 Loss: 0.172426
2023-01-04 12:09: Train Epoch 4: 579/634 Loss: 0.157825
2023-01-04 12:09: Train Epoch 4: 583/634 Loss: 0.230468
2023-01-04 12:09: Train Epoch 4: 587/634 Loss: 0.171832
2023-01-04 12:09: Train Epoch 4: 591/634 Loss: 0.173231
2023-01-04 12:09: Train Epoch 4: 595/634 Loss: 0.163515
2023-01-04 12:09: Train Epoch 4: 599/634 Loss: 0.157254
2023-01-04 12:09: Train Epoch 4: 603/634 Loss: 0.166260
2023-01-04 12:09: Train Epoch 4: 607/634 Loss: 0.168461
2023-01-04 12:09: Train Epoch 4: 611/634 Loss: 0.161841
2023-01-04 12:09: Train Epoch 4: 615/634 Loss: 0.152654
2023-01-04 12:09: Train Epoch 4: 619/634 Loss: 0.172914
2023-01-04 12:09: Train Epoch 4: 623/634 Loss: 0.141268
2023-01-04 12:09: Train Epoch 4: 627/634 Loss: 0.162874
2023-01-04 12:09: Train Epoch 4: 631/634 Loss: 0.176855
2023-01-04 12:09: Train Epoch 4: 633/634 Loss: 0.060902
2023-01-04 12:09: **********Train Epoch 4: averaged Loss: 0.175282 
2023-01-04 12:09: 
Epoch time elapsed: 350.3573045730591

2023-01-04 12:09: 
 metrics validation: {'precision': 0.6873406966864911, 'recall': 0.6223076923076923, 'f1-score': 0.6532095276544208, 'support': 1300, 'AUC': 0.8277331360946746, 'AUCPR': 0.7482902389680766, 'TP': 809, 'FP': 368, 'TN': 2232, 'FN': 491} 

2023-01-04 12:09: **********Val Epoch 4: average Loss: 0.282851
2023-01-04 12:10: 
 Testing metrics {'precision': 0.7822349570200573, 'recall': 0.6669381107491856, 'f1-score': 0.72, 'support': 1228, 'AUC': 0.8673444147948519, 'AUCPR': 0.7971429893107026, 'TP': 819, 'FP': 228, 'TN': 2228, 'FN': 409} 

2023-01-04 12:10: 
 Testing metrics {'precision': 0.8774798343143667, 'recall': 0.9133197186294532, 'f1-score': 0.8950411385368023, 'support': 4407, 'AUC': 0.9664342353216249, 'AUCPR': 0.9343197387452312, 'TP': 4025, 'FP': 562, 'TN': 8252, 'FN': 382} 

2023-01-04 12:10: Train Epoch 5: 3/634 Loss: 0.161820
2023-01-04 12:10: Train Epoch 5: 7/634 Loss: 0.203679
2023-01-04 12:10: Train Epoch 5: 11/634 Loss: 0.170831
2023-01-04 12:11: Train Epoch 5: 15/634 Loss: 0.159978
2023-01-04 12:11: Train Epoch 5: 19/634 Loss: 0.168081
2023-01-04 12:11: Train Epoch 5: 23/634 Loss: 0.182991
2023-01-04 12:11: Train Epoch 5: 27/634 Loss: 0.157337
2023-01-04 12:11: Train Epoch 5: 31/634 Loss: 0.213888
2023-01-04 12:11: Train Epoch 5: 35/634 Loss: 0.196251
2023-01-04 12:11: Train Epoch 5: 39/634 Loss: 0.180809
2023-01-04 12:11: Train Epoch 5: 43/634 Loss: 0.219836
2023-01-04 12:11: Train Epoch 5: 47/634 Loss: 0.192015
2023-01-04 12:11: Train Epoch 5: 51/634 Loss: 0.199064
2023-01-04 12:11: Train Epoch 5: 55/634 Loss: 0.215928
2023-01-04 12:11: Train Epoch 5: 59/634 Loss: 0.198618
2023-01-04 12:11: Train Epoch 5: 63/634 Loss: 0.160342
2023-01-04 12:11: Train Epoch 5: 67/634 Loss: 0.216133
2023-01-04 12:11: Train Epoch 5: 71/634 Loss: 0.217609
2023-01-04 12:11: Train Epoch 5: 75/634 Loss: 0.181637
2023-01-04 12:11: Train Epoch 5: 79/634 Loss: 0.244972
2023-01-04 12:11: Train Epoch 5: 83/634 Loss: 0.168023
2023-01-04 12:11: Train Epoch 5: 87/634 Loss: 0.175455
2023-01-04 12:11: Train Epoch 5: 91/634 Loss: 0.173623
2023-01-04 12:11: Train Epoch 5: 95/634 Loss: 0.179796
2023-01-04 12:11: Train Epoch 5: 99/634 Loss: 0.196964
2023-01-04 12:11: Train Epoch 5: 103/634 Loss: 0.169083
2023-01-04 12:11: Train Epoch 5: 107/634 Loss: 0.180244
2023-01-04 12:11: Train Epoch 5: 111/634 Loss: 0.169411
2023-01-04 12:11: Train Epoch 5: 115/634 Loss: 0.169416
2023-01-04 12:11: Train Epoch 5: 119/634 Loss: 0.180781
2023-01-04 12:12: Train Epoch 5: 123/634 Loss: 0.167295
2023-01-04 12:12: Train Epoch 5: 127/634 Loss: 0.144507
2023-01-04 12:12: Train Epoch 5: 131/634 Loss: 0.200155
2023-01-04 12:12: Train Epoch 5: 135/634 Loss: 0.164018
2023-01-04 12:12: Train Epoch 5: 139/634 Loss: 0.195269
2023-01-04 12:12: Train Epoch 5: 143/634 Loss: 0.139995
2023-01-04 12:12: Train Epoch 5: 147/634 Loss: 0.170087
2023-01-04 12:12: Train Epoch 5: 151/634 Loss: 0.146955
2023-01-04 12:12: Train Epoch 5: 155/634 Loss: 0.159333
2023-01-04 12:12: Train Epoch 5: 159/634 Loss: 0.209509
2023-01-04 12:12: Train Epoch 5: 163/634 Loss: 0.183783
2023-01-04 12:12: Train Epoch 5: 167/634 Loss: 0.190560
2023-01-04 12:12: Train Epoch 5: 171/634 Loss: 0.187629
2023-01-04 12:12: Train Epoch 5: 175/634 Loss: 0.198262
2023-01-04 12:12: Train Epoch 5: 179/634 Loss: 0.168103
2023-01-04 12:12: Train Epoch 5: 183/634 Loss: 0.160574
2023-01-04 12:12: Train Epoch 5: 187/634 Loss: 0.206554
2023-01-04 12:12: Train Epoch 5: 191/634 Loss: 0.147924
2023-01-04 12:12: Train Epoch 5: 195/634 Loss: 0.202898
2023-01-04 12:12: Train Epoch 5: 199/634 Loss: 0.182455
2023-01-04 12:12: Train Epoch 5: 203/634 Loss: 0.197882
2023-01-04 12:12: Train Epoch 5: 207/634 Loss: 0.177832
2023-01-04 12:12: Train Epoch 5: 211/634 Loss: 0.199738
2023-01-04 12:12: Train Epoch 5: 215/634 Loss: 0.173913
2023-01-04 12:12: Train Epoch 5: 219/634 Loss: 0.182056
2023-01-04 12:12: Train Epoch 5: 223/634 Loss: 0.189890
2023-01-04 12:12: Train Epoch 5: 227/634 Loss: 0.175544
2023-01-04 12:12: Train Epoch 5: 231/634 Loss: 0.156778
2023-01-04 12:13: Train Epoch 5: 235/634 Loss: 0.177647
2023-01-04 12:13: Train Epoch 5: 239/634 Loss: 0.179138
2023-01-04 12:13: Train Epoch 5: 243/634 Loss: 0.172753
2023-01-04 12:13: Train Epoch 5: 247/634 Loss: 0.223129
2023-01-04 12:13: Train Epoch 5: 251/634 Loss: 0.178212
2023-01-04 12:13: Train Epoch 5: 255/634 Loss: 0.174831
2023-01-04 12:13: Train Epoch 5: 259/634 Loss: 0.142234
2023-01-04 12:13: Train Epoch 5: 263/634 Loss: 0.187721
2023-01-04 12:13: Train Epoch 5: 267/634 Loss: 0.164504
2023-01-04 12:13: Train Epoch 5: 271/634 Loss: 0.167038
2023-01-04 12:13: Train Epoch 5: 275/634 Loss: 0.180842
2023-01-04 12:13: Train Epoch 5: 279/634 Loss: 0.199028
2023-01-04 12:13: Train Epoch 5: 283/634 Loss: 0.156893
2023-01-04 12:13: Train Epoch 5: 287/634 Loss: 0.112901
2023-01-04 12:13: Train Epoch 5: 291/634 Loss: 0.183036
2023-01-04 12:13: Train Epoch 5: 295/634 Loss: 0.149552
2023-01-04 12:13: Train Epoch 5: 299/634 Loss: 0.159833
2023-01-04 12:13: Train Epoch 5: 303/634 Loss: 0.216297
2023-01-04 12:13: Train Epoch 5: 307/634 Loss: 0.160677
2023-01-04 12:13: Train Epoch 5: 311/634 Loss: 0.242614
2023-01-04 12:13: Train Epoch 5: 315/634 Loss: 0.150537
2023-01-04 12:13: Train Epoch 5: 319/634 Loss: 0.195924
2023-01-04 12:13: Train Epoch 5: 323/634 Loss: 0.191607
2023-01-04 12:13: Train Epoch 5: 327/634 Loss: 0.159129
2023-01-04 12:13: Train Epoch 5: 331/634 Loss: 0.195953
2023-01-04 12:13: Train Epoch 5: 335/634 Loss: 0.184344
2023-01-04 12:13: Train Epoch 5: 339/634 Loss: 0.178832
2023-01-04 12:14: Train Epoch 5: 343/634 Loss: 0.118485
2023-01-04 12:14: Train Epoch 5: 347/634 Loss: 0.200666
2023-01-04 12:14: Train Epoch 5: 351/634 Loss: 0.162631
2023-01-04 12:14: Train Epoch 5: 355/634 Loss: 0.184368
2023-01-04 12:14: Train Epoch 5: 359/634 Loss: 0.165753
2023-01-04 12:14: Train Epoch 5: 363/634 Loss: 0.177080
2023-01-04 12:14: Train Epoch 5: 367/634 Loss: 0.161049
2023-01-04 12:14: Train Epoch 5: 371/634 Loss: 0.131126
2023-01-04 12:14: Train Epoch 5: 375/634 Loss: 0.160125
2023-01-04 12:14: Train Epoch 5: 379/634 Loss: 0.178636
2023-01-04 12:14: Train Epoch 5: 383/634 Loss: 0.154774
2023-01-04 12:14: Train Epoch 5: 387/634 Loss: 0.185841
2023-01-04 12:14: Train Epoch 5: 391/634 Loss: 0.223181
2023-01-04 12:14: Train Epoch 5: 395/634 Loss: 0.172022
2023-01-04 12:14: Train Epoch 5: 399/634 Loss: 0.198296
2023-01-04 12:14: Train Epoch 5: 403/634 Loss: 0.184315
2023-01-04 12:14: Train Epoch 5: 407/634 Loss: 0.165131
2023-01-04 12:14: Train Epoch 5: 411/634 Loss: 0.160267
2023-01-04 12:14: Train Epoch 5: 415/634 Loss: 0.181271
2023-01-04 12:14: Train Epoch 5: 419/634 Loss: 0.196489
2023-01-04 12:14: Train Epoch 5: 423/634 Loss: 0.197706
2023-01-04 12:14: Train Epoch 5: 427/634 Loss: 0.153833
2023-01-04 12:14: Train Epoch 5: 431/634 Loss: 0.195798
2023-01-04 12:14: Train Epoch 5: 435/634 Loss: 0.181765
2023-01-04 12:14: Train Epoch 5: 439/634 Loss: 0.176989
2023-01-04 12:14: Train Epoch 5: 443/634 Loss: 0.163098
2023-01-04 12:14: Train Epoch 5: 447/634 Loss: 0.163026
2023-01-04 12:14: Train Epoch 5: 451/634 Loss: 0.154744
2023-01-04 12:15: Train Epoch 5: 455/634 Loss: 0.140229
2023-01-04 12:15: Train Epoch 5: 459/634 Loss: 0.164099
2023-01-04 12:15: Train Epoch 5: 463/634 Loss: 0.192212
2023-01-04 12:15: Train Epoch 5: 467/634 Loss: 0.152563
2023-01-04 12:15: Train Epoch 5: 471/634 Loss: 0.176936
2023-01-04 12:15: Train Epoch 5: 475/634 Loss: 0.152173
2023-01-04 12:15: Train Epoch 5: 479/634 Loss: 0.185069
2023-01-04 12:15: Train Epoch 5: 483/634 Loss: 0.147059
2023-01-04 12:15: Train Epoch 5: 487/634 Loss: 0.161394
2023-01-04 12:15: Train Epoch 5: 491/634 Loss: 0.169071
2023-01-04 12:15: Train Epoch 5: 495/634 Loss: 0.148958
2023-01-04 12:15: Train Epoch 5: 499/634 Loss: 0.128900
2023-01-04 12:15: Train Epoch 5: 503/634 Loss: 0.181669
2023-01-04 12:15: Train Epoch 5: 507/634 Loss: 0.179522
2023-01-04 12:15: Train Epoch 5: 511/634 Loss: 0.197123
2023-01-04 12:15: Train Epoch 5: 515/634 Loss: 0.167771
2023-01-04 12:15: Train Epoch 5: 519/634 Loss: 0.138776
2023-01-04 12:15: Train Epoch 5: 523/634 Loss: 0.156270
2023-01-04 12:15: Train Epoch 5: 527/634 Loss: 0.167394
2023-01-04 12:15: Train Epoch 5: 531/634 Loss: 0.139524
2023-01-04 12:15: Train Epoch 5: 535/634 Loss: 0.163901
2023-01-04 12:15: Train Epoch 5: 539/634 Loss: 0.175256
2023-01-04 12:15: Train Epoch 5: 543/634 Loss: 0.159885
2023-01-04 12:15: Train Epoch 5: 547/634 Loss: 0.200728
2023-01-04 12:15: Train Epoch 5: 551/634 Loss: 0.176603
2023-01-04 12:15: Train Epoch 5: 555/634 Loss: 0.210614
2023-01-04 12:15: Train Epoch 5: 559/634 Loss: 0.199929
2023-01-04 12:16: Train Epoch 5: 563/634 Loss: 0.235718
2023-01-04 12:16: Train Epoch 5: 567/634 Loss: 0.168780
2023-01-04 12:16: Train Epoch 5: 571/634 Loss: 0.184911
2023-01-04 12:16: Train Epoch 5: 575/634 Loss: 0.181798
2023-01-04 12:16: Train Epoch 5: 579/634 Loss: 0.167705
2023-01-04 12:16: Train Epoch 5: 583/634 Loss: 0.175405
2023-01-04 12:16: Train Epoch 5: 587/634 Loss: 0.192504
2023-01-04 12:16: Train Epoch 5: 591/634 Loss: 0.170263
2023-01-04 12:16: Train Epoch 5: 595/634 Loss: 0.147368
2023-01-04 12:16: Train Epoch 5: 599/634 Loss: 0.151988
2023-01-04 12:16: Train Epoch 5: 603/634 Loss: 0.174331
2023-01-04 12:16: Train Epoch 5: 607/634 Loss: 0.208706
2023-01-04 12:16: Train Epoch 5: 611/634 Loss: 0.186989
2023-01-04 12:16: Train Epoch 5: 615/634 Loss: 0.120648
2023-01-04 12:16: Train Epoch 5: 619/634 Loss: 0.200342
2023-01-04 12:16: Train Epoch 5: 623/634 Loss: 0.164149
2023-01-04 12:16: Train Epoch 5: 627/634 Loss: 0.177187
2023-01-04 12:16: Train Epoch 5: 631/634 Loss: 0.176341
2023-01-04 12:16: Train Epoch 5: 633/634 Loss: 0.068493
2023-01-04 12:16: **********Train Epoch 5: averaged Loss: 0.176132 
2023-01-04 12:16: 
Epoch time elapsed: 346.8168647289276

2023-01-04 12:16: 
 metrics validation: {'precision': 0.688412017167382, 'recall': 0.6169230769230769, 'f1-score': 0.6507099391480731, 'support': 1300, 'AUC': 0.8303097633136095, 'AUCPR': 0.7460862504546275, 'TP': 802, 'FP': 363, 'TN': 2237, 'FN': 498} 

2023-01-04 12:16: **********Val Epoch 5: average Loss: 0.273016
2023-01-04 12:17: 
 Testing metrics {'precision': 0.7822349570200573, 'recall': 0.6669381107491856, 'f1-score': 0.72, 'support': 1228, 'AUC': 0.8673444147948519, 'AUCPR': 0.7971429893107026, 'TP': 819, 'FP': 228, 'TN': 2228, 'FN': 409} 

2023-01-04 12:17: 
 Testing metrics {'precision': 0.8774798343143667, 'recall': 0.9133197186294532, 'f1-score': 0.8950411385368023, 'support': 4407, 'AUC': 0.9664342353216249, 'AUCPR': 0.9343197387452312, 'TP': 4025, 'FP': 562, 'TN': 8252, 'FN': 382} 

2023-01-04 12:17: Train Epoch 6: 3/634 Loss: 0.213745
2023-01-04 12:18: Train Epoch 6: 7/634 Loss: 0.187959
2023-01-04 12:18: Train Epoch 6: 11/634 Loss: 0.127607
2023-01-04 12:18: Train Epoch 6: 15/634 Loss: 0.206025
2023-01-04 12:18: Train Epoch 6: 19/634 Loss: 0.187938
2023-01-04 12:18: Train Epoch 6: 23/634 Loss: 0.162457
2023-01-04 12:18: Train Epoch 6: 27/634 Loss: 0.172094
2023-01-04 12:18: Train Epoch 6: 31/634 Loss: 0.173236
2023-01-04 12:18: Train Epoch 6: 35/634 Loss: 0.177174
2023-01-04 12:18: Train Epoch 6: 39/634 Loss: 0.163581
2023-01-04 12:18: Train Epoch 6: 43/634 Loss: 0.144392
2023-01-04 12:18: Train Epoch 6: 47/634 Loss: 0.183871
2023-01-04 12:18: Train Epoch 6: 51/634 Loss: 0.159314
2023-01-04 12:18: Train Epoch 6: 55/634 Loss: 0.191481
2023-01-04 12:18: Train Epoch 6: 59/634 Loss: 0.137386
2023-01-04 12:18: Train Epoch 6: 63/634 Loss: 0.191965
2023-01-04 12:18: Train Epoch 6: 67/634 Loss: 0.193989
2023-01-04 12:18: Train Epoch 6: 71/634 Loss: 0.176414
2023-01-04 12:18: Train Epoch 6: 75/634 Loss: 0.179298
2023-01-04 12:18: Train Epoch 6: 79/634 Loss: 0.189045
2023-01-04 12:18: Train Epoch 6: 83/634 Loss: 0.197490
2023-01-04 12:18: Train Epoch 6: 87/634 Loss: 0.188812
2023-01-04 12:18: Train Epoch 6: 91/634 Loss: 0.200010
2023-01-04 12:18: Train Epoch 6: 95/634 Loss: 0.134201
2023-01-04 12:18: Train Epoch 6: 99/634 Loss: 0.177787
2023-01-04 12:18: Train Epoch 6: 103/634 Loss: 0.199152
2023-01-04 12:18: Train Epoch 6: 107/634 Loss: 0.159657
2023-01-04 12:18: Train Epoch 6: 111/634 Loss: 0.183044
2023-01-04 12:18: Train Epoch 6: 115/634 Loss: 0.156626
2023-01-04 12:19: Train Epoch 6: 119/634 Loss: 0.204304
2023-01-04 12:19: Train Epoch 6: 123/634 Loss: 0.212201
2023-01-04 12:19: Train Epoch 6: 127/634 Loss: 0.190918
2023-01-04 12:19: Train Epoch 6: 131/634 Loss: 0.215131
2023-01-04 12:19: Train Epoch 6: 135/634 Loss: 0.190107
2023-01-04 12:19: Train Epoch 6: 139/634 Loss: 0.175644
2023-01-04 12:19: Train Epoch 6: 143/634 Loss: 0.193417
2023-01-04 12:19: Train Epoch 6: 147/634 Loss: 0.211752
2023-01-04 12:19: Train Epoch 6: 151/634 Loss: 0.205909
2023-01-04 12:19: Train Epoch 6: 155/634 Loss: 0.175762
2023-01-04 12:19: Train Epoch 6: 159/634 Loss: 0.169288
2023-01-04 12:19: Train Epoch 6: 163/634 Loss: 0.147413
2023-01-04 12:19: Train Epoch 6: 167/634 Loss: 0.187243
2023-01-04 12:19: Train Epoch 6: 171/634 Loss: 0.179019
2023-01-04 12:19: Train Epoch 6: 175/634 Loss: 0.173400
2023-01-04 12:19: Train Epoch 6: 179/634 Loss: 0.197600
2023-01-04 12:19: Train Epoch 6: 183/634 Loss: 0.181069
2023-01-04 12:19: Train Epoch 6: 187/634 Loss: 0.157463
2023-01-04 12:19: Train Epoch 6: 191/634 Loss: 0.192803
2023-01-04 12:19: Train Epoch 6: 195/634 Loss: 0.224894
2023-01-04 12:19: Train Epoch 6: 199/634 Loss: 0.179131
2023-01-04 12:19: Train Epoch 6: 203/634 Loss: 0.142134
2023-01-04 12:19: Train Epoch 6: 207/634 Loss: 0.183572
2023-01-04 12:19: Train Epoch 6: 211/634 Loss: 0.154508
2023-01-04 12:19: Train Epoch 6: 215/634 Loss: 0.162462
2023-01-04 12:19: Train Epoch 6: 219/634 Loss: 0.186994
2023-01-04 12:19: Train Epoch 6: 223/634 Loss: 0.180068
2023-01-04 12:20: Train Epoch 6: 227/634 Loss: 0.194781
2023-01-04 12:20: Train Epoch 6: 231/634 Loss: 0.173692
2023-01-04 12:20: Train Epoch 6: 235/634 Loss: 0.160962
2023-01-04 12:20: Train Epoch 6: 239/634 Loss: 0.144570
2023-01-04 12:20: Train Epoch 6: 243/634 Loss: 0.192882
2023-01-04 12:20: Train Epoch 6: 247/634 Loss: 0.194713
2023-01-04 12:20: Train Epoch 6: 251/634 Loss: 0.176647
2023-01-04 12:20: Train Epoch 6: 255/634 Loss: 0.157544
2023-01-04 12:20: Train Epoch 6: 259/634 Loss: 0.167645
2023-01-04 12:20: Train Epoch 6: 263/634 Loss: 0.171468
2023-01-04 12:20: Train Epoch 6: 267/634 Loss: 0.210624
2023-01-04 12:20: Train Epoch 6: 271/634 Loss: 0.179959
2023-01-04 12:20: Train Epoch 6: 275/634 Loss: 0.142041
2023-01-04 12:20: Train Epoch 6: 279/634 Loss: 0.142168
2023-01-04 12:20: Train Epoch 6: 283/634 Loss: 0.183956
2023-01-04 12:20: Train Epoch 6: 287/634 Loss: 0.173392
2023-01-04 12:20: Train Epoch 6: 291/634 Loss: 0.208545
2023-01-04 12:20: Train Epoch 6: 295/634 Loss: 0.140826
2023-01-04 12:20: Train Epoch 6: 299/634 Loss: 0.182971
2023-01-04 12:20: Train Epoch 6: 303/634 Loss: 0.175558
2023-01-04 12:20: Train Epoch 6: 307/634 Loss: 0.207624
2023-01-04 12:20: Train Epoch 6: 311/634 Loss: 0.155936
2023-01-04 12:20: Train Epoch 6: 315/634 Loss: 0.182284
2023-01-04 12:20: Train Epoch 6: 319/634 Loss: 0.198487
2023-01-04 12:20: Train Epoch 6: 323/634 Loss: 0.201983
2023-01-04 12:20: Train Epoch 6: 327/634 Loss: 0.159286
2023-01-04 12:20: Train Epoch 6: 331/634 Loss: 0.193284
2023-01-04 12:20: Train Epoch 6: 335/634 Loss: 0.163266
2023-01-04 12:21: Train Epoch 6: 339/634 Loss: 0.168419
2023-01-04 12:21: Train Epoch 6: 343/634 Loss: 0.173598
2023-01-04 12:21: Train Epoch 6: 347/634 Loss: 0.187269
2023-01-04 12:21: Train Epoch 6: 351/634 Loss: 0.146829
2023-01-04 12:21: Train Epoch 6: 355/634 Loss: 0.162585
2023-01-04 12:21: Train Epoch 6: 359/634 Loss: 0.143453
2023-01-04 12:21: Train Epoch 6: 363/634 Loss: 0.185944
2023-01-04 12:21: Train Epoch 6: 367/634 Loss: 0.159428
2023-01-04 12:21: Train Epoch 6: 371/634 Loss: 0.176098
2023-01-04 12:21: Train Epoch 6: 375/634 Loss: 0.195733
2023-01-04 12:21: Train Epoch 6: 379/634 Loss: 0.134182
2023-01-04 12:21: Train Epoch 6: 383/634 Loss: 0.220981
2023-01-04 12:21: Train Epoch 6: 387/634 Loss: 0.144906
2023-01-04 12:21: Train Epoch 6: 391/634 Loss: 0.166981
2023-01-04 12:21: Train Epoch 6: 395/634 Loss: 0.162626
2023-01-04 12:21: Train Epoch 6: 399/634 Loss: 0.147487
2023-01-04 12:21: Train Epoch 6: 403/634 Loss: 0.177183
2023-01-04 12:21: Train Epoch 6: 407/634 Loss: 0.199955
2023-01-04 12:21: Train Epoch 6: 411/634 Loss: 0.154989
2023-01-04 12:21: Train Epoch 6: 415/634 Loss: 0.213889
2023-01-04 12:21: Train Epoch 6: 419/634 Loss: 0.207873
2023-01-04 12:21: Train Epoch 6: 423/634 Loss: 0.179630
2023-01-04 12:21: Train Epoch 6: 427/634 Loss: 0.213867
2023-01-04 12:21: Train Epoch 6: 431/634 Loss: 0.180218
2023-01-04 12:21: Train Epoch 6: 435/634 Loss: 0.163356
2023-01-04 12:21: Train Epoch 6: 439/634 Loss: 0.195869
2023-01-04 12:21: Train Epoch 6: 443/634 Loss: 0.165503
2023-01-04 12:22: Train Epoch 6: 447/634 Loss: 0.207786
2023-01-04 12:22: Train Epoch 6: 451/634 Loss: 0.152506
2023-01-04 12:22: Train Epoch 6: 455/634 Loss: 0.166618
2023-01-04 12:22: Train Epoch 6: 459/634 Loss: 0.179453
2023-01-04 12:22: Train Epoch 6: 463/634 Loss: 0.193096
2023-01-04 12:22: Train Epoch 6: 467/634 Loss: 0.146397
2023-01-04 12:22: Train Epoch 6: 471/634 Loss: 0.181249
2023-01-04 12:22: Train Epoch 6: 475/634 Loss: 0.135152
2023-01-04 12:22: Train Epoch 6: 479/634 Loss: 0.169452
2023-01-04 12:22: Train Epoch 6: 483/634 Loss: 0.176754
2023-01-04 12:22: Train Epoch 6: 487/634 Loss: 0.162917
2023-01-04 12:22: Train Epoch 6: 491/634 Loss: 0.160297
2023-01-04 12:22: Train Epoch 6: 495/634 Loss: 0.180831
2023-01-04 12:22: Train Epoch 6: 499/634 Loss: 0.145429
2023-01-04 12:22: Train Epoch 6: 503/634 Loss: 0.171249
2023-01-04 12:22: Train Epoch 6: 507/634 Loss: 0.166038
2023-01-04 12:22: Train Epoch 6: 511/634 Loss: 0.171626
2023-01-04 12:22: Train Epoch 6: 515/634 Loss: 0.137190
2023-01-04 12:22: Train Epoch 6: 519/634 Loss: 0.158922
2023-01-04 12:22: Train Epoch 6: 523/634 Loss: 0.200618
2023-01-04 12:22: Train Epoch 6: 527/634 Loss: 0.177133
2023-01-04 12:22: Train Epoch 6: 531/634 Loss: 0.140841
2023-01-04 12:22: Train Epoch 6: 535/634 Loss: 0.164635
2023-01-04 12:22: Train Epoch 6: 539/634 Loss: 0.175194
2023-01-04 12:22: Train Epoch 6: 543/634 Loss: 0.180443
2023-01-04 12:22: Train Epoch 6: 547/634 Loss: 0.146488
2023-01-04 12:22: Train Epoch 6: 551/634 Loss: 0.147636
2023-01-04 12:22: Train Epoch 6: 555/634 Loss: 0.169740
2023-01-04 12:23: Train Epoch 6: 559/634 Loss: 0.195658
2023-01-04 12:23: Train Epoch 6: 563/634 Loss: 0.163218
2023-01-04 12:23: Train Epoch 6: 567/634 Loss: 0.179285
2023-01-04 12:23: Train Epoch 6: 571/634 Loss: 0.158341
2023-01-04 12:23: Train Epoch 6: 575/634 Loss: 0.141969
2023-01-04 12:23: Train Epoch 6: 579/634 Loss: 0.201608
2023-01-04 12:23: Train Epoch 6: 583/634 Loss: 0.137031
2023-01-04 12:23: Train Epoch 6: 587/634 Loss: 0.154622
2023-01-04 12:23: Train Epoch 6: 591/634 Loss: 0.142829
2023-01-04 12:23: Train Epoch 6: 595/634 Loss: 0.180214
2023-01-04 12:23: Train Epoch 6: 599/634 Loss: 0.241890
2023-01-04 12:23: Train Epoch 6: 603/634 Loss: 0.174284
2023-01-04 12:23: Train Epoch 6: 607/634 Loss: 0.197520
2023-01-04 12:23: Train Epoch 6: 611/634 Loss: 0.144261
2023-01-04 12:23: Train Epoch 6: 615/634 Loss: 0.185000
2023-01-04 12:23: Train Epoch 6: 619/634 Loss: 0.202005
2023-01-04 12:23: Train Epoch 6: 623/634 Loss: 0.170053
2023-01-04 12:23: Train Epoch 6: 627/634 Loss: 0.191915
2023-01-04 12:23: Train Epoch 6: 631/634 Loss: 0.193794
2023-01-04 12:23: Train Epoch 6: 633/634 Loss: 0.081623
2023-01-04 12:23: **********Train Epoch 6: averaged Loss: 0.175212 
2023-01-04 12:23: 
Epoch time elapsed: 346.49001121520996

2023-01-04 12:23: 
 metrics validation: {'precision': 0.737799043062201, 'recall': 0.5930769230769231, 'f1-score': 0.6575692963752665, 'support': 1300, 'AUC': 0.8337122781065089, 'AUCPR': 0.7485740174413301, 'TP': 771, 'FP': 274, 'TN': 2326, 'FN': 529} 

2023-01-04 12:23: **********Val Epoch 6: average Loss: 0.264329
2023-01-04 12:23: *********************************Current best model saved!
2023-01-04 12:24: 
 Testing metrics {'precision': 0.8017148981779206, 'recall': 0.6091205211726385, 'f1-score': 0.6922720962517352, 'support': 1228, 'AUC': 0.8724495750618042, 'AUCPR': 0.8090801112986218, 'TP': 748, 'FP': 185, 'TN': 2271, 'FN': 480} 

2023-01-04 12:24: 
 Testing metrics {'precision': 0.8951809904508106, 'recall': 0.9146811890174722, 'f1-score': 0.9048260381593715, 'support': 4407, 'AUC': 0.9698895418200586, 'AUCPR': 0.9425560270579549, 'TP': 4031, 'FP': 472, 'TN': 8342, 'FN': 376} 

2023-01-04 12:25: Train Epoch 7: 3/634 Loss: 0.186030
2023-01-04 12:25: Train Epoch 7: 7/634 Loss: 0.167101
2023-01-04 12:25: Train Epoch 7: 11/634 Loss: 0.162887
2023-01-04 12:25: Train Epoch 7: 15/634 Loss: 0.192553
2023-01-04 12:25: Train Epoch 7: 19/634 Loss: 0.187456
2023-01-04 12:25: Train Epoch 7: 23/634 Loss: 0.168849
2023-01-04 12:25: Train Epoch 7: 27/634 Loss: 0.182348
2023-01-04 12:25: Train Epoch 7: 31/634 Loss: 0.181996
2023-01-04 12:25: Train Epoch 7: 35/634 Loss: 0.160825
2023-01-04 12:25: Train Epoch 7: 39/634 Loss: 0.176332
2023-01-04 12:25: Train Epoch 7: 43/634 Loss: 0.193745
2023-01-04 12:25: Train Epoch 7: 47/634 Loss: 0.170889
2023-01-04 12:25: Train Epoch 7: 51/634 Loss: 0.213232
2023-01-04 12:25: Train Epoch 7: 55/634 Loss: 0.123823
2023-01-04 12:25: Train Epoch 7: 59/634 Loss: 0.231807
2023-01-04 12:25: Train Epoch 7: 63/634 Loss: 0.143058
2023-01-04 12:25: Train Epoch 7: 67/634 Loss: 0.144195
2023-01-04 12:25: Train Epoch 7: 71/634 Loss: 0.177689
2023-01-04 12:25: Train Epoch 7: 75/634 Loss: 0.194861
2023-01-04 12:25: Train Epoch 7: 79/634 Loss: 0.155368
2023-01-04 12:25: Train Epoch 7: 83/634 Loss: 0.182144
2023-01-04 12:25: Train Epoch 7: 87/634 Loss: 0.157565
2023-01-04 12:25: Train Epoch 7: 91/634 Loss: 0.164153
2023-01-04 12:25: Train Epoch 7: 95/634 Loss: 0.163709
2023-01-04 12:25: Train Epoch 7: 99/634 Loss: 0.130507
2023-01-04 12:25: Train Epoch 7: 103/634 Loss: 0.177089
2023-01-04 12:25: Train Epoch 7: 107/634 Loss: 0.147997
2023-01-04 12:25: Train Epoch 7: 111/634 Loss: 0.191164
2023-01-04 12:26: Train Epoch 7: 115/634 Loss: 0.154873
2023-01-04 12:26: Train Epoch 7: 119/634 Loss: 0.163705
2023-01-04 12:26: Train Epoch 7: 123/634 Loss: 0.176818
2023-01-04 12:26: Train Epoch 7: 127/634 Loss: 0.169551
2023-01-04 12:26: Train Epoch 7: 131/634 Loss: 0.202931
2023-01-04 12:26: Train Epoch 7: 135/634 Loss: 0.152107
2023-01-04 12:26: Train Epoch 7: 139/634 Loss: 0.135053
2023-01-04 12:26: Train Epoch 7: 143/634 Loss: 0.217401
2023-01-04 12:26: Train Epoch 7: 147/634 Loss: 0.162444
2023-01-04 12:26: Train Epoch 7: 151/634 Loss: 0.187940
2023-01-04 12:26: Train Epoch 7: 155/634 Loss: 0.137735
2023-01-04 12:26: Train Epoch 7: 159/634 Loss: 0.172601
2023-01-04 12:26: Train Epoch 7: 163/634 Loss: 0.174393
2023-01-04 12:26: Train Epoch 7: 167/634 Loss: 0.140114
2023-01-04 12:26: Train Epoch 7: 171/634 Loss: 0.146673
2023-01-04 12:26: Train Epoch 7: 175/634 Loss: 0.149601
2023-01-04 12:26: Train Epoch 7: 179/634 Loss: 0.124572
2023-01-04 12:26: Train Epoch 7: 183/634 Loss: 0.172174
2023-01-04 12:26: Train Epoch 7: 187/634 Loss: 0.198617
2023-01-04 12:26: Train Epoch 7: 191/634 Loss: 0.160999
2023-01-04 12:26: Train Epoch 7: 195/634 Loss: 0.159025
2023-01-04 12:26: Train Epoch 7: 199/634 Loss: 0.134089
2023-01-04 12:26: Train Epoch 7: 203/634 Loss: 0.155654
2023-01-04 12:26: Train Epoch 7: 207/634 Loss: 0.184398
2023-01-04 12:26: Train Epoch 7: 211/634 Loss: 0.175740
2023-01-04 12:26: Train Epoch 7: 215/634 Loss: 0.174727
2023-01-04 12:26: Train Epoch 7: 219/634 Loss: 0.198701
2023-01-04 12:27: Train Epoch 7: 223/634 Loss: 0.189127
2023-01-04 12:27: Train Epoch 7: 227/634 Loss: 0.135200
2023-01-04 12:27: Train Epoch 7: 231/634 Loss: 0.141360
2023-01-04 12:27: Train Epoch 7: 235/634 Loss: 0.142581
2023-01-04 12:27: Train Epoch 7: 239/634 Loss: 0.163491
2023-01-04 12:27: Train Epoch 7: 243/634 Loss: 0.203936
2023-01-04 12:27: Train Epoch 7: 247/634 Loss: 0.175565
2023-01-04 12:27: Train Epoch 7: 251/634 Loss: 0.186003
2023-01-04 12:27: Train Epoch 7: 255/634 Loss: 0.146534
2023-01-04 12:27: Train Epoch 7: 259/634 Loss: 0.129270
2023-01-04 12:27: Train Epoch 7: 263/634 Loss: 0.132375
2023-01-04 12:27: Train Epoch 7: 267/634 Loss: 0.151068
2023-01-04 12:27: Train Epoch 7: 271/634 Loss: 0.162522
2023-01-04 12:27: Train Epoch 7: 275/634 Loss: 0.143642
2023-01-04 12:27: Train Epoch 7: 279/634 Loss: 0.182117
2023-01-04 12:27: Train Epoch 7: 283/634 Loss: 0.167745
2023-01-04 12:27: Train Epoch 7: 287/634 Loss: 0.163879
2023-01-04 12:27: Train Epoch 7: 291/634 Loss: 0.180706
2023-01-04 12:27: Train Epoch 7: 295/634 Loss: 0.166527
2023-01-04 12:27: Train Epoch 7: 299/634 Loss: 0.160730
2023-01-04 12:27: Train Epoch 7: 303/634 Loss: 0.186683
2023-01-04 12:27: Train Epoch 7: 307/634 Loss: 0.137223
2023-01-04 12:27: Train Epoch 7: 311/634 Loss: 0.168664
2023-01-04 12:27: Train Epoch 7: 315/634 Loss: 0.159452
2023-01-04 12:27: Train Epoch 7: 319/634 Loss: 0.160292
2023-01-04 12:27: Train Epoch 7: 323/634 Loss: 0.159537
2023-01-04 12:27: Train Epoch 7: 327/634 Loss: 0.173920
2023-01-04 12:27: Train Epoch 7: 331/634 Loss: 0.148587
2023-01-04 12:28: Train Epoch 7: 335/634 Loss: 0.190014
2023-01-04 12:28: Train Epoch 7: 339/634 Loss: 0.179255
2023-01-04 12:28: Train Epoch 7: 343/634 Loss: 0.173102
2023-01-04 12:28: Train Epoch 7: 347/634 Loss: 0.183215
2023-01-04 12:28: Train Epoch 7: 351/634 Loss: 0.129109
2023-01-04 12:28: Train Epoch 7: 355/634 Loss: 0.129414
2023-01-04 12:28: Train Epoch 7: 359/634 Loss: 0.143632
2023-01-04 12:28: Train Epoch 7: 363/634 Loss: 0.146665
2023-01-04 12:28: Train Epoch 7: 367/634 Loss: 0.159766
2023-01-04 12:28: Train Epoch 7: 371/634 Loss: 0.177742
2023-01-04 12:28: Train Epoch 7: 375/634 Loss: 0.131143
2023-01-04 12:28: Train Epoch 7: 379/634 Loss: 0.184533
2023-01-04 12:28: Train Epoch 7: 383/634 Loss: 0.186037
2023-01-04 12:28: Train Epoch 7: 387/634 Loss: 0.166789
2023-01-04 12:28: Train Epoch 7: 391/634 Loss: 0.147551
2023-01-04 12:28: Train Epoch 7: 395/634 Loss: 0.160111
2023-01-04 12:28: Train Epoch 7: 399/634 Loss: 0.157266
2023-01-04 12:28: Train Epoch 7: 403/634 Loss: 0.190301
2023-01-04 12:28: Train Epoch 7: 407/634 Loss: 0.150457
2023-01-04 12:28: Train Epoch 7: 411/634 Loss: 0.206808
2023-01-04 12:28: Train Epoch 7: 415/634 Loss: 0.165961
2023-01-04 12:28: Train Epoch 7: 419/634 Loss: 0.188238
2023-01-04 12:28: Train Epoch 7: 423/634 Loss: 0.189222
2023-01-04 12:28: Train Epoch 7: 427/634 Loss: 0.150410
2023-01-04 12:28: Train Epoch 7: 431/634 Loss: 0.166467
2023-01-04 12:28: Train Epoch 7: 435/634 Loss: 0.181875
2023-01-04 12:28: Train Epoch 7: 439/634 Loss: 0.154522
2023-01-04 12:29: Train Epoch 7: 443/634 Loss: 0.156698
2023-01-04 12:29: Train Epoch 7: 447/634 Loss: 0.142600
2023-01-04 12:29: Train Epoch 7: 451/634 Loss: 0.176987
2023-01-04 12:29: Train Epoch 7: 455/634 Loss: 0.154762
2023-01-04 12:29: Train Epoch 7: 459/634 Loss: 0.134062
2023-01-04 12:29: Train Epoch 7: 463/634 Loss: 0.199390
2023-01-04 12:29: Train Epoch 7: 467/634 Loss: 0.212905
2023-01-04 12:29: Train Epoch 7: 471/634 Loss: 0.209754
2023-01-04 12:29: Train Epoch 7: 475/634 Loss: 0.170771
2023-01-04 12:29: Train Epoch 7: 479/634 Loss: 0.187378
2023-01-04 12:29: Train Epoch 7: 483/634 Loss: 0.194167
2023-01-04 12:29: Train Epoch 7: 487/634 Loss: 0.162557
2023-01-04 12:29: Train Epoch 7: 491/634 Loss: 0.167800
2023-01-04 12:29: Train Epoch 7: 495/634 Loss: 0.135495
2023-01-04 12:29: Train Epoch 7: 499/634 Loss: 0.126648
2023-01-04 12:29: Train Epoch 7: 503/634 Loss: 0.210266
2023-01-04 12:29: Train Epoch 7: 507/634 Loss: 0.170113
2023-01-04 12:29: Train Epoch 7: 511/634 Loss: 0.176676
2023-01-04 12:29: Train Epoch 7: 515/634 Loss: 0.187891
2023-01-04 12:29: Train Epoch 7: 519/634 Loss: 0.149569
2023-01-04 12:29: Train Epoch 7: 523/634 Loss: 0.137829
2023-01-04 12:29: Train Epoch 7: 527/634 Loss: 0.195614
2023-01-04 12:29: Train Epoch 7: 531/634 Loss: 0.161948
2023-01-04 12:29: Train Epoch 7: 535/634 Loss: 0.160333
2023-01-04 12:29: Train Epoch 7: 539/634 Loss: 0.117169
2023-01-04 12:29: Train Epoch 7: 543/634 Loss: 0.194508
2023-01-04 12:29: Train Epoch 7: 547/634 Loss: 0.170484
2023-01-04 12:29: Train Epoch 7: 551/634 Loss: 0.155509
2023-01-04 12:30: Train Epoch 7: 555/634 Loss: 0.124034
2023-01-04 12:30: Train Epoch 7: 559/634 Loss: 0.141808
2023-01-04 12:30: Train Epoch 7: 563/634 Loss: 0.165364
2023-01-04 12:30: Train Epoch 7: 567/634 Loss: 0.153294
2023-01-04 12:30: Train Epoch 7: 571/634 Loss: 0.164914
2023-01-04 12:30: Train Epoch 7: 575/634 Loss: 0.175731
2023-01-04 12:30: Train Epoch 7: 579/634 Loss: 0.185999
2023-01-04 12:30: Train Epoch 7: 583/634 Loss: 0.196581
2023-01-04 12:30: Train Epoch 7: 587/634 Loss: 0.160189
2023-01-04 12:30: Train Epoch 7: 591/634 Loss: 0.150262
2023-01-04 12:30: Train Epoch 7: 595/634 Loss: 0.159484
2023-01-04 12:30: Train Epoch 7: 599/634 Loss: 0.183120
2023-01-04 12:30: Train Epoch 7: 603/634 Loss: 0.149551
2023-01-04 12:30: Train Epoch 7: 607/634 Loss: 0.170473
2023-01-04 12:30: Train Epoch 7: 611/634 Loss: 0.152906
2023-01-04 12:30: Train Epoch 7: 615/634 Loss: 0.148668
2023-01-04 12:30: Train Epoch 7: 619/634 Loss: 0.197827
2023-01-04 12:30: Train Epoch 7: 623/634 Loss: 0.182811
2023-01-04 12:30: Train Epoch 7: 627/634 Loss: 0.127081
2023-01-04 12:30: Train Epoch 7: 631/634 Loss: 0.143418
2023-01-04 12:30: Train Epoch 7: 633/634 Loss: 0.055454
2023-01-04 12:30: **********Train Epoch 7: averaged Loss: 0.165592 
2023-01-04 12:30: 
Epoch time elapsed: 345.5110466480255

2023-01-04 12:30: 
 metrics validation: {'precision': 0.7210708117443869, 'recall': 0.6423076923076924, 'f1-score': 0.6794141578519123, 'support': 1300, 'AUC': 0.8440593195266272, 'AUCPR': 0.7653546807878097, 'TP': 835, 'FP': 323, 'TN': 2277, 'FN': 465} 

2023-01-04 12:30: **********Val Epoch 7: average Loss: 0.253477
2023-01-04 12:30: *********************************Current best model saved!
2023-01-04 12:31: 
 Testing metrics {'precision': 0.7996219281663516, 'recall': 0.6889250814332247, 'f1-score': 0.7401574803149606, 'support': 1228, 'AUC': 0.8780169418243166, 'AUCPR': 0.8189319100296575, 'TP': 846, 'FP': 212, 'TN': 2244, 'FN': 382} 

2023-01-04 12:31: 
 Testing metrics {'precision': 0.8804442508710801, 'recall': 0.9174041297935103, 'f1-score': 0.8985442826980775, 'support': 4407, 'AUC': 0.9733193612962523, 'AUCPR': 0.9521882417572206, 'TP': 4043, 'FP': 549, 'TN': 8265, 'FN': 364} 

2023-01-04 12:32: Train Epoch 8: 3/634 Loss: 0.152989
2023-01-04 12:32: Train Epoch 8: 7/634 Loss: 0.147489
2023-01-04 12:32: Train Epoch 8: 11/634 Loss: 0.158851
2023-01-04 12:32: Train Epoch 8: 15/634 Loss: 0.191071
2023-01-04 12:32: Train Epoch 8: 19/634 Loss: 0.219442
2023-01-04 12:32: Train Epoch 8: 23/634 Loss: 0.146322
2023-01-04 12:32: Train Epoch 8: 27/634 Loss: 0.151453
2023-01-04 12:32: Train Epoch 8: 31/634 Loss: 0.143914
2023-01-04 12:32: Train Epoch 8: 35/634 Loss: 0.120563
2023-01-04 12:32: Train Epoch 8: 39/634 Loss: 0.147531
2023-01-04 12:32: Train Epoch 8: 43/634 Loss: 0.177456
2023-01-04 12:32: Train Epoch 8: 47/634 Loss: 0.183933
2023-01-04 12:32: Train Epoch 8: 51/634 Loss: 0.127556
2023-01-04 12:32: Train Epoch 8: 55/634 Loss: 0.153286
2023-01-04 12:32: Train Epoch 8: 59/634 Loss: 0.181624
2023-01-04 12:32: Train Epoch 8: 63/634 Loss: 0.201966
2023-01-04 12:32: Train Epoch 8: 67/634 Loss: 0.198280
2023-01-04 12:32: Train Epoch 8: 71/634 Loss: 0.161344
2023-01-04 12:32: Train Epoch 8: 75/634 Loss: 0.163139
2023-01-04 12:32: Train Epoch 8: 79/634 Loss: 0.147846
2023-01-04 12:32: Train Epoch 8: 83/634 Loss: 0.137109
2023-01-04 12:32: Train Epoch 8: 87/634 Loss: 0.141595
2023-01-04 12:32: Train Epoch 8: 91/634 Loss: 0.153900
2023-01-04 12:32: Train Epoch 8: 95/634 Loss: 0.170930
2023-01-04 12:32: Train Epoch 8: 99/634 Loss: 0.172396
2023-01-04 12:32: Train Epoch 8: 103/634 Loss: 0.142235
2023-01-04 12:32: Train Epoch 8: 107/634 Loss: 0.166097
2023-01-04 12:33: Train Epoch 8: 111/634 Loss: 0.164400
2023-01-04 12:33: Train Epoch 8: 115/634 Loss: 0.194253
2023-01-04 12:33: Train Epoch 8: 119/634 Loss: 0.179084
2023-01-04 12:33: Train Epoch 8: 123/634 Loss: 0.151288
2023-01-04 12:33: Train Epoch 8: 127/634 Loss: 0.145246
2023-01-04 12:33: Train Epoch 8: 131/634 Loss: 0.162059
2023-01-04 12:33: Train Epoch 8: 135/634 Loss: 0.178407
2023-01-04 12:33: Train Epoch 8: 139/634 Loss: 0.136429
2023-01-04 12:33: Train Epoch 8: 143/634 Loss: 0.134637
2023-01-04 12:33: Train Epoch 8: 147/634 Loss: 0.149759
2023-01-04 12:33: Train Epoch 8: 151/634 Loss: 0.200571
2023-01-04 12:33: Train Epoch 8: 155/634 Loss: 0.133021
2023-01-04 12:33: Train Epoch 8: 159/634 Loss: 0.139913
2023-01-04 12:33: Train Epoch 8: 163/634 Loss: 0.139005
2023-01-04 12:33: Train Epoch 8: 167/634 Loss: 0.187267
2023-01-04 12:33: Train Epoch 8: 171/634 Loss: 0.169392
2023-01-04 12:33: Train Epoch 8: 175/634 Loss: 0.181791
2023-01-04 12:33: Train Epoch 8: 179/634 Loss: 0.177050
2023-01-04 12:33: Train Epoch 8: 183/634 Loss: 0.216719
2023-01-04 12:33: Train Epoch 8: 187/634 Loss: 0.146402
2023-01-04 12:33: Train Epoch 8: 191/634 Loss: 0.136151
2023-01-04 12:33: Train Epoch 8: 195/634 Loss: 0.161618
2023-01-04 12:33: Train Epoch 8: 199/634 Loss: 0.145733
2023-01-04 12:33: Train Epoch 8: 203/634 Loss: 0.160382
2023-01-04 12:33: Train Epoch 8: 207/634 Loss: 0.172527
2023-01-04 12:33: Train Epoch 8: 211/634 Loss: 0.108240
2023-01-04 12:33: Train Epoch 8: 215/634 Loss: 0.159260
2023-01-04 12:34: Train Epoch 8: 219/634 Loss: 0.137890
2023-01-04 12:34: Train Epoch 8: 223/634 Loss: 0.155862
2023-01-04 12:34: Train Epoch 8: 227/634 Loss: 0.125822
2023-01-04 12:34: Train Epoch 8: 231/634 Loss: 0.137475
2023-01-04 12:34: Train Epoch 8: 235/634 Loss: 0.178940
2023-01-04 12:34: Train Epoch 8: 239/634 Loss: 0.217427
2023-01-04 12:34: Train Epoch 8: 243/634 Loss: 0.187304
2023-01-04 12:34: Train Epoch 8: 247/634 Loss: 0.164745
2023-01-04 12:34: Train Epoch 8: 251/634 Loss: 0.160768
2023-01-04 12:34: Train Epoch 8: 255/634 Loss: 0.135090
2023-01-04 12:34: Train Epoch 8: 259/634 Loss: 0.149966
2023-01-04 12:34: Train Epoch 8: 263/634 Loss: 0.173156
2023-01-04 12:34: Train Epoch 8: 267/634 Loss: 0.171307
2023-01-04 12:34: Train Epoch 8: 271/634 Loss: 0.141069
2023-01-04 12:34: Train Epoch 8: 275/634 Loss: 0.142823
2023-01-04 12:34: Train Epoch 8: 279/634 Loss: 0.158523
2023-01-04 12:34: Train Epoch 8: 283/634 Loss: 0.137074
2023-01-04 12:34: Train Epoch 8: 287/634 Loss: 0.114063
2023-01-04 12:34: Train Epoch 8: 291/634 Loss: 0.148290
2023-01-04 12:34: Train Epoch 8: 295/634 Loss: 0.171459
2023-01-04 12:34: Train Epoch 8: 299/634 Loss: 0.150643
2023-01-04 12:34: Train Epoch 8: 303/634 Loss: 0.135130
2023-01-04 12:34: Train Epoch 8: 307/634 Loss: 0.186849
2023-01-04 12:34: Train Epoch 8: 311/634 Loss: 0.129865
2023-01-04 12:34: Train Epoch 8: 315/634 Loss: 0.148653
2023-01-04 12:34: Train Epoch 8: 319/634 Loss: 0.162166
2023-01-04 12:34: Train Epoch 8: 323/634 Loss: 0.143364
2023-01-04 12:34: Train Epoch 8: 327/634 Loss: 0.159890
2023-01-04 12:35: Train Epoch 8: 331/634 Loss: 0.157591
2023-01-04 12:35: Train Epoch 8: 335/634 Loss: 0.160585
2023-01-04 12:35: Train Epoch 8: 339/634 Loss: 0.136716
2023-01-04 12:35: Train Epoch 8: 343/634 Loss: 0.165429
2023-01-04 12:35: Train Epoch 8: 347/634 Loss: 0.140067
2023-01-04 12:35: Train Epoch 8: 351/634 Loss: 0.133976
2023-01-04 12:35: Train Epoch 8: 355/634 Loss: 0.180953
2023-01-04 12:35: Train Epoch 8: 359/634 Loss: 0.146435
2023-01-04 12:35: Train Epoch 8: 363/634 Loss: 0.163566
2023-01-04 12:35: Train Epoch 8: 367/634 Loss: 0.154592
2023-01-04 12:35: Train Epoch 8: 371/634 Loss: 0.146002
2023-01-04 12:35: Train Epoch 8: 375/634 Loss: 0.165694
2023-01-04 12:35: Train Epoch 8: 379/634 Loss: 0.127902
2023-01-04 12:35: Train Epoch 8: 383/634 Loss: 0.134156
2023-01-04 12:35: Train Epoch 8: 387/634 Loss: 0.145142
2023-01-04 12:35: Train Epoch 8: 391/634 Loss: 0.191086
2023-01-04 12:35: Train Epoch 8: 395/634 Loss: 0.158788
2023-01-04 12:35: Train Epoch 8: 399/634 Loss: 0.153483
2023-01-04 12:35: Train Epoch 8: 403/634 Loss: 0.161326
2023-01-04 12:35: Train Epoch 8: 407/634 Loss: 0.158525
2023-01-04 12:35: Train Epoch 8: 411/634 Loss: 0.135252
2023-01-04 12:35: Train Epoch 8: 415/634 Loss: 0.152958
2023-01-04 12:35: Train Epoch 8: 419/634 Loss: 0.133496
2023-01-04 12:35: Train Epoch 8: 423/634 Loss: 0.149387
2023-01-04 12:35: Train Epoch 8: 427/634 Loss: 0.142970
2023-01-04 12:35: Train Epoch 8: 431/634 Loss: 0.138773
2023-01-04 12:35: Train Epoch 8: 435/634 Loss: 0.183987
2023-01-04 12:35: Train Epoch 8: 439/634 Loss: 0.119644
2023-01-04 12:36: Train Epoch 8: 443/634 Loss: 0.145197
2023-01-04 12:36: Train Epoch 8: 447/634 Loss: 0.150205
2023-01-04 12:36: Train Epoch 8: 451/634 Loss: 0.124639
2023-01-04 12:36: Train Epoch 8: 455/634 Loss: 0.158228
2023-01-04 12:36: Train Epoch 8: 459/634 Loss: 0.137343
2023-01-04 12:36: Train Epoch 8: 463/634 Loss: 0.129761
2023-01-04 12:36: Train Epoch 8: 467/634 Loss: 0.150780
2023-01-04 12:36: Train Epoch 8: 471/634 Loss: 0.152077
2023-01-04 12:36: Train Epoch 8: 475/634 Loss: 0.119080
2023-01-04 12:36: Train Epoch 8: 479/634 Loss: 0.177419
2023-01-04 12:36: Train Epoch 8: 483/634 Loss: 0.141293
2023-01-04 12:36: Train Epoch 8: 487/634 Loss: 0.199928
2023-01-04 12:36: Train Epoch 8: 491/634 Loss: 0.182282
2023-01-04 12:36: Train Epoch 8: 495/634 Loss: 0.180270
2023-01-04 12:36: Train Epoch 8: 499/634 Loss: 0.144994
2023-01-04 12:36: Train Epoch 8: 503/634 Loss: 0.147051
2023-01-04 12:36: Train Epoch 8: 507/634 Loss: 0.168581
2023-01-04 12:36: Train Epoch 8: 511/634 Loss: 0.124190
2023-01-04 12:36: Train Epoch 8: 515/634 Loss: 0.138769
2023-01-04 12:36: Train Epoch 8: 519/634 Loss: 0.181728
2023-01-04 12:36: Train Epoch 8: 523/634 Loss: 0.169941
2023-01-04 12:36: Train Epoch 8: 527/634 Loss: 0.143307
2023-01-04 12:36: Train Epoch 8: 531/634 Loss: 0.195136
2023-01-04 12:36: Train Epoch 8: 535/634 Loss: 0.151386
2023-01-04 12:36: Train Epoch 8: 539/634 Loss: 0.166825
2023-01-04 12:36: Train Epoch 8: 543/634 Loss: 0.149565
2023-01-04 12:36: Train Epoch 8: 547/634 Loss: 0.147625
2023-01-04 12:37: Train Epoch 8: 551/634 Loss: 0.228697
2023-01-04 12:37: Train Epoch 8: 555/634 Loss: 0.195511
2023-01-04 12:37: Train Epoch 8: 559/634 Loss: 0.166296
2023-01-04 12:37: Train Epoch 8: 563/634 Loss: 0.122176
2023-01-04 12:37: Train Epoch 8: 567/634 Loss: 0.162156
2023-01-04 12:37: Train Epoch 8: 571/634 Loss: 0.166494
2023-01-04 12:37: Train Epoch 8: 575/634 Loss: 0.124610
2023-01-04 12:37: Train Epoch 8: 579/634 Loss: 0.189887
2023-01-04 12:37: Train Epoch 8: 583/634 Loss: 0.138218
2023-01-04 12:37: Train Epoch 8: 587/634 Loss: 0.131662
2023-01-04 12:37: Train Epoch 8: 591/634 Loss: 0.152699
2023-01-04 12:37: Train Epoch 8: 595/634 Loss: 0.170042
2023-01-04 12:37: Train Epoch 8: 599/634 Loss: 0.129180
2023-01-04 12:37: Train Epoch 8: 603/634 Loss: 0.130627
2023-01-04 12:37: Train Epoch 8: 607/634 Loss: 0.141321
2023-01-04 12:37: Train Epoch 8: 611/634 Loss: 0.141450
2023-01-04 12:37: Train Epoch 8: 615/634 Loss: 0.157293
2023-01-04 12:37: Train Epoch 8: 619/634 Loss: 0.107249
2023-01-04 12:37: Train Epoch 8: 623/634 Loss: 0.160113
2023-01-04 12:37: Train Epoch 8: 627/634 Loss: 0.159640
2023-01-04 12:37: Train Epoch 8: 631/634 Loss: 0.150444
2023-01-04 12:37: Train Epoch 8: 633/634 Loss: 0.063326
2023-01-04 12:37: **********Train Epoch 8: averaged Loss: 0.155482 
2023-01-04 12:37: 
Epoch time elapsed: 345.32502698898315

2023-01-04 12:37: 
 metrics validation: {'precision': 0.7415215398716773, 'recall': 0.6223076923076923, 'f1-score': 0.6767043078209954, 'support': 1300, 'AUC': 0.8533426035502959, 'AUCPR': 0.7755501525618824, 'TP': 809, 'FP': 282, 'TN': 2318, 'FN': 491} 

2023-01-04 12:37: **********Val Epoch 8: average Loss: 0.250286
2023-01-04 12:37: *********************************Current best model saved!
2023-01-04 12:38: 
 Testing metrics {'precision': 0.8148148148148148, 'recall': 0.6628664495114006, 'f1-score': 0.7310282891782667, 'support': 1228, 'AUC': 0.8866712113656378, 'AUCPR': 0.8298837722560698, 'TP': 814, 'FP': 185, 'TN': 2271, 'FN': 414} 

2023-01-04 12:39: 
 Testing metrics {'precision': 0.8968430413517119, 'recall': 0.9153619242114818, 'f1-score': 0.9060078607523864, 'support': 4407, 'AUC': 0.9760264434806746, 'AUCPR': 0.9581479535273069, 'TP': 4034, 'FP': 464, 'TN': 8350, 'FN': 373} 

2023-01-04 12:39: Train Epoch 9: 3/634 Loss: 0.134125
2023-01-04 12:39: Train Epoch 9: 7/634 Loss: 0.115828
2023-01-04 12:39: Train Epoch 9: 11/634 Loss: 0.185135
2023-01-04 12:39: Train Epoch 9: 15/634 Loss: 0.161432
2023-01-04 12:39: Train Epoch 9: 19/634 Loss: 0.181047
2023-01-04 12:39: Train Epoch 9: 23/634 Loss: 0.144629
2023-01-04 12:39: Train Epoch 9: 27/634 Loss: 0.142893
2023-01-04 12:39: Train Epoch 9: 31/634 Loss: 0.146768
2023-01-04 12:39: Train Epoch 9: 35/634 Loss: 0.170283
2023-01-04 12:39: Train Epoch 9: 39/634 Loss: 0.126948
2023-01-04 12:39: Train Epoch 9: 43/634 Loss: 0.119435
2023-01-04 12:39: Train Epoch 9: 47/634 Loss: 0.132141
2023-01-04 12:39: Train Epoch 9: 51/634 Loss: 0.107179
2023-01-04 12:39: Train Epoch 9: 55/634 Loss: 0.118946
2023-01-04 12:39: Train Epoch 9: 59/634 Loss: 0.176691
2023-01-04 12:39: Train Epoch 9: 63/634 Loss: 0.149092
2023-01-04 12:39: Train Epoch 9: 67/634 Loss: 0.164038
2023-01-04 12:39: Train Epoch 9: 71/634 Loss: 0.142686
2023-01-04 12:39: Train Epoch 9: 75/634 Loss: 0.103351
2023-01-04 12:39: Train Epoch 9: 79/634 Loss: 0.152267
2023-01-04 12:39: Train Epoch 9: 83/634 Loss: 0.146962
2023-01-04 12:39: Train Epoch 9: 87/634 Loss: 0.127665
2023-01-04 12:39: Train Epoch 9: 91/634 Loss: 0.172616
2023-01-04 12:39: Train Epoch 9: 95/634 Loss: 0.156227
2023-01-04 12:39: Train Epoch 9: 99/634 Loss: 0.190304
2023-01-04 12:39: Train Epoch 9: 103/634 Loss: 0.154071
2023-01-04 12:39: Train Epoch 9: 107/634 Loss: 0.129505
2023-01-04 12:40: Train Epoch 9: 111/634 Loss: 0.117667
2023-01-04 12:40: Train Epoch 9: 115/634 Loss: 0.156973
2023-01-04 12:40: Train Epoch 9: 119/634 Loss: 0.160481
2023-01-04 12:40: Train Epoch 9: 123/634 Loss: 0.145953
2023-01-04 12:40: Train Epoch 9: 127/634 Loss: 0.125075
2023-01-04 12:40: Train Epoch 9: 131/634 Loss: 0.153482
2023-01-04 12:40: Train Epoch 9: 135/634 Loss: 0.169119
2023-01-04 12:40: Train Epoch 9: 139/634 Loss: 0.142718
2023-01-04 12:40: Train Epoch 9: 143/634 Loss: 0.129281
2023-01-04 12:40: Train Epoch 9: 147/634 Loss: 0.144490
2023-01-04 12:40: Train Epoch 9: 151/634 Loss: 0.170211
2023-01-04 12:40: Train Epoch 9: 155/634 Loss: 0.164396
2023-01-04 12:40: Train Epoch 9: 159/634 Loss: 0.137130
2023-01-04 12:40: Train Epoch 9: 163/634 Loss: 0.156244
2023-01-04 12:40: Train Epoch 9: 167/634 Loss: 0.152590
2023-01-04 12:40: Train Epoch 9: 171/634 Loss: 0.196871
2023-01-04 12:40: Train Epoch 9: 175/634 Loss: 0.131364
2023-01-04 12:40: Train Epoch 9: 179/634 Loss: 0.148204
2023-01-04 12:40: Train Epoch 9: 183/634 Loss: 0.145814
2023-01-04 12:40: Train Epoch 9: 187/634 Loss: 0.141059
2023-01-04 12:40: Train Epoch 9: 191/634 Loss: 0.139646
2023-01-04 12:40: Train Epoch 9: 195/634 Loss: 0.157116
2023-01-04 12:40: Train Epoch 9: 199/634 Loss: 0.142352
2023-01-04 12:40: Train Epoch 9: 203/634 Loss: 0.132658
2023-01-04 12:40: Train Epoch 9: 207/634 Loss: 0.142144
2023-01-04 12:40: Train Epoch 9: 211/634 Loss: 0.127985
2023-01-04 12:40: Train Epoch 9: 215/634 Loss: 0.159148
2023-01-04 12:41: Train Epoch 9: 219/634 Loss: 0.182268
2023-01-04 12:41: Train Epoch 9: 223/634 Loss: 0.138019
2023-01-04 12:41: Train Epoch 9: 227/634 Loss: 0.115999
2023-01-04 12:41: Train Epoch 9: 231/634 Loss: 0.149893
2023-01-04 12:41: Train Epoch 9: 235/634 Loss: 0.187613
2023-01-04 12:41: Train Epoch 9: 239/634 Loss: 0.201976
2023-01-04 12:41: Train Epoch 9: 243/634 Loss: 0.143038
2023-01-04 12:41: Train Epoch 9: 247/634 Loss: 0.151279
2023-01-04 12:41: Train Epoch 9: 251/634 Loss: 0.153633
2023-01-04 12:41: Train Epoch 9: 255/634 Loss: 0.158085
2023-01-04 12:41: Train Epoch 9: 259/634 Loss: 0.165163
2023-01-04 12:41: Train Epoch 9: 263/634 Loss: 0.151007
2023-01-04 12:41: Train Epoch 9: 267/634 Loss: 0.152218
2023-01-04 12:41: Train Epoch 9: 271/634 Loss: 0.129087
2023-01-04 12:41: Train Epoch 9: 275/634 Loss: 0.160649
2023-01-04 12:41: Train Epoch 9: 279/634 Loss: 0.140763
2023-01-04 12:41: Train Epoch 9: 283/634 Loss: 0.135402
2023-01-04 12:41: Train Epoch 9: 287/634 Loss: 0.151245
2023-01-04 12:41: Train Epoch 9: 291/634 Loss: 0.172859
2023-01-04 12:41: Train Epoch 9: 295/634 Loss: 0.123842
2023-01-04 12:41: Train Epoch 9: 299/634 Loss: 0.150906
2023-01-04 12:41: Train Epoch 9: 303/634 Loss: 0.141055
2023-01-04 12:41: Train Epoch 9: 307/634 Loss: 0.172565
2023-01-04 12:41: Train Epoch 9: 311/634 Loss: 0.122450
2023-01-04 12:41: Train Epoch 9: 315/634 Loss: 0.142874
2023-01-04 12:41: Train Epoch 9: 319/634 Loss: 0.132705
2023-01-04 12:41: Train Epoch 9: 323/634 Loss: 0.157988
2023-01-04 12:41: Train Epoch 9: 327/634 Loss: 0.216295
2023-01-04 12:42: Train Epoch 9: 331/634 Loss: 0.177300
2023-01-04 12:42: Train Epoch 9: 335/634 Loss: 0.155304
2023-01-04 12:42: Train Epoch 9: 339/634 Loss: 0.152470
2023-01-04 12:42: Train Epoch 9: 343/634 Loss: 0.188265
2023-01-04 12:42: Train Epoch 9: 347/634 Loss: 0.195965
2023-01-04 12:42: Train Epoch 9: 351/634 Loss: 0.169940
2023-01-04 12:42: Train Epoch 9: 355/634 Loss: 0.147406
2023-01-04 12:42: Train Epoch 9: 359/634 Loss: 0.134525
2023-01-04 12:42: Train Epoch 9: 363/634 Loss: 0.147465
2023-01-04 12:42: Train Epoch 9: 367/634 Loss: 0.151110
2023-01-04 12:42: Train Epoch 9: 371/634 Loss: 0.152950
2023-01-04 12:42: Train Epoch 9: 375/634 Loss: 0.126182
2023-01-04 12:42: Train Epoch 9: 379/634 Loss: 0.147340
2023-01-04 12:42: Train Epoch 9: 383/634 Loss: 0.149019
2023-01-04 12:42: Train Epoch 9: 387/634 Loss: 0.133338
2023-01-04 12:42: Train Epoch 9: 391/634 Loss: 0.137636
2023-01-04 12:42: Train Epoch 9: 395/634 Loss: 0.135585
2023-01-04 12:42: Train Epoch 9: 399/634 Loss: 0.143872
2023-01-04 12:42: Train Epoch 9: 403/634 Loss: 0.134311
2023-01-04 12:42: Train Epoch 9: 407/634 Loss: 0.193194
2023-01-04 12:42: Train Epoch 9: 411/634 Loss: 0.157517
2023-01-04 12:42: Train Epoch 9: 415/634 Loss: 0.135996
2023-01-04 12:42: Train Epoch 9: 419/634 Loss: 0.160415
2023-01-04 12:42: Train Epoch 9: 423/634 Loss: 0.156202
2023-01-04 12:42: Train Epoch 9: 427/634 Loss: 0.172899
2023-01-04 12:42: Train Epoch 9: 431/634 Loss: 0.180337
2023-01-04 12:42: Train Epoch 9: 435/634 Loss: 0.165847
2023-01-04 12:42: Train Epoch 9: 439/634 Loss: 0.152970
2023-01-04 12:43: Train Epoch 9: 443/634 Loss: 0.124450
2023-01-04 12:43: Train Epoch 9: 447/634 Loss: 0.130416
2023-01-04 12:43: Train Epoch 9: 451/634 Loss: 0.118683
2023-01-04 12:43: Train Epoch 9: 455/634 Loss: 0.197927
2023-01-04 12:43: Train Epoch 9: 459/634 Loss: 0.133348
2023-01-04 12:43: Train Epoch 9: 463/634 Loss: 0.135727
2023-01-04 12:43: Train Epoch 9: 467/634 Loss: 0.141488
2023-01-04 12:43: Train Epoch 9: 471/634 Loss: 0.122752
2023-01-04 12:43: Train Epoch 9: 475/634 Loss: 0.170806
2023-01-04 12:43: Train Epoch 9: 479/634 Loss: 0.135374
2023-01-04 12:43: Train Epoch 9: 483/634 Loss: 0.128795
2023-01-04 12:43: Train Epoch 9: 487/634 Loss: 0.136292
2023-01-04 12:43: Train Epoch 9: 491/634 Loss: 0.143798
2023-01-04 12:43: Train Epoch 9: 495/634 Loss: 0.182054
2023-01-04 12:43: Train Epoch 9: 499/634 Loss: 0.160655
2023-01-04 12:43: Train Epoch 9: 503/634 Loss: 0.124484
2023-01-04 12:43: Train Epoch 9: 507/634 Loss: 0.157279
2023-01-04 12:43: Train Epoch 9: 511/634 Loss: 0.189687
2023-01-04 12:43: Train Epoch 9: 515/634 Loss: 0.153061
2023-01-04 12:43: Train Epoch 9: 519/634 Loss: 0.153987
2023-01-04 12:43: Train Epoch 9: 523/634 Loss: 0.122944
2023-01-04 12:43: Train Epoch 9: 527/634 Loss: 0.138387
2023-01-04 12:43: Train Epoch 9: 531/634 Loss: 0.153897
2023-01-04 12:43: Train Epoch 9: 535/634 Loss: 0.130179
2023-01-04 12:43: Train Epoch 9: 539/634 Loss: 0.126960
2023-01-04 12:43: Train Epoch 9: 543/634 Loss: 0.135923
2023-01-04 12:43: Train Epoch 9: 547/634 Loss: 0.153592
2023-01-04 12:44: Train Epoch 9: 551/634 Loss: 0.164676
2023-01-04 12:44: Train Epoch 9: 555/634 Loss: 0.145700
2023-01-04 12:44: Train Epoch 9: 559/634 Loss: 0.158038
2023-01-04 12:44: Train Epoch 9: 563/634 Loss: 0.175523
2023-01-04 12:44: Train Epoch 9: 567/634 Loss: 0.171408
2023-01-04 12:44: Train Epoch 9: 571/634 Loss: 0.155116
2023-01-04 12:44: Train Epoch 9: 575/634 Loss: 0.122195
2023-01-04 12:44: Train Epoch 9: 579/634 Loss: 0.139332
2023-01-04 12:44: Train Epoch 9: 583/634 Loss: 0.139897
2023-01-04 12:44: Train Epoch 9: 587/634 Loss: 0.163680
2023-01-04 12:44: Train Epoch 9: 591/634 Loss: 0.152084
2023-01-04 12:44: Train Epoch 9: 595/634 Loss: 0.156720
2023-01-04 12:44: Train Epoch 9: 599/634 Loss: 0.153694
2023-01-04 12:44: Train Epoch 9: 603/634 Loss: 0.157650
2023-01-04 12:44: Train Epoch 9: 607/634 Loss: 0.156308
2023-01-04 12:44: Train Epoch 9: 611/634 Loss: 0.140617
2023-01-04 12:44: Train Epoch 9: 615/634 Loss: 0.141441
2023-01-04 12:44: Train Epoch 9: 619/634 Loss: 0.141911
2023-01-04 12:44: Train Epoch 9: 623/634 Loss: 0.175933
2023-01-04 12:44: Train Epoch 9: 627/634 Loss: 0.142108
2023-01-04 12:44: Train Epoch 9: 631/634 Loss: 0.142760
2023-01-04 12:44: Train Epoch 9: 633/634 Loss: 0.068798
2023-01-04 12:44: **********Train Epoch 9: averaged Loss: 0.149479 
2023-01-04 12:44: 
Epoch time elapsed: 344.24266839027405

2023-01-04 12:44: 
 metrics validation: {'precision': 0.7017291066282421, 'recall': 0.7492307692307693, 'f1-score': 0.724702380952381, 'support': 1300, 'AUC': 0.8595409763313608, 'AUCPR': 0.7763281675879462, 'TP': 974, 'FP': 414, 'TN': 2186, 'FN': 326} 

2023-01-04 12:44: **********Val Epoch 9: average Loss: 0.243774
2023-01-04 12:44: *********************************Current best model saved!
2023-01-04 12:45: 
 Testing metrics {'precision': 0.7594339622641509, 'recall': 0.7866449511400652, 'f1-score': 0.7727999999999999, 'support': 1228, 'AUC': 0.8888111544950079, 'AUCPR': 0.8318411734394535, 'TP': 966, 'FP': 306, 'TN': 2150, 'FN': 262} 

2023-01-04 12:45: 
 Testing metrics {'precision': 0.8617765528937884, 'recall': 0.9223961878829136, 'f1-score': 0.8910565541429196, 'support': 4407, 'AUC': 0.9771270323132705, 'AUCPR': 0.9608384841073525, 'TP': 4065, 'FP': 652, 'TN': 8162, 'FN': 342} 

2023-01-04 12:46: Train Epoch 10: 3/634 Loss: 0.168896
2023-01-04 12:46: Train Epoch 10: 7/634 Loss: 0.170852
2023-01-04 12:46: Train Epoch 10: 11/634 Loss: 0.187739
2023-01-04 12:46: Train Epoch 10: 15/634 Loss: 0.147287
2023-01-04 12:46: Train Epoch 10: 19/634 Loss: 0.185042
2023-01-04 12:46: Train Epoch 10: 23/634 Loss: 0.164459
2023-01-04 12:46: Train Epoch 10: 27/634 Loss: 0.150861
2023-01-04 12:46: Train Epoch 10: 31/634 Loss: 0.146385
2023-01-04 12:46: Train Epoch 10: 35/634 Loss: 0.190674
2023-01-04 12:46: Train Epoch 10: 39/634 Loss: 0.127679
2023-01-04 12:46: Train Epoch 10: 43/634 Loss: 0.174095
2023-01-04 12:46: Train Epoch 10: 47/634 Loss: 0.116454
2023-01-04 12:46: Train Epoch 10: 51/634 Loss: 0.151668
2023-01-04 12:46: Train Epoch 10: 55/634 Loss: 0.158525
2023-01-04 12:46: Train Epoch 10: 59/634 Loss: 0.138259
2023-01-04 12:46: Train Epoch 10: 63/634 Loss: 0.169006
2023-01-04 12:46: Train Epoch 10: 67/634 Loss: 0.148676
2023-01-04 12:46: Train Epoch 10: 71/634 Loss: 0.125512
2023-01-04 12:46: Train Epoch 10: 75/634 Loss: 0.151992
2023-01-04 12:46: Train Epoch 10: 79/634 Loss: 0.153886
2023-01-04 12:46: Train Epoch 10: 83/634 Loss: 0.156792
2023-01-04 12:46: Train Epoch 10: 87/634 Loss: 0.109390
2023-01-04 12:46: Train Epoch 10: 91/634 Loss: 0.132927
2023-01-04 12:46: Train Epoch 10: 95/634 Loss: 0.130745
2023-01-04 12:46: Train Epoch 10: 99/634 Loss: 0.141177
2023-01-04 12:46: Train Epoch 10: 103/634 Loss: 0.137950
2023-01-04 12:46: Train Epoch 10: 107/634 Loss: 0.143019
2023-01-04 12:47: Train Epoch 10: 111/634 Loss: 0.194542
2023-01-04 12:47: Train Epoch 10: 115/634 Loss: 0.153439
2023-01-04 12:47: Train Epoch 10: 119/634 Loss: 0.154753
2023-01-04 12:47: Train Epoch 10: 123/634 Loss: 0.163168
2023-01-04 12:47: Train Epoch 10: 127/634 Loss: 0.171091
2023-01-04 12:47: Train Epoch 10: 131/634 Loss: 0.118042
2023-01-04 12:47: Train Epoch 10: 135/634 Loss: 0.131964
2023-01-04 12:47: Train Epoch 10: 139/634 Loss: 0.146556
2023-01-04 12:47: Train Epoch 10: 143/634 Loss: 0.131929
2023-01-04 12:47: Train Epoch 10: 147/634 Loss: 0.206087
2023-01-04 12:47: Train Epoch 10: 151/634 Loss: 0.157139
2023-01-04 12:47: Train Epoch 10: 155/634 Loss: 0.132951
2023-01-04 12:47: Train Epoch 10: 159/634 Loss: 0.163449
2023-01-04 12:47: Train Epoch 10: 163/634 Loss: 0.159690
2023-01-04 12:47: Train Epoch 10: 167/634 Loss: 0.133413
2023-01-04 12:47: Train Epoch 10: 171/634 Loss: 0.147431
2023-01-04 12:47: Train Epoch 10: 175/634 Loss: 0.150545
2023-01-04 12:47: Train Epoch 10: 179/634 Loss: 0.122448
2023-01-04 12:47: Train Epoch 10: 183/634 Loss: 0.142704
2023-01-04 12:47: Train Epoch 10: 187/634 Loss: 0.138004
2023-01-04 12:47: Train Epoch 10: 191/634 Loss: 0.154963
2023-01-04 12:47: Train Epoch 10: 195/634 Loss: 0.147305
2023-01-04 12:47: Train Epoch 10: 199/634 Loss: 0.126163
2023-01-04 12:47: Train Epoch 10: 203/634 Loss: 0.137833
2023-01-04 12:47: Train Epoch 10: 207/634 Loss: 0.131907
2023-01-04 12:47: Train Epoch 10: 211/634 Loss: 0.127279
2023-01-04 12:47: Train Epoch 10: 215/634 Loss: 0.114463
2023-01-04 12:48: Train Epoch 10: 219/634 Loss: 0.131634
2023-01-04 12:48: Train Epoch 10: 223/634 Loss: 0.174042
2023-01-04 12:48: Train Epoch 10: 227/634 Loss: 0.146349
2023-01-04 12:48: Train Epoch 10: 231/634 Loss: 0.161041
2023-01-04 12:48: Train Epoch 10: 235/634 Loss: 0.164330
2023-01-04 12:48: Train Epoch 10: 239/634 Loss: 0.129771
2023-01-04 12:48: Train Epoch 10: 243/634 Loss: 0.139310
2023-01-04 12:48: Train Epoch 10: 247/634 Loss: 0.130731
2023-01-04 12:48: Train Epoch 10: 251/634 Loss: 0.120277
2023-01-04 12:48: Train Epoch 10: 255/634 Loss: 0.151239
2023-01-04 12:48: Train Epoch 10: 259/634 Loss: 0.145550
2023-01-04 12:48: Train Epoch 10: 263/634 Loss: 0.151537
2023-01-04 12:48: Train Epoch 10: 267/634 Loss: 0.139162
2023-01-04 12:48: Train Epoch 10: 271/634 Loss: 0.146629
2023-01-04 12:48: Train Epoch 10: 275/634 Loss: 0.139799
2023-01-04 12:48: Train Epoch 10: 279/634 Loss: 0.136337
2023-01-04 12:48: Train Epoch 10: 283/634 Loss: 0.146425
2023-01-04 12:48: Train Epoch 10: 287/634 Loss: 0.122572
2023-01-04 12:48: Train Epoch 10: 291/634 Loss: 0.147713
2023-01-04 12:48: Train Epoch 10: 295/634 Loss: 0.123729
2023-01-04 12:48: Train Epoch 10: 299/634 Loss: 0.116502
2023-01-04 12:48: Train Epoch 10: 303/634 Loss: 0.121785
2023-01-04 12:48: Train Epoch 10: 307/634 Loss: 0.145631
2023-01-04 12:48: Train Epoch 10: 311/634 Loss: 0.176774
2023-01-04 12:48: Train Epoch 10: 315/634 Loss: 0.154527
2023-01-04 12:48: Train Epoch 10: 319/634 Loss: 0.133223
2023-01-04 12:48: Train Epoch 10: 323/634 Loss: 0.142486
2023-01-04 12:48: Train Epoch 10: 327/634 Loss: 0.105430
2023-01-04 12:49: Train Epoch 10: 331/634 Loss: 0.134735
2023-01-04 12:49: Train Epoch 10: 335/634 Loss: 0.126080
2023-01-04 12:49: Train Epoch 10: 339/634 Loss: 0.132280
2023-01-04 12:49: Train Epoch 10: 343/634 Loss: 0.154603
2023-01-04 12:49: Train Epoch 10: 347/634 Loss: 0.163372
2023-01-04 12:49: Train Epoch 10: 351/634 Loss: 0.159435
2023-01-04 12:49: Train Epoch 10: 355/634 Loss: 0.125217
2023-01-04 12:49: Train Epoch 10: 359/634 Loss: 0.132625
2023-01-04 12:49: Train Epoch 10: 363/634 Loss: 0.139392
2023-01-04 12:49: Train Epoch 10: 367/634 Loss: 0.167502
2023-01-04 12:49: Train Epoch 10: 371/634 Loss: 0.144516
2023-01-04 12:49: Train Epoch 10: 375/634 Loss: 0.148464
2023-01-04 12:49: Train Epoch 10: 379/634 Loss: 0.143068
2023-01-04 12:49: Train Epoch 10: 383/634 Loss: 0.135485
2023-01-04 12:49: Train Epoch 10: 387/634 Loss: 0.133476
2023-01-04 12:49: Train Epoch 10: 391/634 Loss: 0.139319
2023-01-04 12:49: Train Epoch 10: 395/634 Loss: 0.138753
2023-01-04 12:49: Train Epoch 10: 399/634 Loss: 0.194695
2023-01-04 12:49: Train Epoch 10: 403/634 Loss: 0.128074
2023-01-04 12:49: Train Epoch 10: 407/634 Loss: 0.111252
2023-01-04 12:49: Train Epoch 10: 411/634 Loss: 0.192145
2023-01-04 12:49: Train Epoch 10: 415/634 Loss: 0.132958
2023-01-04 12:49: Train Epoch 10: 419/634 Loss: 0.129165
2023-01-04 12:49: Train Epoch 10: 423/634 Loss: 0.178852
2023-01-04 12:49: Train Epoch 10: 427/634 Loss: 0.164094
2023-01-04 12:49: Train Epoch 10: 431/634 Loss: 0.148344
2023-01-04 12:49: Train Epoch 10: 435/634 Loss: 0.152873
2023-01-04 12:50: Train Epoch 10: 439/634 Loss: 0.122666
2023-01-04 12:50: Train Epoch 10: 443/634 Loss: 0.139277
2023-01-04 12:50: Train Epoch 10: 447/634 Loss: 0.130516
2023-01-04 12:50: Train Epoch 10: 451/634 Loss: 0.149128
2023-01-04 12:50: Train Epoch 10: 455/634 Loss: 0.195815
2023-01-04 12:50: Train Epoch 10: 459/634 Loss: 0.151136
2023-01-04 12:50: Train Epoch 10: 463/634 Loss: 0.134264
2023-01-04 12:50: Train Epoch 10: 467/634 Loss: 0.153073
2023-01-04 12:50: Train Epoch 10: 471/634 Loss: 0.123548
2023-01-04 12:50: Train Epoch 10: 475/634 Loss: 0.118665
2023-01-04 12:50: Train Epoch 10: 479/634 Loss: 0.139375
2023-01-04 12:50: Train Epoch 10: 483/634 Loss: 0.124601
2023-01-04 12:50: Train Epoch 10: 487/634 Loss: 0.106136
2023-01-04 12:50: Train Epoch 10: 491/634 Loss: 0.145264
2023-01-04 12:50: Train Epoch 10: 495/634 Loss: 0.155725
2023-01-04 12:50: Train Epoch 10: 499/634 Loss: 0.151374
2023-01-04 12:50: Train Epoch 10: 503/634 Loss: 0.145578
2023-01-04 12:50: Train Epoch 10: 507/634 Loss: 0.127895
2023-01-04 12:50: Train Epoch 10: 511/634 Loss: 0.144938
2023-01-04 12:50: Train Epoch 10: 515/634 Loss: 0.165185
2023-01-04 12:50: Train Epoch 10: 519/634 Loss: 0.119836
2023-01-04 12:50: Train Epoch 10: 523/634 Loss: 0.119020
2023-01-04 12:50: Train Epoch 10: 527/634 Loss: 0.123083
2023-01-04 12:50: Train Epoch 10: 531/634 Loss: 0.111019
2023-01-04 12:50: Train Epoch 10: 535/634 Loss: 0.140584
2023-01-04 12:50: Train Epoch 10: 539/634 Loss: 0.136717
2023-01-04 12:50: Train Epoch 10: 543/634 Loss: 0.153081
2023-01-04 12:51: Train Epoch 10: 547/634 Loss: 0.122585
2023-01-04 12:51: Train Epoch 10: 551/634 Loss: 0.110455
2023-01-04 12:51: Train Epoch 10: 555/634 Loss: 0.126177
2023-01-04 12:51: Train Epoch 10: 559/634 Loss: 0.119806
2023-01-04 12:51: Train Epoch 10: 563/634 Loss: 0.152427
2023-01-04 12:51: Train Epoch 10: 567/634 Loss: 0.141294
2023-01-04 12:51: Train Epoch 10: 571/634 Loss: 0.149141
2023-01-04 12:51: Train Epoch 10: 575/634 Loss: 0.127766
2023-01-04 12:51: Train Epoch 10: 579/634 Loss: 0.131411
2023-01-04 12:51: Train Epoch 10: 583/634 Loss: 0.181392
2023-01-04 12:51: Train Epoch 10: 587/634 Loss: 0.111637
2023-01-04 12:51: Train Epoch 10: 591/634 Loss: 0.155812
2023-01-04 12:51: Train Epoch 10: 595/634 Loss: 0.138030
2023-01-04 12:51: Train Epoch 10: 599/634 Loss: 0.164333
2023-01-04 12:51: Train Epoch 10: 603/634 Loss: 0.160195
2023-01-04 12:51: Train Epoch 10: 607/634 Loss: 0.119878
2023-01-04 12:51: Train Epoch 10: 611/634 Loss: 0.140901
2023-01-04 12:51: Train Epoch 10: 615/634 Loss: 0.141031
2023-01-04 12:51: Train Epoch 10: 619/634 Loss: 0.146169
2023-01-04 12:51: Train Epoch 10: 623/634 Loss: 0.155697
2023-01-04 12:51: Train Epoch 10: 627/634 Loss: 0.173430
2023-01-04 12:51: Train Epoch 10: 631/634 Loss: 0.154422
2023-01-04 12:51: Train Epoch 10: 633/634 Loss: 0.059880
2023-01-04 12:51: **********Train Epoch 10: averaged Loss: 0.143685 
2023-01-04 12:51: 
Epoch time elapsed: 347.14326572418213

2023-01-04 12:52: 
 metrics validation: {'precision': 0.7317269076305221, 'recall': 0.7007692307692308, 'f1-score': 0.7159135559921415, 'support': 1300, 'AUC': 0.8738437869822485, 'AUCPR': 0.7945460235516358, 'TP': 911, 'FP': 334, 'TN': 2266, 'FN': 389} 

2023-01-04 12:52: **********Val Epoch 10: average Loss: 0.222641
2023-01-04 12:52: *********************************Current best model saved!
2023-01-04 12:52: 
 Testing metrics {'precision': 0.7891459074733096, 'recall': 0.7223127035830619, 'f1-score': 0.7542517006802721, 'support': 1228, 'AUC': 0.8920174219355113, 'AUCPR': 0.8345650820959647, 'TP': 887, 'FP': 237, 'TN': 2219, 'FN': 341} 

2023-01-04 12:53: 
 Testing metrics {'precision': 0.8748919619706137, 'recall': 0.9187656001815294, 'f1-score': 0.8962921970116215, 'support': 4407, 'AUC': 0.9778689234884226, 'AUCPR': 0.9610162683191197, 'TP': 4049, 'FP': 579, 'TN': 8235, 'FN': 358} 

2023-01-04 12:53: Train Epoch 11: 3/634 Loss: 0.151833
2023-01-04 12:53: Train Epoch 11: 7/634 Loss: 0.178411
2023-01-04 12:53: Train Epoch 11: 11/634 Loss: 0.122488
2023-01-04 12:53: Train Epoch 11: 15/634 Loss: 0.111720
2023-01-04 12:53: Train Epoch 11: 19/634 Loss: 0.147598
2023-01-04 12:53: Train Epoch 11: 23/634 Loss: 0.143043
2023-01-04 12:53: Train Epoch 11: 27/634 Loss: 0.141963
2023-01-04 12:53: Train Epoch 11: 31/634 Loss: 0.160902
2023-01-04 12:53: Train Epoch 11: 35/634 Loss: 0.144001
2023-01-04 12:53: Train Epoch 11: 39/634 Loss: 0.125762
2023-01-04 12:53: Train Epoch 11: 43/634 Loss: 0.103128
2023-01-04 12:53: Train Epoch 11: 47/634 Loss: 0.172913
2023-01-04 12:53: Train Epoch 11: 51/634 Loss: 0.131811
2023-01-04 12:53: Train Epoch 11: 55/634 Loss: 0.121199
2023-01-04 12:53: Train Epoch 11: 59/634 Loss: 0.179266
2023-01-04 12:53: Train Epoch 11: 63/634 Loss: 0.149512
2023-01-04 12:53: Train Epoch 11: 67/634 Loss: 0.153158
2023-01-04 12:53: Train Epoch 11: 71/634 Loss: 0.126609
2023-01-04 12:53: Train Epoch 11: 75/634 Loss: 0.181738
2023-01-04 12:53: Train Epoch 11: 79/634 Loss: 0.094875
2023-01-04 12:53: Train Epoch 11: 83/634 Loss: 0.170446
2023-01-04 12:53: Train Epoch 11: 87/634 Loss: 0.184138
2023-01-04 12:53: Train Epoch 11: 91/634 Loss: 0.149372
2023-01-04 12:53: Train Epoch 11: 95/634 Loss: 0.164272
2023-01-04 12:53: Train Epoch 11: 99/634 Loss: 0.120764
2023-01-04 12:53: Train Epoch 11: 103/634 Loss: 0.176018
2023-01-04 12:54: Train Epoch 11: 107/634 Loss: 0.169111
2023-01-04 12:54: Train Epoch 11: 111/634 Loss: 0.124121
2023-01-04 12:54: Train Epoch 11: 115/634 Loss: 0.144931
2023-01-04 12:54: Train Epoch 11: 119/634 Loss: 0.128438
2023-01-04 12:54: Train Epoch 11: 123/634 Loss: 0.142022
2023-01-04 12:54: Train Epoch 11: 127/634 Loss: 0.180804
2023-01-04 12:54: Train Epoch 11: 131/634 Loss: 0.149120
2023-01-04 12:54: Train Epoch 11: 135/634 Loss: 0.138777
2023-01-04 12:54: Train Epoch 11: 139/634 Loss: 0.104106
2023-01-04 12:54: Train Epoch 11: 143/634 Loss: 0.125432
2023-01-04 12:54: Train Epoch 11: 147/634 Loss: 0.149187
2023-01-04 12:54: Train Epoch 11: 151/634 Loss: 0.116818
2023-01-04 12:54: Train Epoch 11: 155/634 Loss: 0.186813
2023-01-04 12:54: Train Epoch 11: 159/634 Loss: 0.126605
2023-01-04 12:54: Train Epoch 11: 163/634 Loss: 0.179428
2023-01-04 12:54: Train Epoch 11: 167/634 Loss: 0.108592
2023-01-04 12:54: Train Epoch 11: 171/634 Loss: 0.145394
2023-01-04 12:54: Train Epoch 11: 175/634 Loss: 0.135520
2023-01-04 12:54: Train Epoch 11: 179/634 Loss: 0.148054
2023-01-04 12:54: Train Epoch 11: 183/634 Loss: 0.131937
2023-01-04 12:54: Train Epoch 11: 187/634 Loss: 0.142842
2023-01-04 12:54: Train Epoch 11: 191/634 Loss: 0.121345
2023-01-04 12:54: Train Epoch 11: 195/634 Loss: 0.101198
2023-01-04 12:54: Train Epoch 11: 199/634 Loss: 0.153206
2023-01-04 12:54: Train Epoch 11: 203/634 Loss: 0.134886
2023-01-04 12:54: Train Epoch 11: 207/634 Loss: 0.141987
2023-01-04 12:54: Train Epoch 11: 211/634 Loss: 0.124971
2023-01-04 12:55: Train Epoch 11: 215/634 Loss: 0.140747
2023-01-04 12:55: Train Epoch 11: 219/634 Loss: 0.142998
2023-01-04 12:55: Train Epoch 11: 223/634 Loss: 0.131381
2023-01-04 12:55: Train Epoch 11: 227/634 Loss: 0.206080
2023-01-04 12:55: Train Epoch 11: 231/634 Loss: 0.144085
2023-01-04 12:55: Train Epoch 11: 235/634 Loss: 0.122708
2023-01-04 12:55: Train Epoch 11: 239/634 Loss: 0.144885
2023-01-04 12:55: Train Epoch 11: 243/634 Loss: 0.112969
2023-01-04 12:55: Train Epoch 11: 247/634 Loss: 0.131854
2023-01-04 12:55: Train Epoch 11: 251/634 Loss: 0.126743
2023-01-04 12:55: Train Epoch 11: 255/634 Loss: 0.147753
2023-01-04 12:55: Train Epoch 11: 259/634 Loss: 0.133345
2023-01-04 12:55: Train Epoch 11: 263/634 Loss: 0.148246
2023-01-04 12:55: Train Epoch 11: 267/634 Loss: 0.160660
2023-01-04 12:55: Train Epoch 11: 271/634 Loss: 0.138205
2023-01-04 12:55: Train Epoch 11: 275/634 Loss: 0.146545
2023-01-04 12:55: Train Epoch 11: 279/634 Loss: 0.119497
2023-01-04 12:55: Train Epoch 11: 283/634 Loss: 0.169638
2023-01-04 12:55: Train Epoch 11: 287/634 Loss: 0.144746
2023-01-04 12:55: Train Epoch 11: 291/634 Loss: 0.109144
2023-01-04 12:55: Train Epoch 11: 295/634 Loss: 0.166850
2023-01-04 12:55: Train Epoch 11: 299/634 Loss: 0.113829
2023-01-04 12:55: Train Epoch 11: 303/634 Loss: 0.139408
2023-01-04 12:55: Train Epoch 11: 307/634 Loss: 0.133775
2023-01-04 12:55: Train Epoch 11: 311/634 Loss: 0.123604
2023-01-04 12:55: Train Epoch 11: 315/634 Loss: 0.157006
2023-01-04 12:55: Train Epoch 11: 319/634 Loss: 0.114131
2023-01-04 12:56: Train Epoch 11: 323/634 Loss: 0.153692
2023-01-04 12:56: Train Epoch 11: 327/634 Loss: 0.141493
2023-01-04 12:56: Train Epoch 11: 331/634 Loss: 0.170607
2023-01-04 12:56: Train Epoch 11: 335/634 Loss: 0.132684
2023-01-04 12:56: Train Epoch 11: 339/634 Loss: 0.156489
2023-01-04 12:56: Train Epoch 11: 343/634 Loss: 0.119309
2023-01-04 12:56: Train Epoch 11: 347/634 Loss: 0.151409
2023-01-04 12:56: Train Epoch 11: 351/634 Loss: 0.135372
2023-01-04 12:56: Train Epoch 11: 355/634 Loss: 0.156269
2023-01-04 12:56: Train Epoch 11: 359/634 Loss: 0.117065
2023-01-04 12:56: Train Epoch 11: 363/634 Loss: 0.156751
2023-01-04 12:56: Train Epoch 11: 367/634 Loss: 0.129208
2023-01-04 12:56: Train Epoch 11: 371/634 Loss: 0.152827
2023-01-04 12:56: Train Epoch 11: 375/634 Loss: 0.140310
2023-01-04 12:56: Train Epoch 11: 379/634 Loss: 0.148352
2023-01-04 12:56: Train Epoch 11: 383/634 Loss: 0.098623
2023-01-04 12:56: Train Epoch 11: 387/634 Loss: 0.103794
2023-01-04 12:56: Train Epoch 11: 391/634 Loss: 0.158309
2023-01-04 12:56: Train Epoch 11: 395/634 Loss: 0.129070
2023-01-04 12:56: Train Epoch 11: 399/634 Loss: 0.152686
2023-01-04 12:56: Train Epoch 11: 403/634 Loss: 0.132944
2023-01-04 12:56: Train Epoch 11: 407/634 Loss: 0.157144
2023-01-04 12:56: Train Epoch 11: 411/634 Loss: 0.128930
2023-01-04 12:56: Train Epoch 11: 415/634 Loss: 0.103426
2023-01-04 12:56: Train Epoch 11: 419/634 Loss: 0.136122
2023-01-04 12:56: Train Epoch 11: 423/634 Loss: 0.168139
2023-01-04 12:56: Train Epoch 11: 427/634 Loss: 0.132875
2023-01-04 12:56: Train Epoch 11: 431/634 Loss: 0.131593
2023-01-04 12:57: Train Epoch 11: 435/634 Loss: 0.126704
2023-01-04 12:57: Train Epoch 11: 439/634 Loss: 0.138146
2023-01-04 12:57: Train Epoch 11: 443/634 Loss: 0.166973
2023-01-04 12:57: Train Epoch 11: 447/634 Loss: 0.132424
2023-01-04 12:57: Train Epoch 11: 451/634 Loss: 0.144224
2023-01-04 12:57: Train Epoch 11: 455/634 Loss: 0.145733
2023-01-04 12:57: Train Epoch 11: 459/634 Loss: 0.138079
2023-01-04 12:57: Train Epoch 11: 463/634 Loss: 0.136139
2023-01-04 12:57: Train Epoch 11: 467/634 Loss: 0.157659
2023-01-04 12:57: Train Epoch 11: 471/634 Loss: 0.132823
2023-01-04 12:57: Train Epoch 11: 475/634 Loss: 0.165073
2023-01-04 12:57: Train Epoch 11: 479/634 Loss: 0.145511
2023-01-04 12:57: Train Epoch 11: 483/634 Loss: 0.155652
2023-01-04 12:57: Train Epoch 11: 487/634 Loss: 0.116748
2023-01-04 12:57: Train Epoch 11: 491/634 Loss: 0.130398
2023-01-04 12:57: Train Epoch 11: 495/634 Loss: 0.121664
2023-01-04 12:57: Train Epoch 11: 499/634 Loss: 0.160341
2023-01-04 12:57: Train Epoch 11: 503/634 Loss: 0.147181
2023-01-04 12:57: Train Epoch 11: 507/634 Loss: 0.144651
2023-01-04 12:57: Train Epoch 11: 511/634 Loss: 0.141619
2023-01-04 12:57: Train Epoch 11: 515/634 Loss: 0.147928
2023-01-04 12:57: Train Epoch 11: 519/634 Loss: 0.151217
2023-01-04 12:57: Train Epoch 11: 523/634 Loss: 0.135482
2023-01-04 12:57: Train Epoch 11: 527/634 Loss: 0.143809
2023-01-04 12:57: Train Epoch 11: 531/634 Loss: 0.130966
2023-01-04 12:57: Train Epoch 11: 535/634 Loss: 0.160714
2023-01-04 12:57: Train Epoch 11: 539/634 Loss: 0.132624
2023-01-04 12:58: Train Epoch 11: 543/634 Loss: 0.106047
2023-01-04 12:58: Train Epoch 11: 547/634 Loss: 0.128025
2023-01-04 12:58: Train Epoch 11: 551/634 Loss: 0.176367
2023-01-04 12:58: Train Epoch 11: 555/634 Loss: 0.162795
2023-01-04 12:58: Train Epoch 11: 559/634 Loss: 0.121213
2023-01-04 12:58: Train Epoch 11: 563/634 Loss: 0.135996
2023-01-04 12:58: Train Epoch 11: 567/634 Loss: 0.113917
2023-01-04 12:58: Train Epoch 11: 571/634 Loss: 0.162951
2023-01-04 12:58: Train Epoch 11: 575/634 Loss: 0.125662
2023-01-04 12:58: Train Epoch 11: 579/634 Loss: 0.136119
2023-01-04 12:58: Train Epoch 11: 583/634 Loss: 0.114474
2023-01-04 12:58: Train Epoch 11: 587/634 Loss: 0.137483
2023-01-04 12:58: Train Epoch 11: 591/634 Loss: 0.164908
2023-01-04 12:58: Train Epoch 11: 595/634 Loss: 0.126111
2023-01-04 12:58: Train Epoch 11: 599/634 Loss: 0.118750
2023-01-04 12:58: Train Epoch 11: 603/634 Loss: 0.155485
2023-01-04 12:58: Train Epoch 11: 607/634 Loss: 0.134462
2023-01-04 12:58: Train Epoch 11: 611/634 Loss: 0.129935
2023-01-04 12:58: Train Epoch 11: 615/634 Loss: 0.105637
2023-01-04 12:58: Train Epoch 11: 619/634 Loss: 0.095772
2023-01-04 12:58: Train Epoch 11: 623/634 Loss: 0.164127
2023-01-04 12:58: Train Epoch 11: 627/634 Loss: 0.133028
2023-01-04 12:58: Train Epoch 11: 631/634 Loss: 0.142243
2023-01-04 12:58: Train Epoch 11: 633/634 Loss: 0.036894
2023-01-04 12:58: **********Train Epoch 11: averaged Loss: 0.139672 
2023-01-04 12:58: 
Epoch time elapsed: 347.33421421051025

2023-01-04 12:59: 
 metrics validation: {'precision': 0.7741644083107497, 'recall': 0.6592307692307692, 'f1-score': 0.7120897382633985, 'support': 1300, 'AUC': 0.8818860946745561, 'AUCPR': 0.7967606601478068, 'TP': 857, 'FP': 250, 'TN': 2350, 'FN': 443} 

2023-01-04 12:59: **********Val Epoch 11: average Loss: 0.234659
2023-01-04 12:59: 
 Testing metrics {'precision': 0.7891459074733096, 'recall': 0.7223127035830619, 'f1-score': 0.7542517006802721, 'support': 1228, 'AUC': 0.8920174219355113, 'AUCPR': 0.8345650820959647, 'TP': 887, 'FP': 237, 'TN': 2219, 'FN': 341} 

2023-01-04 13:00: 
 Testing metrics {'precision': 0.8748919619706137, 'recall': 0.9187656001815294, 'f1-score': 0.8962921970116215, 'support': 4407, 'AUC': 0.9778689234884226, 'AUCPR': 0.9610162683191197, 'TP': 4049, 'FP': 579, 'TN': 8235, 'FN': 358} 

2023-01-04 13:00: Train Epoch 12: 3/634 Loss: 0.153993
2023-01-04 13:00: Train Epoch 12: 7/634 Loss: 0.117962
2023-01-04 13:00: Train Epoch 12: 11/634 Loss: 0.147864
2023-01-04 13:00: Train Epoch 12: 15/634 Loss: 0.118434
2023-01-04 13:00: Train Epoch 12: 19/634 Loss: 0.132516
2023-01-04 13:00: Train Epoch 12: 23/634 Loss: 0.153444
2023-01-04 13:00: Train Epoch 12: 27/634 Loss: 0.120390
2023-01-04 13:00: Train Epoch 12: 31/634 Loss: 0.140901
2023-01-04 13:00: Train Epoch 12: 35/634 Loss: 0.124291
2023-01-04 13:00: Train Epoch 12: 39/634 Loss: 0.135416
2023-01-04 13:00: Train Epoch 12: 43/634 Loss: 0.168413
2023-01-04 13:00: Train Epoch 12: 47/634 Loss: 0.138233
2023-01-04 13:00: Train Epoch 12: 51/634 Loss: 0.129110
2023-01-04 13:00: Train Epoch 12: 55/634 Loss: 0.117806
2023-01-04 13:00: Train Epoch 12: 59/634 Loss: 0.175862
2023-01-04 13:00: Train Epoch 12: 63/634 Loss: 0.149768
2023-01-04 13:00: Train Epoch 12: 67/634 Loss: 0.112979
2023-01-04 13:00: Train Epoch 12: 71/634 Loss: 0.137528
2023-01-04 13:00: Train Epoch 12: 75/634 Loss: 0.136998
2023-01-04 13:00: Train Epoch 12: 79/634 Loss: 0.128921
2023-01-04 13:00: Train Epoch 12: 83/634 Loss: 0.182149
2023-01-04 13:00: Train Epoch 12: 87/634 Loss: 0.109154
2023-01-04 13:00: Train Epoch 12: 91/634 Loss: 0.113567
2023-01-04 13:00: Train Epoch 12: 95/634 Loss: 0.143559
2023-01-04 13:01: Train Epoch 12: 99/634 Loss: 0.149622
2023-01-04 13:01: Train Epoch 12: 103/634 Loss: 0.167817
2023-01-04 13:01: Train Epoch 12: 107/634 Loss: 0.132512
2023-01-04 13:01: Train Epoch 12: 111/634 Loss: 0.121893
2023-01-04 13:01: Train Epoch 12: 115/634 Loss: 0.160788
2023-01-04 13:01: Train Epoch 12: 119/634 Loss: 0.148200
2023-01-04 13:01: Train Epoch 12: 123/634 Loss: 0.147764
2023-01-04 13:01: Train Epoch 12: 127/634 Loss: 0.148675
2023-01-04 13:01: Train Epoch 12: 131/634 Loss: 0.150721
2023-01-04 13:01: Train Epoch 12: 135/634 Loss: 0.139159
2023-01-04 13:01: Train Epoch 12: 139/634 Loss: 0.120132
2023-01-04 13:01: Train Epoch 12: 143/634 Loss: 0.136503
2023-01-04 13:01: Train Epoch 12: 147/634 Loss: 0.124745
2023-01-04 13:01: Train Epoch 12: 151/634 Loss: 0.127885
2023-01-04 13:01: Train Epoch 12: 155/634 Loss: 0.135062
2023-01-04 13:01: Train Epoch 12: 159/634 Loss: 0.126821
2023-01-04 13:01: Train Epoch 12: 163/634 Loss: 0.157948
2023-01-04 13:01: Train Epoch 12: 167/634 Loss: 0.134764
2023-01-04 13:01: Train Epoch 12: 171/634 Loss: 0.141654
2023-01-04 13:01: Train Epoch 12: 175/634 Loss: 0.166290
2023-01-04 13:01: Train Epoch 12: 179/634 Loss: 0.113122
2023-01-04 13:01: Train Epoch 12: 183/634 Loss: 0.147678
2023-01-04 13:01: Train Epoch 12: 187/634 Loss: 0.113469
2023-01-04 13:01: Train Epoch 12: 191/634 Loss: 0.125262
2023-01-04 13:01: Train Epoch 12: 195/634 Loss: 0.159885
2023-01-04 13:01: Train Epoch 12: 199/634 Loss: 0.171451
2023-01-04 13:01: Train Epoch 12: 203/634 Loss: 0.153462
2023-01-04 13:02: Train Epoch 12: 207/634 Loss: 0.116043
2023-01-04 13:02: Train Epoch 12: 211/634 Loss: 0.148658
2023-01-04 13:02: Train Epoch 12: 215/634 Loss: 0.136329
2023-01-04 13:02: Train Epoch 12: 219/634 Loss: 0.160909
2023-01-04 13:02: Train Epoch 12: 223/634 Loss: 0.148713
2023-01-04 13:02: Train Epoch 12: 227/634 Loss: 0.132145
2023-01-04 13:02: Train Epoch 12: 231/634 Loss: 0.149578
2023-01-04 13:02: Train Epoch 12: 235/634 Loss: 0.164855
2023-01-04 13:02: Train Epoch 12: 239/634 Loss: 0.143217
2023-01-04 13:02: Train Epoch 12: 243/634 Loss: 0.190651
2023-01-04 13:02: Train Epoch 12: 247/634 Loss: 0.152716
2023-01-04 13:02: Train Epoch 12: 251/634 Loss: 0.137147
2023-01-04 13:02: Train Epoch 12: 255/634 Loss: 0.162671
2023-01-04 13:02: Train Epoch 12: 259/634 Loss: 0.154807
2023-01-04 13:02: Train Epoch 12: 263/634 Loss: 0.172298
2023-01-04 13:02: Train Epoch 12: 267/634 Loss: 0.113203
2023-01-04 13:02: Train Epoch 12: 271/634 Loss: 0.131765
2023-01-04 13:02: Train Epoch 12: 275/634 Loss: 0.151857
2023-01-04 13:02: Train Epoch 12: 279/634 Loss: 0.129776
2023-01-04 13:02: Train Epoch 12: 283/634 Loss: 0.174771
2023-01-04 13:02: Train Epoch 12: 287/634 Loss: 0.153127
2023-01-04 13:02: Train Epoch 12: 291/634 Loss: 0.125075
2023-01-04 13:02: Train Epoch 12: 295/634 Loss: 0.136412
2023-01-04 13:02: Train Epoch 12: 299/634 Loss: 0.148042
2023-01-04 13:02: Train Epoch 12: 303/634 Loss: 0.145805
2023-01-04 13:02: Train Epoch 12: 307/634 Loss: 0.118686
2023-01-04 13:02: Train Epoch 12: 311/634 Loss: 0.144334
2023-01-04 13:02: Train Epoch 12: 315/634 Loss: 0.156009
2023-01-04 13:03: Train Epoch 12: 319/634 Loss: 0.109937
2023-01-04 13:03: Train Epoch 12: 323/634 Loss: 0.121556
2023-01-04 13:03: Train Epoch 12: 327/634 Loss: 0.151143
2023-01-04 13:03: Train Epoch 12: 331/634 Loss: 0.118511
2023-01-04 13:03: Train Epoch 12: 335/634 Loss: 0.185675
2023-01-04 13:03: Train Epoch 12: 339/634 Loss: 0.111498
2023-01-04 13:03: Train Epoch 12: 343/634 Loss: 0.126461
2023-01-04 13:03: Train Epoch 12: 347/634 Loss: 0.136819
2023-01-04 13:03: Train Epoch 12: 351/634 Loss: 0.129668
2023-01-04 13:03: Train Epoch 12: 355/634 Loss: 0.140683
2023-01-04 13:03: Train Epoch 12: 359/634 Loss: 0.137356
2023-01-04 13:03: Train Epoch 12: 363/634 Loss: 0.165287
2023-01-04 13:03: Train Epoch 12: 367/634 Loss: 0.111601
2023-01-04 13:03: Train Epoch 12: 371/634 Loss: 0.137785
2023-01-04 13:03: Train Epoch 12: 375/634 Loss: 0.145127
2023-01-04 13:03: Train Epoch 12: 379/634 Loss: 0.123842
2023-01-04 13:03: Train Epoch 12: 383/634 Loss: 0.143650
2023-01-04 13:03: Train Epoch 12: 387/634 Loss: 0.141164
2023-01-04 13:03: Train Epoch 12: 391/634 Loss: 0.129028
2023-01-04 13:03: Train Epoch 12: 395/634 Loss: 0.129747
2023-01-04 13:03: Train Epoch 12: 399/634 Loss: 0.150120
2023-01-04 13:03: Train Epoch 12: 403/634 Loss: 0.125369
2023-01-04 13:03: Train Epoch 12: 407/634 Loss: 0.136479
2023-01-04 13:03: Train Epoch 12: 411/634 Loss: 0.107613
2023-01-04 13:03: Train Epoch 12: 415/634 Loss: 0.156824
2023-01-04 13:03: Train Epoch 12: 419/634 Loss: 0.151211
2023-01-04 13:03: Train Epoch 12: 423/634 Loss: 0.126446
2023-01-04 13:04: Train Epoch 12: 427/634 Loss: 0.151871
2023-01-04 13:04: Train Epoch 12: 431/634 Loss: 0.113138
2023-01-04 13:04: Train Epoch 12: 435/634 Loss: 0.131164
2023-01-04 13:04: Train Epoch 12: 439/634 Loss: 0.122997
2023-01-04 13:04: Train Epoch 12: 443/634 Loss: 0.126057
2023-01-04 13:04: Train Epoch 12: 447/634 Loss: 0.111738
2023-01-04 13:04: Train Epoch 12: 451/634 Loss: 0.153791
2023-01-04 13:04: Train Epoch 12: 455/634 Loss: 0.140456
2023-01-04 13:04: Train Epoch 12: 459/634 Loss: 0.139462
2023-01-04 13:04: Train Epoch 12: 463/634 Loss: 0.112820
2023-01-04 13:04: Train Epoch 12: 467/634 Loss: 0.150983
2023-01-04 13:04: Train Epoch 12: 471/634 Loss: 0.133270
2023-01-04 13:04: Train Epoch 12: 475/634 Loss: 0.154350
2023-01-04 13:04: Train Epoch 12: 479/634 Loss: 0.129067
2023-01-04 13:04: Train Epoch 12: 483/634 Loss: 0.130765
2023-01-04 13:04: Train Epoch 12: 487/634 Loss: 0.130761
2023-01-04 13:04: Train Epoch 12: 491/634 Loss: 0.126810
2023-01-04 13:04: Train Epoch 12: 495/634 Loss: 0.089030
2023-01-04 13:04: Train Epoch 12: 499/634 Loss: 0.141379
2023-01-04 13:04: Train Epoch 12: 503/634 Loss: 0.136225
2023-01-04 13:04: Train Epoch 12: 507/634 Loss: 0.149738
2023-01-04 13:04: Train Epoch 12: 511/634 Loss: 0.108189
2023-01-04 13:04: Train Epoch 12: 515/634 Loss: 0.129600
2023-01-04 13:04: Train Epoch 12: 519/634 Loss: 0.119339
2023-01-04 13:04: Train Epoch 12: 523/634 Loss: 0.112765
2023-01-04 13:04: Train Epoch 12: 527/634 Loss: 0.101644
2023-01-04 13:04: Train Epoch 12: 531/634 Loss: 0.154492
2023-01-04 13:05: Train Epoch 12: 535/634 Loss: 0.163553
2023-01-04 13:05: Train Epoch 12: 539/634 Loss: 0.150938
2023-01-04 13:05: Train Epoch 12: 543/634 Loss: 0.144427
2023-01-04 13:05: Train Epoch 12: 547/634 Loss: 0.108632
2023-01-04 13:05: Train Epoch 12: 551/634 Loss: 0.137952
2023-01-04 13:05: Train Epoch 12: 555/634 Loss: 0.122246
2023-01-04 13:05: Train Epoch 12: 559/634 Loss: 0.122497
2023-01-04 13:05: Train Epoch 12: 563/634 Loss: 0.136499
2023-01-04 13:05: Train Epoch 12: 567/634 Loss: 0.154232
2023-01-04 13:05: Train Epoch 12: 571/634 Loss: 0.161073
2023-01-04 13:05: Train Epoch 12: 575/634 Loss: 0.124434
2023-01-04 13:05: Train Epoch 12: 579/634 Loss: 0.153046
2023-01-04 13:05: Train Epoch 12: 583/634 Loss: 0.159475
2023-01-04 13:05: Train Epoch 12: 587/634 Loss: 0.138672
2023-01-04 13:05: Train Epoch 12: 591/634 Loss: 0.118176
2023-01-04 13:05: Train Epoch 12: 595/634 Loss: 0.167862
2023-01-04 13:05: Train Epoch 12: 599/634 Loss: 0.130735
2023-01-04 13:05: Train Epoch 12: 603/634 Loss: 0.102241
2023-01-04 13:05: Train Epoch 12: 607/634 Loss: 0.145024
2023-01-04 13:05: Train Epoch 12: 611/634 Loss: 0.140907
2023-01-04 13:05: Train Epoch 12: 615/634 Loss: 0.156935
2023-01-04 13:05: Train Epoch 12: 619/634 Loss: 0.138669
2023-01-04 13:05: Train Epoch 12: 623/634 Loss: 0.155425
2023-01-04 13:05: Train Epoch 12: 627/634 Loss: 0.128737
2023-01-04 13:05: Train Epoch 12: 631/634 Loss: 0.124660
2023-01-04 13:05: Train Epoch 12: 633/634 Loss: 0.068692
2023-01-04 13:05: **********Train Epoch 12: averaged Loss: 0.137864 
2023-01-04 13:05: 
Epoch time elapsed: 349.147310256958

2023-01-04 13:06: 
 metrics validation: {'precision': 0.7321281840591619, 'recall': 0.6853846153846154, 'f1-score': 0.7079856972586411, 'support': 1300, 'AUC': 0.8751565088757396, 'AUCPR': 0.7912826960097217, 'TP': 891, 'FP': 326, 'TN': 2274, 'FN': 409} 

2023-01-04 13:06: **********Val Epoch 12: average Loss: 0.224095
2023-01-04 13:06: 
 Testing metrics {'precision': 0.7891459074733096, 'recall': 0.7223127035830619, 'f1-score': 0.7542517006802721, 'support': 1228, 'AUC': 0.8920174219355113, 'AUCPR': 0.8345650820959647, 'TP': 887, 'FP': 237, 'TN': 2219, 'FN': 341} 

2023-01-04 13:07: 
 Testing metrics {'precision': 0.8748919619706137, 'recall': 0.9187656001815294, 'f1-score': 0.8962921970116215, 'support': 4407, 'AUC': 0.9778689234884226, 'AUCPR': 0.9610162683191197, 'TP': 4049, 'FP': 579, 'TN': 8235, 'FN': 358} 

2023-01-04 13:07: Train Epoch 13: 3/634 Loss: 0.159746
2023-01-04 13:07: Train Epoch 13: 7/634 Loss: 0.163690
2023-01-04 13:07: Train Epoch 13: 11/634 Loss: 0.115961
2023-01-04 13:07: Train Epoch 13: 15/634 Loss: 0.163562
2023-01-04 13:07: Train Epoch 13: 19/634 Loss: 0.116260
2023-01-04 13:07: Train Epoch 13: 23/634 Loss: 0.121404
2023-01-04 13:07: Train Epoch 13: 27/634 Loss: 0.123936
2023-01-04 13:07: Train Epoch 13: 31/634 Loss: 0.156373
2023-01-04 13:07: Train Epoch 13: 35/634 Loss: 0.153802
2023-01-04 13:07: Train Epoch 13: 39/634 Loss: 0.141094
2023-01-04 13:07: Train Epoch 13: 43/634 Loss: 0.116076
2023-01-04 13:07: Train Epoch 13: 47/634 Loss: 0.152297
2023-01-04 13:07: Train Epoch 13: 51/634 Loss: 0.177982
2023-01-04 13:07: Train Epoch 13: 55/634 Loss: 0.130215
2023-01-04 13:07: Train Epoch 13: 59/634 Loss: 0.116998
2023-01-04 13:07: Train Epoch 13: 63/634 Loss: 0.131645
2023-01-04 13:07: Train Epoch 13: 67/634 Loss: 0.154280
2023-01-04 13:07: Train Epoch 13: 71/634 Loss: 0.125784
2023-01-04 13:07: Train Epoch 13: 75/634 Loss: 0.124103
2023-01-04 13:07: Train Epoch 13: 79/634 Loss: 0.138092
2023-01-04 13:07: Train Epoch 13: 83/634 Loss: 0.134367
2023-01-04 13:07: Train Epoch 13: 87/634 Loss: 0.159942
2023-01-04 13:08: Train Epoch 13: 91/634 Loss: 0.159286
2023-01-04 13:08: Train Epoch 13: 95/634 Loss: 0.141267
2023-01-04 13:08: Train Epoch 13: 99/634 Loss: 0.140038
2023-01-04 13:08: Train Epoch 13: 103/634 Loss: 0.134452
2023-01-04 13:08: Train Epoch 13: 107/634 Loss: 0.160886
2023-01-04 13:08: Train Epoch 13: 111/634 Loss: 0.126933
2023-01-04 13:08: Train Epoch 13: 115/634 Loss: 0.128494
2023-01-04 13:08: Train Epoch 13: 119/634 Loss: 0.158516
2023-01-04 13:08: Train Epoch 13: 123/634 Loss: 0.122716
2023-01-04 13:08: Train Epoch 13: 127/634 Loss: 0.129701
2023-01-04 13:08: Train Epoch 13: 131/634 Loss: 0.127933
2023-01-04 13:08: Train Epoch 13: 135/634 Loss: 0.149426
2023-01-04 13:08: Train Epoch 13: 139/634 Loss: 0.124770
2023-01-04 13:08: Train Epoch 13: 143/634 Loss: 0.138675
2023-01-04 13:08: Train Epoch 13: 147/634 Loss: 0.142042
2023-01-04 13:08: Train Epoch 13: 151/634 Loss: 0.161170
2023-01-04 13:08: Train Epoch 13: 155/634 Loss: 0.160589
2023-01-04 13:08: Train Epoch 13: 159/634 Loss: 0.121777
2023-01-04 13:08: Train Epoch 13: 163/634 Loss: 0.142106
2023-01-04 13:08: Train Epoch 13: 167/634 Loss: 0.120196
2023-01-04 13:08: Train Epoch 13: 171/634 Loss: 0.169448
2023-01-04 13:08: Train Epoch 13: 175/634 Loss: 0.141634
2023-01-04 13:08: Train Epoch 13: 179/634 Loss: 0.135393
2023-01-04 13:08: Train Epoch 13: 183/634 Loss: 0.138925
2023-01-04 13:08: Train Epoch 13: 187/634 Loss: 0.120433
2023-01-04 13:08: Train Epoch 13: 191/634 Loss: 0.155914
2023-01-04 13:08: Train Epoch 13: 195/634 Loss: 0.152475
2023-01-04 13:08: Train Epoch 13: 199/634 Loss: 0.150615
2023-01-04 13:09: Train Epoch 13: 203/634 Loss: 0.129851
2023-01-04 13:09: Train Epoch 13: 207/634 Loss: 0.125298
2023-01-04 13:09: Train Epoch 13: 211/634 Loss: 0.095352
2023-01-04 13:09: Train Epoch 13: 215/634 Loss: 0.105079
2023-01-04 13:09: Train Epoch 13: 219/634 Loss: 0.116313
2023-01-04 13:09: Train Epoch 13: 223/634 Loss: 0.144551
2023-01-04 13:09: Train Epoch 13: 227/634 Loss: 0.161727
2023-01-04 13:09: Train Epoch 13: 231/634 Loss: 0.131272
2023-01-04 13:09: Train Epoch 13: 235/634 Loss: 0.142892
2023-01-04 13:09: Train Epoch 13: 239/634 Loss: 0.178073
2023-01-04 13:09: Train Epoch 13: 243/634 Loss: 0.117968
2023-01-04 13:09: Train Epoch 13: 247/634 Loss: 0.139349
2023-01-04 13:09: Train Epoch 13: 251/634 Loss: 0.111536
2023-01-04 13:09: Train Epoch 13: 255/634 Loss: 0.140245
2023-01-04 13:09: Train Epoch 13: 259/634 Loss: 0.145443
2023-01-04 13:09: Train Epoch 13: 263/634 Loss: 0.126412
2023-01-04 13:09: Train Epoch 13: 267/634 Loss: 0.153993
2023-01-04 13:09: Train Epoch 13: 271/634 Loss: 0.139720
2023-01-04 13:09: Train Epoch 13: 275/634 Loss: 0.137301
2023-01-04 13:09: Train Epoch 13: 279/634 Loss: 0.136133
2023-01-04 13:09: Train Epoch 13: 283/634 Loss: 0.137563
2023-01-04 13:09: Train Epoch 13: 287/634 Loss: 0.112132
2023-01-04 13:09: Train Epoch 13: 291/634 Loss: 0.154702
2023-01-04 13:09: Train Epoch 13: 295/634 Loss: 0.110051
2023-01-04 13:09: Train Epoch 13: 299/634 Loss: 0.165395
2023-01-04 13:09: Train Epoch 13: 303/634 Loss: 0.152602
2023-01-04 13:09: Train Epoch 13: 307/634 Loss: 0.165882
2023-01-04 13:10: Train Epoch 13: 311/634 Loss: 0.116733
2023-01-04 13:10: Train Epoch 13: 315/634 Loss: 0.149660
2023-01-04 13:10: Train Epoch 13: 319/634 Loss: 0.132450
2023-01-04 13:10: Train Epoch 13: 323/634 Loss: 0.177135
2023-01-04 13:10: Train Epoch 13: 327/634 Loss: 0.129435
2023-01-04 13:10: Train Epoch 13: 331/634 Loss: 0.158305
2023-01-04 13:10: Train Epoch 13: 335/634 Loss: 0.146335
2023-01-04 13:10: Train Epoch 13: 339/634 Loss: 0.106044
2023-01-04 13:10: Train Epoch 13: 343/634 Loss: 0.144085
2023-01-04 13:10: Train Epoch 13: 347/634 Loss: 0.124129
2023-01-04 13:10: Train Epoch 13: 351/634 Loss: 0.143484
2023-01-04 13:10: Train Epoch 13: 355/634 Loss: 0.129174
2023-01-04 13:10: Train Epoch 13: 359/634 Loss: 0.175802
2023-01-04 13:10: Train Epoch 13: 363/634 Loss: 0.119588
2023-01-04 13:10: Train Epoch 13: 367/634 Loss: 0.138894
2023-01-04 13:10: Train Epoch 13: 371/634 Loss: 0.138974
2023-01-04 13:10: Train Epoch 13: 375/634 Loss: 0.134903
2023-01-04 13:10: Train Epoch 13: 379/634 Loss: 0.148957
2023-01-04 13:10: Train Epoch 13: 383/634 Loss: 0.145081
2023-01-04 13:10: Train Epoch 13: 387/634 Loss: 0.143170
2023-01-04 13:10: Train Epoch 13: 391/634 Loss: 0.114130
2023-01-04 13:10: Train Epoch 13: 395/634 Loss: 0.127623
2023-01-04 13:10: Train Epoch 13: 399/634 Loss: 0.151895
2023-01-04 13:10: Train Epoch 13: 403/634 Loss: 0.133655
2023-01-04 13:10: Train Epoch 13: 407/634 Loss: 0.141381
2023-01-04 13:10: Train Epoch 13: 411/634 Loss: 0.144403
2023-01-04 13:10: Train Epoch 13: 415/634 Loss: 0.127672
2023-01-04 13:11: Train Epoch 13: 419/634 Loss: 0.141266
2023-01-04 13:11: Train Epoch 13: 423/634 Loss: 0.139605
2023-01-04 13:11: Train Epoch 13: 427/634 Loss: 0.137558
2023-01-04 13:11: Train Epoch 13: 431/634 Loss: 0.139954
2023-01-04 13:11: Train Epoch 13: 435/634 Loss: 0.128121
2023-01-04 13:11: Train Epoch 13: 439/634 Loss: 0.157244
2023-01-04 13:11: Train Epoch 13: 443/634 Loss: 0.165623
2023-01-04 13:11: Train Epoch 13: 447/634 Loss: 0.113883
2023-01-04 13:11: Train Epoch 13: 451/634 Loss: 0.111302
2023-01-04 13:11: Train Epoch 13: 455/634 Loss: 0.140769
2023-01-04 13:11: Train Epoch 13: 459/634 Loss: 0.146234
2023-01-04 13:11: Train Epoch 13: 463/634 Loss: 0.126234
2023-01-04 13:11: Train Epoch 13: 467/634 Loss: 0.167984
2023-01-04 13:11: Train Epoch 13: 471/634 Loss: 0.130135
2023-01-04 13:11: Train Epoch 13: 475/634 Loss: 0.130757
2023-01-04 13:11: Train Epoch 13: 479/634 Loss: 0.159802
2023-01-04 13:11: Train Epoch 13: 483/634 Loss: 0.142351
2023-01-04 13:11: Train Epoch 13: 487/634 Loss: 0.107952
2023-01-04 13:11: Train Epoch 13: 491/634 Loss: 0.146831
2023-01-04 13:11: Train Epoch 13: 495/634 Loss: 0.116719
2023-01-04 13:11: Train Epoch 13: 499/634 Loss: 0.125336
2023-01-04 13:11: Train Epoch 13: 503/634 Loss: 0.137429
2023-01-04 13:11: Train Epoch 13: 507/634 Loss: 0.167176
2023-01-04 13:11: Train Epoch 13: 511/634 Loss: 0.140676
2023-01-04 13:11: Train Epoch 13: 515/634 Loss: 0.143940
2023-01-04 13:11: Train Epoch 13: 519/634 Loss: 0.129955
2023-01-04 13:11: Train Epoch 13: 523/634 Loss: 0.105625
2023-01-04 13:11: Train Epoch 13: 527/634 Loss: 0.119391
2023-01-04 13:12: Train Epoch 13: 531/634 Loss: 0.136995
2023-01-04 13:12: Train Epoch 13: 535/634 Loss: 0.115627
2023-01-04 13:12: Train Epoch 13: 539/634 Loss: 0.138723
2023-01-04 13:12: Train Epoch 13: 543/634 Loss: 0.161544
2023-01-04 13:12: Train Epoch 13: 547/634 Loss: 0.116904
2023-01-04 13:12: Train Epoch 13: 551/634 Loss: 0.146104
2023-01-04 13:12: Train Epoch 13: 555/634 Loss: 0.128493
2023-01-04 13:12: Train Epoch 13: 559/634 Loss: 0.123033
2023-01-04 13:12: Train Epoch 13: 563/634 Loss: 0.136621
2023-01-04 13:12: Train Epoch 13: 567/634 Loss: 0.136144
2023-01-04 13:12: Train Epoch 13: 571/634 Loss: 0.143105
2023-01-04 13:12: Train Epoch 13: 575/634 Loss: 0.155448
2023-01-04 13:12: Train Epoch 13: 579/634 Loss: 0.165733
2023-01-04 13:12: Train Epoch 13: 583/634 Loss: 0.127228
2023-01-04 13:12: Train Epoch 13: 587/634 Loss: 0.136189
2023-01-04 13:12: Train Epoch 13: 591/634 Loss: 0.150312
2023-01-04 13:12: Train Epoch 13: 595/634 Loss: 0.136369
2023-01-04 13:12: Train Epoch 13: 599/634 Loss: 0.126735
2023-01-04 13:12: Train Epoch 13: 603/634 Loss: 0.117650
2023-01-04 13:12: Train Epoch 13: 607/634 Loss: 0.162834
2023-01-04 13:12: Train Epoch 13: 611/634 Loss: 0.140295
2023-01-04 13:12: Train Epoch 13: 615/634 Loss: 0.146847
2023-01-04 13:12: Train Epoch 13: 619/634 Loss: 0.151313
2023-01-04 13:12: Train Epoch 13: 623/634 Loss: 0.122291
2023-01-04 13:12: Train Epoch 13: 627/634 Loss: 0.136956
2023-01-04 13:12: Train Epoch 13: 631/634 Loss: 0.162066
2023-01-04 13:12: Train Epoch 13: 633/634 Loss: 0.068302
2023-01-04 13:12: **********Train Epoch 13: averaged Loss: 0.138132 
2023-01-04 13:12: 
Epoch time elapsed: 347.09785294532776

2023-01-04 13:13: 
 metrics validation: {'precision': 0.7188665175242357, 'recall': 0.7415384615384616, 'f1-score': 0.7300265051117002, 'support': 1300, 'AUC': 0.8788300295857987, 'AUCPR': 0.7969706929287959, 'TP': 964, 'FP': 377, 'TN': 2223, 'FN': 336} 

2023-01-04 13:13: **********Val Epoch 13: average Loss: 0.216705
2023-01-04 13:13: *********************************Current best model saved!
2023-01-04 13:13: 
 Testing metrics {'precision': 0.782258064516129, 'recall': 0.7899022801302932, 'f1-score': 0.7860615883306321, 'support': 1228, 'AUC': 0.8967303366613969, 'AUCPR': 0.8402097758061511, 'TP': 970, 'FP': 270, 'TN': 2186, 'FN': 258} 

2023-01-04 13:14: 
 Testing metrics {'precision': 0.8651329674968341, 'recall': 0.9301111867483549, 'f1-score': 0.8964461454346638, 'support': 4407, 'AUC': 0.9792919875135216, 'AUCPR': 0.9645613867356423, 'TP': 4099, 'FP': 639, 'TN': 8175, 'FN': 308} 

2023-01-04 13:14: Train Epoch 14: 3/634 Loss: 0.177223
2023-01-04 13:14: Train Epoch 14: 7/634 Loss: 0.137386
2023-01-04 13:14: Train Epoch 14: 11/634 Loss: 0.153301
2023-01-04 13:14: Train Epoch 14: 15/634 Loss: 0.138042
2023-01-04 13:14: Train Epoch 14: 19/634 Loss: 0.153343
2023-01-04 13:14: Train Epoch 14: 23/634 Loss: 0.166740
2023-01-04 13:14: Train Epoch 14: 27/634 Loss: 0.166495
2023-01-04 13:14: Train Epoch 14: 31/634 Loss: 0.138166
2023-01-04 13:14: Train Epoch 14: 35/634 Loss: 0.144626
2023-01-04 13:14: Train Epoch 14: 39/634 Loss: 0.170160
2023-01-04 13:14: Train Epoch 14: 43/634 Loss: 0.146509
2023-01-04 13:14: Train Epoch 14: 47/634 Loss: 0.114578
2023-01-04 13:14: Train Epoch 14: 51/634 Loss: 0.102666
2023-01-04 13:14: Train Epoch 14: 55/634 Loss: 0.148809
2023-01-04 13:14: Train Epoch 14: 59/634 Loss: 0.130563
2023-01-04 13:14: Train Epoch 14: 63/634 Loss: 0.166528
2023-01-04 13:14: Train Epoch 14: 67/634 Loss: 0.130989
2023-01-04 13:14: Train Epoch 14: 71/634 Loss: 0.124854
2023-01-04 13:14: Train Epoch 14: 75/634 Loss: 0.152191
2023-01-04 13:14: Train Epoch 14: 79/634 Loss: 0.120058
2023-01-04 13:14: Train Epoch 14: 83/634 Loss: 0.133503
2023-01-04 13:15: Train Epoch 14: 87/634 Loss: 0.131748
2023-01-04 13:15: Train Epoch 14: 91/634 Loss: 0.173244
2023-01-04 13:15: Train Epoch 14: 95/634 Loss: 0.122923
2023-01-04 13:15: Train Epoch 14: 99/634 Loss: 0.156101
2023-01-04 13:15: Train Epoch 14: 103/634 Loss: 0.122201
2023-01-04 13:15: Train Epoch 14: 107/634 Loss: 0.145316
2023-01-04 13:15: Train Epoch 14: 111/634 Loss: 0.115853
2023-01-04 13:15: Train Epoch 14: 115/634 Loss: 0.134266
2023-01-04 13:15: Train Epoch 14: 119/634 Loss: 0.133605
2023-01-04 13:15: Train Epoch 14: 123/634 Loss: 0.118756
2023-01-04 13:15: Train Epoch 14: 127/634 Loss: 0.130819
2023-01-04 13:15: Train Epoch 14: 131/634 Loss: 0.126334
2023-01-04 13:15: Train Epoch 14: 135/634 Loss: 0.165532
2023-01-04 13:15: Train Epoch 14: 139/634 Loss: 0.131280
2023-01-04 13:15: Train Epoch 14: 143/634 Loss: 0.155467
2023-01-04 13:15: Train Epoch 14: 147/634 Loss: 0.124603
2023-01-04 13:15: Train Epoch 14: 151/634 Loss: 0.134687
2023-01-04 13:15: Train Epoch 14: 155/634 Loss: 0.117654
2023-01-04 13:15: Train Epoch 14: 159/634 Loss: 0.146293
2023-01-04 13:15: Train Epoch 14: 163/634 Loss: 0.151825
2023-01-04 13:15: Train Epoch 14: 167/634 Loss: 0.109202
2023-01-04 13:15: Train Epoch 14: 171/634 Loss: 0.157701
2023-01-04 13:15: Train Epoch 14: 175/634 Loss: 0.122114
2023-01-04 13:15: Train Epoch 14: 179/634 Loss: 0.154028
2023-01-04 13:15: Train Epoch 14: 183/634 Loss: 0.096130
2023-01-04 13:15: Train Epoch 14: 187/634 Loss: 0.128617
2023-01-04 13:15: Train Epoch 14: 191/634 Loss: 0.143054
2023-01-04 13:16: Train Epoch 14: 195/634 Loss: 0.124588
2023-01-04 13:16: Train Epoch 14: 199/634 Loss: 0.126527
2023-01-04 13:16: Train Epoch 14: 203/634 Loss: 0.129302
2023-01-04 13:16: Train Epoch 14: 207/634 Loss: 0.114658
2023-01-04 13:16: Train Epoch 14: 211/634 Loss: 0.125870
2023-01-04 13:16: Train Epoch 14: 215/634 Loss: 0.121428
2023-01-04 13:16: Train Epoch 14: 219/634 Loss: 0.176389
2023-01-04 13:16: Train Epoch 14: 223/634 Loss: 0.122335
2023-01-04 13:16: Train Epoch 14: 227/634 Loss: 0.121860
2023-01-04 13:16: Train Epoch 14: 231/634 Loss: 0.119617
2023-01-04 13:16: Train Epoch 14: 235/634 Loss: 0.150254
2023-01-04 13:16: Train Epoch 14: 239/634 Loss: 0.130105
2023-01-04 13:16: Train Epoch 14: 243/634 Loss: 0.187581
2023-01-04 13:16: Train Epoch 14: 247/634 Loss: 0.147064
2023-01-04 13:16: Train Epoch 14: 251/634 Loss: 0.116064
2023-01-04 13:16: Train Epoch 14: 255/634 Loss: 0.101619
2023-01-04 13:16: Train Epoch 14: 259/634 Loss: 0.172433
2023-01-04 13:16: Train Epoch 14: 263/634 Loss: 0.184935
2023-01-04 13:16: Train Epoch 14: 267/634 Loss: 0.124181
2023-01-04 13:16: Train Epoch 14: 271/634 Loss: 0.112736
2023-01-04 13:16: Train Epoch 14: 275/634 Loss: 0.124627
2023-01-04 13:16: Train Epoch 14: 279/634 Loss: 0.187184
2023-01-04 13:16: Train Epoch 14: 283/634 Loss: 0.109636
2023-01-04 13:16: Train Epoch 14: 287/634 Loss: 0.131374
2023-01-04 13:16: Train Epoch 14: 291/634 Loss: 0.127124
2023-01-04 13:16: Train Epoch 14: 295/634 Loss: 0.104661
2023-01-04 13:16: Train Epoch 14: 299/634 Loss: 0.254943
2023-01-04 13:16: Train Epoch 14: 303/634 Loss: 0.142955
2023-01-04 13:17: Train Epoch 14: 307/634 Loss: 0.146072
2023-01-04 13:17: Train Epoch 14: 311/634 Loss: 0.152740
2023-01-04 13:17: Train Epoch 14: 315/634 Loss: 0.124960
2023-01-04 13:17: Train Epoch 14: 319/634 Loss: 0.173997
2023-01-04 13:17: Train Epoch 14: 323/634 Loss: 0.129106
2023-01-04 13:17: Train Epoch 14: 327/634 Loss: 0.135217
2023-01-04 13:17: Train Epoch 14: 331/634 Loss: 0.137734
2023-01-04 13:17: Train Epoch 14: 335/634 Loss: 0.126965
2023-01-04 13:17: Train Epoch 14: 339/634 Loss: 0.160819
2023-01-04 13:17: Train Epoch 14: 343/634 Loss: 0.169496
2023-01-04 13:17: Train Epoch 14: 347/634 Loss: 0.146159
2023-01-04 13:17: Train Epoch 14: 351/634 Loss: 0.123632
2023-01-04 13:17: Train Epoch 14: 355/634 Loss: 0.108956
2023-01-04 13:17: Train Epoch 14: 359/634 Loss: 0.125315
2023-01-04 13:17: Train Epoch 14: 363/634 Loss: 0.149899
2023-01-04 13:17: Train Epoch 14: 367/634 Loss: 0.141454
2023-01-04 13:17: Train Epoch 14: 371/634 Loss: 0.119742
2023-01-04 13:17: Train Epoch 14: 375/634 Loss: 0.124164
2023-01-04 13:17: Train Epoch 14: 379/634 Loss: 0.140669
2023-01-04 13:17: Train Epoch 14: 383/634 Loss: 0.107293
2023-01-04 13:17: Train Epoch 14: 387/634 Loss: 0.125471
2023-01-04 13:17: Train Epoch 14: 391/634 Loss: 0.147297
2023-01-04 13:17: Train Epoch 14: 395/634 Loss: 0.172368
2023-01-04 13:17: Train Epoch 14: 399/634 Loss: 0.121451
2023-01-04 13:17: Train Epoch 14: 403/634 Loss: 0.145222
2023-01-04 13:17: Train Epoch 14: 407/634 Loss: 0.122305
2023-01-04 13:17: Train Epoch 14: 411/634 Loss: 0.182320
2023-01-04 13:18: Train Epoch 14: 415/634 Loss: 0.137538
2023-01-04 13:18: Train Epoch 14: 419/634 Loss: 0.144582
2023-01-04 13:18: Train Epoch 14: 423/634 Loss: 0.138179
2023-01-04 13:18: Train Epoch 14: 427/634 Loss: 0.134530
2023-01-04 13:18: Train Epoch 14: 431/634 Loss: 0.141462
2023-01-04 13:18: Train Epoch 14: 435/634 Loss: 0.146182
2023-01-04 13:18: Train Epoch 14: 439/634 Loss: 0.150509
2023-01-04 13:18: Train Epoch 14: 443/634 Loss: 0.166522
2023-01-04 13:18: Train Epoch 14: 447/634 Loss: 0.131536
2023-01-04 13:18: Train Epoch 14: 451/634 Loss: 0.120639
2023-01-04 13:18: Train Epoch 14: 455/634 Loss: 0.137088
2023-01-04 13:18: Train Epoch 14: 459/634 Loss: 0.124711
2023-01-04 13:18: Train Epoch 14: 463/634 Loss: 0.090643
2023-01-04 13:18: Train Epoch 14: 467/634 Loss: 0.137529
2023-01-04 13:18: Train Epoch 14: 471/634 Loss: 0.115623
2023-01-04 13:18: Train Epoch 14: 475/634 Loss: 0.108849
2023-01-04 13:18: Train Epoch 14: 479/634 Loss: 0.110688
2023-01-04 13:18: Train Epoch 14: 483/634 Loss: 0.139391
2023-01-04 13:18: Train Epoch 14: 487/634 Loss: 0.144376
2023-01-04 13:18: Train Epoch 14: 491/634 Loss: 0.122260
2023-01-04 13:18: Train Epoch 14: 495/634 Loss: 0.137869
2023-01-04 13:18: Train Epoch 14: 499/634 Loss: 0.153767
2023-01-04 13:18: Train Epoch 14: 503/634 Loss: 0.157339
2023-01-04 13:18: Train Epoch 14: 507/634 Loss: 0.140308
2023-01-04 13:18: Train Epoch 14: 511/634 Loss: 0.178750
2023-01-04 13:18: Train Epoch 14: 515/634 Loss: 0.132796
2023-01-04 13:18: Train Epoch 14: 519/634 Loss: 0.159160
2023-01-04 13:19: Train Epoch 14: 523/634 Loss: 0.131374
2023-01-04 13:19: Train Epoch 14: 527/634 Loss: 0.112396
2023-01-04 13:19: Train Epoch 14: 531/634 Loss: 0.127590
2023-01-04 13:19: Train Epoch 14: 535/634 Loss: 0.156102
2023-01-04 13:19: Train Epoch 14: 539/634 Loss: 0.142349
2023-01-04 13:19: Train Epoch 14: 543/634 Loss: 0.131656
2023-01-04 13:19: Train Epoch 14: 547/634 Loss: 0.111253
2023-01-04 13:19: Train Epoch 14: 551/634 Loss: 0.126843
2023-01-04 13:19: Train Epoch 14: 555/634 Loss: 0.136996
2023-01-04 13:19: Train Epoch 14: 559/634 Loss: 0.111812
2023-01-04 13:19: Train Epoch 14: 563/634 Loss: 0.149724
2023-01-04 13:19: Train Epoch 14: 567/634 Loss: 0.128994
2023-01-04 13:19: Train Epoch 14: 571/634 Loss: 0.105321
2023-01-04 13:19: Train Epoch 14: 575/634 Loss: 0.145297
2023-01-04 13:19: Train Epoch 14: 579/634 Loss: 0.147745
2023-01-04 13:19: Train Epoch 14: 583/634 Loss: 0.159822
2023-01-04 13:19: Train Epoch 14: 587/634 Loss: 0.140362
2023-01-04 13:19: Train Epoch 14: 591/634 Loss: 0.143130
2023-01-04 13:19: Train Epoch 14: 595/634 Loss: 0.152470
2023-01-04 13:19: Train Epoch 14: 599/634 Loss: 0.148754
2023-01-04 13:19: Train Epoch 14: 603/634 Loss: 0.127273
2023-01-04 13:19: Train Epoch 14: 607/634 Loss: 0.157546
2023-01-04 13:19: Train Epoch 14: 611/634 Loss: 0.122068
2023-01-04 13:19: Train Epoch 14: 615/634 Loss: 0.135555
2023-01-04 13:19: Train Epoch 14: 619/634 Loss: 0.115895
2023-01-04 13:19: Train Epoch 14: 623/634 Loss: 0.126276
2023-01-04 13:19: Train Epoch 14: 627/634 Loss: 0.144736
2023-01-04 13:19: Train Epoch 14: 631/634 Loss: 0.140050
2023-01-04 13:19: Train Epoch 14: 633/634 Loss: 0.066291
2023-01-04 13:19: **********Train Epoch 14: averaged Loss: 0.137531 
2023-01-04 13:19: 
Epoch time elapsed: 346.5626871585846

2023-01-04 13:20: 
 metrics validation: {'precision': 0.7950664136622391, 'recall': 0.6446153846153846, 'f1-score': 0.7119796091758707, 'support': 1300, 'AUC': 0.8931683431952664, 'AUCPR': 0.8141652065015885, 'TP': 838, 'FP': 216, 'TN': 2384, 'FN': 462} 

2023-01-04 13:20: **********Val Epoch 14: average Loss: 0.205087
2023-01-04 13:20: *********************************Current best model saved!
2023-01-04 13:20: 
 Testing metrics {'precision': 0.8329741379310345, 'recall': 0.6294788273615635, 'f1-score': 0.7170686456400741, 'support': 1228, 'AUC': 0.9019396094388269, 'AUCPR': 0.8433225215142268, 'TP': 773, 'FP': 155, 'TN': 2301, 'FN': 455} 

2023-01-04 13:21: 
 Testing metrics {'precision': 0.9115708115480791, 'recall': 0.9099160426594055, 'f1-score': 0.9107426754485578, 'support': 4407, 'AUC': 0.9797061130082207, 'AUCPR': 0.9645600234874565, 'TP': 4010, 'FP': 389, 'TN': 8425, 'FN': 397} 

2023-01-04 13:21: Train Epoch 15: 3/634 Loss: 0.117679
2023-01-04 13:21: Train Epoch 15: 7/634 Loss: 0.118498
2023-01-04 13:21: Train Epoch 15: 11/634 Loss: 0.130335
2023-01-04 13:21: Train Epoch 15: 15/634 Loss: 0.112742
2023-01-04 13:21: Train Epoch 15: 19/634 Loss: 0.139113
2023-01-04 13:21: Train Epoch 15: 23/634 Loss: 0.155108
2023-01-04 13:21: Train Epoch 15: 27/634 Loss: 0.136077
2023-01-04 13:21: Train Epoch 15: 31/634 Loss: 0.147676
2023-01-04 13:21: Train Epoch 15: 35/634 Loss: 0.123639
2023-01-04 13:21: Train Epoch 15: 39/634 Loss: 0.153147
2023-01-04 13:21: Train Epoch 15: 43/634 Loss: 0.178504
2023-01-04 13:21: Train Epoch 15: 47/634 Loss: 0.133718
2023-01-04 13:21: Train Epoch 15: 51/634 Loss: 0.098096
2023-01-04 13:21: Train Epoch 15: 55/634 Loss: 0.158156
2023-01-04 13:21: Train Epoch 15: 59/634 Loss: 0.136523
2023-01-04 13:21: Train Epoch 15: 63/634 Loss: 0.111386
2023-01-04 13:21: Train Epoch 15: 67/634 Loss: 0.137537
2023-01-04 13:21: Train Epoch 15: 71/634 Loss: 0.138726
2023-01-04 13:21: Train Epoch 15: 75/634 Loss: 0.141198
2023-01-04 13:22: Train Epoch 15: 79/634 Loss: 0.132770
2023-01-04 13:22: Train Epoch 15: 83/634 Loss: 0.161028
2023-01-04 13:22: Train Epoch 15: 87/634 Loss: 0.147724
2023-01-04 13:22: Train Epoch 15: 91/634 Loss: 0.144232
2023-01-04 13:22: Train Epoch 15: 95/634 Loss: 0.116024
2023-01-04 13:22: Train Epoch 15: 99/634 Loss: 0.117752
2023-01-04 13:22: Train Epoch 15: 103/634 Loss: 0.105689
2023-01-04 13:22: Train Epoch 15: 107/634 Loss: 0.138926
2023-01-04 13:22: Train Epoch 15: 111/634 Loss: 0.127870
2023-01-04 13:22: Train Epoch 15: 115/634 Loss: 0.099767
2023-01-04 13:22: Train Epoch 15: 119/634 Loss: 0.086968
2023-01-04 13:22: Train Epoch 15: 123/634 Loss: 0.145554
2023-01-04 13:22: Train Epoch 15: 127/634 Loss: 0.085638
2023-01-04 13:22: Train Epoch 15: 131/634 Loss: 0.138752
2023-01-04 13:22: Train Epoch 15: 135/634 Loss: 0.165741
2023-01-04 13:22: Train Epoch 15: 139/634 Loss: 0.143233
2023-01-04 13:22: Train Epoch 15: 143/634 Loss: 0.117735
2023-01-04 13:22: Train Epoch 15: 147/634 Loss: 0.132920
2023-01-04 13:22: Train Epoch 15: 151/634 Loss: 0.129339
2023-01-04 13:22: Train Epoch 15: 155/634 Loss: 0.155800
2023-01-04 13:22: Train Epoch 15: 159/634 Loss: 0.109684
2023-01-04 13:22: Train Epoch 15: 163/634 Loss: 0.138830
2023-01-04 13:22: Train Epoch 15: 167/634 Loss: 0.125213
2023-01-04 13:22: Train Epoch 15: 171/634 Loss: 0.120618
2023-01-04 13:22: Train Epoch 15: 175/634 Loss: 0.155184
2023-01-04 13:22: Train Epoch 15: 179/634 Loss: 0.105662
2023-01-04 13:22: Train Epoch 15: 183/634 Loss: 0.132218
2023-01-04 13:22: Train Epoch 15: 187/634 Loss: 0.126018
2023-01-04 13:23: Train Epoch 15: 191/634 Loss: 0.179395
2023-01-04 13:23: Train Epoch 15: 195/634 Loss: 0.120213
2023-01-04 13:23: Train Epoch 15: 199/634 Loss: 0.101963
2023-01-04 13:23: Train Epoch 15: 203/634 Loss: 0.172074
2023-01-04 13:23: Train Epoch 15: 207/634 Loss: 0.149907
2023-01-04 13:23: Train Epoch 15: 211/634 Loss: 0.117437
2023-01-04 13:23: Train Epoch 15: 215/634 Loss: 0.132360
2023-01-04 13:23: Train Epoch 15: 219/634 Loss: 0.127963
2023-01-04 13:23: Train Epoch 15: 223/634 Loss: 0.147127
2023-01-04 13:23: Train Epoch 15: 227/634 Loss: 0.130093
2023-01-04 13:23: Train Epoch 15: 231/634 Loss: 0.130639
2023-01-04 13:23: Train Epoch 15: 235/634 Loss: 0.131255
2023-01-04 13:23: Train Epoch 15: 239/634 Loss: 0.098624
2023-01-04 13:23: Train Epoch 15: 243/634 Loss: 0.136764
2023-01-04 13:23: Train Epoch 15: 247/634 Loss: 0.118513
2023-01-04 13:23: Train Epoch 15: 251/634 Loss: 0.130731
2023-01-04 13:23: Train Epoch 15: 255/634 Loss: 0.159758
2023-01-04 13:23: Train Epoch 15: 259/634 Loss: 0.161927
2023-01-04 13:23: Train Epoch 15: 263/634 Loss: 0.118447
2023-01-04 13:23: Train Epoch 15: 267/634 Loss: 0.140044
2023-01-04 13:23: Train Epoch 15: 271/634 Loss: 0.137349
2023-01-04 13:23: Train Epoch 15: 275/634 Loss: 0.109954
2023-01-04 13:23: Train Epoch 15: 279/634 Loss: 0.117330
2023-01-04 13:23: Train Epoch 15: 283/634 Loss: 0.151301
2023-01-04 13:23: Train Epoch 15: 287/634 Loss: 0.130188
2023-01-04 13:23: Train Epoch 15: 291/634 Loss: 0.105800
2023-01-04 13:23: Train Epoch 15: 295/634 Loss: 0.126324
2023-01-04 13:24: Train Epoch 15: 299/634 Loss: 0.133838
2023-01-04 13:24: Train Epoch 15: 303/634 Loss: 0.136009
2023-01-04 13:24: Train Epoch 15: 307/634 Loss: 0.113525
2023-01-04 13:24: Train Epoch 15: 311/634 Loss: 0.127628
2023-01-04 13:24: Train Epoch 15: 315/634 Loss: 0.101937
2023-01-04 13:24: Train Epoch 15: 319/634 Loss: 0.113462
2023-01-04 13:24: Train Epoch 15: 323/634 Loss: 0.130237
2023-01-04 13:24: Train Epoch 15: 327/634 Loss: 0.118430
2023-01-04 13:24: Train Epoch 15: 331/634 Loss: 0.139828
2023-01-04 13:24: Train Epoch 15: 335/634 Loss: 0.139559
2023-01-04 13:24: Train Epoch 15: 339/634 Loss: 0.108080
2023-01-04 13:24: Train Epoch 15: 343/634 Loss: 0.131371
2023-01-04 13:24: Train Epoch 15: 347/634 Loss: 0.159237
2023-01-04 13:24: Train Epoch 15: 351/634 Loss: 0.113132
2023-01-04 13:24: Train Epoch 15: 355/634 Loss: 0.127401
2023-01-04 13:24: Train Epoch 15: 359/634 Loss: 0.144042
2023-01-04 13:24: Train Epoch 15: 363/634 Loss: 0.126171
2023-01-04 13:24: Train Epoch 15: 367/634 Loss: 0.120809
2023-01-04 13:24: Train Epoch 15: 371/634 Loss: 0.095848
2023-01-04 13:24: Train Epoch 15: 375/634 Loss: 0.099017
2023-01-04 13:24: Train Epoch 15: 379/634 Loss: 0.115971
2023-01-04 13:24: Train Epoch 15: 383/634 Loss: 0.160543
2023-01-04 13:24: Train Epoch 15: 387/634 Loss: 0.107311
2023-01-04 13:24: Train Epoch 15: 391/634 Loss: 0.122450
2023-01-04 13:24: Train Epoch 15: 395/634 Loss: 0.132026
2023-01-04 13:24: Train Epoch 15: 399/634 Loss: 0.123182
2023-01-04 13:24: Train Epoch 15: 403/634 Loss: 0.147281
2023-01-04 13:24: Train Epoch 15: 407/634 Loss: 0.167240
2023-01-04 13:25: Train Epoch 15: 411/634 Loss: 0.110957
2023-01-04 13:25: Train Epoch 15: 415/634 Loss: 0.158706
2023-01-04 13:25: Train Epoch 15: 419/634 Loss: 0.137982
2023-01-04 13:25: Train Epoch 15: 423/634 Loss: 0.123076
2023-01-04 13:25: Train Epoch 15: 427/634 Loss: 0.132562
2023-01-04 13:25: Train Epoch 15: 431/634 Loss: 0.109797
2023-01-04 13:25: Train Epoch 15: 435/634 Loss: 0.128908
2023-01-04 13:25: Train Epoch 15: 439/634 Loss: 0.131074
2023-01-04 13:25: Train Epoch 15: 443/634 Loss: 0.136736
2023-01-04 13:25: Train Epoch 15: 447/634 Loss: 0.130232
2023-01-04 13:25: Train Epoch 15: 451/634 Loss: 0.164109
2023-01-04 13:25: Train Epoch 15: 455/634 Loss: 0.109431
2023-01-04 13:25: Train Epoch 15: 459/634 Loss: 0.129395
2023-01-04 13:25: Train Epoch 15: 463/634 Loss: 0.143670
2023-01-04 13:25: Train Epoch 15: 467/634 Loss: 0.114206
2023-01-04 13:25: Train Epoch 15: 471/634 Loss: 0.160389
2023-01-04 13:25: Train Epoch 15: 475/634 Loss: 0.131316
2023-01-04 13:25: Train Epoch 15: 479/634 Loss: 0.116730
2023-01-04 13:25: Train Epoch 15: 483/634 Loss: 0.122879
2023-01-04 13:25: Train Epoch 15: 487/634 Loss: 0.095608
2023-01-04 13:25: Train Epoch 15: 491/634 Loss: 0.135190
2023-01-04 13:25: Train Epoch 15: 495/634 Loss: 0.117865
2023-01-04 13:25: Train Epoch 15: 499/634 Loss: 0.139289
2023-01-04 13:25: Train Epoch 15: 503/634 Loss: 0.130034
2023-01-04 13:25: Train Epoch 15: 507/634 Loss: 0.108509
2023-01-04 13:25: Train Epoch 15: 511/634 Loss: 0.146601
2023-01-04 13:25: Train Epoch 15: 515/634 Loss: 0.116154
2023-01-04 13:26: Train Epoch 15: 519/634 Loss: 0.120795
2023-01-04 13:26: Train Epoch 15: 523/634 Loss: 0.129808
2023-01-04 13:26: Train Epoch 15: 527/634 Loss: 0.115633
2023-01-04 13:26: Train Epoch 15: 531/634 Loss: 0.102074
2023-01-04 13:26: Train Epoch 15: 535/634 Loss: 0.128816
2023-01-04 13:26: Train Epoch 15: 539/634 Loss: 0.104191
2023-01-04 13:26: Train Epoch 15: 543/634 Loss: 0.118914
2023-01-04 13:26: Train Epoch 15: 547/634 Loss: 0.143244
2023-01-04 13:26: Train Epoch 15: 551/634 Loss: 0.110961
2023-01-04 13:26: Train Epoch 15: 555/634 Loss: 0.128767
2023-01-04 13:26: Train Epoch 15: 559/634 Loss: 0.140016
2023-01-04 13:26: Train Epoch 15: 563/634 Loss: 0.141431
2023-01-04 13:26: Train Epoch 15: 567/634 Loss: 0.108463
2023-01-04 13:26: Train Epoch 15: 571/634 Loss: 0.147033
2023-01-04 13:26: Train Epoch 15: 575/634 Loss: 0.107776
2023-01-04 13:26: Train Epoch 15: 579/634 Loss: 0.121526
2023-01-04 13:26: Train Epoch 15: 583/634 Loss: 0.150461
2023-01-04 13:26: Train Epoch 15: 587/634 Loss: 0.121380
2023-01-04 13:26: Train Epoch 15: 591/634 Loss: 0.160614
2023-01-04 13:26: Train Epoch 15: 595/634 Loss: 0.121257
2023-01-04 13:26: Train Epoch 15: 599/634 Loss: 0.145371
2023-01-04 13:26: Train Epoch 15: 603/634 Loss: 0.116271
2023-01-04 13:26: Train Epoch 15: 607/634 Loss: 0.139264
2023-01-04 13:26: Train Epoch 15: 611/634 Loss: 0.138650
2023-01-04 13:26: Train Epoch 15: 615/634 Loss: 0.120374
2023-01-04 13:26: Train Epoch 15: 619/634 Loss: 0.139411
2023-01-04 13:26: Train Epoch 15: 623/634 Loss: 0.121994
2023-01-04 13:27: Train Epoch 15: 627/634 Loss: 0.119882
2023-01-04 13:27: Train Epoch 15: 631/634 Loss: 0.126502
2023-01-04 13:27: Train Epoch 15: 633/634 Loss: 0.036230
2023-01-04 13:27: **********Train Epoch 15: averaged Loss: 0.129071 
2023-01-04 13:27: 
Epoch time elapsed: 347.59561228752136

2023-01-04 13:27: 
 metrics validation: {'precision': 0.7809878844361603, 'recall': 0.6446153846153846, 'f1-score': 0.7062789717656974, 'support': 1300, 'AUC': 0.89311775147929, 'AUCPR': 0.8107922055054236, 'TP': 838, 'FP': 235, 'TN': 2365, 'FN': 462} 

2023-01-04 13:27: **********Val Epoch 15: average Loss: 0.207583
2023-01-04 13:27: 
 Testing metrics {'precision': 0.8329741379310345, 'recall': 0.6294788273615635, 'f1-score': 0.7170686456400741, 'support': 1228, 'AUC': 0.9019396094388269, 'AUCPR': 0.8433225215142268, 'TP': 773, 'FP': 155, 'TN': 2301, 'FN': 455} 

2023-01-04 13:28: 
 Testing metrics {'precision': 0.9115708115480791, 'recall': 0.9099160426594055, 'f1-score': 0.9107426754485578, 'support': 4407, 'AUC': 0.9797061130082207, 'AUCPR': 0.9645600234874565, 'TP': 4010, 'FP': 389, 'TN': 8425, 'FN': 397} 

2023-01-04 13:28: Train Epoch 16: 3/634 Loss: 0.129020
2023-01-04 13:28: Train Epoch 16: 7/634 Loss: 0.144620
2023-01-04 13:28: Train Epoch 16: 11/634 Loss: 0.167252
2023-01-04 13:28: Train Epoch 16: 15/634 Loss: 0.129577
2023-01-04 13:28: Train Epoch 16: 19/634 Loss: 0.139786
2023-01-04 13:28: Train Epoch 16: 23/634 Loss: 0.112970
2023-01-04 13:28: Train Epoch 16: 27/634 Loss: 0.132906
2023-01-04 13:28: Train Epoch 16: 31/634 Loss: 0.132832
2023-01-04 13:28: Train Epoch 16: 35/634 Loss: 0.117429
2023-01-04 13:28: Train Epoch 16: 39/634 Loss: 0.113300
2023-01-04 13:28: Train Epoch 16: 43/634 Loss: 0.126130
2023-01-04 13:28: Train Epoch 16: 47/634 Loss: 0.152473
2023-01-04 13:28: Train Epoch 16: 51/634 Loss: 0.103954
2023-01-04 13:28: Train Epoch 16: 55/634 Loss: 0.156514
2023-01-04 13:28: Train Epoch 16: 59/634 Loss: 0.122842
2023-01-04 13:28: Train Epoch 16: 63/634 Loss: 0.129077
2023-01-04 13:28: Train Epoch 16: 67/634 Loss: 0.146356
2023-01-04 13:28: Train Epoch 16: 71/634 Loss: 0.155345
2023-01-04 13:29: Train Epoch 16: 75/634 Loss: 0.142709
2023-01-04 13:29: Train Epoch 16: 79/634 Loss: 0.147603
2023-01-04 13:29: Train Epoch 16: 83/634 Loss: 0.129958
2023-01-04 13:29: Train Epoch 16: 87/634 Loss: 0.130550
2023-01-04 13:29: Train Epoch 16: 91/634 Loss: 0.139829
2023-01-04 13:29: Train Epoch 16: 95/634 Loss: 0.139509
2023-01-04 13:29: Train Epoch 16: 99/634 Loss: 0.139252
2023-01-04 13:29: Train Epoch 16: 103/634 Loss: 0.143945
2023-01-04 13:29: Train Epoch 16: 107/634 Loss: 0.122141
2023-01-04 13:29: Train Epoch 16: 111/634 Loss: 0.120047
2023-01-04 13:29: Train Epoch 16: 115/634 Loss: 0.116923
2023-01-04 13:29: Train Epoch 16: 119/634 Loss: 0.141129
2023-01-04 13:29: Train Epoch 16: 123/634 Loss: 0.161996
2023-01-04 13:29: Train Epoch 16: 127/634 Loss: 0.117085
2023-01-04 13:29: Train Epoch 16: 131/634 Loss: 0.110907
2023-01-04 13:29: Train Epoch 16: 135/634 Loss: 0.123769
2023-01-04 13:29: Train Epoch 16: 139/634 Loss: 0.105222
2023-01-04 13:29: Train Epoch 16: 143/634 Loss: 0.127418
2023-01-04 13:29: Train Epoch 16: 147/634 Loss: 0.113008
2023-01-04 13:29: Train Epoch 16: 151/634 Loss: 0.133576
2023-01-04 13:29: Train Epoch 16: 155/634 Loss: 0.119267
2023-01-04 13:29: Train Epoch 16: 159/634 Loss: 0.131697
2023-01-04 13:29: Train Epoch 16: 163/634 Loss: 0.125434
2023-01-04 13:29: Train Epoch 16: 167/634 Loss: 0.136652
2023-01-04 13:29: Train Epoch 16: 171/634 Loss: 0.134444
2023-01-04 13:29: Train Epoch 16: 175/634 Loss: 0.126398
2023-01-04 13:29: Train Epoch 16: 179/634 Loss: 0.138166
2023-01-04 13:30: Train Epoch 16: 183/634 Loss: 0.118054
2023-01-04 13:30: Train Epoch 16: 187/634 Loss: 0.130377
2023-01-04 13:30: Train Epoch 16: 191/634 Loss: 0.134073
2023-01-04 13:30: Train Epoch 16: 195/634 Loss: 0.090045
2023-01-04 13:30: Train Epoch 16: 199/634 Loss: 0.117737
2023-01-04 13:30: Train Epoch 16: 203/634 Loss: 0.139915
2023-01-04 13:30: Train Epoch 16: 207/634 Loss: 0.091411
2023-01-04 13:30: Train Epoch 16: 211/634 Loss: 0.149333
2023-01-04 13:30: Train Epoch 16: 215/634 Loss: 0.142434
2023-01-04 13:30: Train Epoch 16: 219/634 Loss: 0.141509
2023-01-04 13:30: Train Epoch 16: 223/634 Loss: 0.109065
2023-01-04 13:30: Train Epoch 16: 227/634 Loss: 0.123745
2023-01-04 13:30: Train Epoch 16: 231/634 Loss: 0.131810
2023-01-04 13:30: Train Epoch 16: 235/634 Loss: 0.150395
2023-01-04 13:30: Train Epoch 16: 239/634 Loss: 0.125565
2023-01-04 13:30: Train Epoch 16: 243/634 Loss: 0.132738
2023-01-04 13:30: Train Epoch 16: 247/634 Loss: 0.130265
2023-01-04 13:30: Train Epoch 16: 251/634 Loss: 0.130034
2023-01-04 13:30: Train Epoch 16: 255/634 Loss: 0.143135
2023-01-04 13:30: Train Epoch 16: 259/634 Loss: 0.147601
2023-01-04 13:30: Train Epoch 16: 263/634 Loss: 0.139161
2023-01-04 13:30: Train Epoch 16: 267/634 Loss: 0.160935
2023-01-04 13:30: Train Epoch 16: 271/634 Loss: 0.129586
2023-01-04 13:30: Train Epoch 16: 275/634 Loss: 0.146199
2023-01-04 13:30: Train Epoch 16: 279/634 Loss: 0.163385
2023-01-04 13:30: Train Epoch 16: 283/634 Loss: 0.136596
2023-01-04 13:30: Train Epoch 16: 287/634 Loss: 0.113831
2023-01-04 13:31: Train Epoch 16: 291/634 Loss: 0.149307
2023-01-04 13:31: Train Epoch 16: 295/634 Loss: 0.140870
2023-01-04 13:31: Train Epoch 16: 299/634 Loss: 0.152753
2023-01-04 13:31: Train Epoch 16: 303/634 Loss: 0.170170
2023-01-04 13:31: Train Epoch 16: 307/634 Loss: 0.134177
2023-01-04 13:31: Train Epoch 16: 311/634 Loss: 0.110209
2023-01-04 13:31: Train Epoch 16: 315/634 Loss: 0.128201
2023-01-04 13:31: Train Epoch 16: 319/634 Loss: 0.113974
2023-01-04 13:31: Train Epoch 16: 323/634 Loss: 0.152138
2023-01-04 13:31: Train Epoch 16: 327/634 Loss: 0.132508
2023-01-04 13:31: Train Epoch 16: 331/634 Loss: 0.142025
2023-01-04 13:31: Train Epoch 16: 335/634 Loss: 0.137982
2023-01-04 13:31: Train Epoch 16: 339/634 Loss: 0.140153
2023-01-04 13:31: Train Epoch 16: 343/634 Loss: 0.128343
2023-01-04 13:31: Train Epoch 16: 347/634 Loss: 0.128498
2023-01-04 13:31: Train Epoch 16: 351/634 Loss: 0.126960
2023-01-04 13:31: Train Epoch 16: 355/634 Loss: 0.159669
2023-01-04 13:31: Train Epoch 16: 359/634 Loss: 0.159317
2023-01-04 13:31: Train Epoch 16: 363/634 Loss: 0.161285
2023-01-04 13:31: Train Epoch 16: 367/634 Loss: 0.148586
2023-01-04 13:31: Train Epoch 16: 371/634 Loss: 0.132904
2023-01-04 13:31: Train Epoch 16: 375/634 Loss: 0.123414
2023-01-04 13:31: Train Epoch 16: 379/634 Loss: 0.113898
2023-01-04 13:31: Train Epoch 16: 383/634 Loss: 0.140632
2023-01-04 13:31: Train Epoch 16: 387/634 Loss: 0.122842
2023-01-04 13:31: Train Epoch 16: 391/634 Loss: 0.106018
2023-01-04 13:31: Train Epoch 16: 395/634 Loss: 0.112360
2023-01-04 13:32: Train Epoch 16: 399/634 Loss: 0.122392
2023-01-04 13:32: Train Epoch 16: 403/634 Loss: 0.110288
2023-01-04 13:32: Train Epoch 16: 407/634 Loss: 0.138723
2023-01-04 13:32: Train Epoch 16: 411/634 Loss: 0.130241
2023-01-04 13:32: Train Epoch 16: 415/634 Loss: 0.120094
2023-01-04 13:32: Train Epoch 16: 419/634 Loss: 0.183688
2023-01-04 13:32: Train Epoch 16: 423/634 Loss: 0.149988
2023-01-04 13:32: Train Epoch 16: 427/634 Loss: 0.116530
2023-01-04 13:32: Train Epoch 16: 431/634 Loss: 0.150661
2023-01-04 13:32: Train Epoch 16: 435/634 Loss: 0.145605
2023-01-04 13:32: Train Epoch 16: 439/634 Loss: 0.112576
2023-01-04 13:32: Train Epoch 16: 443/634 Loss: 0.132592
2023-01-04 13:32: Train Epoch 16: 447/634 Loss: 0.109321
2023-01-04 13:32: Train Epoch 16: 451/634 Loss: 0.124633
2023-01-04 13:32: Train Epoch 16: 455/634 Loss: 0.120689
2023-01-04 13:32: Train Epoch 16: 459/634 Loss: 0.137976
2023-01-04 13:32: Train Epoch 16: 463/634 Loss: 0.106252
2023-01-04 13:32: Train Epoch 16: 467/634 Loss: 0.139721
2023-01-04 13:32: Train Epoch 16: 471/634 Loss: 0.133780
2023-01-04 13:32: Train Epoch 16: 475/634 Loss: 0.129438
2023-01-04 13:32: Train Epoch 16: 479/634 Loss: 0.138478
2023-01-04 13:32: Train Epoch 16: 483/634 Loss: 0.121137
2023-01-04 13:32: Train Epoch 16: 487/634 Loss: 0.117712
2023-01-04 13:32: Train Epoch 16: 491/634 Loss: 0.113444
2023-01-04 13:32: Train Epoch 16: 495/634 Loss: 0.144389
2023-01-04 13:32: Train Epoch 16: 499/634 Loss: 0.124182
2023-01-04 13:32: Train Epoch 16: 503/634 Loss: 0.132843
2023-01-04 13:32: Train Epoch 16: 507/634 Loss: 0.146458
2023-01-04 13:33: Train Epoch 16: 511/634 Loss: 0.114238
2023-01-04 13:33: Train Epoch 16: 515/634 Loss: 0.121254
2023-01-04 13:33: Train Epoch 16: 519/634 Loss: 0.111056
2023-01-04 13:33: Train Epoch 16: 523/634 Loss: 0.128929
2023-01-04 13:33: Train Epoch 16: 527/634 Loss: 0.115798
2023-01-04 13:33: Train Epoch 16: 531/634 Loss: 0.115666
2023-01-04 13:33: Train Epoch 16: 535/634 Loss: 0.102514
2023-01-04 13:33: Train Epoch 16: 539/634 Loss: 0.080372
2023-01-04 13:33: Train Epoch 16: 543/634 Loss: 0.141184
2023-01-04 13:33: Train Epoch 16: 547/634 Loss: 0.116855
2023-01-04 13:33: Train Epoch 16: 551/634 Loss: 0.102677
2023-01-04 13:33: Train Epoch 16: 555/634 Loss: 0.101181
2023-01-04 13:33: Train Epoch 16: 559/634 Loss: 0.110273
2023-01-04 13:33: Train Epoch 16: 563/634 Loss: 0.119058
2023-01-04 13:33: Train Epoch 16: 567/634 Loss: 0.129001
2023-01-04 13:33: Train Epoch 16: 571/634 Loss: 0.142439
2023-01-04 13:33: Train Epoch 16: 575/634 Loss: 0.128616
2023-01-04 13:33: Train Epoch 16: 579/634 Loss: 0.156586
2023-01-04 13:33: Train Epoch 16: 583/634 Loss: 0.144066
2023-01-04 13:33: Train Epoch 16: 587/634 Loss: 0.137811
2023-01-04 13:33: Train Epoch 16: 591/634 Loss: 0.091826
2023-01-04 13:33: Train Epoch 16: 595/634 Loss: 0.127414
2023-01-04 13:33: Train Epoch 16: 599/634 Loss: 0.123934
2023-01-04 13:33: Train Epoch 16: 603/634 Loss: 0.109648
2023-01-04 13:33: Train Epoch 16: 607/634 Loss: 0.156099
2023-01-04 13:33: Train Epoch 16: 611/634 Loss: 0.142239
2023-01-04 13:33: Train Epoch 16: 615/634 Loss: 0.120710
2023-01-04 13:34: Train Epoch 16: 619/634 Loss: 0.104909
2023-01-04 13:34: Train Epoch 16: 623/634 Loss: 0.124876
2023-01-04 13:34: Train Epoch 16: 627/634 Loss: 0.113757
2023-01-04 13:34: Train Epoch 16: 631/634 Loss: 0.139289
2023-01-04 13:34: Train Epoch 16: 633/634 Loss: 0.041653
2023-01-04 13:34: **********Train Epoch 16: averaged Loss: 0.129804 
2023-01-04 13:34: 
Epoch time elapsed: 349.65918135643005

2023-01-04 13:34: 
 metrics validation: {'precision': 0.7777777777777778, 'recall': 0.6407692307692308, 'f1-score': 0.7026571067060311, 'support': 1300, 'AUC': 0.8871066568047338, 'AUCPR': 0.8048549228632087, 'TP': 833, 'FP': 238, 'TN': 2362, 'FN': 467} 

2023-01-04 13:34: **********Val Epoch 16: average Loss: 0.220535
2023-01-04 13:34: 
 Testing metrics {'precision': 0.8329741379310345, 'recall': 0.6294788273615635, 'f1-score': 0.7170686456400741, 'support': 1228, 'AUC': 0.9019396094388269, 'AUCPR': 0.8433225215142268, 'TP': 773, 'FP': 155, 'TN': 2301, 'FN': 455} 

2023-01-04 13:35: 
 Testing metrics {'precision': 0.9115708115480791, 'recall': 0.9099160426594055, 'f1-score': 0.9107426754485578, 'support': 4407, 'AUC': 0.9797061130082207, 'AUCPR': 0.9645600234874565, 'TP': 4010, 'FP': 389, 'TN': 8425, 'FN': 397} 

2023-01-04 13:35: Train Epoch 17: 3/634 Loss: 0.130993
2023-01-04 13:35: Train Epoch 17: 7/634 Loss: 0.108785
2023-01-04 13:35: Train Epoch 17: 11/634 Loss: 0.131964
2023-01-04 13:35: Train Epoch 17: 15/634 Loss: 0.138013
2023-01-04 13:35: Train Epoch 17: 19/634 Loss: 0.117864
2023-01-04 13:35: Train Epoch 17: 23/634 Loss: 0.146978
2023-01-04 13:35: Train Epoch 17: 27/634 Loss: 0.104479
2023-01-04 13:35: Train Epoch 17: 31/634 Loss: 0.132302
2023-01-04 13:35: Train Epoch 17: 35/634 Loss: 0.121928
2023-01-04 13:35: Train Epoch 17: 39/634 Loss: 0.114197
2023-01-04 13:35: Train Epoch 17: 43/634 Loss: 0.130097
2023-01-04 13:35: Train Epoch 17: 47/634 Loss: 0.117762
2023-01-04 13:35: Train Epoch 17: 51/634 Loss: 0.168980
2023-01-04 13:35: Train Epoch 17: 55/634 Loss: 0.114614
2023-01-04 13:35: Train Epoch 17: 59/634 Loss: 0.133074
2023-01-04 13:36: Train Epoch 17: 63/634 Loss: 0.130127
2023-01-04 13:36: Train Epoch 17: 67/634 Loss: 0.167535
2023-01-04 13:36: Train Epoch 17: 71/634 Loss: 0.154584
2023-01-04 13:36: Train Epoch 17: 75/634 Loss: 0.120141
2023-01-04 13:36: Train Epoch 17: 79/634 Loss: 0.117941
2023-01-04 13:36: Train Epoch 17: 83/634 Loss: 0.124661
2023-01-04 13:36: Train Epoch 17: 87/634 Loss: 0.155540
2023-01-04 13:36: Train Epoch 17: 91/634 Loss: 0.115057
2023-01-04 13:36: Train Epoch 17: 95/634 Loss: 0.164141
2023-01-04 13:36: Train Epoch 17: 99/634 Loss: 0.138481
2023-01-04 13:36: Train Epoch 17: 103/634 Loss: 0.113684
2023-01-04 13:36: Train Epoch 17: 107/634 Loss: 0.120094
2023-01-04 13:36: Train Epoch 17: 111/634 Loss: 0.129917
2023-01-04 13:36: Train Epoch 17: 115/634 Loss: 0.149389
2023-01-04 13:36: Train Epoch 17: 119/634 Loss: 0.153776
2023-01-04 13:36: Train Epoch 17: 123/634 Loss: 0.113292
2023-01-04 13:36: Train Epoch 17: 127/634 Loss: 0.135681
2023-01-04 13:36: Train Epoch 17: 131/634 Loss: 0.122290
2023-01-04 13:36: Train Epoch 17: 135/634 Loss: 0.148357
2023-01-04 13:36: Train Epoch 17: 139/634 Loss: 0.133538
2023-01-04 13:36: Train Epoch 17: 143/634 Loss: 0.135412
2023-01-04 13:36: Train Epoch 17: 147/634 Loss: 0.123054
2023-01-04 13:36: Train Epoch 17: 151/634 Loss: 0.120995
2023-01-04 13:36: Train Epoch 17: 155/634 Loss: 0.142478
2023-01-04 13:36: Train Epoch 17: 159/634 Loss: 0.096142
2023-01-04 13:36: Train Epoch 17: 163/634 Loss: 0.121079
2023-01-04 13:36: Train Epoch 17: 167/634 Loss: 0.134380
2023-01-04 13:36: Train Epoch 17: 171/634 Loss: 0.129371
2023-01-04 13:37: Train Epoch 17: 175/634 Loss: 0.133838
2023-01-04 13:37: Train Epoch 17: 179/634 Loss: 0.120231
2023-01-04 13:37: Train Epoch 17: 183/634 Loss: 0.133072
2023-01-04 13:37: Train Epoch 17: 187/634 Loss: 0.122685
2023-01-04 13:37: Train Epoch 17: 191/634 Loss: 0.138777
2023-01-04 13:37: Train Epoch 17: 195/634 Loss: 0.136105
2023-01-04 13:37: Train Epoch 17: 199/634 Loss: 0.134762
2023-01-04 13:37: Train Epoch 17: 203/634 Loss: 0.118845
2023-01-04 13:37: Train Epoch 17: 207/634 Loss: 0.124242
2023-01-04 13:37: Train Epoch 17: 211/634 Loss: 0.118298
2023-01-04 13:37: Train Epoch 17: 215/634 Loss: 0.143540
2023-01-04 13:37: Train Epoch 17: 219/634 Loss: 0.136866
2023-01-04 13:37: Train Epoch 17: 223/634 Loss: 0.117302
2023-01-04 13:37: Train Epoch 17: 227/634 Loss: 0.129122
2023-01-04 13:37: Train Epoch 17: 231/634 Loss: 0.130274
2023-01-04 13:37: Train Epoch 17: 235/634 Loss: 0.142305
2023-01-04 13:37: Train Epoch 17: 239/634 Loss: 0.152614
2023-01-04 13:37: Train Epoch 17: 243/634 Loss: 0.134196
2023-01-04 13:37: Train Epoch 17: 247/634 Loss: 0.119925
2023-01-04 13:37: Train Epoch 17: 251/634 Loss: 0.152319
2023-01-04 13:37: Train Epoch 17: 255/634 Loss: 0.120654
2023-01-04 13:37: Train Epoch 17: 259/634 Loss: 0.114967
2023-01-04 13:37: Train Epoch 17: 263/634 Loss: 0.130987
2023-01-04 13:37: Train Epoch 17: 267/634 Loss: 0.134502
2023-01-04 13:37: Train Epoch 17: 271/634 Loss: 0.141836
2023-01-04 13:37: Train Epoch 17: 275/634 Loss: 0.128485
2023-01-04 13:37: Train Epoch 17: 279/634 Loss: 0.118970
2023-01-04 13:38: Train Epoch 17: 283/634 Loss: 0.140710
2023-01-04 13:38: Train Epoch 17: 287/634 Loss: 0.121797
2023-01-04 13:38: Train Epoch 17: 291/634 Loss: 0.133972
2023-01-04 13:38: Train Epoch 17: 295/634 Loss: 0.116898
2023-01-04 13:38: Train Epoch 17: 299/634 Loss: 0.153111
2023-01-04 13:38: Train Epoch 17: 303/634 Loss: 0.153351
2023-01-04 13:38: Train Epoch 17: 307/634 Loss: 0.131777
2023-01-04 13:38: Train Epoch 17: 311/634 Loss: 0.111277
2023-01-04 13:38: Train Epoch 17: 315/634 Loss: 0.092115
2023-01-04 13:38: Train Epoch 17: 319/634 Loss: 0.115593
2023-01-04 13:38: Train Epoch 17: 323/634 Loss: 0.121345
2023-01-04 13:38: Train Epoch 17: 327/634 Loss: 0.130195
2023-01-04 13:38: Train Epoch 17: 331/634 Loss: 0.131160
2023-01-04 13:38: Train Epoch 17: 335/634 Loss: 0.159451
2023-01-04 13:38: Train Epoch 17: 339/634 Loss: 0.118796
2023-01-04 13:38: Train Epoch 17: 343/634 Loss: 0.104885
2023-01-04 13:38: Train Epoch 17: 347/634 Loss: 0.130643
2023-01-04 13:38: Train Epoch 17: 351/634 Loss: 0.124218
2023-01-04 13:38: Train Epoch 17: 355/634 Loss: 0.119366
2023-01-04 13:38: Train Epoch 17: 359/634 Loss: 0.097604
2023-01-04 13:38: Train Epoch 17: 363/634 Loss: 0.114488
2023-01-04 13:38: Train Epoch 17: 367/634 Loss: 0.168943
2023-01-04 13:38: Train Epoch 17: 371/634 Loss: 0.140160
2023-01-04 13:38: Train Epoch 17: 375/634 Loss: 0.122222
2023-01-04 13:38: Train Epoch 17: 379/634 Loss: 0.122534
2023-01-04 13:38: Train Epoch 17: 383/634 Loss: 0.124498
2023-01-04 13:38: Train Epoch 17: 387/634 Loss: 0.147756
2023-01-04 13:39: Train Epoch 17: 391/634 Loss: 0.127326
2023-01-04 13:39: Train Epoch 17: 395/634 Loss: 0.116136
2023-01-04 13:39: Train Epoch 17: 399/634 Loss: 0.125528
2023-01-04 13:39: Train Epoch 17: 403/634 Loss: 0.118621
2023-01-04 13:39: Train Epoch 17: 407/634 Loss: 0.097421
2023-01-04 13:39: Train Epoch 17: 411/634 Loss: 0.134752
2023-01-04 13:39: Train Epoch 17: 415/634 Loss: 0.120065
2023-01-04 13:39: Train Epoch 17: 419/634 Loss: 0.136479
2023-01-04 13:39: Train Epoch 17: 423/634 Loss: 0.144244
2023-01-04 13:39: Train Epoch 17: 427/634 Loss: 0.150693
2023-01-04 13:39: Train Epoch 17: 431/634 Loss: 0.143223
2023-01-04 13:39: Train Epoch 17: 435/634 Loss: 0.139406
2023-01-04 13:39: Train Epoch 17: 439/634 Loss: 0.149151
2023-01-04 13:39: Train Epoch 17: 443/634 Loss: 0.111032
2023-01-04 13:39: Train Epoch 17: 447/634 Loss: 0.142836
2023-01-04 13:39: Train Epoch 17: 451/634 Loss: 0.123537
2023-01-04 13:39: Train Epoch 17: 455/634 Loss: 0.128366
2023-01-04 13:39: Train Epoch 17: 459/634 Loss: 0.170599
2023-01-04 13:39: Train Epoch 17: 463/634 Loss: 0.137469
2023-01-04 13:39: Train Epoch 17: 467/634 Loss: 0.146768
2023-01-04 13:39: Train Epoch 17: 471/634 Loss: 0.158699
2023-01-04 13:39: Train Epoch 17: 475/634 Loss: 0.129259
2023-01-04 13:39: Train Epoch 17: 479/634 Loss: 0.162309
2023-01-04 13:39: Train Epoch 17: 483/634 Loss: 0.142551
2023-01-04 13:39: Train Epoch 17: 487/634 Loss: 0.152625
2023-01-04 13:39: Train Epoch 17: 491/634 Loss: 0.148767
2023-01-04 13:39: Train Epoch 17: 495/634 Loss: 0.124965
2023-01-04 13:39: Train Epoch 17: 499/634 Loss: 0.153350
2023-01-04 13:40: Train Epoch 17: 503/634 Loss: 0.123720
2023-01-04 13:40: Train Epoch 17: 507/634 Loss: 0.116173
2023-01-04 13:40: Train Epoch 17: 511/634 Loss: 0.118693
2023-01-04 13:40: Train Epoch 17: 515/634 Loss: 0.135865
2023-01-04 13:40: Train Epoch 17: 519/634 Loss: 0.163867
2023-01-04 13:40: Train Epoch 17: 523/634 Loss: 0.143151
2023-01-04 13:40: Train Epoch 17: 527/634 Loss: 0.112079
2023-01-04 13:40: Train Epoch 17: 531/634 Loss: 0.151586
2023-01-04 13:40: Train Epoch 17: 535/634 Loss: 0.129947
2023-01-04 13:40: Train Epoch 17: 539/634 Loss: 0.129183
2023-01-04 13:40: Train Epoch 17: 543/634 Loss: 0.128692
2023-01-04 13:40: Train Epoch 17: 547/634 Loss: 0.110458
2023-01-04 13:40: Train Epoch 17: 551/634 Loss: 0.107136
2023-01-04 13:40: Train Epoch 17: 555/634 Loss: 0.114948
2023-01-04 13:40: Train Epoch 17: 559/634 Loss: 0.118982
2023-01-04 13:40: Train Epoch 17: 563/634 Loss: 0.121611
2023-01-04 13:40: Train Epoch 17: 567/634 Loss: 0.140962
2023-01-04 13:40: Train Epoch 17: 571/634 Loss: 0.097667
2023-01-04 13:40: Train Epoch 17: 575/634 Loss: 0.131528
2023-01-04 13:40: Train Epoch 17: 579/634 Loss: 0.139581
2023-01-04 13:40: Train Epoch 17: 583/634 Loss: 0.098188
2023-01-04 13:40: Train Epoch 17: 587/634 Loss: 0.102328
2023-01-04 13:40: Train Epoch 17: 591/634 Loss: 0.138598
2023-01-04 13:40: Train Epoch 17: 595/634 Loss: 0.160959
2023-01-04 13:40: Train Epoch 17: 599/634 Loss: 0.141865
2023-01-04 13:40: Train Epoch 17: 603/634 Loss: 0.126593
2023-01-04 13:40: Train Epoch 17: 607/634 Loss: 0.129379
2023-01-04 13:41: Train Epoch 17: 611/634 Loss: 0.154659
2023-01-04 13:41: Train Epoch 17: 615/634 Loss: 0.119256
2023-01-04 13:41: Train Epoch 17: 619/634 Loss: 0.098526
2023-01-04 13:41: Train Epoch 17: 623/634 Loss: 0.113367
2023-01-04 13:41: Train Epoch 17: 627/634 Loss: 0.123566
2023-01-04 13:41: Train Epoch 17: 631/634 Loss: 0.128705
2023-01-04 13:41: Train Epoch 17: 633/634 Loss: 0.062662
2023-01-04 13:41: **********Train Epoch 17: averaged Loss: 0.130015 
2023-01-04 13:41: 
Epoch time elapsed: 347.38941073417664

2023-01-04 13:41: 
 metrics validation: {'precision': 0.7617021276595745, 'recall': 0.6884615384615385, 'f1-score': 0.7232323232323233, 'support': 1300, 'AUC': 0.8903088757396449, 'AUCPR': 0.8098672186989728, 'TP': 895, 'FP': 280, 'TN': 2320, 'FN': 405} 

2023-01-04 13:41: **********Val Epoch 17: average Loss: 0.208480
2023-01-04 13:41: 
 Testing metrics {'precision': 0.8329741379310345, 'recall': 0.6294788273615635, 'f1-score': 0.7170686456400741, 'support': 1228, 'AUC': 0.9019396094388269, 'AUCPR': 0.8433225215142268, 'TP': 773, 'FP': 155, 'TN': 2301, 'FN': 455} 

2023-01-04 13:42: 
 Testing metrics {'precision': 0.9115708115480791, 'recall': 0.9099160426594055, 'f1-score': 0.9107426754485578, 'support': 4407, 'AUC': 0.9797061130082207, 'AUCPR': 0.9645600234874565, 'TP': 4010, 'FP': 389, 'TN': 8425, 'FN': 397} 

2023-01-04 13:42: Train Epoch 18: 3/634 Loss: 0.110404
2023-01-04 13:42: Train Epoch 18: 7/634 Loss: 0.111616
2023-01-04 13:42: Train Epoch 18: 11/634 Loss: 0.145839
2023-01-04 13:42: Train Epoch 18: 15/634 Loss: 0.142797
2023-01-04 13:42: Train Epoch 18: 19/634 Loss: 0.151374
2023-01-04 13:42: Train Epoch 18: 23/634 Loss: 0.147799
2023-01-04 13:42: Train Epoch 18: 27/634 Loss: 0.117070
2023-01-04 13:42: Train Epoch 18: 31/634 Loss: 0.125108
2023-01-04 13:42: Train Epoch 18: 35/634 Loss: 0.136846
2023-01-04 13:42: Train Epoch 18: 39/634 Loss: 0.121242
2023-01-04 13:42: Train Epoch 18: 43/634 Loss: 0.123906
2023-01-04 13:42: Train Epoch 18: 47/634 Loss: 0.117741
2023-01-04 13:42: Train Epoch 18: 51/634 Loss: 0.133678
2023-01-04 13:42: Train Epoch 18: 55/634 Loss: 0.146086
2023-01-04 13:42: Train Epoch 18: 59/634 Loss: 0.153641
2023-01-04 13:43: Train Epoch 18: 63/634 Loss: 0.133072
2023-01-04 13:43: Train Epoch 18: 67/634 Loss: 0.148447
2023-01-04 13:43: Train Epoch 18: 71/634 Loss: 0.120448
2023-01-04 13:43: Train Epoch 18: 75/634 Loss: 0.128588
2023-01-04 13:43: Train Epoch 18: 79/634 Loss: 0.133712
2023-01-04 13:43: Train Epoch 18: 83/634 Loss: 0.145304
2023-01-04 13:43: Train Epoch 18: 87/634 Loss: 0.145335
2023-01-04 13:43: Train Epoch 18: 91/634 Loss: 0.143989
2023-01-04 13:43: Train Epoch 18: 95/634 Loss: 0.128212
2023-01-04 13:43: Train Epoch 18: 99/634 Loss: 0.114332
2023-01-04 13:43: Train Epoch 18: 103/634 Loss: 0.125328
2023-01-04 13:43: Train Epoch 18: 107/634 Loss: 0.125045
2023-01-04 13:43: Train Epoch 18: 111/634 Loss: 0.112192
2023-01-04 13:43: Train Epoch 18: 115/634 Loss: 0.102267
2023-01-04 13:43: Train Epoch 18: 119/634 Loss: 0.148554
2023-01-04 13:43: Train Epoch 18: 123/634 Loss: 0.115328
2023-01-04 13:43: Train Epoch 18: 127/634 Loss: 0.151235
2023-01-04 13:43: Train Epoch 18: 131/634 Loss: 0.120024
2023-01-04 13:43: Train Epoch 18: 135/634 Loss: 0.147162
2023-01-04 13:43: Train Epoch 18: 139/634 Loss: 0.103818
2023-01-04 13:43: Train Epoch 18: 143/634 Loss: 0.141129
2023-01-04 13:43: Train Epoch 18: 147/634 Loss: 0.123191
2023-01-04 13:43: Train Epoch 18: 151/634 Loss: 0.125453
2023-01-04 13:43: Train Epoch 18: 155/634 Loss: 0.124852
2023-01-04 13:43: Train Epoch 18: 159/634 Loss: 0.116044
2023-01-04 13:43: Train Epoch 18: 163/634 Loss: 0.120348
2023-01-04 13:43: Train Epoch 18: 167/634 Loss: 0.141089
2023-01-04 13:44: Train Epoch 18: 171/634 Loss: 0.152174
2023-01-04 13:44: Train Epoch 18: 175/634 Loss: 0.104113
2023-01-04 13:44: Train Epoch 18: 179/634 Loss: 0.122854
2023-01-04 13:44: Train Epoch 18: 183/634 Loss: 0.124620
2023-01-04 13:44: Train Epoch 18: 187/634 Loss: 0.139547
2023-01-04 13:44: Train Epoch 18: 191/634 Loss: 0.134985
2023-01-04 13:44: Train Epoch 18: 195/634 Loss: 0.120714
2023-01-04 13:44: Train Epoch 18: 199/634 Loss: 0.129771
2023-01-04 13:44: Train Epoch 18: 203/634 Loss: 0.144268
2023-01-04 13:44: Train Epoch 18: 207/634 Loss: 0.102114
2023-01-04 13:44: Train Epoch 18: 211/634 Loss: 0.135857
2023-01-04 13:44: Train Epoch 18: 215/634 Loss: 0.133638
2023-01-04 13:44: Train Epoch 18: 219/634 Loss: 0.154622
2023-01-04 13:44: Train Epoch 18: 223/634 Loss: 0.116031
2023-01-04 13:44: Train Epoch 18: 227/634 Loss: 0.126976
2023-01-04 13:44: Train Epoch 18: 231/634 Loss: 0.147748
2023-01-04 13:44: Train Epoch 18: 235/634 Loss: 0.130182
2023-01-04 13:44: Train Epoch 18: 239/634 Loss: 0.111257
2023-01-04 13:44: Train Epoch 18: 243/634 Loss: 0.078210
2023-01-04 13:44: Train Epoch 18: 247/634 Loss: 0.129764
2023-01-04 13:44: Train Epoch 18: 251/634 Loss: 0.098850
2023-01-04 13:44: Train Epoch 18: 255/634 Loss: 0.114792
2023-01-04 13:44: Train Epoch 18: 259/634 Loss: 0.147576
2023-01-04 13:44: Train Epoch 18: 263/634 Loss: 0.157370
2023-01-04 13:44: Train Epoch 18: 267/634 Loss: 0.145093
2023-01-04 13:44: Train Epoch 18: 271/634 Loss: 0.178891
2023-01-04 13:44: Train Epoch 18: 275/634 Loss: 0.117074
2023-01-04 13:44: Train Epoch 18: 279/634 Loss: 0.154851
2023-01-04 13:45: Train Epoch 18: 283/634 Loss: 0.159558
2023-01-04 13:45: Train Epoch 18: 287/634 Loss: 0.126774
2023-01-04 13:45: Train Epoch 18: 291/634 Loss: 0.106218
2023-01-04 13:45: Train Epoch 18: 295/634 Loss: 0.127156
2023-01-04 13:45: Train Epoch 18: 299/634 Loss: 0.123516
2023-01-04 13:45: Train Epoch 18: 303/634 Loss: 0.163240
2023-01-04 13:45: Train Epoch 18: 307/634 Loss: 0.117466
2023-01-04 13:45: Train Epoch 18: 311/634 Loss: 0.150404
2023-01-04 13:45: Train Epoch 18: 315/634 Loss: 0.121581
2023-01-04 13:45: Train Epoch 18: 319/634 Loss: 0.102773
2023-01-04 13:45: Train Epoch 18: 323/634 Loss: 0.111052
2023-01-04 13:45: Train Epoch 18: 327/634 Loss: 0.150250
2023-01-04 13:45: Train Epoch 18: 331/634 Loss: 0.141988
2023-01-04 13:45: Train Epoch 18: 335/634 Loss: 0.112352
2023-01-04 13:45: Train Epoch 18: 339/634 Loss: 0.118378
2023-01-04 13:45: Train Epoch 18: 343/634 Loss: 0.103915
2023-01-04 13:45: Train Epoch 18: 347/634 Loss: 0.120790
2023-01-04 13:45: Train Epoch 18: 351/634 Loss: 0.108576
2023-01-04 13:45: Train Epoch 18: 355/634 Loss: 0.125730
2023-01-04 13:45: Train Epoch 18: 359/634 Loss: 0.146621
2023-01-04 13:45: Train Epoch 18: 363/634 Loss: 0.120026
2023-01-04 13:45: Train Epoch 18: 367/634 Loss: 0.105665
2023-01-04 13:45: Train Epoch 18: 371/634 Loss: 0.140284
2023-01-04 13:45: Train Epoch 18: 375/634 Loss: 0.115940
2023-01-04 13:45: Train Epoch 18: 379/634 Loss: 0.137058
2023-01-04 13:45: Train Epoch 18: 383/634 Loss: 0.104212
2023-01-04 13:45: Train Epoch 18: 387/634 Loss: 0.102079
2023-01-04 13:46: Train Epoch 18: 391/634 Loss: 0.139700
2023-01-04 13:46: Train Epoch 18: 395/634 Loss: 0.152334
2023-01-04 13:46: Train Epoch 18: 399/634 Loss: 0.122994
2023-01-04 13:46: Train Epoch 18: 403/634 Loss: 0.100993
2023-01-04 13:46: Train Epoch 18: 407/634 Loss: 0.133463
2023-01-04 13:46: Train Epoch 18: 411/634 Loss: 0.133330
2023-01-04 13:46: Train Epoch 18: 415/634 Loss: 0.160945
2023-01-04 13:46: Train Epoch 18: 419/634 Loss: 0.145575
2023-01-04 13:46: Train Epoch 18: 423/634 Loss: 0.165005
2023-01-04 13:46: Train Epoch 18: 427/634 Loss: 0.137286
2023-01-04 13:46: Train Epoch 18: 431/634 Loss: 0.119206
2023-01-04 13:46: Train Epoch 18: 435/634 Loss: 0.116134
2023-01-04 13:46: Train Epoch 18: 439/634 Loss: 0.151743
2023-01-04 13:46: Train Epoch 18: 443/634 Loss: 0.133753
2023-01-04 13:46: Train Epoch 18: 447/634 Loss: 0.122417
2023-01-04 13:46: Train Epoch 18: 451/634 Loss: 0.157848
2023-01-04 13:46: Train Epoch 18: 455/634 Loss: 0.151899
2023-01-04 13:46: Train Epoch 18: 459/634 Loss: 0.108824
2023-01-04 13:46: Train Epoch 18: 463/634 Loss: 0.121629
2023-01-04 13:46: Train Epoch 18: 467/634 Loss: 0.155544
2023-01-04 13:46: Train Epoch 18: 471/634 Loss: 0.139250
2023-01-04 13:46: Train Epoch 18: 475/634 Loss: 0.159328
2023-01-04 13:46: Train Epoch 18: 479/634 Loss: 0.118791
2023-01-04 13:46: Train Epoch 18: 483/634 Loss: 0.119358
2023-01-04 13:46: Train Epoch 18: 487/634 Loss: 0.141655
2023-01-04 13:46: Train Epoch 18: 491/634 Loss: 0.145359
2023-01-04 13:46: Train Epoch 18: 495/634 Loss: 0.137818
2023-01-04 13:46: Train Epoch 18: 499/634 Loss: 0.116187
2023-01-04 13:47: Train Epoch 18: 503/634 Loss: 0.146029
2023-01-04 13:47: Train Epoch 18: 507/634 Loss: 0.126645
2023-01-04 13:47: Train Epoch 18: 511/634 Loss: 0.096695
2023-01-04 13:47: Train Epoch 18: 515/634 Loss: 0.156771
2023-01-04 13:47: Train Epoch 18: 519/634 Loss: 0.129192
2023-01-04 13:47: Train Epoch 18: 523/634 Loss: 0.093564
2023-01-04 13:47: Train Epoch 18: 527/634 Loss: 0.096036
2023-01-04 13:47: Train Epoch 18: 531/634 Loss: 0.131091
2023-01-04 13:47: Train Epoch 18: 535/634 Loss: 0.142250
2023-01-04 13:47: Train Epoch 18: 539/634 Loss: 0.115543
2023-01-04 13:47: Train Epoch 18: 543/634 Loss: 0.161172
2023-01-04 13:47: Train Epoch 18: 547/634 Loss: 0.104090
2023-01-04 13:47: Train Epoch 18: 551/634 Loss: 0.177027
2023-01-04 13:47: Train Epoch 18: 555/634 Loss: 0.125191
2023-01-04 13:47: Train Epoch 18: 559/634 Loss: 0.136870
2023-01-04 13:47: Train Epoch 18: 563/634 Loss: 0.145147
2023-01-04 13:47: Train Epoch 18: 567/634 Loss: 0.120826
2023-01-04 13:47: Train Epoch 18: 571/634 Loss: 0.130370
2023-01-04 13:47: Train Epoch 18: 575/634 Loss: 0.114671
2023-01-04 13:47: Train Epoch 18: 579/634 Loss: 0.139138
2023-01-04 13:47: Train Epoch 18: 583/634 Loss: 0.107478
2023-01-04 13:47: Train Epoch 18: 587/634 Loss: 0.140328
2023-01-04 13:47: Train Epoch 18: 591/634 Loss: 0.123614
2023-01-04 13:47: Train Epoch 18: 595/634 Loss: 0.132515
2023-01-04 13:47: Train Epoch 18: 599/634 Loss: 0.138091
2023-01-04 13:47: Train Epoch 18: 603/634 Loss: 0.101159
2023-01-04 13:47: Train Epoch 18: 607/634 Loss: 0.117498
2023-01-04 13:48: Train Epoch 18: 611/634 Loss: 0.124551
2023-01-04 13:48: Train Epoch 18: 615/634 Loss: 0.163316
2023-01-04 13:48: Train Epoch 18: 619/634 Loss: 0.145231
2023-01-04 13:48: Train Epoch 18: 623/634 Loss: 0.102327
2023-01-04 13:48: Train Epoch 18: 627/634 Loss: 0.140300
2023-01-04 13:48: Train Epoch 18: 631/634 Loss: 0.148609
2023-01-04 13:48: Train Epoch 18: 633/634 Loss: 0.053905
2023-01-04 13:48: **********Train Epoch 18: averaged Loss: 0.129703 
2023-01-04 13:48: 
Epoch time elapsed: 344.78101658821106

2023-01-04 13:48: 
 metrics validation: {'precision': 0.7924528301886793, 'recall': 0.6138461538461538, 'f1-score': 0.6918075422626787, 'support': 1300, 'AUC': 0.8901559171597634, 'AUCPR': 0.8095274816189596, 'TP': 798, 'FP': 209, 'TN': 2391, 'FN': 502} 

2023-01-04 13:48: **********Val Epoch 18: average Loss: 0.218037
2023-01-04 13:48: 
 Testing metrics {'precision': 0.8329741379310345, 'recall': 0.6294788273615635, 'f1-score': 0.7170686456400741, 'support': 1228, 'AUC': 0.9019396094388269, 'AUCPR': 0.8433225215142268, 'TP': 773, 'FP': 155, 'TN': 2301, 'FN': 455} 

2023-01-04 13:49: 
 Testing metrics {'precision': 0.9115708115480791, 'recall': 0.9099160426594055, 'f1-score': 0.9107426754485578, 'support': 4407, 'AUC': 0.9797061130082207, 'AUCPR': 0.9645600234874565, 'TP': 4010, 'FP': 389, 'TN': 8425, 'FN': 397} 

2023-01-04 13:49: Train Epoch 19: 3/634 Loss: 0.117123
2023-01-04 13:49: Train Epoch 19: 7/634 Loss: 0.143895
2023-01-04 13:49: Train Epoch 19: 11/634 Loss: 0.164293
2023-01-04 13:49: Train Epoch 19: 15/634 Loss: 0.131490
2023-01-04 13:49: Train Epoch 19: 19/634 Loss: 0.111217
2023-01-04 13:49: Train Epoch 19: 23/634 Loss: 0.142905
2023-01-04 13:49: Train Epoch 19: 27/634 Loss: 0.158078
2023-01-04 13:49: Train Epoch 19: 31/634 Loss: 0.128836
2023-01-04 13:49: Train Epoch 19: 35/634 Loss: 0.132235
2023-01-04 13:49: Train Epoch 19: 39/634 Loss: 0.145131
2023-01-04 13:49: Train Epoch 19: 43/634 Loss: 0.095662
2023-01-04 13:49: Train Epoch 19: 47/634 Loss: 0.138866
2023-01-04 13:49: Train Epoch 19: 51/634 Loss: 0.105172
2023-01-04 13:49: Train Epoch 19: 55/634 Loss: 0.157352
2023-01-04 13:50: Train Epoch 19: 59/634 Loss: 0.147774
2023-01-04 13:50: Train Epoch 19: 63/634 Loss: 0.143042
2023-01-04 13:50: Train Epoch 19: 67/634 Loss: 0.122886
2023-01-04 13:50: Train Epoch 19: 71/634 Loss: 0.101592
2023-01-04 13:50: Train Epoch 19: 75/634 Loss: 0.120884
2023-01-04 13:50: Train Epoch 19: 79/634 Loss: 0.129946
2023-01-04 13:50: Train Epoch 19: 83/634 Loss: 0.141965
2023-01-04 13:50: Train Epoch 19: 87/634 Loss: 0.140096
2023-01-04 13:50: Train Epoch 19: 91/634 Loss: 0.110355
2023-01-04 13:50: Train Epoch 19: 95/634 Loss: 0.142634
2023-01-04 13:50: Train Epoch 19: 99/634 Loss: 0.103753
2023-01-04 13:50: Train Epoch 19: 103/634 Loss: 0.171277
2023-01-04 13:50: Train Epoch 19: 107/634 Loss: 0.155768
2023-01-04 13:50: Train Epoch 19: 111/634 Loss: 0.138917
2023-01-04 13:50: Train Epoch 19: 115/634 Loss: 0.119896
2023-01-04 13:50: Train Epoch 19: 119/634 Loss: 0.130867
2023-01-04 13:50: Train Epoch 19: 123/634 Loss: 0.146352
2023-01-04 13:50: Train Epoch 19: 127/634 Loss: 0.146394
2023-01-04 13:50: Train Epoch 19: 131/634 Loss: 0.139581
2023-01-04 13:50: Train Epoch 19: 135/634 Loss: 0.125023
2023-01-04 13:50: Train Epoch 19: 139/634 Loss: 0.119646
2023-01-04 13:50: Train Epoch 19: 143/634 Loss: 0.136589
2023-01-04 13:50: Train Epoch 19: 147/634 Loss: 0.125715
2023-01-04 13:50: Train Epoch 19: 151/634 Loss: 0.105537
2023-01-04 13:50: Train Epoch 19: 155/634 Loss: 0.143561
2023-01-04 13:50: Train Epoch 19: 159/634 Loss: 0.118755
2023-01-04 13:50: Train Epoch 19: 163/634 Loss: 0.132981
2023-01-04 13:50: Train Epoch 19: 167/634 Loss: 0.125286
2023-01-04 13:51: Train Epoch 19: 171/634 Loss: 0.139985
2023-01-04 13:51: Train Epoch 19: 175/634 Loss: 0.119593
2023-01-04 13:51: Train Epoch 19: 179/634 Loss: 0.120222
2023-01-04 13:51: Train Epoch 19: 183/634 Loss: 0.129580
2023-01-04 13:51: Train Epoch 19: 187/634 Loss: 0.151529
2023-01-04 13:51: Train Epoch 19: 191/634 Loss: 0.122678
2023-01-04 13:51: Train Epoch 19: 195/634 Loss: 0.144959
2023-01-04 13:51: Train Epoch 19: 199/634 Loss: 0.118593
2023-01-04 13:51: Train Epoch 19: 203/634 Loss: 0.110112
2023-01-04 13:51: Train Epoch 19: 207/634 Loss: 0.110493
2023-01-04 13:51: Train Epoch 19: 211/634 Loss: 0.163404
2023-01-04 13:51: Train Epoch 19: 215/634 Loss: 0.115453
2023-01-04 13:51: Train Epoch 19: 219/634 Loss: 0.116087
2023-01-04 13:51: Train Epoch 19: 223/634 Loss: 0.139936
2023-01-04 13:51: Train Epoch 19: 227/634 Loss: 0.117610
2023-01-04 13:51: Train Epoch 19: 231/634 Loss: 0.102718
2023-01-04 13:51: Train Epoch 19: 235/634 Loss: 0.096923
2023-01-04 13:51: Train Epoch 19: 239/634 Loss: 0.162131
2023-01-04 13:51: Train Epoch 19: 243/634 Loss: 0.135056
2023-01-04 13:51: Train Epoch 19: 247/634 Loss: 0.102853
2023-01-04 13:51: Train Epoch 19: 251/634 Loss: 0.151235
2023-01-04 13:51: Train Epoch 19: 255/634 Loss: 0.120944
2023-01-04 13:51: Train Epoch 19: 259/634 Loss: 0.109461
2023-01-04 13:51: Train Epoch 19: 263/634 Loss: 0.146392
2023-01-04 13:51: Train Epoch 19: 267/634 Loss: 0.161142
2023-01-04 13:51: Train Epoch 19: 271/634 Loss: 0.139819
2023-01-04 13:51: Train Epoch 19: 275/634 Loss: 0.139821
2023-01-04 13:52: Train Epoch 19: 279/634 Loss: 0.100699
2023-01-04 13:52: Train Epoch 19: 283/634 Loss: 0.130421
2023-01-04 13:52: Train Epoch 19: 287/634 Loss: 0.143549
2023-01-04 13:52: Train Epoch 19: 291/634 Loss: 0.123355
2023-01-04 13:52: Train Epoch 19: 295/634 Loss: 0.121464
2023-01-04 13:52: Train Epoch 19: 299/634 Loss: 0.110436
2023-01-04 13:52: Train Epoch 19: 303/634 Loss: 0.108831
2023-01-04 13:52: Train Epoch 19: 307/634 Loss: 0.108272
2023-01-04 13:52: Train Epoch 19: 311/634 Loss: 0.150415
2023-01-04 13:52: Train Epoch 19: 315/634 Loss: 0.139780
2023-01-04 13:52: Train Epoch 19: 319/634 Loss: 0.132729
2023-01-04 13:52: Train Epoch 19: 323/634 Loss: 0.139076
2023-01-04 13:52: Train Epoch 19: 327/634 Loss: 0.129792
2023-01-04 13:52: Train Epoch 19: 331/634 Loss: 0.106700
2023-01-04 13:52: Train Epoch 19: 335/634 Loss: 0.116640
2023-01-04 13:52: Train Epoch 19: 339/634 Loss: 0.126400
2023-01-04 13:52: Train Epoch 19: 343/634 Loss: 0.165841
2023-01-04 13:52: Train Epoch 19: 347/634 Loss: 0.138079
2023-01-04 13:52: Train Epoch 19: 351/634 Loss: 0.145918
2023-01-04 13:52: Train Epoch 19: 355/634 Loss: 0.122894
2023-01-04 13:52: Train Epoch 19: 359/634 Loss: 0.150071
2023-01-04 13:52: Train Epoch 19: 363/634 Loss: 0.128497
2023-01-04 13:52: Train Epoch 19: 367/634 Loss: 0.139408
2023-01-04 13:52: Train Epoch 19: 371/634 Loss: 0.149168
2023-01-04 13:52: Train Epoch 19: 375/634 Loss: 0.142382
2023-01-04 13:52: Train Epoch 19: 379/634 Loss: 0.110638
2023-01-04 13:52: Train Epoch 19: 383/634 Loss: 0.104857
2023-01-04 13:52: Train Epoch 19: 387/634 Loss: 0.105391
2023-01-04 13:53: Train Epoch 19: 391/634 Loss: 0.094218
2023-01-04 13:53: Train Epoch 19: 395/634 Loss: 0.124866
2023-01-04 13:53: Train Epoch 19: 399/634 Loss: 0.141636
2023-01-04 13:53: Train Epoch 19: 403/634 Loss: 0.121321
2023-01-04 13:53: Train Epoch 19: 407/634 Loss: 0.105190
2023-01-04 13:53: Train Epoch 19: 411/634 Loss: 0.102313
2023-01-04 13:53: Train Epoch 19: 415/634 Loss: 0.121766
2023-01-04 13:53: Train Epoch 19: 419/634 Loss: 0.105778
2023-01-04 13:53: Train Epoch 19: 423/634 Loss: 0.120400
2023-01-04 13:53: Train Epoch 19: 427/634 Loss: 0.107465
2023-01-04 13:53: Train Epoch 19: 431/634 Loss: 0.148602
2023-01-04 13:53: Train Epoch 19: 435/634 Loss: 0.134732
2023-01-04 13:53: Train Epoch 19: 439/634 Loss: 0.140323
2023-01-04 13:53: Train Epoch 19: 443/634 Loss: 0.131503
2023-01-04 13:53: Train Epoch 19: 447/634 Loss: 0.122091
2023-01-04 13:53: Train Epoch 19: 451/634 Loss: 0.118000
2023-01-04 13:53: Train Epoch 19: 455/634 Loss: 0.141628
2023-01-04 13:53: Train Epoch 19: 459/634 Loss: 0.145303
2023-01-04 13:53: Train Epoch 19: 463/634 Loss: 0.131135
2023-01-04 13:53: Train Epoch 19: 467/634 Loss: 0.131574
2023-01-04 13:53: Train Epoch 19: 471/634 Loss: 0.140210
2023-01-04 13:53: Train Epoch 19: 475/634 Loss: 0.134098
2023-01-04 13:53: Train Epoch 19: 479/634 Loss: 0.141020
2023-01-04 13:53: Train Epoch 19: 483/634 Loss: 0.119487
2023-01-04 13:53: Train Epoch 19: 487/634 Loss: 0.104197
2023-01-04 13:53: Train Epoch 19: 491/634 Loss: 0.123824
2023-01-04 13:53: Train Epoch 19: 495/634 Loss: 0.115679
2023-01-04 13:54: Train Epoch 19: 499/634 Loss: 0.133697
2023-01-04 13:54: Train Epoch 19: 503/634 Loss: 0.126313
2023-01-04 13:54: Train Epoch 19: 507/634 Loss: 0.145156
2023-01-04 13:54: Train Epoch 19: 511/634 Loss: 0.142019
2023-01-04 13:54: Train Epoch 19: 515/634 Loss: 0.133063
2023-01-04 13:54: Train Epoch 19: 519/634 Loss: 0.095709
2023-01-04 13:54: Train Epoch 19: 523/634 Loss: 0.118765
2023-01-04 13:54: Train Epoch 19: 527/634 Loss: 0.109263
2023-01-04 13:54: Train Epoch 19: 531/634 Loss: 0.131785
2023-01-04 13:54: Train Epoch 19: 535/634 Loss: 0.131492
2023-01-04 13:54: Train Epoch 19: 539/634 Loss: 0.130739
2023-01-04 13:54: Train Epoch 19: 543/634 Loss: 0.159852
2023-01-04 13:54: Train Epoch 19: 547/634 Loss: 0.138810
2023-01-04 13:54: Train Epoch 19: 551/634 Loss: 0.111411
2023-01-04 13:54: Train Epoch 19: 555/634 Loss: 0.142052
2023-01-04 13:54: Train Epoch 19: 559/634 Loss: 0.138026
2023-01-04 13:54: Train Epoch 19: 563/634 Loss: 0.129177
2023-01-04 13:54: Train Epoch 19: 567/634 Loss: 0.110075
2023-01-04 13:54: Train Epoch 19: 571/634 Loss: 0.122652
2023-01-04 13:54: Train Epoch 19: 575/634 Loss: 0.186153
2023-01-04 13:54: Train Epoch 19: 579/634 Loss: 0.121166
2023-01-04 13:54: Train Epoch 19: 583/634 Loss: 0.113570
2023-01-04 13:54: Train Epoch 19: 587/634 Loss: 0.133503
2023-01-04 13:54: Train Epoch 19: 591/634 Loss: 0.112023
2023-01-04 13:54: Train Epoch 19: 595/634 Loss: 0.156219
2023-01-04 13:54: Train Epoch 19: 599/634 Loss: 0.115848
2023-01-04 13:54: Train Epoch 19: 603/634 Loss: 0.125770
2023-01-04 13:54: Train Epoch 19: 607/634 Loss: 0.114066
2023-01-04 13:55: Train Epoch 19: 611/634 Loss: 0.113933
2023-01-04 13:55: Train Epoch 19: 615/634 Loss: 0.132781
2023-01-04 13:55: Train Epoch 19: 619/634 Loss: 0.140116
2023-01-04 13:55: Train Epoch 19: 623/634 Loss: 0.117663
2023-01-04 13:55: Train Epoch 19: 627/634 Loss: 0.139668
2023-01-04 13:55: Train Epoch 19: 631/634 Loss: 0.152628
2023-01-04 13:55: Train Epoch 19: 633/634 Loss: 0.060083
2023-01-04 13:55: **********Train Epoch 19: averaged Loss: 0.128889 
2023-01-04 13:55: 
Epoch time elapsed: 346.4069547653198

2023-01-04 13:55: 
 metrics validation: {'precision': 0.783203125, 'recall': 0.6169230769230769, 'f1-score': 0.6901893287435455, 'support': 1300, 'AUC': 0.8892724852071006, 'AUCPR': 0.8085341978719186, 'TP': 802, 'FP': 222, 'TN': 2378, 'FN': 498} 

2023-01-04 13:55: **********Val Epoch 19: average Loss: 0.218520
2023-01-04 13:55: Validation performance didn't improve for 5 epochs. Training stops.
2023-01-04 13:55: Total training time: 142.1756min, best loss: 0.205087
2023-01-04 13:55: Saving current best model to /home/joel.chacon/tmp/convLSTM/WildFire_GCN/experiments/2020/2023010411331666204319251/best_model.pth
2023-01-04 13:55: 
 Testing metrics {'precision': 0.8329741379310345, 'recall': 0.6294788273615635, 'f1-score': 0.7170686456400741, 'support': 1228, 'AUC': 0.9019396094388269, 'AUCPR': 0.8433225215142268, 'TP': 773, 'FP': 155, 'TN': 2301, 'FN': 455} 

2023-01-04 13:56: 
 Testing metrics {'precision': 0.9115708115480791, 'recall': 0.9099160426594055, 'f1-score': 0.9107426754485578, 'support': 4407, 'AUC': 0.9797061130082207, 'AUCPR': 0.9645600234874565, 'TP': 4010, 'FP': 389, 'TN': 8425, 'FN': 397} 

