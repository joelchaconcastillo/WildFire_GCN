2023-01-02 05:26: log dir: /home/joel.chacon/tmp/testing/WildFire_GCN/experiments/2020/2023010205262428504454013
2023-01-02 05:26: Experiment log path in: /home/joel.chacon/tmp/testing/WildFire_GCN/experiments/2020/2023010205262428504454013
2023-01-02 05:26: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/testing/WildFire_GCN/experiments/2020/2023010205262428504454013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=64, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-02 05:26: Argument batch_size: 256
2023-01-02 05:26: Argument clc: 'vec'
2023-01-02 05:26: Argument cuda: True
2023-01-02 05:26: Argument dataset: '2020'
2023-01-02 05:26: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-02 05:26: Argument debug: False
2023-01-02 05:26: Argument default_graph: True
2023-01-02 05:26: Argument device: 'cpu'
2023-01-02 05:26: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-02 05:26: Argument early_stop: True
2023-01-02 05:26: Argument early_stop_patience: 8
2023-01-02 05:26: Argument embed_dim: 64
2023-01-02 05:26: Argument epochs: 30
2023-01-02 05:26: Argument grad_norm: False
2023-01-02 05:26: Argument horizon: 1
2023-01-02 05:26: Argument input_dim: 25
2023-01-02 05:26: Argument lag: 10
2023-01-02 05:26: Argument link_len: 2
2023-01-02 05:26: Argument log_dir: '/home/joel.chacon/tmp/testing/WildFire_GCN/experiments/2020/2023010205262428504454013'
2023-01-02 05:26: Argument log_step: 1
2023-01-02 05:26: Argument loss_func: 'nllloss'
2023-01-02 05:26: Argument lr_decay: True
2023-01-02 05:26: Argument lr_decay_rate: 0.1
2023-01-02 05:26: Argument lr_decay_step: '15, 20'
2023-01-02 05:26: Argument lr_init: 0.0001
2023-01-02 05:26: Argument max_grad_norm: 5
2023-01-02 05:26: Argument minbatch_size: 64
2023-01-02 05:26: Argument mode: 'train'
2023-01-02 05:26: Argument model: 'fire_GCN'
2023-01-02 05:26: Argument nan_fill: -1.0
2023-01-02 05:26: Argument num_layers: 1
2023-01-02 05:26: Argument num_nodes: 625
2023-01-02 05:26: Argument num_workers: 12
2023-01-02 05:26: Argument output_dim: 2
2023-01-02 05:26: Argument patch_height: 25
2023-01-02 05:26: Argument patch_width: 25
2023-01-02 05:26: Argument persistent_workers: True
2023-01-02 05:26: Argument pin_memory: True
2023-01-02 05:26: Argument plot: False
2023-01-02 05:26: Argument positive_weight: 0.5
2023-01-02 05:26: Argument prefetch_factor: 2
2023-01-02 05:26: Argument real_value: True
2023-01-02 05:26: Argument rnn_units: 64
2023-01-02 05:26: Argument seed: 10000
2023-01-02 05:26: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-02 05:26: Argument teacher_forcing: False
2023-01-02 05:26: Argument weight_decay: 0.0
2023-01-02 05:26: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([64, 2, 89, 64]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 64]) True
encoder.cell_list.0.gate.bias_pool torch.Size([64, 128]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([64, 2, 89, 32]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 32]) True
encoder.cell_list.0.update.bias_pool torch.Size([64, 64]) True
encoder.cell_list.0.update.T torch.Size([10]) True
conv1.weight torch.Size([1, 1, 1, 64]) True
conv1.bias torch.Size([1]) True
fc1.weight torch.Size([2, 625]) True
fc1.bias torch.Size([2]) True
Total params num: 1153451
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/testing/WildFire_GCN/experiments/2020/2023010205262428504454013/run.log
2023-01-02 05:26: Train Epoch 1: 3/634 Loss: 0.534227
2023-01-02 05:27: Train Epoch 1: 7/634 Loss: 0.738433
2023-01-02 05:27: Train Epoch 1: 11/634 Loss: 0.495047
2023-01-02 05:27: Train Epoch 1: 15/634 Loss: 0.411550
2023-01-02 05:28: Train Epoch 1: 19/634 Loss: 0.341545
2023-01-02 05:28: Train Epoch 1: 23/634 Loss: 0.300874
2023-01-02 05:28: Train Epoch 1: 27/634 Loss: 0.264152
2023-01-02 05:29: Train Epoch 1: 31/634 Loss: 0.327003
2023-01-02 05:29: Train Epoch 1: 35/634 Loss: 0.327108
2023-01-02 05:29: Train Epoch 1: 39/634 Loss: 0.304982
2023-01-02 05:30: Train Epoch 1: 43/634 Loss: 0.251022
2023-01-02 05:30: Train Epoch 1: 47/634 Loss: 0.252565
2023-01-02 05:31: Train Epoch 1: 51/634 Loss: 0.262318
2023-01-02 05:31: Train Epoch 1: 55/634 Loss: 0.230596
2023-01-02 05:31: Train Epoch 1: 59/634 Loss: 0.267675
2023-01-02 05:32: Train Epoch 1: 63/634 Loss: 0.277575
2023-01-02 05:32: Train Epoch 1: 67/634 Loss: 0.263707
2023-01-02 05:32: Train Epoch 1: 71/634 Loss: 0.242481
2023-01-02 05:33: Train Epoch 1: 75/634 Loss: 0.232887
2023-01-02 05:33: Train Epoch 1: 79/634 Loss: 0.276599
2023-01-02 05:33: Train Epoch 1: 83/634 Loss: 0.244636
2023-01-02 05:34: Train Epoch 1: 87/634 Loss: 0.238301
2023-01-02 05:34: Train Epoch 1: 91/634 Loss: 0.241327
2023-01-02 05:34: Train Epoch 1: 95/634 Loss: 0.251398
2023-01-02 05:35: Train Epoch 1: 99/634 Loss: 0.240844
2023-01-02 05:35: Train Epoch 1: 103/634 Loss: 0.227717
2023-01-02 05:35: Train Epoch 1: 107/634 Loss: 0.223261
2023-01-02 05:36: Train Epoch 1: 111/634 Loss: 0.225102
2023-01-02 05:36: Train Epoch 1: 115/634 Loss: 0.234117
2023-01-02 05:37: Train Epoch 1: 119/634 Loss: 0.250062
2023-01-02 05:37: Train Epoch 1: 123/634 Loss: 0.221674
2023-01-02 05:37: Train Epoch 1: 127/634 Loss: 0.227259
2023-01-02 05:38: Train Epoch 1: 131/634 Loss: 0.259410
2023-01-02 05:38: Train Epoch 1: 135/634 Loss: 0.263219
2023-01-02 05:38: Train Epoch 1: 139/634 Loss: 0.216388
2023-01-02 05:39: Train Epoch 1: 143/634 Loss: 0.232265
2023-01-02 05:39: Train Epoch 1: 147/634 Loss: 0.239375
2023-01-02 05:39: Train Epoch 1: 151/634 Loss: 0.205310
2023-01-02 05:40: Train Epoch 1: 155/634 Loss: 0.241647
2023-01-02 05:40: Train Epoch 1: 159/634 Loss: 0.243365
2023-01-02 05:40: Train Epoch 1: 163/634 Loss: 0.209805
2023-01-02 05:41: Train Epoch 1: 167/634 Loss: 0.240345
2023-01-02 05:41: Train Epoch 1: 171/634 Loss: 0.219160
2023-01-02 05:41: Train Epoch 1: 175/634 Loss: 0.221089
2023-01-02 05:42: Train Epoch 1: 179/634 Loss: 0.222548
2023-01-02 05:42: Train Epoch 1: 183/634 Loss: 0.203210
2023-01-02 05:42: Train Epoch 1: 187/634 Loss: 0.210763
2023-01-02 05:43: Train Epoch 1: 191/634 Loss: 0.245925
2023-01-02 05:43: Train Epoch 1: 195/634 Loss: 0.232268
2023-01-02 05:44: Train Epoch 1: 199/634 Loss: 0.203426
2023-01-02 05:44: Train Epoch 1: 203/634 Loss: 0.217663
2023-01-02 05:44: Train Epoch 1: 207/634 Loss: 0.219874
2023-01-02 05:45: Train Epoch 1: 211/634 Loss: 0.220550
2023-01-02 05:45: Train Epoch 1: 215/634 Loss: 0.228724
2023-01-02 05:45: Train Epoch 1: 219/634 Loss: 0.219866
2023-01-02 05:46: Train Epoch 1: 223/634 Loss: 0.228349
2023-01-02 05:46: Train Epoch 1: 227/634 Loss: 0.204886
2023-01-02 05:46: Train Epoch 1: 231/634 Loss: 0.208346
2023-01-02 05:47: Train Epoch 1: 235/634 Loss: 0.205313
2023-01-02 05:47: Train Epoch 1: 239/634 Loss: 0.211291
2023-01-02 05:47: Train Epoch 1: 243/634 Loss: 0.236158
2023-01-02 05:48: Train Epoch 1: 247/634 Loss: 0.231171
2023-01-02 05:48: Train Epoch 1: 251/634 Loss: 0.222014
2023-01-02 05:48: Train Epoch 1: 255/634 Loss: 0.203887
2023-01-02 05:49: Train Epoch 1: 259/634 Loss: 0.233858
2023-01-02 05:49: Train Epoch 1: 263/634 Loss: 0.251663
2023-01-02 05:49: Train Epoch 1: 267/634 Loss: 0.228437
2023-01-02 05:50: Train Epoch 1: 271/634 Loss: 0.237669
2023-01-02 05:50: Train Epoch 1: 275/634 Loss: 0.218612
2023-01-02 05:50: Train Epoch 1: 279/634 Loss: 0.239528
2023-01-02 05:51: Train Epoch 1: 283/634 Loss: 0.228314
2023-01-02 05:51: Train Epoch 1: 287/634 Loss: 0.265293
2023-01-02 05:51: Train Epoch 1: 291/634 Loss: 0.195593
2023-01-02 05:52: Train Epoch 1: 295/634 Loss: 0.188606
2023-01-02 05:52: Train Epoch 1: 299/634 Loss: 0.256668
2023-01-02 05:53: Train Epoch 1: 303/634 Loss: 0.215698
2023-01-02 05:53: Train Epoch 1: 307/634 Loss: 0.218002
2023-01-02 05:53: Train Epoch 1: 311/634 Loss: 0.197038
2023-01-02 05:54: Train Epoch 1: 315/634 Loss: 0.190484
2023-01-02 05:54: Train Epoch 1: 319/634 Loss: 0.196431
2023-01-02 05:54: Train Epoch 1: 323/634 Loss: 0.222183
2023-01-02 05:55: Train Epoch 1: 327/634 Loss: 0.241618
2023-01-02 05:55: Train Epoch 1: 331/634 Loss: 0.208183
2023-01-02 05:55: Train Epoch 1: 335/634 Loss: 0.207020
2023-01-02 05:56: Train Epoch 1: 339/634 Loss: 0.217709
2023-01-02 05:56: Train Epoch 1: 343/634 Loss: 0.208230
2023-01-02 05:56: Train Epoch 1: 347/634 Loss: 0.191885
2023-01-02 05:57: Train Epoch 1: 351/634 Loss: 0.222030
2023-01-02 05:57: Train Epoch 1: 355/634 Loss: 0.216465
2023-01-02 05:57: Train Epoch 1: 359/634 Loss: 0.228286
2023-01-02 05:58: Train Epoch 1: 363/634 Loss: 0.241895
2023-01-02 05:58: Train Epoch 1: 367/634 Loss: 0.198938
2023-01-02 05:58: Train Epoch 1: 371/634 Loss: 0.210588
2023-01-02 05:59: Train Epoch 1: 375/634 Loss: 0.210696
2023-01-02 05:59: Train Epoch 1: 379/634 Loss: 0.212819
2023-01-02 05:59: Train Epoch 1: 383/634 Loss: 0.232880
2023-01-02 06:00: Train Epoch 1: 387/634 Loss: 0.204344
2023-01-02 06:00: Train Epoch 1: 391/634 Loss: 0.214771
2023-01-02 06:01: Train Epoch 1: 395/634 Loss: 0.200881
2023-01-02 06:01: Train Epoch 1: 399/634 Loss: 0.246376
2023-01-02 06:01: Train Epoch 1: 403/634 Loss: 0.229496
2023-01-02 06:02: Train Epoch 1: 407/634 Loss: 0.193540
2023-01-02 06:02: Train Epoch 1: 411/634 Loss: 0.205986
2023-01-02 06:02: Train Epoch 1: 415/634 Loss: 0.191952
2023-01-02 06:03: Train Epoch 1: 419/634 Loss: 0.201388
2023-01-02 06:03: Train Epoch 1: 423/634 Loss: 0.223786
2023-01-02 06:03: Train Epoch 1: 427/634 Loss: 0.201223
2023-01-02 06:04: Train Epoch 1: 431/634 Loss: 0.224211
2023-01-02 06:04: Train Epoch 1: 435/634 Loss: 0.190340
2023-01-02 06:04: Train Epoch 1: 439/634 Loss: 0.193444
2023-01-02 06:05: Train Epoch 1: 443/634 Loss: 0.242265
2023-01-02 06:05: Train Epoch 1: 447/634 Loss: 0.203668
2023-01-02 06:05: Train Epoch 1: 451/634 Loss: 0.171276
2023-01-02 06:06: Train Epoch 1: 455/634 Loss: 0.213586
2023-01-02 06:06: Train Epoch 1: 459/634 Loss: 0.193073
2023-01-02 06:06: Train Epoch 1: 463/634 Loss: 0.213661
2023-01-02 06:07: Train Epoch 1: 467/634 Loss: 0.216428
2023-01-02 06:07: Train Epoch 1: 471/634 Loss: 0.242329
2023-01-02 06:08: Train Epoch 1: 475/634 Loss: 0.217746
2023-01-02 06:08: Train Epoch 1: 479/634 Loss: 0.217315
2023-01-02 06:08: Train Epoch 1: 483/634 Loss: 0.203175
2023-01-02 06:09: Train Epoch 1: 487/634 Loss: 0.236341
2023-01-02 06:09: Train Epoch 1: 491/634 Loss: 0.228258
2023-01-02 06:09: Train Epoch 1: 495/634 Loss: 0.218296
2023-01-02 06:10: Train Epoch 1: 499/634 Loss: 0.193966
2023-01-02 06:10: Train Epoch 1: 503/634 Loss: 0.227122
2023-01-02 06:10: Train Epoch 1: 507/634 Loss: 0.228542
2023-01-02 06:11: Train Epoch 1: 511/634 Loss: 0.245622
2023-01-02 06:11: Train Epoch 1: 515/634 Loss: 0.206442
2023-01-02 06:11: Train Epoch 1: 519/634 Loss: 0.183110
2023-01-02 06:12: Train Epoch 1: 523/634 Loss: 0.207215
2023-01-02 06:12: Train Epoch 1: 527/634 Loss: 0.217792
2023-01-02 06:12: Train Epoch 1: 531/634 Loss: 0.238571
2023-01-02 06:13: Train Epoch 1: 535/634 Loss: 0.209885
2023-01-02 06:13: Train Epoch 1: 539/634 Loss: 0.218992
2023-01-02 06:13: Train Epoch 1: 543/634 Loss: 0.225508
2023-01-02 06:14: Train Epoch 1: 547/634 Loss: 0.206270
2023-01-02 06:14: Train Epoch 1: 551/634 Loss: 0.227863
2023-01-02 06:14: Train Epoch 1: 555/634 Loss: 0.263380
2023-01-02 06:15: Train Epoch 1: 559/634 Loss: 0.195697
2023-01-02 06:15: Train Epoch 1: 563/634 Loss: 0.203679
2023-01-02 06:15: Train Epoch 1: 567/634 Loss: 0.255074
2023-01-02 06:16: Train Epoch 1: 571/634 Loss: 0.203603
2023-01-02 06:16: Train Epoch 1: 575/634 Loss: 0.197777
2023-01-02 06:17: Train Epoch 1: 579/634 Loss: 0.219961
2023-01-02 06:17: Train Epoch 1: 583/634 Loss: 0.200044
2023-01-02 06:17: Train Epoch 1: 587/634 Loss: 0.220180
2023-01-02 06:18: Train Epoch 1: 591/634 Loss: 0.175922
2023-01-02 06:18: Train Epoch 1: 595/634 Loss: 0.207003
2023-01-02 06:18: Train Epoch 1: 599/634 Loss: 0.232544
2023-01-02 06:19: Train Epoch 1: 603/634 Loss: 0.231071
2023-01-02 06:19: Train Epoch 1: 607/634 Loss: 0.235481
2023-01-02 06:19: Train Epoch 1: 611/634 Loss: 0.217692
2023-01-02 06:20: Train Epoch 1: 615/634 Loss: 0.196865
2023-01-02 06:20: Train Epoch 1: 619/634 Loss: 0.204021
2023-01-02 06:20: Train Epoch 1: 623/634 Loss: 0.210950
2023-01-02 06:21: Train Epoch 1: 627/634 Loss: 0.216035
2023-01-02 06:21: Train Epoch 1: 631/634 Loss: 0.240102
2023-01-02 06:21: Train Epoch 1: 633/634 Loss: 0.087114
2023-01-02 06:21: **********Train Epoch 1: averaged Loss: 0.232825 
2023-01-02 06:21: 
Epoch time elapsed: 3317.5262444019318

2023-01-02 06:23: 
 metrics validation: {'precision': 0.6623376623376623, 'recall': 0.7453846153846154, 'f1-score': 0.7014115092290989, 'support': 1300, 'AUC': 0.8431863905325444, 'AUCPR': 0.7240554713189736, 'TP': 969, 'FP': 494, 'TN': 2106, 'FN': 331} 

2023-01-02 06:23: **********Val Epoch 1: average Loss: 0.221857
2023-01-02 06:23: *********************************Current best model saved!
2023-01-02 06:24: 
 Testing metrics {'precision': 0.7140718562874252, 'recall': 0.7768729641693811, 'f1-score': 0.7441497659906396, 'support': 1228, 'AUC': 0.8638214994323546, 'AUCPR': 0.7670198581234899, 'TP': 954, 'FP': 382, 'TN': 2074, 'FN': 274} 

2023-01-02 06:29: 
 Testing metrics {'precision': 0.8039716869838773, 'recall': 0.9278420694349898, 'f1-score': 0.8614768776993574, 'support': 4407, 'AUC': 0.9684900339821815, 'AUCPR': 0.9381617278222952, 'TP': 4089, 'FP': 997, 'TN': 7817, 'FN': 318} 

2023-01-02 06:30: Train Epoch 2: 3/634 Loss: 0.250209
2023-01-02 06:30: Train Epoch 2: 7/634 Loss: 0.217363
2023-01-02 06:30: Train Epoch 2: 11/634 Loss: 0.252382
2023-01-02 06:31: Train Epoch 2: 15/634 Loss: 0.215599
2023-01-02 06:31: Train Epoch 2: 19/634 Loss: 0.221491
2023-01-02 06:32: Train Epoch 2: 23/634 Loss: 0.221188
2023-01-02 06:32: Train Epoch 2: 27/634 Loss: 0.217955
2023-01-02 06:32: Train Epoch 2: 31/634 Loss: 0.197259
2023-01-02 06:33: Train Epoch 2: 35/634 Loss: 0.201729
2023-01-02 06:33: Train Epoch 2: 39/634 Loss: 0.244003
2023-01-02 06:33: Train Epoch 2: 43/634 Loss: 0.203771
2023-01-02 06:34: Train Epoch 2: 47/634 Loss: 0.204653
2023-01-02 06:34: Train Epoch 2: 51/634 Loss: 0.182391
2023-01-02 06:34: Train Epoch 2: 55/634 Loss: 0.208747
2023-01-02 06:35: Train Epoch 2: 59/634 Loss: 0.213340
2023-01-02 06:35: Train Epoch 2: 63/634 Loss: 0.204500
2023-01-02 06:35: Train Epoch 2: 67/634 Loss: 0.208797
2023-01-02 06:36: Train Epoch 2: 71/634 Loss: 0.206715
2023-01-02 06:36: Train Epoch 2: 75/634 Loss: 0.176123
2023-01-02 06:37: Train Epoch 2: 79/634 Loss: 0.198900
2023-01-02 06:37: Train Epoch 2: 83/634 Loss: 0.222451
2023-01-02 06:37: Train Epoch 2: 87/634 Loss: 0.224874
2023-01-02 06:38: Train Epoch 2: 91/634 Loss: 0.185034
2023-01-02 06:38: Train Epoch 2: 95/634 Loss: 0.217651
2023-01-02 06:38: Train Epoch 2: 99/634 Loss: 0.184388
2023-01-02 06:39: Train Epoch 2: 103/634 Loss: 0.194134
2023-01-02 06:39: Train Epoch 2: 107/634 Loss: 0.211295
2023-01-02 06:39: Train Epoch 2: 111/634 Loss: 0.213026
2023-01-02 06:40: Train Epoch 2: 115/634 Loss: 0.239356
2023-01-02 06:40: Train Epoch 2: 119/634 Loss: 0.234815
2023-01-02 06:40: Train Epoch 2: 123/634 Loss: 0.209149
2023-01-02 06:41: Train Epoch 2: 127/634 Loss: 0.211073
2023-01-02 06:41: Train Epoch 2: 131/634 Loss: 0.190654
2023-01-02 06:41: Train Epoch 2: 135/634 Loss: 0.195422
2023-01-02 06:42: Train Epoch 2: 139/634 Loss: 0.186208
2023-01-02 06:42: Train Epoch 2: 143/634 Loss: 0.199961
2023-01-02 06:43: Train Epoch 2: 147/634 Loss: 0.201166
2023-01-02 06:43: Train Epoch 2: 151/634 Loss: 0.200948
2023-01-02 06:43: Train Epoch 2: 155/634 Loss: 0.188863
2023-01-02 06:44: Train Epoch 2: 159/634 Loss: 0.205126
2023-01-02 06:44: Train Epoch 2: 163/634 Loss: 0.183317
2023-01-02 06:44: Train Epoch 2: 167/634 Loss: 0.204779
2023-01-02 06:45: Train Epoch 2: 171/634 Loss: 0.185747
2023-01-02 06:45: Train Epoch 2: 175/634 Loss: 0.221776
2023-01-02 06:45: Train Epoch 2: 179/634 Loss: 0.185071
2023-01-02 06:46: Train Epoch 2: 183/634 Loss: 0.186124
2023-01-02 06:46: Train Epoch 2: 187/634 Loss: 0.195779
2023-01-02 06:47: Train Epoch 2: 191/634 Loss: 0.215298
2023-01-02 06:47: Train Epoch 2: 195/634 Loss: 0.172098
2023-01-02 06:47: Train Epoch 2: 199/634 Loss: 0.201241
2023-01-02 06:48: Train Epoch 2: 203/634 Loss: 0.181210
2023-01-02 06:48: Train Epoch 2: 207/634 Loss: 0.194382
2023-01-02 06:48: Train Epoch 2: 211/634 Loss: 0.233714
2023-01-02 06:49: Train Epoch 2: 215/634 Loss: 0.210737
2023-01-02 06:49: Train Epoch 2: 219/634 Loss: 0.185524
2023-01-02 06:49: Train Epoch 2: 223/634 Loss: 0.195962
2023-01-02 06:50: Train Epoch 2: 227/634 Loss: 0.195514
2023-01-02 06:50: Train Epoch 2: 231/634 Loss: 0.172297
2023-01-02 06:51: Train Epoch 2: 235/634 Loss: 0.189112
2023-01-02 06:51: Train Epoch 2: 239/634 Loss: 0.179240
2023-01-02 06:51: Train Epoch 2: 243/634 Loss: 0.220689
2023-01-02 06:52: Train Epoch 2: 247/634 Loss: 0.224327
2023-01-02 06:52: Train Epoch 2: 251/634 Loss: 0.238181
2023-01-02 06:52: Train Epoch 2: 255/634 Loss: 0.217483
2023-01-02 06:53: Train Epoch 2: 259/634 Loss: 0.226309
2023-01-02 06:53: Train Epoch 2: 263/634 Loss: 0.244814
2023-01-02 06:54: Train Epoch 2: 267/634 Loss: 0.214304
2023-01-02 06:54: Train Epoch 2: 271/634 Loss: 0.192958
2023-01-02 06:54: Train Epoch 2: 275/634 Loss: 0.205033
2023-01-02 06:55: Train Epoch 2: 279/634 Loss: 0.201026
2023-01-02 06:55: Train Epoch 2: 283/634 Loss: 0.226149
2023-01-02 06:56: Train Epoch 2: 287/634 Loss: 0.182468
2023-01-02 06:56: Train Epoch 2: 291/634 Loss: 0.216802
2023-01-02 06:56: Train Epoch 2: 295/634 Loss: 0.234967
2023-01-02 06:57: Train Epoch 2: 299/634 Loss: 0.209888
2023-01-02 06:57: Train Epoch 2: 303/634 Loss: 0.169880
2023-01-02 06:57: Train Epoch 2: 307/634 Loss: 0.206362
2023-01-02 06:58: Train Epoch 2: 311/634 Loss: 0.205969
2023-01-02 06:58: Train Epoch 2: 315/634 Loss: 0.207691
2023-01-02 06:59: Train Epoch 2: 319/634 Loss: 0.226611
2023-01-02 06:59: Train Epoch 2: 323/634 Loss: 0.208142
2023-01-02 06:59: Train Epoch 2: 327/634 Loss: 0.206926
2023-01-02 07:00: Train Epoch 2: 331/634 Loss: 0.220888
2023-01-02 07:00: Train Epoch 2: 335/634 Loss: 0.173203
2023-01-02 07:00: Train Epoch 2: 339/634 Loss: 0.178316
2023-01-02 07:01: Train Epoch 2: 343/634 Loss: 0.196298
2023-01-02 07:01: Train Epoch 2: 347/634 Loss: 0.210503
2023-01-02 07:02: Train Epoch 2: 351/634 Loss: 0.204698
2023-01-02 07:02: Train Epoch 2: 355/634 Loss: 0.218155
2023-01-02 07:02: Train Epoch 2: 359/634 Loss: 0.212892
2023-01-02 07:03: Train Epoch 2: 363/634 Loss: 0.219251
2023-01-02 07:03: Train Epoch 2: 367/634 Loss: 0.184624
2023-01-02 07:03: Train Epoch 2: 371/634 Loss: 0.196372
2023-01-02 07:04: Train Epoch 2: 375/634 Loss: 0.201936
2023-01-02 07:04: Train Epoch 2: 379/634 Loss: 0.190243
2023-01-02 07:05: Train Epoch 2: 383/634 Loss: 0.198250
2023-01-02 07:05: Train Epoch 2: 387/634 Loss: 0.226965
2023-01-02 07:05: Train Epoch 2: 391/634 Loss: 0.231787
2023-01-02 07:06: Train Epoch 2: 395/634 Loss: 0.178038
2023-01-02 07:06: Train Epoch 2: 399/634 Loss: 0.165147
2023-01-02 07:06: Train Epoch 2: 403/634 Loss: 0.215966
2023-01-02 07:07: Train Epoch 2: 407/634 Loss: 0.190678
2023-01-02 07:07: Train Epoch 2: 411/634 Loss: 0.195873
2023-01-02 07:07: Train Epoch 2: 415/634 Loss: 0.177241
2023-01-02 07:08: Train Epoch 2: 419/634 Loss: 0.192829
2023-01-02 07:08: Train Epoch 2: 423/634 Loss: 0.184511
2023-01-02 07:09: Train Epoch 2: 427/634 Loss: 0.210766
2023-01-02 07:09: Train Epoch 2: 431/634 Loss: 0.202269
2023-01-02 07:09: Train Epoch 2: 435/634 Loss: 0.207742
2023-01-02 07:10: Train Epoch 2: 439/634 Loss: 0.186912
2023-01-02 07:10: Train Epoch 2: 443/634 Loss: 0.189954
2023-01-02 07:10: Train Epoch 2: 447/634 Loss: 0.200783
2023-01-02 07:11: Train Epoch 2: 451/634 Loss: 0.166489
2023-01-02 07:11: Train Epoch 2: 455/634 Loss: 0.198867
2023-01-02 07:11: Train Epoch 2: 459/634 Loss: 0.188039
2023-01-02 07:12: Train Epoch 2: 463/634 Loss: 0.206004
2023-01-02 07:12: Train Epoch 2: 467/634 Loss: 0.211684
2023-01-02 07:13: Train Epoch 2: 471/634 Loss: 0.240856
2023-01-02 07:13: Train Epoch 2: 475/634 Loss: 0.194994
2023-01-02 07:13: Train Epoch 2: 479/634 Loss: 0.211257
2023-01-02 07:14: Train Epoch 2: 483/634 Loss: 0.210056
2023-01-02 07:14: Train Epoch 2: 487/634 Loss: 0.204856
2023-01-02 07:14: Train Epoch 2: 491/634 Loss: 0.196659
2023-01-02 07:15: Train Epoch 2: 495/634 Loss: 0.191823
2023-01-02 07:15: Train Epoch 2: 499/634 Loss: 0.214420
2023-01-02 07:16: Train Epoch 2: 503/634 Loss: 0.192063
2023-01-02 07:16: Train Epoch 2: 507/634 Loss: 0.189671
2023-01-02 07:16: Train Epoch 2: 511/634 Loss: 0.193304
2023-01-02 07:17: Train Epoch 2: 515/634 Loss: 0.211512
2023-01-02 07:17: Train Epoch 2: 519/634 Loss: 0.176391
2023-01-02 07:17: Train Epoch 2: 523/634 Loss: 0.206720
2023-01-02 07:18: Train Epoch 2: 527/634 Loss: 0.220173
2023-01-02 07:18: Train Epoch 2: 531/634 Loss: 0.195566
2023-01-02 07:18: Train Epoch 2: 535/634 Loss: 0.184402
2023-01-02 07:19: Train Epoch 2: 539/634 Loss: 0.228271
2023-01-02 07:19: Train Epoch 2: 543/634 Loss: 0.177271
2023-01-02 07:19: Train Epoch 2: 547/634 Loss: 0.214024
2023-01-02 07:20: Train Epoch 2: 551/634 Loss: 0.204306
2023-01-02 07:20: Train Epoch 2: 555/634 Loss: 0.187997
2023-01-02 07:21: Train Epoch 2: 559/634 Loss: 0.225943
2023-01-02 07:21: Train Epoch 2: 563/634 Loss: 0.205265
2023-01-02 07:21: Train Epoch 2: 567/634 Loss: 0.191301
2023-01-02 07:22: Train Epoch 2: 571/634 Loss: 0.203530
2023-01-02 07:22: Train Epoch 2: 575/634 Loss: 0.193952
2023-01-02 07:22: Train Epoch 2: 579/634 Loss: 0.188083
2023-01-02 07:23: Train Epoch 2: 583/634 Loss: 0.186705
2023-01-02 07:23: Train Epoch 2: 587/634 Loss: 0.185068
2023-01-02 07:23: Train Epoch 2: 591/634 Loss: 0.213369
2023-01-02 07:24: Train Epoch 2: 595/634 Loss: 0.169303
2023-01-02 07:24: Train Epoch 2: 599/634 Loss: 0.182173
2023-01-02 07:24: Train Epoch 2: 603/634 Loss: 0.198841
2023-01-02 07:25: Train Epoch 2: 607/634 Loss: 0.196407
2023-01-02 07:25: Train Epoch 2: 611/634 Loss: 0.181300
2023-01-02 07:26: Train Epoch 2: 615/634 Loss: 0.165331
2023-01-02 07:26: Train Epoch 2: 619/634 Loss: 0.211108
2023-01-02 07:26: Train Epoch 2: 623/634 Loss: 0.201321
2023-01-02 07:27: Train Epoch 2: 627/634 Loss: 0.173021
2023-01-02 07:27: Train Epoch 2: 631/634 Loss: 0.197571
2023-01-02 07:27: Train Epoch 2: 633/634 Loss: 0.091090
2023-01-02 07:27: **********Train Epoch 2: averaged Loss: 0.201761 
2023-01-02 07:27: 
Epoch time elapsed: 3469.854322195053

2023-01-02 07:29: 
 metrics validation: {'precision': 0.7816425120772947, 'recall': 0.6223076923076923, 'f1-score': 0.6929336188436831, 'support': 1300, 'AUC': 0.8576044378698224, 'AUCPR': 0.755158387832059, 'TP': 809, 'FP': 226, 'TN': 2374, 'FN': 491} 

2023-01-02 07:29: **********Val Epoch 2: average Loss: 0.216771
2023-01-02 07:29: *********************************Current best model saved!
2023-01-02 07:30: 
 Testing metrics {'precision': 0.8093126385809313, 'recall': 0.5944625407166124, 'f1-score': 0.6854460093896714, 'support': 1228, 'AUC': 0.875292774989655, 'AUCPR': 0.7948020730114036, 'TP': 730, 'FP': 172, 'TN': 2284, 'FN': 498} 

2023-01-02 07:35: 
 Testing metrics {'precision': 0.8912264995523724, 'recall': 0.9035625141819832, 'f1-score': 0.8973521126760563, 'support': 4407, 'AUC': 0.9706792147257938, 'AUCPR': 0.9437690025826734, 'TP': 3982, 'FP': 486, 'TN': 8328, 'FN': 425} 

2023-01-02 07:36: Train Epoch 3: 3/634 Loss: 0.189365
2023-01-02 07:36: Train Epoch 3: 7/634 Loss: 0.207561
2023-01-02 07:36: Train Epoch 3: 11/634 Loss: 0.181566
2023-01-02 07:37: Train Epoch 3: 15/634 Loss: 0.217436
2023-01-02 07:37: Train Epoch 3: 19/634 Loss: 0.185622
2023-01-02 07:37: Train Epoch 3: 23/634 Loss: 0.180985
2023-01-02 07:38: Train Epoch 3: 27/634 Loss: 0.195148
2023-01-02 07:38: Train Epoch 3: 31/634 Loss: 0.160661
2023-01-02 07:38: Train Epoch 3: 35/634 Loss: 0.176868
2023-01-02 07:39: Train Epoch 3: 39/634 Loss: 0.208850
2023-01-02 07:39: Train Epoch 3: 43/634 Loss: 0.187552
2023-01-02 07:39: Train Epoch 3: 47/634 Loss: 0.202944
2023-01-02 07:40: Train Epoch 3: 51/634 Loss: 0.214799
2023-01-02 07:40: Train Epoch 3: 55/634 Loss: 0.181364
2023-01-02 07:41: Train Epoch 3: 59/634 Loss: 0.192086
2023-01-02 07:41: Train Epoch 3: 63/634 Loss: 0.198094
2023-01-02 07:41: Train Epoch 3: 67/634 Loss: 0.233520
2023-01-02 07:42: Train Epoch 3: 71/634 Loss: 0.200553
2023-01-02 07:42: Train Epoch 3: 75/634 Loss: 0.182207
2023-01-02 07:42: Train Epoch 3: 79/634 Loss: 0.203727
2023-01-02 07:43: Train Epoch 3: 83/634 Loss: 0.172459
2023-01-02 07:43: Train Epoch 3: 87/634 Loss: 0.214448
2023-01-02 07:43: Train Epoch 3: 91/634 Loss: 0.204476
2023-01-02 07:44: Train Epoch 3: 95/634 Loss: 0.183556
2023-01-02 07:44: Train Epoch 3: 99/634 Loss: 0.190431
2023-01-02 07:44: Train Epoch 3: 103/634 Loss: 0.171739
2023-01-02 07:45: Train Epoch 3: 107/634 Loss: 0.169475
2023-01-02 07:45: Train Epoch 3: 111/634 Loss: 0.187785
2023-01-02 07:45: Train Epoch 3: 115/634 Loss: 0.195522
2023-01-02 07:46: Train Epoch 3: 119/634 Loss: 0.185386
2023-01-02 07:46: Train Epoch 3: 123/634 Loss: 0.218598
2023-01-02 07:46: Train Epoch 3: 127/634 Loss: 0.165699
2023-01-02 07:47: Train Epoch 3: 131/634 Loss: 0.156656
2023-01-02 07:47: Train Epoch 3: 135/634 Loss: 0.176204
2023-01-02 07:47: Train Epoch 3: 139/634 Loss: 0.241684
2023-01-02 07:48: Train Epoch 3: 143/634 Loss: 0.202286
2023-01-02 07:48: Train Epoch 3: 147/634 Loss: 0.176572
2023-01-02 07:49: Train Epoch 3: 151/634 Loss: 0.191139
2023-01-02 07:49: Train Epoch 3: 155/634 Loss: 0.183953
2023-01-02 07:49: Train Epoch 3: 159/634 Loss: 0.226929
2023-01-02 07:50: Train Epoch 3: 163/634 Loss: 0.203361
2023-01-02 07:50: Train Epoch 3: 167/634 Loss: 0.213595
2023-01-02 07:50: Train Epoch 3: 171/634 Loss: 0.200672
2023-01-02 07:51: Train Epoch 3: 175/634 Loss: 0.223028
2023-01-02 07:51: Train Epoch 3: 179/634 Loss: 0.203553
2023-01-02 07:51: Train Epoch 3: 183/634 Loss: 0.226549
2023-01-02 07:52: Train Epoch 3: 187/634 Loss: 0.222123
2023-01-02 07:52: Train Epoch 3: 191/634 Loss: 0.179804
2023-01-02 07:52: Train Epoch 3: 195/634 Loss: 0.208774
2023-01-02 07:53: Train Epoch 3: 199/634 Loss: 0.202334
2023-01-02 07:53: Train Epoch 3: 203/634 Loss: 0.204110
2023-01-02 07:53: Train Epoch 3: 207/634 Loss: 0.198067
2023-01-02 07:54: Train Epoch 3: 211/634 Loss: 0.200433
2023-01-02 07:54: Train Epoch 3: 215/634 Loss: 0.205517
2023-01-02 07:54: Train Epoch 3: 219/634 Loss: 0.204500
2023-01-02 07:55: Train Epoch 3: 223/634 Loss: 0.185980
2023-01-02 07:55: Train Epoch 3: 227/634 Loss: 0.195385
2023-01-02 07:55: Train Epoch 3: 231/634 Loss: 0.215372
2023-01-02 07:56: Train Epoch 3: 235/634 Loss: 0.187629
2023-01-02 07:56: Train Epoch 3: 239/634 Loss: 0.197997
2023-01-02 07:57: Train Epoch 3: 243/634 Loss: 0.167352
2023-01-02 07:57: Train Epoch 3: 247/634 Loss: 0.214252
2023-01-02 07:57: Train Epoch 3: 251/634 Loss: 0.236604
2023-01-02 07:58: Train Epoch 3: 255/634 Loss: 0.164880
2023-01-02 07:58: Train Epoch 3: 259/634 Loss: 0.205524
2023-01-02 07:58: Train Epoch 3: 263/634 Loss: 0.190494
2023-01-02 07:59: Train Epoch 3: 267/634 Loss: 0.203258
2023-01-02 07:59: Train Epoch 3: 271/634 Loss: 0.198899
2023-01-02 07:59: Train Epoch 3: 275/634 Loss: 0.171631
2023-01-02 08:00: Train Epoch 3: 279/634 Loss: 0.205983
2023-01-02 08:00: Train Epoch 3: 283/634 Loss: 0.225132
2023-01-02 08:00: Train Epoch 3: 287/634 Loss: 0.223021
2023-01-02 08:01: Train Epoch 3: 291/634 Loss: 0.206335
2023-01-02 08:01: Train Epoch 3: 295/634 Loss: 0.199462
2023-01-02 08:02: Train Epoch 3: 299/634 Loss: 0.203512
2023-01-02 08:02: Train Epoch 3: 303/634 Loss: 0.220993
2023-01-02 08:02: Train Epoch 3: 307/634 Loss: 0.197696
2023-01-02 08:03: Train Epoch 3: 311/634 Loss: 0.176483
2023-01-02 08:03: Train Epoch 3: 315/634 Loss: 0.211627
2023-01-02 08:03: Train Epoch 3: 319/634 Loss: 0.187479
2023-01-02 08:04: Train Epoch 3: 323/634 Loss: 0.197744
2023-01-02 08:04: Train Epoch 3: 327/634 Loss: 0.213580
2023-01-02 08:04: Train Epoch 3: 331/634 Loss: 0.217022
2023-01-02 08:05: Train Epoch 3: 335/634 Loss: 0.208880
2023-01-02 08:05: Train Epoch 3: 339/634 Loss: 0.180241
2023-01-02 08:05: Train Epoch 3: 343/634 Loss: 0.201887
2023-01-02 08:06: Train Epoch 3: 347/634 Loss: 0.198052
2023-01-02 08:06: Train Epoch 3: 351/634 Loss: 0.181844
2023-01-02 08:06: Train Epoch 3: 355/634 Loss: 0.197335
2023-01-02 08:07: Train Epoch 3: 359/634 Loss: 0.176743
2023-01-02 08:07: Train Epoch 3: 363/634 Loss: 0.165650
2023-01-02 08:07: Train Epoch 3: 367/634 Loss: 0.178202
2023-01-02 08:08: Train Epoch 3: 371/634 Loss: 0.198887
2023-01-02 08:08: Train Epoch 3: 375/634 Loss: 0.202771
2023-01-02 08:09: Train Epoch 3: 379/634 Loss: 0.231659
2023-01-02 08:09: Train Epoch 3: 383/634 Loss: 0.200195
2023-01-02 08:09: Train Epoch 3: 387/634 Loss: 0.214506
2023-01-02 08:10: Train Epoch 3: 391/634 Loss: 0.196434
2023-01-02 08:10: Train Epoch 3: 395/634 Loss: 0.175094
2023-01-02 08:10: Train Epoch 3: 399/634 Loss: 0.195956
2023-01-02 08:11: Train Epoch 3: 403/634 Loss: 0.184632
2023-01-02 08:11: Train Epoch 3: 407/634 Loss: 0.178073
2023-01-02 08:11: Train Epoch 3: 411/634 Loss: 0.200353
2023-01-02 08:12: Train Epoch 3: 415/634 Loss: 0.181635
2023-01-02 08:12: Train Epoch 3: 419/634 Loss: 0.193764
2023-01-02 08:12: Train Epoch 3: 423/634 Loss: 0.202870
2023-01-02 08:13: Train Epoch 3: 427/634 Loss: 0.200816
2023-01-02 08:13: Train Epoch 3: 431/634 Loss: 0.261193
2023-01-02 08:13: Train Epoch 3: 435/634 Loss: 0.233557
2023-01-02 08:14: Train Epoch 3: 439/634 Loss: 0.207228
2023-01-02 08:14: Train Epoch 3: 443/634 Loss: 0.202406
2023-01-02 08:14: Train Epoch 3: 447/634 Loss: 0.176403
2023-01-02 08:15: Train Epoch 3: 451/634 Loss: 0.181264
2023-01-02 08:15: Train Epoch 3: 455/634 Loss: 0.207527
2023-01-02 08:16: Train Epoch 3: 459/634 Loss: 0.219441
2023-01-02 08:16: Train Epoch 3: 463/634 Loss: 0.208225
2023-01-02 08:16: Train Epoch 3: 467/634 Loss: 0.176792
2023-01-02 08:17: Train Epoch 3: 471/634 Loss: 0.213450
2023-01-02 08:17: Train Epoch 3: 475/634 Loss: 0.172961
2023-01-02 08:17: Train Epoch 3: 479/634 Loss: 0.190001
2023-01-02 08:18: Train Epoch 3: 483/634 Loss: 0.206990
2023-01-02 08:18: Train Epoch 3: 487/634 Loss: 0.196260
2023-01-02 08:18: Train Epoch 3: 491/634 Loss: 0.189004
2023-01-02 08:19: Train Epoch 3: 495/634 Loss: 0.171923
2023-01-02 08:19: Train Epoch 3: 499/634 Loss: 0.194224
2023-01-02 08:19: Train Epoch 3: 503/634 Loss: 0.168335
2023-01-02 08:20: Train Epoch 3: 507/634 Loss: 0.158380
2023-01-02 08:20: Train Epoch 3: 511/634 Loss: 0.245514
2023-01-02 08:20: Train Epoch 3: 515/634 Loss: 0.239159
2023-01-02 08:21: Train Epoch 3: 519/634 Loss: 0.185608
2023-01-02 08:21: Train Epoch 3: 523/634 Loss: 0.190397
2023-01-02 08:22: Train Epoch 3: 527/634 Loss: 0.209832
2023-01-02 08:22: Train Epoch 3: 531/634 Loss: 0.209119
2023-01-02 08:22: Train Epoch 3: 535/634 Loss: 0.178548
2023-01-02 08:23: Train Epoch 3: 539/634 Loss: 0.201765
2023-01-02 08:23: Train Epoch 3: 543/634 Loss: 0.223688
2023-01-02 08:23: Train Epoch 3: 547/634 Loss: 0.183917
2023-01-02 08:24: Train Epoch 3: 551/634 Loss: 0.184637
2023-01-02 08:24: Train Epoch 3: 555/634 Loss: 0.187069
2023-01-02 08:24: Train Epoch 3: 559/634 Loss: 0.166256
2023-01-02 08:25: Train Epoch 3: 563/634 Loss: 0.172586
2023-01-02 08:25: Train Epoch 3: 567/634 Loss: 0.184339
2023-01-02 08:25: Train Epoch 3: 571/634 Loss: 0.202829
2023-01-02 08:26: Train Epoch 3: 575/634 Loss: 0.172799
2023-01-02 08:26: Train Epoch 3: 579/634 Loss: 0.181199
2023-01-02 08:26: Train Epoch 3: 583/634 Loss: 0.202494
2023-01-02 08:27: Train Epoch 3: 587/634 Loss: 0.161857
2023-01-02 08:27: Train Epoch 3: 591/634 Loss: 0.166695
2023-01-02 08:27: Train Epoch 3: 595/634 Loss: 0.186794
2023-01-02 08:28: Train Epoch 3: 599/634 Loss: 0.188878
2023-01-02 08:28: Train Epoch 3: 603/634 Loss: 0.165171
2023-01-02 08:28: Train Epoch 3: 607/634 Loss: 0.171690
2023-01-02 08:29: Train Epoch 3: 611/634 Loss: 0.165891
2023-01-02 08:29: Train Epoch 3: 615/634 Loss: 0.219239
2023-01-02 08:29: Train Epoch 3: 619/634 Loss: 0.167106
2023-01-02 08:30: Train Epoch 3: 623/634 Loss: 0.190891
2023-01-02 08:30: Train Epoch 3: 627/634 Loss: 0.210863
2023-01-02 08:30: Train Epoch 3: 631/634 Loss: 0.225628
2023-01-02 08:31: Train Epoch 3: 633/634 Loss: 0.094453
2023-01-02 08:31: **********Train Epoch 3: averaged Loss: 0.195299 
2023-01-02 08:31: 
Epoch time elapsed: 3325.2292606830597

2023-01-02 08:32: 
 metrics validation: {'precision': 0.7577996715927751, 'recall': 0.71, 'f1-score': 0.733121525019857, 'support': 1300, 'AUC': 0.8735863905325445, 'AUCPR': 0.7750585128374401, 'TP': 923, 'FP': 295, 'TN': 2305, 'FN': 377} 

2023-01-02 08:32: **********Val Epoch 3: average Loss: 0.198000
2023-01-02 08:32: *********************************Current best model saved!
2023-01-02 08:34: 
 Testing metrics {'precision': 0.7871524448705657, 'recall': 0.6685667752442996, 'f1-score': 0.7230295024218407, 'support': 1228, 'AUC': 0.8867604032934036, 'AUCPR': 0.8130738143201134, 'TP': 821, 'FP': 222, 'TN': 2234, 'FN': 407} 

2023-01-02 08:39: 
 Testing metrics {'precision': 0.8692403486924035, 'recall': 0.9503063308373043, 'f1-score': 0.9079674796747967, 'support': 4407, 'AUC': 0.9731465644343588, 'AUCPR': 0.9496139926775057, 'TP': 4188, 'FP': 630, 'TN': 8184, 'FN': 219} 

2023-01-02 08:39: Train Epoch 4: 3/634 Loss: 0.201410
2023-01-02 08:39: Train Epoch 4: 7/634 Loss: 0.172030
2023-01-02 08:40: Train Epoch 4: 11/634 Loss: 0.209976
2023-01-02 08:40: Train Epoch 4: 15/634 Loss: 0.175678
2023-01-02 08:40: Train Epoch 4: 19/634 Loss: 0.191856
2023-01-02 08:41: Train Epoch 4: 23/634 Loss: 0.166886
2023-01-02 08:41: Train Epoch 4: 27/634 Loss: 0.174949
2023-01-02 08:41: Train Epoch 4: 31/634 Loss: 0.188097
2023-01-02 08:42: Train Epoch 4: 35/634 Loss: 0.188363
2023-01-02 08:42: Train Epoch 4: 39/634 Loss: 0.187461
2023-01-02 08:43: Train Epoch 4: 43/634 Loss: 0.198984
2023-01-02 08:43: Train Epoch 4: 47/634 Loss: 0.225248
2023-01-02 08:43: Train Epoch 4: 51/634 Loss: 0.218169
2023-01-02 08:44: Train Epoch 4: 55/634 Loss: 0.210742
2023-01-02 08:44: Train Epoch 4: 59/634 Loss: 0.213442
2023-01-02 08:44: Train Epoch 4: 63/634 Loss: 0.188941
2023-01-02 08:45: Train Epoch 4: 67/634 Loss: 0.194678
2023-01-02 08:45: Train Epoch 4: 71/634 Loss: 0.200800
2023-01-02 08:45: Train Epoch 4: 75/634 Loss: 0.170834
2023-01-02 08:46: Train Epoch 4: 79/634 Loss: 0.185966
2023-01-02 08:46: Train Epoch 4: 83/634 Loss: 0.177601
2023-01-02 08:46: Train Epoch 4: 87/634 Loss: 0.175313
2023-01-02 08:47: Train Epoch 4: 91/634 Loss: 0.182870
2023-01-02 08:47: Train Epoch 4: 95/634 Loss: 0.205812
2023-01-02 08:47: Train Epoch 4: 99/634 Loss: 0.185885
2023-01-02 08:48: Train Epoch 4: 103/634 Loss: 0.221644
2023-01-02 08:48: Train Epoch 4: 107/634 Loss: 0.207679
2023-01-02 08:48: Train Epoch 4: 111/634 Loss: 0.184141
2023-01-02 08:49: Train Epoch 4: 115/634 Loss: 0.205347
2023-01-02 08:49: Train Epoch 4: 119/634 Loss: 0.189968
2023-01-02 08:49: Train Epoch 4: 123/634 Loss: 0.179809
2023-01-02 08:50: Train Epoch 4: 127/634 Loss: 0.215430
2023-01-02 08:50: Train Epoch 4: 131/634 Loss: 0.202348
2023-01-02 08:51: Train Epoch 4: 135/634 Loss: 0.234907
2023-01-02 08:51: Train Epoch 4: 139/634 Loss: 0.215746
2023-01-02 08:51: Train Epoch 4: 143/634 Loss: 0.206210
2023-01-02 08:52: Train Epoch 4: 147/634 Loss: 0.187501
2023-01-02 08:52: Train Epoch 4: 151/634 Loss: 0.208231
2023-01-02 08:52: Train Epoch 4: 155/634 Loss: 0.215006
2023-01-02 08:53: Train Epoch 4: 159/634 Loss: 0.204069
2023-01-02 08:53: Train Epoch 4: 163/634 Loss: 0.238310
2023-01-02 08:53: Train Epoch 4: 167/634 Loss: 0.188085
2023-01-02 08:54: Train Epoch 4: 171/634 Loss: 0.159745
2023-01-02 08:54: Train Epoch 4: 175/634 Loss: 0.198430
2023-01-02 08:54: Train Epoch 4: 179/634 Loss: 0.198092
2023-01-02 08:55: Train Epoch 4: 183/634 Loss: 0.179044
2023-01-02 08:55: Train Epoch 4: 187/634 Loss: 0.213666
2023-01-02 08:55: Train Epoch 4: 191/634 Loss: 0.226342
2023-01-02 08:56: Train Epoch 4: 195/634 Loss: 0.196876
2023-01-02 08:56: Train Epoch 4: 199/634 Loss: 0.218046
2023-01-02 08:56: Train Epoch 4: 203/634 Loss: 0.207431
2023-01-02 08:57: Train Epoch 4: 207/634 Loss: 0.195678
2023-01-02 08:57: Train Epoch 4: 211/634 Loss: 0.180961
2023-01-02 08:57: Train Epoch 4: 215/634 Loss: 0.205772
2023-01-02 08:58: Train Epoch 4: 219/634 Loss: 0.180983
2023-01-02 08:58: Train Epoch 4: 223/634 Loss: 0.174106
2023-01-02 08:58: Train Epoch 4: 227/634 Loss: 0.174082
2023-01-02 08:59: Train Epoch 4: 231/634 Loss: 0.199221
2023-01-02 08:59: Train Epoch 4: 235/634 Loss: 0.166433
2023-01-02 09:00: Train Epoch 4: 239/634 Loss: 0.229781
2023-01-02 09:00: Train Epoch 4: 243/634 Loss: 0.174988
2023-01-02 09:00: Train Epoch 4: 247/634 Loss: 0.185103
2023-01-02 09:01: Train Epoch 4: 251/634 Loss: 0.200103
2023-01-02 09:01: Train Epoch 4: 255/634 Loss: 0.170875
2023-01-02 09:01: Train Epoch 4: 259/634 Loss: 0.170584
2023-01-02 09:02: Train Epoch 4: 263/634 Loss: 0.173855
2023-01-02 09:02: Train Epoch 4: 267/634 Loss: 0.214111
2023-01-02 09:02: Train Epoch 4: 271/634 Loss: 0.201620
2023-01-02 09:03: Train Epoch 4: 275/634 Loss: 0.207099
2023-01-02 09:03: Train Epoch 4: 279/634 Loss: 0.162679
2023-01-02 09:03: Train Epoch 4: 283/634 Loss: 0.176306
2023-01-02 09:04: Train Epoch 4: 287/634 Loss: 0.197066
2023-01-02 09:04: Train Epoch 4: 291/634 Loss: 0.164441
2023-01-02 09:04: Train Epoch 4: 295/634 Loss: 0.205895
2023-01-02 09:05: Train Epoch 4: 299/634 Loss: 0.190684
2023-01-02 09:05: Train Epoch 4: 303/634 Loss: 0.175900
2023-01-02 09:05: Train Epoch 4: 307/634 Loss: 0.191662
2023-01-02 09:06: Train Epoch 4: 311/634 Loss: 0.195055
2023-01-02 09:06: Train Epoch 4: 315/634 Loss: 0.203279
2023-01-02 09:07: Train Epoch 4: 319/634 Loss: 0.200315
2023-01-02 09:07: Train Epoch 4: 323/634 Loss: 0.175885
2023-01-02 09:07: Train Epoch 4: 327/634 Loss: 0.187190
2023-01-02 09:08: Train Epoch 4: 331/634 Loss: 0.169448
2023-01-02 09:08: Train Epoch 4: 335/634 Loss: 0.198461
2023-01-02 09:08: Train Epoch 4: 339/634 Loss: 0.177926
2023-01-02 09:09: Train Epoch 4: 343/634 Loss: 0.177001
2023-01-02 09:09: Train Epoch 4: 347/634 Loss: 0.254026
2023-01-02 09:09: Train Epoch 4: 351/634 Loss: 0.149846
2023-01-02 09:10: Train Epoch 4: 355/634 Loss: 0.196005
2023-01-02 09:10: Train Epoch 4: 359/634 Loss: 0.198102
2023-01-02 09:11: Train Epoch 4: 363/634 Loss: 0.176645
2023-01-02 09:11: Train Epoch 4: 367/634 Loss: 0.190667
2023-01-02 09:11: Train Epoch 4: 371/634 Loss: 0.211942
2023-01-02 09:12: Train Epoch 4: 375/634 Loss: 0.177650
2023-01-02 09:12: Train Epoch 4: 379/634 Loss: 0.179116
2023-01-02 09:12: Train Epoch 4: 383/634 Loss: 0.207257
2023-01-02 09:13: Train Epoch 4: 387/634 Loss: 0.198360
2023-01-02 09:13: Train Epoch 4: 391/634 Loss: 0.177982
2023-01-02 09:13: Train Epoch 4: 395/634 Loss: 0.176523
2023-01-02 09:14: Train Epoch 4: 399/634 Loss: 0.179397
2023-01-02 09:14: Train Epoch 4: 403/634 Loss: 0.216273
2023-01-02 09:14: Train Epoch 4: 407/634 Loss: 0.238108
2023-01-02 09:15: Train Epoch 4: 411/634 Loss: 0.196430
2023-01-02 09:15: Train Epoch 4: 415/634 Loss: 0.174539
2023-01-02 09:15: Train Epoch 4: 419/634 Loss: 0.173591
2023-01-02 09:16: Train Epoch 4: 423/634 Loss: 0.227317
2023-01-02 09:16: Train Epoch 4: 427/634 Loss: 0.166061
2023-01-02 09:17: Train Epoch 4: 431/634 Loss: 0.177382
2023-01-02 09:17: Train Epoch 4: 435/634 Loss: 0.184509
2023-01-02 09:17: Train Epoch 4: 439/634 Loss: 0.170371
2023-01-02 09:18: Train Epoch 4: 443/634 Loss: 0.208374
2023-01-02 09:18: Train Epoch 4: 447/634 Loss: 0.178113
2023-01-02 09:18: Train Epoch 4: 451/634 Loss: 0.184978
2023-01-02 09:19: Train Epoch 4: 455/634 Loss: 0.189894
2023-01-02 09:19: Train Epoch 4: 459/634 Loss: 0.199493
2023-01-02 09:19: Train Epoch 4: 463/634 Loss: 0.176054
2023-01-02 09:20: Train Epoch 4: 467/634 Loss: 0.170343
2023-01-02 09:20: Train Epoch 4: 471/634 Loss: 0.201304
2023-01-02 09:20: Train Epoch 4: 475/634 Loss: 0.202855
2023-01-02 09:21: Train Epoch 4: 479/634 Loss: 0.205054
2023-01-02 09:21: Train Epoch 4: 483/634 Loss: 0.162339
2023-01-02 09:21: Train Epoch 4: 487/634 Loss: 0.175657
2023-01-02 09:22: Train Epoch 4: 491/634 Loss: 0.171260
2023-01-02 09:22: Train Epoch 4: 495/634 Loss: 0.189245
2023-01-02 09:22: Train Epoch 4: 499/634 Loss: 0.174875
2023-01-02 09:23: Train Epoch 4: 503/634 Loss: 0.184444
2023-01-02 09:23: Train Epoch 4: 507/634 Loss: 0.182506
2023-01-02 09:24: Train Epoch 4: 511/634 Loss: 0.174570
2023-01-02 09:24: Train Epoch 4: 515/634 Loss: 0.200466
2023-01-02 09:24: Train Epoch 4: 519/634 Loss: 0.181826
2023-01-02 09:25: Train Epoch 4: 523/634 Loss: 0.158432
2023-01-02 09:25: Train Epoch 4: 527/634 Loss: 0.176810
2023-01-02 09:25: Train Epoch 4: 531/634 Loss: 0.172691
2023-01-02 09:26: Train Epoch 4: 535/634 Loss: 0.162100
2023-01-02 09:26: Train Epoch 4: 539/634 Loss: 0.186707
2023-01-02 09:26: Train Epoch 4: 543/634 Loss: 0.199316
2023-01-02 09:27: Train Epoch 4: 547/634 Loss: 0.173505
2023-01-02 09:27: Train Epoch 4: 551/634 Loss: 0.171596
2023-01-02 09:27: Train Epoch 4: 555/634 Loss: 0.183794
2023-01-02 09:28: Train Epoch 4: 559/634 Loss: 0.189961
2023-01-02 09:28: Train Epoch 4: 563/634 Loss: 0.175875
2023-01-02 09:28: Train Epoch 4: 567/634 Loss: 0.189456
2023-01-02 09:29: Train Epoch 4: 571/634 Loss: 0.195642
2023-01-02 09:29: Train Epoch 4: 575/634 Loss: 0.173040
2023-01-02 09:29: Train Epoch 4: 579/634 Loss: 0.183626
2023-01-02 09:30: Train Epoch 4: 583/634 Loss: 0.191076
2023-01-02 09:30: Train Epoch 4: 587/634 Loss: 0.162877
2023-01-02 09:31: Train Epoch 4: 591/634 Loss: 0.225698
2023-01-02 09:31: Train Epoch 4: 595/634 Loss: 0.195312
2023-01-02 09:31: Train Epoch 4: 599/634 Loss: 0.199004
2023-01-02 09:32: Train Epoch 4: 603/634 Loss: 0.179973
2023-01-02 09:32: Train Epoch 4: 607/634 Loss: 0.200880
2023-01-02 09:32: Train Epoch 4: 611/634 Loss: 0.198286
2023-01-02 09:33: Train Epoch 4: 615/634 Loss: 0.204360
2023-01-02 09:33: Train Epoch 4: 619/634 Loss: 0.198118
2023-01-02 09:33: Train Epoch 4: 623/634 Loss: 0.198941
2023-01-02 09:34: Train Epoch 4: 627/634 Loss: 0.166718
2023-01-02 09:34: Train Epoch 4: 631/634 Loss: 0.195477
2023-01-02 09:34: Train Epoch 4: 633/634 Loss: 0.062889
2023-01-02 09:34: **********Train Epoch 4: averaged Loss: 0.190142 
2023-01-02 09:34: 
Epoch time elapsed: 3334.661036968231

2023-01-02 09:36: 
 metrics validation: {'precision': 0.7245854361932228, 'recall': 0.7730769230769231, 'f1-score': 0.7480461481205807, 'support': 1300, 'AUC': 0.8860504437869823, 'AUCPR': 0.7871677825952353, 'TP': 1005, 'FP': 382, 'TN': 2218, 'FN': 295} 

2023-01-02 09:36: **********Val Epoch 4: average Loss: 0.191383
2023-01-02 09:36: *********************************Current best model saved!
2023-01-02 09:37: 
 Testing metrics {'precision': 0.7585644371941273, 'recall': 0.757328990228013, 'f1-score': 0.7579462102689486, 'support': 1228, 'AUC': 0.8947807138537278, 'AUCPR': 0.8236680166666049, 'TP': 930, 'FP': 296, 'TN': 2160, 'FN': 298} 

2023-01-02 09:42: 
 Testing metrics {'precision': 0.8433367243133265, 'recall': 0.9405491263898343, 'f1-score': 0.8892941428877923, 'support': 4407, 'AUC': 0.9763251951469208, 'AUCPR': 0.9550979970278101, 'TP': 4145, 'FP': 770, 'TN': 8044, 'FN': 262} 

2023-01-02 09:43: Train Epoch 5: 3/634 Loss: 0.181324
2023-01-02 09:43: Train Epoch 5: 7/634 Loss: 0.195785
2023-01-02 09:43: Train Epoch 5: 11/634 Loss: 0.203968
2023-01-02 09:44: Train Epoch 5: 15/634 Loss: 0.202820
2023-01-02 09:44: Train Epoch 5: 19/634 Loss: 0.199727
2023-01-02 09:44: Train Epoch 5: 23/634 Loss: 0.171263
2023-01-02 09:45: Train Epoch 5: 27/634 Loss: 0.163292
2023-01-02 09:45: Train Epoch 5: 31/634 Loss: 0.158231
2023-01-02 09:45: Train Epoch 5: 35/634 Loss: 0.174882
2023-01-02 09:46: Train Epoch 5: 39/634 Loss: 0.185233
2023-01-02 09:46: Train Epoch 5: 43/634 Loss: 0.198669
2023-01-02 09:46: Train Epoch 5: 47/634 Loss: 0.174909
2023-01-02 09:47: Train Epoch 5: 51/634 Loss: 0.160335
2023-01-02 09:47: Train Epoch 5: 55/634 Loss: 0.208316
2023-01-02 09:48: Train Epoch 5: 59/634 Loss: 0.196114
2023-01-02 09:48: Train Epoch 5: 63/634 Loss: 0.190662
2023-01-02 09:48: Train Epoch 5: 67/634 Loss: 0.178976
2023-01-02 09:49: Train Epoch 5: 71/634 Loss: 0.181051
2023-01-02 09:49: Train Epoch 5: 75/634 Loss: 0.189300
2023-01-02 09:49: Train Epoch 5: 79/634 Loss: 0.163408
2023-01-02 09:50: Train Epoch 5: 83/634 Loss: 0.163891
2023-01-02 09:50: Train Epoch 5: 87/634 Loss: 0.172507
2023-01-02 09:50: Train Epoch 5: 91/634 Loss: 0.153598
2023-01-02 09:51: Train Epoch 5: 95/634 Loss: 0.171330
2023-01-02 09:51: Train Epoch 5: 99/634 Loss: 0.176553
2023-01-02 09:51: Train Epoch 5: 103/634 Loss: 0.172731
2023-01-02 09:52: Train Epoch 5: 107/634 Loss: 0.156932
2023-01-02 09:52: Train Epoch 5: 111/634 Loss: 0.206339
2023-01-02 09:52: Train Epoch 5: 115/634 Loss: 0.186453
2023-01-02 09:53: Train Epoch 5: 119/634 Loss: 0.192852
2023-01-02 09:53: Train Epoch 5: 123/634 Loss: 0.214419
2023-01-02 09:53: Train Epoch 5: 127/634 Loss: 0.195394
2023-01-02 09:54: Train Epoch 5: 131/634 Loss: 0.236098
2023-01-02 09:54: Train Epoch 5: 135/634 Loss: 0.187474
2023-01-02 09:54: Train Epoch 5: 139/634 Loss: 0.180729
2023-01-02 09:55: Train Epoch 5: 143/634 Loss: 0.198807
2023-01-02 09:55: Train Epoch 5: 147/634 Loss: 0.199826
2023-01-02 09:55: Train Epoch 5: 151/634 Loss: 0.215092
2023-01-02 09:56: Train Epoch 5: 155/634 Loss: 0.181027
2023-01-02 09:56: Train Epoch 5: 159/634 Loss: 0.211416
2023-01-02 09:57: Train Epoch 5: 163/634 Loss: 0.196555
2023-01-02 09:57: Train Epoch 5: 167/634 Loss: 0.191755
2023-01-02 09:57: Train Epoch 5: 171/634 Loss: 0.176875
2023-01-02 09:58: Train Epoch 5: 175/634 Loss: 0.169386
2023-01-02 09:58: Train Epoch 5: 179/634 Loss: 0.203866
2023-01-02 09:58: Train Epoch 5: 183/634 Loss: 0.187310
2023-01-02 09:59: Train Epoch 5: 187/634 Loss: 0.220040
2023-01-02 09:59: Train Epoch 5: 191/634 Loss: 0.201534
2023-01-02 09:59: Train Epoch 5: 195/634 Loss: 0.208018
2023-01-02 10:00: Train Epoch 5: 199/634 Loss: 0.176970
2023-01-02 10:00: Train Epoch 5: 203/634 Loss: 0.169965
2023-01-02 10:00: Train Epoch 5: 207/634 Loss: 0.169968
2023-01-02 10:01: Train Epoch 5: 211/634 Loss: 0.216802
2023-01-02 10:01: Train Epoch 5: 215/634 Loss: 0.170261
2023-01-02 10:01: Train Epoch 5: 219/634 Loss: 0.198470
2023-01-02 10:02: Train Epoch 5: 223/634 Loss: 0.182354
2023-01-02 10:02: Train Epoch 5: 227/634 Loss: 0.193263
2023-01-02 10:02: Train Epoch 5: 231/634 Loss: 0.182060
2023-01-02 10:03: Train Epoch 5: 235/634 Loss: 0.166951
2023-01-02 10:03: Train Epoch 5: 239/634 Loss: 0.190347
2023-01-02 10:04: Train Epoch 5: 243/634 Loss: 0.190615
2023-01-02 10:04: Train Epoch 5: 247/634 Loss: 0.192274
2023-01-02 10:04: Train Epoch 5: 251/634 Loss: 0.219243
2023-01-02 10:05: Train Epoch 5: 255/634 Loss: 0.185817
2023-01-02 10:05: Train Epoch 5: 259/634 Loss: 0.201994
2023-01-02 10:05: Train Epoch 5: 263/634 Loss: 0.171178
2023-01-02 10:06: Train Epoch 5: 267/634 Loss: 0.178229
2023-01-02 10:06: Train Epoch 5: 271/634 Loss: 0.185400
2023-01-02 10:06: Train Epoch 5: 275/634 Loss: 0.185558
2023-01-02 10:07: Train Epoch 5: 279/634 Loss: 0.150943
2023-01-02 10:07: Train Epoch 5: 283/634 Loss: 0.152605
2023-01-02 10:07: Train Epoch 5: 287/634 Loss: 0.196804
2023-01-02 10:08: Train Epoch 5: 291/634 Loss: 0.186693
2023-01-02 10:08: Train Epoch 5: 295/634 Loss: 0.160199
2023-01-02 10:08: Train Epoch 5: 299/634 Loss: 0.193706
2023-01-02 10:09: Train Epoch 5: 303/634 Loss: 0.188194
2023-01-02 10:09: Train Epoch 5: 307/634 Loss: 0.192206
2023-01-02 10:09: Train Epoch 5: 311/634 Loss: 0.189972
2023-01-02 10:10: Train Epoch 5: 315/634 Loss: 0.184941
2023-01-02 10:10: Train Epoch 5: 319/634 Loss: 0.174125
2023-01-02 10:11: Train Epoch 5: 323/634 Loss: 0.168616
2023-01-02 10:11: Train Epoch 5: 327/634 Loss: 0.158325
2023-01-02 10:11: Train Epoch 5: 331/634 Loss: 0.162667
2023-01-02 10:12: Train Epoch 5: 335/634 Loss: 0.162943
2023-01-02 10:12: Train Epoch 5: 339/634 Loss: 0.209632
2023-01-02 10:12: Train Epoch 5: 343/634 Loss: 0.184182
2023-01-02 10:13: Train Epoch 5: 347/634 Loss: 0.170957
2023-01-02 10:13: Train Epoch 5: 351/634 Loss: 0.209667
2023-01-02 10:13: Train Epoch 5: 355/634 Loss: 0.210282
2023-01-02 10:14: Train Epoch 5: 359/634 Loss: 0.162870
2023-01-02 10:14: Train Epoch 5: 363/634 Loss: 0.193955
2023-01-02 10:14: Train Epoch 5: 367/634 Loss: 0.244026
2023-01-02 10:15: Train Epoch 5: 371/634 Loss: 0.194137
2023-01-02 10:15: Train Epoch 5: 375/634 Loss: 0.169612
2023-01-02 10:15: Train Epoch 5: 379/634 Loss: 0.173644
2023-01-02 10:16: Train Epoch 5: 383/634 Loss: 0.231861
2023-01-02 10:16: Train Epoch 5: 387/634 Loss: 0.171713
2023-01-02 10:17: Train Epoch 5: 391/634 Loss: 0.196214
2023-01-02 10:17: Train Epoch 5: 395/634 Loss: 0.212834
2023-01-02 10:17: Train Epoch 5: 399/634 Loss: 0.192229
2023-01-02 10:18: Train Epoch 5: 403/634 Loss: 0.177464
2023-01-02 10:18: Train Epoch 5: 407/634 Loss: 0.202692
2023-01-02 10:18: Train Epoch 5: 411/634 Loss: 0.171694
2023-01-02 10:19: Train Epoch 5: 415/634 Loss: 0.169179
2023-01-02 10:19: Train Epoch 5: 419/634 Loss: 0.178193
2023-01-02 10:19: Train Epoch 5: 423/634 Loss: 0.214716
2023-01-02 10:20: Train Epoch 5: 427/634 Loss: 0.182545
2023-01-02 10:20: Train Epoch 5: 431/634 Loss: 0.184076
2023-01-02 10:20: Train Epoch 5: 435/634 Loss: 0.188800
2023-01-02 10:21: Train Epoch 5: 439/634 Loss: 0.210850
2023-01-02 10:21: Train Epoch 5: 443/634 Loss: 0.167360
2023-01-02 10:21: Train Epoch 5: 447/634 Loss: 0.172150
2023-01-02 10:22: Train Epoch 5: 451/634 Loss: 0.182022
2023-01-02 10:22: Train Epoch 5: 455/634 Loss: 0.171765
2023-01-02 10:22: Train Epoch 5: 459/634 Loss: 0.177134
2023-01-02 10:23: Train Epoch 5: 463/634 Loss: 0.167192
2023-01-02 10:23: Train Epoch 5: 467/634 Loss: 0.191588
2023-01-02 10:24: Train Epoch 5: 471/634 Loss: 0.167109
2023-01-02 10:24: Train Epoch 5: 475/634 Loss: 0.172697
2023-01-02 10:24: Train Epoch 5: 479/634 Loss: 0.160384
2023-01-02 10:25: Train Epoch 5: 483/634 Loss: 0.186290
2023-01-02 10:25: Train Epoch 5: 487/634 Loss: 0.201710
2023-01-02 10:25: Train Epoch 5: 491/634 Loss: 0.208453
2023-01-02 10:26: Train Epoch 5: 495/634 Loss: 0.197188
2023-01-02 10:26: Train Epoch 5: 499/634 Loss: 0.185386
2023-01-02 10:26: Train Epoch 5: 503/634 Loss: 0.185762
2023-01-02 10:27: Train Epoch 5: 507/634 Loss: 0.185495
2023-01-02 10:27: Train Epoch 5: 511/634 Loss: 0.180106
2023-01-02 10:27: Train Epoch 5: 515/634 Loss: 0.179971
2023-01-02 10:28: Train Epoch 5: 519/634 Loss: 0.175084
2023-01-02 10:28: Train Epoch 5: 523/634 Loss: 0.185774
2023-01-02 10:29: Train Epoch 5: 527/634 Loss: 0.195290
2023-01-02 10:29: Train Epoch 5: 531/634 Loss: 0.181362
2023-01-02 10:29: Train Epoch 5: 535/634 Loss: 0.180543
2023-01-02 10:30: Train Epoch 5: 539/634 Loss: 0.200012
2023-01-02 10:30: Train Epoch 5: 543/634 Loss: 0.176392
2023-01-02 10:30: Train Epoch 5: 547/634 Loss: 0.214402
2023-01-02 10:31: Train Epoch 5: 551/634 Loss: 0.182236
2023-01-02 10:31: Train Epoch 5: 555/634 Loss: 0.178187
2023-01-02 10:31: Train Epoch 5: 559/634 Loss: 0.172241
2023-01-02 10:32: Train Epoch 5: 563/634 Loss: 0.166023
2023-01-02 10:32: Train Epoch 5: 567/634 Loss: 0.176805
2023-01-02 10:32: Train Epoch 5: 571/634 Loss: 0.201211
2023-01-02 10:33: Train Epoch 5: 575/634 Loss: 0.178966
2023-01-02 10:33: Train Epoch 5: 579/634 Loss: 0.163020
2023-01-02 10:33: Train Epoch 5: 583/634 Loss: 0.193567
2023-01-02 10:34: Train Epoch 5: 587/634 Loss: 0.171109
2023-01-02 10:34: Train Epoch 5: 591/634 Loss: 0.160050
2023-01-02 10:34: Train Epoch 5: 595/634 Loss: 0.195851
2023-01-02 10:35: Train Epoch 5: 599/634 Loss: 0.165505
2023-01-02 10:35: Train Epoch 5: 603/634 Loss: 0.174904
2023-01-02 10:35: Train Epoch 5: 607/634 Loss: 0.176882
2023-01-02 10:36: Train Epoch 5: 611/634 Loss: 0.179379
2023-01-02 10:36: Train Epoch 5: 615/634 Loss: 0.172480
2023-01-02 10:37: Train Epoch 5: 619/634 Loss: 0.174433
2023-01-02 10:37: Train Epoch 5: 623/634 Loss: 0.215661
2023-01-02 10:37: Train Epoch 5: 627/634 Loss: 0.175634
2023-01-02 10:38: Train Epoch 5: 631/634 Loss: 0.200224
2023-01-02 10:38: Train Epoch 5: 633/634 Loss: 0.067206
2023-01-02 10:38: **********Train Epoch 5: averaged Loss: 0.184629 
2023-01-02 10:38: 
Epoch time elapsed: 3333.573497056961

2023-01-02 10:39: 
 metrics validation: {'precision': 0.758761206193969, 'recall': 0.7161538461538461, 'f1-score': 0.736842105263158, 'support': 1300, 'AUC': 0.8956763313609468, 'AUCPR': 0.7982516104053781, 'TP': 931, 'FP': 296, 'TN': 2304, 'FN': 369} 

2023-01-02 10:39: **********Val Epoch 5: average Loss: 0.182294
2023-01-02 10:39: *********************************Current best model saved!
2023-01-02 10:41: 
 Testing metrics {'precision': 0.8009569377990431, 'recall': 0.6815960912052117, 'f1-score': 0.7364716234051913, 'support': 1228, 'AUC': 0.9003737771753548, 'AUCPR': 0.8356880686379158, 'TP': 837, 'FP': 208, 'TN': 2248, 'FN': 391} 

2023-01-02 10:46: 
 Testing metrics {'precision': 0.8696116090482288, 'recall': 0.9246653051962787, 'f1-score': 0.8962938524139448, 'support': 4407, 'AUC': 0.972144280848655, 'AUCPR': 0.9418624376059688, 'TP': 4075, 'FP': 611, 'TN': 8203, 'FN': 332} 

2023-01-02 10:46: Train Epoch 6: 3/634 Loss: 0.177661
2023-01-02 10:47: Train Epoch 6: 7/634 Loss: 0.180155
2023-01-02 10:47: Train Epoch 6: 11/634 Loss: 0.174902
2023-01-02 10:47: Train Epoch 6: 15/634 Loss: 0.149717
2023-01-02 10:48: Train Epoch 6: 19/634 Loss: 0.193809
2023-01-02 10:48: Train Epoch 6: 23/634 Loss: 0.157360
2023-01-02 10:48: Train Epoch 6: 27/634 Loss: 0.189814
2023-01-02 10:49: Train Epoch 6: 31/634 Loss: 0.175467
2023-01-02 10:49: Train Epoch 6: 35/634 Loss: 0.156877
2023-01-02 10:49: Train Epoch 6: 39/634 Loss: 0.173068
2023-01-02 10:50: Train Epoch 6: 43/634 Loss: 0.180942
2023-01-02 10:50: Train Epoch 6: 47/634 Loss: 0.166296
2023-01-02 10:50: Train Epoch 6: 51/634 Loss: 0.193201
2023-01-02 10:51: Train Epoch 6: 55/634 Loss: 0.170675
2023-01-02 10:51: Train Epoch 6: 59/634 Loss: 0.195466
2023-01-02 10:51: Train Epoch 6: 63/634 Loss: 0.178037
2023-01-02 10:52: Train Epoch 6: 67/634 Loss: 0.166749
2023-01-02 10:52: Train Epoch 6: 71/634 Loss: 0.179536
2023-01-02 10:52: Train Epoch 6: 75/634 Loss: 0.181963
2023-01-02 10:53: Train Epoch 6: 79/634 Loss: 0.175699
2023-01-02 10:53: Train Epoch 6: 83/634 Loss: 0.183296
2023-01-02 10:54: Train Epoch 6: 87/634 Loss: 0.155014
2023-01-02 10:54: Train Epoch 6: 91/634 Loss: 0.157062
2023-01-02 10:54: Train Epoch 6: 95/634 Loss: 0.193307
2023-01-02 10:55: Train Epoch 6: 99/634 Loss: 0.192207
2023-01-02 10:55: Train Epoch 6: 103/634 Loss: 0.199038
2023-01-02 10:55: Train Epoch 6: 107/634 Loss: 0.207144
2023-01-02 10:56: Train Epoch 6: 111/634 Loss: 0.189412
2023-01-02 10:56: Train Epoch 6: 115/634 Loss: 0.157946
2023-01-02 10:56: Train Epoch 6: 119/634 Loss: 0.165963
2023-01-02 10:57: Train Epoch 6: 123/634 Loss: 0.168547
2023-01-02 10:57: Train Epoch 6: 127/634 Loss: 0.192353
2023-01-02 10:57: Train Epoch 6: 131/634 Loss: 0.199157
2023-01-02 10:58: Train Epoch 6: 135/634 Loss: 0.169403
2023-01-02 10:58: Train Epoch 6: 139/634 Loss: 0.212504
2023-01-02 10:58: Train Epoch 6: 143/634 Loss: 0.176168
2023-01-02 10:59: Train Epoch 6: 147/634 Loss: 0.182869
2023-01-02 10:59: Train Epoch 6: 151/634 Loss: 0.186340
2023-01-02 10:59: Train Epoch 6: 155/634 Loss: 0.162146
2023-01-02 11:00: Train Epoch 6: 159/634 Loss: 0.184259
2023-01-02 11:00: Train Epoch 6: 163/634 Loss: 0.188075
2023-01-02 11:00: Train Epoch 6: 167/634 Loss: 0.182222
2023-01-02 11:01: Train Epoch 6: 171/634 Loss: 0.165856
2023-01-02 11:01: Train Epoch 6: 175/634 Loss: 0.175262
2023-01-02 11:02: Train Epoch 6: 179/634 Loss: 0.172796
2023-01-02 11:02: Train Epoch 6: 183/634 Loss: 0.177550
2023-01-02 11:02: Train Epoch 6: 187/634 Loss: 0.188074
2023-01-02 11:03: Train Epoch 6: 191/634 Loss: 0.170555
2023-01-02 11:03: Train Epoch 6: 195/634 Loss: 0.205700
2023-01-02 11:03: Train Epoch 6: 199/634 Loss: 0.158381
2023-01-02 11:04: Train Epoch 6: 203/634 Loss: 0.151748
2023-01-02 11:04: Train Epoch 6: 207/634 Loss: 0.223753
2023-01-02 11:04: Train Epoch 6: 211/634 Loss: 0.161018
2023-01-02 11:05: Train Epoch 6: 215/634 Loss: 0.199547
2023-01-02 11:05: Train Epoch 6: 219/634 Loss: 0.204073
2023-01-02 11:05: Train Epoch 6: 223/634 Loss: 0.170936
2023-01-02 11:06: Train Epoch 6: 227/634 Loss: 0.212946
2023-01-02 11:06: Train Epoch 6: 231/634 Loss: 0.186697
2023-01-02 11:07: Train Epoch 6: 235/634 Loss: 0.185270
2023-01-02 11:07: Train Epoch 6: 239/634 Loss: 0.175729
2023-01-02 11:07: Train Epoch 6: 243/634 Loss: 0.205185
2023-01-02 11:08: Train Epoch 6: 247/634 Loss: 0.179937
2023-01-02 11:08: Train Epoch 6: 251/634 Loss: 0.176975
2023-01-02 11:08: Train Epoch 6: 255/634 Loss: 0.175584
2023-01-02 11:09: Train Epoch 6: 259/634 Loss: 0.184640
2023-01-02 11:09: Train Epoch 6: 263/634 Loss: 0.154980
2023-01-02 11:09: Train Epoch 6: 267/634 Loss: 0.178397
2023-01-02 11:10: Train Epoch 6: 271/634 Loss: 0.173589
2023-01-02 11:10: Train Epoch 6: 275/634 Loss: 0.184962
2023-01-02 11:10: Train Epoch 6: 279/634 Loss: 0.153207
2023-01-02 11:11: Train Epoch 6: 283/634 Loss: 0.201525
2023-01-02 11:11: Train Epoch 6: 287/634 Loss: 0.201642
2023-01-02 11:12: Train Epoch 6: 291/634 Loss: 0.203816
2023-01-02 11:12: Train Epoch 6: 295/634 Loss: 0.201434
2023-01-02 11:12: Train Epoch 6: 299/634 Loss: 0.191069
2023-01-02 11:13: Train Epoch 6: 303/634 Loss: 0.190305
2023-01-02 11:13: Train Epoch 6: 307/634 Loss: 0.183453
2023-01-02 11:13: Train Epoch 6: 311/634 Loss: 0.167705
2023-01-02 11:14: Train Epoch 6: 315/634 Loss: 0.187821
2023-01-02 11:14: Train Epoch 6: 319/634 Loss: 0.172297
2023-01-02 11:14: Train Epoch 6: 323/634 Loss: 0.210279
2023-01-02 11:15: Train Epoch 6: 327/634 Loss: 0.196536
2023-01-02 11:15: Train Epoch 6: 331/634 Loss: 0.165398
2023-01-02 11:15: Train Epoch 6: 335/634 Loss: 0.160411
2023-01-02 11:16: Train Epoch 6: 339/634 Loss: 0.221218
2023-01-02 11:16: Train Epoch 6: 343/634 Loss: 0.152595
2023-01-02 11:16: Train Epoch 6: 347/634 Loss: 0.172975
2023-01-02 11:17: Train Epoch 6: 351/634 Loss: 0.192025
2023-01-02 11:17: Train Epoch 6: 355/634 Loss: 0.170845
2023-01-02 11:17: Train Epoch 6: 359/634 Loss: 0.192411
2023-01-02 11:18: Train Epoch 6: 363/634 Loss: 0.149996
2023-01-02 11:18: Train Epoch 6: 367/634 Loss: 0.191714
2023-01-02 11:19: Train Epoch 6: 371/634 Loss: 0.155922
2023-01-02 11:19: Train Epoch 6: 375/634 Loss: 0.187145
2023-01-02 11:19: Train Epoch 6: 379/634 Loss: 0.179176
2023-01-02 11:20: Train Epoch 6: 383/634 Loss: 0.157100
2023-01-02 11:20: Train Epoch 6: 387/634 Loss: 0.157525
2023-01-02 11:20: Train Epoch 6: 391/634 Loss: 0.169514
2023-01-02 11:21: Train Epoch 6: 395/634 Loss: 0.168946
2023-01-02 11:21: Train Epoch 6: 399/634 Loss: 0.170057
2023-01-02 11:21: Train Epoch 6: 403/634 Loss: 0.155129
2023-01-02 11:22: Train Epoch 6: 407/634 Loss: 0.183579
2023-01-02 11:22: Train Epoch 6: 411/634 Loss: 0.186376
2023-01-02 11:22: Train Epoch 6: 415/634 Loss: 0.166747
2023-01-02 11:23: Train Epoch 6: 419/634 Loss: 0.182742
2023-01-02 11:23: Train Epoch 6: 423/634 Loss: 0.200016
2023-01-02 11:23: Train Epoch 6: 427/634 Loss: 0.189343
2023-01-02 11:24: Train Epoch 6: 431/634 Loss: 0.191659
2023-01-02 11:24: Train Epoch 6: 435/634 Loss: 0.201971
2023-01-02 11:25: Train Epoch 6: 439/634 Loss: 0.156578
2023-01-02 11:25: Train Epoch 6: 443/634 Loss: 0.202680
2023-01-02 11:25: Train Epoch 6: 447/634 Loss: 0.194695
2023-01-02 11:26: Train Epoch 6: 451/634 Loss: 0.174978
2023-01-02 11:26: Train Epoch 6: 455/634 Loss: 0.168356
2023-01-02 11:26: Train Epoch 6: 459/634 Loss: 0.209542
2023-01-02 11:27: Train Epoch 6: 463/634 Loss: 0.161392
2023-01-02 11:27: Train Epoch 6: 467/634 Loss: 0.168852
2023-01-02 11:27: Train Epoch 6: 471/634 Loss: 0.161185
2023-01-02 11:28: Train Epoch 6: 475/634 Loss: 0.164439
2023-01-02 11:28: Train Epoch 6: 479/634 Loss: 0.171238
2023-01-02 11:28: Train Epoch 6: 483/634 Loss: 0.184733
2023-01-02 11:29: Train Epoch 6: 487/634 Loss: 0.166380
2023-01-02 11:29: Train Epoch 6: 491/634 Loss: 0.191206
2023-01-02 11:30: Train Epoch 6: 495/634 Loss: 0.175525
2023-01-02 11:30: Train Epoch 6: 499/634 Loss: 0.177142
2023-01-02 11:30: Train Epoch 6: 503/634 Loss: 0.206241
2023-01-02 11:31: Train Epoch 6: 507/634 Loss: 0.169142
2023-01-02 11:31: Train Epoch 6: 511/634 Loss: 0.190944
2023-01-02 11:31: Train Epoch 6: 515/634 Loss: 0.180382
2023-01-02 11:32: Train Epoch 6: 519/634 Loss: 0.178298
2023-01-02 11:32: Train Epoch 6: 523/634 Loss: 0.221583
2023-01-02 11:32: Train Epoch 6: 527/634 Loss: 0.201139
2023-01-02 11:33: Train Epoch 6: 531/634 Loss: 0.176233
2023-01-02 11:33: Train Epoch 6: 535/634 Loss: 0.228597
2023-01-02 11:33: Train Epoch 6: 539/634 Loss: 0.182053
2023-01-02 11:34: Train Epoch 6: 543/634 Loss: 0.162931
2023-01-02 11:34: Train Epoch 6: 547/634 Loss: 0.181280
2023-01-02 11:34: Train Epoch 6: 551/634 Loss: 0.201839
2023-01-02 11:35: Train Epoch 6: 555/634 Loss: 0.207445
2023-01-02 11:35: Train Epoch 6: 559/634 Loss: 0.171438
2023-01-02 11:35: Train Epoch 6: 563/634 Loss: 0.239892
2023-01-02 11:36: Train Epoch 6: 567/634 Loss: 0.168784
2023-01-02 11:36: Train Epoch 6: 571/634 Loss: 0.153344
2023-01-02 11:37: Train Epoch 6: 575/634 Loss: 0.161563
2023-01-02 11:37: Train Epoch 6: 579/634 Loss: 0.173090
2023-01-02 11:37: Train Epoch 6: 583/634 Loss: 0.165249
2023-01-02 11:38: Train Epoch 6: 587/634 Loss: 0.175552
2023-01-02 11:38: Train Epoch 6: 591/634 Loss: 0.203095
2023-01-02 11:38: Train Epoch 6: 595/634 Loss: 0.166352
2023-01-02 11:39: Train Epoch 6: 599/634 Loss: 0.194318
2023-01-02 11:39: Train Epoch 6: 603/634 Loss: 0.186327
2023-01-02 11:39: Train Epoch 6: 607/634 Loss: 0.186087
2023-01-02 11:40: Train Epoch 6: 611/634 Loss: 0.174574
2023-01-02 11:40: Train Epoch 6: 615/634 Loss: 0.159235
2023-01-02 11:40: Train Epoch 6: 619/634 Loss: 0.200067
2023-01-02 11:41: Train Epoch 6: 623/634 Loss: 0.154812
2023-01-02 11:41: Train Epoch 6: 627/634 Loss: 0.165647
2023-01-02 11:41: Train Epoch 6: 631/634 Loss: 0.181055
2023-01-02 11:42: Train Epoch 6: 633/634 Loss: 0.072898
2023-01-02 11:42: **********Train Epoch 6: averaged Loss: 0.180038 
2023-01-02 11:42: 
Epoch time elapsed: 3349.9337768554688

2023-01-02 11:43: 
 metrics validation: {'precision': 0.8087557603686636, 'recall': 0.54, 'f1-score': 0.64760147601476, 'support': 1300, 'AUC': 0.9039911242603551, 'AUCPR': 0.8058176215002917, 'TP': 702, 'FP': 166, 'TN': 2434, 'FN': 598} 

2023-01-02 11:43: **********Val Epoch 6: average Loss: 0.193862
2023-01-02 11:45: 
 Testing metrics {'precision': 0.8009569377990431, 'recall': 0.6815960912052117, 'f1-score': 0.7364716234051913, 'support': 1228, 'AUC': 0.9003737771753548, 'AUCPR': 0.8356880686379158, 'TP': 837, 'FP': 208, 'TN': 2248, 'FN': 391} 

2023-01-02 11:50: 
 Testing metrics {'precision': 0.8696116090482288, 'recall': 0.9246653051962787, 'f1-score': 0.8962938524139448, 'support': 4407, 'AUC': 0.972144280848655, 'AUCPR': 0.9418624376059688, 'TP': 4075, 'FP': 611, 'TN': 8203, 'FN': 332} 

2023-01-02 11:50: Train Epoch 7: 3/634 Loss: 0.184222
2023-01-02 11:50: Train Epoch 7: 7/634 Loss: 0.191726
2023-01-02 11:51: Train Epoch 7: 11/634 Loss: 0.190128
2023-01-02 11:51: Train Epoch 7: 15/634 Loss: 0.190006
2023-01-02 11:51: Train Epoch 7: 19/634 Loss: 0.187810
2023-01-02 11:52: Train Epoch 7: 23/634 Loss: 0.212561
2023-01-02 11:52: Train Epoch 7: 27/634 Loss: 0.169865
2023-01-02 11:53: Train Epoch 7: 31/634 Loss: 0.163285
2023-01-02 11:53: Train Epoch 7: 35/634 Loss: 0.147741
2023-01-02 11:53: Train Epoch 7: 39/634 Loss: 0.181748
2023-01-02 11:54: Train Epoch 7: 43/634 Loss: 0.171824
2023-01-02 11:54: Train Epoch 7: 47/634 Loss: 0.189715
2023-01-02 11:54: Train Epoch 7: 51/634 Loss: 0.153698
2023-01-02 11:55: Train Epoch 7: 55/634 Loss: 0.173037
2023-01-02 11:55: Train Epoch 7: 59/634 Loss: 0.176151
2023-01-02 11:55: Train Epoch 7: 63/634 Loss: 0.188761
2023-01-02 11:56: Train Epoch 7: 67/634 Loss: 0.208985
2023-01-02 11:56: Train Epoch 7: 71/634 Loss: 0.206297
2023-01-02 11:56: Train Epoch 7: 75/634 Loss: 0.186975
2023-01-02 11:57: Train Epoch 7: 79/634 Loss: 0.147530
2023-01-02 11:57: Train Epoch 7: 83/634 Loss: 0.174451
2023-01-02 11:57: Train Epoch 7: 87/634 Loss: 0.202841
2023-01-02 11:58: Train Epoch 7: 91/634 Loss: 0.190728
2023-01-02 11:58: Train Epoch 7: 95/634 Loss: 0.179448
2023-01-02 11:58: Train Epoch 7: 99/634 Loss: 0.191705
2023-01-02 11:59: Train Epoch 7: 103/634 Loss: 0.169171
2023-01-02 11:59: Train Epoch 7: 107/634 Loss: 0.200734
2023-01-02 11:59: Train Epoch 7: 111/634 Loss: 0.137748
2023-01-02 12:00: Train Epoch 7: 115/634 Loss: 0.186488
2023-01-02 12:00: Train Epoch 7: 119/634 Loss: 0.150581
2023-01-02 12:00: Train Epoch 7: 123/634 Loss: 0.178316
2023-01-02 12:01: Train Epoch 7: 127/634 Loss: 0.172302
2023-01-02 12:01: Train Epoch 7: 131/634 Loss: 0.173015
2023-01-02 12:02: Train Epoch 7: 135/634 Loss: 0.167853
2023-01-02 12:02: Train Epoch 7: 139/634 Loss: 0.167221
2023-01-02 12:02: Train Epoch 7: 143/634 Loss: 0.179779
2023-01-02 12:03: Train Epoch 7: 147/634 Loss: 0.160975
2023-01-02 12:03: Train Epoch 7: 151/634 Loss: 0.170527
2023-01-02 12:03: Train Epoch 7: 155/634 Loss: 0.194306
2023-01-02 12:04: Train Epoch 7: 159/634 Loss: 0.190398
2023-01-02 12:04: Train Epoch 7: 163/634 Loss: 0.185268
2023-01-02 12:04: Train Epoch 7: 167/634 Loss: 0.196766
2023-01-02 12:05: Train Epoch 7: 171/634 Loss: 0.157640
2023-01-02 12:05: Train Epoch 7: 175/634 Loss: 0.205200
2023-01-02 12:05: Train Epoch 7: 179/634 Loss: 0.158690
2023-01-02 12:06: Train Epoch 7: 183/634 Loss: 0.161004
2023-01-02 12:06: Train Epoch 7: 187/634 Loss: 0.163327
2023-01-02 12:06: Train Epoch 7: 191/634 Loss: 0.171159
2023-01-02 12:07: Train Epoch 7: 195/634 Loss: 0.175974
2023-01-02 12:07: Train Epoch 7: 199/634 Loss: 0.207846
2023-01-02 12:07: Train Epoch 7: 203/634 Loss: 0.195209
2023-01-02 12:08: Train Epoch 7: 207/634 Loss: 0.173890
2023-01-02 12:08: Train Epoch 7: 211/634 Loss: 0.184133
2023-01-02 12:08: Train Epoch 7: 215/634 Loss: 0.169987
2023-01-02 12:09: Train Epoch 7: 219/634 Loss: 0.182328
2023-01-02 12:09: Train Epoch 7: 223/634 Loss: 0.179818
2023-01-02 12:09: Train Epoch 7: 227/634 Loss: 0.143355
2023-01-02 12:10: Train Epoch 7: 231/634 Loss: 0.197617
2023-01-02 12:10: Train Epoch 7: 235/634 Loss: 0.175261
2023-01-02 12:10: Train Epoch 7: 239/634 Loss: 0.168399
2023-01-02 12:11: Train Epoch 7: 243/634 Loss: 0.187722
2023-01-02 12:11: Train Epoch 7: 247/634 Loss: 0.162762
2023-01-02 12:11: Train Epoch 7: 251/634 Loss: 0.163588
2023-01-02 12:12: Train Epoch 7: 255/634 Loss: 0.162175
2023-01-02 12:12: Train Epoch 7: 259/634 Loss: 0.192820
2023-01-02 12:13: Train Epoch 7: 263/634 Loss: 0.169745
2023-01-02 12:13: Train Epoch 7: 267/634 Loss: 0.183499
2023-01-02 12:13: Train Epoch 7: 271/634 Loss: 0.193801
2023-01-02 12:14: Train Epoch 7: 275/634 Loss: 0.181559
2023-01-02 12:14: Train Epoch 7: 279/634 Loss: 0.167543
2023-01-02 12:14: Train Epoch 7: 283/634 Loss: 0.176370
2023-01-02 12:15: Train Epoch 7: 287/634 Loss: 0.164697
2023-01-02 12:15: Train Epoch 7: 291/634 Loss: 0.192495
2023-01-02 12:15: Train Epoch 7: 295/634 Loss: 0.175557
2023-01-02 12:16: Train Epoch 7: 299/634 Loss: 0.176286
2023-01-02 12:16: Train Epoch 7: 303/634 Loss: 0.158722
2023-01-02 12:16: Train Epoch 7: 307/634 Loss: 0.163350
2023-01-02 12:17: Train Epoch 7: 311/634 Loss: 0.197475
2023-01-02 12:17: Train Epoch 7: 315/634 Loss: 0.190508
2023-01-02 12:17: Train Epoch 7: 319/634 Loss: 0.169997
2023-01-02 12:18: Train Epoch 7: 323/634 Loss: 0.184785
2023-01-02 12:18: Train Epoch 7: 327/634 Loss: 0.167373
2023-01-02 12:18: Train Epoch 7: 331/634 Loss: 0.190037
2023-01-02 12:19: Train Epoch 7: 335/634 Loss: 0.162920
2023-01-02 12:19: Train Epoch 7: 339/634 Loss: 0.168765
2023-01-02 12:19: Train Epoch 7: 343/634 Loss: 0.174295
2023-01-02 12:20: Train Epoch 7: 347/634 Loss: 0.153857
2023-01-02 12:20: Train Epoch 7: 351/634 Loss: 0.151986
2023-01-02 12:20: Train Epoch 7: 355/634 Loss: 0.212712
2023-01-02 12:21: Train Epoch 7: 359/634 Loss: 0.178719
2023-01-02 12:21: Train Epoch 7: 363/634 Loss: 0.158600
2023-01-02 12:21: Train Epoch 7: 367/634 Loss: 0.185998
2023-01-02 12:22: Train Epoch 7: 371/634 Loss: 0.174407
2023-01-02 12:22: Train Epoch 7: 375/634 Loss: 0.191562
2023-01-02 12:22: Train Epoch 7: 379/634 Loss: 0.168820
2023-01-02 12:23: Train Epoch 7: 383/634 Loss: 0.205485
2023-01-02 12:23: Train Epoch 7: 387/634 Loss: 0.180010
2023-01-02 12:23: Train Epoch 7: 391/634 Loss: 0.176013
2023-01-02 12:24: Train Epoch 7: 395/634 Loss: 0.190413
2023-01-02 12:24: Train Epoch 7: 399/634 Loss: 0.217326
2023-01-02 12:24: Train Epoch 7: 403/634 Loss: 0.189489
2023-01-02 12:25: Train Epoch 7: 407/634 Loss: 0.187981
2023-01-02 12:25: Train Epoch 7: 411/634 Loss: 0.203255
2023-01-02 12:26: Train Epoch 7: 415/634 Loss: 0.184240
2023-01-02 12:26: Train Epoch 7: 419/634 Loss: 0.185286
2023-01-02 12:26: Train Epoch 7: 423/634 Loss: 0.172247
2023-01-02 12:27: Train Epoch 7: 427/634 Loss: 0.191230
2023-01-02 12:27: Train Epoch 7: 431/634 Loss: 0.199275
2023-01-02 12:27: Train Epoch 7: 435/634 Loss: 0.222430
2023-01-02 12:28: Train Epoch 7: 439/634 Loss: 0.169172
2023-01-02 12:28: Train Epoch 7: 443/634 Loss: 0.191988
2023-01-02 12:28: Train Epoch 7: 447/634 Loss: 0.151490
2023-01-02 12:29: Train Epoch 7: 451/634 Loss: 0.187671
2023-01-02 12:29: Train Epoch 7: 455/634 Loss: 0.188280
2023-01-02 12:29: Train Epoch 7: 459/634 Loss: 0.219232
2023-01-02 12:30: Train Epoch 7: 463/634 Loss: 0.169528
2023-01-02 12:30: Train Epoch 7: 467/634 Loss: 0.175551
2023-01-02 12:30: Train Epoch 7: 471/634 Loss: 0.222918
2023-01-02 12:31: Train Epoch 7: 475/634 Loss: 0.169021
2023-01-02 12:31: Train Epoch 7: 479/634 Loss: 0.193321
2023-01-02 12:31: Train Epoch 7: 483/634 Loss: 0.195043
2023-01-02 12:32: Train Epoch 7: 487/634 Loss: 0.170614
2023-01-02 12:32: Train Epoch 7: 491/634 Loss: 0.148444
2023-01-02 12:33: Train Epoch 7: 495/634 Loss: 0.191545
2023-01-02 12:33: Train Epoch 7: 499/634 Loss: 0.198127
2023-01-02 12:33: Train Epoch 7: 503/634 Loss: 0.170029
2023-01-02 12:34: Train Epoch 7: 507/634 Loss: 0.166631
2023-01-02 12:34: Train Epoch 7: 511/634 Loss: 0.205963
2023-01-02 12:34: Train Epoch 7: 515/634 Loss: 0.160391
2023-01-02 12:35: Train Epoch 7: 519/634 Loss: 0.138638
2023-01-02 12:35: Train Epoch 7: 523/634 Loss: 0.151186
2023-01-02 12:35: Train Epoch 7: 527/634 Loss: 0.163381
2023-01-02 12:36: Train Epoch 7: 531/634 Loss: 0.200673
2023-01-02 12:36: Train Epoch 7: 535/634 Loss: 0.184397
2023-01-02 12:36: Train Epoch 7: 539/634 Loss: 0.190126
2023-01-02 12:37: Train Epoch 7: 543/634 Loss: 0.171544
2023-01-02 12:37: Train Epoch 7: 547/634 Loss: 0.169640
2023-01-02 12:37: Train Epoch 7: 551/634 Loss: 0.189453
2023-01-02 12:38: Train Epoch 7: 555/634 Loss: 0.209384
2023-01-02 12:38: Train Epoch 7: 559/634 Loss: 0.186971
2023-01-02 12:39: Train Epoch 7: 563/634 Loss: 0.179157
2023-01-02 12:39: Train Epoch 7: 567/634 Loss: 0.189413
2023-01-02 12:39: Train Epoch 7: 571/634 Loss: 0.166878
2023-01-02 12:40: Train Epoch 7: 575/634 Loss: 0.193790
2023-01-02 12:40: Train Epoch 7: 579/634 Loss: 0.184049
2023-01-02 12:40: Train Epoch 7: 583/634 Loss: 0.181385
2023-01-02 12:41: Train Epoch 7: 587/634 Loss: 0.179195
2023-01-02 12:41: Train Epoch 7: 591/634 Loss: 0.199435
2023-01-02 12:41: Train Epoch 7: 595/634 Loss: 0.161466
2023-01-02 12:42: Train Epoch 7: 599/634 Loss: 0.191705
2023-01-02 12:42: Train Epoch 7: 603/634 Loss: 0.188105
2023-01-02 12:42: Train Epoch 7: 607/634 Loss: 0.164113
2023-01-02 12:43: Train Epoch 7: 611/634 Loss: 0.174542
2023-01-02 12:43: Train Epoch 7: 615/634 Loss: 0.191562
2023-01-02 12:43: Train Epoch 7: 619/634 Loss: 0.196640
2023-01-02 12:44: Train Epoch 7: 623/634 Loss: 0.221446
2023-01-02 12:44: Train Epoch 7: 627/634 Loss: 0.178412
2023-01-02 12:44: Train Epoch 7: 631/634 Loss: 0.164129
2023-01-02 12:45: Train Epoch 7: 633/634 Loss: 0.065736
2023-01-02 12:45: **********Train Epoch 7: averaged Loss: 0.179530 
2023-01-02 12:45: 
Epoch time elapsed: 3298.5692417621613

2023-01-02 12:46: 
 metrics validation: {'precision': 0.6474777448071216, 'recall': 0.8392307692307692, 'f1-score': 0.7309882747068676, 'support': 1300, 'AUC': 0.8901476331360947, 'AUCPR': 0.7998051424785676, 'TP': 1091, 'FP': 594, 'TN': 2006, 'FN': 209} 

2023-01-02 12:46: **********Val Epoch 7: average Loss: 0.210641
2023-01-02 12:48: 
 Testing metrics {'precision': 0.8009569377990431, 'recall': 0.6815960912052117, 'f1-score': 0.7364716234051913, 'support': 1228, 'AUC': 0.9003737771753548, 'AUCPR': 0.8356880686379158, 'TP': 837, 'FP': 208, 'TN': 2248, 'FN': 391} 

2023-01-02 12:53: 
 Testing metrics {'precision': 0.8696116090482288, 'recall': 0.9246653051962787, 'f1-score': 0.8962938524139448, 'support': 4407, 'AUC': 0.972144280848655, 'AUCPR': 0.9418624376059688, 'TP': 4075, 'FP': 611, 'TN': 8203, 'FN': 332} 

2023-01-02 12:53: Train Epoch 8: 3/634 Loss: 0.173106
2023-01-02 12:53: Train Epoch 8: 7/634 Loss: 0.160781
2023-01-02 12:54: Train Epoch 8: 11/634 Loss: 0.215436
2023-01-02 12:54: Train Epoch 8: 15/634 Loss: 0.160784
2023-01-02 12:54: Train Epoch 8: 19/634 Loss: 0.173357
2023-01-02 12:55: Train Epoch 8: 23/634 Loss: 0.194327
2023-01-02 12:55: Train Epoch 8: 27/634 Loss: 0.168955
2023-01-02 12:55: Train Epoch 8: 31/634 Loss: 0.186462
2023-01-02 12:56: Train Epoch 8: 35/634 Loss: 0.168510
2023-01-02 12:56: Train Epoch 8: 39/634 Loss: 0.186301
2023-01-02 12:56: Train Epoch 8: 43/634 Loss: 0.160084
2023-01-02 12:57: Train Epoch 8: 47/634 Loss: 0.239046
2023-01-02 12:57: Train Epoch 8: 51/634 Loss: 0.171910
2023-01-02 12:57: Train Epoch 8: 55/634 Loss: 0.169999
2023-01-02 12:58: Train Epoch 8: 59/634 Loss: 0.186077
2023-01-02 12:58: Train Epoch 8: 63/634 Loss: 0.166428
2023-01-02 12:59: Train Epoch 8: 67/634 Loss: 0.175510
2023-01-02 12:59: Train Epoch 8: 71/634 Loss: 0.184093
2023-01-02 12:59: Train Epoch 8: 75/634 Loss: 0.165202
2023-01-02 13:00: Train Epoch 8: 79/634 Loss: 0.163265
2023-01-02 13:00: Train Epoch 8: 83/634 Loss: 0.176143
2023-01-02 13:00: Train Epoch 8: 87/634 Loss: 0.170152
2023-01-02 13:01: Train Epoch 8: 91/634 Loss: 0.190968
2023-01-02 13:01: Train Epoch 8: 95/634 Loss: 0.169119
2023-01-02 13:01: Train Epoch 8: 99/634 Loss: 0.162469
2023-01-02 13:02: Train Epoch 8: 103/634 Loss: 0.202379
2023-01-02 13:02: Train Epoch 8: 107/634 Loss: 0.192336
2023-01-02 13:02: Train Epoch 8: 111/634 Loss: 0.178376
2023-01-02 13:03: Train Epoch 8: 115/634 Loss: 0.176213
2023-01-02 13:03: Train Epoch 8: 119/634 Loss: 0.181336
2023-01-02 13:03: Train Epoch 8: 123/634 Loss: 0.193620
2023-01-02 13:04: Train Epoch 8: 127/634 Loss: 0.158927
2023-01-02 13:04: Train Epoch 8: 131/634 Loss: 0.182695
2023-01-02 13:04: Train Epoch 8: 135/634 Loss: 0.160085
2023-01-02 13:05: Train Epoch 8: 139/634 Loss: 0.177973
2023-01-02 13:05: Train Epoch 8: 143/634 Loss: 0.175040
2023-01-02 13:05: Train Epoch 8: 147/634 Loss: 0.209531
2023-01-02 13:06: Train Epoch 8: 151/634 Loss: 0.187502
2023-01-02 13:06: Train Epoch 8: 155/634 Loss: 0.183531
2023-01-02 13:07: Train Epoch 8: 159/634 Loss: 0.177052
2023-01-02 13:07: Train Epoch 8: 163/634 Loss: 0.189423
2023-01-02 13:07: Train Epoch 8: 167/634 Loss: 0.175564
2023-01-02 13:08: Train Epoch 8: 171/634 Loss: 0.175462
2023-01-02 13:08: Train Epoch 8: 175/634 Loss: 0.178463
2023-01-02 13:08: Train Epoch 8: 179/634 Loss: 0.182401
2023-01-02 13:09: Train Epoch 8: 183/634 Loss: 0.167440
2023-01-02 13:09: Train Epoch 8: 187/634 Loss: 0.164929
2023-01-02 13:09: Train Epoch 8: 191/634 Loss: 0.178150
2023-01-02 13:10: Train Epoch 8: 195/634 Loss: 0.178428
2023-01-02 13:10: Train Epoch 8: 199/634 Loss: 0.182335
2023-01-02 13:10: Train Epoch 8: 203/634 Loss: 0.171296
2023-01-02 13:11: Train Epoch 8: 207/634 Loss: 0.190797
2023-01-02 13:11: Train Epoch 8: 211/634 Loss: 0.182154
2023-01-02 13:11: Train Epoch 8: 215/634 Loss: 0.194796
2023-01-02 13:12: Train Epoch 8: 219/634 Loss: 0.182999
2023-01-02 13:12: Train Epoch 8: 223/634 Loss: 0.188484
2023-01-02 13:12: Train Epoch 8: 227/634 Loss: 0.180794
2023-01-02 13:13: Train Epoch 8: 231/634 Loss: 0.196996
2023-01-02 13:13: Train Epoch 8: 235/634 Loss: 0.186778
2023-01-02 13:13: Train Epoch 8: 239/634 Loss: 0.152754
2023-01-02 13:14: Train Epoch 8: 243/634 Loss: 0.174469
2023-01-02 13:14: Train Epoch 8: 247/634 Loss: 0.211895
2023-01-02 13:14: Train Epoch 8: 251/634 Loss: 0.167525
2023-01-02 13:15: Train Epoch 8: 255/634 Loss: 0.191160
2023-01-02 13:15: Train Epoch 8: 259/634 Loss: 0.163222
2023-01-02 13:15: Train Epoch 8: 263/634 Loss: 0.175754
2023-01-02 13:16: Train Epoch 8: 267/634 Loss: 0.184160
2023-01-02 13:16: Train Epoch 8: 271/634 Loss: 0.182264
2023-01-02 13:17: Train Epoch 8: 275/634 Loss: 0.184838
2023-01-02 13:17: Train Epoch 8: 279/634 Loss: 0.171774
2023-01-02 13:17: Train Epoch 8: 283/634 Loss: 0.182390
2023-01-02 13:18: Train Epoch 8: 287/634 Loss: 0.161327
2023-01-02 13:18: Train Epoch 8: 291/634 Loss: 0.163919
2023-01-02 13:18: Train Epoch 8: 295/634 Loss: 0.188699
2023-01-02 13:19: Train Epoch 8: 299/634 Loss: 0.196171
2023-01-02 13:19: Train Epoch 8: 303/634 Loss: 0.153543
2023-01-02 13:19: Train Epoch 8: 307/634 Loss: 0.153290
2023-01-02 13:20: Train Epoch 8: 311/634 Loss: 0.204991
2023-01-02 13:20: Train Epoch 8: 315/634 Loss: 0.155584
2023-01-02 13:20: Train Epoch 8: 319/634 Loss: 0.170104
2023-01-02 13:21: Train Epoch 8: 323/634 Loss: 0.165952
2023-01-02 13:21: Train Epoch 8: 327/634 Loss: 0.181899
2023-01-02 13:21: Train Epoch 8: 331/634 Loss: 0.161032
2023-01-02 13:22: Train Epoch 8: 335/634 Loss: 0.156619
2023-01-02 13:22: Train Epoch 8: 339/634 Loss: 0.169341
2023-01-02 13:22: Train Epoch 8: 343/634 Loss: 0.195255
2023-01-02 13:23: Train Epoch 8: 347/634 Loss: 0.162639
2023-01-02 13:23: Train Epoch 8: 351/634 Loss: 0.193609
2023-01-02 13:24: Train Epoch 8: 355/634 Loss: 0.196399
2023-01-02 13:24: Train Epoch 8: 359/634 Loss: 0.173031
2023-01-02 13:24: Train Epoch 8: 363/634 Loss: 0.177026
2023-01-02 13:25: Train Epoch 8: 367/634 Loss: 0.172206
2023-01-02 13:25: Train Epoch 8: 371/634 Loss: 0.183899
2023-01-02 13:25: Train Epoch 8: 375/634 Loss: 0.197647
2023-01-02 13:26: Train Epoch 8: 379/634 Loss: 0.197869
2023-01-02 13:26: Train Epoch 8: 383/634 Loss: 0.185318
2023-01-02 13:26: Train Epoch 8: 387/634 Loss: 0.184690
2023-01-02 13:27: Train Epoch 8: 391/634 Loss: 0.162627
2023-01-02 13:27: Train Epoch 8: 395/634 Loss: 0.175343
2023-01-02 13:27: Train Epoch 8: 399/634 Loss: 0.189077
2023-01-02 13:28: Train Epoch 8: 403/634 Loss: 0.177172
2023-01-02 13:28: Train Epoch 8: 407/634 Loss: 0.179337
2023-01-02 13:28: Train Epoch 8: 411/634 Loss: 0.234224
2023-01-02 13:29: Train Epoch 8: 415/634 Loss: 0.208012
2023-01-02 13:29: Train Epoch 8: 419/634 Loss: 0.184025
2023-01-02 13:29: Train Epoch 8: 423/634 Loss: 0.171360
2023-01-02 13:30: Train Epoch 8: 427/634 Loss: 0.218736
2023-01-02 13:30: Train Epoch 8: 431/634 Loss: 0.193441
2023-01-02 13:30: Train Epoch 8: 435/634 Loss: 0.181317
2023-01-02 13:31: Train Epoch 8: 439/634 Loss: 0.182950
2023-01-02 13:31: Train Epoch 8: 443/634 Loss: 0.175348
2023-01-02 13:32: Train Epoch 8: 447/634 Loss: 0.188769
2023-01-02 13:32: Train Epoch 8: 451/634 Loss: 0.172197
2023-01-02 13:32: Train Epoch 8: 455/634 Loss: 0.174313
2023-01-02 13:33: Train Epoch 8: 459/634 Loss: 0.181916
2023-01-02 13:33: Train Epoch 8: 463/634 Loss: 0.171076
2023-01-02 13:33: Train Epoch 8: 467/634 Loss: 0.179105
2023-01-02 13:34: Train Epoch 8: 471/634 Loss: 0.163590
2023-01-02 13:34: Train Epoch 8: 475/634 Loss: 0.184703
2023-01-02 13:34: Train Epoch 8: 479/634 Loss: 0.165891
2023-01-02 13:35: Train Epoch 8: 483/634 Loss: 0.187022
2023-01-02 13:35: Train Epoch 8: 487/634 Loss: 0.182198
2023-01-02 13:35: Train Epoch 8: 491/634 Loss: 0.184132
2023-01-02 13:36: Train Epoch 8: 495/634 Loss: 0.160963
2023-01-02 13:36: Train Epoch 8: 499/634 Loss: 0.189973
2023-01-02 13:36: Train Epoch 8: 503/634 Loss: 0.159189
2023-01-02 13:37: Train Epoch 8: 507/634 Loss: 0.180319
2023-01-02 13:37: Train Epoch 8: 511/634 Loss: 0.184146
2023-01-02 13:38: Train Epoch 8: 515/634 Loss: 0.158599
2023-01-02 13:38: Train Epoch 8: 519/634 Loss: 0.197991
2023-01-02 13:38: Train Epoch 8: 523/634 Loss: 0.173195
2023-01-02 13:39: Train Epoch 8: 527/634 Loss: 0.196049
2023-01-02 13:39: Train Epoch 8: 531/634 Loss: 0.194249
2023-01-02 13:39: Train Epoch 8: 535/634 Loss: 0.181278
2023-01-02 13:40: Train Epoch 8: 539/634 Loss: 0.205455
2023-01-02 13:40: Train Epoch 8: 543/634 Loss: 0.233059
2023-01-02 13:40: Train Epoch 8: 547/634 Loss: 0.161493
2023-01-02 13:41: Train Epoch 8: 551/634 Loss: 0.202261
2023-01-02 13:41: Train Epoch 8: 555/634 Loss: 0.245293
2023-01-02 13:41: Train Epoch 8: 559/634 Loss: 0.191300
2023-01-02 13:42: Train Epoch 8: 563/634 Loss: 0.175364
2023-01-02 13:42: Train Epoch 8: 567/634 Loss: 0.186314
2023-01-02 13:42: Train Epoch 8: 571/634 Loss: 0.189342
2023-01-02 13:43: Train Epoch 8: 575/634 Loss: 0.179985
2023-01-02 13:43: Train Epoch 8: 579/634 Loss: 0.193634
2023-01-02 13:44: Train Epoch 8: 583/634 Loss: 0.194042
2023-01-02 13:44: Train Epoch 8: 587/634 Loss: 0.190807
2023-01-02 13:44: Train Epoch 8: 591/634 Loss: 0.183298
2023-01-02 13:45: Train Epoch 8: 595/634 Loss: 0.200363
2023-01-02 13:45: Train Epoch 8: 599/634 Loss: 0.209848
2023-01-02 13:45: Train Epoch 8: 603/634 Loss: 0.196648
2023-01-02 13:46: Train Epoch 8: 607/634 Loss: 0.169362
2023-01-02 13:46: Train Epoch 8: 611/634 Loss: 0.206443
2023-01-02 13:46: Train Epoch 8: 615/634 Loss: 0.185193
2023-01-02 13:47: Train Epoch 8: 619/634 Loss: 0.170994
2023-01-02 13:47: Train Epoch 8: 623/634 Loss: 0.194511
2023-01-02 13:47: Train Epoch 8: 627/634 Loss: 0.227210
2023-01-02 13:48: Train Epoch 8: 631/634 Loss: 0.208043
2023-01-02 13:48: Train Epoch 8: 633/634 Loss: 0.069411
2023-01-02 13:48: **********Train Epoch 8: averaged Loss: 0.181639 
2023-01-02 13:48: 
Epoch time elapsed: 3305.3247408866882

2023-01-02 13:49: 
 metrics validation: {'precision': 0.8122699386503067, 'recall': 0.5092307692307693, 'f1-score': 0.6260047281323877, 'support': 1300, 'AUC': 0.9028751479289939, 'AUCPR': 0.8106084691400777, 'TP': 662, 'FP': 153, 'TN': 2447, 'FN': 638} 

2023-01-02 13:49: **********Val Epoch 8: average Loss: 0.191477
