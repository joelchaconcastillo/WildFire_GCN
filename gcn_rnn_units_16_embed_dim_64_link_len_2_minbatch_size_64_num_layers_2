2023-01-02 19:14: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010219144382175754013
2023-01-02 19:14: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010219144382175754013
2023-01-02 19:14: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010219144382175754013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=2, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-02 19:14: Argument batch_size: 256
2023-01-02 19:14: Argument clc: 'vec'
2023-01-02 19:14: Argument cuda: True
2023-01-02 19:14: Argument dataset: '2020'
2023-01-02 19:14: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-02 19:14: Argument debug: False
2023-01-02 19:14: Argument default_graph: True
2023-01-02 19:14: Argument device: 'cpu'
2023-01-02 19:14: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-02 19:14: Argument early_stop: True
2023-01-02 19:14: Argument early_stop_patience: 8
2023-01-02 19:14: Argument embed_dim: 64
2023-01-02 19:14: Argument epochs: 30
2023-01-02 19:14: Argument grad_norm: False
2023-01-02 19:14: Argument horizon: 1
2023-01-02 19:14: Argument input_dim: 25
2023-01-02 19:14: Argument lag: 10
2023-01-02 19:14: Argument link_len: 2
2023-01-02 19:14: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010219144382175754013'
2023-01-02 19:14: Argument log_step: 1
2023-01-02 19:14: Argument loss_func: 'nllloss'
2023-01-02 19:14: Argument lr_decay: True
2023-01-02 19:14: Argument lr_decay_rate: 0.1
2023-01-02 19:14: Argument lr_decay_step: '15'
2023-01-02 19:14: Argument lr_init: 0.0001
2023-01-02 19:14: Argument max_grad_norm: 5
2023-01-02 19:14: Argument minbatch_size: 64
2023-01-02 19:14: Argument mode: 'train'
2023-01-02 19:14: Argument model: 'fire_GCN'
2023-01-02 19:14: Argument nan_fill: -1.0
2023-01-02 19:14: Argument num_layers: 2
2023-01-02 19:14: Argument num_nodes: 625
2023-01-02 19:14: Argument num_workers: 12
2023-01-02 19:14: Argument output_dim: 2
2023-01-02 19:14: Argument patch_height: 25
2023-01-02 19:14: Argument patch_width: 25
2023-01-02 19:14: Argument persistent_workers: True
2023-01-02 19:14: Argument pin_memory: True
2023-01-02 19:14: Argument plot: False
2023-01-02 19:14: Argument positive_weight: 0.5
2023-01-02 19:14: Argument prefetch_factor: 2
2023-01-02 19:14: Argument real_value: True
2023-01-02 19:14: Argument rnn_units: 16
2023-01-02 19:14: Argument seed: 10000
2023-01-02 19:14: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-02 19:14: Argument teacher_forcing: False
2023-01-02 19:14: Argument weight_decay: 0.0
2023-01-02 19:14: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([64, 2, 41, 16]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 16]) True
encoder.cell_list.0.gate.bias_pool torch.Size([64, 32]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([64, 2, 41, 8]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 8]) True
encoder.cell_list.0.update.bias_pool torch.Size([64, 16]) True
encoder.cell_list.0.update.T torch.Size([10]) True
encoder.cell_list.1.gate.weights_pool torch.Size([64, 2, 32, 16]) True
encoder.cell_list.1.gate.weights_window torch.Size([64, 16, 16]) True
encoder.cell_list.1.gate.bias_pool torch.Size([64, 32]) True
encoder.cell_list.1.gate.T torch.Size([10]) True
encoder.cell_list.1.update.weights_pool torch.Size([64, 2, 32, 8]) True
encoder.cell_list.1.update.weights_window torch.Size([64, 16, 8]) True
encoder.cell_list.1.update.bias_pool torch.Size([64, 16]) True
encoder.cell_list.1.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 10000]) True
fc1.bias torch.Size([2]) True
Total params num: 316604
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010219144382175754013/run.log
2023-01-02 19:14: Train Epoch 1: 3/634 Loss: 0.323848
2023-01-02 19:15: Train Epoch 1: 7/634 Loss: 0.495560
2023-01-02 19:15: Train Epoch 1: 11/634 Loss: 0.273771
2023-01-02 19:15: Train Epoch 1: 15/634 Loss: 0.285132
2023-01-02 19:15: Train Epoch 1: 19/634 Loss: 0.320053
2023-01-02 19:15: Train Epoch 1: 23/634 Loss: 0.322213
2023-01-02 19:15: Train Epoch 1: 27/634 Loss: 0.244196
2023-01-02 19:15: Train Epoch 1: 31/634 Loss: 0.233757
2023-01-02 19:15: Train Epoch 1: 35/634 Loss: 0.263842
2023-01-02 19:16: Train Epoch 1: 39/634 Loss: 0.289016
2023-01-02 19:16: Train Epoch 1: 43/634 Loss: 0.245709
2023-01-02 19:16: Train Epoch 1: 47/634 Loss: 0.222639
2023-01-02 19:16: Train Epoch 1: 51/634 Loss: 0.272363
2023-01-02 19:16: Train Epoch 1: 55/634 Loss: 0.237572
2023-01-02 19:16: Train Epoch 1: 59/634 Loss: 0.254337
2023-01-02 19:16: Train Epoch 1: 63/634 Loss: 0.261456
2023-01-02 19:17: Train Epoch 1: 67/634 Loss: 0.210247
2023-01-02 19:17: Train Epoch 1: 71/634 Loss: 0.213810
2023-01-02 19:17: Train Epoch 1: 75/634 Loss: 0.220364
2023-01-02 19:17: Train Epoch 1: 79/634 Loss: 0.223364
2023-01-02 19:17: Train Epoch 1: 83/634 Loss: 0.197507
2023-01-02 19:17: Train Epoch 1: 87/634 Loss: 0.218648
2023-01-02 19:17: Train Epoch 1: 91/634 Loss: 0.216350
2023-01-02 19:17: Train Epoch 1: 95/634 Loss: 0.209426
2023-01-02 19:18: Train Epoch 1: 99/634 Loss: 0.203076
2023-01-02 19:18: Train Epoch 1: 103/634 Loss: 0.227913
2023-01-02 19:18: Train Epoch 1: 107/634 Loss: 0.203526
2023-01-02 19:18: Train Epoch 1: 111/634 Loss: 0.243011
2023-01-02 19:18: Train Epoch 1: 115/634 Loss: 0.247745
2023-01-02 19:18: Train Epoch 1: 119/634 Loss: 0.213223
2023-01-02 19:18: Train Epoch 1: 123/634 Loss: 0.203931
2023-01-02 19:19: Train Epoch 1: 127/634 Loss: 0.210084
2023-01-02 19:19: Train Epoch 1: 131/634 Loss: 0.235414
2023-01-02 19:19: Train Epoch 1: 135/634 Loss: 0.214681
2023-01-02 19:19: Train Epoch 1: 139/634 Loss: 0.231365
2023-01-02 19:19: Train Epoch 1: 143/634 Loss: 0.201541
2023-01-02 19:19: Train Epoch 1: 147/634 Loss: 0.202627
2023-01-02 19:19: Train Epoch 1: 151/634 Loss: 0.214558
2023-01-02 19:20: Train Epoch 1: 155/634 Loss: 0.218346
2023-01-02 19:20: Train Epoch 1: 159/634 Loss: 0.205392
2023-01-02 19:20: Train Epoch 1: 163/634 Loss: 0.221572
2023-01-02 19:20: Train Epoch 1: 167/634 Loss: 0.211138
2023-01-02 19:20: Train Epoch 1: 171/634 Loss: 0.173759
2023-01-02 19:20: Train Epoch 1: 175/634 Loss: 0.207022
2023-01-02 19:20: Train Epoch 1: 179/634 Loss: 0.191517
2023-01-02 19:21: Train Epoch 1: 183/634 Loss: 0.204789
2023-01-02 19:21: Train Epoch 1: 187/634 Loss: 0.220217
2023-01-02 19:21: Train Epoch 1: 191/634 Loss: 0.223826
2023-01-02 19:21: Train Epoch 1: 195/634 Loss: 0.229504
2023-01-02 19:21: Train Epoch 1: 199/634 Loss: 0.207137
2023-01-02 19:21: Train Epoch 1: 203/634 Loss: 0.188457
2023-01-02 19:21: Train Epoch 1: 207/634 Loss: 0.212042
2023-01-02 19:21: Train Epoch 1: 211/634 Loss: 0.186036
2023-01-02 19:22: Train Epoch 1: 215/634 Loss: 0.175241
2023-01-02 19:22: Train Epoch 1: 219/634 Loss: 0.211311
2023-01-02 19:22: Train Epoch 1: 223/634 Loss: 0.192744
2023-01-02 19:22: Train Epoch 1: 227/634 Loss: 0.213234
2023-01-02 19:22: Train Epoch 1: 231/634 Loss: 0.208698
2023-01-02 19:22: Train Epoch 1: 235/634 Loss: 0.209827
2023-01-02 19:22: Train Epoch 1: 239/634 Loss: 0.205990
2023-01-02 19:23: Train Epoch 1: 243/634 Loss: 0.194137
2023-01-02 19:23: Train Epoch 1: 247/634 Loss: 0.219037
2023-01-02 19:23: Train Epoch 1: 251/634 Loss: 0.205008
2023-01-02 19:23: Train Epoch 1: 255/634 Loss: 0.220342
2023-01-02 19:23: Train Epoch 1: 259/634 Loss: 0.203806
2023-01-02 19:23: Train Epoch 1: 263/634 Loss: 0.195638
2023-01-02 19:23: Train Epoch 1: 267/634 Loss: 0.200351
2023-01-02 19:24: Train Epoch 1: 271/634 Loss: 0.215041
2023-01-02 19:24: Train Epoch 1: 275/634 Loss: 0.213826
2023-01-02 19:24: Train Epoch 1: 279/634 Loss: 0.180206
2023-01-02 19:24: Train Epoch 1: 283/634 Loss: 0.199209
2023-01-02 19:24: Train Epoch 1: 287/634 Loss: 0.179006
2023-01-02 19:24: Train Epoch 1: 291/634 Loss: 0.207584
2023-01-02 19:24: Train Epoch 1: 295/634 Loss: 0.212821
2023-01-02 19:25: Train Epoch 1: 299/634 Loss: 0.204821
2023-01-02 19:25: Train Epoch 1: 303/634 Loss: 0.198884
2023-01-02 19:25: Train Epoch 1: 307/634 Loss: 0.219542
2023-01-02 19:25: Train Epoch 1: 311/634 Loss: 0.181857
2023-01-02 19:25: Train Epoch 1: 315/634 Loss: 0.184444
2023-01-02 19:25: Train Epoch 1: 319/634 Loss: 0.191379
2023-01-02 19:25: Train Epoch 1: 323/634 Loss: 0.207278
2023-01-02 19:26: Train Epoch 1: 327/634 Loss: 0.222164
2023-01-02 19:26: Train Epoch 1: 331/634 Loss: 0.188939
2023-01-02 19:26: Train Epoch 1: 335/634 Loss: 0.202633
2023-01-02 19:26: Train Epoch 1: 339/634 Loss: 0.174534
2023-01-02 19:26: Train Epoch 1: 343/634 Loss: 0.194598
2023-01-02 19:26: Train Epoch 1: 347/634 Loss: 0.200251
2023-01-02 19:26: Train Epoch 1: 351/634 Loss: 0.164755
2023-01-02 19:26: Train Epoch 1: 355/634 Loss: 0.191849
2023-01-02 19:27: Train Epoch 1: 359/634 Loss: 0.197967
2023-01-02 19:27: Train Epoch 1: 363/634 Loss: 0.189952
2023-01-02 19:27: Train Epoch 1: 367/634 Loss: 0.217726
2023-01-02 19:27: Train Epoch 1: 371/634 Loss: 0.211027
2023-01-02 19:27: Train Epoch 1: 375/634 Loss: 0.202509
2023-01-02 19:27: Train Epoch 1: 379/634 Loss: 0.193572
2023-01-02 19:27: Train Epoch 1: 383/634 Loss: 0.255621
2023-01-02 19:28: Train Epoch 1: 387/634 Loss: 0.235379
2023-01-02 19:28: Train Epoch 1: 391/634 Loss: 0.216775
2023-01-02 19:28: Train Epoch 1: 395/634 Loss: 0.199660
2023-01-02 19:28: Train Epoch 1: 399/634 Loss: 0.238437
2023-01-02 19:28: Train Epoch 1: 403/634 Loss: 0.234067
2023-01-02 19:28: Train Epoch 1: 407/634 Loss: 0.214611
2023-01-02 19:28: Train Epoch 1: 411/634 Loss: 0.212800
2023-01-02 19:29: Train Epoch 1: 415/634 Loss: 0.229662
2023-01-02 19:29: Train Epoch 1: 419/634 Loss: 0.217118
2023-01-02 19:29: Train Epoch 1: 423/634 Loss: 0.221708
2023-01-02 19:29: Train Epoch 1: 427/634 Loss: 0.186945
2023-01-02 19:29: Train Epoch 1: 431/634 Loss: 0.230570
2023-01-02 19:29: Train Epoch 1: 435/634 Loss: 0.206966
2023-01-02 19:29: Train Epoch 1: 439/634 Loss: 0.203892
2023-01-02 19:29: Train Epoch 1: 443/634 Loss: 0.191057
2023-01-02 19:30: Train Epoch 1: 447/634 Loss: 0.161896
2023-01-02 19:30: Train Epoch 1: 451/634 Loss: 0.228248
2023-01-02 19:30: Train Epoch 1: 455/634 Loss: 0.248676
2023-01-02 19:30: Train Epoch 1: 459/634 Loss: 0.221432
2023-01-02 19:30: Train Epoch 1: 463/634 Loss: 0.202064
2023-01-02 19:30: Train Epoch 1: 467/634 Loss: 0.185991
2023-01-02 19:30: Train Epoch 1: 471/634 Loss: 0.185034
2023-01-02 19:31: Train Epoch 1: 475/634 Loss: 0.220641
2023-01-02 19:31: Train Epoch 1: 479/634 Loss: 0.204980
2023-01-02 19:31: Train Epoch 1: 483/634 Loss: 0.203746
2023-01-02 19:31: Train Epoch 1: 487/634 Loss: 0.208809
2023-01-02 19:31: Train Epoch 1: 491/634 Loss: 0.186870
2023-01-02 19:31: Train Epoch 1: 495/634 Loss: 0.196783
2023-01-02 19:31: Train Epoch 1: 499/634 Loss: 0.178493
2023-01-02 19:32: Train Epoch 1: 503/634 Loss: 0.211188
2023-01-02 19:32: Train Epoch 1: 507/634 Loss: 0.183645
2023-01-02 19:32: Train Epoch 1: 511/634 Loss: 0.188530
2023-01-02 19:32: Train Epoch 1: 515/634 Loss: 0.215744
2023-01-02 19:32: Train Epoch 1: 519/634 Loss: 0.183586
2023-01-02 19:32: Train Epoch 1: 523/634 Loss: 0.207104
2023-01-02 19:32: Train Epoch 1: 527/634 Loss: 0.204266
2023-01-02 19:33: Train Epoch 1: 531/634 Loss: 0.180956
2023-01-02 19:33: Train Epoch 1: 535/634 Loss: 0.206450
2023-01-02 19:33: Train Epoch 1: 539/634 Loss: 0.205486
2023-01-02 19:33: Train Epoch 1: 543/634 Loss: 0.200819
2023-01-02 19:33: Train Epoch 1: 547/634 Loss: 0.176069
2023-01-02 19:33: Train Epoch 1: 551/634 Loss: 0.192142
2023-01-02 19:33: Train Epoch 1: 555/634 Loss: 0.202810
2023-01-02 19:33: Train Epoch 1: 559/634 Loss: 0.188754
2023-01-02 19:34: Train Epoch 1: 563/634 Loss: 0.201287
2023-01-02 19:34: Train Epoch 1: 567/634 Loss: 0.204442
2023-01-02 19:34: Train Epoch 1: 571/634 Loss: 0.194755
2023-01-02 19:34: Train Epoch 1: 575/634 Loss: 0.177825
2023-01-02 19:34: Train Epoch 1: 579/634 Loss: 0.193156
2023-01-02 19:34: Train Epoch 1: 583/634 Loss: 0.174682
2023-01-02 19:34: Train Epoch 1: 587/634 Loss: 0.198105
2023-01-02 19:35: Train Epoch 1: 591/634 Loss: 0.200180
2023-01-02 19:35: Train Epoch 1: 595/634 Loss: 0.185179
2023-01-02 19:35: Train Epoch 1: 599/634 Loss: 0.207047
2023-01-02 19:35: Train Epoch 1: 603/634 Loss: 0.189057
2023-01-02 19:35: Train Epoch 1: 607/634 Loss: 0.164396
2023-01-02 19:35: Train Epoch 1: 611/634 Loss: 0.185467
2023-01-02 19:35: Train Epoch 1: 615/634 Loss: 0.169874
2023-01-02 19:36: Train Epoch 1: 619/634 Loss: 0.194252
2023-01-02 19:36: Train Epoch 1: 623/634 Loss: 0.198036
2023-01-02 19:36: Train Epoch 1: 627/634 Loss: 0.223253
2023-01-02 19:36: Train Epoch 1: 631/634 Loss: 0.190289
2023-01-02 19:36: Train Epoch 1: 633/634 Loss: 0.064730
2023-01-02 19:36: **********Train Epoch 1: averaged Loss: 0.211351 
2023-01-02 19:36: 
Epoch time elapsed: 1303.76043343544

2023-01-02 19:37: 
 metrics validation: {'precision': 0.6901709401709402, 'recall': 0.7453846153846154, 'f1-score': 0.7167159763313609, 'support': 1300, 'AUC': 0.8549514792899408, 'AUCPR': 0.7673945401615345, 'TP': 969, 'FP': 435, 'TN': 2165, 'FN': 331} 

2023-01-02 19:37: **********Val Epoch 1: average Loss: 0.213408
2023-01-02 19:37: *********************************Current best model saved!
2023-01-02 19:37: 
 Testing metrics {'precision': 0.7485620377978636, 'recall': 0.74185667752443, 'f1-score': 0.7451942740286298, 'support': 1228, 'AUC': 0.8770663349213255, 'AUCPR': 0.8113935420710998, 'TP': 911, 'FP': 306, 'TN': 2150, 'FN': 317} 

2023-01-02 19:40: 
 Testing metrics {'precision': 0.8555461830451286, 'recall': 0.9205808940322214, 'f1-score': 0.8868728822822166, 'support': 4407, 'AUC': 0.9689349884760043, 'AUCPR': 0.9367765594975521, 'TP': 4057, 'FP': 685, 'TN': 8129, 'FN': 350} 

2023-01-02 19:40: Train Epoch 2: 3/634 Loss: 0.191078
2023-01-02 19:40: Train Epoch 2: 7/634 Loss: 0.209763
2023-01-02 19:40: Train Epoch 2: 11/634 Loss: 0.168287
2023-01-02 19:40: Train Epoch 2: 15/634 Loss: 0.170870
2023-01-02 19:40: Train Epoch 2: 19/634 Loss: 0.179393
2023-01-02 19:41: Train Epoch 2: 23/634 Loss: 0.201291
2023-01-02 19:41: Train Epoch 2: 27/634 Loss: 0.186145
2023-01-02 19:41: Train Epoch 2: 31/634 Loss: 0.181963
2023-01-02 19:41: Train Epoch 2: 35/634 Loss: 0.185668
2023-01-02 19:41: Train Epoch 2: 39/634 Loss: 0.192885
2023-01-02 19:41: Train Epoch 2: 43/634 Loss: 0.167075
2023-01-02 19:41: Train Epoch 2: 47/634 Loss: 0.159793
2023-01-02 19:42: Train Epoch 2: 51/634 Loss: 0.187378
2023-01-02 19:42: Train Epoch 2: 55/634 Loss: 0.153435
2023-01-02 19:42: Train Epoch 2: 59/634 Loss: 0.214891
2023-01-02 19:42: Train Epoch 2: 63/634 Loss: 0.184337
2023-01-02 19:42: Train Epoch 2: 67/634 Loss: 0.182552
2023-01-02 19:42: Train Epoch 2: 71/634 Loss: 0.198695
2023-01-02 19:42: Train Epoch 2: 75/634 Loss: 0.191194
2023-01-02 19:43: Train Epoch 2: 79/634 Loss: 0.176974
2023-01-02 19:43: Train Epoch 2: 83/634 Loss: 0.180699
2023-01-02 19:43: Train Epoch 2: 87/634 Loss: 0.162652
2023-01-02 19:43: Train Epoch 2: 91/634 Loss: 0.191251
2023-01-02 19:43: Train Epoch 2: 95/634 Loss: 0.169853
2023-01-02 19:43: Train Epoch 2: 99/634 Loss: 0.181184
2023-01-02 19:44: Train Epoch 2: 103/634 Loss: 0.222454
2023-01-02 19:44: Train Epoch 2: 107/634 Loss: 0.174273
2023-01-02 19:44: Train Epoch 2: 111/634 Loss: 0.190478
2023-01-02 19:44: Train Epoch 2: 115/634 Loss: 0.192191
2023-01-02 19:44: Train Epoch 2: 119/634 Loss: 0.199047
2023-01-02 19:44: Train Epoch 2: 123/634 Loss: 0.183654
2023-01-02 19:44: Train Epoch 2: 127/634 Loss: 0.203004
2023-01-02 19:45: Train Epoch 2: 131/634 Loss: 0.173371
2023-01-02 19:45: Train Epoch 2: 135/634 Loss: 0.195263
2023-01-02 19:45: Train Epoch 2: 139/634 Loss: 0.169461
2023-01-02 19:45: Train Epoch 2: 143/634 Loss: 0.175036
2023-01-02 19:45: Train Epoch 2: 147/634 Loss: 0.217633
2023-01-02 19:45: Train Epoch 2: 151/634 Loss: 0.210288
2023-01-02 19:45: Train Epoch 2: 155/634 Loss: 0.168152
2023-01-02 19:46: Train Epoch 2: 159/634 Loss: 0.163381
2023-01-02 19:46: Train Epoch 2: 163/634 Loss: 0.209159
2023-01-02 19:46: Train Epoch 2: 167/634 Loss: 0.207389
2023-01-02 19:46: Train Epoch 2: 171/634 Loss: 0.213252
2023-01-02 19:46: Train Epoch 2: 175/634 Loss: 0.180750
2023-01-02 19:46: Train Epoch 2: 179/634 Loss: 0.186489
2023-01-02 19:46: Train Epoch 2: 183/634 Loss: 0.225866
2023-01-02 19:47: Train Epoch 2: 187/634 Loss: 0.197629
2023-01-02 19:47: Train Epoch 2: 191/634 Loss: 0.187059
2023-01-02 19:47: Train Epoch 2: 195/634 Loss: 0.178491
2023-01-02 19:47: Train Epoch 2: 199/634 Loss: 0.194224
2023-01-02 19:47: Train Epoch 2: 203/634 Loss: 0.219771
2023-01-02 19:47: Train Epoch 2: 207/634 Loss: 0.200576
2023-01-02 19:47: Train Epoch 2: 211/634 Loss: 0.195372
2023-01-02 19:48: Train Epoch 2: 215/634 Loss: 0.184345
2023-01-02 19:48: Train Epoch 2: 219/634 Loss: 0.186181
2023-01-02 19:48: Train Epoch 2: 223/634 Loss: 0.190807
2023-01-02 19:48: Train Epoch 2: 227/634 Loss: 0.184644
2023-01-02 19:48: Train Epoch 2: 231/634 Loss: 0.203854
2023-01-02 19:48: Train Epoch 2: 235/634 Loss: 0.188579
2023-01-02 19:48: Train Epoch 2: 239/634 Loss: 0.181410
2023-01-02 19:49: Train Epoch 2: 243/634 Loss: 0.194239
2023-01-02 19:49: Train Epoch 2: 247/634 Loss: 0.197690
2023-01-02 19:49: Train Epoch 2: 251/634 Loss: 0.190193
2023-01-02 19:49: Train Epoch 2: 255/634 Loss: 0.199440
2023-01-02 19:49: Train Epoch 2: 259/634 Loss: 0.194561
2023-01-02 19:49: Train Epoch 2: 263/634 Loss: 0.175964
2023-01-02 19:50: Train Epoch 2: 267/634 Loss: 0.198118
2023-01-02 19:50: Train Epoch 2: 271/634 Loss: 0.174462
2023-01-02 19:50: Train Epoch 2: 275/634 Loss: 0.173268
2023-01-02 19:50: Train Epoch 2: 279/634 Loss: 0.205448
2023-01-02 19:50: Train Epoch 2: 283/634 Loss: 0.186217
2023-01-02 19:50: Train Epoch 2: 287/634 Loss: 0.212260
2023-01-02 19:50: Train Epoch 2: 291/634 Loss: 0.181162
2023-01-02 19:51: Train Epoch 2: 295/634 Loss: 0.173583
2023-01-02 19:51: Train Epoch 2: 299/634 Loss: 0.184046
2023-01-02 19:51: Train Epoch 2: 303/634 Loss: 0.204988
2023-01-02 19:51: Train Epoch 2: 307/634 Loss: 0.192243
2023-01-02 19:51: Train Epoch 2: 311/634 Loss: 0.184066
2023-01-02 19:51: Train Epoch 2: 315/634 Loss: 0.197149
2023-01-02 19:51: Train Epoch 2: 319/634 Loss: 0.189375
2023-01-02 19:52: Train Epoch 2: 323/634 Loss: 0.170657
2023-01-02 19:52: Train Epoch 2: 327/634 Loss: 0.175746
2023-01-02 19:52: Train Epoch 2: 331/634 Loss: 0.175318
2023-01-02 19:52: Train Epoch 2: 335/634 Loss: 0.205883
2023-01-02 19:52: Train Epoch 2: 339/634 Loss: 0.185491
2023-01-02 19:52: Train Epoch 2: 343/634 Loss: 0.186856
2023-01-02 19:52: Train Epoch 2: 347/634 Loss: 0.201963
2023-01-02 19:53: Train Epoch 2: 351/634 Loss: 0.190173
2023-01-02 19:53: Train Epoch 2: 355/634 Loss: 0.169474
2023-01-02 19:53: Train Epoch 2: 359/634 Loss: 0.206372
2023-01-02 19:53: Train Epoch 2: 363/634 Loss: 0.179959
2023-01-02 19:53: Train Epoch 2: 367/634 Loss: 0.202484
2023-01-02 19:53: Train Epoch 2: 371/634 Loss: 0.172855
2023-01-02 19:53: Train Epoch 2: 375/634 Loss: 0.174168
2023-01-02 19:54: Train Epoch 2: 379/634 Loss: 0.216713
2023-01-02 19:54: Train Epoch 2: 383/634 Loss: 0.181017
2023-01-02 19:54: Train Epoch 2: 387/634 Loss: 0.172589
2023-01-02 19:54: Train Epoch 2: 391/634 Loss: 0.172611
2023-01-02 19:54: Train Epoch 2: 395/634 Loss: 0.201670
2023-01-02 19:54: Train Epoch 2: 399/634 Loss: 0.195066
2023-01-02 19:55: Train Epoch 2: 403/634 Loss: 0.175064
2023-01-02 19:55: Train Epoch 2: 407/634 Loss: 0.198895
2023-01-02 19:55: Train Epoch 2: 411/634 Loss: 0.175931
2023-01-02 19:55: Train Epoch 2: 415/634 Loss: 0.154155
2023-01-02 19:55: Train Epoch 2: 419/634 Loss: 0.154395
2023-01-02 19:55: Train Epoch 2: 423/634 Loss: 0.201555
2023-01-02 19:55: Train Epoch 2: 427/634 Loss: 0.179639
2023-01-02 19:56: Train Epoch 2: 431/634 Loss: 0.183837
2023-01-02 19:56: Train Epoch 2: 435/634 Loss: 0.154299
2023-01-02 19:56: Train Epoch 2: 439/634 Loss: 0.187218
2023-01-02 19:56: Train Epoch 2: 443/634 Loss: 0.175921
2023-01-02 19:56: Train Epoch 2: 447/634 Loss: 0.196397
2023-01-02 19:56: Train Epoch 2: 451/634 Loss: 0.184695
2023-01-02 19:56: Train Epoch 2: 455/634 Loss: 0.155429
2023-01-02 19:57: Train Epoch 2: 459/634 Loss: 0.164020
2023-01-02 19:57: Train Epoch 2: 463/634 Loss: 0.158813
2023-01-02 19:57: Train Epoch 2: 467/634 Loss: 0.192813
2023-01-02 19:57: Train Epoch 2: 471/634 Loss: 0.186863
2023-01-02 19:57: Train Epoch 2: 475/634 Loss: 0.184940
2023-01-02 19:57: Train Epoch 2: 479/634 Loss: 0.174416
2023-01-02 19:58: Train Epoch 2: 483/634 Loss: 0.185247
2023-01-02 19:58: Train Epoch 2: 487/634 Loss: 0.202611
2023-01-02 19:58: Train Epoch 2: 491/634 Loss: 0.176680
2023-01-02 19:58: Train Epoch 2: 495/634 Loss: 0.186634
2023-01-02 19:58: Train Epoch 2: 499/634 Loss: 0.184485
2023-01-02 19:58: Train Epoch 2: 503/634 Loss: 0.173871
2023-01-02 19:58: Train Epoch 2: 507/634 Loss: 0.178865
2023-01-02 19:59: Train Epoch 2: 511/634 Loss: 0.174734
2023-01-02 19:59: Train Epoch 2: 515/634 Loss: 0.170245
2023-01-02 19:59: Train Epoch 2: 519/634 Loss: 0.170064
2023-01-02 19:59: Train Epoch 2: 523/634 Loss: 0.185802
2023-01-02 19:59: Train Epoch 2: 527/634 Loss: 0.187230
2023-01-02 19:59: Train Epoch 2: 531/634 Loss: 0.197770
2023-01-02 19:59: Train Epoch 2: 535/634 Loss: 0.187564
2023-01-02 20:00: Train Epoch 2: 539/634 Loss: 0.172912
2023-01-02 20:00: Train Epoch 2: 543/634 Loss: 0.209831
2023-01-02 20:00: Train Epoch 2: 547/634 Loss: 0.165820
2023-01-02 20:00: Train Epoch 2: 551/634 Loss: 0.160363
2023-01-02 20:00: Train Epoch 2: 555/634 Loss: 0.199783
2023-01-02 20:00: Train Epoch 2: 559/634 Loss: 0.173284
2023-01-02 20:00: Train Epoch 2: 563/634 Loss: 0.213054
2023-01-02 20:01: Train Epoch 2: 567/634 Loss: 0.193408
2023-01-02 20:01: Train Epoch 2: 571/634 Loss: 0.170961
2023-01-02 20:01: Train Epoch 2: 575/634 Loss: 0.186256
2023-01-02 20:01: Train Epoch 2: 579/634 Loss: 0.208860
2023-01-02 20:01: Train Epoch 2: 583/634 Loss: 0.197913
2023-01-02 20:01: Train Epoch 2: 587/634 Loss: 0.230962
2023-01-02 20:01: Train Epoch 2: 591/634 Loss: 0.181643
2023-01-02 20:02: Train Epoch 2: 595/634 Loss: 0.206473
2023-01-02 20:02: Train Epoch 2: 599/634 Loss: 0.189445
2023-01-02 20:02: Train Epoch 2: 603/634 Loss: 0.154868
2023-01-02 20:02: Train Epoch 2: 607/634 Loss: 0.192347
2023-01-02 20:02: Train Epoch 2: 611/634 Loss: 0.173649
2023-01-02 20:02: Train Epoch 2: 615/634 Loss: 0.204546
2023-01-02 20:02: Train Epoch 2: 619/634 Loss: 0.201222
2023-01-02 20:03: Train Epoch 2: 623/634 Loss: 0.191245
2023-01-02 20:03: Train Epoch 2: 627/634 Loss: 0.173332
2023-01-02 20:03: Train Epoch 2: 631/634 Loss: 0.176205
2023-01-02 20:03: Train Epoch 2: 633/634 Loss: 0.052727
2023-01-02 20:03: **********Train Epoch 2: averaged Loss: 0.185853 
2023-01-02 20:03: 
Epoch time elapsed: 1398.052357673645

2023-01-02 20:04: 
 metrics validation: {'precision': 0.7251289609432572, 'recall': 0.7569230769230769, 'f1-score': 0.7406849830636056, 'support': 1300, 'AUC': 0.8877720414201185, 'AUCPR': 0.8021486125535494, 'TP': 984, 'FP': 373, 'TN': 2227, 'FN': 316} 

2023-01-02 20:04: **********Val Epoch 2: average Loss: 0.188033
2023-01-02 20:04: *********************************Current best model saved!
2023-01-02 20:04: 
 Testing metrics {'precision': 0.7699490662139219, 'recall': 0.738599348534202, 'f1-score': 0.7539484621778886, 'support': 1228, 'AUC': 0.89660865102017, 'AUCPR': 0.8315538858245226, 'TP': 907, 'FP': 271, 'TN': 2185, 'FN': 321} 

2023-01-02 20:06: 
 Testing metrics {'precision': 0.8579869170711121, 'recall': 0.92262309961425, 'f1-score': 0.8891318609228077, 'support': 4407, 'AUC': 0.96772519161478, 'AUCPR': 0.9318711360885744, 'TP': 4066, 'FP': 673, 'TN': 8141, 'FN': 341} 

2023-01-02 20:07: Train Epoch 3: 3/634 Loss: 0.216151
2023-01-02 20:07: Train Epoch 3: 7/634 Loss: 0.173217
2023-01-02 20:07: Train Epoch 3: 11/634 Loss: 0.167890
2023-01-02 20:07: Train Epoch 3: 15/634 Loss: 0.191419
2023-01-02 20:07: Train Epoch 3: 19/634 Loss: 0.146101
2023-01-02 20:07: Train Epoch 3: 23/634 Loss: 0.188286
2023-01-02 20:07: Train Epoch 3: 27/634 Loss: 0.162718
2023-01-02 20:08: Train Epoch 3: 31/634 Loss: 0.153283
2023-01-02 20:08: Train Epoch 3: 35/634 Loss: 0.181449
2023-01-02 20:08: Train Epoch 3: 39/634 Loss: 0.197961
2023-01-02 20:08: Train Epoch 3: 43/634 Loss: 0.201701
2023-01-02 20:08: Train Epoch 3: 47/634 Loss: 0.167457
2023-01-02 20:08: Train Epoch 3: 51/634 Loss: 0.147201
2023-01-02 20:08: Train Epoch 3: 55/634 Loss: 0.199642
2023-01-02 20:09: Train Epoch 3: 59/634 Loss: 0.206248
2023-01-02 20:09: Train Epoch 3: 63/634 Loss: 0.192908
2023-01-02 20:09: Train Epoch 3: 67/634 Loss: 0.179219
2023-01-02 20:09: Train Epoch 3: 71/634 Loss: 0.166002
2023-01-02 20:09: Train Epoch 3: 75/634 Loss: 0.184053
2023-01-02 20:09: Train Epoch 3: 79/634 Loss: 0.160739
2023-01-02 20:09: Train Epoch 3: 83/634 Loss: 0.166880
2023-01-02 20:10: Train Epoch 3: 87/634 Loss: 0.189847
2023-01-02 20:10: Train Epoch 3: 91/634 Loss: 0.167259
2023-01-02 20:10: Train Epoch 3: 95/634 Loss: 0.176581
2023-01-02 20:10: Train Epoch 3: 99/634 Loss: 0.159216
2023-01-02 20:10: Train Epoch 3: 103/634 Loss: 0.201949
2023-01-02 20:10: Train Epoch 3: 107/634 Loss: 0.181196
2023-01-02 20:10: Train Epoch 3: 111/634 Loss: 0.183553
2023-01-02 20:11: Train Epoch 3: 115/634 Loss: 0.173918
2023-01-02 20:11: Train Epoch 3: 119/634 Loss: 0.179092
2023-01-02 20:11: Train Epoch 3: 123/634 Loss: 0.172856
2023-01-02 20:11: Train Epoch 3: 127/634 Loss: 0.159523
2023-01-02 20:11: Train Epoch 3: 131/634 Loss: 0.177237
2023-01-02 20:11: Train Epoch 3: 135/634 Loss: 0.181202
2023-01-02 20:11: Train Epoch 3: 139/634 Loss: 0.177818
2023-01-02 20:12: Train Epoch 3: 143/634 Loss: 0.175286
2023-01-02 20:12: Train Epoch 3: 147/634 Loss: 0.178966
2023-01-02 20:12: Train Epoch 3: 151/634 Loss: 0.166972
2023-01-02 20:12: Train Epoch 3: 155/634 Loss: 0.188125
2023-01-02 20:12: Train Epoch 3: 159/634 Loss: 0.161879
2023-01-02 20:12: Train Epoch 3: 163/634 Loss: 0.189660
2023-01-02 20:12: Train Epoch 3: 167/634 Loss: 0.169771
2023-01-02 20:13: Train Epoch 3: 171/634 Loss: 0.185940
2023-01-02 20:13: Train Epoch 3: 175/634 Loss: 0.153601
2023-01-02 20:13: Train Epoch 3: 179/634 Loss: 0.184344
2023-01-02 20:13: Train Epoch 3: 183/634 Loss: 0.185754
2023-01-02 20:13: Train Epoch 3: 187/634 Loss: 0.181962
2023-01-02 20:13: Train Epoch 3: 191/634 Loss: 0.156715
2023-01-02 20:13: Train Epoch 3: 195/634 Loss: 0.174067
2023-01-02 20:14: Train Epoch 3: 199/634 Loss: 0.171050
2023-01-02 20:14: Train Epoch 3: 203/634 Loss: 0.173756
2023-01-02 20:14: Train Epoch 3: 207/634 Loss: 0.167169
2023-01-02 20:14: Train Epoch 3: 211/634 Loss: 0.207374
2023-01-02 20:14: Train Epoch 3: 215/634 Loss: 0.183585
2023-01-02 20:14: Train Epoch 3: 219/634 Loss: 0.191406
2023-01-02 20:14: Train Epoch 3: 223/634 Loss: 0.167606
2023-01-02 20:15: Train Epoch 3: 227/634 Loss: 0.172586
2023-01-02 20:15: Train Epoch 3: 231/634 Loss: 0.173057
2023-01-02 20:15: Train Epoch 3: 235/634 Loss: 0.212711
2023-01-02 20:15: Train Epoch 3: 239/634 Loss: 0.186103
2023-01-02 20:15: Train Epoch 3: 243/634 Loss: 0.182211
2023-01-02 20:15: Train Epoch 3: 247/634 Loss: 0.177301
2023-01-02 20:15: Train Epoch 3: 251/634 Loss: 0.166893
2023-01-02 20:16: Train Epoch 3: 255/634 Loss: 0.148984
2023-01-02 20:16: Train Epoch 3: 259/634 Loss: 0.179852
2023-01-02 20:16: Train Epoch 3: 263/634 Loss: 0.184045
2023-01-02 20:16: Train Epoch 3: 267/634 Loss: 0.184244
2023-01-02 20:16: Train Epoch 3: 271/634 Loss: 0.179347
2023-01-02 20:16: Train Epoch 3: 275/634 Loss: 0.230952
2023-01-02 20:16: Train Epoch 3: 279/634 Loss: 0.178485
2023-01-02 20:17: Train Epoch 3: 283/634 Loss: 0.174717
2023-01-02 20:17: Train Epoch 3: 287/634 Loss: 0.158568
2023-01-02 20:17: Train Epoch 3: 291/634 Loss: 0.166848
2023-01-02 20:17: Train Epoch 3: 295/634 Loss: 0.200495
2023-01-02 20:17: Train Epoch 3: 299/634 Loss: 0.194938
2023-01-02 20:17: Train Epoch 3: 303/634 Loss: 0.153786
2023-01-02 20:17: Train Epoch 3: 307/634 Loss: 0.179552
2023-01-02 20:18: Train Epoch 3: 311/634 Loss: 0.186803
2023-01-02 20:18: Train Epoch 3: 315/634 Loss: 0.193942
2023-01-02 20:18: Train Epoch 3: 319/634 Loss: 0.182302
2023-01-02 20:18: Train Epoch 3: 323/634 Loss: 0.180037
2023-01-02 20:18: Train Epoch 3: 327/634 Loss: 0.175686
2023-01-02 20:18: Train Epoch 3: 331/634 Loss: 0.166871
2023-01-02 20:18: Train Epoch 3: 335/634 Loss: 0.168646
2023-01-02 20:19: Train Epoch 3: 339/634 Loss: 0.168563
2023-01-02 20:19: Train Epoch 3: 343/634 Loss: 0.179078
2023-01-02 20:19: Train Epoch 3: 347/634 Loss: 0.182589
2023-01-02 20:19: Train Epoch 3: 351/634 Loss: 0.188485
2023-01-02 20:19: Train Epoch 3: 355/634 Loss: 0.181826
2023-01-02 20:19: Train Epoch 3: 359/634 Loss: 0.202344
2023-01-02 20:19: Train Epoch 3: 363/634 Loss: 0.172459
2023-01-02 20:19: Train Epoch 3: 367/634 Loss: 0.178934
2023-01-02 20:20: Train Epoch 3: 371/634 Loss: 0.170364
2023-01-02 20:20: Train Epoch 3: 375/634 Loss: 0.176788
2023-01-02 20:20: Train Epoch 3: 379/634 Loss: 0.172758
2023-01-02 20:20: Train Epoch 3: 383/634 Loss: 0.161990
2023-01-02 20:20: Train Epoch 3: 387/634 Loss: 0.169652
2023-01-02 20:20: Train Epoch 3: 391/634 Loss: 0.175144
2023-01-02 20:20: Train Epoch 3: 395/634 Loss: 0.189483
2023-01-02 20:21: Train Epoch 3: 399/634 Loss: 0.176945
2023-01-02 20:21: Train Epoch 3: 403/634 Loss: 0.173095
2023-01-02 20:21: Train Epoch 3: 407/634 Loss: 0.182097
2023-01-02 20:21: Train Epoch 3: 411/634 Loss: 0.154005
2023-01-02 20:21: Train Epoch 3: 415/634 Loss: 0.182051
2023-01-02 20:21: Train Epoch 3: 419/634 Loss: 0.169782
2023-01-02 20:21: Train Epoch 3: 423/634 Loss: 0.190785
2023-01-02 20:22: Train Epoch 3: 427/634 Loss: 0.179636
2023-01-02 20:22: Train Epoch 3: 431/634 Loss: 0.184486
2023-01-02 20:22: Train Epoch 3: 435/634 Loss: 0.175317
2023-01-02 20:22: Train Epoch 3: 439/634 Loss: 0.175906
2023-01-02 20:22: Train Epoch 3: 443/634 Loss: 0.154059
2023-01-02 20:22: Train Epoch 3: 447/634 Loss: 0.163684
2023-01-02 20:22: Train Epoch 3: 451/634 Loss: 0.183848
2023-01-02 20:23: Train Epoch 3: 455/634 Loss: 0.166339
2023-01-02 20:23: Train Epoch 3: 459/634 Loss: 0.174852
2023-01-02 20:23: Train Epoch 3: 463/634 Loss: 0.159469
2023-01-02 20:23: Train Epoch 3: 467/634 Loss: 0.176397
2023-01-02 20:23: Train Epoch 3: 471/634 Loss: 0.172394
2023-01-02 20:23: Train Epoch 3: 475/634 Loss: 0.163906
2023-01-02 20:23: Train Epoch 3: 479/634 Loss: 0.177973
2023-01-02 20:24: Train Epoch 3: 483/634 Loss: 0.166133
2023-01-02 20:24: Train Epoch 3: 487/634 Loss: 0.164216
2023-01-02 20:24: Train Epoch 3: 491/634 Loss: 0.167331
2023-01-02 20:24: Train Epoch 3: 495/634 Loss: 0.189278
2023-01-02 20:24: Train Epoch 3: 499/634 Loss: 0.144533
2023-01-02 20:24: Train Epoch 3: 503/634 Loss: 0.165246
2023-01-02 20:24: Train Epoch 3: 507/634 Loss: 0.158711
2023-01-02 20:24: Train Epoch 3: 511/634 Loss: 0.169269
2023-01-02 20:25: Train Epoch 3: 515/634 Loss: 0.164254
2023-01-02 20:25: Train Epoch 3: 519/634 Loss: 0.147023
2023-01-02 20:25: Train Epoch 3: 523/634 Loss: 0.167354
2023-01-02 20:25: Train Epoch 3: 527/634 Loss: 0.180118
2023-01-02 20:25: Train Epoch 3: 531/634 Loss: 0.156686
2023-01-02 20:25: Train Epoch 3: 535/634 Loss: 0.166543
2023-01-02 20:25: Train Epoch 3: 539/634 Loss: 0.154127
2023-01-02 20:26: Train Epoch 3: 543/634 Loss: 0.155138
2023-01-02 20:26: Train Epoch 3: 547/634 Loss: 0.151498
2023-01-02 20:26: Train Epoch 3: 551/634 Loss: 0.165158
2023-01-02 20:26: Train Epoch 3: 555/634 Loss: 0.173341
2023-01-02 20:26: Train Epoch 3: 559/634 Loss: 0.173259
2023-01-02 20:26: Train Epoch 3: 563/634 Loss: 0.151023
2023-01-02 20:26: Train Epoch 3: 567/634 Loss: 0.174597
2023-01-02 20:27: Train Epoch 3: 571/634 Loss: 0.161666
2023-01-02 20:27: Train Epoch 3: 575/634 Loss: 0.167140
2023-01-02 20:27: Train Epoch 3: 579/634 Loss: 0.156009
2023-01-02 20:27: Train Epoch 3: 583/634 Loss: 0.175633
2023-01-02 20:27: Train Epoch 3: 587/634 Loss: 0.181136
2023-01-02 20:27: Train Epoch 3: 591/634 Loss: 0.172509
2023-01-02 20:27: Train Epoch 3: 595/634 Loss: 0.189841
2023-01-02 20:28: Train Epoch 3: 599/634 Loss: 0.176207
2023-01-02 20:28: Train Epoch 3: 603/634 Loss: 0.186100
2023-01-02 20:28: Train Epoch 3: 607/634 Loss: 0.163171
2023-01-02 20:28: Train Epoch 3: 611/634 Loss: 0.166504
2023-01-02 20:28: Train Epoch 3: 615/634 Loss: 0.183743
2023-01-02 20:28: Train Epoch 3: 619/634 Loss: 0.181920
2023-01-02 20:28: Train Epoch 3: 623/634 Loss: 0.159695
2023-01-02 20:29: Train Epoch 3: 627/634 Loss: 0.216660
2023-01-02 20:29: Train Epoch 3: 631/634 Loss: 0.156380
2023-01-02 20:29: Train Epoch 3: 633/634 Loss: 0.059541
2023-01-02 20:29: **********Train Epoch 3: averaged Loss: 0.174546 
2023-01-02 20:29: 
Epoch time elapsed: 1339.368860244751

2023-01-02 20:29: 
 metrics validation: {'precision': 0.7196593328601846, 'recall': 0.78, 'f1-score': 0.7486157253599114, 'support': 1300, 'AUC': 0.902080177514793, 'AUCPR': 0.8183945099471989, 'TP': 1014, 'FP': 395, 'TN': 2205, 'FN': 286} 

2023-01-02 20:29: **********Val Epoch 3: average Loss: 0.176926
2023-01-02 20:29: *********************************Current best model saved!
2023-01-02 20:30: 
 Testing metrics {'precision': 0.765905383360522, 'recall': 0.7646579804560261, 'f1-score': 0.7652811735941321, 'support': 1228, 'AUC': 0.9086402773504227, 'AUCPR': 0.8542321227383901, 'TP': 939, 'FP': 287, 'TN': 2169, 'FN': 289} 

2023-01-02 20:32: 
 Testing metrics {'precision': 0.8540161057195953, 'recall': 0.9385069208078057, 'f1-score': 0.8942702702702703, 'support': 4407, 'AUC': 0.9731436038206642, 'AUCPR': 0.9430066891289723, 'TP': 4136, 'FP': 707, 'TN': 8107, 'FN': 271} 

2023-01-02 20:32: Train Epoch 4: 3/634 Loss: 0.194151
2023-01-02 20:33: Train Epoch 4: 7/634 Loss: 0.158451
2023-01-02 20:33: Train Epoch 4: 11/634 Loss: 0.159886
2023-01-02 20:33: Train Epoch 4: 15/634 Loss: 0.179717
2023-01-02 20:33: Train Epoch 4: 19/634 Loss: 0.165305
2023-01-02 20:33: Train Epoch 4: 23/634 Loss: 0.144648
2023-01-02 20:33: Train Epoch 4: 27/634 Loss: 0.145638
2023-01-02 20:33: Train Epoch 4: 31/634 Loss: 0.156154
2023-01-02 20:34: Train Epoch 4: 35/634 Loss: 0.172910
2023-01-02 20:34: Train Epoch 4: 39/634 Loss: 0.162109
2023-01-02 20:34: Train Epoch 4: 43/634 Loss: 0.159003
2023-01-02 20:34: Train Epoch 4: 47/634 Loss: 0.175776
2023-01-02 20:34: Train Epoch 4: 51/634 Loss: 0.151235
2023-01-02 20:34: Train Epoch 4: 55/634 Loss: 0.169100
2023-01-02 20:34: Train Epoch 4: 59/634 Loss: 0.188179
2023-01-02 20:35: Train Epoch 4: 63/634 Loss: 0.187714
2023-01-02 20:35: Train Epoch 4: 67/634 Loss: 0.192066
2023-01-02 20:35: Train Epoch 4: 71/634 Loss: 0.151547
2023-01-02 20:35: Train Epoch 4: 75/634 Loss: 0.149520
2023-01-02 20:35: Train Epoch 4: 79/634 Loss: 0.162038
2023-01-02 20:35: Train Epoch 4: 83/634 Loss: 0.185877
2023-01-02 20:35: Train Epoch 4: 87/634 Loss: 0.176350
2023-01-02 20:35: Train Epoch 4: 91/634 Loss: 0.154493
2023-01-02 20:36: Train Epoch 4: 95/634 Loss: 0.153477
2023-01-02 20:36: Train Epoch 4: 99/634 Loss: 0.149674
2023-01-02 20:36: Train Epoch 4: 103/634 Loss: 0.178076
2023-01-02 20:36: Train Epoch 4: 107/634 Loss: 0.164041
2023-01-02 20:36: Train Epoch 4: 111/634 Loss: 0.152532
2023-01-02 20:36: Train Epoch 4: 115/634 Loss: 0.168995
2023-01-02 20:36: Train Epoch 4: 119/634 Loss: 0.192850
2023-01-02 20:37: Train Epoch 4: 123/634 Loss: 0.160430
2023-01-02 20:37: Train Epoch 4: 127/634 Loss: 0.192281
2023-01-02 20:37: Train Epoch 4: 131/634 Loss: 0.157847
2023-01-02 20:37: Train Epoch 4: 135/634 Loss: 0.186668
2023-01-02 20:37: Train Epoch 4: 139/634 Loss: 0.169675
2023-01-02 20:37: Train Epoch 4: 143/634 Loss: 0.178810
2023-01-02 20:37: Train Epoch 4: 147/634 Loss: 0.165648
2023-01-02 20:38: Train Epoch 4: 151/634 Loss: 0.155173
2023-01-02 20:38: Train Epoch 4: 155/634 Loss: 0.155943
2023-01-02 20:38: Train Epoch 4: 159/634 Loss: 0.140768
2023-01-02 20:38: Train Epoch 4: 163/634 Loss: 0.160421
2023-01-02 20:38: Train Epoch 4: 167/634 Loss: 0.173120
2023-01-02 20:38: Train Epoch 4: 171/634 Loss: 0.159546
2023-01-02 20:38: Train Epoch 4: 175/634 Loss: 0.145275
2023-01-02 20:38: Train Epoch 4: 179/634 Loss: 0.179262
2023-01-02 20:39: Train Epoch 4: 183/634 Loss: 0.142729
2023-01-02 20:39: Train Epoch 4: 187/634 Loss: 0.184746
2023-01-02 20:39: Train Epoch 4: 191/634 Loss: 0.140186
2023-01-02 20:39: Train Epoch 4: 195/634 Loss: 0.149672
2023-01-02 20:39: Train Epoch 4: 199/634 Loss: 0.137959
2023-01-02 20:39: Train Epoch 4: 203/634 Loss: 0.162804
2023-01-02 20:39: Train Epoch 4: 207/634 Loss: 0.157787
2023-01-02 20:40: Train Epoch 4: 211/634 Loss: 0.151969
2023-01-02 20:40: Train Epoch 4: 215/634 Loss: 0.169188
2023-01-02 20:40: Train Epoch 4: 219/634 Loss: 0.165515
2023-01-02 20:40: Train Epoch 4: 223/634 Loss: 0.176728
2023-01-02 20:40: Train Epoch 4: 227/634 Loss: 0.172206
2023-01-02 20:40: Train Epoch 4: 231/634 Loss: 0.166600
2023-01-02 20:41: Train Epoch 4: 235/634 Loss: 0.173949
2023-01-02 20:41: Train Epoch 4: 239/634 Loss: 0.163641
2023-01-02 20:41: Train Epoch 4: 243/634 Loss: 0.174810
2023-01-02 20:41: Train Epoch 4: 247/634 Loss: 0.147164
2023-01-02 20:41: Train Epoch 4: 251/634 Loss: 0.170996
2023-01-02 20:41: Train Epoch 4: 255/634 Loss: 0.160125
2023-01-02 20:41: Train Epoch 4: 259/634 Loss: 0.156512
2023-01-02 20:42: Train Epoch 4: 263/634 Loss: 0.161957
2023-01-02 20:42: Train Epoch 4: 267/634 Loss: 0.156421
2023-01-02 20:42: Train Epoch 4: 271/634 Loss: 0.165405
2023-01-02 20:42: Train Epoch 4: 275/634 Loss: 0.221538
2023-01-02 20:42: Train Epoch 4: 279/634 Loss: 0.165420
2023-01-02 20:42: Train Epoch 4: 283/634 Loss: 0.178256
2023-01-02 20:42: Train Epoch 4: 287/634 Loss: 0.175247
2023-01-02 20:43: Train Epoch 4: 291/634 Loss: 0.157679
2023-01-02 20:43: Train Epoch 4: 295/634 Loss: 0.174491
2023-01-02 20:43: Train Epoch 4: 299/634 Loss: 0.150813
2023-01-02 20:43: Train Epoch 4: 303/634 Loss: 0.159276
2023-01-02 20:43: Train Epoch 4: 307/634 Loss: 0.155311
2023-01-02 20:43: Train Epoch 4: 311/634 Loss: 0.191506
2023-01-02 20:43: Train Epoch 4: 315/634 Loss: 0.171047
2023-01-02 20:44: Train Epoch 4: 319/634 Loss: 0.148222
2023-01-02 20:44: Train Epoch 4: 323/634 Loss: 0.151204
2023-01-02 20:44: Train Epoch 4: 327/634 Loss: 0.178519
2023-01-02 20:44: Train Epoch 4: 331/634 Loss: 0.186981
2023-01-02 20:44: Train Epoch 4: 335/634 Loss: 0.151986
2023-01-02 20:44: Train Epoch 4: 339/634 Loss: 0.155019
2023-01-02 20:44: Train Epoch 4: 343/634 Loss: 0.160238
2023-01-02 20:45: Train Epoch 4: 347/634 Loss: 0.192202
2023-01-02 20:45: Train Epoch 4: 351/634 Loss: 0.155163
2023-01-02 20:45: Train Epoch 4: 355/634 Loss: 0.155257
2023-01-02 20:45: Train Epoch 4: 359/634 Loss: 0.151219
2023-01-02 20:45: Train Epoch 4: 363/634 Loss: 0.166509
2023-01-02 20:45: Train Epoch 4: 367/634 Loss: 0.163126
2023-01-02 20:45: Train Epoch 4: 371/634 Loss: 0.160871
2023-01-02 20:46: Train Epoch 4: 375/634 Loss: 0.166146
2023-01-02 20:46: Train Epoch 4: 379/634 Loss: 0.154518
2023-01-02 20:46: Train Epoch 4: 383/634 Loss: 0.179452
2023-01-02 20:46: Train Epoch 4: 387/634 Loss: 0.158676
2023-01-02 20:46: Train Epoch 4: 391/634 Loss: 0.157996
2023-01-02 20:46: Train Epoch 4: 395/634 Loss: 0.171642
2023-01-02 20:46: Train Epoch 4: 399/634 Loss: 0.181803
2023-01-02 20:47: Train Epoch 4: 403/634 Loss: 0.166029
2023-01-02 20:47: Train Epoch 4: 407/634 Loss: 0.158906
2023-01-02 20:47: Train Epoch 4: 411/634 Loss: 0.145896
2023-01-02 20:47: Train Epoch 4: 415/634 Loss: 0.152071
2023-01-02 20:47: Train Epoch 4: 419/634 Loss: 0.166098
2023-01-02 20:47: Train Epoch 4: 423/634 Loss: 0.186367
2023-01-02 20:47: Train Epoch 4: 427/634 Loss: 0.174123
2023-01-02 20:48: Train Epoch 4: 431/634 Loss: 0.171090
2023-01-02 20:48: Train Epoch 4: 435/634 Loss: 0.162357
2023-01-02 20:48: Train Epoch 4: 439/634 Loss: 0.165133
2023-01-02 20:48: Train Epoch 4: 443/634 Loss: 0.171225
2023-01-02 20:48: Train Epoch 4: 447/634 Loss: 0.182102
2023-01-02 20:48: Train Epoch 4: 451/634 Loss: 0.150742
2023-01-02 20:48: Train Epoch 4: 455/634 Loss: 0.163526
2023-01-02 20:49: Train Epoch 4: 459/634 Loss: 0.168527
2023-01-02 20:49: Train Epoch 4: 463/634 Loss: 0.177300
2023-01-02 20:49: Train Epoch 4: 467/634 Loss: 0.146650
2023-01-02 20:49: Train Epoch 4: 471/634 Loss: 0.172644
2023-01-02 20:49: Train Epoch 4: 475/634 Loss: 0.174662
2023-01-02 20:49: Train Epoch 4: 479/634 Loss: 0.157915
2023-01-02 20:49: Train Epoch 4: 483/634 Loss: 0.169398
2023-01-02 20:50: Train Epoch 4: 487/634 Loss: 0.148066
2023-01-02 20:50: Train Epoch 4: 491/634 Loss: 0.148135
2023-01-02 20:50: Train Epoch 4: 495/634 Loss: 0.149349
2023-01-02 20:50: Train Epoch 4: 499/634 Loss: 0.171985
2023-01-02 20:50: Train Epoch 4: 503/634 Loss: 0.176557
2023-01-02 20:50: Train Epoch 4: 507/634 Loss: 0.168816
2023-01-02 20:50: Train Epoch 4: 511/634 Loss: 0.160203
2023-01-02 20:50: Train Epoch 4: 515/634 Loss: 0.163317
2023-01-02 20:51: Train Epoch 4: 519/634 Loss: 0.181552
2023-01-02 20:51: Train Epoch 4: 523/634 Loss: 0.149695
2023-01-02 20:51: Train Epoch 4: 527/634 Loss: 0.173649
2023-01-02 20:51: Train Epoch 4: 531/634 Loss: 0.171104
2023-01-02 20:51: Train Epoch 4: 535/634 Loss: 0.173457
2023-01-02 20:51: Train Epoch 4: 539/634 Loss: 0.170073
2023-01-02 20:51: Train Epoch 4: 543/634 Loss: 0.183500
2023-01-02 20:52: Train Epoch 4: 547/634 Loss: 0.179316
2023-01-02 20:52: Train Epoch 4: 551/634 Loss: 0.157875
2023-01-02 20:52: Train Epoch 4: 555/634 Loss: 0.174855
2023-01-02 20:52: Train Epoch 4: 559/634 Loss: 0.203585
2023-01-02 20:52: Train Epoch 4: 563/634 Loss: 0.159682
2023-01-02 20:52: Train Epoch 4: 567/634 Loss: 0.153896
2023-01-02 20:52: Train Epoch 4: 571/634 Loss: 0.157631
2023-01-02 20:52: Train Epoch 4: 575/634 Loss: 0.169955
2023-01-02 20:53: Train Epoch 4: 579/634 Loss: 0.177190
2023-01-02 20:53: Train Epoch 4: 583/634 Loss: 0.147791
2023-01-02 20:53: Train Epoch 4: 587/634 Loss: 0.197108
2023-01-02 20:53: Train Epoch 4: 591/634 Loss: 0.166569
2023-01-02 20:53: Train Epoch 4: 595/634 Loss: 0.176639
2023-01-02 20:53: Train Epoch 4: 599/634 Loss: 0.150574
2023-01-02 20:53: Train Epoch 4: 603/634 Loss: 0.180732
2023-01-02 20:53: Train Epoch 4: 607/634 Loss: 0.157298
2023-01-02 20:54: Train Epoch 4: 611/634 Loss: 0.192119
2023-01-02 20:54: Train Epoch 4: 615/634 Loss: 0.147948
2023-01-02 20:54: Train Epoch 4: 619/634 Loss: 0.161106
2023-01-02 20:54: Train Epoch 4: 623/634 Loss: 0.165351
2023-01-02 20:54: Train Epoch 4: 627/634 Loss: 0.167018
2023-01-02 20:54: Train Epoch 4: 631/634 Loss: 0.153898
2023-01-02 20:54: Train Epoch 4: 633/634 Loss: 0.061618
2023-01-02 20:54: **********Train Epoch 4: averaged Loss: 0.165225 
2023-01-02 20:54: 
Epoch time elapsed: 1319.6711685657501

2023-01-02 20:55: 
 metrics validation: {'precision': 0.8442622950819673, 'recall': 0.4753846153846154, 'f1-score': 0.6082677165354331, 'support': 1300, 'AUC': 0.9134556213017752, 'AUCPR': 0.8360239409708371, 'TP': 618, 'FP': 114, 'TN': 2486, 'FN': 682} 

2023-01-02 20:55: **********Val Epoch 4: average Loss: 0.189662
2023-01-02 20:56: 
 Testing metrics {'precision': 0.765905383360522, 'recall': 0.7646579804560261, 'f1-score': 0.7652811735941321, 'support': 1228, 'AUC': 0.9086402773504227, 'AUCPR': 0.8542321227383901, 'TP': 939, 'FP': 287, 'TN': 2169, 'FN': 289} 

2023-01-02 20:58: 
 Testing metrics {'precision': 0.8540161057195953, 'recall': 0.9385069208078057, 'f1-score': 0.8942702702702703, 'support': 4407, 'AUC': 0.9731436038206642, 'AUCPR': 0.9430066891289723, 'TP': 4136, 'FP': 707, 'TN': 8107, 'FN': 271} 

2023-01-02 20:58: Train Epoch 5: 3/634 Loss: 0.156965
2023-01-02 20:58: Train Epoch 5: 7/634 Loss: 0.153360
2023-01-02 20:58: Train Epoch 5: 11/634 Loss: 0.176721
2023-01-02 20:58: Train Epoch 5: 15/634 Loss: 0.188759
2023-01-02 20:58: Train Epoch 5: 19/634 Loss: 0.171780
2023-01-02 20:59: Train Epoch 5: 23/634 Loss: 0.172866
2023-01-02 20:59: Train Epoch 5: 27/634 Loss: 0.206636
2023-01-02 20:59: Train Epoch 5: 31/634 Loss: 0.159318
2023-01-02 20:59: Train Epoch 5: 35/634 Loss: 0.179827
2023-01-02 20:59: Train Epoch 5: 39/634 Loss: 0.155473
2023-01-02 20:59: Train Epoch 5: 43/634 Loss: 0.179847
2023-01-02 20:59: Train Epoch 5: 47/634 Loss: 0.179724
2023-01-02 21:00: Train Epoch 5: 51/634 Loss: 0.182788
2023-01-02 21:00: Train Epoch 5: 55/634 Loss: 0.169418
2023-01-02 21:00: Train Epoch 5: 59/634 Loss: 0.167447
2023-01-02 21:00: Train Epoch 5: 63/634 Loss: 0.174812
2023-01-02 21:00: Train Epoch 5: 67/634 Loss: 0.173023
2023-01-02 21:00: Train Epoch 5: 71/634 Loss: 0.169322
2023-01-02 21:00: Train Epoch 5: 75/634 Loss: 0.165495
2023-01-02 21:01: Train Epoch 5: 79/634 Loss: 0.147963
2023-01-02 21:01: Train Epoch 5: 83/634 Loss: 0.151657
2023-01-02 21:01: Train Epoch 5: 87/634 Loss: 0.176030
2023-01-02 21:01: Train Epoch 5: 91/634 Loss: 0.165562
2023-01-02 21:01: Train Epoch 5: 95/634 Loss: 0.147387
2023-01-02 21:01: Train Epoch 5: 99/634 Loss: 0.165720
2023-01-02 21:01: Train Epoch 5: 103/634 Loss: 0.170024
2023-01-02 21:02: Train Epoch 5: 107/634 Loss: 0.152716
2023-01-02 21:02: Train Epoch 5: 111/634 Loss: 0.147023
2023-01-02 21:02: Train Epoch 5: 115/634 Loss: 0.171622
2023-01-02 21:02: Train Epoch 5: 119/634 Loss: 0.174953
2023-01-02 21:02: Train Epoch 5: 123/634 Loss: 0.159142
2023-01-02 21:02: Train Epoch 5: 127/634 Loss: 0.161398
2023-01-02 21:02: Train Epoch 5: 131/634 Loss: 0.153716
2023-01-02 21:03: Train Epoch 5: 135/634 Loss: 0.189823
2023-01-02 21:03: Train Epoch 5: 139/634 Loss: 0.171666
2023-01-02 21:03: Train Epoch 5: 143/634 Loss: 0.150052
2023-01-02 21:03: Train Epoch 5: 147/634 Loss: 0.163498
2023-01-02 21:03: Train Epoch 5: 151/634 Loss: 0.150727
2023-01-02 21:03: Train Epoch 5: 155/634 Loss: 0.162277
2023-01-02 21:03: Train Epoch 5: 159/634 Loss: 0.171674
2023-01-02 21:04: Train Epoch 5: 163/634 Loss: 0.181233
2023-01-02 21:04: Train Epoch 5: 167/634 Loss: 0.159671
2023-01-02 21:04: Train Epoch 5: 171/634 Loss: 0.182382
2023-01-02 21:04: Train Epoch 5: 175/634 Loss: 0.184481
2023-01-02 21:04: Train Epoch 5: 179/634 Loss: 0.157859
2023-01-02 21:04: Train Epoch 5: 183/634 Loss: 0.156863
2023-01-02 21:04: Train Epoch 5: 187/634 Loss: 0.172169
2023-01-02 21:04: Train Epoch 5: 191/634 Loss: 0.163875
2023-01-02 21:05: Train Epoch 5: 195/634 Loss: 0.170497
2023-01-02 21:05: Train Epoch 5: 199/634 Loss: 0.174183
2023-01-02 21:05: Train Epoch 5: 203/634 Loss: 0.164483
2023-01-02 21:05: Train Epoch 5: 207/634 Loss: 0.153553
2023-01-02 21:05: Train Epoch 5: 211/634 Loss: 0.170983
2023-01-02 21:05: Train Epoch 5: 215/634 Loss: 0.157084
2023-01-02 21:05: Train Epoch 5: 219/634 Loss: 0.178450
2023-01-02 21:06: Train Epoch 5: 223/634 Loss: 0.149187
2023-01-02 21:06: Train Epoch 5: 227/634 Loss: 0.182070
2023-01-02 21:06: Train Epoch 5: 231/634 Loss: 0.163227
2023-01-02 21:06: Train Epoch 5: 235/634 Loss: 0.168712
2023-01-02 21:06: Train Epoch 5: 239/634 Loss: 0.180394
2023-01-02 21:06: Train Epoch 5: 243/634 Loss: 0.166301
2023-01-02 21:06: Train Epoch 5: 247/634 Loss: 0.155678
2023-01-02 21:07: Train Epoch 5: 251/634 Loss: 0.140634
2023-01-02 21:07: Train Epoch 5: 255/634 Loss: 0.179014
2023-01-02 21:07: Train Epoch 5: 259/634 Loss: 0.165586
2023-01-02 21:07: Train Epoch 5: 263/634 Loss: 0.171072
2023-01-02 21:07: Train Epoch 5: 267/634 Loss: 0.160280
2023-01-02 21:07: Train Epoch 5: 271/634 Loss: 0.154700
2023-01-02 21:07: Train Epoch 5: 275/634 Loss: 0.138196
2023-01-02 21:08: Train Epoch 5: 279/634 Loss: 0.158867
2023-01-02 21:08: Train Epoch 5: 283/634 Loss: 0.161989
2023-01-02 21:08: Train Epoch 5: 287/634 Loss: 0.149756
2023-01-02 21:08: Train Epoch 5: 291/634 Loss: 0.182593
2023-01-02 21:08: Train Epoch 5: 295/634 Loss: 0.139605
2023-01-02 21:08: Train Epoch 5: 299/634 Loss: 0.173631
2023-01-02 21:08: Train Epoch 5: 303/634 Loss: 0.152959
2023-01-02 21:09: Train Epoch 5: 307/634 Loss: 0.148465
2023-01-02 21:09: Train Epoch 5: 311/634 Loss: 0.163172
2023-01-02 21:09: Train Epoch 5: 315/634 Loss: 0.197012
2023-01-02 21:09: Train Epoch 5: 319/634 Loss: 0.150408
2023-01-02 21:09: Train Epoch 5: 323/634 Loss: 0.176970
2023-01-02 21:09: Train Epoch 5: 327/634 Loss: 0.181533
2023-01-02 21:09: Train Epoch 5: 331/634 Loss: 0.173997
2023-01-02 21:09: Train Epoch 5: 335/634 Loss: 0.163602
2023-01-02 21:10: Train Epoch 5: 339/634 Loss: 0.186404
2023-01-02 21:10: Train Epoch 5: 343/634 Loss: 0.175703
2023-01-02 21:10: Train Epoch 5: 347/634 Loss: 0.167754
2023-01-02 21:10: Train Epoch 5: 351/634 Loss: 0.168065
2023-01-02 21:10: Train Epoch 5: 355/634 Loss: 0.169354
2023-01-02 21:10: Train Epoch 5: 359/634 Loss: 0.177157
2023-01-02 21:10: Train Epoch 5: 363/634 Loss: 0.168515
2023-01-02 21:11: Train Epoch 5: 367/634 Loss: 0.166872
2023-01-02 21:11: Train Epoch 5: 371/634 Loss: 0.152723
2023-01-02 21:11: Train Epoch 5: 375/634 Loss: 0.162832
2023-01-02 21:11: Train Epoch 5: 379/634 Loss: 0.153095
2023-01-02 21:11: Train Epoch 5: 383/634 Loss: 0.164101
2023-01-02 21:11: Train Epoch 5: 387/634 Loss: 0.163495
2023-01-02 21:11: Train Epoch 5: 391/634 Loss: 0.181916
2023-01-02 21:12: Train Epoch 5: 395/634 Loss: 0.170149
2023-01-02 21:12: Train Epoch 5: 399/634 Loss: 0.149275
2023-01-02 21:12: Train Epoch 5: 403/634 Loss: 0.185710
2023-01-02 21:12: Train Epoch 5: 407/634 Loss: 0.167731
2023-01-02 21:12: Train Epoch 5: 411/634 Loss: 0.160642
2023-01-02 21:12: Train Epoch 5: 415/634 Loss: 0.150664
2023-01-02 21:12: Train Epoch 5: 419/634 Loss: 0.147948
2023-01-02 21:13: Train Epoch 5: 423/634 Loss: 0.160423
2023-01-02 21:13: Train Epoch 5: 427/634 Loss: 0.149640
2023-01-02 21:13: Train Epoch 5: 431/634 Loss: 0.167382
2023-01-02 21:13: Train Epoch 5: 435/634 Loss: 0.137881
2023-01-02 21:13: Train Epoch 5: 439/634 Loss: 0.153518
2023-01-02 21:13: Train Epoch 5: 443/634 Loss: 0.143719
2023-01-02 21:13: Train Epoch 5: 447/634 Loss: 0.188670
2023-01-02 21:14: Train Epoch 5: 451/634 Loss: 0.164568
2023-01-02 21:14: Train Epoch 5: 455/634 Loss: 0.130193
2023-01-02 21:14: Train Epoch 5: 459/634 Loss: 0.183995
2023-01-02 21:14: Train Epoch 5: 463/634 Loss: 0.168470
2023-01-02 21:14: Train Epoch 5: 467/634 Loss: 0.161249
2023-01-02 21:14: Train Epoch 5: 471/634 Loss: 0.141099
2023-01-02 21:14: Train Epoch 5: 475/634 Loss: 0.158210
2023-01-02 21:15: Train Epoch 5: 479/634 Loss: 0.166156
2023-01-02 21:15: Train Epoch 5: 483/634 Loss: 0.160274
2023-01-02 21:15: Train Epoch 5: 487/634 Loss: 0.169904
2023-01-02 21:15: Train Epoch 5: 491/634 Loss: 0.168357
2023-01-02 21:15: Train Epoch 5: 495/634 Loss: 0.155620
2023-01-02 21:15: Train Epoch 5: 499/634 Loss: 0.166068
2023-01-02 21:15: Train Epoch 5: 503/634 Loss: 0.166636
2023-01-02 21:16: Train Epoch 5: 507/634 Loss: 0.160026
2023-01-02 21:16: Train Epoch 5: 511/634 Loss: 0.157345
2023-01-02 21:16: Train Epoch 5: 515/634 Loss: 0.146703
2023-01-02 21:16: Train Epoch 5: 519/634 Loss: 0.163345
2023-01-02 21:16: Train Epoch 5: 523/634 Loss: 0.157941
2023-01-02 21:16: Train Epoch 5: 527/634 Loss: 0.151734
2023-01-02 21:16: Train Epoch 5: 531/634 Loss: 0.156857
2023-01-02 21:17: Train Epoch 5: 535/634 Loss: 0.164958
2023-01-02 21:17: Train Epoch 5: 539/634 Loss: 0.147674
2023-01-02 21:17: Train Epoch 5: 543/634 Loss: 0.177145
2023-01-02 21:17: Train Epoch 5: 547/634 Loss: 0.156498
2023-01-02 21:17: Train Epoch 5: 551/634 Loss: 0.144365
2023-01-02 21:17: Train Epoch 5: 555/634 Loss: 0.181263
2023-01-02 21:17: Train Epoch 5: 559/634 Loss: 0.173533
2023-01-02 21:18: Train Epoch 5: 563/634 Loss: 0.171745
2023-01-02 21:18: Train Epoch 5: 567/634 Loss: 0.144062
2023-01-02 21:18: Train Epoch 5: 571/634 Loss: 0.152034
2023-01-02 21:18: Train Epoch 5: 575/634 Loss: 0.167939
2023-01-02 21:18: Train Epoch 5: 579/634 Loss: 0.169554
2023-01-02 21:18: Train Epoch 5: 583/634 Loss: 0.193773
2023-01-02 21:18: Train Epoch 5: 587/634 Loss: 0.169452
2023-01-02 21:19: Train Epoch 5: 591/634 Loss: 0.151370
2023-01-02 21:19: Train Epoch 5: 595/634 Loss: 0.175179
2023-01-02 21:19: Train Epoch 5: 599/634 Loss: 0.184366
2023-01-02 21:19: Train Epoch 5: 603/634 Loss: 0.176362
2023-01-02 21:19: Train Epoch 5: 607/634 Loss: 0.167115
2023-01-02 21:19: Train Epoch 5: 611/634 Loss: 0.180584
2023-01-02 21:19: Train Epoch 5: 615/634 Loss: 0.141545
2023-01-02 21:20: Train Epoch 5: 619/634 Loss: 0.173989
2023-01-02 21:20: Train Epoch 5: 623/634 Loss: 0.145732
2023-01-02 21:20: Train Epoch 5: 627/634 Loss: 0.173075
2023-01-02 21:20: Train Epoch 5: 631/634 Loss: 0.191891
2023-01-02 21:20: Train Epoch 5: 633/634 Loss: 0.084604
2023-01-02 21:20: **********Train Epoch 5: averaged Loss: 0.164601 
2023-01-02 21:20: 
Epoch time elapsed: 1337.1239986419678

2023-01-02 21:21: 
 metrics validation: {'precision': 0.7096336499321574, 'recall': 0.8046153846153846, 'f1-score': 0.754145638067772, 'support': 1300, 'AUC': 0.9025791420118343, 'AUCPR': 0.8222430673212944, 'TP': 1046, 'FP': 428, 'TN': 2172, 'FN': 254} 

2023-01-02 21:21: **********Val Epoch 5: average Loss: 0.178429
2023-01-02 21:21: 
 Testing metrics {'precision': 0.765905383360522, 'recall': 0.7646579804560261, 'f1-score': 0.7652811735941321, 'support': 1228, 'AUC': 0.9086402773504227, 'AUCPR': 0.8542321227383901, 'TP': 939, 'FP': 287, 'TN': 2169, 'FN': 289} 

2023-01-02 21:24: 
 Testing metrics {'precision': 0.8540161057195953, 'recall': 0.9385069208078057, 'f1-score': 0.8942702702702703, 'support': 4407, 'AUC': 0.9731436038206642, 'AUCPR': 0.9430066891289723, 'TP': 4136, 'FP': 707, 'TN': 8107, 'FN': 271} 

2023-01-02 21:24: Train Epoch 6: 3/634 Loss: 0.161849
2023-01-02 21:24: Train Epoch 6: 7/634 Loss: 0.163817
2023-01-02 21:24: Train Epoch 6: 11/634 Loss: 0.173110
2023-01-02 21:24: Train Epoch 6: 15/634 Loss: 0.145632
2023-01-02 21:24: Train Epoch 6: 19/634 Loss: 0.162046
2023-01-02 21:24: Train Epoch 6: 23/634 Loss: 0.154693
2023-01-02 21:25: Train Epoch 6: 27/634 Loss: 0.156573
2023-01-02 21:25: Train Epoch 6: 31/634 Loss: 0.161344
2023-01-02 21:25: Train Epoch 6: 35/634 Loss: 0.169935
2023-01-02 21:25: Train Epoch 6: 39/634 Loss: 0.154242
2023-01-02 21:25: Train Epoch 6: 43/634 Loss: 0.156711
2023-01-02 21:25: Train Epoch 6: 47/634 Loss: 0.167263
2023-01-02 21:25: Train Epoch 6: 51/634 Loss: 0.173363
2023-01-02 21:25: Train Epoch 6: 55/634 Loss: 0.207244
2023-01-02 21:26: Train Epoch 6: 59/634 Loss: 0.153009
2023-01-02 21:26: Train Epoch 6: 63/634 Loss: 0.158507
2023-01-02 21:26: Train Epoch 6: 67/634 Loss: 0.153696
2023-01-02 21:26: Train Epoch 6: 71/634 Loss: 0.174539
2023-01-02 21:26: Train Epoch 6: 75/634 Loss: 0.184822
2023-01-02 21:26: Train Epoch 6: 79/634 Loss: 0.168814
2023-01-02 21:26: Train Epoch 6: 83/634 Loss: 0.174014
2023-01-02 21:27: Train Epoch 6: 87/634 Loss: 0.169699
2023-01-02 21:27: Train Epoch 6: 91/634 Loss: 0.177438
2023-01-02 21:27: Train Epoch 6: 95/634 Loss: 0.181136
2023-01-02 21:27: Train Epoch 6: 99/634 Loss: 0.189073
2023-01-02 21:27: Train Epoch 6: 103/634 Loss: 0.175554
2023-01-02 21:27: Train Epoch 6: 107/634 Loss: 0.173218
2023-01-02 21:28: Train Epoch 6: 111/634 Loss: 0.158068
2023-01-02 21:28: Train Epoch 6: 115/634 Loss: 0.175420
2023-01-02 21:28: Train Epoch 6: 119/634 Loss: 0.169810
2023-01-02 21:28: Train Epoch 6: 123/634 Loss: 0.187415
2023-01-02 21:28: Train Epoch 6: 127/634 Loss: 0.173447
2023-01-02 21:28: Train Epoch 6: 131/634 Loss: 0.180546
2023-01-02 21:28: Train Epoch 6: 135/634 Loss: 0.176110
2023-01-02 21:29: Train Epoch 6: 139/634 Loss: 0.159907
2023-01-02 21:29: Train Epoch 6: 143/634 Loss: 0.187137
2023-01-02 21:29: Train Epoch 6: 147/634 Loss: 0.183343
2023-01-02 21:29: Train Epoch 6: 151/634 Loss: 0.130051
2023-01-02 21:29: Train Epoch 6: 155/634 Loss: 0.181312
2023-01-02 21:29: Train Epoch 6: 159/634 Loss: 0.146947
2023-01-02 21:29: Train Epoch 6: 163/634 Loss: 0.174108
2023-01-02 21:30: Train Epoch 6: 167/634 Loss: 0.173317
2023-01-02 21:30: Train Epoch 6: 171/634 Loss: 0.136739
2023-01-02 21:30: Train Epoch 6: 175/634 Loss: 0.156851
2023-01-02 21:30: Train Epoch 6: 179/634 Loss: 0.178373
2023-01-02 21:30: Train Epoch 6: 183/634 Loss: 0.171723
2023-01-02 21:30: Train Epoch 6: 187/634 Loss: 0.155581
2023-01-02 21:31: Train Epoch 6: 191/634 Loss: 0.196760
2023-01-02 21:31: Train Epoch 6: 195/634 Loss: 0.191688
2023-01-02 21:31: Train Epoch 6: 199/634 Loss: 0.152297
2023-01-02 21:31: Train Epoch 6: 203/634 Loss: 0.196120
2023-01-02 21:31: Train Epoch 6: 207/634 Loss: 0.179184
2023-01-02 21:31: Train Epoch 6: 211/634 Loss: 0.157823
2023-01-02 21:31: Train Epoch 6: 215/634 Loss: 0.165046
2023-01-02 21:31: Train Epoch 6: 219/634 Loss: 0.145441
2023-01-02 21:32: Train Epoch 6: 223/634 Loss: 0.149779
2023-01-02 21:32: Train Epoch 6: 227/634 Loss: 0.145069
2023-01-02 21:32: Train Epoch 6: 231/634 Loss: 0.190195
2023-01-02 21:32: Train Epoch 6: 235/634 Loss: 0.152519
2023-01-02 21:32: Train Epoch 6: 239/634 Loss: 0.163319
2023-01-02 21:32: Train Epoch 6: 243/634 Loss: 0.146354
2023-01-02 21:32: Train Epoch 6: 247/634 Loss: 0.165379
2023-01-02 21:33: Train Epoch 6: 251/634 Loss: 0.159232
2023-01-02 21:33: Train Epoch 6: 255/634 Loss: 0.148706
2023-01-02 21:33: Train Epoch 6: 259/634 Loss: 0.172788
2023-01-02 21:33: Train Epoch 6: 263/634 Loss: 0.175907
2023-01-02 21:33: Train Epoch 6: 267/634 Loss: 0.185531
2023-01-02 21:33: Train Epoch 6: 271/634 Loss: 0.166731
2023-01-02 21:33: Train Epoch 6: 275/634 Loss: 0.176094
2023-01-02 21:34: Train Epoch 6: 279/634 Loss: 0.156480
2023-01-02 21:34: Train Epoch 6: 283/634 Loss: 0.159189
2023-01-02 21:34: Train Epoch 6: 287/634 Loss: 0.166988
2023-01-02 21:34: Train Epoch 6: 291/634 Loss: 0.174689
2023-01-02 21:34: Train Epoch 6: 295/634 Loss: 0.164651
2023-01-02 21:34: Train Epoch 6: 299/634 Loss: 0.151209
2023-01-02 21:34: Train Epoch 6: 303/634 Loss: 0.163400
2023-01-02 21:35: Train Epoch 6: 307/634 Loss: 0.171239
2023-01-02 21:35: Train Epoch 6: 311/634 Loss: 0.154295
2023-01-02 21:35: Train Epoch 6: 315/634 Loss: 0.163392
2023-01-02 21:35: Train Epoch 6: 319/634 Loss: 0.167422
2023-01-02 21:35: Train Epoch 6: 323/634 Loss: 0.140057
2023-01-02 21:35: Train Epoch 6: 327/634 Loss: 0.146249
2023-01-02 21:36: Train Epoch 6: 331/634 Loss: 0.170218
2023-01-02 21:36: Train Epoch 6: 335/634 Loss: 0.164507
2023-01-02 21:36: Train Epoch 6: 339/634 Loss: 0.164798
2023-01-02 21:36: Train Epoch 6: 343/634 Loss: 0.163083
2023-01-02 21:36: Train Epoch 6: 347/634 Loss: 0.163692
2023-01-02 21:36: Train Epoch 6: 351/634 Loss: 0.156933
2023-01-02 21:36: Train Epoch 6: 355/634 Loss: 0.164777
2023-01-02 21:37: Train Epoch 6: 359/634 Loss: 0.184749
2023-01-02 21:37: Train Epoch 6: 363/634 Loss: 0.185773
2023-01-02 21:37: Train Epoch 6: 367/634 Loss: 0.202374
2023-01-02 21:37: Train Epoch 6: 371/634 Loss: 0.147069
2023-01-02 21:37: Train Epoch 6: 375/634 Loss: 0.147687
2023-01-02 21:37: Train Epoch 6: 379/634 Loss: 0.178898
2023-01-02 21:37: Train Epoch 6: 383/634 Loss: 0.169618
2023-01-02 21:38: Train Epoch 6: 387/634 Loss: 0.156276
2023-01-02 21:38: Train Epoch 6: 391/634 Loss: 0.159105
2023-01-02 21:38: Train Epoch 6: 395/634 Loss: 0.165547
2023-01-02 21:38: Train Epoch 6: 399/634 Loss: 0.159246
2023-01-02 21:38: Train Epoch 6: 403/634 Loss: 0.157363
2023-01-02 21:38: Train Epoch 6: 407/634 Loss: 0.143721
2023-01-02 21:38: Train Epoch 6: 411/634 Loss: 0.194551
2023-01-02 21:39: Train Epoch 6: 415/634 Loss: 0.152831
2023-01-02 21:39: Train Epoch 6: 419/634 Loss: 0.160843
2023-01-02 21:39: Train Epoch 6: 423/634 Loss: 0.167667
2023-01-02 21:39: Train Epoch 6: 427/634 Loss: 0.177528
2023-01-02 21:39: Train Epoch 6: 431/634 Loss: 0.171464
2023-01-02 21:39: Train Epoch 6: 435/634 Loss: 0.192948
2023-01-02 21:40: Train Epoch 6: 439/634 Loss: 0.176227
2023-01-02 21:40: Train Epoch 6: 443/634 Loss: 0.173249
2023-01-02 21:40: Train Epoch 6: 447/634 Loss: 0.186684
2023-01-02 21:40: Train Epoch 6: 451/634 Loss: 0.159176
2023-01-02 21:40: Train Epoch 6: 455/634 Loss: 0.158428
2023-01-02 21:40: Train Epoch 6: 459/634 Loss: 0.163928
2023-01-02 21:40: Train Epoch 6: 463/634 Loss: 0.160044
2023-01-02 21:40: Train Epoch 6: 467/634 Loss: 0.133842
2023-01-02 21:41: Train Epoch 6: 471/634 Loss: 0.176001
2023-01-02 21:41: Train Epoch 6: 475/634 Loss: 0.153159
2023-01-02 21:41: Train Epoch 6: 479/634 Loss: 0.139048
2023-01-02 21:41: Train Epoch 6: 483/634 Loss: 0.147447
2023-01-02 21:41: Train Epoch 6: 487/634 Loss: 0.153976
2023-01-02 21:41: Train Epoch 6: 491/634 Loss: 0.166670
2023-01-02 21:41: Train Epoch 6: 495/634 Loss: 0.136059
2023-01-02 21:42: Train Epoch 6: 499/634 Loss: 0.150975
2023-01-02 21:42: Train Epoch 6: 503/634 Loss: 0.171777
2023-01-02 21:42: Train Epoch 6: 507/634 Loss: 0.153615
2023-01-02 21:42: Train Epoch 6: 511/634 Loss: 0.176553
2023-01-02 21:42: Train Epoch 6: 515/634 Loss: 0.168508
2023-01-02 21:42: Train Epoch 6: 519/634 Loss: 0.185440
2023-01-02 21:42: Train Epoch 6: 523/634 Loss: 0.148462
2023-01-02 21:43: Train Epoch 6: 527/634 Loss: 0.158949
2023-01-02 21:43: Train Epoch 6: 531/634 Loss: 0.139190
2023-01-02 21:43: Train Epoch 6: 535/634 Loss: 0.155843
2023-01-02 21:43: Train Epoch 6: 539/634 Loss: 0.173728
2023-01-02 21:43: Train Epoch 6: 543/634 Loss: 0.179068
2023-01-02 21:43: Train Epoch 6: 547/634 Loss: 0.156808
2023-01-02 21:43: Train Epoch 6: 551/634 Loss: 0.182302
2023-01-02 21:44: Train Epoch 6: 555/634 Loss: 0.159197
2023-01-02 21:44: Train Epoch 6: 559/634 Loss: 0.157348
2023-01-02 21:44: Train Epoch 6: 563/634 Loss: 0.172199
2023-01-02 21:44: Train Epoch 6: 567/634 Loss: 0.174562
2023-01-02 21:44: Train Epoch 6: 571/634 Loss: 0.163428
2023-01-02 21:44: Train Epoch 6: 575/634 Loss: 0.161457
2023-01-02 21:44: Train Epoch 6: 579/634 Loss: 0.150222
2023-01-02 21:45: Train Epoch 6: 583/634 Loss: 0.172936
2023-01-02 21:45: Train Epoch 6: 587/634 Loss: 0.147418
2023-01-02 21:45: Train Epoch 6: 591/634 Loss: 0.148730
2023-01-02 21:45: Train Epoch 6: 595/634 Loss: 0.183901
2023-01-02 21:45: Train Epoch 6: 599/634 Loss: 0.169499
2023-01-02 21:45: Train Epoch 6: 603/634 Loss: 0.192720
2023-01-02 21:45: Train Epoch 6: 607/634 Loss: 0.177131
2023-01-02 21:46: Train Epoch 6: 611/634 Loss: 0.163307
2023-01-02 21:46: Train Epoch 6: 615/634 Loss: 0.175392
2023-01-02 21:46: Train Epoch 6: 619/634 Loss: 0.173909
2023-01-02 21:46: Train Epoch 6: 623/634 Loss: 0.148809
2023-01-02 21:46: Train Epoch 6: 627/634 Loss: 0.172345
2023-01-02 21:46: Train Epoch 6: 631/634 Loss: 0.165397
2023-01-02 21:46: Train Epoch 6: 633/634 Loss: 0.064725
2023-01-02 21:46: **********Train Epoch 6: averaged Loss: 0.165169 
2023-01-02 21:46: 
Epoch time elapsed: 1366.6164207458496

2023-01-02 21:47: 
 metrics validation: {'precision': 0.8125689084895259, 'recall': 0.566923076923077, 'f1-score': 0.6678749433620299, 'support': 1300, 'AUC': 0.918042899408284, 'AUCPR': 0.8423401442927543, 'TP': 737, 'FP': 170, 'TN': 2430, 'FN': 563} 

2023-01-02 21:47: **********Val Epoch 6: average Loss: 0.170007
2023-01-02 21:47: *********************************Current best model saved!
2023-01-02 21:47: 
 Testing metrics {'precision': 0.8741258741258742, 'recall': 0.6107491856677525, 'f1-score': 0.7190795781399809, 'support': 1228, 'AUC': 0.9100358491867289, 'AUCPR': 0.856152971036096, 'TP': 750, 'FP': 108, 'TN': 2348, 'FN': 478} 

2023-01-02 21:50: 
 Testing metrics {'precision': 0.9217021276595745, 'recall': 0.7372362151123213, 'f1-score': 0.819213313161876, 'support': 4407, 'AUC': 0.9686718671519601, 'AUCPR': 0.9310269927675575, 'TP': 3249, 'FP': 276, 'TN': 8538, 'FN': 1158} 

2023-01-02 21:50: Train Epoch 7: 3/634 Loss: 0.158560
2023-01-02 21:50: Train Epoch 7: 7/634 Loss: 0.154754
2023-01-02 21:50: Train Epoch 7: 11/634 Loss: 0.181164
2023-01-02 21:50: Train Epoch 7: 15/634 Loss: 0.182558
2023-01-02 21:50: Train Epoch 7: 19/634 Loss: 0.159059
2023-01-02 21:51: Train Epoch 7: 23/634 Loss: 0.173046
2023-01-02 21:51: Train Epoch 7: 27/634 Loss: 0.156177
2023-01-02 21:51: Train Epoch 7: 31/634 Loss: 0.142541
2023-01-02 21:51: Train Epoch 7: 35/634 Loss: 0.153907
2023-01-02 21:51: Train Epoch 7: 39/634 Loss: 0.159341
2023-01-02 21:51: Train Epoch 7: 43/634 Loss: 0.179898
2023-01-02 21:51: Train Epoch 7: 47/634 Loss: 0.154702
2023-01-02 21:52: Train Epoch 7: 51/634 Loss: 0.154768
2023-01-02 21:52: Train Epoch 7: 55/634 Loss: 0.139140
2023-01-02 21:52: Train Epoch 7: 59/634 Loss: 0.166152
2023-01-02 21:52: Train Epoch 7: 63/634 Loss: 0.173590
2023-01-02 21:52: Train Epoch 7: 67/634 Loss: 0.160957
2023-01-02 21:52: Train Epoch 7: 71/634 Loss: 0.141470
2023-01-02 21:52: Train Epoch 7: 75/634 Loss: 0.133202
2023-01-02 21:53: Train Epoch 7: 79/634 Loss: 0.147801
2023-01-02 21:53: Train Epoch 7: 83/634 Loss: 0.172425
2023-01-02 21:53: Train Epoch 7: 87/634 Loss: 0.154971
2023-01-02 21:53: Train Epoch 7: 91/634 Loss: 0.156039
2023-01-02 21:53: Train Epoch 7: 95/634 Loss: 0.152848
2023-01-02 21:53: Train Epoch 7: 99/634 Loss: 0.146271
2023-01-02 21:53: Train Epoch 7: 103/634 Loss: 0.165068
2023-01-02 21:54: Train Epoch 7: 107/634 Loss: 0.153139
2023-01-02 21:54: Train Epoch 7: 111/634 Loss: 0.179079
2023-01-02 21:54: Train Epoch 7: 115/634 Loss: 0.163446
2023-01-02 21:54: Train Epoch 7: 119/634 Loss: 0.192869
2023-01-02 21:54: Train Epoch 7: 123/634 Loss: 0.147961
2023-01-02 21:54: Train Epoch 7: 127/634 Loss: 0.158959
2023-01-02 21:54: Train Epoch 7: 131/634 Loss: 0.173091
2023-01-02 21:55: Train Epoch 7: 135/634 Loss: 0.162883
2023-01-02 21:55: Train Epoch 7: 139/634 Loss: 0.161492
2023-01-02 21:55: Train Epoch 7: 143/634 Loss: 0.135911
2023-01-02 21:55: Train Epoch 7: 147/634 Loss: 0.191775
2023-01-02 21:55: Train Epoch 7: 151/634 Loss: 0.188070
2023-01-02 21:55: Train Epoch 7: 155/634 Loss: 0.143824
2023-01-02 21:55: Train Epoch 7: 159/634 Loss: 0.168336
2023-01-02 21:56: Train Epoch 7: 163/634 Loss: 0.161310
2023-01-02 21:56: Train Epoch 7: 167/634 Loss: 0.206508
2023-01-02 21:56: Train Epoch 7: 171/634 Loss: 0.161655
2023-01-02 21:56: Train Epoch 7: 175/634 Loss: 0.167913
2023-01-02 21:56: Train Epoch 7: 179/634 Loss: 0.187041
2023-01-02 21:56: Train Epoch 7: 183/634 Loss: 0.163378
2023-01-02 21:56: Train Epoch 7: 187/634 Loss: 0.168859
2023-01-02 21:57: Train Epoch 7: 191/634 Loss: 0.183267
2023-01-02 21:57: Train Epoch 7: 195/634 Loss: 0.167438
2023-01-02 21:57: Train Epoch 7: 199/634 Loss: 0.195576
2023-01-02 21:57: Train Epoch 7: 203/634 Loss: 0.141621
2023-01-02 21:57: Train Epoch 7: 207/634 Loss: 0.149723
2023-01-02 21:57: Train Epoch 7: 211/634 Loss: 0.174744
2023-01-02 21:57: Train Epoch 7: 215/634 Loss: 0.184102
2023-01-02 21:58: Train Epoch 7: 219/634 Loss: 0.188980
2023-01-02 21:58: Train Epoch 7: 223/634 Loss: 0.195135
2023-01-02 21:58: Train Epoch 7: 227/634 Loss: 0.143022
2023-01-02 21:58: Train Epoch 7: 231/634 Loss: 0.161491
2023-01-02 21:58: Train Epoch 7: 235/634 Loss: 0.147418
2023-01-02 21:58: Train Epoch 7: 239/634 Loss: 0.145283
2023-01-02 21:58: Train Epoch 7: 243/634 Loss: 0.166109
2023-01-02 21:59: Train Epoch 7: 247/634 Loss: 0.160412
2023-01-02 21:59: Train Epoch 7: 251/634 Loss: 0.145571
2023-01-02 21:59: Train Epoch 7: 255/634 Loss: 0.157736
2023-01-02 21:59: Train Epoch 7: 259/634 Loss: 0.150575
2023-01-02 21:59: Train Epoch 7: 263/634 Loss: 0.153582
2023-01-02 21:59: Train Epoch 7: 267/634 Loss: 0.146099
2023-01-02 21:59: Train Epoch 7: 271/634 Loss: 0.180525
2023-01-02 22:00: Train Epoch 7: 275/634 Loss: 0.189789
2023-01-02 22:00: Train Epoch 7: 279/634 Loss: 0.129507
2023-01-02 22:00: Train Epoch 7: 283/634 Loss: 0.173293
2023-01-02 22:00: Train Epoch 7: 287/634 Loss: 0.141007
2023-01-02 22:00: Train Epoch 7: 291/634 Loss: 0.137604
2023-01-02 22:00: Train Epoch 7: 295/634 Loss: 0.156259
2023-01-02 22:00: Train Epoch 7: 299/634 Loss: 0.170071
2023-01-02 22:01: Train Epoch 7: 303/634 Loss: 0.150153
2023-01-02 22:01: Train Epoch 7: 307/634 Loss: 0.172399
2023-01-02 22:01: Train Epoch 7: 311/634 Loss: 0.168261
2023-01-02 22:01: Train Epoch 7: 315/634 Loss: 0.155566
2023-01-02 22:01: Train Epoch 7: 319/634 Loss: 0.153161
2023-01-02 22:01: Train Epoch 7: 323/634 Loss: 0.160982
2023-01-02 22:01: Train Epoch 7: 327/634 Loss: 0.169894
2023-01-02 22:02: Train Epoch 7: 331/634 Loss: 0.159138
2023-01-02 22:02: Train Epoch 7: 335/634 Loss: 0.194471
2023-01-02 22:02: Train Epoch 7: 339/634 Loss: 0.168791
2023-01-02 22:02: Train Epoch 7: 343/634 Loss: 0.171982
2023-01-02 22:02: Train Epoch 7: 347/634 Loss: 0.177838
2023-01-02 22:02: Train Epoch 7: 351/634 Loss: 0.168046
2023-01-02 22:02: Train Epoch 7: 355/634 Loss: 0.163495
2023-01-02 22:03: Train Epoch 7: 359/634 Loss: 0.150515
2023-01-02 22:03: Train Epoch 7: 363/634 Loss: 0.154644
2023-01-02 22:03: Train Epoch 7: 367/634 Loss: 0.191985
2023-01-02 22:03: Train Epoch 7: 371/634 Loss: 0.182811
2023-01-02 22:03: Train Epoch 7: 375/634 Loss: 0.160890
2023-01-02 22:03: Train Epoch 7: 379/634 Loss: 0.143527
2023-01-02 22:03: Train Epoch 7: 383/634 Loss: 0.148308
2023-01-02 22:04: Train Epoch 7: 387/634 Loss: 0.178653
2023-01-02 22:04: Train Epoch 7: 391/634 Loss: 0.176049
2023-01-02 22:04: Train Epoch 7: 395/634 Loss: 0.162178
2023-01-02 22:04: Train Epoch 7: 399/634 Loss: 0.158884
2023-01-02 22:04: Train Epoch 7: 403/634 Loss: 0.135243
2023-01-02 22:04: Train Epoch 7: 407/634 Loss: 0.173575
2023-01-02 22:04: Train Epoch 7: 411/634 Loss: 0.164641
2023-01-02 22:05: Train Epoch 7: 415/634 Loss: 0.165390
2023-01-02 22:05: Train Epoch 7: 419/634 Loss: 0.139460
2023-01-02 22:05: Train Epoch 7: 423/634 Loss: 0.152724
2023-01-02 22:05: Train Epoch 7: 427/634 Loss: 0.173087
2023-01-02 22:05: Train Epoch 7: 431/634 Loss: 0.174107
2023-01-02 22:05: Train Epoch 7: 435/634 Loss: 0.157140
2023-01-02 22:05: Train Epoch 7: 439/634 Loss: 0.153032
2023-01-02 22:05: Train Epoch 7: 443/634 Loss: 0.148694
2023-01-02 22:06: Train Epoch 7: 447/634 Loss: 0.153126
2023-01-02 22:06: Train Epoch 7: 451/634 Loss: 0.154947
2023-01-02 22:06: Train Epoch 7: 455/634 Loss: 0.133868
2023-01-02 22:06: Train Epoch 7: 459/634 Loss: 0.148498
2023-01-02 22:06: Train Epoch 7: 463/634 Loss: 0.162786
2023-01-02 22:06: Train Epoch 7: 467/634 Loss: 0.137924
2023-01-02 22:06: Train Epoch 7: 471/634 Loss: 0.154672
2023-01-02 22:07: Train Epoch 7: 475/634 Loss: 0.147200
2023-01-02 22:07: Train Epoch 7: 479/634 Loss: 0.183315
2023-01-02 22:07: Train Epoch 7: 483/634 Loss: 0.179718
2023-01-02 22:07: Train Epoch 7: 487/634 Loss: 0.184278
2023-01-02 22:07: Train Epoch 7: 491/634 Loss: 0.163081
2023-01-02 22:07: Train Epoch 7: 495/634 Loss: 0.165687
2023-01-02 22:07: Train Epoch 7: 499/634 Loss: 0.148587
2023-01-02 22:08: Train Epoch 7: 503/634 Loss: 0.176087
2023-01-02 22:08: Train Epoch 7: 507/634 Loss: 0.161393
2023-01-02 22:08: Train Epoch 7: 511/634 Loss: 0.188902
2023-01-02 22:08: Train Epoch 7: 515/634 Loss: 0.158268
2023-01-02 22:08: Train Epoch 7: 519/634 Loss: 0.193381
2023-01-02 22:08: Train Epoch 7: 523/634 Loss: 0.190501
2023-01-02 22:09: Train Epoch 7: 527/634 Loss: 0.175408
2023-01-02 22:09: Train Epoch 7: 531/634 Loss: 0.195872
2023-01-02 22:09: Train Epoch 7: 535/634 Loss: 0.152879
2023-01-02 22:09: Train Epoch 7: 539/634 Loss: 0.158662
2023-01-02 22:09: Train Epoch 7: 543/634 Loss: 0.193467
2023-01-02 22:09: Train Epoch 7: 547/634 Loss: 0.205367
2023-01-02 22:09: Train Epoch 7: 551/634 Loss: 0.158856
2023-01-02 22:10: Train Epoch 7: 555/634 Loss: 0.165178
2023-01-02 22:10: Train Epoch 7: 559/634 Loss: 0.163934
2023-01-02 22:10: Train Epoch 7: 563/634 Loss: 0.168499
2023-01-02 22:10: Train Epoch 7: 567/634 Loss: 0.155551
2023-01-02 22:10: Train Epoch 7: 571/634 Loss: 0.170139
2023-01-02 22:10: Train Epoch 7: 575/634 Loss: 0.152162
2023-01-02 22:10: Train Epoch 7: 579/634 Loss: 0.172566
2023-01-02 22:11: Train Epoch 7: 583/634 Loss: 0.155226
2023-01-02 22:11: Train Epoch 7: 587/634 Loss: 0.153165
2023-01-02 22:11: Train Epoch 7: 591/634 Loss: 0.187140
2023-01-02 22:11: Train Epoch 7: 595/634 Loss: 0.173824
2023-01-02 22:11: Train Epoch 7: 599/634 Loss: 0.139693
2023-01-02 22:11: Train Epoch 7: 603/634 Loss: 0.138486
2023-01-02 22:11: Train Epoch 7: 607/634 Loss: 0.139507
2023-01-02 22:12: Train Epoch 7: 611/634 Loss: 0.148101
2023-01-02 22:12: Train Epoch 7: 615/634 Loss: 0.154093
2023-01-02 22:12: Train Epoch 7: 619/634 Loss: 0.133772
2023-01-02 22:12: Train Epoch 7: 623/634 Loss: 0.154099
2023-01-02 22:12: Train Epoch 7: 627/634 Loss: 0.191607
2023-01-02 22:12: Train Epoch 7: 631/634 Loss: 0.141828
2023-01-02 22:12: Train Epoch 7: 633/634 Loss: 0.056825
2023-01-02 22:12: **********Train Epoch 7: averaged Loss: 0.162363 
2023-01-02 22:12: 
Epoch time elapsed: 1355.2437558174133

2023-01-02 22:13: 
 metrics validation: {'precision': 0.8111627906976744, 'recall': 0.6707692307692308, 'f1-score': 0.7343157894736843, 'support': 1300, 'AUC': 0.9239902366863906, 'AUCPR': 0.8537745195628629, 'TP': 872, 'FP': 203, 'TN': 2397, 'FN': 428} 

2023-01-02 22:13: **********Val Epoch 7: average Loss: 0.159275
2023-01-02 22:13: *********************************Current best model saved!
2023-01-02 22:14: 
 Testing metrics {'precision': 0.8605405405405405, 'recall': 0.6482084690553745, 'f1-score': 0.7394333488156061, 'support': 1228, 'AUC': 0.9182090128277224, 'AUCPR': 0.8674346802008155, 'TP': 796, 'FP': 129, 'TN': 2327, 'FN': 432} 

2023-01-02 22:16: 
 Testing metrics {'precision': 0.9142929806714141, 'recall': 0.8157476741547538, 'f1-score': 0.8622136946876124, 'support': 4407, 'AUC': 0.9721850987009393, 'AUCPR': 0.9414758250275549, 'TP': 3595, 'FP': 337, 'TN': 8477, 'FN': 812} 

2023-01-02 22:16: Train Epoch 8: 3/634 Loss: 0.142808
2023-01-02 22:16: Train Epoch 8: 7/634 Loss: 0.162803
2023-01-02 22:16: Train Epoch 8: 11/634 Loss: 0.126261
2023-01-02 22:16: Train Epoch 8: 15/634 Loss: 0.159165
2023-01-02 22:16: Train Epoch 8: 19/634 Loss: 0.163208
2023-01-02 22:17: Train Epoch 8: 23/634 Loss: 0.144898
2023-01-02 22:17: Train Epoch 8: 27/634 Loss: 0.158056
2023-01-02 22:17: Train Epoch 8: 31/634 Loss: 0.150398
2023-01-02 22:17: Train Epoch 8: 35/634 Loss: 0.174569
2023-01-02 22:17: Train Epoch 8: 39/634 Loss: 0.149116
2023-01-02 22:17: Train Epoch 8: 43/634 Loss: 0.149426
2023-01-02 22:17: Train Epoch 8: 47/634 Loss: 0.126238
2023-01-02 22:18: Train Epoch 8: 51/634 Loss: 0.172927
2023-01-02 22:18: Train Epoch 8: 55/634 Loss: 0.155887
2023-01-02 22:18: Train Epoch 8: 59/634 Loss: 0.139708
2023-01-02 22:18: Train Epoch 8: 63/634 Loss: 0.153801
2023-01-02 22:18: Train Epoch 8: 67/634 Loss: 0.147132
2023-01-02 22:18: Train Epoch 8: 71/634 Loss: 0.124301
2023-01-02 22:18: Train Epoch 8: 75/634 Loss: 0.151094
2023-01-02 22:19: Train Epoch 8: 79/634 Loss: 0.144140
2023-01-02 22:19: Train Epoch 8: 83/634 Loss: 0.148047
2023-01-02 22:19: Train Epoch 8: 87/634 Loss: 0.159954
2023-01-02 22:19: Train Epoch 8: 91/634 Loss: 0.148004
2023-01-02 22:19: Train Epoch 8: 95/634 Loss: 0.160169
2023-01-02 22:19: Train Epoch 8: 99/634 Loss: 0.152170
2023-01-02 22:19: Train Epoch 8: 103/634 Loss: 0.148271
2023-01-02 22:20: Train Epoch 8: 107/634 Loss: 0.159860
2023-01-02 22:20: Train Epoch 8: 111/634 Loss: 0.166493
2023-01-02 22:20: Train Epoch 8: 115/634 Loss: 0.190292
2023-01-02 22:20: Train Epoch 8: 119/634 Loss: 0.187896
2023-01-02 22:20: Train Epoch 8: 123/634 Loss: 0.142647
2023-01-02 22:20: Train Epoch 8: 127/634 Loss: 0.165347
2023-01-02 22:20: Train Epoch 8: 131/634 Loss: 0.157140
2023-01-02 22:21: Train Epoch 8: 135/634 Loss: 0.161392
2023-01-02 22:21: Train Epoch 8: 139/634 Loss: 0.156271
2023-01-02 22:21: Train Epoch 8: 143/634 Loss: 0.140631
2023-01-02 22:21: Train Epoch 8: 147/634 Loss: 0.173318
2023-01-02 22:21: Train Epoch 8: 151/634 Loss: 0.157137
2023-01-02 22:21: Train Epoch 8: 155/634 Loss: 0.147513
2023-01-02 22:21: Train Epoch 8: 159/634 Loss: 0.161559
2023-01-02 22:22: Train Epoch 8: 163/634 Loss: 0.187281
2023-01-02 22:22: Train Epoch 8: 167/634 Loss: 0.169866
2023-01-02 22:22: Train Epoch 8: 171/634 Loss: 0.159026
2023-01-02 22:22: Train Epoch 8: 175/634 Loss: 0.125212
2023-01-02 22:22: Train Epoch 8: 179/634 Loss: 0.131728
2023-01-02 22:22: Train Epoch 8: 183/634 Loss: 0.148472
2023-01-02 22:23: Train Epoch 8: 187/634 Loss: 0.160649
2023-01-02 22:23: Train Epoch 8: 191/634 Loss: 0.141664
2023-01-02 22:23: Train Epoch 8: 195/634 Loss: 0.147762
2023-01-02 22:23: Train Epoch 8: 199/634 Loss: 0.146582
2023-01-02 22:23: Train Epoch 8: 203/634 Loss: 0.158981
2023-01-02 22:23: Train Epoch 8: 207/634 Loss: 0.138863
2023-01-02 22:23: Train Epoch 8: 211/634 Loss: 0.153420
2023-01-02 22:24: Train Epoch 8: 215/634 Loss: 0.158611
2023-01-02 22:24: Train Epoch 8: 219/634 Loss: 0.164615
2023-01-02 22:24: Train Epoch 8: 223/634 Loss: 0.144040
2023-01-02 22:24: Train Epoch 8: 227/634 Loss: 0.135174
2023-01-02 22:24: Train Epoch 8: 231/634 Loss: 0.163088
2023-01-02 22:24: Train Epoch 8: 235/634 Loss: 0.141693
2023-01-02 22:24: Train Epoch 8: 239/634 Loss: 0.164187
2023-01-02 22:25: Train Epoch 8: 243/634 Loss: 0.137409
2023-01-02 22:25: Train Epoch 8: 247/634 Loss: 0.144806
2023-01-02 22:25: Train Epoch 8: 251/634 Loss: 0.163161
2023-01-02 22:25: Train Epoch 8: 255/634 Loss: 0.167125
2023-01-02 22:25: Train Epoch 8: 259/634 Loss: 0.181317
2023-01-02 22:25: Train Epoch 8: 263/634 Loss: 0.150407
2023-01-02 22:25: Train Epoch 8: 267/634 Loss: 0.167637
2023-01-02 22:26: Train Epoch 8: 271/634 Loss: 0.137652
2023-01-02 22:26: Train Epoch 8: 275/634 Loss: 0.141043
2023-01-02 22:26: Train Epoch 8: 279/634 Loss: 0.157997
2023-01-02 22:26: Train Epoch 8: 283/634 Loss: 0.143721
2023-01-02 22:26: Train Epoch 8: 287/634 Loss: 0.141928
2023-01-02 22:26: Train Epoch 8: 291/634 Loss: 0.147490
2023-01-02 22:26: Train Epoch 8: 295/634 Loss: 0.133255
2023-01-02 22:27: Train Epoch 8: 299/634 Loss: 0.177661
2023-01-02 22:27: Train Epoch 8: 303/634 Loss: 0.153693
2023-01-02 22:27: Train Epoch 8: 307/634 Loss: 0.153560
2023-01-02 22:27: Train Epoch 8: 311/634 Loss: 0.162917
2023-01-02 22:27: Train Epoch 8: 315/634 Loss: 0.157603
2023-01-02 22:27: Train Epoch 8: 319/634 Loss: 0.145172
2023-01-02 22:28: Train Epoch 8: 323/634 Loss: 0.142341
2023-01-02 22:28: Train Epoch 8: 327/634 Loss: 0.151909
2023-01-02 22:28: Train Epoch 8: 331/634 Loss: 0.187551
2023-01-02 22:28: Train Epoch 8: 335/634 Loss: 0.143238
2023-01-02 22:28: Train Epoch 8: 339/634 Loss: 0.160585
2023-01-02 22:28: Train Epoch 8: 343/634 Loss: 0.139095
2023-01-02 22:28: Train Epoch 8: 347/634 Loss: 0.132917
2023-01-02 22:29: Train Epoch 8: 351/634 Loss: 0.173930
2023-01-02 22:29: Train Epoch 8: 355/634 Loss: 0.143999
2023-01-02 22:29: Train Epoch 8: 359/634 Loss: 0.149161
2023-01-02 22:29: Train Epoch 8: 363/634 Loss: 0.151463
2023-01-02 22:29: Train Epoch 8: 367/634 Loss: 0.169256
2023-01-02 22:29: Train Epoch 8: 371/634 Loss: 0.160973
2023-01-02 22:30: Train Epoch 8: 375/634 Loss: 0.159732
2023-01-02 22:30: Train Epoch 8: 379/634 Loss: 0.149301
2023-01-02 22:30: Train Epoch 8: 383/634 Loss: 0.148997
2023-01-02 22:30: Train Epoch 8: 387/634 Loss: 0.165247
2023-01-02 22:30: Train Epoch 8: 391/634 Loss: 0.176406
2023-01-02 22:30: Train Epoch 8: 395/634 Loss: 0.150257
2023-01-02 22:30: Train Epoch 8: 399/634 Loss: 0.163917
2023-01-02 22:31: Train Epoch 8: 403/634 Loss: 0.165487
2023-01-02 22:31: Train Epoch 8: 407/634 Loss: 0.131670
2023-01-02 22:31: Train Epoch 8: 411/634 Loss: 0.144100
2023-01-02 22:31: Train Epoch 8: 415/634 Loss: 0.165188
2023-01-02 22:31: Train Epoch 8: 419/634 Loss: 0.148471
2023-01-02 22:31: Train Epoch 8: 423/634 Loss: 0.161767
2023-01-02 22:31: Train Epoch 8: 427/634 Loss: 0.150992
2023-01-02 22:32: Train Epoch 8: 431/634 Loss: 0.151149
2023-01-02 22:32: Train Epoch 8: 435/634 Loss: 0.144184
2023-01-02 22:32: Train Epoch 8: 439/634 Loss: 0.159674
2023-01-02 22:32: Train Epoch 8: 443/634 Loss: 0.167155
2023-01-02 22:32: Train Epoch 8: 447/634 Loss: 0.156668
2023-01-02 22:32: Train Epoch 8: 451/634 Loss: 0.175441
2023-01-02 22:32: Train Epoch 8: 455/634 Loss: 0.135421
2023-01-02 22:33: Train Epoch 8: 459/634 Loss: 0.151565
2023-01-02 22:33: Train Epoch 8: 463/634 Loss: 0.138387
2023-01-02 22:33: Train Epoch 8: 467/634 Loss: 0.172470
2023-01-02 22:33: Train Epoch 8: 471/634 Loss: 0.142190
2023-01-02 22:33: Train Epoch 8: 475/634 Loss: 0.181459
2023-01-02 22:33: Train Epoch 8: 479/634 Loss: 0.145522
2023-01-02 22:33: Train Epoch 8: 483/634 Loss: 0.121858
2023-01-02 22:34: Train Epoch 8: 487/634 Loss: 0.169169
2023-01-02 22:34: Train Epoch 8: 491/634 Loss: 0.159511
2023-01-02 22:34: Train Epoch 8: 495/634 Loss: 0.166961
2023-01-02 22:34: Train Epoch 8: 499/634 Loss: 0.158238
2023-01-02 22:34: Train Epoch 8: 503/634 Loss: 0.165968
2023-01-02 22:34: Train Epoch 8: 507/634 Loss: 0.163955
2023-01-02 22:34: Train Epoch 8: 511/634 Loss: 0.148946
2023-01-02 22:35: Train Epoch 8: 515/634 Loss: 0.141981
2023-01-02 22:35: Train Epoch 8: 519/634 Loss: 0.160405
2023-01-02 22:35: Train Epoch 8: 523/634 Loss: 0.143791
2023-01-02 22:35: Train Epoch 8: 527/634 Loss: 0.153901
2023-01-02 22:35: Train Epoch 8: 531/634 Loss: 0.153968
2023-01-02 22:35: Train Epoch 8: 535/634 Loss: 0.154116
2023-01-02 22:35: Train Epoch 8: 539/634 Loss: 0.171624
2023-01-02 22:36: Train Epoch 8: 543/634 Loss: 0.144692
2023-01-02 22:36: Train Epoch 8: 547/634 Loss: 0.167213
2023-01-02 22:36: Train Epoch 8: 551/634 Loss: 0.171619
2023-01-02 22:36: Train Epoch 8: 555/634 Loss: 0.174890
2023-01-02 22:36: Train Epoch 8: 559/634 Loss: 0.185439
2023-01-02 22:36: Train Epoch 8: 563/634 Loss: 0.155291
2023-01-02 22:37: Train Epoch 8: 567/634 Loss: 0.173208
2023-01-02 22:37: Train Epoch 8: 571/634 Loss: 0.136467
2023-01-02 22:37: Train Epoch 8: 575/634 Loss: 0.173415
2023-01-02 22:37: Train Epoch 8: 579/634 Loss: 0.149142
2023-01-02 22:37: Train Epoch 8: 583/634 Loss: 0.158185
2023-01-02 22:37: Train Epoch 8: 587/634 Loss: 0.144046
2023-01-02 22:37: Train Epoch 8: 591/634 Loss: 0.189371
2023-01-02 22:38: Train Epoch 8: 595/634 Loss: 0.134883
2023-01-02 22:38: Train Epoch 8: 599/634 Loss: 0.179310
2023-01-02 22:38: Train Epoch 8: 603/634 Loss: 0.150613
2023-01-02 22:38: Train Epoch 8: 607/634 Loss: 0.156259
2023-01-02 22:38: Train Epoch 8: 611/634 Loss: 0.140473
2023-01-02 22:38: Train Epoch 8: 615/634 Loss: 0.140647
2023-01-02 22:38: Train Epoch 8: 619/634 Loss: 0.167992
2023-01-02 22:39: Train Epoch 8: 623/634 Loss: 0.167781
2023-01-02 22:39: Train Epoch 8: 627/634 Loss: 0.159868
2023-01-02 22:39: Train Epoch 8: 631/634 Loss: 0.163896
2023-01-02 22:39: Train Epoch 8: 633/634 Loss: 0.068761
2023-01-02 22:39: **********Train Epoch 8: averaged Loss: 0.154614 
2023-01-02 22:39: 
Epoch time elapsed: 1387.3201508522034

2023-01-02 22:40: 
 metrics validation: {'precision': 0.8274002157497303, 'recall': 0.59, 'f1-score': 0.688819039066008, 'support': 1300, 'AUC': 0.9297840236686391, 'AUCPR': 0.8596038538253927, 'TP': 767, 'FP': 160, 'TN': 2440, 'FN': 533} 

2023-01-02 22:40: **********Val Epoch 8: average Loss: 0.158147
2023-01-02 22:40: *********************************Current best model saved!
2023-01-02 22:40: 
 Testing metrics {'precision': 0.883352208380521, 'recall': 0.6351791530944625, 'f1-score': 0.738986262434865, 'support': 1228, 'AUC': 0.9252439017920615, 'AUCPR': 0.8780004580671148, 'TP': 780, 'FP': 103, 'TN': 2353, 'FN': 448} 

2023-01-02 22:42: 
 Testing metrics {'precision': 0.9331689947959463, 'recall': 0.7730882686634899, 'f1-score': 0.8456192603623728, 'support': 4407, 'AUC': 0.9725069174095363, 'AUCPR': 0.9407024382631225, 'TP': 3407, 'FP': 244, 'TN': 8570, 'FN': 1000} 

2023-01-02 22:43: Train Epoch 9: 3/634 Loss: 0.166562
2023-01-02 22:43: Train Epoch 9: 7/634 Loss: 0.144300
2023-01-02 22:43: Train Epoch 9: 11/634 Loss: 0.135661
2023-01-02 22:43: Train Epoch 9: 15/634 Loss: 0.165505
2023-01-02 22:43: Train Epoch 9: 19/634 Loss: 0.156388
2023-01-02 22:43: Train Epoch 9: 23/634 Loss: 0.151217
2023-01-02 22:43: Train Epoch 9: 27/634 Loss: 0.172871
2023-01-02 22:44: Train Epoch 9: 31/634 Loss: 0.149874
2023-01-02 22:44: Train Epoch 9: 35/634 Loss: 0.117997
2023-01-02 22:44: Train Epoch 9: 39/634 Loss: 0.137468
2023-01-02 22:44: Train Epoch 9: 43/634 Loss: 0.146324
2023-01-02 22:44: Train Epoch 9: 47/634 Loss: 0.146515
2023-01-02 22:44: Train Epoch 9: 51/634 Loss: 0.147391
2023-01-02 22:44: Train Epoch 9: 55/634 Loss: 0.126665
2023-01-02 22:44: Train Epoch 9: 59/634 Loss: 0.151851
2023-01-02 22:45: Train Epoch 9: 63/634 Loss: 0.166016
2023-01-02 22:45: Train Epoch 9: 67/634 Loss: 0.161979
2023-01-02 22:45: Train Epoch 9: 71/634 Loss: 0.187824
2023-01-02 22:45: Train Epoch 9: 75/634 Loss: 0.138277
2023-01-02 22:45: Train Epoch 9: 79/634 Loss: 0.167839
2023-01-02 22:45: Train Epoch 9: 83/634 Loss: 0.153900
2023-01-02 22:45: Train Epoch 9: 87/634 Loss: 0.142973
2023-01-02 22:46: Train Epoch 9: 91/634 Loss: 0.136041
2023-01-02 22:46: Train Epoch 9: 95/634 Loss: 0.132895
2023-01-02 22:46: Train Epoch 9: 99/634 Loss: 0.166878
2023-01-02 22:46: Train Epoch 9: 103/634 Loss: 0.159696
2023-01-02 22:46: Train Epoch 9: 107/634 Loss: 0.172026
2023-01-02 22:46: Train Epoch 9: 111/634 Loss: 0.144748
2023-01-02 22:46: Train Epoch 9: 115/634 Loss: 0.137769
2023-01-02 22:47: Train Epoch 9: 119/634 Loss: 0.165067
2023-01-02 22:47: Train Epoch 9: 123/634 Loss: 0.163167
2023-01-02 22:47: Train Epoch 9: 127/634 Loss: 0.144008
2023-01-02 22:47: Train Epoch 9: 131/634 Loss: 0.154191
2023-01-02 22:47: Train Epoch 9: 135/634 Loss: 0.124853
2023-01-02 22:47: Train Epoch 9: 139/634 Loss: 0.166875
2023-01-02 22:47: Train Epoch 9: 143/634 Loss: 0.153577
2023-01-02 22:47: Train Epoch 9: 147/634 Loss: 0.170585
2023-01-02 22:48: Train Epoch 9: 151/634 Loss: 0.148913
2023-01-02 22:48: Train Epoch 9: 155/634 Loss: 0.155415
2023-01-02 22:48: Train Epoch 9: 159/634 Loss: 0.160479
2023-01-02 22:48: Train Epoch 9: 163/634 Loss: 0.148429
2023-01-02 22:48: Train Epoch 9: 167/634 Loss: 0.154859
2023-01-02 22:48: Train Epoch 9: 171/634 Loss: 0.137690
2023-01-02 22:48: Train Epoch 9: 175/634 Loss: 0.149287
2023-01-02 22:49: Train Epoch 9: 179/634 Loss: 0.154727
2023-01-02 22:49: Train Epoch 9: 183/634 Loss: 0.137930
2023-01-02 22:49: Train Epoch 9: 187/634 Loss: 0.165895
2023-01-02 22:49: Train Epoch 9: 191/634 Loss: 0.141550
2023-01-02 22:49: Train Epoch 9: 195/634 Loss: 0.162928
2023-01-02 22:49: Train Epoch 9: 199/634 Loss: 0.134094
2023-01-02 22:49: Train Epoch 9: 203/634 Loss: 0.133830
2023-01-02 22:50: Train Epoch 9: 207/634 Loss: 0.155357
2023-01-02 22:50: Train Epoch 9: 211/634 Loss: 0.152837
2023-01-02 22:50: Train Epoch 9: 215/634 Loss: 0.159070
2023-01-02 22:50: Train Epoch 9: 219/634 Loss: 0.148679
2023-01-02 22:50: Train Epoch 9: 223/634 Loss: 0.160150
2023-01-02 22:50: Train Epoch 9: 227/634 Loss: 0.161265
2023-01-02 22:50: Train Epoch 9: 231/634 Loss: 0.121647
2023-01-02 22:51: Train Epoch 9: 235/634 Loss: 0.138425
2023-01-02 22:51: Train Epoch 9: 239/634 Loss: 0.116182
2023-01-02 22:51: Train Epoch 9: 243/634 Loss: 0.148230
2023-01-02 22:51: Train Epoch 9: 247/634 Loss: 0.132182
2023-01-02 22:51: Train Epoch 9: 251/634 Loss: 0.135519
2023-01-02 22:51: Train Epoch 9: 255/634 Loss: 0.208708
2023-01-02 22:51: Train Epoch 9: 259/634 Loss: 0.173346
2023-01-02 22:52: Train Epoch 9: 263/634 Loss: 0.163886
2023-01-02 22:52: Train Epoch 9: 267/634 Loss: 0.173332
2023-01-02 22:52: Train Epoch 9: 271/634 Loss: 0.157184
2023-01-02 22:52: Train Epoch 9: 275/634 Loss: 0.138405
2023-01-02 22:52: Train Epoch 9: 279/634 Loss: 0.138392
2023-01-02 22:52: Train Epoch 9: 283/634 Loss: 0.154091
2023-01-02 22:52: Train Epoch 9: 287/634 Loss: 0.167204
2023-01-02 22:53: Train Epoch 9: 291/634 Loss: 0.143733
2023-01-02 22:53: Train Epoch 9: 295/634 Loss: 0.140463
2023-01-02 22:53: Train Epoch 9: 299/634 Loss: 0.140257
2023-01-02 22:53: Train Epoch 9: 303/634 Loss: 0.149140
2023-01-02 22:53: Train Epoch 9: 307/634 Loss: 0.146434
2023-01-02 22:53: Train Epoch 9: 311/634 Loss: 0.158733
2023-01-02 22:53: Train Epoch 9: 315/634 Loss: 0.150707
2023-01-02 22:54: Train Epoch 9: 319/634 Loss: 0.124102
2023-01-02 22:54: Train Epoch 9: 323/634 Loss: 0.155319
2023-01-02 22:54: Train Epoch 9: 327/634 Loss: 0.160853
2023-01-02 22:54: Train Epoch 9: 331/634 Loss: 0.154294
2023-01-02 22:54: Train Epoch 9: 335/634 Loss: 0.131008
2023-01-02 22:54: Train Epoch 9: 339/634 Loss: 0.139948
2023-01-02 22:54: Train Epoch 9: 343/634 Loss: 0.176620
2023-01-02 22:54: Train Epoch 9: 347/634 Loss: 0.148495
2023-01-02 22:55: Train Epoch 9: 351/634 Loss: 0.142510
2023-01-02 22:55: Train Epoch 9: 355/634 Loss: 0.156819
2023-01-02 22:55: Train Epoch 9: 359/634 Loss: 0.158471
2023-01-02 22:55: Train Epoch 9: 363/634 Loss: 0.135324
2023-01-02 22:55: Train Epoch 9: 367/634 Loss: 0.130183
2023-01-02 22:55: Train Epoch 9: 371/634 Loss: 0.149530
2023-01-02 22:55: Train Epoch 9: 375/634 Loss: 0.150104
2023-01-02 22:56: Train Epoch 9: 379/634 Loss: 0.137735
2023-01-02 22:56: Train Epoch 9: 383/634 Loss: 0.149966
2023-01-02 22:56: Train Epoch 9: 387/634 Loss: 0.176991
2023-01-02 22:56: Train Epoch 9: 391/634 Loss: 0.148190
2023-01-02 22:56: Train Epoch 9: 395/634 Loss: 0.140121
2023-01-02 22:56: Train Epoch 9: 399/634 Loss: 0.141153
2023-01-02 22:56: Train Epoch 9: 403/634 Loss: 0.142723
2023-01-02 22:57: Train Epoch 9: 407/634 Loss: 0.139687
2023-01-02 22:57: Train Epoch 9: 411/634 Loss: 0.128871
2023-01-02 22:57: Train Epoch 9: 415/634 Loss: 0.152572
2023-01-02 22:57: Train Epoch 9: 419/634 Loss: 0.140961
2023-01-02 22:57: Train Epoch 9: 423/634 Loss: 0.152285
2023-01-02 22:57: Train Epoch 9: 427/634 Loss: 0.147266
2023-01-02 22:57: Train Epoch 9: 431/634 Loss: 0.156994
2023-01-02 22:58: Train Epoch 9: 435/634 Loss: 0.152339
2023-01-02 22:58: Train Epoch 9: 439/634 Loss: 0.145871
2023-01-02 22:58: Train Epoch 9: 443/634 Loss: 0.128913
2023-01-02 22:58: Train Epoch 9: 447/634 Loss: 0.145748
2023-01-02 22:58: Train Epoch 9: 451/634 Loss: 0.163557
2023-01-02 22:58: Train Epoch 9: 455/634 Loss: 0.136054
2023-01-02 22:58: Train Epoch 9: 459/634 Loss: 0.172666
2023-01-02 22:59: Train Epoch 9: 463/634 Loss: 0.156882
2023-01-02 22:59: Train Epoch 9: 467/634 Loss: 0.155016
2023-01-02 22:59: Train Epoch 9: 471/634 Loss: 0.149445
2023-01-02 22:59: Train Epoch 9: 475/634 Loss: 0.137296
2023-01-02 22:59: Train Epoch 9: 479/634 Loss: 0.155028
2023-01-02 22:59: Train Epoch 9: 483/634 Loss: 0.149767
2023-01-02 22:59: Train Epoch 9: 487/634 Loss: 0.135759
2023-01-02 23:00: Train Epoch 9: 491/634 Loss: 0.166419
2023-01-02 23:00: Train Epoch 9: 495/634 Loss: 0.147872
2023-01-02 23:00: Train Epoch 9: 499/634 Loss: 0.165696
2023-01-02 23:00: Train Epoch 9: 503/634 Loss: 0.128834
2023-01-02 23:00: Train Epoch 9: 507/634 Loss: 0.155654
2023-01-02 23:00: Train Epoch 9: 511/634 Loss: 0.146346
2023-01-02 23:01: Train Epoch 9: 515/634 Loss: 0.155895
2023-01-02 23:01: Train Epoch 9: 519/634 Loss: 0.178120
2023-01-02 23:01: Train Epoch 9: 523/634 Loss: 0.123303
2023-01-02 23:01: Train Epoch 9: 527/634 Loss: 0.130566
2023-01-02 23:01: Train Epoch 9: 531/634 Loss: 0.132697
2023-01-02 23:01: Train Epoch 9: 535/634 Loss: 0.155887
2023-01-02 23:01: Train Epoch 9: 539/634 Loss: 0.177240
2023-01-02 23:01: Train Epoch 9: 543/634 Loss: 0.146520
2023-01-02 23:02: Train Epoch 9: 547/634 Loss: 0.132845
2023-01-02 23:02: Train Epoch 9: 551/634 Loss: 0.140543
2023-01-02 23:02: Train Epoch 9: 555/634 Loss: 0.164856
2023-01-02 23:02: Train Epoch 9: 559/634 Loss: 0.138653
2023-01-02 23:02: Train Epoch 9: 563/634 Loss: 0.133767
2023-01-02 23:02: Train Epoch 9: 567/634 Loss: 0.172401
2023-01-02 23:02: Train Epoch 9: 571/634 Loss: 0.170548
2023-01-02 23:03: Train Epoch 9: 575/634 Loss: 0.130712
2023-01-02 23:03: Train Epoch 9: 579/634 Loss: 0.153253
2023-01-02 23:03: Train Epoch 9: 583/634 Loss: 0.154406
2023-01-02 23:03: Train Epoch 9: 587/634 Loss: 0.132296
2023-01-02 23:03: Train Epoch 9: 591/634 Loss: 0.130784
2023-01-02 23:03: Train Epoch 9: 595/634 Loss: 0.130806
2023-01-02 23:03: Train Epoch 9: 599/634 Loss: 0.161261
2023-01-02 23:04: Train Epoch 9: 603/634 Loss: 0.175013
2023-01-02 23:04: Train Epoch 9: 607/634 Loss: 0.148448
2023-01-02 23:04: Train Epoch 9: 611/634 Loss: 0.144208
2023-01-02 23:04: Train Epoch 9: 615/634 Loss: 0.138025
2023-01-02 23:04: Train Epoch 9: 619/634 Loss: 0.131477
2023-01-02 23:04: Train Epoch 9: 623/634 Loss: 0.156610
2023-01-02 23:04: Train Epoch 9: 627/634 Loss: 0.126750
2023-01-02 23:05: Train Epoch 9: 631/634 Loss: 0.164217
2023-01-02 23:05: Train Epoch 9: 633/634 Loss: 0.071978
2023-01-02 23:05: **********Train Epoch 9: averaged Loss: 0.149155 
2023-01-02 23:05: 
Epoch time elapsed: 1329.0225789546967

2023-01-02 23:05: 
 metrics validation: {'precision': 0.8354285714285714, 'recall': 0.5623076923076923, 'f1-score': 0.672183908045977, 'support': 1300, 'AUC': 0.9283390532544378, 'AUCPR': 0.862289600735604, 'TP': 731, 'FP': 144, 'TN': 2456, 'FN': 569} 

2023-01-02 23:05: **********Val Epoch 9: average Loss: 0.167328
2023-01-02 23:06: 
 Testing metrics {'precision': 0.883352208380521, 'recall': 0.6351791530944625, 'f1-score': 0.738986262434865, 'support': 1228, 'AUC': 0.9252439017920615, 'AUCPR': 0.8780004580671148, 'TP': 780, 'FP': 103, 'TN': 2353, 'FN': 448} 

2023-01-02 23:08: 
 Testing metrics {'precision': 0.9331689947959463, 'recall': 0.7730882686634899, 'f1-score': 0.8456192603623728, 'support': 4407, 'AUC': 0.9725069174095363, 'AUCPR': 0.9407024382631225, 'TP': 3407, 'FP': 244, 'TN': 8570, 'FN': 1000} 

2023-01-02 23:08: Train Epoch 10: 3/634 Loss: 0.168197
2023-01-02 23:08: Train Epoch 10: 7/634 Loss: 0.145992
2023-01-02 23:09: Train Epoch 10: 11/634 Loss: 0.147952
2023-01-02 23:09: Train Epoch 10: 15/634 Loss: 0.149027
2023-01-02 23:09: Train Epoch 10: 19/634 Loss: 0.113921
2023-01-02 23:09: Train Epoch 10: 23/634 Loss: 0.142839
2023-01-02 23:09: Train Epoch 10: 27/634 Loss: 0.147252
2023-01-02 23:09: Train Epoch 10: 31/634 Loss: 0.166430
2023-01-02 23:09: Train Epoch 10: 35/634 Loss: 0.131512
2023-01-02 23:10: Train Epoch 10: 39/634 Loss: 0.149399
2023-01-02 23:10: Train Epoch 10: 43/634 Loss: 0.169125
2023-01-02 23:10: Train Epoch 10: 47/634 Loss: 0.155140
2023-01-02 23:10: Train Epoch 10: 51/634 Loss: 0.133089
2023-01-02 23:10: Train Epoch 10: 55/634 Loss: 0.156422
2023-01-02 23:10: Train Epoch 10: 59/634 Loss: 0.161470
2023-01-02 23:10: Train Epoch 10: 63/634 Loss: 0.165798
2023-01-02 23:11: Train Epoch 10: 67/634 Loss: 0.161342
2023-01-02 23:11: Train Epoch 10: 71/634 Loss: 0.153288
2023-01-02 23:11: Train Epoch 10: 75/634 Loss: 0.151034
2023-01-02 23:11: Train Epoch 10: 79/634 Loss: 0.161754
2023-01-02 23:11: Train Epoch 10: 83/634 Loss: 0.154788
2023-01-02 23:11: Train Epoch 10: 87/634 Loss: 0.127082
2023-01-02 23:11: Train Epoch 10: 91/634 Loss: 0.162909
2023-01-02 23:12: Train Epoch 10: 95/634 Loss: 0.139507
2023-01-02 23:12: Train Epoch 10: 99/634 Loss: 0.151292
2023-01-02 23:12: Train Epoch 10: 103/634 Loss: 0.158926
2023-01-02 23:12: Train Epoch 10: 107/634 Loss: 0.169320
2023-01-02 23:12: Train Epoch 10: 111/634 Loss: 0.160795
2023-01-02 23:12: Train Epoch 10: 115/634 Loss: 0.153276
2023-01-02 23:12: Train Epoch 10: 119/634 Loss: 0.146012
2023-01-02 23:13: Train Epoch 10: 123/634 Loss: 0.158593
2023-01-02 23:13: Train Epoch 10: 127/634 Loss: 0.159550
2023-01-02 23:13: Train Epoch 10: 131/634 Loss: 0.143908
2023-01-02 23:13: Train Epoch 10: 135/634 Loss: 0.144243
2023-01-02 23:13: Train Epoch 10: 139/634 Loss: 0.152368
2023-01-02 23:13: Train Epoch 10: 143/634 Loss: 0.150659
2023-01-02 23:13: Train Epoch 10: 147/634 Loss: 0.146190
2023-01-02 23:14: Train Epoch 10: 151/634 Loss: 0.155881
2023-01-02 23:14: Train Epoch 10: 155/634 Loss: 0.146840
2023-01-02 23:14: Train Epoch 10: 159/634 Loss: 0.157294
2023-01-02 23:14: Train Epoch 10: 163/634 Loss: 0.142296
2023-01-02 23:14: Train Epoch 10: 167/634 Loss: 0.148151
2023-01-02 23:14: Train Epoch 10: 171/634 Loss: 0.183952
2023-01-02 23:15: Train Epoch 10: 175/634 Loss: 0.163498
2023-01-02 23:15: Train Epoch 10: 179/634 Loss: 0.169114
2023-01-02 23:15: Train Epoch 10: 183/634 Loss: 0.141878
2023-01-02 23:15: Train Epoch 10: 187/634 Loss: 0.132821
2023-01-02 23:15: Train Epoch 10: 191/634 Loss: 0.168687
2023-01-02 23:15: Train Epoch 10: 195/634 Loss: 0.154281
2023-01-02 23:15: Train Epoch 10: 199/634 Loss: 0.146636
2023-01-02 23:16: Train Epoch 10: 203/634 Loss: 0.171498
2023-01-02 23:16: Train Epoch 10: 207/634 Loss: 0.152692
2023-01-02 23:16: Train Epoch 10: 211/634 Loss: 0.142379
2023-01-02 23:16: Train Epoch 10: 215/634 Loss: 0.144091
2023-01-02 23:16: Train Epoch 10: 219/634 Loss: 0.169747
2023-01-02 23:16: Train Epoch 10: 223/634 Loss: 0.158120
2023-01-02 23:16: Train Epoch 10: 227/634 Loss: 0.139751
2023-01-02 23:17: Train Epoch 10: 231/634 Loss: 0.169827
2023-01-02 23:17: Train Epoch 10: 235/634 Loss: 0.138964
2023-01-02 23:17: Train Epoch 10: 239/634 Loss: 0.138072
2023-01-02 23:17: Train Epoch 10: 243/634 Loss: 0.132851
2023-01-02 23:17: Train Epoch 10: 247/634 Loss: 0.147968
2023-01-02 23:17: Train Epoch 10: 251/634 Loss: 0.136677
2023-01-02 23:17: Train Epoch 10: 255/634 Loss: 0.129715
2023-01-02 23:18: Train Epoch 10: 259/634 Loss: 0.166313
2023-01-02 23:18: Train Epoch 10: 263/634 Loss: 0.141868
2023-01-02 23:18: Train Epoch 10: 267/634 Loss: 0.129831
2023-01-02 23:18: Train Epoch 10: 271/634 Loss: 0.139740
2023-01-02 23:18: Train Epoch 10: 275/634 Loss: 0.164653
2023-01-02 23:18: Train Epoch 10: 279/634 Loss: 0.168150
2023-01-02 23:18: Train Epoch 10: 283/634 Loss: 0.141034
2023-01-02 23:19: Train Epoch 10: 287/634 Loss: 0.125671
2023-01-02 23:19: Train Epoch 10: 291/634 Loss: 0.146476
2023-01-02 23:19: Train Epoch 10: 295/634 Loss: 0.141130
2023-01-02 23:19: Train Epoch 10: 299/634 Loss: 0.149667
2023-01-02 23:19: Train Epoch 10: 303/634 Loss: 0.129158
2023-01-02 23:19: Train Epoch 10: 307/634 Loss: 0.159654
2023-01-02 23:19: Train Epoch 10: 311/634 Loss: 0.164061
2023-01-02 23:20: Train Epoch 10: 315/634 Loss: 0.156907
2023-01-02 23:20: Train Epoch 10: 319/634 Loss: 0.140530
2023-01-02 23:20: Train Epoch 10: 323/634 Loss: 0.162643
2023-01-02 23:20: Train Epoch 10: 327/634 Loss: 0.128184
2023-01-02 23:20: Train Epoch 10: 331/634 Loss: 0.150007
2023-01-02 23:20: Train Epoch 10: 335/634 Loss: 0.166197
2023-01-02 23:20: Train Epoch 10: 339/634 Loss: 0.141750
2023-01-02 23:21: Train Epoch 10: 343/634 Loss: 0.162382
2023-01-02 23:21: Train Epoch 10: 347/634 Loss: 0.137867
2023-01-02 23:21: Train Epoch 10: 351/634 Loss: 0.161870
2023-01-02 23:21: Train Epoch 10: 355/634 Loss: 0.152747
2023-01-02 23:21: Train Epoch 10: 359/634 Loss: 0.157277
2023-01-02 23:21: Train Epoch 10: 363/634 Loss: 0.144290
2023-01-02 23:21: Train Epoch 10: 367/634 Loss: 0.163397
2023-01-02 23:22: Train Epoch 10: 371/634 Loss: 0.165278
2023-01-02 23:22: Train Epoch 10: 375/634 Loss: 0.133557
2023-01-02 23:22: Train Epoch 10: 379/634 Loss: 0.143221
2023-01-02 23:22: Train Epoch 10: 383/634 Loss: 0.159929
2023-01-02 23:22: Train Epoch 10: 387/634 Loss: 0.149684
2023-01-02 23:22: Train Epoch 10: 391/634 Loss: 0.152078
2023-01-02 23:23: Train Epoch 10: 395/634 Loss: 0.142355
2023-01-02 23:23: Train Epoch 10: 399/634 Loss: 0.145890
2023-01-02 23:23: Train Epoch 10: 403/634 Loss: 0.138958
2023-01-02 23:23: Train Epoch 10: 407/634 Loss: 0.170076
2023-01-02 23:23: Train Epoch 10: 411/634 Loss: 0.131847
2023-01-02 23:23: Train Epoch 10: 415/634 Loss: 0.170299
2023-01-02 23:23: Train Epoch 10: 419/634 Loss: 0.144459
2023-01-02 23:24: Train Epoch 10: 423/634 Loss: 0.149862
2023-01-02 23:24: Train Epoch 10: 427/634 Loss: 0.145028
2023-01-02 23:24: Train Epoch 10: 431/634 Loss: 0.140941
2023-01-02 23:24: Train Epoch 10: 435/634 Loss: 0.166266
2023-01-02 23:24: Train Epoch 10: 439/634 Loss: 0.171683
2023-01-02 23:24: Train Epoch 10: 443/634 Loss: 0.169595
2023-01-02 23:24: Train Epoch 10: 447/634 Loss: 0.144475
2023-01-02 23:25: Train Epoch 10: 451/634 Loss: 0.163323
2023-01-02 23:25: Train Epoch 10: 455/634 Loss: 0.146271
2023-01-02 23:25: Train Epoch 10: 459/634 Loss: 0.126364
2023-01-02 23:25: Train Epoch 10: 463/634 Loss: 0.137859
2023-01-02 23:25: Train Epoch 10: 467/634 Loss: 0.158433
2023-01-02 23:25: Train Epoch 10: 471/634 Loss: 0.139292
2023-01-02 23:25: Train Epoch 10: 475/634 Loss: 0.145918
2023-01-02 23:26: Train Epoch 10: 479/634 Loss: 0.164947
2023-01-02 23:26: Train Epoch 10: 483/634 Loss: 0.132632
2023-01-02 23:26: Train Epoch 10: 487/634 Loss: 0.162669
2023-01-02 23:26: Train Epoch 10: 491/634 Loss: 0.154445
2023-01-02 23:26: Train Epoch 10: 495/634 Loss: 0.169391
2023-01-02 23:27: Train Epoch 10: 499/634 Loss: 0.129393
2023-01-02 23:27: Train Epoch 10: 503/634 Loss: 0.138467
2023-01-02 23:27: Train Epoch 10: 507/634 Loss: 0.167068
2023-01-02 23:27: Train Epoch 10: 511/634 Loss: 0.174954
2023-01-02 23:27: Train Epoch 10: 515/634 Loss: 0.145994
2023-01-02 23:27: Train Epoch 10: 519/634 Loss: 0.159245
2023-01-02 23:28: Train Epoch 10: 523/634 Loss: 0.131030
2023-01-02 23:28: Train Epoch 10: 527/634 Loss: 0.156484
2023-01-02 23:28: Train Epoch 10: 531/634 Loss: 0.140716
2023-01-02 23:28: Train Epoch 10: 535/634 Loss: 0.146998
2023-01-02 23:28: Train Epoch 10: 539/634 Loss: 0.144875
2023-01-02 23:28: Train Epoch 10: 543/634 Loss: 0.130395
2023-01-02 23:29: Train Epoch 10: 547/634 Loss: 0.130199
2023-01-02 23:29: Train Epoch 10: 551/634 Loss: 0.152244
2023-01-02 23:29: Train Epoch 10: 555/634 Loss: 0.136449
2023-01-02 23:29: Train Epoch 10: 559/634 Loss: 0.144700
2023-01-02 23:29: Train Epoch 10: 563/634 Loss: 0.159268
2023-01-02 23:30: Train Epoch 10: 567/634 Loss: 0.134589
2023-01-02 23:30: Train Epoch 10: 571/634 Loss: 0.149575
2023-01-02 23:30: Train Epoch 10: 575/634 Loss: 0.133566
2023-01-02 23:30: Train Epoch 10: 579/634 Loss: 0.151281
2023-01-02 23:30: Train Epoch 10: 583/634 Loss: 0.143564
2023-01-02 23:31: Train Epoch 10: 587/634 Loss: 0.155631
2023-01-02 23:31: Train Epoch 10: 591/634 Loss: 0.143193
2023-01-02 23:31: Train Epoch 10: 595/634 Loss: 0.142829
2023-01-02 23:31: Train Epoch 10: 599/634 Loss: 0.153712
2023-01-02 23:31: Train Epoch 10: 603/634 Loss: 0.147630
2023-01-02 23:31: Train Epoch 10: 607/634 Loss: 0.155437
2023-01-02 23:32: Train Epoch 10: 611/634 Loss: 0.156286
2023-01-02 23:32: Train Epoch 10: 615/634 Loss: 0.145494
2023-01-02 23:32: Train Epoch 10: 619/634 Loss: 0.156601
2023-01-02 23:32: Train Epoch 10: 623/634 Loss: 0.159623
2023-01-02 23:32: Train Epoch 10: 627/634 Loss: 0.154574
2023-01-02 23:32: Train Epoch 10: 631/634 Loss: 0.165546
2023-01-02 23:33: Train Epoch 10: 633/634 Loss: 0.056143
2023-01-02 23:33: **********Train Epoch 10: averaged Loss: 0.149801 
2023-01-02 23:33: 
Epoch time elapsed: 1466.185652256012

2023-01-02 23:33: 
 metrics validation: {'precision': 0.8596491228070176, 'recall': 0.49, 'f1-score': 0.624203821656051, 'support': 1300, 'AUC': 0.9282239644970414, 'AUCPR': 0.8567740908818527, 'TP': 637, 'FP': 104, 'TN': 2496, 'FN': 663} 

2023-01-02 23:33: **********Val Epoch 10: average Loss: 0.179215
2023-01-02 23:34: 
 Testing metrics {'precision': 0.883352208380521, 'recall': 0.6351791530944625, 'f1-score': 0.738986262434865, 'support': 1228, 'AUC': 0.9252439017920615, 'AUCPR': 0.8780004580671148, 'TP': 780, 'FP': 103, 'TN': 2353, 'FN': 448} 

2023-01-02 23:37: 
 Testing metrics {'precision': 0.9331689947959463, 'recall': 0.7730882686634899, 'f1-score': 0.8456192603623728, 'support': 4407, 'AUC': 0.9725069174095363, 'AUCPR': 0.9407024382631225, 'TP': 3407, 'FP': 244, 'TN': 8570, 'FN': 1000} 

2023-01-02 23:37: Train Epoch 11: 3/634 Loss: 0.159222
2023-01-02 23:37: Train Epoch 11: 7/634 Loss: 0.137203
2023-01-02 23:38: Train Epoch 11: 11/634 Loss: 0.147616
2023-01-02 23:38: Train Epoch 11: 15/634 Loss: 0.172211
2023-01-02 23:38: Train Epoch 11: 19/634 Loss: 0.167617
2023-01-02 23:38: Train Epoch 11: 23/634 Loss: 0.135729
2023-01-02 23:38: Train Epoch 11: 27/634 Loss: 0.123183
2023-01-02 23:38: Train Epoch 11: 31/634 Loss: 0.137085
2023-01-02 23:39: Train Epoch 11: 35/634 Loss: 0.162190
2023-01-02 23:39: Train Epoch 11: 39/634 Loss: 0.139881
2023-01-02 23:39: Train Epoch 11: 43/634 Loss: 0.135982
2023-01-02 23:39: Train Epoch 11: 47/634 Loss: 0.173681
2023-01-02 23:39: Train Epoch 11: 51/634 Loss: 0.160980
2023-01-02 23:40: Train Epoch 11: 55/634 Loss: 0.129522
2023-01-02 23:40: Train Epoch 11: 59/634 Loss: 0.133904
2023-01-02 23:40: Train Epoch 11: 63/634 Loss: 0.132879
2023-01-02 23:40: Train Epoch 11: 67/634 Loss: 0.151428
2023-01-02 23:40: Train Epoch 11: 71/634 Loss: 0.147352
2023-01-02 23:41: Train Epoch 11: 75/634 Loss: 0.157687
2023-01-02 23:41: Train Epoch 11: 79/634 Loss: 0.155881
2023-01-02 23:41: Train Epoch 11: 83/634 Loss: 0.178795
2023-01-02 23:41: Train Epoch 11: 87/634 Loss: 0.179678
2023-01-02 23:41: Train Epoch 11: 91/634 Loss: 0.140426
2023-01-02 23:42: Train Epoch 11: 95/634 Loss: 0.159785
2023-01-02 23:42: Train Epoch 11: 99/634 Loss: 0.175648
2023-01-02 23:42: Train Epoch 11: 103/634 Loss: 0.154533
2023-01-02 23:42: Train Epoch 11: 107/634 Loss: 0.157869
2023-01-02 23:42: Train Epoch 11: 111/634 Loss: 0.172262
2023-01-02 23:43: Train Epoch 11: 115/634 Loss: 0.148009
2023-01-02 23:43: Train Epoch 11: 119/634 Loss: 0.169172
2023-01-02 23:43: Train Epoch 11: 123/634 Loss: 0.147214
2023-01-02 23:43: Train Epoch 11: 127/634 Loss: 0.151522
2023-01-02 23:43: Train Epoch 11: 131/634 Loss: 0.144200
2023-01-02 23:44: Train Epoch 11: 135/634 Loss: 0.153748
2023-01-02 23:44: Train Epoch 11: 139/634 Loss: 0.156749
2023-01-02 23:44: Train Epoch 11: 143/634 Loss: 0.151166
2023-01-02 23:44: Train Epoch 11: 147/634 Loss: 0.157930
2023-01-02 23:44: Train Epoch 11: 151/634 Loss: 0.148291
2023-01-02 23:45: Train Epoch 11: 155/634 Loss: 0.136914
2023-01-02 23:45: Train Epoch 11: 159/634 Loss: 0.133858
2023-01-02 23:45: Train Epoch 11: 163/634 Loss: 0.145338
2023-01-02 23:45: Train Epoch 11: 167/634 Loss: 0.139155
2023-01-02 23:45: Train Epoch 11: 171/634 Loss: 0.143349
2023-01-02 23:46: Train Epoch 11: 175/634 Loss: 0.134508
2023-01-02 23:46: Train Epoch 11: 179/634 Loss: 0.149964
2023-01-02 23:46: Train Epoch 11: 183/634 Loss: 0.149234
2023-01-02 23:46: Train Epoch 11: 187/634 Loss: 0.136334
2023-01-02 23:46: Train Epoch 11: 191/634 Loss: 0.148890
2023-01-02 23:47: Train Epoch 11: 195/634 Loss: 0.145072
2023-01-02 23:47: Train Epoch 11: 199/634 Loss: 0.139368
2023-01-02 23:47: Train Epoch 11: 203/634 Loss: 0.162005
2023-01-02 23:47: Train Epoch 11: 207/634 Loss: 0.138931
2023-01-02 23:47: Train Epoch 11: 211/634 Loss: 0.154001
2023-01-02 23:48: Train Epoch 11: 215/634 Loss: 0.152603
2023-01-02 23:48: Train Epoch 11: 219/634 Loss: 0.155743
2023-01-02 23:48: Train Epoch 11: 223/634 Loss: 0.169882
2023-01-02 23:48: Train Epoch 11: 227/634 Loss: 0.159931
2023-01-02 23:48: Train Epoch 11: 231/634 Loss: 0.155596
2023-01-02 23:48: Train Epoch 11: 235/634 Loss: 0.134386
2023-01-02 23:49: Train Epoch 11: 239/634 Loss: 0.140398
2023-01-02 23:49: Train Epoch 11: 243/634 Loss: 0.201246
2023-01-02 23:49: Train Epoch 11: 247/634 Loss: 0.155799
2023-01-02 23:49: Train Epoch 11: 251/634 Loss: 0.161335
2023-01-02 23:49: Train Epoch 11: 255/634 Loss: 0.141338
2023-01-02 23:50: Train Epoch 11: 259/634 Loss: 0.163242
2023-01-02 23:50: Train Epoch 11: 263/634 Loss: 0.158774
2023-01-02 23:50: Train Epoch 11: 267/634 Loss: 0.141659
2023-01-02 23:50: Train Epoch 11: 271/634 Loss: 0.137661
2023-01-02 23:50: Train Epoch 11: 275/634 Loss: 0.186228
2023-01-02 23:51: Train Epoch 11: 279/634 Loss: 0.183647
2023-01-02 23:51: Train Epoch 11: 283/634 Loss: 0.155828
2023-01-02 23:51: Train Epoch 11: 287/634 Loss: 0.160465
2023-01-02 23:51: Train Epoch 11: 291/634 Loss: 0.164310
2023-01-02 23:51: Train Epoch 11: 295/634 Loss: 0.158222
2023-01-02 23:51: Train Epoch 11: 299/634 Loss: 0.170074
2023-01-02 23:52: Train Epoch 11: 303/634 Loss: 0.148512
2023-01-02 23:52: Train Epoch 11: 307/634 Loss: 0.142873
2023-01-02 23:52: Train Epoch 11: 311/634 Loss: 0.150196
2023-01-02 23:52: Train Epoch 11: 315/634 Loss: 0.158988
2023-01-02 23:52: Train Epoch 11: 319/634 Loss: 0.150627
2023-01-02 23:53: Train Epoch 11: 323/634 Loss: 0.127214
2023-01-02 23:53: Train Epoch 11: 327/634 Loss: 0.137165
2023-01-02 23:53: Train Epoch 11: 331/634 Loss: 0.152051
2023-01-02 23:53: Train Epoch 11: 335/634 Loss: 0.150019
2023-01-02 23:53: Train Epoch 11: 339/634 Loss: 0.165403
2023-01-02 23:54: Train Epoch 11: 343/634 Loss: 0.146574
2023-01-02 23:54: Train Epoch 11: 347/634 Loss: 0.155238
2023-01-02 23:54: Train Epoch 11: 351/634 Loss: 0.138643
2023-01-02 23:54: Train Epoch 11: 355/634 Loss: 0.170532
2023-01-02 23:54: Train Epoch 11: 359/634 Loss: 0.164224
2023-01-02 23:54: Train Epoch 11: 363/634 Loss: 0.144424
2023-01-02 23:55: Train Epoch 11: 367/634 Loss: 0.181259
2023-01-02 23:55: Train Epoch 11: 371/634 Loss: 0.153230
2023-01-02 23:55: Train Epoch 11: 375/634 Loss: 0.152094
2023-01-02 23:55: Train Epoch 11: 379/634 Loss: 0.154140
2023-01-02 23:55: Train Epoch 11: 383/634 Loss: 0.166948
2023-01-02 23:55: Train Epoch 11: 387/634 Loss: 0.150609
2023-01-02 23:56: Train Epoch 11: 391/634 Loss: 0.169777
2023-01-02 23:56: Train Epoch 11: 395/634 Loss: 0.137846
2023-01-02 23:56: Train Epoch 11: 399/634 Loss: 0.157028
2023-01-02 23:56: Train Epoch 11: 403/634 Loss: 0.134885
2023-01-02 23:56: Train Epoch 11: 407/634 Loss: 0.146085
2023-01-02 23:57: Train Epoch 11: 411/634 Loss: 0.141853
2023-01-02 23:57: Train Epoch 11: 415/634 Loss: 0.146759
2023-01-02 23:57: Train Epoch 11: 419/634 Loss: 0.124637
2023-01-02 23:57: Train Epoch 11: 423/634 Loss: 0.149790
2023-01-02 23:57: Train Epoch 11: 427/634 Loss: 0.150356
2023-01-02 23:57: Train Epoch 11: 431/634 Loss: 0.139323
2023-01-02 23:58: Train Epoch 11: 435/634 Loss: 0.152968
2023-01-02 23:58: Train Epoch 11: 439/634 Loss: 0.148422
2023-01-02 23:58: Train Epoch 11: 443/634 Loss: 0.147947
2023-01-02 23:58: Train Epoch 11: 447/634 Loss: 0.135119
2023-01-02 23:58: Train Epoch 11: 451/634 Loss: 0.159700
2023-01-02 23:58: Train Epoch 11: 455/634 Loss: 0.170510
2023-01-02 23:59: Train Epoch 11: 459/634 Loss: 0.134992
2023-01-02 23:59: Train Epoch 11: 463/634 Loss: 0.151750
2023-01-02 23:59: Train Epoch 11: 467/634 Loss: 0.127811
2023-01-02 23:59: Train Epoch 11: 471/634 Loss: 0.144380
2023-01-02 23:59: Train Epoch 11: 475/634 Loss: 0.134315
2023-01-03 00:00: Train Epoch 11: 479/634 Loss: 0.138391
2023-01-03 00:00: Train Epoch 11: 483/634 Loss: 0.139013
2023-01-03 00:00: Train Epoch 11: 487/634 Loss: 0.140598
2023-01-03 00:00: Train Epoch 11: 491/634 Loss: 0.143146
2023-01-03 00:01: Train Epoch 11: 495/634 Loss: 0.126190
2023-01-03 00:01: Train Epoch 11: 499/634 Loss: 0.121993
2023-01-03 00:01: Train Epoch 11: 503/634 Loss: 0.132027
2023-01-03 00:01: Train Epoch 11: 507/634 Loss: 0.142315
2023-01-03 00:01: Train Epoch 11: 511/634 Loss: 0.172881
2023-01-03 00:01: Train Epoch 11: 515/634 Loss: 0.153325
2023-01-03 00:02: Train Epoch 11: 519/634 Loss: 0.139405
2023-01-03 00:02: Train Epoch 11: 523/634 Loss: 0.142421
2023-01-03 00:02: Train Epoch 11: 527/634 Loss: 0.142751
2023-01-03 00:02: Train Epoch 11: 531/634 Loss: 0.164414
2023-01-03 00:02: Train Epoch 11: 535/634 Loss: 0.171571
2023-01-03 00:03: Train Epoch 11: 539/634 Loss: 0.160575
2023-01-03 00:03: Train Epoch 11: 543/634 Loss: 0.157558
2023-01-03 00:03: Train Epoch 11: 547/634 Loss: 0.123574
2023-01-03 00:03: Train Epoch 11: 551/634 Loss: 0.134811
2023-01-03 00:03: Train Epoch 11: 555/634 Loss: 0.126861
2023-01-03 00:04: Train Epoch 11: 559/634 Loss: 0.133535
2023-01-03 00:04: Train Epoch 11: 563/634 Loss: 0.129954
2023-01-03 00:04: Train Epoch 11: 567/634 Loss: 0.136641
2023-01-03 00:04: Train Epoch 11: 571/634 Loss: 0.141861
2023-01-03 00:04: Train Epoch 11: 575/634 Loss: 0.138394
2023-01-03 00:05: Train Epoch 11: 579/634 Loss: 0.153904
2023-01-03 00:05: Train Epoch 11: 583/634 Loss: 0.151283
2023-01-03 00:05: Train Epoch 11: 587/634 Loss: 0.165638
2023-01-03 00:05: Train Epoch 11: 591/634 Loss: 0.126764
2023-01-03 00:05: Train Epoch 11: 595/634 Loss: 0.128433
2023-01-03 00:06: Train Epoch 11: 599/634 Loss: 0.141259
2023-01-03 00:06: Train Epoch 11: 603/634 Loss: 0.120323
2023-01-03 00:06: Train Epoch 11: 607/634 Loss: 0.150211
2023-01-03 00:06: Train Epoch 11: 611/634 Loss: 0.144213
2023-01-03 00:06: Train Epoch 11: 615/634 Loss: 0.136836
2023-01-03 00:07: Train Epoch 11: 619/634 Loss: 0.153847
2023-01-03 00:07: Train Epoch 11: 623/634 Loss: 0.142861
2023-01-03 00:07: Train Epoch 11: 627/634 Loss: 0.146087
2023-01-03 00:07: Train Epoch 11: 631/634 Loss: 0.149115
2023-01-03 00:07: Train Epoch 11: 633/634 Loss: 0.061836
2023-01-03 00:07: **********Train Epoch 11: averaged Loss: 0.148853 
2023-01-03 00:07: 
Epoch time elapsed: 1804.2624921798706

2023-01-03 00:08: 
 metrics validation: {'precision': 0.796669588080631, 'recall': 0.6992307692307692, 'f1-score': 0.7447767308480131, 'support': 1300, 'AUC': 0.9280662721893491, 'AUCPR': 0.8640515403287193, 'TP': 909, 'FP': 232, 'TN': 2368, 'FN': 391} 

2023-01-03 00:08: **********Val Epoch 11: average Loss: 0.152665
2023-01-03 00:08: *********************************Current best model saved!
2023-01-03 00:09: 
 Testing metrics {'precision': 0.8574423480083857, 'recall': 0.6661237785016286, 'f1-score': 0.7497708524289642, 'support': 1228, 'AUC': 0.9173197460981017, 'AUCPR': 0.872776795765277, 'TP': 818, 'FP': 136, 'TN': 2320, 'FN': 410} 

2023-01-03 00:13: 
 Testing metrics {'precision': 0.9057187017001546, 'recall': 0.7978216473791695, 'f1-score': 0.8483532392327181, 'support': 4407, 'AUC': 0.9689325556238814, 'AUCPR': 0.9293686726701968, 'TP': 3516, 'FP': 366, 'TN': 8448, 'FN': 891} 

2023-01-03 00:13: Train Epoch 12: 3/634 Loss: 0.143750
2023-01-03 00:13: Train Epoch 12: 7/634 Loss: 0.149278
2023-01-03 00:13: Train Epoch 12: 11/634 Loss: 0.135817
2023-01-03 00:14: Train Epoch 12: 15/634 Loss: 0.119062
2023-01-03 00:14: Train Epoch 12: 19/634 Loss: 0.119011
2023-01-03 00:14: Train Epoch 12: 23/634 Loss: 0.153995
2023-01-03 00:14: Train Epoch 12: 27/634 Loss: 0.152827
2023-01-03 00:14: Train Epoch 12: 31/634 Loss: 0.108155
2023-01-03 00:14: Train Epoch 12: 35/634 Loss: 0.160663
2023-01-03 00:15: Train Epoch 12: 39/634 Loss: 0.160392
2023-01-03 00:15: Train Epoch 12: 43/634 Loss: 0.145741
2023-01-03 00:15: Train Epoch 12: 47/634 Loss: 0.163329
2023-01-03 00:15: Train Epoch 12: 51/634 Loss: 0.146079
2023-01-03 00:15: Train Epoch 12: 55/634 Loss: 0.146075
2023-01-03 00:15: Train Epoch 12: 59/634 Loss: 0.166735
2023-01-03 00:16: Train Epoch 12: 63/634 Loss: 0.130772
2023-01-03 00:16: Train Epoch 12: 67/634 Loss: 0.164371
2023-01-03 00:16: Train Epoch 12: 71/634 Loss: 0.141787
2023-01-03 00:16: Train Epoch 12: 75/634 Loss: 0.168848
2023-01-03 00:16: Train Epoch 12: 79/634 Loss: 0.143844
2023-01-03 00:17: Train Epoch 12: 83/634 Loss: 0.157340
2023-01-03 00:17: Train Epoch 12: 87/634 Loss: 0.143962
2023-01-03 00:17: Train Epoch 12: 91/634 Loss: 0.145108
2023-01-03 00:17: Train Epoch 12: 95/634 Loss: 0.137412
2023-01-03 00:17: Train Epoch 12: 99/634 Loss: 0.152714
2023-01-03 00:17: Train Epoch 12: 103/634 Loss: 0.154539
2023-01-03 00:18: Train Epoch 12: 107/634 Loss: 0.128382
2023-01-03 00:18: Train Epoch 12: 111/634 Loss: 0.133050
2023-01-03 00:18: Train Epoch 12: 115/634 Loss: 0.134375
2023-01-03 00:18: Train Epoch 12: 119/634 Loss: 0.157782
2023-01-03 00:18: Train Epoch 12: 123/634 Loss: 0.157348
2023-01-03 00:19: Train Epoch 12: 127/634 Loss: 0.160538
2023-01-03 00:19: Train Epoch 12: 131/634 Loss: 0.149906
2023-01-03 00:19: Train Epoch 12: 135/634 Loss: 0.167425
2023-01-03 00:19: Train Epoch 12: 139/634 Loss: 0.175779
2023-01-03 00:19: Train Epoch 12: 143/634 Loss: 0.165745
2023-01-03 00:20: Train Epoch 12: 147/634 Loss: 0.134186
2023-01-03 00:20: Train Epoch 12: 151/634 Loss: 0.183754
2023-01-03 00:20: Train Epoch 12: 155/634 Loss: 0.130032
2023-01-03 00:20: Train Epoch 12: 159/634 Loss: 0.166809
2023-01-03 00:20: Train Epoch 12: 163/634 Loss: 0.145560
2023-01-03 00:21: Train Epoch 12: 167/634 Loss: 0.122846
2023-01-03 00:21: Train Epoch 12: 171/634 Loss: 0.148458
2023-01-03 00:21: Train Epoch 12: 175/634 Loss: 0.163254
2023-01-03 00:21: Train Epoch 12: 179/634 Loss: 0.144772
2023-01-03 00:21: Train Epoch 12: 183/634 Loss: 0.107719
2023-01-03 00:21: Train Epoch 12: 187/634 Loss: 0.144357
2023-01-03 00:22: Train Epoch 12: 191/634 Loss: 0.169672
2023-01-03 00:22: Train Epoch 12: 195/634 Loss: 0.167050
2023-01-03 00:22: Train Epoch 12: 199/634 Loss: 0.121654
2023-01-03 00:22: Train Epoch 12: 203/634 Loss: 0.165007
2023-01-03 00:22: Train Epoch 12: 207/634 Loss: 0.140875
2023-01-03 00:23: Train Epoch 12: 211/634 Loss: 0.143940
2023-01-03 00:23: Train Epoch 12: 215/634 Loss: 0.163543
2023-01-03 00:23: Train Epoch 12: 219/634 Loss: 0.139496
2023-01-03 00:23: Train Epoch 12: 223/634 Loss: 0.138481
2023-01-03 00:23: Train Epoch 12: 227/634 Loss: 0.145593
2023-01-03 00:23: Train Epoch 12: 231/634 Loss: 0.155362
2023-01-03 00:24: Train Epoch 12: 235/634 Loss: 0.138531
2023-01-03 00:24: Train Epoch 12: 239/634 Loss: 0.152328
2023-01-03 00:24: Train Epoch 12: 243/634 Loss: 0.152190
2023-01-03 00:24: Train Epoch 12: 247/634 Loss: 0.151748
2023-01-03 00:24: Train Epoch 12: 251/634 Loss: 0.165059
2023-01-03 00:25: Train Epoch 12: 255/634 Loss: 0.117611
2023-01-03 00:25: Train Epoch 12: 259/634 Loss: 0.146289
2023-01-03 00:25: Train Epoch 12: 263/634 Loss: 0.129421
2023-01-03 00:25: Train Epoch 12: 267/634 Loss: 0.171492
2023-01-03 00:25: Train Epoch 12: 271/634 Loss: 0.137435
2023-01-03 00:26: Train Epoch 12: 275/634 Loss: 0.146547
2023-01-03 00:26: Train Epoch 12: 279/634 Loss: 0.145612
2023-01-03 00:26: Train Epoch 12: 283/634 Loss: 0.142327
2023-01-03 00:26: Train Epoch 12: 287/634 Loss: 0.156494
2023-01-03 00:26: Train Epoch 12: 291/634 Loss: 0.145279
2023-01-03 00:26: Train Epoch 12: 295/634 Loss: 0.143736
2023-01-03 00:27: Train Epoch 12: 299/634 Loss: 0.159672
2023-01-03 00:27: Train Epoch 12: 303/634 Loss: 0.156962
2023-01-03 00:27: Train Epoch 12: 307/634 Loss: 0.135115
2023-01-03 00:27: Train Epoch 12: 311/634 Loss: 0.160916
2023-01-03 00:27: Train Epoch 12: 315/634 Loss: 0.138291
2023-01-03 00:28: Train Epoch 12: 319/634 Loss: 0.148701
2023-01-03 00:28: Train Epoch 12: 323/634 Loss: 0.141049
2023-01-03 00:28: Train Epoch 12: 327/634 Loss: 0.152198
2023-01-03 00:28: Train Epoch 12: 331/634 Loss: 0.133970
2023-01-03 00:28: Train Epoch 12: 335/634 Loss: 0.142935
2023-01-03 00:29: Train Epoch 12: 339/634 Loss: 0.161895
2023-01-03 00:29: Train Epoch 12: 343/634 Loss: 0.150051
2023-01-03 00:29: Train Epoch 12: 347/634 Loss: 0.151302
2023-01-03 00:29: Train Epoch 12: 351/634 Loss: 0.125113
2023-01-03 00:29: Train Epoch 12: 355/634 Loss: 0.151965
2023-01-03 00:30: Train Epoch 12: 359/634 Loss: 0.151023
2023-01-03 00:30: Train Epoch 12: 363/634 Loss: 0.154738
2023-01-03 00:30: Train Epoch 12: 367/634 Loss: 0.123249
2023-01-03 00:30: Train Epoch 12: 371/634 Loss: 0.136587
2023-01-03 00:30: Train Epoch 12: 375/634 Loss: 0.141685
2023-01-03 00:31: Train Epoch 12: 379/634 Loss: 0.136057
2023-01-03 00:31: Train Epoch 12: 383/634 Loss: 0.162970
2023-01-03 00:31: Train Epoch 12: 387/634 Loss: 0.163591
2023-01-03 00:31: Train Epoch 12: 391/634 Loss: 0.137222
2023-01-03 00:31: Train Epoch 12: 395/634 Loss: 0.157655
2023-01-03 00:32: Train Epoch 12: 399/634 Loss: 0.123137
2023-01-03 00:32: Train Epoch 12: 403/634 Loss: 0.141968
2023-01-03 00:32: Train Epoch 12: 407/634 Loss: 0.136989
2023-01-03 00:32: Train Epoch 12: 411/634 Loss: 0.142061
2023-01-03 00:32: Train Epoch 12: 415/634 Loss: 0.155051
2023-01-03 00:33: Train Epoch 12: 419/634 Loss: 0.156429
2023-01-03 00:33: Train Epoch 12: 423/634 Loss: 0.159271
2023-01-03 00:33: Train Epoch 12: 427/634 Loss: 0.146736
2023-01-03 00:33: Train Epoch 12: 431/634 Loss: 0.139492
2023-01-03 00:33: Train Epoch 12: 435/634 Loss: 0.139486
2023-01-03 00:33: Train Epoch 12: 439/634 Loss: 0.149391
2023-01-03 00:34: Train Epoch 12: 443/634 Loss: 0.114950
2023-01-03 00:34: Train Epoch 12: 447/634 Loss: 0.138232
2023-01-03 00:34: Train Epoch 12: 451/634 Loss: 0.137311
2023-01-03 00:34: Train Epoch 12: 455/634 Loss: 0.127894
2023-01-03 00:34: Train Epoch 12: 459/634 Loss: 0.154688
2023-01-03 00:35: Train Epoch 12: 463/634 Loss: 0.154115
2023-01-03 00:35: Train Epoch 12: 467/634 Loss: 0.133242
2023-01-03 00:35: Train Epoch 12: 471/634 Loss: 0.153575
2023-01-03 00:35: Train Epoch 12: 475/634 Loss: 0.171229
2023-01-03 00:35: Train Epoch 12: 479/634 Loss: 0.146060
2023-01-03 00:36: Train Epoch 12: 483/634 Loss: 0.144769
2023-01-03 00:36: Train Epoch 12: 487/634 Loss: 0.137922
2023-01-03 00:36: Train Epoch 12: 491/634 Loss: 0.150384
2023-01-03 00:36: Train Epoch 12: 495/634 Loss: 0.138143
2023-01-03 00:36: Train Epoch 12: 499/634 Loss: 0.157060
2023-01-03 00:36: Train Epoch 12: 503/634 Loss: 0.141098
2023-01-03 00:37: Train Epoch 12: 507/634 Loss: 0.129135
2023-01-03 00:37: Train Epoch 12: 511/634 Loss: 0.127476
2023-01-03 00:37: Train Epoch 12: 515/634 Loss: 0.148926
2023-01-03 00:37: Train Epoch 12: 519/634 Loss: 0.142477
2023-01-03 00:37: Train Epoch 12: 523/634 Loss: 0.147071
2023-01-03 00:37: Train Epoch 12: 527/634 Loss: 0.165794
2023-01-03 00:38: Train Epoch 12: 531/634 Loss: 0.128870
2023-01-03 00:38: Train Epoch 12: 535/634 Loss: 0.139152
2023-01-03 00:38: Train Epoch 12: 539/634 Loss: 0.158534
2023-01-03 00:38: Train Epoch 12: 543/634 Loss: 0.148497
2023-01-03 00:38: Train Epoch 12: 547/634 Loss: 0.154715
2023-01-03 00:39: Train Epoch 12: 551/634 Loss: 0.151859
2023-01-03 00:39: Train Epoch 12: 555/634 Loss: 0.179879
2023-01-03 00:39: Train Epoch 12: 559/634 Loss: 0.138417
2023-01-03 00:39: Train Epoch 12: 563/634 Loss: 0.151712
2023-01-03 00:39: Train Epoch 12: 567/634 Loss: 0.148151
2023-01-03 00:40: Train Epoch 12: 571/634 Loss: 0.159972
2023-01-03 00:40: Train Epoch 12: 575/634 Loss: 0.134371
2023-01-03 00:40: Train Epoch 12: 579/634 Loss: 0.128188
2023-01-03 00:40: Train Epoch 12: 583/634 Loss: 0.160370
2023-01-03 00:40: Train Epoch 12: 587/634 Loss: 0.158415
2023-01-03 00:41: Train Epoch 12: 591/634 Loss: 0.141868
2023-01-03 00:41: Train Epoch 12: 595/634 Loss: 0.151194
2023-01-03 00:41: Train Epoch 12: 599/634 Loss: 0.147927
2023-01-03 00:41: Train Epoch 12: 603/634 Loss: 0.133679
2023-01-03 00:41: Train Epoch 12: 607/634 Loss: 0.138145
2023-01-03 00:42: Train Epoch 12: 611/634 Loss: 0.144006
2023-01-03 00:42: Train Epoch 12: 615/634 Loss: 0.155504
2023-01-03 00:42: Train Epoch 12: 619/634 Loss: 0.134626
2023-01-03 00:42: Train Epoch 12: 623/634 Loss: 0.142462
2023-01-03 00:42: Train Epoch 12: 627/634 Loss: 0.177801
2023-01-03 00:42: Train Epoch 12: 631/634 Loss: 0.129467
2023-01-03 00:42: Train Epoch 12: 633/634 Loss: 0.061826
2023-01-03 00:42: **********Train Epoch 12: averaged Loss: 0.146242 
2023-01-03 00:42: 
Epoch time elapsed: 1792.4264507293701

2023-01-03 00:43: 
 metrics validation: {'precision': 0.8626444159178434, 'recall': 0.5169230769230769, 'f1-score': 0.6464646464646465, 'support': 1300, 'AUC': 0.9241233727810652, 'AUCPR': 0.8543927692296333, 'TP': 672, 'FP': 107, 'TN': 2493, 'FN': 628} 

2023-01-03 00:43: **********Val Epoch 12: average Loss: 0.188162
2023-01-03 00:44: 
 Testing metrics {'precision': 0.8574423480083857, 'recall': 0.6661237785016286, 'f1-score': 0.7497708524289642, 'support': 1228, 'AUC': 0.9173197460981017, 'AUCPR': 0.872776795765277, 'TP': 818, 'FP': 136, 'TN': 2320, 'FN': 410} 

2023-01-03 00:47: 
 Testing metrics {'precision': 0.9057187017001546, 'recall': 0.7978216473791695, 'f1-score': 0.8483532392327181, 'support': 4407, 'AUC': 0.9689325556238814, 'AUCPR': 0.9293686726701968, 'TP': 3516, 'FP': 366, 'TN': 8448, 'FN': 891} 

2023-01-03 00:47: Train Epoch 13: 3/634 Loss: 0.160376
2023-01-03 00:48: Train Epoch 13: 7/634 Loss: 0.157452
2023-01-03 00:48: Train Epoch 13: 11/634 Loss: 0.144928
2023-01-03 00:48: Train Epoch 13: 15/634 Loss: 0.138745
2023-01-03 00:48: Train Epoch 13: 19/634 Loss: 0.142940
2023-01-03 00:48: Train Epoch 13: 23/634 Loss: 0.158022
2023-01-03 00:49: Train Epoch 13: 27/634 Loss: 0.152966
2023-01-03 00:49: Train Epoch 13: 31/634 Loss: 0.176360
2023-01-03 00:49: Train Epoch 13: 35/634 Loss: 0.146916
2023-01-03 00:49: Train Epoch 13: 39/634 Loss: 0.176408
2023-01-03 00:49: Train Epoch 13: 43/634 Loss: 0.175732
2023-01-03 00:49: Train Epoch 13: 47/634 Loss: 0.142072
2023-01-03 00:50: Train Epoch 13: 51/634 Loss: 0.124164
2023-01-03 00:50: Train Epoch 13: 55/634 Loss: 0.149681
2023-01-03 00:50: Train Epoch 13: 59/634 Loss: 0.125817
2023-01-03 00:50: Train Epoch 13: 63/634 Loss: 0.163054
2023-01-03 00:51: Train Epoch 13: 67/634 Loss: 0.164336
2023-01-03 00:51: Train Epoch 13: 71/634 Loss: 0.166232
2023-01-03 00:51: Train Epoch 13: 75/634 Loss: 0.165286
2023-01-03 00:51: Train Epoch 13: 79/634 Loss: 0.115004
2023-01-03 00:51: Train Epoch 13: 83/634 Loss: 0.176842
2023-01-03 00:51: Train Epoch 13: 87/634 Loss: 0.168012
2023-01-03 00:52: Train Epoch 13: 91/634 Loss: 0.122745
2023-01-03 00:52: Train Epoch 13: 95/634 Loss: 0.154283
2023-01-03 00:52: Train Epoch 13: 99/634 Loss: 0.154630
2023-01-03 00:52: Train Epoch 13: 103/634 Loss: 0.135378
2023-01-03 00:52: Train Epoch 13: 107/634 Loss: 0.170301
2023-01-03 00:52: Train Epoch 13: 111/634 Loss: 0.134543
2023-01-03 00:53: Train Epoch 13: 115/634 Loss: 0.146826
2023-01-03 00:53: Train Epoch 13: 119/634 Loss: 0.106147
2023-01-03 00:53: Train Epoch 13: 123/634 Loss: 0.135519
2023-01-03 00:53: Train Epoch 13: 127/634 Loss: 0.155273
2023-01-03 00:53: Train Epoch 13: 131/634 Loss: 0.134185
2023-01-03 00:54: Train Epoch 13: 135/634 Loss: 0.124339
2023-01-03 00:54: Train Epoch 13: 139/634 Loss: 0.129427
2023-01-03 00:54: Train Epoch 13: 143/634 Loss: 0.164359
2023-01-03 00:54: Train Epoch 13: 147/634 Loss: 0.151656
2023-01-03 00:54: Train Epoch 13: 151/634 Loss: 0.151916
2023-01-03 00:54: Train Epoch 13: 155/634 Loss: 0.142020
2023-01-03 00:55: Train Epoch 13: 159/634 Loss: 0.161758
2023-01-03 00:55: Train Epoch 13: 163/634 Loss: 0.137276
2023-01-03 00:55: Train Epoch 13: 167/634 Loss: 0.134058
2023-01-03 00:55: Train Epoch 13: 171/634 Loss: 0.145798
2023-01-03 00:55: Train Epoch 13: 175/634 Loss: 0.164881
2023-01-03 00:56: Train Epoch 13: 179/634 Loss: 0.151283
2023-01-03 00:56: Train Epoch 13: 183/634 Loss: 0.147984
2023-01-03 00:56: Train Epoch 13: 187/634 Loss: 0.162472
2023-01-03 00:56: Train Epoch 13: 191/634 Loss: 0.134710
2023-01-03 00:56: Train Epoch 13: 195/634 Loss: 0.158841
2023-01-03 00:56: Train Epoch 13: 199/634 Loss: 0.153522
2023-01-03 00:57: Train Epoch 13: 203/634 Loss: 0.156414
2023-01-03 00:57: Train Epoch 13: 207/634 Loss: 0.149646
2023-01-03 00:57: Train Epoch 13: 211/634 Loss: 0.145414
2023-01-03 00:57: Train Epoch 13: 215/634 Loss: 0.135537
2023-01-03 00:57: Train Epoch 13: 219/634 Loss: 0.163677
2023-01-03 00:58: Train Epoch 13: 223/634 Loss: 0.139737
2023-01-03 00:58: Train Epoch 13: 227/634 Loss: 0.123344
2023-01-03 00:58: Train Epoch 13: 231/634 Loss: 0.159495
2023-01-03 00:58: Train Epoch 13: 235/634 Loss: 0.158844
2023-01-03 00:58: Train Epoch 13: 239/634 Loss: 0.164107
2023-01-03 00:59: Train Epoch 13: 243/634 Loss: 0.148819
2023-01-03 00:59: Train Epoch 13: 247/634 Loss: 0.148296
2023-01-03 00:59: Train Epoch 13: 251/634 Loss: 0.157277
2023-01-03 00:59: Train Epoch 13: 255/634 Loss: 0.140682
2023-01-03 00:59: Train Epoch 13: 259/634 Loss: 0.163178
2023-01-03 01:00: Train Epoch 13: 263/634 Loss: 0.161268
2023-01-03 01:00: Train Epoch 13: 267/634 Loss: 0.150776
2023-01-03 01:00: Train Epoch 13: 271/634 Loss: 0.151120
2023-01-03 01:00: Train Epoch 13: 275/634 Loss: 0.147098
2023-01-03 01:01: Train Epoch 13: 279/634 Loss: 0.129433
2023-01-03 01:01: Train Epoch 13: 283/634 Loss: 0.148896
2023-01-03 01:01: Train Epoch 13: 287/634 Loss: 0.124742
2023-01-03 01:01: Train Epoch 13: 291/634 Loss: 0.139480
2023-01-03 01:01: Train Epoch 13: 295/634 Loss: 0.143491
2023-01-03 01:02: Train Epoch 13: 299/634 Loss: 0.132667
2023-01-03 01:02: Train Epoch 13: 303/634 Loss: 0.132107
2023-01-03 01:02: Train Epoch 13: 307/634 Loss: 0.153917
2023-01-03 01:02: Train Epoch 13: 311/634 Loss: 0.155897
2023-01-03 01:02: Train Epoch 13: 315/634 Loss: 0.147906
2023-01-03 01:03: Train Epoch 13: 319/634 Loss: 0.161657
2023-01-03 01:03: Train Epoch 13: 323/634 Loss: 0.143683
2023-01-03 01:03: Train Epoch 13: 327/634 Loss: 0.151032
2023-01-03 01:03: Train Epoch 13: 331/634 Loss: 0.130447
2023-01-03 01:03: Train Epoch 13: 335/634 Loss: 0.142944
2023-01-03 01:04: Train Epoch 13: 339/634 Loss: 0.134747
2023-01-03 01:04: Train Epoch 13: 343/634 Loss: 0.155746
2023-01-03 01:04: Train Epoch 13: 347/634 Loss: 0.149710
2023-01-03 01:04: Train Epoch 13: 351/634 Loss: 0.148778
2023-01-03 01:04: Train Epoch 13: 355/634 Loss: 0.150692
2023-01-03 01:04: Train Epoch 13: 359/634 Loss: 0.126280
2023-01-03 01:05: Train Epoch 13: 363/634 Loss: 0.144964
2023-01-03 01:05: Train Epoch 13: 367/634 Loss: 0.148141
2023-01-03 01:05: Train Epoch 13: 371/634 Loss: 0.158812
2023-01-03 01:05: Train Epoch 13: 375/634 Loss: 0.119914
2023-01-03 01:05: Train Epoch 13: 379/634 Loss: 0.145609
2023-01-03 01:06: Train Epoch 13: 383/634 Loss: 0.139016
2023-01-03 01:06: Train Epoch 13: 387/634 Loss: 0.149375
2023-01-03 01:06: Train Epoch 13: 391/634 Loss: 0.140038
2023-01-03 01:06: Train Epoch 13: 395/634 Loss: 0.126938
2023-01-03 01:06: Train Epoch 13: 399/634 Loss: 0.141271
2023-01-03 01:06: Train Epoch 13: 403/634 Loss: 0.136507
2023-01-03 01:07: Train Epoch 13: 407/634 Loss: 0.136486
2023-01-03 01:07: Train Epoch 13: 411/634 Loss: 0.147796
2023-01-03 01:07: Train Epoch 13: 415/634 Loss: 0.134522
2023-01-03 01:07: Train Epoch 13: 419/634 Loss: 0.164966
2023-01-03 01:07: Train Epoch 13: 423/634 Loss: 0.143316
2023-01-03 01:08: Train Epoch 13: 427/634 Loss: 0.165595
2023-01-03 01:08: Train Epoch 13: 431/634 Loss: 0.172555
2023-01-03 01:08: Train Epoch 13: 435/634 Loss: 0.153296
2023-01-03 01:08: Train Epoch 13: 439/634 Loss: 0.118889
2023-01-03 01:08: Train Epoch 13: 443/634 Loss: 0.163130
2023-01-03 01:09: Train Epoch 13: 447/634 Loss: 0.168914
2023-01-03 01:09: Train Epoch 13: 451/634 Loss: 0.142090
2023-01-03 01:09: Train Epoch 13: 455/634 Loss: 0.127870
2023-01-03 01:09: Train Epoch 13: 459/634 Loss: 0.165806
2023-01-03 01:09: Train Epoch 13: 463/634 Loss: 0.157040
2023-01-03 01:09: Train Epoch 13: 467/634 Loss: 0.154174
2023-01-03 01:10: Train Epoch 13: 471/634 Loss: 0.143503
2023-01-03 01:10: Train Epoch 13: 475/634 Loss: 0.139783
2023-01-03 01:10: Train Epoch 13: 479/634 Loss: 0.138495
2023-01-03 01:10: Train Epoch 13: 483/634 Loss: 0.135044
2023-01-03 01:11: Train Epoch 13: 487/634 Loss: 0.120605
2023-01-03 01:11: Train Epoch 13: 491/634 Loss: 0.151310
2023-01-03 01:11: Train Epoch 13: 495/634 Loss: 0.126132
2023-01-03 01:11: Train Epoch 13: 499/634 Loss: 0.156954
2023-01-03 01:11: Train Epoch 13: 503/634 Loss: 0.153938
2023-01-03 01:12: Train Epoch 13: 507/634 Loss: 0.158585
2023-01-03 01:12: Train Epoch 13: 511/634 Loss: 0.128837
2023-01-03 01:12: Train Epoch 13: 515/634 Loss: 0.128104
2023-01-03 01:12: Train Epoch 13: 519/634 Loss: 0.166323
2023-01-03 01:12: Train Epoch 13: 523/634 Loss: 0.140984
2023-01-03 01:13: Train Epoch 13: 527/634 Loss: 0.143157
2023-01-03 01:13: Train Epoch 13: 531/634 Loss: 0.164713
2023-01-03 01:13: Train Epoch 13: 535/634 Loss: 0.154255
2023-01-03 01:13: Train Epoch 13: 539/634 Loss: 0.159745
2023-01-03 01:13: Train Epoch 13: 543/634 Loss: 0.151692
2023-01-03 01:13: Train Epoch 13: 547/634 Loss: 0.147238
2023-01-03 01:14: Train Epoch 13: 551/634 Loss: 0.149279
2023-01-03 01:14: Train Epoch 13: 555/634 Loss: 0.177725
2023-01-03 01:14: Train Epoch 13: 559/634 Loss: 0.143817
2023-01-03 01:14: Train Epoch 13: 563/634 Loss: 0.144635
2023-01-03 01:14: Train Epoch 13: 567/634 Loss: 0.146453
2023-01-03 01:15: Train Epoch 13: 571/634 Loss: 0.122092
2023-01-03 01:15: Train Epoch 13: 575/634 Loss: 0.156982
2023-01-03 01:15: Train Epoch 13: 579/634 Loss: 0.126108
2023-01-03 01:15: Train Epoch 13: 583/634 Loss: 0.140540
2023-01-03 01:15: Train Epoch 13: 587/634 Loss: 0.149808
2023-01-03 01:15: Train Epoch 13: 591/634 Loss: 0.123123
2023-01-03 01:16: Train Epoch 13: 595/634 Loss: 0.154200
2023-01-03 01:16: Train Epoch 13: 599/634 Loss: 0.142581
2023-01-03 01:16: Train Epoch 13: 603/634 Loss: 0.166727
2023-01-03 01:16: Train Epoch 13: 607/634 Loss: 0.156324
2023-01-03 01:16: Train Epoch 13: 611/634 Loss: 0.137221
2023-01-03 01:16: Train Epoch 13: 615/634 Loss: 0.153788
2023-01-03 01:17: Train Epoch 13: 619/634 Loss: 0.152904
2023-01-03 01:17: Train Epoch 13: 623/634 Loss: 0.162274
2023-01-03 01:17: Train Epoch 13: 627/634 Loss: 0.157673
2023-01-03 01:17: Train Epoch 13: 631/634 Loss: 0.136212
2023-01-03 01:17: Train Epoch 13: 633/634 Loss: 0.044204
2023-01-03 01:17: **********Train Epoch 13: averaged Loss: 0.146840 
2023-01-03 01:17: 
Epoch time elapsed: 1798.8706848621368

2023-01-03 01:18: 
 metrics validation: {'precision': 0.9051948051948052, 'recall': 0.5361538461538462, 'f1-score': 0.6734299516908213, 'support': 1300, 'AUC': 0.9459982248520711, 'AUCPR': 0.8902286844057996, 'TP': 697, 'FP': 73, 'TN': 2527, 'FN': 603} 

2023-01-03 01:18: **********Val Epoch 13: average Loss: 0.165580
2023-01-03 01:19: 
 Testing metrics {'precision': 0.8574423480083857, 'recall': 0.6661237785016286, 'f1-score': 0.7497708524289642, 'support': 1228, 'AUC': 0.9173197460981017, 'AUCPR': 0.872776795765277, 'TP': 818, 'FP': 136, 'TN': 2320, 'FN': 410} 

2023-01-03 01:22: 
 Testing metrics {'precision': 0.9057187017001546, 'recall': 0.7978216473791695, 'f1-score': 0.8483532392327181, 'support': 4407, 'AUC': 0.9689325556238814, 'AUCPR': 0.9293686726701968, 'TP': 3516, 'FP': 366, 'TN': 8448, 'FN': 891} 

2023-01-03 01:22: Train Epoch 14: 3/634 Loss: 0.144457
2023-01-03 01:22: Train Epoch 14: 7/634 Loss: 0.132302
2023-01-03 01:22: Train Epoch 14: 11/634 Loss: 0.147007
2023-01-03 01:22: Train Epoch 14: 15/634 Loss: 0.136542
2023-01-03 01:23: Train Epoch 14: 19/634 Loss: 0.165347
2023-01-03 01:23: Train Epoch 14: 23/634 Loss: 0.161837
2023-01-03 01:23: Train Epoch 14: 27/634 Loss: 0.166514
2023-01-03 01:23: Train Epoch 14: 31/634 Loss: 0.155876
2023-01-03 01:23: Train Epoch 14: 35/634 Loss: 0.131839
2023-01-03 01:23: Train Epoch 14: 39/634 Loss: 0.161383
2023-01-03 01:24: Train Epoch 14: 43/634 Loss: 0.126743
2023-01-03 01:24: Train Epoch 14: 47/634 Loss: 0.143899
2023-01-03 01:24: Train Epoch 14: 51/634 Loss: 0.125822
2023-01-03 01:24: Train Epoch 14: 55/634 Loss: 0.162444
2023-01-03 01:24: Train Epoch 14: 59/634 Loss: 0.174625
2023-01-03 01:25: Train Epoch 14: 63/634 Loss: 0.130134
2023-01-03 01:25: Train Epoch 14: 67/634 Loss: 0.133147
2023-01-03 01:25: Train Epoch 14: 71/634 Loss: 0.135352
2023-01-03 01:25: Train Epoch 14: 75/634 Loss: 0.127969
2023-01-03 01:25: Train Epoch 14: 79/634 Loss: 0.131364
2023-01-03 01:25: Train Epoch 14: 83/634 Loss: 0.129336
2023-01-03 01:26: Train Epoch 14: 87/634 Loss: 0.167394
2023-01-03 01:26: Train Epoch 14: 91/634 Loss: 0.141902
2023-01-03 01:26: Train Epoch 14: 95/634 Loss: 0.152267
2023-01-03 01:26: Train Epoch 14: 99/634 Loss: 0.149658
2023-01-03 01:26: Train Epoch 14: 103/634 Loss: 0.140226
2023-01-03 01:27: Train Epoch 14: 107/634 Loss: 0.142872
2023-01-03 01:27: Train Epoch 14: 111/634 Loss: 0.151030
2023-01-03 01:27: Train Epoch 14: 115/634 Loss: 0.152178
2023-01-03 01:27: Train Epoch 14: 119/634 Loss: 0.150092
2023-01-03 01:27: Train Epoch 14: 123/634 Loss: 0.137405
2023-01-03 01:27: Train Epoch 14: 127/634 Loss: 0.144606
2023-01-03 01:28: Train Epoch 14: 131/634 Loss: 0.149796
2023-01-03 01:28: Train Epoch 14: 135/634 Loss: 0.142024
2023-01-03 01:28: Train Epoch 14: 139/634 Loss: 0.160553
2023-01-03 01:28: Train Epoch 14: 143/634 Loss: 0.152130
2023-01-03 01:28: Train Epoch 14: 147/634 Loss: 0.143341
2023-01-03 01:28: Train Epoch 14: 151/634 Loss: 0.160561
2023-01-03 01:29: Train Epoch 14: 155/634 Loss: 0.142612
2023-01-03 01:29: Train Epoch 14: 159/634 Loss: 0.119660
2023-01-03 01:29: Train Epoch 14: 163/634 Loss: 0.136937
2023-01-03 01:29: Train Epoch 14: 167/634 Loss: 0.163350
2023-01-03 01:29: Train Epoch 14: 171/634 Loss: 0.151194
2023-01-03 01:30: Train Epoch 14: 175/634 Loss: 0.137378
2023-01-03 01:30: Train Epoch 14: 179/634 Loss: 0.154697
2023-01-03 01:30: Train Epoch 14: 183/634 Loss: 0.143276
2023-01-03 01:30: Train Epoch 14: 187/634 Loss: 0.150559
2023-01-03 01:30: Train Epoch 14: 191/634 Loss: 0.174936
2023-01-03 01:31: Train Epoch 14: 195/634 Loss: 0.124637
2023-01-03 01:31: Train Epoch 14: 199/634 Loss: 0.149141
2023-01-03 01:31: Train Epoch 14: 203/634 Loss: 0.136923
2023-01-03 01:31: Train Epoch 14: 207/634 Loss: 0.157032
2023-01-03 01:31: Train Epoch 14: 211/634 Loss: 0.154050
2023-01-03 01:31: Train Epoch 14: 215/634 Loss: 0.142468
2023-01-03 01:32: Train Epoch 14: 219/634 Loss: 0.121537
2023-01-03 01:32: Train Epoch 14: 223/634 Loss: 0.159780
2023-01-03 01:32: Train Epoch 14: 227/634 Loss: 0.167214
2023-01-03 01:32: Train Epoch 14: 231/634 Loss: 0.160270
2023-01-03 01:32: Train Epoch 14: 235/634 Loss: 0.153967
2023-01-03 01:33: Train Epoch 14: 239/634 Loss: 0.155710
2023-01-03 01:33: Train Epoch 14: 243/634 Loss: 0.142999
2023-01-03 01:33: Train Epoch 14: 247/634 Loss: 0.146506
2023-01-03 01:33: Train Epoch 14: 251/634 Loss: 0.138792
2023-01-03 01:33: Train Epoch 14: 255/634 Loss: 0.149673
2023-01-03 01:33: Train Epoch 14: 259/634 Loss: 0.141003
2023-01-03 01:34: Train Epoch 14: 263/634 Loss: 0.162251
2023-01-03 01:34: Train Epoch 14: 267/634 Loss: 0.158415
2023-01-03 01:34: Train Epoch 14: 271/634 Loss: 0.156758
2023-01-03 01:34: Train Epoch 14: 275/634 Loss: 0.142318
2023-01-03 01:34: Train Epoch 14: 279/634 Loss: 0.139424
2023-01-03 01:35: Train Epoch 14: 283/634 Loss: 0.147072
2023-01-03 01:35: Train Epoch 14: 287/634 Loss: 0.155693
2023-01-03 01:35: Train Epoch 14: 291/634 Loss: 0.156919
2023-01-03 01:35: Train Epoch 14: 295/634 Loss: 0.151382
2023-01-03 01:35: Train Epoch 14: 299/634 Loss: 0.133828
2023-01-03 01:35: Train Epoch 14: 303/634 Loss: 0.170050
2023-01-03 01:36: Train Epoch 14: 307/634 Loss: 0.125464
2023-01-03 01:36: Train Epoch 14: 311/634 Loss: 0.136744
2023-01-03 01:36: Train Epoch 14: 315/634 Loss: 0.130638
2023-01-03 01:36: Train Epoch 14: 319/634 Loss: 0.152668
2023-01-03 01:36: Train Epoch 14: 323/634 Loss: 0.140555
2023-01-03 01:37: Train Epoch 14: 327/634 Loss: 0.145098
2023-01-03 01:37: Train Epoch 14: 331/634 Loss: 0.126863
2023-01-03 01:37: Train Epoch 14: 335/634 Loss: 0.141867
2023-01-03 01:37: Train Epoch 14: 339/634 Loss: 0.176295
2023-01-03 01:37: Train Epoch 14: 343/634 Loss: 0.144947
2023-01-03 01:37: Train Epoch 14: 347/634 Loss: 0.144732
2023-01-03 01:38: Train Epoch 14: 351/634 Loss: 0.148590
2023-01-03 01:38: Train Epoch 14: 355/634 Loss: 0.123131
2023-01-03 01:38: Train Epoch 14: 359/634 Loss: 0.137293
2023-01-03 01:38: Train Epoch 14: 363/634 Loss: 0.132588
2023-01-03 01:38: Train Epoch 14: 367/634 Loss: 0.162160
2023-01-03 01:38: Train Epoch 14: 371/634 Loss: 0.131748
2023-01-03 01:39: Train Epoch 14: 375/634 Loss: 0.159467
2023-01-03 01:39: Train Epoch 14: 379/634 Loss: 0.168250
2023-01-03 01:39: Train Epoch 14: 383/634 Loss: 0.142487
2023-01-03 01:39: Train Epoch 14: 387/634 Loss: 0.159104
2023-01-03 01:39: Train Epoch 14: 391/634 Loss: 0.153329
2023-01-03 01:40: Train Epoch 14: 395/634 Loss: 0.210256
2023-01-03 01:40: Train Epoch 14: 399/634 Loss: 0.134835
2023-01-03 01:40: Train Epoch 14: 403/634 Loss: 0.165329
2023-01-03 01:40: Train Epoch 14: 407/634 Loss: 0.149385
2023-01-03 01:40: Train Epoch 14: 411/634 Loss: 0.152125
2023-01-03 01:41: Train Epoch 14: 415/634 Loss: 0.133919
2023-01-03 01:41: Train Epoch 14: 419/634 Loss: 0.161047
2023-01-03 01:41: Train Epoch 14: 423/634 Loss: 0.136447
2023-01-03 01:41: Train Epoch 14: 427/634 Loss: 0.154401
2023-01-03 01:41: Train Epoch 14: 431/634 Loss: 0.134936
2023-01-03 01:42: Train Epoch 14: 435/634 Loss: 0.142696
2023-01-03 01:42: Train Epoch 14: 439/634 Loss: 0.131660
2023-01-03 01:42: Train Epoch 14: 443/634 Loss: 0.145438
2023-01-03 01:42: Train Epoch 14: 447/634 Loss: 0.109901
2023-01-03 01:42: Train Epoch 14: 451/634 Loss: 0.135250
2023-01-03 01:43: Train Epoch 14: 455/634 Loss: 0.132039
2023-01-03 01:43: Train Epoch 14: 459/634 Loss: 0.127242
2023-01-03 01:43: Train Epoch 14: 463/634 Loss: 0.124121
2023-01-03 01:43: Train Epoch 14: 467/634 Loss: 0.144940
2023-01-03 01:43: Train Epoch 14: 471/634 Loss: 0.154708
2023-01-03 01:43: Train Epoch 14: 475/634 Loss: 0.140561
2023-01-03 01:44: Train Epoch 14: 479/634 Loss: 0.121840
2023-01-03 01:44: Train Epoch 14: 483/634 Loss: 0.149753
2023-01-03 01:44: Train Epoch 14: 487/634 Loss: 0.160624
2023-01-03 01:44: Train Epoch 14: 491/634 Loss: 0.165760
2023-01-03 01:44: Train Epoch 14: 495/634 Loss: 0.138661
2023-01-03 01:45: Train Epoch 14: 499/634 Loss: 0.158556
2023-01-03 01:45: Train Epoch 14: 503/634 Loss: 0.169511
2023-01-03 01:45: Train Epoch 14: 507/634 Loss: 0.149988
2023-01-03 01:45: Train Epoch 14: 511/634 Loss: 0.142272
2023-01-03 01:45: Train Epoch 14: 515/634 Loss: 0.147961
2023-01-03 01:45: Train Epoch 14: 519/634 Loss: 0.158342
2023-01-03 01:46: Train Epoch 14: 523/634 Loss: 0.155891
2023-01-03 01:46: Train Epoch 14: 527/634 Loss: 0.133038
2023-01-03 01:46: Train Epoch 14: 531/634 Loss: 0.164568
2023-01-03 01:46: Train Epoch 14: 535/634 Loss: 0.140388
2023-01-03 01:46: Train Epoch 14: 539/634 Loss: 0.166059
2023-01-03 01:47: Train Epoch 14: 543/634 Loss: 0.133341
2023-01-03 01:47: Train Epoch 14: 547/634 Loss: 0.137311
2023-01-03 01:47: Train Epoch 14: 551/634 Loss: 0.147926
2023-01-03 01:47: Train Epoch 14: 555/634 Loss: 0.140108
2023-01-03 01:47: Train Epoch 14: 559/634 Loss: 0.128006
2023-01-03 01:48: Train Epoch 14: 563/634 Loss: 0.162932
2023-01-03 01:48: Train Epoch 14: 567/634 Loss: 0.157018
2023-01-03 01:48: Train Epoch 14: 571/634 Loss: 0.165872
2023-01-03 01:48: Train Epoch 14: 575/634 Loss: 0.152931
2023-01-03 01:48: Train Epoch 14: 579/634 Loss: 0.117521
2023-01-03 01:49: Train Epoch 14: 583/634 Loss: 0.157711
2023-01-03 01:49: Train Epoch 14: 587/634 Loss: 0.127514
2023-01-03 01:49: Train Epoch 14: 591/634 Loss: 0.159438
2023-01-03 01:49: Train Epoch 14: 595/634 Loss: 0.134749
2023-01-03 01:49: Train Epoch 14: 599/634 Loss: 0.151843
2023-01-03 01:50: Train Epoch 14: 603/634 Loss: 0.151479
2023-01-03 01:50: Train Epoch 14: 607/634 Loss: 0.148170
2023-01-03 01:50: Train Epoch 14: 611/634 Loss: 0.165165
2023-01-03 01:50: Train Epoch 14: 615/634 Loss: 0.153144
2023-01-03 01:51: Train Epoch 14: 619/634 Loss: 0.125922
2023-01-03 01:51: Train Epoch 14: 623/634 Loss: 0.144426
2023-01-03 01:51: Train Epoch 14: 627/634 Loss: 0.120544
2023-01-03 01:51: Train Epoch 14: 631/634 Loss: 0.142221
2023-01-03 01:51: Train Epoch 14: 633/634 Loss: 0.055993
2023-01-03 01:51: **********Train Epoch 14: averaged Loss: 0.146051 
2023-01-03 01:51: 
Epoch time elapsed: 1771.976196050644

2023-01-03 01:52: 
 metrics validation: {'precision': 0.8852242744063324, 'recall': 0.5161538461538462, 'f1-score': 0.652089407191448, 'support': 1300, 'AUC': 0.9379532544378699, 'AUCPR': 0.8785167255070866, 'TP': 671, 'FP': 87, 'TN': 2513, 'FN': 629} 

2023-01-03 01:52: **********Val Epoch 14: average Loss: 0.170748
2023-01-03 01:53: 
 Testing metrics {'precision': 0.8574423480083857, 'recall': 0.6661237785016286, 'f1-score': 0.7497708524289642, 'support': 1228, 'AUC': 0.9173197460981017, 'AUCPR': 0.872776795765277, 'TP': 818, 'FP': 136, 'TN': 2320, 'FN': 410} 

2023-01-03 01:56: 
 Testing metrics {'precision': 0.9057187017001546, 'recall': 0.7978216473791695, 'f1-score': 0.8483532392327181, 'support': 4407, 'AUC': 0.9689325556238814, 'AUCPR': 0.9293686726701968, 'TP': 3516, 'FP': 366, 'TN': 8448, 'FN': 891} 

2023-01-03 01:56: Train Epoch 15: 3/634 Loss: 0.159928
2023-01-03 01:56: Train Epoch 15: 7/634 Loss: 0.145984
2023-01-03 01:56: Train Epoch 15: 11/634 Loss: 0.149189
2023-01-03 01:56: Train Epoch 15: 15/634 Loss: 0.153541
2023-01-03 01:57: Train Epoch 15: 19/634 Loss: 0.133963
2023-01-03 01:57: Train Epoch 15: 23/634 Loss: 0.132015
2023-01-03 01:57: Train Epoch 15: 27/634 Loss: 0.159594
2023-01-03 01:57: Train Epoch 15: 31/634 Loss: 0.159869
2023-01-03 01:57: Train Epoch 15: 35/634 Loss: 0.148434
2023-01-03 01:58: Train Epoch 15: 39/634 Loss: 0.131720
2023-01-03 01:58: Train Epoch 15: 43/634 Loss: 0.146909
2023-01-03 01:58: Train Epoch 15: 47/634 Loss: 0.153145
2023-01-03 01:58: Train Epoch 15: 51/634 Loss: 0.150255
2023-01-03 01:58: Train Epoch 15: 55/634 Loss: 0.174226
2023-01-03 01:58: Train Epoch 15: 59/634 Loss: 0.148932
2023-01-03 01:59: Train Epoch 15: 63/634 Loss: 0.136362
2023-01-03 01:59: Train Epoch 15: 67/634 Loss: 0.148588
2023-01-03 01:59: Train Epoch 15: 71/634 Loss: 0.183447
2023-01-03 01:59: Train Epoch 15: 75/634 Loss: 0.137386
2023-01-03 01:59: Train Epoch 15: 79/634 Loss: 0.152171
2023-01-03 01:59: Train Epoch 15: 83/634 Loss: 0.136376
2023-01-03 02:00: Train Epoch 15: 87/634 Loss: 0.149686
2023-01-03 02:00: Train Epoch 15: 91/634 Loss: 0.148566
2023-01-03 02:00: Train Epoch 15: 95/634 Loss: 0.141050
2023-01-03 02:00: Train Epoch 15: 99/634 Loss: 0.144129
2023-01-03 02:00: Train Epoch 15: 103/634 Loss: 0.146217
2023-01-03 02:01: Train Epoch 15: 107/634 Loss: 0.154475
2023-01-03 02:01: Train Epoch 15: 111/634 Loss: 0.134973
2023-01-03 02:01: Train Epoch 15: 115/634 Loss: 0.176696
2023-01-03 02:01: Train Epoch 15: 119/634 Loss: 0.150655
2023-01-03 02:01: Train Epoch 15: 123/634 Loss: 0.144173
2023-01-03 02:01: Train Epoch 15: 127/634 Loss: 0.154556
2023-01-03 02:02: Train Epoch 15: 131/634 Loss: 0.138504
2023-01-03 02:02: Train Epoch 15: 135/634 Loss: 0.164395
2023-01-03 02:02: Train Epoch 15: 139/634 Loss: 0.113616
2023-01-03 02:02: Train Epoch 15: 143/634 Loss: 0.143423
2023-01-03 02:02: Train Epoch 15: 147/634 Loss: 0.142734
2023-01-03 02:03: Train Epoch 15: 151/634 Loss: 0.156247
2023-01-03 02:03: Train Epoch 15: 155/634 Loss: 0.149487
2023-01-03 02:03: Train Epoch 15: 159/634 Loss: 0.146608
2023-01-03 02:03: Train Epoch 15: 163/634 Loss: 0.146288
2023-01-03 02:03: Train Epoch 15: 167/634 Loss: 0.147504
2023-01-03 02:04: Train Epoch 15: 171/634 Loss: 0.143293
2023-01-03 02:04: Train Epoch 15: 175/634 Loss: 0.154534
2023-01-03 02:04: Train Epoch 15: 179/634 Loss: 0.170650
2023-01-03 02:04: Train Epoch 15: 183/634 Loss: 0.141304
2023-01-03 02:04: Train Epoch 15: 187/634 Loss: 0.125059
2023-01-03 02:05: Train Epoch 15: 191/634 Loss: 0.168852
2023-01-03 02:05: Train Epoch 15: 195/634 Loss: 0.159187
2023-01-03 02:05: Train Epoch 15: 199/634 Loss: 0.118951
2023-01-03 02:05: Train Epoch 15: 203/634 Loss: 0.150951
2023-01-03 02:05: Train Epoch 15: 207/634 Loss: 0.153693
2023-01-03 02:05: Train Epoch 15: 211/634 Loss: 0.144239
2023-01-03 02:06: Train Epoch 15: 215/634 Loss: 0.120793
2023-01-03 02:06: Train Epoch 15: 219/634 Loss: 0.148257
2023-01-03 02:06: Train Epoch 15: 223/634 Loss: 0.131373
2023-01-03 02:06: Train Epoch 15: 227/634 Loss: 0.150452
2023-01-03 02:06: Train Epoch 15: 231/634 Loss: 0.140514
2023-01-03 02:06: Train Epoch 15: 235/634 Loss: 0.138708
2023-01-03 02:07: Train Epoch 15: 239/634 Loss: 0.132737
2023-01-03 02:07: Train Epoch 15: 243/634 Loss: 0.144024
2023-01-03 02:07: Train Epoch 15: 247/634 Loss: 0.161184
2023-01-03 02:07: Train Epoch 15: 251/634 Loss: 0.130757
2023-01-03 02:07: Train Epoch 15: 255/634 Loss: 0.155788
2023-01-03 02:07: Train Epoch 15: 259/634 Loss: 0.155924
2023-01-03 02:08: Train Epoch 15: 263/634 Loss: 0.146596
2023-01-03 02:08: Train Epoch 15: 267/634 Loss: 0.149474
2023-01-03 02:08: Train Epoch 15: 271/634 Loss: 0.149115
2023-01-03 02:08: Train Epoch 15: 275/634 Loss: 0.140661
2023-01-03 02:08: Train Epoch 15: 279/634 Loss: 0.176667
2023-01-03 02:08: Train Epoch 15: 283/634 Loss: 0.138431
2023-01-03 02:09: Train Epoch 15: 287/634 Loss: 0.133385
2023-01-03 02:09: Train Epoch 15: 291/634 Loss: 0.137954
2023-01-03 02:09: Train Epoch 15: 295/634 Loss: 0.170964
2023-01-03 02:09: Train Epoch 15: 299/634 Loss: 0.145849
2023-01-03 02:09: Train Epoch 15: 303/634 Loss: 0.147913
2023-01-03 02:10: Train Epoch 15: 307/634 Loss: 0.151760
2023-01-03 02:10: Train Epoch 15: 311/634 Loss: 0.166094
2023-01-03 02:10: Train Epoch 15: 315/634 Loss: 0.136405
2023-01-03 02:10: Train Epoch 15: 319/634 Loss: 0.157599
2023-01-03 02:10: Train Epoch 15: 323/634 Loss: 0.151838
2023-01-03 02:11: Train Epoch 15: 327/634 Loss: 0.156743
2023-01-03 02:11: Train Epoch 15: 331/634 Loss: 0.147659
2023-01-03 02:11: Train Epoch 15: 335/634 Loss: 0.129532
2023-01-03 02:11: Train Epoch 15: 339/634 Loss: 0.127648
2023-01-03 02:11: Train Epoch 15: 343/634 Loss: 0.149281
2023-01-03 02:11: Train Epoch 15: 347/634 Loss: 0.127391
2023-01-03 02:12: Train Epoch 15: 351/634 Loss: 0.129153
2023-01-03 02:12: Train Epoch 15: 355/634 Loss: 0.128233
2023-01-03 02:12: Train Epoch 15: 359/634 Loss: 0.147537
2023-01-03 02:12: Train Epoch 15: 363/634 Loss: 0.133970
2023-01-03 02:12: Train Epoch 15: 367/634 Loss: 0.173457
2023-01-03 02:13: Train Epoch 15: 371/634 Loss: 0.125244
2023-01-03 02:13: Train Epoch 15: 375/634 Loss: 0.161591
2023-01-03 02:13: Train Epoch 15: 379/634 Loss: 0.171704
2023-01-03 02:13: Train Epoch 15: 383/634 Loss: 0.149129
2023-01-03 02:13: Train Epoch 15: 387/634 Loss: 0.165406
2023-01-03 02:14: Train Epoch 15: 391/634 Loss: 0.162346
2023-01-03 02:14: Train Epoch 15: 395/634 Loss: 0.153543
2023-01-03 02:14: Train Epoch 15: 399/634 Loss: 0.125941
2023-01-03 02:14: Train Epoch 15: 403/634 Loss: 0.119479
2023-01-03 02:14: Train Epoch 15: 407/634 Loss: 0.157422
2023-01-03 02:14: Train Epoch 15: 411/634 Loss: 0.129644
2023-01-03 02:15: Train Epoch 15: 415/634 Loss: 0.159500
2023-01-03 02:15: Train Epoch 15: 419/634 Loss: 0.159126
2023-01-03 02:15: Train Epoch 15: 423/634 Loss: 0.145555
2023-01-03 02:15: Train Epoch 15: 427/634 Loss: 0.157152
2023-01-03 02:15: Train Epoch 15: 431/634 Loss: 0.132987
2023-01-03 02:16: Train Epoch 15: 435/634 Loss: 0.140444
2023-01-03 02:16: Train Epoch 15: 439/634 Loss: 0.137652
2023-01-03 02:16: Train Epoch 15: 443/634 Loss: 0.170477
2023-01-03 02:16: Train Epoch 15: 447/634 Loss: 0.150550
2023-01-03 02:16: Train Epoch 15: 451/634 Loss: 0.138260
2023-01-03 02:17: Train Epoch 15: 455/634 Loss: 0.141073
2023-01-03 02:17: Train Epoch 15: 459/634 Loss: 0.148685
2023-01-03 02:17: Train Epoch 15: 463/634 Loss: 0.161669
2023-01-03 02:17: Train Epoch 15: 467/634 Loss: 0.130074
2023-01-03 02:17: Train Epoch 15: 471/634 Loss: 0.141499
2023-01-03 02:17: Train Epoch 15: 475/634 Loss: 0.173191
2023-01-03 02:18: Train Epoch 15: 479/634 Loss: 0.144486
2023-01-03 02:18: Train Epoch 15: 483/634 Loss: 0.145354
2023-01-03 02:18: Train Epoch 15: 487/634 Loss: 0.156992
2023-01-03 02:18: Train Epoch 15: 491/634 Loss: 0.153911
2023-01-03 02:18: Train Epoch 15: 495/634 Loss: 0.147119
2023-01-03 02:18: Train Epoch 15: 499/634 Loss: 0.131555
2023-01-03 02:19: Train Epoch 15: 503/634 Loss: 0.170411
2023-01-03 02:19: Train Epoch 15: 507/634 Loss: 0.139190
2023-01-03 02:19: Train Epoch 15: 511/634 Loss: 0.170603
2023-01-03 02:19: Train Epoch 15: 515/634 Loss: 0.140214
2023-01-03 02:20: Train Epoch 15: 519/634 Loss: 0.168917
2023-01-03 02:20: Train Epoch 15: 523/634 Loss: 0.133513
2023-01-03 02:20: Train Epoch 15: 527/634 Loss: 0.128308
2023-01-03 02:20: Train Epoch 15: 531/634 Loss: 0.142905
2023-01-03 02:20: Train Epoch 15: 535/634 Loss: 0.151554
2023-01-03 02:21: Train Epoch 15: 539/634 Loss: 0.156003
2023-01-03 02:21: Train Epoch 15: 543/634 Loss: 0.138093
2023-01-03 02:21: Train Epoch 15: 547/634 Loss: 0.153545
2023-01-03 02:21: Train Epoch 15: 551/634 Loss: 0.145374
2023-01-03 02:21: Train Epoch 15: 555/634 Loss: 0.135804
2023-01-03 02:22: Train Epoch 15: 559/634 Loss: 0.143074
2023-01-03 02:22: Train Epoch 15: 563/634 Loss: 0.150480
2023-01-03 02:22: Train Epoch 15: 567/634 Loss: 0.150129
2023-01-03 02:22: Train Epoch 15: 571/634 Loss: 0.153413
2023-01-03 02:22: Train Epoch 15: 575/634 Loss: 0.127794
2023-01-03 02:22: Train Epoch 15: 579/634 Loss: 0.150310
2023-01-03 02:23: Train Epoch 15: 583/634 Loss: 0.136904
2023-01-03 02:23: Train Epoch 15: 587/634 Loss: 0.144475
2023-01-03 02:23: Train Epoch 15: 591/634 Loss: 0.137358
2023-01-03 02:23: Train Epoch 15: 595/634 Loss: 0.144534
2023-01-03 02:23: Train Epoch 15: 599/634 Loss: 0.171699
2023-01-03 02:24: Train Epoch 15: 603/634 Loss: 0.128501
2023-01-03 02:24: Train Epoch 15: 607/634 Loss: 0.144091
2023-01-03 02:24: Train Epoch 15: 611/634 Loss: 0.151880
2023-01-03 02:24: Train Epoch 15: 615/634 Loss: 0.128848
2023-01-03 02:24: Train Epoch 15: 619/634 Loss: 0.144353
2023-01-03 02:24: Train Epoch 15: 623/634 Loss: 0.138417
2023-01-03 02:25: Train Epoch 15: 627/634 Loss: 0.138595
2023-01-03 02:25: Train Epoch 15: 631/634 Loss: 0.160512
2023-01-03 02:25: Train Epoch 15: 633/634 Loss: 0.076902
2023-01-03 02:25: **********Train Epoch 15: averaged Loss: 0.146629 
2023-01-03 02:25: 
Epoch time elapsed: 1744.2570655345917

2023-01-03 02:26: 
 metrics validation: {'precision': 0.7951219512195122, 'recall': 0.7523076923076923, 'f1-score': 0.7731225296442688, 'support': 1300, 'AUC': 0.9247011834319527, 'AUCPR': 0.8599791896489372, 'TP': 978, 'FP': 252, 'TN': 2348, 'FN': 322} 

2023-01-03 02:26: **********Val Epoch 15: average Loss: 0.159094
2023-01-03 02:26: 
 Testing metrics {'precision': 0.8574423480083857, 'recall': 0.6661237785016286, 'f1-score': 0.7497708524289642, 'support': 1228, 'AUC': 0.9173197460981017, 'AUCPR': 0.872776795765277, 'TP': 818, 'FP': 136, 'TN': 2320, 'FN': 410} 

2023-01-03 02:29: 
 Testing metrics {'precision': 0.9057187017001546, 'recall': 0.7978216473791695, 'f1-score': 0.8483532392327181, 'support': 4407, 'AUC': 0.9689325556238814, 'AUCPR': 0.9293686726701968, 'TP': 3516, 'FP': 366, 'TN': 8448, 'FN': 891} 

2023-01-03 02:29: Train Epoch 16: 3/634 Loss: 0.151977
2023-01-03 02:30: Train Epoch 16: 7/634 Loss: 0.142856
2023-01-03 02:30: Train Epoch 16: 11/634 Loss: 0.146189
2023-01-03 02:30: Train Epoch 16: 15/634 Loss: 0.141340
2023-01-03 02:30: Train Epoch 16: 19/634 Loss: 0.172814
2023-01-03 02:31: Train Epoch 16: 23/634 Loss: 0.131042
2023-01-03 02:31: Train Epoch 16: 27/634 Loss: 0.150111
2023-01-03 02:31: Train Epoch 16: 31/634 Loss: 0.138681
2023-01-03 02:31: Train Epoch 16: 35/634 Loss: 0.153606
2023-01-03 02:31: Train Epoch 16: 39/634 Loss: 0.128110
2023-01-03 02:31: Train Epoch 16: 43/634 Loss: 0.126800
2023-01-03 02:32: Train Epoch 16: 47/634 Loss: 0.127397
2023-01-03 02:32: Train Epoch 16: 51/634 Loss: 0.126122
2023-01-03 02:32: Train Epoch 16: 55/634 Loss: 0.139055
2023-01-03 02:32: Train Epoch 16: 59/634 Loss: 0.177697
2023-01-03 02:32: Train Epoch 16: 63/634 Loss: 0.149540
2023-01-03 02:32: Train Epoch 16: 67/634 Loss: 0.140472
2023-01-03 02:33: Train Epoch 16: 71/634 Loss: 0.140162
2023-01-03 02:33: Train Epoch 16: 75/634 Loss: 0.138439
2023-01-03 02:33: Train Epoch 16: 79/634 Loss: 0.162673
2023-01-03 02:33: Train Epoch 16: 83/634 Loss: 0.137358
2023-01-03 02:33: Train Epoch 16: 87/634 Loss: 0.130938
2023-01-03 02:34: Train Epoch 16: 91/634 Loss: 0.137713
2023-01-03 02:34: Train Epoch 16: 95/634 Loss: 0.147609
2023-01-03 02:34: Train Epoch 16: 99/634 Loss: 0.144554
2023-01-03 02:34: Train Epoch 16: 103/634 Loss: 0.120000
2023-01-03 02:34: Train Epoch 16: 107/634 Loss: 0.130766
2023-01-03 02:34: Train Epoch 16: 111/634 Loss: 0.167537
2023-01-03 02:35: Train Epoch 16: 115/634 Loss: 0.127913
2023-01-03 02:35: Train Epoch 16: 119/634 Loss: 0.158564
2023-01-03 02:35: Train Epoch 16: 123/634 Loss: 0.134745
2023-01-03 02:35: Train Epoch 16: 127/634 Loss: 0.140981
2023-01-03 02:35: Train Epoch 16: 131/634 Loss: 0.123978
2023-01-03 02:36: Train Epoch 16: 135/634 Loss: 0.143648
2023-01-03 02:36: Train Epoch 16: 139/634 Loss: 0.118089
2023-01-03 02:36: Train Epoch 16: 143/634 Loss: 0.154151
2023-01-03 02:36: Train Epoch 16: 147/634 Loss: 0.153555
2023-01-03 02:36: Train Epoch 16: 151/634 Loss: 0.144984
2023-01-03 02:36: Train Epoch 16: 155/634 Loss: 0.161124
2023-01-03 02:37: Train Epoch 16: 159/634 Loss: 0.152066
2023-01-03 02:37: Train Epoch 16: 163/634 Loss: 0.146174
2023-01-03 02:37: Train Epoch 16: 167/634 Loss: 0.121693
2023-01-03 02:37: Train Epoch 16: 171/634 Loss: 0.130281
2023-01-03 02:38: Train Epoch 16: 175/634 Loss: 0.147676
2023-01-03 02:38: Train Epoch 16: 179/634 Loss: 0.139171
2023-01-03 02:38: Train Epoch 16: 183/634 Loss: 0.136474
2023-01-03 02:38: Train Epoch 16: 187/634 Loss: 0.125795
2023-01-03 02:39: Train Epoch 16: 191/634 Loss: 0.137612
2023-01-03 02:39: Train Epoch 16: 195/634 Loss: 0.141983
2023-01-03 02:39: Train Epoch 16: 199/634 Loss: 0.140426
2023-01-03 02:39: Train Epoch 16: 203/634 Loss: 0.131253
2023-01-03 02:39: Train Epoch 16: 207/634 Loss: 0.143177
2023-01-03 02:40: Train Epoch 16: 211/634 Loss: 0.137030
2023-01-03 02:40: Train Epoch 16: 215/634 Loss: 0.118844
2023-01-03 02:40: Train Epoch 16: 219/634 Loss: 0.164799
2023-01-03 02:40: Train Epoch 16: 223/634 Loss: 0.140546
2023-01-03 02:40: Train Epoch 16: 227/634 Loss: 0.131418
2023-01-03 02:41: Train Epoch 16: 231/634 Loss: 0.142396
2023-01-03 02:41: Train Epoch 16: 235/634 Loss: 0.131470
2023-01-03 02:41: Train Epoch 16: 239/634 Loss: 0.124952
2023-01-03 02:41: Train Epoch 16: 243/634 Loss: 0.136598
2023-01-03 02:41: Train Epoch 16: 247/634 Loss: 0.144484
2023-01-03 02:42: Train Epoch 16: 251/634 Loss: 0.165691
2023-01-03 02:42: Train Epoch 16: 255/634 Loss: 0.115907
2023-01-03 02:42: Train Epoch 16: 259/634 Loss: 0.129231
2023-01-03 02:42: Train Epoch 16: 263/634 Loss: 0.146248
2023-01-03 02:43: Train Epoch 16: 267/634 Loss: 0.156128
2023-01-03 02:43: Train Epoch 16: 271/634 Loss: 0.141723
2023-01-03 02:43: Train Epoch 16: 275/634 Loss: 0.139004
2023-01-03 02:43: Train Epoch 16: 279/634 Loss: 0.140157
2023-01-03 02:43: Train Epoch 16: 283/634 Loss: 0.125034
2023-01-03 02:44: Train Epoch 16: 287/634 Loss: 0.140301
2023-01-03 02:44: Train Epoch 16: 291/634 Loss: 0.137357
2023-01-03 02:44: Train Epoch 16: 295/634 Loss: 0.130337
2023-01-03 02:44: Train Epoch 16: 299/634 Loss: 0.156071
2023-01-03 02:44: Train Epoch 16: 303/634 Loss: 0.144313
2023-01-03 02:44: Train Epoch 16: 307/634 Loss: 0.127262
2023-01-03 02:45: Train Epoch 16: 311/634 Loss: 0.136735
2023-01-03 02:45: Train Epoch 16: 315/634 Loss: 0.151411
2023-01-03 02:45: Train Epoch 16: 319/634 Loss: 0.129417
2023-01-03 02:45: Train Epoch 16: 323/634 Loss: 0.136151
2023-01-03 02:45: Train Epoch 16: 327/634 Loss: 0.137630
2023-01-03 02:46: Train Epoch 16: 331/634 Loss: 0.153217
2023-01-03 02:46: Train Epoch 16: 335/634 Loss: 0.144996
2023-01-03 02:46: Train Epoch 16: 339/634 Loss: 0.148568
2023-01-03 02:46: Train Epoch 16: 343/634 Loss: 0.139972
2023-01-03 02:46: Train Epoch 16: 347/634 Loss: 0.125996
2023-01-03 02:46: Train Epoch 16: 351/634 Loss: 0.115425
2023-01-03 02:47: Train Epoch 16: 355/634 Loss: 0.158097
2023-01-03 02:47: Train Epoch 16: 359/634 Loss: 0.119612
2023-01-03 02:47: Train Epoch 16: 363/634 Loss: 0.147217
2023-01-03 02:47: Train Epoch 16: 367/634 Loss: 0.154117
2023-01-03 02:47: Train Epoch 16: 371/634 Loss: 0.135126
2023-01-03 02:47: Train Epoch 16: 375/634 Loss: 0.136394
2023-01-03 02:48: Train Epoch 16: 379/634 Loss: 0.136260
2023-01-03 02:48: Train Epoch 16: 383/634 Loss: 0.130428
2023-01-03 02:48: Train Epoch 16: 387/634 Loss: 0.136394
2023-01-03 02:48: Train Epoch 16: 391/634 Loss: 0.149903
2023-01-03 02:48: Train Epoch 16: 395/634 Loss: 0.132747
2023-01-03 02:49: Train Epoch 16: 399/634 Loss: 0.148831
2023-01-03 02:49: Train Epoch 16: 403/634 Loss: 0.135615
2023-01-03 02:49: Train Epoch 16: 407/634 Loss: 0.151408
2023-01-03 02:49: Train Epoch 16: 411/634 Loss: 0.147391
2023-01-03 02:49: Train Epoch 16: 415/634 Loss: 0.143693
2023-01-03 02:49: Train Epoch 16: 419/634 Loss: 0.145652
2023-01-03 02:50: Train Epoch 16: 423/634 Loss: 0.134946
2023-01-03 02:50: Train Epoch 16: 427/634 Loss: 0.114673
2023-01-03 02:50: Train Epoch 16: 431/634 Loss: 0.130268
2023-01-03 02:50: Train Epoch 16: 435/634 Loss: 0.155640
2023-01-03 02:50: Train Epoch 16: 439/634 Loss: 0.137735
2023-01-03 02:51: Train Epoch 16: 443/634 Loss: 0.146327
2023-01-03 02:51: Train Epoch 16: 447/634 Loss: 0.145518
2023-01-03 02:51: Train Epoch 16: 451/634 Loss: 0.154619
2023-01-03 02:51: Train Epoch 16: 455/634 Loss: 0.145737
2023-01-03 02:51: Train Epoch 16: 459/634 Loss: 0.124839
2023-01-03 02:52: Train Epoch 16: 463/634 Loss: 0.147272
2023-01-03 02:52: Train Epoch 16: 467/634 Loss: 0.138392
2023-01-03 02:52: Train Epoch 16: 471/634 Loss: 0.142968
2023-01-03 02:52: Train Epoch 16: 475/634 Loss: 0.164375
2023-01-03 02:52: Train Epoch 16: 479/634 Loss: 0.127091
2023-01-03 02:52: Train Epoch 16: 483/634 Loss: 0.139481
2023-01-03 02:53: Train Epoch 16: 487/634 Loss: 0.126580
2023-01-03 02:53: Train Epoch 16: 491/634 Loss: 0.119134
2023-01-03 02:53: Train Epoch 16: 495/634 Loss: 0.151281
2023-01-03 02:53: Train Epoch 16: 499/634 Loss: 0.132909
2023-01-03 02:53: Train Epoch 16: 503/634 Loss: 0.135137
2023-01-03 02:54: Train Epoch 16: 507/634 Loss: 0.145436
2023-01-03 02:54: Train Epoch 16: 511/634 Loss: 0.129311
2023-01-03 02:54: Train Epoch 16: 515/634 Loss: 0.132377
2023-01-03 02:54: Train Epoch 16: 519/634 Loss: 0.129549
2023-01-03 02:54: Train Epoch 16: 523/634 Loss: 0.143549
2023-01-03 02:55: Train Epoch 16: 527/634 Loss: 0.135636
2023-01-03 02:55: Train Epoch 16: 531/634 Loss: 0.112658
2023-01-03 02:55: Train Epoch 16: 535/634 Loss: 0.126811
2023-01-03 02:55: Train Epoch 16: 539/634 Loss: 0.141921
2023-01-03 02:55: Train Epoch 16: 543/634 Loss: 0.127618
2023-01-03 02:56: Train Epoch 16: 547/634 Loss: 0.126414
2023-01-03 02:56: Train Epoch 16: 551/634 Loss: 0.116359
2023-01-03 02:56: Train Epoch 16: 555/634 Loss: 0.125436
2023-01-03 02:56: Train Epoch 16: 559/634 Loss: 0.134775
2023-01-03 02:56: Train Epoch 16: 563/634 Loss: 0.129015
2023-01-03 02:56: Train Epoch 16: 567/634 Loss: 0.126327
2023-01-03 02:57: Train Epoch 16: 571/634 Loss: 0.148056
2023-01-03 02:57: Train Epoch 16: 575/634 Loss: 0.141408
2023-01-03 02:57: Train Epoch 16: 579/634 Loss: 0.129936
2023-01-03 02:57: Train Epoch 16: 583/634 Loss: 0.144410
2023-01-03 02:57: Train Epoch 16: 587/634 Loss: 0.131962
2023-01-03 02:58: Train Epoch 16: 591/634 Loss: 0.140938
2023-01-03 02:58: Train Epoch 16: 595/634 Loss: 0.155988
2023-01-03 02:58: Train Epoch 16: 599/634 Loss: 0.145215
2023-01-03 02:58: Train Epoch 16: 603/634 Loss: 0.134382
2023-01-03 02:58: Train Epoch 16: 607/634 Loss: 0.121108
2023-01-03 02:58: Train Epoch 16: 611/634 Loss: 0.147865
2023-01-03 02:59: Train Epoch 16: 615/634 Loss: 0.150243
2023-01-03 02:59: Train Epoch 16: 619/634 Loss: 0.132571
2023-01-03 02:59: Train Epoch 16: 623/634 Loss: 0.152375
2023-01-03 02:59: Train Epoch 16: 627/634 Loss: 0.136472
2023-01-03 02:59: Train Epoch 16: 631/634 Loss: 0.145303
2023-01-03 02:59: Train Epoch 16: 633/634 Loss: 0.052276
2023-01-03 02:59: **********Train Epoch 16: averaged Loss: 0.138751 
2023-01-03 02:59: 
Epoch time elapsed: 1802.949051141739

2023-01-03 03:00: 
 metrics validation: {'precision': 0.8373305526590198, 'recall': 0.6176923076923077, 'f1-score': 0.7109340416113324, 'support': 1300, 'AUC': 0.9322721893491123, 'AUCPR': 0.8696775104804517, 'TP': 803, 'FP': 156, 'TN': 2444, 'FN': 497} 

2023-01-03 03:00: **********Val Epoch 16: average Loss: 0.157674
2023-01-03 03:01: 
 Testing metrics {'precision': 0.8574423480083857, 'recall': 0.6661237785016286, 'f1-score': 0.7497708524289642, 'support': 1228, 'AUC': 0.9173197460981017, 'AUCPR': 0.872776795765277, 'TP': 818, 'FP': 136, 'TN': 2320, 'FN': 410} 

2023-01-03 03:04: 
 Testing metrics {'precision': 0.9057187017001546, 'recall': 0.7978216473791695, 'f1-score': 0.8483532392327181, 'support': 4407, 'AUC': 0.9689325556238814, 'AUCPR': 0.9293686726701968, 'TP': 3516, 'FP': 366, 'TN': 8448, 'FN': 891} 

2023-01-03 03:04: Train Epoch 17: 3/634 Loss: 0.164535
2023-01-03 03:04: Train Epoch 17: 7/634 Loss: 0.170024
2023-01-03 03:04: Train Epoch 17: 11/634 Loss: 0.147322
2023-01-03 03:05: Train Epoch 17: 15/634 Loss: 0.139718
2023-01-03 03:05: Train Epoch 17: 19/634 Loss: 0.131227
2023-01-03 03:05: Train Epoch 17: 23/634 Loss: 0.137518
2023-01-03 03:05: Train Epoch 17: 27/634 Loss: 0.132775
2023-01-03 03:05: Train Epoch 17: 31/634 Loss: 0.138211
2023-01-03 03:06: Train Epoch 17: 35/634 Loss: 0.142359
2023-01-03 03:06: Train Epoch 17: 39/634 Loss: 0.139263
2023-01-03 03:06: Train Epoch 17: 43/634 Loss: 0.147037
2023-01-03 03:06: Train Epoch 17: 47/634 Loss: 0.137940
2023-01-03 03:06: Train Epoch 17: 51/634 Loss: 0.153682
2023-01-03 03:06: Train Epoch 17: 55/634 Loss: 0.132170
2023-01-03 03:07: Train Epoch 17: 59/634 Loss: 0.128897
2023-01-03 03:07: Train Epoch 17: 63/634 Loss: 0.149376
2023-01-03 03:07: Train Epoch 17: 67/634 Loss: 0.128770
2023-01-03 03:07: Train Epoch 17: 71/634 Loss: 0.148132
2023-01-03 03:07: Train Epoch 17: 75/634 Loss: 0.146154
2023-01-03 03:08: Train Epoch 17: 79/634 Loss: 0.132701
2023-01-03 03:08: Train Epoch 17: 83/634 Loss: 0.142025
2023-01-03 03:08: Train Epoch 17: 87/634 Loss: 0.125960
2023-01-03 03:08: Train Epoch 17: 91/634 Loss: 0.148728
2023-01-03 03:08: Train Epoch 17: 95/634 Loss: 0.127884
2023-01-03 03:09: Train Epoch 17: 99/634 Loss: 0.131833
2023-01-03 03:09: Train Epoch 17: 103/634 Loss: 0.159222
2023-01-03 03:09: Train Epoch 17: 107/634 Loss: 0.157654
2023-01-03 03:09: Train Epoch 17: 111/634 Loss: 0.170045
2023-01-03 03:09: Train Epoch 17: 115/634 Loss: 0.136263
2023-01-03 03:09: Train Epoch 17: 119/634 Loss: 0.119332
2023-01-03 03:10: Train Epoch 17: 123/634 Loss: 0.123958
2023-01-03 03:10: Train Epoch 17: 127/634 Loss: 0.133797
2023-01-03 03:10: Train Epoch 17: 131/634 Loss: 0.127704
2023-01-03 03:10: Train Epoch 17: 135/634 Loss: 0.147834
2023-01-03 03:10: Train Epoch 17: 139/634 Loss: 0.137571
2023-01-03 03:11: Train Epoch 17: 143/634 Loss: 0.129650
2023-01-03 03:11: Train Epoch 17: 147/634 Loss: 0.122201
2023-01-03 03:11: Train Epoch 17: 151/634 Loss: 0.119045
2023-01-03 03:11: Train Epoch 17: 155/634 Loss: 0.127112
2023-01-03 03:11: Train Epoch 17: 159/634 Loss: 0.118139
2023-01-03 03:12: Train Epoch 17: 163/634 Loss: 0.132472
2023-01-03 03:12: Train Epoch 17: 167/634 Loss: 0.131636
2023-01-03 03:12: Train Epoch 17: 171/634 Loss: 0.134848
2023-01-03 03:12: Train Epoch 17: 175/634 Loss: 0.141385
2023-01-03 03:12: Train Epoch 17: 179/634 Loss: 0.156049
2023-01-03 03:13: Train Epoch 17: 183/634 Loss: 0.117938
2023-01-03 03:13: Train Epoch 17: 187/634 Loss: 0.131862
2023-01-03 03:13: Train Epoch 17: 191/634 Loss: 0.148344
2023-01-03 03:13: Train Epoch 17: 195/634 Loss: 0.156941
2023-01-03 03:13: Train Epoch 17: 199/634 Loss: 0.155504
2023-01-03 03:13: Train Epoch 17: 203/634 Loss: 0.146684
2023-01-03 03:14: Train Epoch 17: 207/634 Loss: 0.137344
2023-01-03 03:14: Train Epoch 17: 211/634 Loss: 0.132067
2023-01-03 03:14: Train Epoch 17: 215/634 Loss: 0.137640
2023-01-03 03:14: Train Epoch 17: 219/634 Loss: 0.154527
2023-01-03 03:14: Train Epoch 17: 223/634 Loss: 0.125118
2023-01-03 03:14: Train Epoch 17: 227/634 Loss: 0.132976
2023-01-03 03:15: Train Epoch 17: 231/634 Loss: 0.120581
2023-01-03 03:15: Train Epoch 17: 235/634 Loss: 0.127379
2023-01-03 03:15: Train Epoch 17: 239/634 Loss: 0.140264
2023-01-03 03:15: Train Epoch 17: 243/634 Loss: 0.141103
2023-01-03 03:15: Train Epoch 17: 247/634 Loss: 0.135378
2023-01-03 03:16: Train Epoch 17: 251/634 Loss: 0.140879
2023-01-03 03:16: Train Epoch 17: 255/634 Loss: 0.148019
2023-01-03 03:16: Train Epoch 17: 259/634 Loss: 0.145789
2023-01-03 03:16: Train Epoch 17: 263/634 Loss: 0.136047
2023-01-03 03:16: Train Epoch 17: 267/634 Loss: 0.120880
2023-01-03 03:16: Train Epoch 17: 271/634 Loss: 0.149120
2023-01-03 03:17: Train Epoch 17: 275/634 Loss: 0.137379
2023-01-03 03:17: Train Epoch 17: 279/634 Loss: 0.134820
2023-01-03 03:17: Train Epoch 17: 283/634 Loss: 0.119423
2023-01-03 03:17: Train Epoch 17: 287/634 Loss: 0.147368
2023-01-03 03:17: Train Epoch 17: 291/634 Loss: 0.157139
2023-01-03 03:18: Train Epoch 17: 295/634 Loss: 0.131538
2023-01-03 03:18: Train Epoch 17: 299/634 Loss: 0.128249
2023-01-03 03:18: Train Epoch 17: 303/634 Loss: 0.141703
2023-01-03 03:18: Train Epoch 17: 307/634 Loss: 0.133445
2023-01-03 03:18: Train Epoch 17: 311/634 Loss: 0.135797
2023-01-03 03:18: Train Epoch 17: 315/634 Loss: 0.132397
2023-01-03 03:19: Train Epoch 17: 319/634 Loss: 0.143356
2023-01-03 03:19: Train Epoch 17: 323/634 Loss: 0.129474
2023-01-03 03:19: Train Epoch 17: 327/634 Loss: 0.123886
2023-01-03 03:19: Train Epoch 17: 331/634 Loss: 0.133086
2023-01-03 03:19: Train Epoch 17: 335/634 Loss: 0.138498
2023-01-03 03:19: Train Epoch 17: 339/634 Loss: 0.136983
2023-01-03 03:20: Train Epoch 17: 343/634 Loss: 0.115100
2023-01-03 03:20: Train Epoch 17: 347/634 Loss: 0.158559
2023-01-03 03:20: Train Epoch 17: 351/634 Loss: 0.124959
2023-01-03 03:20: Train Epoch 17: 355/634 Loss: 0.133187
2023-01-03 03:21: Train Epoch 17: 359/634 Loss: 0.137134
2023-01-03 03:21: Train Epoch 17: 363/634 Loss: 0.136829
2023-01-03 03:21: Train Epoch 17: 367/634 Loss: 0.154288
2023-01-03 03:21: Train Epoch 17: 371/634 Loss: 0.144537
2023-01-03 03:21: Train Epoch 17: 375/634 Loss: 0.139290
2023-01-03 03:22: Train Epoch 17: 379/634 Loss: 0.122275
2023-01-03 03:22: Train Epoch 17: 383/634 Loss: 0.128531
2023-01-03 03:22: Train Epoch 17: 387/634 Loss: 0.129864
2023-01-03 03:22: Train Epoch 17: 391/634 Loss: 0.124361
2023-01-03 03:22: Train Epoch 17: 395/634 Loss: 0.153148
2023-01-03 03:23: Train Epoch 17: 399/634 Loss: 0.149552
2023-01-03 03:23: Train Epoch 17: 403/634 Loss: 0.155451
2023-01-03 03:23: Train Epoch 17: 407/634 Loss: 0.132122
2023-01-03 03:23: Train Epoch 17: 411/634 Loss: 0.125072
2023-01-03 03:24: Train Epoch 17: 415/634 Loss: 0.109415
2023-01-03 03:24: Train Epoch 17: 419/634 Loss: 0.157336
2023-01-03 03:24: Train Epoch 17: 423/634 Loss: 0.138050
2023-01-03 03:24: Train Epoch 17: 427/634 Loss: 0.127530
2023-01-03 03:24: Train Epoch 17: 431/634 Loss: 0.142742
2023-01-03 03:24: Train Epoch 17: 435/634 Loss: 0.120229
2023-01-03 03:25: Train Epoch 17: 439/634 Loss: 0.147157
2023-01-03 03:25: Train Epoch 17: 443/634 Loss: 0.145919
2023-01-03 03:25: Train Epoch 17: 447/634 Loss: 0.150905
2023-01-03 03:25: Train Epoch 17: 451/634 Loss: 0.128715
2023-01-03 03:25: Train Epoch 17: 455/634 Loss: 0.135792
2023-01-03 03:25: Train Epoch 17: 459/634 Loss: 0.119557
2023-01-03 03:26: Train Epoch 17: 463/634 Loss: 0.116746
2023-01-03 03:26: Train Epoch 17: 467/634 Loss: 0.136955
2023-01-03 03:26: Train Epoch 17: 471/634 Loss: 0.115912
2023-01-03 03:26: Train Epoch 17: 475/634 Loss: 0.137572
2023-01-03 03:26: Train Epoch 17: 479/634 Loss: 0.137201
2023-01-03 03:27: Train Epoch 17: 483/634 Loss: 0.139709
2023-01-03 03:27: Train Epoch 17: 487/634 Loss: 0.141445
2023-01-03 03:27: Train Epoch 17: 491/634 Loss: 0.136274
2023-01-03 03:27: Train Epoch 17: 495/634 Loss: 0.152843
2023-01-03 03:28: Train Epoch 17: 499/634 Loss: 0.123121
2023-01-03 03:28: Train Epoch 17: 503/634 Loss: 0.127438
2023-01-03 03:28: Train Epoch 17: 507/634 Loss: 0.141673
2023-01-03 03:28: Train Epoch 17: 511/634 Loss: 0.146078
2023-01-03 03:28: Train Epoch 17: 515/634 Loss: 0.146612
2023-01-03 03:29: Train Epoch 17: 519/634 Loss: 0.142571
2023-01-03 03:29: Train Epoch 17: 523/634 Loss: 0.113754
2023-01-03 03:29: Train Epoch 17: 527/634 Loss: 0.131487
2023-01-03 03:29: Train Epoch 17: 531/634 Loss: 0.130544
2023-01-03 03:30: Train Epoch 17: 535/634 Loss: 0.166996
2023-01-03 03:30: Train Epoch 17: 539/634 Loss: 0.143452
2023-01-03 03:30: Train Epoch 17: 543/634 Loss: 0.151393
2023-01-03 03:30: Train Epoch 17: 547/634 Loss: 0.161450
2023-01-03 03:30: Train Epoch 17: 551/634 Loss: 0.148371
2023-01-03 03:31: Train Epoch 17: 555/634 Loss: 0.137538
2023-01-03 03:31: Train Epoch 17: 559/634 Loss: 0.154490
2023-01-03 03:31: Train Epoch 17: 563/634 Loss: 0.152214
2023-01-03 03:31: Train Epoch 17: 567/634 Loss: 0.122354
2023-01-03 03:32: Train Epoch 17: 571/634 Loss: 0.147602
2023-01-03 03:32: Train Epoch 17: 575/634 Loss: 0.168464
2023-01-03 03:32: Train Epoch 17: 579/634 Loss: 0.147606
2023-01-03 03:32: Train Epoch 17: 583/634 Loss: 0.135122
2023-01-03 03:32: Train Epoch 17: 587/634 Loss: 0.139523
2023-01-03 03:32: Train Epoch 17: 591/634 Loss: 0.119947
2023-01-03 03:33: Train Epoch 17: 595/634 Loss: 0.114785
2023-01-03 03:33: Train Epoch 17: 599/634 Loss: 0.131249
2023-01-03 03:33: Train Epoch 17: 603/634 Loss: 0.140171
2023-01-03 03:33: Train Epoch 17: 607/634 Loss: 0.134735
2023-01-03 03:33: Train Epoch 17: 611/634 Loss: 0.144252
2023-01-03 03:33: Train Epoch 17: 615/634 Loss: 0.120621
2023-01-03 03:34: Train Epoch 17: 619/634 Loss: 0.115095
2023-01-03 03:34: Train Epoch 17: 623/634 Loss: 0.135212
2023-01-03 03:34: Train Epoch 17: 627/634 Loss: 0.116244
2023-01-03 03:34: Train Epoch 17: 631/634 Loss: 0.129219
2023-01-03 03:34: Train Epoch 17: 633/634 Loss: 0.054159
2023-01-03 03:34: **********Train Epoch 17: averaged Loss: 0.136949 
2023-01-03 03:34: 
Epoch time elapsed: 1815.088466644287

2023-01-03 03:35: 
 metrics validation: {'precision': 0.8504784688995215, 'recall': 0.546923076923077, 'f1-score': 0.6657303370786517, 'support': 1300, 'AUC': 0.9313573964497042, 'AUCPR': 0.8681445860243371, 'TP': 711, 'FP': 125, 'TN': 2475, 'FN': 589} 

2023-01-03 03:35: **********Val Epoch 17: average Loss: 0.168612
2023-01-03 03:36: 
 Testing metrics {'precision': 0.8574423480083857, 'recall': 0.6661237785016286, 'f1-score': 0.7497708524289642, 'support': 1228, 'AUC': 0.9173197460981017, 'AUCPR': 0.872776795765277, 'TP': 818, 'FP': 136, 'TN': 2320, 'FN': 410} 

2023-01-03 03:39: 
 Testing metrics {'precision': 0.9057187017001546, 'recall': 0.7978216473791695, 'f1-score': 0.8483532392327181, 'support': 4407, 'AUC': 0.9689325556238814, 'AUCPR': 0.9293686726701968, 'TP': 3516, 'FP': 366, 'TN': 8448, 'FN': 891} 

2023-01-03 03:39: Train Epoch 18: 3/634 Loss: 0.166968
2023-01-03 03:39: Train Epoch 18: 7/634 Loss: 0.125184
2023-01-03 03:39: Train Epoch 18: 11/634 Loss: 0.146552
2023-01-03 03:40: Train Epoch 18: 15/634 Loss: 0.144321
2023-01-03 03:40: Train Epoch 18: 19/634 Loss: 0.140195
2023-01-03 03:40: Train Epoch 18: 23/634 Loss: 0.137126
2023-01-03 03:40: Train Epoch 18: 27/634 Loss: 0.132158
2023-01-03 03:41: Train Epoch 18: 31/634 Loss: 0.144155
2023-01-03 03:41: Train Epoch 18: 35/634 Loss: 0.154811
2023-01-03 03:41: Train Epoch 18: 39/634 Loss: 0.159982
2023-01-03 03:41: Train Epoch 18: 43/634 Loss: 0.168430
2023-01-03 03:42: Train Epoch 18: 47/634 Loss: 0.151258
2023-01-03 03:42: Train Epoch 18: 51/634 Loss: 0.142652
2023-01-03 03:42: Train Epoch 18: 55/634 Loss: 0.158865
2023-01-03 03:42: Train Epoch 18: 59/634 Loss: 0.134073
2023-01-03 03:42: Train Epoch 18: 63/634 Loss: 0.144161
2023-01-03 03:42: Train Epoch 18: 67/634 Loss: 0.138614
2023-01-03 03:43: Train Epoch 18: 71/634 Loss: 0.144599
2023-01-03 03:43: Train Epoch 18: 75/634 Loss: 0.131934
2023-01-03 03:43: Train Epoch 18: 79/634 Loss: 0.142104
2023-01-03 03:43: Train Epoch 18: 83/634 Loss: 0.132216
2023-01-03 03:43: Train Epoch 18: 87/634 Loss: 0.124404
2023-01-03 03:44: Train Epoch 18: 91/634 Loss: 0.131446
2023-01-03 03:44: Train Epoch 18: 95/634 Loss: 0.124585
2023-01-03 03:44: Train Epoch 18: 99/634 Loss: 0.143632
2023-01-03 03:44: Train Epoch 18: 103/634 Loss: 0.149142
2023-01-03 03:44: Train Epoch 18: 107/634 Loss: 0.152191
2023-01-03 03:45: Train Epoch 18: 111/634 Loss: 0.176582
2023-01-03 03:45: Train Epoch 18: 115/634 Loss: 0.149483
2023-01-03 03:45: Train Epoch 18: 119/634 Loss: 0.128715
2023-01-03 03:45: Train Epoch 18: 123/634 Loss: 0.135864
2023-01-03 03:45: Train Epoch 18: 127/634 Loss: 0.123690
2023-01-03 03:45: Train Epoch 18: 131/634 Loss: 0.143370
2023-01-03 03:46: Train Epoch 18: 135/634 Loss: 0.138940
2023-01-03 03:46: Train Epoch 18: 139/634 Loss: 0.151323
2023-01-03 03:46: Train Epoch 18: 143/634 Loss: 0.153195
2023-01-03 03:46: Train Epoch 18: 147/634 Loss: 0.128275
2023-01-03 03:46: Train Epoch 18: 151/634 Loss: 0.135227
2023-01-03 03:47: Train Epoch 18: 155/634 Loss: 0.143317
2023-01-03 03:47: Train Epoch 18: 159/634 Loss: 0.142007
2023-01-03 03:47: Train Epoch 18: 163/634 Loss: 0.131659
2023-01-03 03:47: Train Epoch 18: 167/634 Loss: 0.149864
2023-01-03 03:47: Train Epoch 18: 171/634 Loss: 0.133653
2023-01-03 03:47: Train Epoch 18: 175/634 Loss: 0.127876
2023-01-03 03:48: Train Epoch 18: 179/634 Loss: 0.143365
2023-01-03 03:48: Train Epoch 18: 183/634 Loss: 0.134331
2023-01-03 03:48: Train Epoch 18: 187/634 Loss: 0.137525
2023-01-03 03:48: Train Epoch 18: 191/634 Loss: 0.123281
2023-01-03 03:48: Train Epoch 18: 195/634 Loss: 0.148018
2023-01-03 03:49: Train Epoch 18: 199/634 Loss: 0.159754
2023-01-03 03:49: Train Epoch 18: 203/634 Loss: 0.142384
2023-01-03 03:49: Train Epoch 18: 207/634 Loss: 0.121996
2023-01-03 03:49: Train Epoch 18: 211/634 Loss: 0.134846
2023-01-03 03:49: Train Epoch 18: 215/634 Loss: 0.134087
2023-01-03 03:50: Train Epoch 18: 219/634 Loss: 0.150545
2023-01-03 03:50: Train Epoch 18: 223/634 Loss: 0.140463
2023-01-03 03:50: Train Epoch 18: 227/634 Loss: 0.141801
2023-01-03 03:50: Train Epoch 18: 231/634 Loss: 0.141645
2023-01-03 03:50: Train Epoch 18: 235/634 Loss: 0.128674
2023-01-03 03:51: Train Epoch 18: 239/634 Loss: 0.125170
2023-01-03 03:51: Train Epoch 18: 243/634 Loss: 0.121727
2023-01-03 03:51: Train Epoch 18: 247/634 Loss: 0.151493
2023-01-03 03:51: Train Epoch 18: 251/634 Loss: 0.136169
2023-01-03 03:51: Train Epoch 18: 255/634 Loss: 0.146705
2023-01-03 03:51: Train Epoch 18: 259/634 Loss: 0.126248
2023-01-03 03:52: Train Epoch 18: 263/634 Loss: 0.126049
2023-01-03 03:52: Train Epoch 18: 267/634 Loss: 0.135241
2023-01-03 03:52: Train Epoch 18: 271/634 Loss: 0.128736
2023-01-03 03:52: Train Epoch 18: 275/634 Loss: 0.137713
2023-01-03 03:52: Train Epoch 18: 279/634 Loss: 0.132025
2023-01-03 03:53: Train Epoch 18: 283/634 Loss: 0.146873
2023-01-03 03:53: Train Epoch 18: 287/634 Loss: 0.142914
2023-01-03 03:53: Train Epoch 18: 291/634 Loss: 0.149574
2023-01-03 03:53: Train Epoch 18: 295/634 Loss: 0.138558
2023-01-03 03:53: Train Epoch 18: 299/634 Loss: 0.140755
2023-01-03 03:54: Train Epoch 18: 303/634 Loss: 0.137105
2023-01-03 03:54: Train Epoch 18: 307/634 Loss: 0.157484
2023-01-03 03:54: Train Epoch 18: 311/634 Loss: 0.123861
2023-01-03 03:54: Train Epoch 18: 315/634 Loss: 0.150691
2023-01-03 03:54: Train Epoch 18: 319/634 Loss: 0.133217
2023-01-03 03:54: Train Epoch 18: 323/634 Loss: 0.136387
2023-01-03 03:55: Train Epoch 18: 327/634 Loss: 0.141641
2023-01-03 03:55: Train Epoch 18: 331/634 Loss: 0.141989
2023-01-03 03:55: Train Epoch 18: 335/634 Loss: 0.128080
2023-01-03 03:55: Train Epoch 18: 339/634 Loss: 0.134379
2023-01-03 03:55: Train Epoch 18: 343/634 Loss: 0.126103
2023-01-03 03:56: Train Epoch 18: 347/634 Loss: 0.135193
2023-01-03 03:56: Train Epoch 18: 351/634 Loss: 0.145695
2023-01-03 03:56: Train Epoch 18: 355/634 Loss: 0.129559
2023-01-03 03:56: Train Epoch 18: 359/634 Loss: 0.139259
2023-01-03 03:56: Train Epoch 18: 363/634 Loss: 0.134760
2023-01-03 03:57: Train Epoch 18: 367/634 Loss: 0.133301
2023-01-03 03:57: Train Epoch 18: 371/634 Loss: 0.131147
2023-01-03 03:57: Train Epoch 18: 375/634 Loss: 0.135905
2023-01-03 03:57: Train Epoch 18: 379/634 Loss: 0.141457
2023-01-03 03:57: Train Epoch 18: 383/634 Loss: 0.144016
2023-01-03 03:57: Train Epoch 18: 387/634 Loss: 0.141232
2023-01-03 03:58: Train Epoch 18: 391/634 Loss: 0.158292
2023-01-03 03:58: Train Epoch 18: 395/634 Loss: 0.124292
2023-01-03 03:58: Train Epoch 18: 399/634 Loss: 0.137498
2023-01-03 03:58: Train Epoch 18: 403/634 Loss: 0.125677
2023-01-03 03:58: Train Epoch 18: 407/634 Loss: 0.139693
2023-01-03 03:59: Train Epoch 18: 411/634 Loss: 0.132799
2023-01-03 03:59: Train Epoch 18: 415/634 Loss: 0.156219
2023-01-03 03:59: Train Epoch 18: 419/634 Loss: 0.132716
2023-01-03 03:59: Train Epoch 18: 423/634 Loss: 0.144806
2023-01-03 03:59: Train Epoch 18: 427/634 Loss: 0.117040
2023-01-03 04:00: Train Epoch 18: 431/634 Loss: 0.151199
2023-01-03 04:00: Train Epoch 18: 435/634 Loss: 0.152683
2023-01-03 04:00: Train Epoch 18: 439/634 Loss: 0.132439
2023-01-03 04:00: Train Epoch 18: 443/634 Loss: 0.140139
2023-01-03 04:00: Train Epoch 18: 447/634 Loss: 0.116540
2023-01-03 04:01: Train Epoch 18: 451/634 Loss: 0.130010
2023-01-03 04:01: Train Epoch 18: 455/634 Loss: 0.144706
2023-01-03 04:01: Train Epoch 18: 459/634 Loss: 0.142381
2023-01-03 04:01: Train Epoch 18: 463/634 Loss: 0.123739
2023-01-03 04:01: Train Epoch 18: 467/634 Loss: 0.130740
2023-01-03 04:02: Train Epoch 18: 471/634 Loss: 0.107312
2023-01-03 04:02: Train Epoch 18: 475/634 Loss: 0.121563
2023-01-03 04:02: Train Epoch 18: 479/634 Loss: 0.147711
2023-01-03 04:02: Train Epoch 18: 483/634 Loss: 0.142601
2023-01-03 04:02: Train Epoch 18: 487/634 Loss: 0.145945
2023-01-03 04:02: Train Epoch 18: 491/634 Loss: 0.145087
2023-01-03 04:03: Train Epoch 18: 495/634 Loss: 0.155846
2023-01-03 04:03: Train Epoch 18: 499/634 Loss: 0.129063
2023-01-03 04:03: Train Epoch 18: 503/634 Loss: 0.134457
2023-01-03 04:03: Train Epoch 18: 507/634 Loss: 0.124228
2023-01-03 04:03: Train Epoch 18: 511/634 Loss: 0.160453
2023-01-03 04:03: Train Epoch 18: 515/634 Loss: 0.151599
2023-01-03 04:04: Train Epoch 18: 519/634 Loss: 0.143440
2023-01-03 04:04: Train Epoch 18: 523/634 Loss: 0.139793
2023-01-03 04:04: Train Epoch 18: 527/634 Loss: 0.133910
2023-01-03 04:04: Train Epoch 18: 531/634 Loss: 0.121952
2023-01-03 04:04: Train Epoch 18: 535/634 Loss: 0.150932
2023-01-03 04:04: Train Epoch 18: 539/634 Loss: 0.137309
2023-01-03 04:05: Train Epoch 18: 543/634 Loss: 0.143828
2023-01-03 04:05: Train Epoch 18: 547/634 Loss: 0.122428
2023-01-03 04:05: Train Epoch 18: 551/634 Loss: 0.145366
2023-01-03 04:05: Train Epoch 18: 555/634 Loss: 0.146439
2023-01-03 04:05: Train Epoch 18: 559/634 Loss: 0.135386
2023-01-03 04:06: Train Epoch 18: 563/634 Loss: 0.133168
2023-01-03 04:06: Train Epoch 18: 567/634 Loss: 0.140372
2023-01-03 04:06: Train Epoch 18: 571/634 Loss: 0.116660
2023-01-03 04:06: Train Epoch 18: 575/634 Loss: 0.158020
2023-01-03 04:06: Train Epoch 18: 579/634 Loss: 0.142517
2023-01-03 04:07: Train Epoch 18: 583/634 Loss: 0.128752
2023-01-03 04:07: Train Epoch 18: 587/634 Loss: 0.141878
2023-01-03 04:07: Train Epoch 18: 591/634 Loss: 0.138576
2023-01-03 04:07: Train Epoch 18: 595/634 Loss: 0.130268
2023-01-03 04:07: Train Epoch 18: 599/634 Loss: 0.126898
2023-01-03 04:07: Train Epoch 18: 603/634 Loss: 0.129922
2023-01-03 04:08: Train Epoch 18: 607/634 Loss: 0.138595
2023-01-03 04:08: Train Epoch 18: 611/634 Loss: 0.140169
2023-01-03 04:08: Train Epoch 18: 615/634 Loss: 0.136881
2023-01-03 04:08: Train Epoch 18: 619/634 Loss: 0.132401
2023-01-03 04:08: Train Epoch 18: 623/634 Loss: 0.127256
2023-01-03 04:08: Train Epoch 18: 627/634 Loss: 0.152133
2023-01-03 04:09: Train Epoch 18: 631/634 Loss: 0.141715
2023-01-03 04:09: Train Epoch 18: 633/634 Loss: 0.061068
2023-01-03 04:09: **********Train Epoch 18: averaged Loss: 0.138286 
2023-01-03 04:09: 
Epoch time elapsed: 1782.8265368938446

2023-01-03 04:10: 
 metrics validation: {'precision': 0.8439181916038752, 'recall': 0.6030769230769231, 'f1-score': 0.7034544638851503, 'support': 1300, 'AUC': 0.9335180473372781, 'AUCPR': 0.8709196892987396, 'TP': 784, 'FP': 145, 'TN': 2455, 'FN': 516} 

2023-01-03 04:10: **********Val Epoch 18: average Loss: 0.157976
2023-01-03 04:10: 
 Testing metrics {'precision': 0.8574423480083857, 'recall': 0.6661237785016286, 'f1-score': 0.7497708524289642, 'support': 1228, 'AUC': 0.9173197460981017, 'AUCPR': 0.872776795765277, 'TP': 818, 'FP': 136, 'TN': 2320, 'FN': 410} 

2023-01-03 04:14: 
 Testing metrics {'precision': 0.9057187017001546, 'recall': 0.7978216473791695, 'f1-score': 0.8483532392327181, 'support': 4407, 'AUC': 0.9689325556238814, 'AUCPR': 0.9293686726701968, 'TP': 3516, 'FP': 366, 'TN': 8448, 'FN': 891} 

2023-01-03 04:14: Train Epoch 19: 3/634 Loss: 0.139161
2023-01-03 04:14: Train Epoch 19: 7/634 Loss: 0.156674
2023-01-03 04:14: Train Epoch 19: 11/634 Loss: 0.128171
2023-01-03 04:14: Train Epoch 19: 15/634 Loss: 0.152843
2023-01-03 04:15: Train Epoch 19: 19/634 Loss: 0.138057
2023-01-03 04:15: Train Epoch 19: 23/634 Loss: 0.153258
2023-01-03 04:15: Train Epoch 19: 27/634 Loss: 0.155437
2023-01-03 04:15: Train Epoch 19: 31/634 Loss: 0.138720
2023-01-03 04:15: Train Epoch 19: 35/634 Loss: 0.150849
2023-01-03 04:16: Train Epoch 19: 39/634 Loss: 0.173462
2023-01-03 04:16: Train Epoch 19: 43/634 Loss: 0.150167
2023-01-03 04:16: Train Epoch 19: 47/634 Loss: 0.135043
2023-01-03 04:16: Train Epoch 19: 51/634 Loss: 0.150333
2023-01-03 04:16: Train Epoch 19: 55/634 Loss: 0.136650
2023-01-03 04:17: Train Epoch 19: 59/634 Loss: 0.138982
2023-01-03 04:17: Train Epoch 19: 63/634 Loss: 0.141349
2023-01-03 04:17: Train Epoch 19: 67/634 Loss: 0.146342
2023-01-03 04:17: Train Epoch 19: 71/634 Loss: 0.136493
2023-01-03 04:17: Train Epoch 19: 75/634 Loss: 0.139242
2023-01-03 04:18: Train Epoch 19: 79/634 Loss: 0.135543
2023-01-03 04:18: Train Epoch 19: 83/634 Loss: 0.120757
2023-01-03 04:18: Train Epoch 19: 87/634 Loss: 0.129428
2023-01-03 04:18: Train Epoch 19: 91/634 Loss: 0.157951
2023-01-03 04:19: Train Epoch 19: 95/634 Loss: 0.119227
2023-01-03 04:19: Train Epoch 19: 99/634 Loss: 0.135370
2023-01-03 04:19: Train Epoch 19: 103/634 Loss: 0.146101
2023-01-03 04:19: Train Epoch 19: 107/634 Loss: 0.150478
2023-01-03 04:19: Train Epoch 19: 111/634 Loss: 0.148302
2023-01-03 04:20: Train Epoch 19: 115/634 Loss: 0.168481
2023-01-03 04:20: Train Epoch 19: 119/634 Loss: 0.147483
2023-01-03 04:20: Train Epoch 19: 123/634 Loss: 0.144191
2023-01-03 04:20: Train Epoch 19: 127/634 Loss: 0.147019
2023-01-03 04:21: Train Epoch 19: 131/634 Loss: 0.119295
2023-01-03 04:21: Train Epoch 19: 135/634 Loss: 0.136224
2023-01-03 04:21: Train Epoch 19: 139/634 Loss: 0.118963
2023-01-03 04:21: Train Epoch 19: 143/634 Loss: 0.121814
2023-01-03 04:21: Train Epoch 19: 147/634 Loss: 0.121519
2023-01-03 04:22: Train Epoch 19: 151/634 Loss: 0.128809
2023-01-03 04:22: Train Epoch 19: 155/634 Loss: 0.140972
2023-01-03 04:22: Train Epoch 19: 159/634 Loss: 0.126614
2023-01-03 04:22: Train Epoch 19: 163/634 Loss: 0.150507
2023-01-03 04:22: Train Epoch 19: 167/634 Loss: 0.144916
2023-01-03 04:22: Train Epoch 19: 171/634 Loss: 0.138902
2023-01-03 04:23: Train Epoch 19: 175/634 Loss: 0.143452
2023-01-03 04:23: Train Epoch 19: 179/634 Loss: 0.141538
2023-01-03 04:23: Train Epoch 19: 183/634 Loss: 0.127506
2023-01-03 04:23: Train Epoch 19: 187/634 Loss: 0.129918
2023-01-03 04:23: Train Epoch 19: 191/634 Loss: 0.134035
2023-01-03 04:24: Train Epoch 19: 195/634 Loss: 0.136786
2023-01-03 04:24: Train Epoch 19: 199/634 Loss: 0.152736
2023-01-03 04:24: Train Epoch 19: 203/634 Loss: 0.135512
2023-01-03 04:24: Train Epoch 19: 207/634 Loss: 0.123356
2023-01-03 04:24: Train Epoch 19: 211/634 Loss: 0.162121
2023-01-03 04:24: Train Epoch 19: 215/634 Loss: 0.137274
2023-01-03 04:25: Train Epoch 19: 219/634 Loss: 0.148452
2023-01-03 04:25: Train Epoch 19: 223/634 Loss: 0.175341
2023-01-03 04:25: Train Epoch 19: 227/634 Loss: 0.133983
2023-01-03 04:25: Train Epoch 19: 231/634 Loss: 0.138085
2023-01-03 04:25: Train Epoch 19: 235/634 Loss: 0.128314
2023-01-03 04:26: Train Epoch 19: 239/634 Loss: 0.139361
2023-01-03 04:26: Train Epoch 19: 243/634 Loss: 0.135674
2023-01-03 04:26: Train Epoch 19: 247/634 Loss: 0.107337
2023-01-03 04:26: Train Epoch 19: 251/634 Loss: 0.129906
2023-01-03 04:26: Train Epoch 19: 255/634 Loss: 0.143500
2023-01-03 04:26: Train Epoch 19: 259/634 Loss: 0.148889
2023-01-03 04:27: Train Epoch 19: 263/634 Loss: 0.128079
2023-01-03 04:27: Train Epoch 19: 267/634 Loss: 0.138098
2023-01-03 04:27: Train Epoch 19: 271/634 Loss: 0.136890
2023-01-03 04:27: Train Epoch 19: 275/634 Loss: 0.157317
2023-01-03 04:27: Train Epoch 19: 279/634 Loss: 0.161040
2023-01-03 04:28: Train Epoch 19: 283/634 Loss: 0.127754
2023-01-03 04:28: Train Epoch 19: 287/634 Loss: 0.137973
2023-01-03 04:28: Train Epoch 19: 291/634 Loss: 0.132776
2023-01-03 04:28: Train Epoch 19: 295/634 Loss: 0.149729
2023-01-03 04:28: Train Epoch 19: 299/634 Loss: 0.148899
2023-01-03 04:29: Train Epoch 19: 303/634 Loss: 0.156556
2023-01-03 04:29: Train Epoch 19: 307/634 Loss: 0.136530
2023-01-03 04:29: Train Epoch 19: 311/634 Loss: 0.139877
2023-01-03 04:29: Train Epoch 19: 315/634 Loss: 0.130068
2023-01-03 04:29: Train Epoch 19: 319/634 Loss: 0.153111
2023-01-03 04:29: Train Epoch 19: 323/634 Loss: 0.122794
2023-01-03 04:30: Train Epoch 19: 327/634 Loss: 0.142589
2023-01-03 04:30: Train Epoch 19: 331/634 Loss: 0.116774
2023-01-03 04:30: Train Epoch 19: 335/634 Loss: 0.150074
2023-01-03 04:30: Train Epoch 19: 339/634 Loss: 0.137405
2023-01-03 04:30: Train Epoch 19: 343/634 Loss: 0.133921
2023-01-03 04:31: Train Epoch 19: 347/634 Loss: 0.142319
2023-01-03 04:31: Train Epoch 19: 351/634 Loss: 0.125217
2023-01-03 04:31: Train Epoch 19: 355/634 Loss: 0.156712
2023-01-03 04:31: Train Epoch 19: 359/634 Loss: 0.152338
2023-01-03 04:31: Train Epoch 19: 363/634 Loss: 0.144883
2023-01-03 04:32: Train Epoch 19: 367/634 Loss: 0.139955
2023-01-03 04:32: Train Epoch 19: 371/634 Loss: 0.139811
2023-01-03 04:32: Train Epoch 19: 375/634 Loss: 0.131561
2023-01-03 04:32: Train Epoch 19: 379/634 Loss: 0.131528
2023-01-03 04:32: Train Epoch 19: 383/634 Loss: 0.144205
2023-01-03 04:32: Train Epoch 19: 387/634 Loss: 0.145890
2023-01-03 04:33: Train Epoch 19: 391/634 Loss: 0.123005
2023-01-03 04:33: Train Epoch 19: 395/634 Loss: 0.151614
2023-01-03 04:33: Train Epoch 19: 399/634 Loss: 0.134060
2023-01-03 04:33: Train Epoch 19: 403/634 Loss: 0.128481
2023-01-03 04:33: Train Epoch 19: 407/634 Loss: 0.128923
2023-01-03 04:34: Train Epoch 19: 411/634 Loss: 0.159026
2023-01-03 04:34: Train Epoch 19: 415/634 Loss: 0.137423
2023-01-03 04:34: Train Epoch 19: 419/634 Loss: 0.132546
2023-01-03 04:34: Train Epoch 19: 423/634 Loss: 0.121428
2023-01-03 04:34: Train Epoch 19: 427/634 Loss: 0.134611
2023-01-03 04:34: Train Epoch 19: 431/634 Loss: 0.163793
2023-01-03 04:35: Train Epoch 19: 435/634 Loss: 0.122927
2023-01-03 04:35: Train Epoch 19: 439/634 Loss: 0.133256
2023-01-03 04:35: Train Epoch 19: 443/634 Loss: 0.152459
2023-01-03 04:35: Train Epoch 19: 447/634 Loss: 0.146852
2023-01-03 04:35: Train Epoch 19: 451/634 Loss: 0.125653
2023-01-03 04:36: Train Epoch 19: 455/634 Loss: 0.140992
2023-01-03 04:36: Train Epoch 19: 459/634 Loss: 0.112753
2023-01-03 04:36: Train Epoch 19: 463/634 Loss: 0.149527
2023-01-03 04:36: Train Epoch 19: 467/634 Loss: 0.137417
2023-01-03 04:36: Train Epoch 19: 471/634 Loss: 0.145613
2023-01-03 04:37: Train Epoch 19: 475/634 Loss: 0.123120
2023-01-03 04:37: Train Epoch 19: 479/634 Loss: 0.172590
2023-01-03 04:37: Train Epoch 19: 483/634 Loss: 0.150701
2023-01-03 04:37: Train Epoch 19: 487/634 Loss: 0.163490
2023-01-03 04:37: Train Epoch 19: 491/634 Loss: 0.148065
2023-01-03 04:38: Train Epoch 19: 495/634 Loss: 0.141101
2023-01-03 04:38: Train Epoch 19: 499/634 Loss: 0.152461
2023-01-03 04:38: Train Epoch 19: 503/634 Loss: 0.134917
2023-01-03 04:38: Train Epoch 19: 507/634 Loss: 0.123420
2023-01-03 04:38: Train Epoch 19: 511/634 Loss: 0.118871
2023-01-03 04:38: Train Epoch 19: 515/634 Loss: 0.139228
2023-01-03 04:39: Train Epoch 19: 519/634 Loss: 0.158144
2023-01-03 04:39: Train Epoch 19: 523/634 Loss: 0.149996
2023-01-03 04:39: Train Epoch 19: 527/634 Loss: 0.145790
2023-01-03 04:39: Train Epoch 19: 531/634 Loss: 0.164542
2023-01-03 04:39: Train Epoch 19: 535/634 Loss: 0.140908
2023-01-03 04:39: Train Epoch 19: 539/634 Loss: 0.144111
2023-01-03 04:40: Train Epoch 19: 543/634 Loss: 0.147421
2023-01-03 04:40: Train Epoch 19: 547/634 Loss: 0.129836
2023-01-03 04:40: Train Epoch 19: 551/634 Loss: 0.126965
2023-01-03 04:40: Train Epoch 19: 555/634 Loss: 0.152938
2023-01-03 04:40: Train Epoch 19: 559/634 Loss: 0.125434
2023-01-03 04:41: Train Epoch 19: 563/634 Loss: 0.148847
2023-01-03 04:41: Train Epoch 19: 567/634 Loss: 0.162586
2023-01-03 04:41: Train Epoch 19: 571/634 Loss: 0.151839
2023-01-03 04:41: Train Epoch 19: 575/634 Loss: 0.125456
2023-01-03 04:41: Train Epoch 19: 579/634 Loss: 0.136991
2023-01-03 04:42: Train Epoch 19: 583/634 Loss: 0.144127
2023-01-03 04:42: Train Epoch 19: 587/634 Loss: 0.133150
2023-01-03 04:42: Train Epoch 19: 591/634 Loss: 0.143777
2023-01-03 04:42: Train Epoch 19: 595/634 Loss: 0.135071
2023-01-03 04:42: Train Epoch 19: 599/634 Loss: 0.141866
2023-01-03 04:42: Train Epoch 19: 603/634 Loss: 0.141547
2023-01-03 04:43: Train Epoch 19: 607/634 Loss: 0.148224
2023-01-03 04:43: Train Epoch 19: 611/634 Loss: 0.164424
2023-01-03 04:43: Train Epoch 19: 615/634 Loss: 0.130251
2023-01-03 04:43: Train Epoch 19: 619/634 Loss: 0.130094
2023-01-03 04:43: Train Epoch 19: 623/634 Loss: 0.138132
2023-01-03 04:43: Train Epoch 19: 627/634 Loss: 0.136071
2023-01-03 04:44: Train Epoch 19: 631/634 Loss: 0.146372
2023-01-03 04:44: Train Epoch 19: 633/634 Loss: 0.063848
2023-01-03 04:44: **********Train Epoch 19: averaged Loss: 0.140031 
2023-01-03 04:44: 
Epoch time elapsed: 1803.04044008255

2023-01-03 04:45: 
 metrics validation: {'precision': 0.8640661938534279, 'recall': 0.5623076923076923, 'f1-score': 0.6812674743709226, 'support': 1300, 'AUC': 0.9321931952662723, 'AUCPR': 0.8689067843960123, 'TP': 731, 'FP': 115, 'TN': 2485, 'FN': 569} 

2023-01-03 04:45: **********Val Epoch 19: average Loss: 0.167809
2023-01-03 04:45: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-03 04:45: Total training time: 570.3995min, best loss: 0.152665
2023-01-03 04:45: Saving current best model to /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010219144382175754013/best_model.pth
2023-01-03 04:45: 
 Testing metrics {'precision': 0.8574423480083857, 'recall': 0.6661237785016286, 'f1-score': 0.7497708524289642, 'support': 1228, 'AUC': 0.9173197460981017, 'AUCPR': 0.872776795765277, 'TP': 818, 'FP': 136, 'TN': 2320, 'FN': 410} 

2023-01-03 04:48: 
 Testing metrics {'precision': 0.9057187017001546, 'recall': 0.7978216473791695, 'f1-score': 0.8483532392327181, 'support': 4407, 'AUC': 0.9689325556238814, 'AUCPR': 0.9293686726701968, 'TP': 3516, 'FP': 366, 'TN': 8448, 'FN': 891} 

