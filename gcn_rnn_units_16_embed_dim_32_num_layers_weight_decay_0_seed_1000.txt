/home/joel.chacon/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2022-12-28 00:10: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103480989258820
2022-12-28 00:10: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103480989258820
2022-12-28 00:10: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=32, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103480989258820', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0005, max_grad_norm=5, mode='train', model='fire_GCN', nan_fill=0.5, num_layers=1, num_nodes=625, num_workers=20, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=1000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2022-12-28 00:10: Argument batch_size: 256
2022-12-28 00:10: Argument clc: 'vec'
2022-12-28 00:10: Argument cuda: True
2022-12-28 00:10: Argument dataset: '2020'
2022-12-28 00:10: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2022-12-28 00:10: Argument debug: False
2022-12-28 00:10: Argument default_graph: True
2022-12-28 00:10: Argument device: 'cpu'
2022-12-28 00:10: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2022-12-28 00:10: Argument early_stop: True
2022-12-28 00:10: Argument early_stop_patience: 8
2022-12-28 00:10: Argument embed_dim: 32
2022-12-28 00:10: Argument epochs: 30
2022-12-28 00:10: Argument grad_norm: False
2022-12-28 00:10: Argument horizon: 1
2022-12-28 00:10: Argument input_dim: 25
2022-12-28 00:10: Argument lag: 10
2022-12-28 00:10: Argument link_len: 2
2022-12-28 00:10: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103480989258820'
2022-12-28 00:10: Argument log_step: 1
2022-12-28 00:10: Argument loss_func: 'nllloss'
2022-12-28 00:10: Argument lr_decay: True
2022-12-28 00:10: Argument lr_decay_rate: 0.1
2022-12-28 00:10: Argument lr_decay_step: '15, 20'
2022-12-28 00:10: Argument lr_init: 0.0005
2022-12-28 00:10: Argument max_grad_norm: 5
2022-12-28 00:10: Argument mode: 'train'
2022-12-28 00:10: Argument model: 'fire_GCN'
2022-12-28 00:10: Argument nan_fill: 0.5
2022-12-28 00:10: Argument num_layers: 1
2022-12-28 00:10: Argument num_nodes: 625
2022-12-28 00:10: Argument num_workers: 20
2022-12-28 00:10: Argument output_dim: 2
2022-12-28 00:10: Argument patch_height: 25
2022-12-28 00:10: Argument patch_width: 25
2022-12-28 00:10: Argument persistent_workers: True
2022-12-28 00:10: Argument pin_memory: True
2022-12-28 00:10: Argument plot: False
2022-12-28 00:10: Argument positive_weight: 0.5
2022-12-28 00:10: Argument prefetch_factor: 2
2022-12-28 00:10: Argument real_value: True
2022-12-28 00:10: Argument rnn_units: 16
2022-12-28 00:10: Argument seed: 1000
2022-12-28 00:10: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2022-12-28 00:10: Argument teacher_forcing: False
2022-12-28 00:10: Argument weight_decay: 0.0
2022-12-28 00:10: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 32]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([32, 2, 41, 16]) True
encoder.cell_list.0.gate.weights_window torch.Size([32, 1, 16]) True
encoder.cell_list.0.gate.bias_pool torch.Size([32, 32]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([32, 2, 41, 8]) True
encoder.cell_list.0.update.weights_window torch.Size([32, 1, 8]) True
encoder.cell_list.0.update.bias_pool torch.Size([32, 16]) True
encoder.cell_list.0.update.T torch.Size([10]) True
end_conv.weight torch.Size([2, 1, 625, 16]) True
end_conv.bias torch.Size([2]) True
Total params num: 105352
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2022122800103480989258820/run.log
2022-12-28 00:11: Train Epoch 1: 0/159 Loss: 0.672054
2022-12-28 00:12: Train Epoch 1: 1/159 Loss: 2.407225
2022-12-28 00:13: Train Epoch 1: 2/159 Loss: 0.860022
2022-12-28 00:14: Train Epoch 1: 3/159 Loss: 0.987226
2022-12-28 00:15: Train Epoch 1: 4/159 Loss: 1.589128
2022-12-28 00:16: Train Epoch 1: 5/159 Loss: 1.553402
2022-12-28 00:16: Train Epoch 1: 6/159 Loss: 1.578452
2022-12-28 00:17: Train Epoch 1: 7/159 Loss: 1.012121
2022-12-28 00:18: Train Epoch 1: 8/159 Loss: 0.646319
2022-12-28 00:19: Train Epoch 1: 9/159 Loss: 1.023107
2022-12-28 00:20: Train Epoch 1: 10/159 Loss: 1.223760
2022-12-28 00:21: Train Epoch 1: 11/159 Loss: 1.020160
2022-12-28 00:22: Train Epoch 1: 12/159 Loss: 0.684565
2022-12-28 00:22: Train Epoch 1: 13/159 Loss: 0.662044
2022-12-28 00:23: Train Epoch 1: 14/159 Loss: 0.798636
2022-12-28 00:24: Train Epoch 1: 15/159 Loss: 0.832344
2022-12-28 00:25: Train Epoch 1: 16/159 Loss: 0.884708
2022-12-28 00:26: Train Epoch 1: 17/159 Loss: 1.048532
2022-12-28 00:27: Train Epoch 1: 18/159 Loss: 0.720513
2022-12-28 00:28: Train Epoch 1: 19/159 Loss: 0.634837
2022-12-28 00:28: Train Epoch 1: 20/159 Loss: 0.697473
2022-12-28 00:29: Train Epoch 1: 21/159 Loss: 0.855376
2022-12-28 00:30: Train Epoch 1: 22/159 Loss: 0.817399
2022-12-28 00:31: Train Epoch 1: 23/159 Loss: 0.703872
2022-12-28 00:32: Train Epoch 1: 24/159 Loss: 0.610571
2022-12-28 00:33: Train Epoch 1: 25/159 Loss: 0.664358
2022-12-28 00:34: Train Epoch 1: 26/159 Loss: 0.829459
2022-12-28 00:34: Train Epoch 1: 27/159 Loss: 0.763395
2022-12-28 00:35: Train Epoch 1: 28/159 Loss: 0.676577
2022-12-28 00:36: Train Epoch 1: 29/159 Loss: 0.579999
2022-12-28 00:37: Train Epoch 1: 30/159 Loss: 0.590458
2022-12-28 00:38: Train Epoch 1: 31/159 Loss: 0.629187
2022-12-28 00:39: Train Epoch 1: 32/159 Loss: 0.659361
2022-12-28 00:40: Train Epoch 1: 33/159 Loss: 0.633245
2022-12-28 00:40: Train Epoch 1: 34/159 Loss: 0.601294
2022-12-28 00:41: Train Epoch 1: 35/159 Loss: 0.566960
2022-12-28 00:42: Train Epoch 1: 36/159 Loss: 0.632405
2022-12-28 00:43: Train Epoch 1: 37/159 Loss: 0.641142
2022-12-28 00:44: Train Epoch 1: 38/159 Loss: 0.671660
2022-12-28 00:45: Train Epoch 1: 39/159 Loss: 0.611805
2022-12-28 00:46: Train Epoch 1: 40/159 Loss: 0.587988
2022-12-28 00:46: Train Epoch 1: 41/159 Loss: 0.604880
2022-12-28 00:47: Train Epoch 1: 42/159 Loss: 0.603174
2022-12-28 00:48: Train Epoch 1: 43/159 Loss: 0.579270
2022-12-28 00:49: Train Epoch 1: 44/159 Loss: 0.512436
2022-12-28 00:50: Train Epoch 1: 45/159 Loss: 0.576447
2022-12-28 00:51: Train Epoch 1: 46/159 Loss: 0.653696
2022-12-28 00:52: Train Epoch 1: 47/159 Loss: 0.616566
2022-12-28 00:52: Train Epoch 1: 48/159 Loss: 0.550078
2022-12-28 00:53: Train Epoch 1: 49/159 Loss: 0.535461
2022-12-28 00:54: Train Epoch 1: 50/159 Loss: 0.567139
2022-12-28 00:55: Train Epoch 1: 51/159 Loss: 0.556661
2022-12-28 00:56: Train Epoch 1: 52/159 Loss: 0.525610
2022-12-28 00:57: Train Epoch 1: 53/159 Loss: 0.478957
2022-12-28 00:58: Train Epoch 1: 54/159 Loss: 0.554869
2022-12-28 00:59: Train Epoch 1: 55/159 Loss: 0.549622
2022-12-28 00:59: Train Epoch 1: 56/159 Loss: 0.492141
2022-12-28 01:00: Train Epoch 1: 57/159 Loss: 0.479906
2022-12-28 01:01: Train Epoch 1: 58/159 Loss: 0.496837
2022-12-28 01:02: Train Epoch 1: 59/159 Loss: 0.506935
2022-12-28 01:03: Train Epoch 1: 60/159 Loss: 0.502082
2022-12-28 01:04: Train Epoch 1: 61/159 Loss: 0.464692
2022-12-28 01:04: Train Epoch 1: 62/159 Loss: 0.487507
2022-12-28 01:05: Train Epoch 1: 63/159 Loss: 0.488261
2022-12-28 01:06: Train Epoch 1: 64/159 Loss: 0.472533
2022-12-28 01:07: Train Epoch 1: 65/159 Loss: 0.438639
2022-12-28 01:08: Train Epoch 1: 66/159 Loss: 0.442823
2022-12-28 01:09: Train Epoch 1: 67/159 Loss: 0.434969
2022-12-28 01:10: Train Epoch 1: 68/159 Loss: 0.406450
2022-12-28 01:10: Train Epoch 1: 69/159 Loss: 0.415337
2022-12-28 01:11: Train Epoch 1: 70/159 Loss: 0.430866
2022-12-28 01:12: Train Epoch 1: 71/159 Loss: 0.391388
2022-12-28 01:13: Train Epoch 1: 72/159 Loss: 0.442780
2022-12-28 01:14: Train Epoch 1: 73/159 Loss: 0.444067
2022-12-28 01:15: Train Epoch 1: 74/159 Loss: 0.359782
2022-12-28 01:15: Train Epoch 1: 75/159 Loss: 0.411155
2022-12-28 01:16: Train Epoch 1: 76/159 Loss: 0.401307
2022-12-28 01:17: Train Epoch 1: 77/159 Loss: 0.370589
2022-12-28 01:18: Train Epoch 1: 78/159 Loss: 0.402101
2022-12-28 01:19: Train Epoch 1: 79/159 Loss: 0.360130
2022-12-28 01:20: Train Epoch 1: 80/159 Loss: 0.354148
2022-12-28 01:21: Train Epoch 1: 81/159 Loss: 0.375543
2022-12-28 01:21: Train Epoch 1: 82/159 Loss: 0.318126
2022-12-28 01:22: Train Epoch 1: 83/159 Loss: 0.394904
2022-12-28 01:23: Train Epoch 1: 84/159 Loss: 0.369593
2022-12-28 01:24: Train Epoch 1: 85/159 Loss: 0.361119
2022-12-28 01:25: Train Epoch 1: 86/159 Loss: 0.359822
2022-12-28 01:26: Train Epoch 1: 87/159 Loss: 0.312920
2022-12-28 01:27: Train Epoch 1: 88/159 Loss: 0.347968
2022-12-28 01:27: Train Epoch 1: 89/159 Loss: 0.334517
2022-12-28 01:28: Train Epoch 1: 90/159 Loss: 0.334790
2022-12-28 01:29: Train Epoch 1: 91/159 Loss: 0.317735
2022-12-28 01:30: Train Epoch 1: 92/159 Loss: 0.331538
2022-12-28 01:31: Train Epoch 1: 93/159 Loss: 0.362731
2022-12-28 01:32: Train Epoch 1: 94/159 Loss: 0.286794
2022-12-28 01:33: Train Epoch 1: 95/159 Loss: 0.341936
2022-12-28 01:34: Train Epoch 1: 96/159 Loss: 0.316601
2022-12-28 01:34: Train Epoch 1: 97/159 Loss: 0.310254
2022-12-28 01:35: Train Epoch 1: 98/159 Loss: 0.322938
2022-12-28 01:36: Train Epoch 1: 99/159 Loss: 0.328748
2022-12-28 01:37: Train Epoch 1: 100/159 Loss: 0.299199
2022-12-28 01:38: Train Epoch 1: 101/159 Loss: 0.284591
2022-12-28 01:39: Train Epoch 1: 102/159 Loss: 0.282146
2022-12-28 01:40: Train Epoch 1: 103/159 Loss: 0.348516
2022-12-28 01:40: Train Epoch 1: 104/159 Loss: 0.327623
2022-12-28 01:41: Train Epoch 1: 105/159 Loss: 0.296603
2022-12-28 01:42: Train Epoch 1: 106/159 Loss: 0.280210
2022-12-28 01:43: Train Epoch 1: 107/159 Loss: 0.362434
2022-12-28 01:44: Train Epoch 1: 108/159 Loss: 0.324744
2022-12-28 01:45: Train Epoch 1: 109/159 Loss: 0.324072
2022-12-28 01:46: Train Epoch 1: 110/159 Loss: 0.333965
2022-12-28 01:46: Train Epoch 1: 111/159 Loss: 0.367718
2022-12-28 01:47: Train Epoch 1: 112/159 Loss: 0.352319
2022-12-28 01:48: Train Epoch 1: 113/159 Loss: 0.309231
2022-12-28 01:49: Train Epoch 1: 114/159 Loss: 0.443638
2022-12-28 01:50: Train Epoch 1: 115/159 Loss: 0.333063
2022-12-28 01:51: Train Epoch 1: 116/159 Loss: 0.311724
2022-12-28 01:52: Train Epoch 1: 117/159 Loss: 0.313783
2022-12-28 01:52: Train Epoch 1: 118/159 Loss: 0.306427
2022-12-28 01:53: Train Epoch 1: 119/159 Loss: 0.294004
2022-12-28 01:54: Train Epoch 1: 120/159 Loss: 0.299879
2022-12-28 01:55: Train Epoch 1: 121/159 Loss: 0.395299
2022-12-28 01:56: Train Epoch 1: 122/159 Loss: 0.338714
2022-12-28 01:57: Train Epoch 1: 123/159 Loss: 0.353698
2022-12-28 01:57: Train Epoch 1: 124/159 Loss: 0.311939
2022-12-28 01:58: Train Epoch 1: 125/159 Loss: 0.357798
2022-12-28 01:59: Train Epoch 1: 126/159 Loss: 0.265353
2022-12-28 02:00: Train Epoch 1: 127/159 Loss: 0.279823
2022-12-28 02:01: Train Epoch 1: 128/159 Loss: 0.335644
2022-12-28 02:02: Train Epoch 1: 129/159 Loss: 0.348340
2022-12-28 02:03: Train Epoch 1: 130/159 Loss: 0.314781
2022-12-28 02:03: Train Epoch 1: 131/159 Loss: 0.290680
2022-12-28 02:04: Train Epoch 1: 132/159 Loss: 0.358193
2022-12-28 02:05: Train Epoch 1: 133/159 Loss: 0.269113
2022-12-28 02:06: Train Epoch 1: 134/159 Loss: 0.290565
2022-12-28 02:07: Train Epoch 1: 135/159 Loss: 0.322879
2022-12-28 02:08: Train Epoch 1: 136/159 Loss: 0.284437
2022-12-28 02:08: Train Epoch 1: 137/159 Loss: 0.332597
2022-12-28 02:09: Train Epoch 1: 138/159 Loss: 0.250405
2022-12-28 02:10: Train Epoch 1: 139/159 Loss: 0.334901
2022-12-28 02:11: Train Epoch 1: 140/159 Loss: 0.312771
2022-12-28 02:12: Train Epoch 1: 141/159 Loss: 0.278982
2022-12-28 02:13: Train Epoch 1: 142/159 Loss: 0.305798
2022-12-28 02:13: Train Epoch 1: 143/159 Loss: 0.335589
2022-12-28 02:14: Train Epoch 1: 144/159 Loss: 0.305298
2022-12-28 02:15: Train Epoch 1: 145/159 Loss: 0.311480
2022-12-28 02:16: Train Epoch 1: 146/159 Loss: 0.278842
2022-12-28 02:17: Train Epoch 1: 147/159 Loss: 0.327336
2022-12-28 02:18: Train Epoch 1: 148/159 Loss: 0.287496
2022-12-28 02:18: Train Epoch 1: 149/159 Loss: 0.342727
2022-12-28 02:19: Train Epoch 1: 150/159 Loss: 0.265672
2022-12-28 02:20: Train Epoch 1: 151/159 Loss: 0.288957
2022-12-28 02:21: Train Epoch 1: 152/159 Loss: 0.336135
2022-12-28 02:22: Train Epoch 1: 153/159 Loss: 0.314037
2022-12-28 02:22: Train Epoch 1: 154/159 Loss: 0.321765
2022-12-28 02:23: Train Epoch 1: 155/159 Loss: 0.266898
2022-12-28 02:24: Train Epoch 1: 156/159 Loss: 0.297387
2022-12-28 02:25: Train Epoch 1: 157/159 Loss: 0.328061
2022-12-28 02:25: Train Epoch 1: 158/159 Loss: 0.301231
2022-12-28 02:25: **********Train Epoch 1: averaged Loss: 0.498689 
2022-12-28 02:25: 
Epoch time elapsed: 8107.57390666008

2022-12-28 02:30: 
 metrics validation: {'precision': 0.7255772646536413, 'recall': 0.6284615384615385, 'f1-score': 0.6735366859027205, 'support': 1300, 'AUC': 0.819862426035503, 'AUCPR': 0.7236616513005238, 'TP': 817, 'FP': 309, 'TN': 2291, 'FN': 483} 

2022-12-28 02:30: **********Val Epoch 1: average Loss: 0.582958
2022-12-28 02:30: *********************************Current best model saved!
/home/joel.chacon/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2022-12-28 02:34: 
 Testing metrics {'precision': 0.7829313543599258, 'recall': 0.6872964169381107, 'f1-score': 0.7320034692107545, 'support': 1228, 'AUC': 0.8615383187089519, 'AUCPR': 0.7935327368516708, 'TP': 844, 'FP': 234, 'TN': 2222, 'FN': 384} 

2022-12-28 02:35: Train Epoch 2: 0/159 Loss: 0.289318
2022-12-28 02:36: Train Epoch 2: 1/159 Loss: 0.254629
2022-12-28 02:37: Train Epoch 2: 2/159 Loss: 0.267507
2022-12-28 02:38: Train Epoch 2: 3/159 Loss: 0.272820
2022-12-28 02:39: Train Epoch 2: 4/159 Loss: 0.324593
2022-12-28 02:39: Train Epoch 2: 5/159 Loss: 0.284923
2022-12-28 02:40: Train Epoch 2: 6/159 Loss: 0.354666
2022-12-28 02:41: Train Epoch 2: 7/159 Loss: 0.285896
2022-12-28 02:42: Train Epoch 2: 8/159 Loss: 0.271899
2022-12-28 02:43: Train Epoch 2: 9/159 Loss: 0.261124
2022-12-28 02:44: Train Epoch 2: 10/159 Loss: 0.264073
2022-12-28 02:45: Train Epoch 2: 11/159 Loss: 0.318334
2022-12-28 02:46: Train Epoch 2: 12/159 Loss: 0.264111
2022-12-28 02:47: Train Epoch 2: 13/159 Loss: 0.223979
2022-12-28 02:48: Train Epoch 2: 14/159 Loss: 0.368216
2022-12-28 02:48: Train Epoch 2: 15/159 Loss: 0.300116
2022-12-28 02:49: Train Epoch 2: 16/159 Loss: 0.303462
2022-12-28 02:50: Train Epoch 2: 17/159 Loss: 0.318128
2022-12-28 02:51: Train Epoch 2: 18/159 Loss: 0.302668
2022-12-28 02:52: Train Epoch 2: 19/159 Loss: 0.285325
2022-12-28 02:53: Train Epoch 2: 20/159 Loss: 0.347480
2022-12-28 02:54: Train Epoch 2: 21/159 Loss: 0.268633
2022-12-28 02:54: Train Epoch 2: 22/159 Loss: 0.323345
2022-12-28 02:55: Train Epoch 2: 23/159 Loss: 0.321740
2022-12-28 02:56: Train Epoch 2: 24/159 Loss: 0.250593
2022-12-28 02:57: Train Epoch 2: 25/159 Loss: 0.243692
2022-12-28 02:58: Train Epoch 2: 26/159 Loss: 0.260075
2022-12-28 02:59: Train Epoch 2: 27/159 Loss: 0.241519
2022-12-28 03:00: Train Epoch 2: 28/159 Loss: 0.388353
2022-12-28 03:01: Train Epoch 2: 29/159 Loss: 0.326828
2022-12-28 03:01: Train Epoch 2: 30/159 Loss: 0.296554
2022-12-28 03:02: Train Epoch 2: 31/159 Loss: 0.320058
2022-12-28 03:03: Train Epoch 2: 32/159 Loss: 0.306139
2022-12-28 03:04: Train Epoch 2: 33/159 Loss: 0.272981
2022-12-28 03:05: Train Epoch 2: 34/159 Loss: 0.277614
2022-12-28 03:06: Train Epoch 2: 35/159 Loss: 0.243132
2022-12-28 03:07: Train Epoch 2: 36/159 Loss: 0.360351
2022-12-28 03:08: Train Epoch 2: 37/159 Loss: 0.222752
2022-12-28 03:08: Train Epoch 2: 38/159 Loss: 0.226786
2022-12-28 03:09: Train Epoch 2: 39/159 Loss: 0.261182
2022-12-28 03:10: Train Epoch 2: 40/159 Loss: 0.377357
2022-12-28 03:11: Train Epoch 2: 41/159 Loss: 0.285509
2022-12-28 03:12: Train Epoch 2: 42/159 Loss: 0.293981
2022-12-28 03:13: Train Epoch 2: 43/159 Loss: 0.291871
2022-12-28 03:14: Train Epoch 2: 44/159 Loss: 0.350324
2022-12-28 03:14: Train Epoch 2: 45/159 Loss: 0.276241
2022-12-28 03:15: Train Epoch 2: 46/159 Loss: 0.236508
2022-12-28 03:16: Train Epoch 2: 47/159 Loss: 0.331995
2022-12-28 03:17: Train Epoch 2: 48/159 Loss: 0.305184
2022-12-28 03:18: Train Epoch 2: 49/159 Loss: 0.246940
2022-12-28 03:19: Train Epoch 2: 50/159 Loss: 0.306373
2022-12-28 03:20: Train Epoch 2: 51/159 Loss: 0.331231
2022-12-28 03:21: Train Epoch 2: 52/159 Loss: 0.288444
2022-12-28 03:22: Train Epoch 2: 53/159 Loss: 0.241803
2022-12-28 03:22: Train Epoch 2: 54/159 Loss: 0.232425
2022-12-28 03:23: Train Epoch 2: 55/159 Loss: 0.242870
2022-12-28 03:24: Train Epoch 2: 56/159 Loss: 0.320543
2022-12-28 03:25: Train Epoch 2: 57/159 Loss: 0.346250
2022-12-28 03:26: Train Epoch 2: 58/159 Loss: 0.252066
2022-12-28 03:27: Train Epoch 2: 59/159 Loss: 0.273932
2022-12-28 03:28: Train Epoch 2: 60/159 Loss: 0.339465
2022-12-28 03:28: Train Epoch 2: 61/159 Loss: 0.359573
2022-12-28 03:29: Train Epoch 2: 62/159 Loss: 0.366538
2022-12-28 03:30: Train Epoch 2: 63/159 Loss: 0.305122
2022-12-28 03:31: Train Epoch 2: 64/159 Loss: 0.270745
2022-12-28 03:32: Train Epoch 2: 65/159 Loss: 0.253461
2022-12-28 03:33: Train Epoch 2: 66/159 Loss: 0.289081
2022-12-28 03:34: Train Epoch 2: 67/159 Loss: 0.344429
2022-12-28 03:35: Train Epoch 2: 68/159 Loss: 0.368336
2022-12-28 03:35: Train Epoch 2: 69/159 Loss: 0.299909
2022-12-28 03:36: Train Epoch 2: 70/159 Loss: 0.267519
2022-12-28 03:37: Train Epoch 2: 71/159 Loss: 0.302712
2022-12-28 03:38: Train Epoch 2: 72/159 Loss: 0.259582
2022-12-28 03:39: Train Epoch 2: 73/159 Loss: 0.232861
2022-12-28 03:40: Train Epoch 2: 74/159 Loss: 0.300667
2022-12-28 03:41: Train Epoch 2: 75/159 Loss: 0.258819
2022-12-28 03:42: Train Epoch 2: 76/159 Loss: 0.257437
2022-12-28 03:42: Train Epoch 2: 77/159 Loss: 0.304796
2022-12-28 03:43: Train Epoch 2: 78/159 Loss: 0.293495
2022-12-28 03:44: Train Epoch 2: 79/159 Loss: 0.368215
2022-12-28 03:45: Train Epoch 2: 80/159 Loss: 0.294718
2022-12-28 03:46: Train Epoch 2: 81/159 Loss: 0.257910
2022-12-28 03:47: Train Epoch 2: 82/159 Loss: 0.248097
2022-12-28 03:48: Train Epoch 2: 83/159 Loss: 0.337157
2022-12-28 03:49: Train Epoch 2: 84/159 Loss: 0.271509
2022-12-28 03:49: Train Epoch 2: 85/159 Loss: 0.268106
2022-12-28 03:50: Train Epoch 2: 86/159 Loss: 0.246458
2022-12-28 03:51: Train Epoch 2: 87/159 Loss: 0.228222
2022-12-28 03:52: Train Epoch 2: 88/159 Loss: 0.262385
2022-12-28 03:53: Train Epoch 2: 89/159 Loss: 0.310492
2022-12-28 03:54: Train Epoch 2: 90/159 Loss: 0.343107
2022-12-28 03:55: Train Epoch 2: 91/159 Loss: 0.363849
2022-12-28 03:56: Train Epoch 2: 92/159 Loss: 0.304571
2022-12-28 03:57: Train Epoch 2: 93/159 Loss: 0.289060
2022-12-28 03:57: Train Epoch 2: 94/159 Loss: 0.267063
2022-12-28 03:58: Train Epoch 2: 95/159 Loss: 0.240819
2022-12-28 03:59: Train Epoch 2: 96/159 Loss: 0.282816
2022-12-28 04:00: Train Epoch 2: 97/159 Loss: 0.326019
2022-12-28 04:01: Train Epoch 2: 98/159 Loss: 0.343304
2022-12-28 04:02: Train Epoch 2: 99/159 Loss: 0.286822
2022-12-28 04:03: Train Epoch 2: 100/159 Loss: 0.323453
2022-12-28 04:04: Train Epoch 2: 101/159 Loss: 0.350439
2022-12-28 04:04: Train Epoch 2: 102/159 Loss: 0.322447
2022-12-28 04:05: Train Epoch 2: 103/159 Loss: 0.343002
2022-12-28 04:06: Train Epoch 2: 104/159 Loss: 0.275047
2022-12-28 04:07: Train Epoch 2: 105/159 Loss: 0.235674
2022-12-28 04:08: Train Epoch 2: 106/159 Loss: 0.304881
2022-12-28 04:09: Train Epoch 2: 107/159 Loss: 0.333137
2022-12-28 04:10: Train Epoch 2: 108/159 Loss: 0.265195
2022-12-28 04:11: Train Epoch 2: 109/159 Loss: 0.272218
2022-12-28 04:11: Train Epoch 2: 110/159 Loss: 0.297736
2022-12-28 04:12: Train Epoch 2: 111/159 Loss: 0.274508
2022-12-28 04:13: Train Epoch 2: 112/159 Loss: 0.335260
2022-12-28 04:14: Train Epoch 2: 113/159 Loss: 0.258831
2022-12-28 04:15: Train Epoch 2: 114/159 Loss: 0.236493
2022-12-28 04:16: Train Epoch 2: 115/159 Loss: 0.257923
2022-12-28 04:17: Train Epoch 2: 116/159 Loss: 0.268543
2022-12-28 04:18: Train Epoch 2: 117/159 Loss: 0.271096
2022-12-28 04:19: Train Epoch 2: 118/159 Loss: 0.304381
2022-12-28 04:19: Train Epoch 2: 119/159 Loss: 0.266835
2022-12-28 04:20: Train Epoch 2: 120/159 Loss: 0.329365
2022-12-28 04:21: Train Epoch 2: 121/159 Loss: 0.254785
2022-12-28 04:22: Train Epoch 2: 122/159 Loss: 0.330983
2022-12-28 04:23: Train Epoch 2: 123/159 Loss: 0.244497
2022-12-28 04:24: Train Epoch 2: 124/159 Loss: 0.309993
2022-12-28 04:25: Train Epoch 2: 125/159 Loss: 0.283338
2022-12-28 04:25: Train Epoch 2: 126/159 Loss: 0.317398
2022-12-28 04:26: Train Epoch 2: 127/159 Loss: 0.321614
2022-12-28 04:27: Train Epoch 2: 128/159 Loss: 0.310614
2022-12-28 04:28: Train Epoch 2: 129/159 Loss: 0.331930
2022-12-28 04:29: Train Epoch 2: 130/159 Loss: 0.206895
2022-12-28 04:30: Train Epoch 2: 131/159 Loss: 0.253794
2022-12-28 04:30: Train Epoch 2: 132/159 Loss: 0.356532
2022-12-28 04:31: Train Epoch 2: 133/159 Loss: 0.319473
2022-12-28 04:32: Train Epoch 2: 134/159 Loss: 0.237377
2022-12-28 04:33: Train Epoch 2: 135/159 Loss: 0.279871
2022-12-28 04:34: Train Epoch 2: 136/159 Loss: 0.302161
2022-12-28 04:35: Train Epoch 2: 137/159 Loss: 0.320586
2022-12-28 04:36: Train Epoch 2: 138/159 Loss: 0.332266
2022-12-28 04:36: Train Epoch 2: 139/159 Loss: 0.257633
2022-12-28 04:37: Train Epoch 2: 140/159 Loss: 0.207684
2022-12-28 04:38: Train Epoch 2: 141/159 Loss: 0.365468
2022-12-28 04:39: Train Epoch 2: 142/159 Loss: 0.290985
2022-12-28 04:40: Train Epoch 2: 143/159 Loss: 0.317165
2022-12-28 04:41: Train Epoch 2: 144/159 Loss: 0.301639
2022-12-28 04:41: Train Epoch 2: 145/159 Loss: 0.326117
2022-12-28 04:42: Train Epoch 2: 146/159 Loss: 0.364546
2022-12-28 04:43: Train Epoch 2: 147/159 Loss: 0.373007
2022-12-28 04:44: Train Epoch 2: 148/159 Loss: 0.274556
2022-12-28 04:45: Train Epoch 2: 149/159 Loss: 0.268205
2022-12-28 04:46: Train Epoch 2: 150/159 Loss: 0.322086
2022-12-28 04:47: Train Epoch 2: 151/159 Loss: 0.263989
2022-12-28 04:47: Train Epoch 2: 152/159 Loss: 0.314534
2022-12-28 04:48: Train Epoch 2: 153/159 Loss: 0.228646
2022-12-28 04:49: Train Epoch 2: 154/159 Loss: 0.344563
2022-12-28 04:50: Train Epoch 2: 155/159 Loss: 0.258846
2022-12-28 04:51: Train Epoch 2: 156/159 Loss: 0.241548
2022-12-28 04:52: Train Epoch 2: 157/159 Loss: 0.334062
2022-12-28 04:52: Train Epoch 2: 158/159 Loss: 0.324364
2022-12-28 04:52: **********Train Epoch 2: averaged Loss: 0.293352 
2022-12-28 04:52: 
Epoch time elapsed: 8292.808896541595

2022-12-28 04:56: 
 metrics validation: {'precision': 0.7604562737642585, 'recall': 0.6153846153846154, 'f1-score': 0.6802721088435375, 'support': 1300, 'AUC': 0.8361186390532546, 'AUCPR': 0.7517744449613938, 'TP': 800, 'FP': 252, 'TN': 2348, 'FN': 500} 

2022-12-28 04:56: **********Val Epoch 2: average Loss: 0.547051
2022-12-28 04:56: *********************************Current best model saved!
2022-12-28 05:00: 
 Testing metrics {'precision': 0.818089430894309, 'recall': 0.6555374592833876, 'f1-score': 0.7278481012658229, 'support': 1228, 'AUC': 0.8695006047809525, 'AUCPR': 0.8065929284914979, 'TP': 805, 'FP': 179, 'TN': 2277, 'FN': 423} 

2022-12-28 05:01: Train Epoch 3: 0/159 Loss: 0.269254
2022-12-28 05:01: Train Epoch 3: 1/159 Loss: 0.257869
2022-12-28 05:02: Train Epoch 3: 2/159 Loss: 0.217595
2022-12-28 05:03: Train Epoch 3: 3/159 Loss: 0.242994
2022-12-28 05:04: Train Epoch 3: 4/159 Loss: 0.299147
2022-12-28 05:05: Train Epoch 3: 5/159 Loss: 0.241140
2022-12-28 05:06: Train Epoch 3: 6/159 Loss: 0.263689
2022-12-28 05:07: Train Epoch 3: 7/159 Loss: 0.295972
2022-12-28 05:08: Train Epoch 3: 8/159 Loss: 0.255997
2022-12-28 05:08: Train Epoch 3: 9/159 Loss: 0.274364
2022-12-28 05:09: Train Epoch 3: 10/159 Loss: 0.320882
2022-12-28 05:10: Train Epoch 3: 11/159 Loss: 0.311809
2022-12-28 05:11: Train Epoch 3: 12/159 Loss: 0.254510
2022-12-28 05:12: Train Epoch 3: 13/159 Loss: 0.335445
2022-12-28 05:13: Train Epoch 3: 14/159 Loss: 0.245400
2022-12-28 05:14: Train Epoch 3: 15/159 Loss: 0.258081
2022-12-28 05:15: Train Epoch 3: 16/159 Loss: 0.274349
2022-12-28 05:15: Train Epoch 3: 17/159 Loss: 0.276366
2022-12-28 05:16: Train Epoch 3: 18/159 Loss: 0.276758
2022-12-28 05:17: Train Epoch 3: 19/159 Loss: 0.327035
2022-12-28 05:18: Train Epoch 3: 20/159 Loss: 0.327071
2022-12-28 05:19: Train Epoch 3: 21/159 Loss: 0.196774
2022-12-28 05:20: Train Epoch 3: 22/159 Loss: 0.280659
2022-12-28 05:21: Train Epoch 3: 23/159 Loss: 0.322596
2022-12-28 05:22: Train Epoch 3: 24/159 Loss: 0.370002
2022-12-28 05:22: Train Epoch 3: 25/159 Loss: 0.201958
2022-12-28 05:23: Train Epoch 3: 26/159 Loss: 0.246637
2022-12-28 05:24: Train Epoch 3: 27/159 Loss: 0.221910
2022-12-28 05:25: Train Epoch 3: 28/159 Loss: 0.304059
2022-12-28 05:26: Train Epoch 3: 29/159 Loss: 0.227005
2022-12-28 05:27: Train Epoch 3: 30/159 Loss: 0.222140
2022-12-28 05:28: Train Epoch 3: 31/159 Loss: 0.211745
2022-12-28 05:28: Train Epoch 3: 32/159 Loss: 0.332866
2022-12-28 05:29: Train Epoch 3: 33/159 Loss: 0.235981
2022-12-28 05:30: Train Epoch 3: 34/159 Loss: 0.219240
2022-12-28 05:31: Train Epoch 3: 35/159 Loss: 0.304063
2022-12-28 05:32: Train Epoch 3: 36/159 Loss: 0.231462
2022-12-28 05:33: Train Epoch 3: 37/159 Loss: 0.279040
2022-12-28 05:34: Train Epoch 3: 38/159 Loss: 0.351826
2022-12-28 05:35: Train Epoch 3: 39/159 Loss: 0.226033
2022-12-28 05:35: Train Epoch 3: 40/159 Loss: 0.303903
2022-12-28 05:36: Train Epoch 3: 41/159 Loss: 0.301718
2022-12-28 05:37: Train Epoch 3: 42/159 Loss: 0.307514
2022-12-28 05:38: Train Epoch 3: 43/159 Loss: 0.284373
2022-12-28 05:39: Train Epoch 3: 44/159 Loss: 0.292120
2022-12-28 05:40: Train Epoch 3: 45/159 Loss: 0.271043
2022-12-28 05:41: Train Epoch 3: 46/159 Loss: 0.284922
2022-12-28 05:42: Train Epoch 3: 47/159 Loss: 0.225213
2022-12-28 05:42: Train Epoch 3: 48/159 Loss: 0.264211
2022-12-28 05:43: Train Epoch 3: 49/159 Loss: 0.278212
2022-12-28 05:44: Train Epoch 3: 50/159 Loss: 0.223619
2022-12-28 05:45: Train Epoch 3: 51/159 Loss: 0.225670
2022-12-28 05:46: Train Epoch 3: 52/159 Loss: 0.338802
2022-12-28 05:47: Train Epoch 3: 53/159 Loss: 0.273406
2022-12-28 05:48: Train Epoch 3: 54/159 Loss: 0.308546
2022-12-28 05:48: Train Epoch 3: 55/159 Loss: 0.309433
2022-12-28 05:49: Train Epoch 3: 56/159 Loss: 0.254243
2022-12-28 05:50: Train Epoch 3: 57/159 Loss: 0.254121
2022-12-28 05:51: Train Epoch 3: 58/159 Loss: 0.304147
2022-12-28 05:52: Train Epoch 3: 59/159 Loss: 0.289802
2022-12-28 05:53: Train Epoch 3: 60/159 Loss: 0.276541
2022-12-28 05:54: Train Epoch 3: 61/159 Loss: 0.232544
2022-12-28 05:54: Train Epoch 3: 62/159 Loss: 0.304172
2022-12-28 05:55: Train Epoch 3: 63/159 Loss: 0.297335
2022-12-28 05:56: Train Epoch 3: 64/159 Loss: 0.264033
2022-12-28 05:57: Train Epoch 3: 65/159 Loss: 0.274691
2022-12-28 05:58: Train Epoch 3: 66/159 Loss: 0.193604
2022-12-28 05:59: Train Epoch 3: 67/159 Loss: 0.247624
2022-12-28 06:00: Train Epoch 3: 68/159 Loss: 0.286463
2022-12-28 06:00: Train Epoch 3: 69/159 Loss: 0.258210
2022-12-28 06:01: Train Epoch 3: 70/159 Loss: 0.294736
2022-12-28 06:02: Train Epoch 3: 71/159 Loss: 0.265878
2022-12-28 06:03: Train Epoch 3: 72/159 Loss: 0.308588
2022-12-28 06:04: Train Epoch 3: 73/159 Loss: 0.368151
2022-12-28 06:05: Train Epoch 3: 74/159 Loss: 0.246158
2022-12-28 06:06: Train Epoch 3: 75/159 Loss: 0.394270
2022-12-28 06:07: Train Epoch 3: 76/159 Loss: 0.308272
2022-12-28 06:07: Train Epoch 3: 77/159 Loss: 0.340969
2022-12-28 06:08: Train Epoch 3: 78/159 Loss: 0.251854
2022-12-28 06:09: Train Epoch 3: 79/159 Loss: 0.352426
2022-12-28 06:10: Train Epoch 3: 80/159 Loss: 0.246754
2022-12-28 06:11: Train Epoch 3: 81/159 Loss: 0.225275
2022-12-28 06:12: Train Epoch 3: 82/159 Loss: 0.261517
2022-12-28 06:13: Train Epoch 3: 83/159 Loss: 0.271279
2022-12-28 06:13: Train Epoch 3: 84/159 Loss: 0.375046
2022-12-28 06:14: Train Epoch 3: 85/159 Loss: 0.225768
2022-12-28 06:15: Train Epoch 3: 86/159 Loss: 0.223205
2022-12-28 06:16: Train Epoch 3: 87/159 Loss: 0.329175
2022-12-28 06:17: Train Epoch 3: 88/159 Loss: 0.324473
2022-12-28 06:18: Train Epoch 3: 89/159 Loss: 0.317454
2022-12-28 06:19: Train Epoch 3: 90/159 Loss: 0.332690
2022-12-28 06:20: Train Epoch 3: 91/159 Loss: 0.272623
2022-12-28 06:20: Train Epoch 3: 92/159 Loss: 0.297254
2022-12-28 06:21: Train Epoch 3: 93/159 Loss: 0.286945
2022-12-28 06:22: Train Epoch 3: 94/159 Loss: 0.323256
2022-12-28 06:23: Train Epoch 3: 95/159 Loss: 0.325157
2022-12-28 06:24: Train Epoch 3: 96/159 Loss: 0.242924
2022-12-28 06:25: Train Epoch 3: 97/159 Loss: 0.269853
2022-12-28 06:26: Train Epoch 3: 98/159 Loss: 0.276259
2022-12-28 06:26: Train Epoch 3: 99/159 Loss: 0.279261
2022-12-28 06:27: Train Epoch 3: 100/159 Loss: 0.259989
2022-12-28 06:28: Train Epoch 3: 101/159 Loss: 0.274770
2022-12-28 06:29: Train Epoch 3: 102/159 Loss: 0.203087
2022-12-28 06:30: Train Epoch 3: 103/159 Loss: 0.220135
2022-12-28 06:31: Train Epoch 3: 104/159 Loss: 0.221888
2022-12-28 06:32: Train Epoch 3: 105/159 Loss: 0.257175
2022-12-28 06:33: Train Epoch 3: 106/159 Loss: 0.304831
2022-12-28 06:33: Train Epoch 3: 107/159 Loss: 0.370560
2022-12-28 06:34: Train Epoch 3: 108/159 Loss: 0.328285
2022-12-28 06:35: Train Epoch 3: 109/159 Loss: 0.266940
2022-12-28 06:36: Train Epoch 3: 110/159 Loss: 0.210824
2022-12-28 06:37: Train Epoch 3: 111/159 Loss: 0.408369
2022-12-28 06:38: Train Epoch 3: 112/159 Loss: 0.291852
2022-12-28 06:39: Train Epoch 3: 113/159 Loss: 0.229179
2022-12-28 06:40: Train Epoch 3: 114/159 Loss: 0.256849
2022-12-28 06:40: Train Epoch 3: 115/159 Loss: 0.277363
2022-12-28 06:41: Train Epoch 3: 116/159 Loss: 0.270074
2022-12-28 06:42: Train Epoch 3: 117/159 Loss: 0.284773
2022-12-28 06:43: Train Epoch 3: 118/159 Loss: 0.281306
2022-12-28 06:44: Train Epoch 3: 119/159 Loss: 0.266521
2022-12-28 06:45: Train Epoch 3: 120/159 Loss: 0.303840
2022-12-28 06:46: Train Epoch 3: 121/159 Loss: 0.289757
2022-12-28 06:47: Train Epoch 3: 122/159 Loss: 0.279414
2022-12-28 06:47: Train Epoch 3: 123/159 Loss: 0.233850
2022-12-28 06:48: Train Epoch 3: 124/159 Loss: 0.318236
2022-12-28 06:49: Train Epoch 3: 125/159 Loss: 0.305334
2022-12-28 06:50: Train Epoch 3: 126/159 Loss: 0.282994
2022-12-28 06:51: Train Epoch 3: 127/159 Loss: 0.215118
2022-12-28 06:52: Train Epoch 3: 128/159 Loss: 0.311551
2022-12-28 06:53: Train Epoch 3: 129/159 Loss: 0.364377
2022-12-28 06:54: Train Epoch 3: 130/159 Loss: 0.271264
2022-12-28 06:54: Train Epoch 3: 131/159 Loss: 0.270118
2022-12-28 06:55: Train Epoch 3: 132/159 Loss: 0.327375
2022-12-28 06:56: Train Epoch 3: 133/159 Loss: 0.258516
2022-12-28 06:57: Train Epoch 3: 134/159 Loss: 0.300054
2022-12-28 06:58: Train Epoch 3: 135/159 Loss: 0.249539
2022-12-28 06:59: Train Epoch 3: 136/159 Loss: 0.257537
2022-12-28 06:59: Train Epoch 3: 137/159 Loss: 0.364996
2022-12-28 07:00: Train Epoch 3: 138/159 Loss: 0.338537
2022-12-28 07:01: Train Epoch 3: 139/159 Loss: 0.333332
2022-12-28 07:02: Train Epoch 3: 140/159 Loss: 0.313515
2022-12-28 07:03: Train Epoch 3: 141/159 Loss: 0.290718
2022-12-28 07:04: Train Epoch 3: 142/159 Loss: 0.254616
2022-12-28 07:04: Train Epoch 3: 143/159 Loss: 0.229037
2022-12-28 07:05: Train Epoch 3: 144/159 Loss: 0.282514
2022-12-28 07:06: Train Epoch 3: 145/159 Loss: 0.289727
2022-12-28 07:07: Train Epoch 3: 146/159 Loss: 0.242341
2022-12-28 07:08: Train Epoch 3: 147/159 Loss: 0.292714
2022-12-28 07:09: Train Epoch 3: 148/159 Loss: 0.244488
2022-12-28 07:10: Train Epoch 3: 149/159 Loss: 0.216606
2022-12-28 07:10: Train Epoch 3: 150/159 Loss: 0.341349
2022-12-28 07:11: Train Epoch 3: 151/159 Loss: 0.224563
2022-12-28 07:12: Train Epoch 3: 152/159 Loss: 0.331389
2022-12-28 07:13: Train Epoch 3: 153/159 Loss: 0.303081
2022-12-28 07:14: Train Epoch 3: 154/159 Loss: 0.238155
2022-12-28 07:15: Train Epoch 3: 155/159 Loss: 0.281201
2022-12-28 07:15: Train Epoch 3: 156/159 Loss: 0.271167
2022-12-28 07:16: Train Epoch 3: 157/159 Loss: 0.292602
2022-12-28 07:17: Train Epoch 3: 158/159 Loss: 0.257629
2022-12-28 07:17: **********Train Epoch 3: averaged Loss: 0.279480 
2022-12-28 07:17: 
Epoch time elapsed: 8216.384375810623

2022-12-28 07:20: 
 metrics validation: {'precision': 0.7539756782039289, 'recall': 0.62, 'f1-score': 0.6804558885605742, 'support': 1300, 'AUC': 0.8409005917159763, 'AUCPR': 0.7614215199935097, 'TP': 806, 'FP': 263, 'TN': 2337, 'FN': 494} 

2022-12-28 07:20: **********Val Epoch 3: average Loss: 0.532410
2022-12-28 07:20: *********************************Current best model saved!
2022-12-28 07:24: 
 Testing metrics {'precision': 0.8230174081237911, 'recall': 0.6929967426710097, 'f1-score': 0.7524314765694076, 'support': 1228, 'AUC': 0.8745530456556568, 'AUCPR': 0.8177576872399297, 'TP': 851, 'FP': 183, 'TN': 2273, 'FN': 377} 

2022-12-28 07:25: Train Epoch 4: 0/159 Loss: 0.262510
2022-12-28 07:26: Train Epoch 4: 1/159 Loss: 0.251265
2022-12-28 07:27: Train Epoch 4: 2/159 Loss: 0.278538
2022-12-28 07:28: Train Epoch 4: 3/159 Loss: 0.315889
2022-12-28 07:29: Train Epoch 4: 4/159 Loss: 0.270532
2022-12-28 07:30: Train Epoch 4: 5/159 Loss: 0.256526
2022-12-28 07:31: Train Epoch 4: 6/159 Loss: 0.278836
2022-12-28 07:31: Train Epoch 4: 7/159 Loss: 0.274587
2022-12-28 07:32: Train Epoch 4: 8/159 Loss: 0.306480
2022-12-28 07:33: Train Epoch 4: 9/159 Loss: 0.248633
2022-12-28 07:34: Train Epoch 4: 10/159 Loss: 0.285208
2022-12-28 07:35: Train Epoch 4: 11/159 Loss: 0.288089
2022-12-28 07:36: Train Epoch 4: 12/159 Loss: 0.252427
2022-12-28 07:37: Train Epoch 4: 13/159 Loss: 0.304582
2022-12-28 07:38: Train Epoch 4: 14/159 Loss: 0.249509
2022-12-28 07:38: Train Epoch 4: 15/159 Loss: 0.238332
2022-12-28 07:39: Train Epoch 4: 16/159 Loss: 0.359572
2022-12-28 07:40: Train Epoch 4: 17/159 Loss: 0.271141
2022-12-28 07:41: Train Epoch 4: 18/159 Loss: 0.342111
2022-12-28 07:42: Train Epoch 4: 19/159 Loss: 0.319752
2022-12-28 07:43: Train Epoch 4: 20/159 Loss: 0.335468
2022-12-28 07:44: Train Epoch 4: 21/159 Loss: 0.252721
2022-12-28 07:44: Train Epoch 4: 22/159 Loss: 0.288070
2022-12-28 07:45: Train Epoch 4: 23/159 Loss: 0.245211
2022-12-28 07:46: Train Epoch 4: 24/159 Loss: 0.285793
2022-12-28 07:47: Train Epoch 4: 25/159 Loss: 0.268736
2022-12-28 07:48: Train Epoch 4: 26/159 Loss: 0.227898
2022-12-28 07:49: Train Epoch 4: 27/159 Loss: 0.245188
2022-12-28 07:50: Train Epoch 4: 28/159 Loss: 0.271516
2022-12-28 07:51: Train Epoch 4: 29/159 Loss: 0.318919
2022-12-28 07:51: Train Epoch 4: 30/159 Loss: 0.265049
2022-12-28 07:52: Train Epoch 4: 31/159 Loss: 0.289478
2022-12-28 07:53: Train Epoch 4: 32/159 Loss: 0.295333
2022-12-28 07:54: Train Epoch 4: 33/159 Loss: 0.241773
2022-12-28 07:55: Train Epoch 4: 34/159 Loss: 0.267069
2022-12-28 07:56: Train Epoch 4: 35/159 Loss: 0.260184
2022-12-28 07:57: Train Epoch 4: 36/159 Loss: 0.291350
2022-12-28 07:57: Train Epoch 4: 37/159 Loss: 0.278878
2022-12-28 07:58: Train Epoch 4: 38/159 Loss: 0.209811
2022-12-28 07:59: Train Epoch 4: 39/159 Loss: 0.340332
2022-12-28 08:00: Train Epoch 4: 40/159 Loss: 0.202622
2022-12-28 08:01: Train Epoch 4: 41/159 Loss: 0.261616
2022-12-28 08:02: Train Epoch 4: 42/159 Loss: 0.310856
2022-12-28 08:03: Train Epoch 4: 43/159 Loss: 0.198922
2022-12-28 08:04: Train Epoch 4: 44/159 Loss: 0.338589
2022-12-28 08:04: Train Epoch 4: 45/159 Loss: 0.209732
2022-12-28 08:05: Train Epoch 4: 46/159 Loss: 0.218095
2022-12-28 08:06: Train Epoch 4: 47/159 Loss: 0.351054
2022-12-28 08:07: Train Epoch 4: 48/159 Loss: 0.296334
2022-12-28 08:08: Train Epoch 4: 49/159 Loss: 0.289814
2022-12-28 08:09: Train Epoch 4: 50/159 Loss: 0.215704
2022-12-28 08:10: Train Epoch 4: 51/159 Loss: 0.226910
2022-12-28 08:11: Train Epoch 4: 52/159 Loss: 0.333655
2022-12-28 08:11: Train Epoch 4: 53/159 Loss: 0.278248
2022-12-28 08:12: Train Epoch 4: 54/159 Loss: 0.242429
2022-12-28 08:13: Train Epoch 4: 55/159 Loss: 0.253151
2022-12-28 08:14: Train Epoch 4: 56/159 Loss: 0.336911
2022-12-28 08:15: Train Epoch 4: 57/159 Loss: 0.280339
2022-12-28 08:16: Train Epoch 4: 58/159 Loss: 0.279718
2022-12-28 08:17: Train Epoch 4: 59/159 Loss: 0.281796
2022-12-28 08:18: Train Epoch 4: 60/159 Loss: 0.258951
2022-12-28 08:18: Train Epoch 4: 61/159 Loss: 0.306177
2022-12-28 08:19: Train Epoch 4: 62/159 Loss: 0.251986
2022-12-28 08:20: Train Epoch 4: 63/159 Loss: 0.223087
2022-12-28 08:21: Train Epoch 4: 64/159 Loss: 0.220836
2022-12-28 08:22: Train Epoch 4: 65/159 Loss: 0.269014
2022-12-28 08:23: Train Epoch 4: 66/159 Loss: 0.324697
2022-12-28 08:24: Train Epoch 4: 67/159 Loss: 0.258173
2022-12-28 08:24: Train Epoch 4: 68/159 Loss: 0.265194
2022-12-28 08:25: Train Epoch 4: 69/159 Loss: 0.341695
2022-12-28 08:26: Train Epoch 4: 70/159 Loss: 0.266103
2022-12-28 08:27: Train Epoch 4: 71/159 Loss: 0.245662
2022-12-28 08:28: Train Epoch 4: 72/159 Loss: 0.233964
2022-12-28 08:29: Train Epoch 4: 73/159 Loss: 0.277139
2022-12-28 08:30: Train Epoch 4: 74/159 Loss: 0.233525
2022-12-28 08:31: Train Epoch 4: 75/159 Loss: 0.274622
2022-12-28 08:31: Train Epoch 4: 76/159 Loss: 0.346008
2022-12-28 08:32: Train Epoch 4: 77/159 Loss: 0.221370
2022-12-28 08:33: Train Epoch 4: 78/159 Loss: 0.277385
2022-12-28 08:34: Train Epoch 4: 79/159 Loss: 0.250889
2022-12-28 08:35: Train Epoch 4: 80/159 Loss: 0.264821
2022-12-28 08:36: Train Epoch 4: 81/159 Loss: 0.260997
2022-12-28 08:37: Train Epoch 4: 82/159 Loss: 0.260710
2022-12-28 08:38: Train Epoch 4: 83/159 Loss: 0.259452
2022-12-28 08:38: Train Epoch 4: 84/159 Loss: 0.308082
2022-12-28 08:39: Train Epoch 4: 85/159 Loss: 0.306229
2022-12-28 08:40: Train Epoch 4: 86/159 Loss: 0.283215
2022-12-28 08:41: Train Epoch 4: 87/159 Loss: 0.298147
2022-12-28 08:42: Train Epoch 4: 88/159 Loss: 0.315970
2022-12-28 08:43: Train Epoch 4: 89/159 Loss: 0.195056
2022-12-28 08:44: Train Epoch 4: 90/159 Loss: 0.254902
2022-12-28 08:45: Train Epoch 4: 91/159 Loss: 0.291428
2022-12-28 08:45: Train Epoch 4: 92/159 Loss: 0.218743
2022-12-28 08:46: Train Epoch 4: 93/159 Loss: 0.342015
2022-12-28 08:47: Train Epoch 4: 94/159 Loss: 0.249251
2022-12-28 08:48: Train Epoch 4: 95/159 Loss: 0.196760
2022-12-28 08:49: Train Epoch 4: 96/159 Loss: 0.289856
2022-12-28 08:50: Train Epoch 4: 97/159 Loss: 0.257085
2022-12-28 08:51: Train Epoch 4: 98/159 Loss: 0.274484
2022-12-28 08:51: Train Epoch 4: 99/159 Loss: 0.279320
2022-12-28 08:52: Train Epoch 4: 100/159 Loss: 0.249790
2022-12-28 08:53: Train Epoch 4: 101/159 Loss: 0.245678
2022-12-28 08:54: Train Epoch 4: 102/159 Loss: 0.340171
2022-12-28 08:55: Train Epoch 4: 103/159 Loss: 0.305731
2022-12-28 08:56: Train Epoch 4: 104/159 Loss: 0.250032
2022-12-28 08:57: Train Epoch 4: 105/159 Loss: 0.271476
2022-12-28 08:58: Train Epoch 4: 106/159 Loss: 0.261711
2022-12-28 08:58: Train Epoch 4: 107/159 Loss: 0.279605
2022-12-28 08:59: Train Epoch 4: 108/159 Loss: 0.276346
2022-12-28 09:00: Train Epoch 4: 109/159 Loss: 0.259851
2022-12-28 09:01: Train Epoch 4: 110/159 Loss: 0.275892
2022-12-28 09:02: Train Epoch 4: 111/159 Loss: 0.305045
2022-12-28 09:03: Train Epoch 4: 112/159 Loss: 0.257869
2022-12-28 09:04: Train Epoch 4: 113/159 Loss: 0.274091
2022-12-28 09:04: Train Epoch 4: 114/159 Loss: 0.310782
2022-12-28 09:05: Train Epoch 4: 115/159 Loss: 0.228232
2022-12-28 09:06: Train Epoch 4: 116/159 Loss: 0.264886
2022-12-28 09:07: Train Epoch 4: 117/159 Loss: 0.223153
2022-12-28 09:08: Train Epoch 4: 118/159 Loss: 0.262489
2022-12-28 09:09: Train Epoch 4: 119/159 Loss: 0.222838
2022-12-28 09:10: Train Epoch 4: 120/159 Loss: 0.333793
2022-12-28 09:11: Train Epoch 4: 121/159 Loss: 0.313577
2022-12-28 09:11: Train Epoch 4: 122/159 Loss: 0.307194
2022-12-28 09:12: Train Epoch 4: 123/159 Loss: 0.256318
2022-12-28 09:13: Train Epoch 4: 124/159 Loss: 0.274507
2022-12-28 09:14: Train Epoch 4: 125/159 Loss: 0.320082
2022-12-28 09:15: Train Epoch 4: 126/159 Loss: 0.230881
2022-12-28 09:16: Train Epoch 4: 127/159 Loss: 0.246202
2022-12-28 09:16: Train Epoch 4: 128/159 Loss: 0.295328
2022-12-28 09:17: Train Epoch 4: 129/159 Loss: 0.291884
2022-12-28 09:18: Train Epoch 4: 130/159 Loss: 0.273654
2022-12-28 09:19: Train Epoch 4: 131/159 Loss: 0.259325
2022-12-28 09:20: Train Epoch 4: 132/159 Loss: 0.310182
2022-12-28 09:21: Train Epoch 4: 133/159 Loss: 0.278069
2022-12-28 09:21: Train Epoch 4: 134/159 Loss: 0.232006
2022-12-28 09:22: Train Epoch 4: 135/159 Loss: 0.246285
2022-12-28 09:23: Train Epoch 4: 136/159 Loss: 0.250441
2022-12-28 09:24: Train Epoch 4: 137/159 Loss: 0.233898
2022-12-28 09:25: Train Epoch 4: 138/159 Loss: 0.194356
2022-12-28 09:26: Train Epoch 4: 139/159 Loss: 0.322251
2022-12-28 09:27: Train Epoch 4: 140/159 Loss: 0.305733
2022-12-28 09:27: Train Epoch 4: 141/159 Loss: 0.292170
2022-12-28 09:28: Train Epoch 4: 142/159 Loss: 0.310611
2022-12-28 09:29: Train Epoch 4: 143/159 Loss: 0.277714
2022-12-28 09:30: Train Epoch 4: 144/159 Loss: 0.259910
2022-12-28 09:31: Train Epoch 4: 145/159 Loss: 0.265160
2022-12-28 09:32: Train Epoch 4: 146/159 Loss: 0.304747
2022-12-28 09:32: Train Epoch 4: 147/159 Loss: 0.287789
2022-12-28 09:33: Train Epoch 4: 148/159 Loss: 0.224230
2022-12-28 09:34: Train Epoch 4: 149/159 Loss: 0.292862
2022-12-28 09:35: Train Epoch 4: 150/159 Loss: 0.237027
2022-12-28 09:36: Train Epoch 4: 151/159 Loss: 0.261067
2022-12-28 09:37: Train Epoch 4: 152/159 Loss: 0.254426
2022-12-28 09:37: Train Epoch 4: 153/159 Loss: 0.278391
2022-12-28 09:38: Train Epoch 4: 154/159 Loss: 0.260979
2022-12-28 09:39: Train Epoch 4: 155/159 Loss: 0.277384
2022-12-28 09:40: Train Epoch 4: 156/159 Loss: 0.273487
2022-12-28 09:41: Train Epoch 4: 157/159 Loss: 0.263415
2022-12-28 09:41: Train Epoch 4: 158/159 Loss: 0.217642
2022-12-28 09:41: **********Train Epoch 4: averaged Loss: 0.272160 
2022-12-28 09:41: 
Epoch time elapsed: 8210.837666034698

2022-12-28 09:45: 
 metrics validation: {'precision': 0.7548672566371681, 'recall': 0.6561538461538462, 'f1-score': 0.7020576131687244, 'support': 1300, 'AUC': 0.8441494082840236, 'AUCPR': 0.7689894770854546, 'TP': 853, 'FP': 277, 'TN': 2323, 'FN': 447} 

2022-12-28 09:45: **********Val Epoch 4: average Loss: 0.537637
2022-12-28 09:49: 
 Testing metrics {'precision': 0.8230174081237911, 'recall': 0.6929967426710097, 'f1-score': 0.7524314765694076, 'support': 1228, 'AUC': 0.8745530456556568, 'AUCPR': 0.8177576872399297, 'TP': 851, 'FP': 183, 'TN': 2273, 'FN': 377} 

2022-12-28 09:50: Train Epoch 5: 0/159 Loss: 0.309998
2022-12-28 09:51: Train Epoch 5: 1/159 Loss: 0.303531
2022-12-28 09:52: Train Epoch 5: 2/159 Loss: 0.246951
2022-12-28 09:53: Train Epoch 5: 3/159 Loss: 0.283611
2022-12-28 09:53: Train Epoch 5: 4/159 Loss: 0.233272
2022-12-28 09:54: Train Epoch 5: 5/159 Loss: 0.203358
2022-12-28 09:55: Train Epoch 5: 6/159 Loss: 0.268014
2022-12-28 09:56: Train Epoch 5: 7/159 Loss: 0.247603
2022-12-28 09:57: Train Epoch 5: 8/159 Loss: 0.281036
2022-12-28 09:58: Train Epoch 5: 9/159 Loss: 0.354974
2022-12-28 09:59: Train Epoch 5: 10/159 Loss: 0.351507
2022-12-28 09:59: Train Epoch 5: 11/159 Loss: 0.214681
2022-12-28 10:00: Train Epoch 5: 12/159 Loss: 0.241560
2022-12-28 10:01: Train Epoch 5: 13/159 Loss: 0.304948
2022-12-28 10:02: Train Epoch 5: 14/159 Loss: 0.229827
2022-12-28 10:03: Train Epoch 5: 15/159 Loss: 0.275649
2022-12-28 10:04: Train Epoch 5: 16/159 Loss: 0.295785
2022-12-28 10:05: Train Epoch 5: 17/159 Loss: 0.268692
2022-12-28 10:06: Train Epoch 5: 18/159 Loss: 0.255564
2022-12-28 10:06: Train Epoch 5: 19/159 Loss: 0.286076
2022-12-28 10:07: Train Epoch 5: 20/159 Loss: 0.215339
2022-12-28 10:08: Train Epoch 5: 21/159 Loss: 0.269869
2022-12-28 10:09: Train Epoch 5: 22/159 Loss: 0.243500
2022-12-28 10:10: Train Epoch 5: 23/159 Loss: 0.272558
2022-12-28 10:11: Train Epoch 5: 24/159 Loss: 0.236412
2022-12-28 10:12: Train Epoch 5: 25/159 Loss: 0.302105
2022-12-28 10:12: Train Epoch 5: 26/159 Loss: 0.202430
2022-12-28 10:13: Train Epoch 5: 27/159 Loss: 0.271539
2022-12-28 10:14: Train Epoch 5: 28/159 Loss: 0.276745
2022-12-28 10:15: Train Epoch 5: 29/159 Loss: 0.297915
2022-12-28 10:16: Train Epoch 5: 30/159 Loss: 0.315490
2022-12-28 10:17: Train Epoch 5: 31/159 Loss: 0.257840
2022-12-28 10:18: Train Epoch 5: 32/159 Loss: 0.270401
2022-12-28 10:19: Train Epoch 5: 33/159 Loss: 0.279423
2022-12-28 10:19: Train Epoch 5: 34/159 Loss: 0.294574
2022-12-28 10:20: Train Epoch 5: 35/159 Loss: 0.214202
2022-12-28 10:21: Train Epoch 5: 36/159 Loss: 0.300771
2022-12-28 10:22: Train Epoch 5: 37/159 Loss: 0.233559
2022-12-28 10:23: Train Epoch 5: 38/159 Loss: 0.282060
2022-12-28 10:24: Train Epoch 5: 39/159 Loss: 0.390071
2022-12-28 10:25: Train Epoch 5: 40/159 Loss: 0.237149
2022-12-28 10:25: Train Epoch 5: 41/159 Loss: 0.232321
2022-12-28 10:26: Train Epoch 5: 42/159 Loss: 0.285906
2022-12-28 10:27: Train Epoch 5: 43/159 Loss: 0.350679
2022-12-28 10:28: Train Epoch 5: 44/159 Loss: 0.252834
2022-12-28 10:29: Train Epoch 5: 45/159 Loss: 0.218847
2022-12-28 10:30: Train Epoch 5: 46/159 Loss: 0.262806
2022-12-28 10:31: Train Epoch 5: 47/159 Loss: 0.321954
2022-12-28 10:31: Train Epoch 5: 48/159 Loss: 0.257760
2022-12-28 10:32: Train Epoch 5: 49/159 Loss: 0.302323
2022-12-28 10:33: Train Epoch 5: 50/159 Loss: 0.263666
2022-12-28 10:34: Train Epoch 5: 51/159 Loss: 0.285709
2022-12-28 10:35: Train Epoch 5: 52/159 Loss: 0.239370
2022-12-28 10:36: Train Epoch 5: 53/159 Loss: 0.266563
2022-12-28 10:37: Train Epoch 5: 54/159 Loss: 0.376316
2022-12-28 10:38: Train Epoch 5: 55/159 Loss: 0.286413
2022-12-28 10:38: Train Epoch 5: 56/159 Loss: 0.217487
2022-12-28 10:39: Train Epoch 5: 57/159 Loss: 0.267460
2022-12-28 10:40: Train Epoch 5: 58/159 Loss: 0.261227
2022-12-28 10:41: Train Epoch 5: 59/159 Loss: 0.257174
2022-12-28 10:42: Train Epoch 5: 60/159 Loss: 0.277260
2022-12-28 10:43: Train Epoch 5: 61/159 Loss: 0.282467
2022-12-28 10:44: Train Epoch 5: 62/159 Loss: 0.257456
2022-12-28 10:44: Train Epoch 5: 63/159 Loss: 0.242370
2022-12-28 10:45: Train Epoch 5: 64/159 Loss: 0.264065
2022-12-28 10:46: Train Epoch 5: 65/159 Loss: 0.256571
2022-12-28 10:47: Train Epoch 5: 66/159 Loss: 0.260165
2022-12-28 10:48: Train Epoch 5: 67/159 Loss: 0.260636
2022-12-28 10:49: Train Epoch 5: 68/159 Loss: 0.259011
2022-12-28 10:50: Train Epoch 5: 69/159 Loss: 0.288577
2022-12-28 10:50: Train Epoch 5: 70/159 Loss: 0.240133
2022-12-28 10:51: Train Epoch 5: 71/159 Loss: 0.288121
2022-12-28 10:52: Train Epoch 5: 72/159 Loss: 0.257728
2022-12-28 10:53: Train Epoch 5: 73/159 Loss: 0.264162
2022-12-28 10:54: Train Epoch 5: 74/159 Loss: 0.284168
2022-12-28 10:55: Train Epoch 5: 75/159 Loss: 0.256109
2022-12-28 10:56: Train Epoch 5: 76/159 Loss: 0.215939
2022-12-28 10:56: Train Epoch 5: 77/159 Loss: 0.308925
2022-12-28 10:57: Train Epoch 5: 78/159 Loss: 0.231333
2022-12-28 10:58: Train Epoch 5: 79/159 Loss: 0.266172
2022-12-28 10:59: Train Epoch 5: 80/159 Loss: 0.265336
2022-12-28 11:00: Train Epoch 5: 81/159 Loss: 0.215698
2022-12-28 11:01: Train Epoch 5: 82/159 Loss: 0.288213
2022-12-28 11:02: Train Epoch 5: 83/159 Loss: 0.314381
2022-12-28 11:02: Train Epoch 5: 84/159 Loss: 0.298958
2022-12-28 11:03: Train Epoch 5: 85/159 Loss: 0.227893
2022-12-28 11:04: Train Epoch 5: 86/159 Loss: 0.214501
2022-12-28 11:05: Train Epoch 5: 87/159 Loss: 0.252756
2022-12-28 11:06: Train Epoch 5: 88/159 Loss: 0.271089
2022-12-28 11:07: Train Epoch 5: 89/159 Loss: 0.276175
2022-12-28 11:08: Train Epoch 5: 90/159 Loss: 0.263688
2022-12-28 11:09: Train Epoch 5: 91/159 Loss: 0.352389
2022-12-28 11:09: Train Epoch 5: 92/159 Loss: 0.198245
2022-12-28 11:10: Train Epoch 5: 93/159 Loss: 0.262130
2022-12-28 11:11: Train Epoch 5: 94/159 Loss: 0.244464
2022-12-28 11:12: Train Epoch 5: 95/159 Loss: 0.309334
2022-12-28 11:13: Train Epoch 5: 96/159 Loss: 0.280260
2022-12-28 11:14: Train Epoch 5: 97/159 Loss: 0.292060
2022-12-28 11:15: Train Epoch 5: 98/159 Loss: 0.249660
2022-12-28 11:16: Train Epoch 5: 99/159 Loss: 0.298549
2022-12-28 11:16: Train Epoch 5: 100/159 Loss: 0.316496
2022-12-28 11:17: Train Epoch 5: 101/159 Loss: 0.324397
2022-12-28 11:18: Train Epoch 5: 102/159 Loss: 0.296989
2022-12-28 11:19: Train Epoch 5: 103/159 Loss: 0.323642
2022-12-28 11:20: Train Epoch 5: 104/159 Loss: 0.243572
2022-12-28 11:21: Train Epoch 5: 105/159 Loss: 0.254546
2022-12-28 11:22: Train Epoch 5: 106/159 Loss: 0.297518
2022-12-28 11:23: Train Epoch 5: 107/159 Loss: 0.236159
2022-12-28 11:23: Train Epoch 5: 108/159 Loss: 0.286213
2022-12-28 11:24: Train Epoch 5: 109/159 Loss: 0.281891
2022-12-28 11:25: Train Epoch 5: 110/159 Loss: 0.227155
2022-12-28 11:26: Train Epoch 5: 111/159 Loss: 0.259226
2022-12-28 11:27: Train Epoch 5: 112/159 Loss: 0.277670
2022-12-28 11:28: Train Epoch 5: 113/159 Loss: 0.269559
2022-12-28 11:29: Train Epoch 5: 114/159 Loss: 0.311542
2022-12-28 11:29: Train Epoch 5: 115/159 Loss: 0.260754
2022-12-28 11:30: Train Epoch 5: 116/159 Loss: 0.218623
2022-12-28 11:31: Train Epoch 5: 117/159 Loss: 0.268619
2022-12-28 11:32: Train Epoch 5: 118/159 Loss: 0.255911
2022-12-28 11:33: Train Epoch 5: 119/159 Loss: 0.262543
2022-12-28 11:34: Train Epoch 5: 120/159 Loss: 0.290977
2022-12-28 11:35: Train Epoch 5: 121/159 Loss: 0.331356
2022-12-28 11:36: Train Epoch 5: 122/159 Loss: 0.300133
2022-12-28 11:36: Train Epoch 5: 123/159 Loss: 0.266980
2022-12-28 11:37: Train Epoch 5: 124/159 Loss: 0.237284
2022-12-28 11:38: Train Epoch 5: 125/159 Loss: 0.252580
2022-12-28 11:39: Train Epoch 5: 126/159 Loss: 0.224671
2022-12-28 11:40: Train Epoch 5: 127/159 Loss: 0.321888
2022-12-28 11:41: Train Epoch 5: 128/159 Loss: 0.276928
2022-12-28 11:42: Train Epoch 5: 129/159 Loss: 0.267837
2022-12-28 11:42: Train Epoch 5: 130/159 Loss: 0.306258
2022-12-28 11:43: Train Epoch 5: 131/159 Loss: 0.343798
2022-12-28 11:44: Train Epoch 5: 132/159 Loss: 0.298728
2022-12-28 11:45: Train Epoch 5: 133/159 Loss: 0.367074
2022-12-28 11:46: Train Epoch 5: 134/159 Loss: 0.297535
2022-12-28 11:47: Train Epoch 5: 135/159 Loss: 0.291179
2022-12-28 11:48: Train Epoch 5: 136/159 Loss: 0.304707
2022-12-28 11:48: Train Epoch 5: 137/159 Loss: 0.297798
2022-12-28 11:49: Train Epoch 5: 138/159 Loss: 0.352810
2022-12-28 11:50: Train Epoch 5: 139/159 Loss: 0.284809
2022-12-28 11:51: Train Epoch 5: 140/159 Loss: 0.250588
2022-12-28 11:52: Train Epoch 5: 141/159 Loss: 0.330892
2022-12-28 11:53: Train Epoch 5: 142/159 Loss: 0.306811
2022-12-28 11:53: Train Epoch 5: 143/159 Loss: 0.272660
2022-12-28 11:54: Train Epoch 5: 144/159 Loss: 0.275599
2022-12-28 11:55: Train Epoch 5: 145/159 Loss: 0.294598
2022-12-28 11:56: Train Epoch 5: 146/159 Loss: 0.206463
2022-12-28 11:57: Train Epoch 5: 147/159 Loss: 0.230831
2022-12-28 11:58: Train Epoch 5: 148/159 Loss: 0.267975
2022-12-28 11:59: Train Epoch 5: 149/159 Loss: 0.295535
2022-12-28 11:59: Train Epoch 5: 150/159 Loss: 0.307763
2022-12-28 12:00: Train Epoch 5: 151/159 Loss: 0.271778
2022-12-28 12:01: Train Epoch 5: 152/159 Loss: 0.236022
2022-12-28 12:02: Train Epoch 5: 153/159 Loss: 0.300253
2022-12-28 12:03: Train Epoch 5: 154/159 Loss: 0.309826
2022-12-28 12:04: Train Epoch 5: 155/159 Loss: 0.296975
2022-12-28 12:04: Train Epoch 5: 156/159 Loss: 0.321897
2022-12-28 12:05: Train Epoch 5: 157/159 Loss: 0.275701
2022-12-28 12:06: Train Epoch 5: 158/159 Loss: 0.407889
2022-12-28 12:06: **********Train Epoch 5: averaged Loss: 0.275553 
2022-12-28 12:06: 
Epoch time elapsed: 8207.984904766083

2022-12-28 12:10: 
 metrics validation: {'precision': 0.6936170212765957, 'recall': 0.7523076923076923, 'f1-score': 0.7217712177121771, 'support': 1300, 'AUC': 0.8446016272189348, 'AUCPR': 0.769185654871443, 'TP': 978, 'FP': 432, 'TN': 2168, 'FN': 322} 

2022-12-28 12:10: **********Val Epoch 5: average Loss: 0.531841
2022-12-28 12:10: *********************************Current best model saved!
2022-12-28 12:13: 
 Testing metrics {'precision': 0.7399527186761229, 'recall': 0.7646579804560261, 'f1-score': 0.7521025230276331, 'support': 1228, 'AUC': 0.8758735172256469, 'AUCPR': 0.82306579087273, 'TP': 939, 'FP': 330, 'TN': 2126, 'FN': 289} 

2022-12-28 12:15: Train Epoch 6: 0/159 Loss: 0.302053
2022-12-28 12:15: Train Epoch 6: 1/159 Loss: 0.280760
2022-12-28 12:16: Train Epoch 6: 2/159 Loss: 0.342450
2022-12-28 12:17: Train Epoch 6: 3/159 Loss: 0.353863
2022-12-28 12:18: Train Epoch 6: 4/159 Loss: 0.271521
2022-12-28 12:19: Train Epoch 6: 5/159 Loss: 0.261489
2022-12-28 12:20: Train Epoch 6: 6/159 Loss: 0.322232
2022-12-28 12:21: Train Epoch 6: 7/159 Loss: 0.222098
2022-12-28 12:22: Train Epoch 6: 8/159 Loss: 0.241010
2022-12-28 12:22: Train Epoch 6: 9/159 Loss: 0.310952
2022-12-28 12:23: Train Epoch 6: 10/159 Loss: 0.305856
2022-12-28 12:24: Train Epoch 6: 11/159 Loss: 0.260265
2022-12-28 12:25: Train Epoch 6: 12/159 Loss: 0.204443
2022-12-28 12:26: Train Epoch 6: 13/159 Loss: 0.280687
2022-12-28 12:27: Train Epoch 6: 14/159 Loss: 0.292527
2022-12-28 12:28: Train Epoch 6: 15/159 Loss: 0.282819
2022-12-28 12:29: Train Epoch 6: 16/159 Loss: 0.230672
2022-12-28 12:29: Train Epoch 6: 17/159 Loss: 0.258639
2022-12-28 12:30: Train Epoch 6: 18/159 Loss: 0.247942
2022-12-28 12:31: Train Epoch 6: 19/159 Loss: 0.284864
2022-12-28 12:32: Train Epoch 6: 20/159 Loss: 0.234169
2022-12-28 12:33: Train Epoch 6: 21/159 Loss: 0.303780
2022-12-28 12:34: Train Epoch 6: 22/159 Loss: 0.299113
2022-12-28 12:35: Train Epoch 6: 23/159 Loss: 0.218278
2022-12-28 12:36: Train Epoch 6: 24/159 Loss: 0.301363
2022-12-28 12:37: Train Epoch 6: 25/159 Loss: 0.183708
2022-12-28 12:37: Train Epoch 6: 26/159 Loss: 0.306586
2022-12-28 12:38: Train Epoch 6: 27/159 Loss: 0.218581
2022-12-28 12:39: Train Epoch 6: 28/159 Loss: 0.232893
2022-12-28 12:40: Train Epoch 6: 29/159 Loss: 0.236651
2022-12-28 12:41: Train Epoch 6: 30/159 Loss: 0.252697
2022-12-28 12:42: Train Epoch 6: 31/159 Loss: 0.287522
2022-12-28 12:43: Train Epoch 6: 32/159 Loss: 0.296711
2022-12-28 12:44: Train Epoch 6: 33/159 Loss: 0.291385
2022-12-28 12:44: Train Epoch 6: 34/159 Loss: 0.368408
2022-12-28 12:45: Train Epoch 6: 35/159 Loss: 0.255911
2022-12-28 12:46: Train Epoch 6: 36/159 Loss: 0.321340
2022-12-28 12:47: Train Epoch 6: 37/159 Loss: 0.446252
2022-12-28 12:48: Train Epoch 6: 38/159 Loss: 0.292584
2022-12-28 12:49: Train Epoch 6: 39/159 Loss: 0.263276
2022-12-28 12:50: Train Epoch 6: 40/159 Loss: 0.260260
2022-12-28 12:50: Train Epoch 6: 41/159 Loss: 0.245315
2022-12-28 12:51: Train Epoch 6: 42/159 Loss: 0.233134
2022-12-28 12:52: Train Epoch 6: 43/159 Loss: 0.250971
2022-12-28 12:53: Train Epoch 6: 44/159 Loss: 0.278234
2022-12-28 12:54: Train Epoch 6: 45/159 Loss: 0.245023
2022-12-28 12:55: Train Epoch 6: 46/159 Loss: 0.263447
2022-12-28 12:56: Train Epoch 6: 47/159 Loss: 0.336926
2022-12-28 12:57: Train Epoch 6: 48/159 Loss: 0.235783
2022-12-28 12:57: Train Epoch 6: 49/159 Loss: 0.312470
2022-12-28 12:58: Train Epoch 6: 50/159 Loss: 0.307361
2022-12-28 12:59: Train Epoch 6: 51/159 Loss: 0.212460
2022-12-28 13:00: Train Epoch 6: 52/159 Loss: 0.262923
2022-12-28 13:01: Train Epoch 6: 53/159 Loss: 0.242481
2022-12-28 13:02: Train Epoch 6: 54/159 Loss: 0.321372
2022-12-28 13:03: Train Epoch 6: 55/159 Loss: 0.259407
2022-12-28 13:03: Train Epoch 6: 56/159 Loss: 0.256164
2022-12-28 13:04: Train Epoch 6: 57/159 Loss: 0.234882
2022-12-28 13:05: Train Epoch 6: 58/159 Loss: 0.324800
2022-12-28 13:06: Train Epoch 6: 59/159 Loss: 0.256982
2022-12-28 13:07: Train Epoch 6: 60/159 Loss: 0.264381
2022-12-28 13:08: Train Epoch 6: 61/159 Loss: 0.275165
2022-12-28 13:09: Train Epoch 6: 62/159 Loss: 0.253813
2022-12-28 13:09: Train Epoch 6: 63/159 Loss: 0.295969
2022-12-28 13:10: Train Epoch 6: 64/159 Loss: 0.300553
2022-12-28 13:11: Train Epoch 6: 65/159 Loss: 0.224608
2022-12-28 13:12: Train Epoch 6: 66/159 Loss: 0.265249
2022-12-28 13:13: Train Epoch 6: 67/159 Loss: 0.282574
2022-12-28 13:14: Train Epoch 6: 68/159 Loss: 0.246064
2022-12-28 13:15: Train Epoch 6: 69/159 Loss: 0.279527
2022-12-28 13:16: Train Epoch 6: 70/159 Loss: 0.299363
2022-12-28 13:16: Train Epoch 6: 71/159 Loss: 0.337937
2022-12-28 13:17: Train Epoch 6: 72/159 Loss: 0.237470
2022-12-28 13:18: Train Epoch 6: 73/159 Loss: 0.237964
2022-12-28 13:19: Train Epoch 6: 74/159 Loss: 0.208515
2022-12-28 13:20: Train Epoch 6: 75/159 Loss: 0.268897
2022-12-28 13:21: Train Epoch 6: 76/159 Loss: 0.287520
2022-12-28 13:22: Train Epoch 6: 77/159 Loss: 0.266733
2022-12-28 13:22: Train Epoch 6: 78/159 Loss: 0.305602
2022-12-28 13:23: Train Epoch 6: 79/159 Loss: 0.213215
2022-12-28 13:24: Train Epoch 6: 80/159 Loss: 0.262444
2022-12-28 13:25: Train Epoch 6: 81/159 Loss: 0.200438
2022-12-28 13:26: Train Epoch 6: 82/159 Loss: 0.243647
2022-12-28 13:27: Train Epoch 6: 83/159 Loss: 0.311431
2022-12-28 13:28: Train Epoch 6: 84/159 Loss: 0.234920
2022-12-28 13:29: Train Epoch 6: 85/159 Loss: 0.245269
2022-12-28 13:29: Train Epoch 6: 86/159 Loss: 0.289342
2022-12-28 13:30: Train Epoch 6: 87/159 Loss: 0.292841
2022-12-28 13:31: Train Epoch 6: 88/159 Loss: 0.308226
2022-12-28 13:32: Train Epoch 6: 89/159 Loss: 0.338762
2022-12-28 13:33: Train Epoch 6: 90/159 Loss: 0.233583
2022-12-28 13:34: Train Epoch 6: 91/159 Loss: 0.246838
2022-12-28 13:35: Train Epoch 6: 92/159 Loss: 0.268520
2022-12-28 13:36: Train Epoch 6: 93/159 Loss: 0.313199
2022-12-28 13:36: Train Epoch 6: 94/159 Loss: 0.278767
2022-12-28 13:37: Train Epoch 6: 95/159 Loss: 0.256623
2022-12-28 13:38: Train Epoch 6: 96/159 Loss: 0.324383
2022-12-28 13:39: Train Epoch 6: 97/159 Loss: 0.228398
2022-12-28 13:40: Train Epoch 6: 98/159 Loss: 0.266208
2022-12-28 13:41: Train Epoch 6: 99/159 Loss: 0.305199
2022-12-28 13:42: Train Epoch 6: 100/159 Loss: 0.296965
2022-12-28 13:42: Train Epoch 6: 101/159 Loss: 0.361567
2022-12-28 13:43: Train Epoch 6: 102/159 Loss: 0.276289
2022-12-28 13:44: Train Epoch 6: 103/159 Loss: 0.204240
2022-12-28 13:45: Train Epoch 6: 104/159 Loss: 0.312014
2022-12-28 13:46: Train Epoch 6: 105/159 Loss: 0.297337
2022-12-28 13:47: Train Epoch 6: 106/159 Loss: 0.276378
2022-12-28 13:48: Train Epoch 6: 107/159 Loss: 0.269239
2022-12-28 13:48: Train Epoch 6: 108/159 Loss: 0.328424
2022-12-28 13:49: Train Epoch 6: 109/159 Loss: 0.268624
2022-12-28 13:50: Train Epoch 6: 110/159 Loss: 0.249100
2022-12-28 13:51: Train Epoch 6: 111/159 Loss: 0.303260
2022-12-28 13:52: Train Epoch 6: 112/159 Loss: 0.286012
2022-12-28 13:53: Train Epoch 6: 113/159 Loss: 0.233386
2022-12-28 13:54: Train Epoch 6: 114/159 Loss: 0.316600
2022-12-28 13:54: Train Epoch 6: 115/159 Loss: 0.354739
2022-12-28 13:55: Train Epoch 6: 116/159 Loss: 0.237254
2022-12-28 13:56: Train Epoch 6: 117/159 Loss: 0.225748
2022-12-28 13:57: Train Epoch 6: 118/159 Loss: 0.284364
2022-12-28 13:58: Train Epoch 6: 119/159 Loss: 0.323387
2022-12-28 13:59: Train Epoch 6: 120/159 Loss: 0.359414
2022-12-28 14:00: Train Epoch 6: 121/159 Loss: 0.303674
2022-12-28 14:00: Train Epoch 6: 122/159 Loss: 0.258795
2022-12-28 14:01: Train Epoch 6: 123/159 Loss: 0.301743
2022-12-28 14:02: Train Epoch 6: 124/159 Loss: 0.288792
2022-12-28 14:03: Train Epoch 6: 125/159 Loss: 0.251462
2022-12-28 14:04: Train Epoch 6: 126/159 Loss: 0.331527
2022-12-28 14:05: Train Epoch 6: 127/159 Loss: 0.228712
2022-12-28 14:06: Train Epoch 6: 128/159 Loss: 0.276882
2022-12-28 14:06: Train Epoch 6: 129/159 Loss: 0.278099
2022-12-28 14:07: Train Epoch 6: 130/159 Loss: 0.327560
2022-12-28 14:08: Train Epoch 6: 131/159 Loss: 0.215350
2022-12-28 14:09: Train Epoch 6: 132/159 Loss: 0.269403
2022-12-28 14:10: Train Epoch 6: 133/159 Loss: 0.278615
2022-12-28 14:11: Train Epoch 6: 134/159 Loss: 0.301456
2022-12-28 14:12: Train Epoch 6: 135/159 Loss: 0.287575
2022-12-28 14:13: Train Epoch 6: 136/159 Loss: 0.358873
2022-12-28 14:13: Train Epoch 6: 137/159 Loss: 0.342773
2022-12-28 14:14: Train Epoch 6: 138/159 Loss: 0.278021
2022-12-28 14:15: Train Epoch 6: 139/159 Loss: 0.303001
2022-12-28 14:16: Train Epoch 6: 140/159 Loss: 0.282354
2022-12-28 14:17: Train Epoch 6: 141/159 Loss: 0.284016
2022-12-28 14:18: Train Epoch 6: 142/159 Loss: 0.209337
2022-12-28 14:18: Train Epoch 6: 143/159 Loss: 0.276896
2022-12-28 14:19: Train Epoch 6: 144/159 Loss: 0.255461
2022-12-28 14:20: Train Epoch 6: 145/159 Loss: 0.278855
2022-12-28 14:21: Train Epoch 6: 146/159 Loss: 0.305603
2022-12-28 14:22: Train Epoch 6: 147/159 Loss: 0.356779
2022-12-28 14:23: Train Epoch 6: 148/159 Loss: 0.348383
2022-12-28 14:23: Train Epoch 6: 149/159 Loss: 0.298261
2022-12-28 14:24: Train Epoch 6: 150/159 Loss: 0.307973
2022-12-28 14:25: Train Epoch 6: 151/159 Loss: 0.347112
2022-12-28 14:26: Train Epoch 6: 152/159 Loss: 0.261206
2022-12-28 14:27: Train Epoch 6: 153/159 Loss: 0.256943
2022-12-28 14:28: Train Epoch 6: 154/159 Loss: 0.233974
2022-12-28 14:29: Train Epoch 6: 155/159 Loss: 0.333612
2022-12-28 14:29: Train Epoch 6: 156/159 Loss: 0.267274
2022-12-28 14:30: Train Epoch 6: 157/159 Loss: 0.229461
2022-12-28 14:30: Train Epoch 6: 158/159 Loss: 0.326520
2022-12-28 14:30: **********Train Epoch 6: averaged Loss: 0.278714 
2022-12-28 14:30: 
Epoch time elapsed: 8222.071559667587

2022-12-28 14:34: 
 metrics validation: {'precision': 0.8015267175572519, 'recall': 0.5653846153846154, 'f1-score': 0.6630581867388362, 'support': 1300, 'AUC': 0.8458420118343195, 'AUCPR': 0.7717277190908437, 'TP': 735, 'FP': 182, 'TN': 2418, 'FN': 565} 

2022-12-28 14:34: **********Val Epoch 6: average Loss: 0.577053
2022-12-28 14:38: 
 Testing metrics {'precision': 0.7399527186761229, 'recall': 0.7646579804560261, 'f1-score': 0.7521025230276331, 'support': 1228, 'AUC': 0.8758735172256469, 'AUCPR': 0.82306579087273, 'TP': 939, 'FP': 330, 'TN': 2126, 'FN': 289} 

2022-12-28 14:39: Train Epoch 7: 0/159 Loss: 0.236968
2022-12-28 14:40: Train Epoch 7: 1/159 Loss: 0.254074
2022-12-28 14:41: Train Epoch 7: 2/159 Loss: 0.332270
2022-12-28 14:42: Train Epoch 7: 3/159 Loss: 0.310309
2022-12-28 14:43: Train Epoch 7: 4/159 Loss: 0.255977
2022-12-28 14:44: Train Epoch 7: 5/159 Loss: 0.279891
2022-12-28 14:44: Train Epoch 7: 6/159 Loss: 0.409279
2022-12-28 14:45: Train Epoch 7: 7/159 Loss: 0.265478
2022-12-28 14:46: Train Epoch 7: 8/159 Loss: 0.288460
2022-12-28 14:47: Train Epoch 7: 9/159 Loss: 0.361239
2022-12-28 14:48: Train Epoch 7: 10/159 Loss: 0.260516
2022-12-28 14:49: Train Epoch 7: 11/159 Loss: 0.236664
2022-12-28 14:50: Train Epoch 7: 12/159 Loss: 0.381660
2022-12-28 14:50: Train Epoch 7: 13/159 Loss: 0.322087
2022-12-28 14:51: Train Epoch 7: 14/159 Loss: 0.318384
2022-12-28 14:52: Train Epoch 7: 15/159 Loss: 0.314563
2022-12-28 14:53: Train Epoch 7: 16/159 Loss: 0.272637
2022-12-28 14:54: Train Epoch 7: 17/159 Loss: 0.286793
2022-12-28 14:55: Train Epoch 7: 18/159 Loss: 0.368916
2022-12-28 14:56: Train Epoch 7: 19/159 Loss: 0.375588
