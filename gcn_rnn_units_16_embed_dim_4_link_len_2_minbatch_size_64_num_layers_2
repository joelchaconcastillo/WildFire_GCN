2023-01-03 13:18: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010313181006037354013
2023-01-03 13:18: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010313181006037354013
2023-01-03 13:18: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=4, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010313181006037354013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=2, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=16, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-03 13:18: Argument batch_size: 256
2023-01-03 13:18: Argument clc: 'vec'
2023-01-03 13:18: Argument cuda: True
2023-01-03 13:18: Argument dataset: '2020'
2023-01-03 13:18: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-03 13:18: Argument debug: False
2023-01-03 13:18: Argument default_graph: True
2023-01-03 13:18: Argument device: 'cpu'
2023-01-03 13:18: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-03 13:18: Argument early_stop: True
2023-01-03 13:18: Argument early_stop_patience: 8
2023-01-03 13:18: Argument embed_dim: 4
2023-01-03 13:18: Argument epochs: 30
2023-01-03 13:18: Argument grad_norm: False
2023-01-03 13:18: Argument horizon: 1
2023-01-03 13:18: Argument input_dim: 25
2023-01-03 13:18: Argument lag: 10
2023-01-03 13:18: Argument link_len: 2
2023-01-03 13:18: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010313181006037354013'
2023-01-03 13:18: Argument log_step: 1
2023-01-03 13:18: Argument loss_func: 'nllloss'
2023-01-03 13:18: Argument lr_decay: True
2023-01-03 13:18: Argument lr_decay_rate: 0.1
2023-01-03 13:18: Argument lr_decay_step: '15'
2023-01-03 13:18: Argument lr_init: 0.0001
2023-01-03 13:18: Argument max_grad_norm: 5
2023-01-03 13:18: Argument minbatch_size: 64
2023-01-03 13:18: Argument mode: 'train'
2023-01-03 13:18: Argument model: 'fire_GCN'
2023-01-03 13:18: Argument nan_fill: -1.0
2023-01-03 13:18: Argument num_layers: 2
2023-01-03 13:18: Argument num_nodes: 625
2023-01-03 13:18: Argument num_workers: 12
2023-01-03 13:18: Argument output_dim: 2
2023-01-03 13:18: Argument patch_height: 25
2023-01-03 13:18: Argument patch_width: 25
2023-01-03 13:18: Argument persistent_workers: True
2023-01-03 13:18: Argument pin_memory: True
2023-01-03 13:18: Argument plot: False
2023-01-03 13:18: Argument positive_weight: 0.5
2023-01-03 13:18: Argument prefetch_factor: 2
2023-01-03 13:18: Argument real_value: True
2023-01-03 13:18: Argument rnn_units: 16
2023-01-03 13:18: Argument seed: 10000
2023-01-03 13:18: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-03 13:18: Argument teacher_forcing: False
2023-01-03 13:18: Argument weight_decay: 0.0
2023-01-03 13:18: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 4]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([4, 2, 41, 16]) True
encoder.cell_list.0.gate.weights_window torch.Size([4, 1, 16]) True
encoder.cell_list.0.gate.bias_pool torch.Size([4, 32]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([4, 2, 41, 8]) True
encoder.cell_list.0.update.weights_window torch.Size([4, 1, 8]) True
encoder.cell_list.0.update.bias_pool torch.Size([4, 16]) True
encoder.cell_list.0.update.T torch.Size([10]) True
encoder.cell_list.1.gate.weights_pool torch.Size([4, 2, 32, 16]) True
encoder.cell_list.1.gate.weights_window torch.Size([4, 16, 16]) True
encoder.cell_list.1.gate.bias_pool torch.Size([4, 32]) True
encoder.cell_list.1.gate.T torch.Size([10]) True
encoder.cell_list.1.update.weights_pool torch.Size([4, 2, 32, 8]) True
encoder.cell_list.1.update.weights_window torch.Size([4, 16, 8]) True
encoder.cell_list.1.update.bias_pool torch.Size([4, 16]) True
encoder.cell_list.1.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 10000]) True
fc1.bias torch.Size([2]) True
Total params num: 38624
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010313181006037354013/run.log
2023-01-03 13:18: Train Epoch 1: 3/634 Loss: 0.390851
2023-01-03 13:18: Train Epoch 1: 7/634 Loss: 0.320084
2023-01-03 13:18: Train Epoch 1: 11/634 Loss: 0.297985
2023-01-03 13:18: Train Epoch 1: 15/634 Loss: 0.332350
2023-01-03 13:19: Train Epoch 1: 19/634 Loss: 0.348059
2023-01-03 13:19: Train Epoch 1: 23/634 Loss: 0.360016
2023-01-03 13:19: Train Epoch 1: 27/634 Loss: 0.295293
2023-01-03 13:19: Train Epoch 1: 31/634 Loss: 0.261677
2023-01-03 13:19: Train Epoch 1: 35/634 Loss: 0.284079
2023-01-03 13:19: Train Epoch 1: 39/634 Loss: 0.283827
2023-01-03 13:20: Train Epoch 1: 43/634 Loss: 0.285673
2023-01-03 13:20: Train Epoch 1: 47/634 Loss: 0.279115
2023-01-03 13:20: Train Epoch 1: 51/634 Loss: 0.295550
2023-01-03 13:20: Train Epoch 1: 55/634 Loss: 0.274316
2023-01-03 13:20: Train Epoch 1: 59/634 Loss: 0.271455
2023-01-03 13:20: Train Epoch 1: 63/634 Loss: 0.261804
2023-01-03 13:21: Train Epoch 1: 67/634 Loss: 0.249994
2023-01-03 13:21: Train Epoch 1: 71/634 Loss: 0.259470
2023-01-03 13:21: Train Epoch 1: 75/634 Loss: 0.264837
2023-01-03 13:21: Train Epoch 1: 79/634 Loss: 0.235996
2023-01-03 13:21: Train Epoch 1: 83/634 Loss: 0.244232
2023-01-03 13:21: Train Epoch 1: 87/634 Loss: 0.232684
2023-01-03 13:22: Train Epoch 1: 91/634 Loss: 0.236045
2023-01-03 13:22: Train Epoch 1: 95/634 Loss: 0.226559
2023-01-03 13:22: Train Epoch 1: 99/634 Loss: 0.250414
2023-01-03 13:22: Train Epoch 1: 103/634 Loss: 0.228338
2023-01-03 13:22: Train Epoch 1: 107/634 Loss: 0.230436
2023-01-03 13:22: Train Epoch 1: 111/634 Loss: 0.235525
2023-01-03 13:22: Train Epoch 1: 115/634 Loss: 0.233534
2023-01-03 13:23: Train Epoch 1: 119/634 Loss: 0.233171
2023-01-03 13:23: Train Epoch 1: 123/634 Loss: 0.231112
2023-01-03 13:23: Train Epoch 1: 127/634 Loss: 0.214312
2023-01-03 13:23: Train Epoch 1: 131/634 Loss: 0.222853
2023-01-03 13:23: Train Epoch 1: 135/634 Loss: 0.207678
2023-01-03 13:23: Train Epoch 1: 139/634 Loss: 0.198990
2023-01-03 13:24: Train Epoch 1: 143/634 Loss: 0.220140
2023-01-03 13:24: Train Epoch 1: 147/634 Loss: 0.199518
2023-01-03 13:24: Train Epoch 1: 151/634 Loss: 0.204795
2023-01-03 13:24: Train Epoch 1: 155/634 Loss: 0.190385
2023-01-03 13:24: Train Epoch 1: 159/634 Loss: 0.188044
2023-01-03 13:24: Train Epoch 1: 163/634 Loss: 0.196047
2023-01-03 13:25: Train Epoch 1: 167/634 Loss: 0.188619
2023-01-03 13:25: Train Epoch 1: 171/634 Loss: 0.208998
2023-01-03 13:25: Train Epoch 1: 175/634 Loss: 0.166543
2023-01-03 13:25: Train Epoch 1: 179/634 Loss: 0.185263
2023-01-03 13:25: Train Epoch 1: 183/634 Loss: 0.204755
2023-01-03 13:25: Train Epoch 1: 187/634 Loss: 0.177671
2023-01-03 13:25: Train Epoch 1: 191/634 Loss: 0.193404
2023-01-03 13:26: Train Epoch 1: 195/634 Loss: 0.185883
2023-01-03 13:26: Train Epoch 1: 199/634 Loss: 0.187818
2023-01-03 13:26: Train Epoch 1: 203/634 Loss: 0.176964
2023-01-03 13:26: Train Epoch 1: 207/634 Loss: 0.189783
2023-01-03 13:26: Train Epoch 1: 211/634 Loss: 0.195504
2023-01-03 13:26: Train Epoch 1: 215/634 Loss: 0.171717
2023-01-03 13:27: Train Epoch 1: 219/634 Loss: 0.188868
2023-01-03 13:27: Train Epoch 1: 223/634 Loss: 0.177001
2023-01-03 13:27: Train Epoch 1: 227/634 Loss: 0.190991
2023-01-03 13:27: Train Epoch 1: 231/634 Loss: 0.186627
2023-01-03 13:27: Train Epoch 1: 235/634 Loss: 0.180234
2023-01-03 13:28: Train Epoch 1: 239/634 Loss: 0.186256
2023-01-03 13:28: Train Epoch 1: 243/634 Loss: 0.195443
2023-01-03 13:28: Train Epoch 1: 247/634 Loss: 0.201771
2023-01-03 13:28: Train Epoch 1: 251/634 Loss: 0.158936
2023-01-03 13:28: Train Epoch 1: 255/634 Loss: 0.136343
2023-01-03 13:28: Train Epoch 1: 259/634 Loss: 0.166566
2023-01-03 13:28: Train Epoch 1: 263/634 Loss: 0.150390
2023-01-03 13:29: Train Epoch 1: 267/634 Loss: 0.158201
2023-01-03 13:29: Train Epoch 1: 271/634 Loss: 0.149173
2023-01-03 13:29: Train Epoch 1: 275/634 Loss: 0.174855
2023-01-03 13:29: Train Epoch 1: 279/634 Loss: 0.159796
2023-01-03 13:29: Train Epoch 1: 283/634 Loss: 0.180322
2023-01-03 13:30: Train Epoch 1: 287/634 Loss: 0.162900
2023-01-03 13:30: Train Epoch 1: 291/634 Loss: 0.190139
2023-01-03 13:30: Train Epoch 1: 295/634 Loss: 0.174360
2023-01-03 13:30: Train Epoch 1: 299/634 Loss: 0.156908
2023-01-03 13:30: Train Epoch 1: 303/634 Loss: 0.165158
2023-01-03 13:31: Train Epoch 1: 307/634 Loss: 0.171163
2023-01-03 13:31: Train Epoch 1: 311/634 Loss: 0.149459
2023-01-03 13:31: Train Epoch 1: 315/634 Loss: 0.163662
2023-01-03 13:31: Train Epoch 1: 319/634 Loss: 0.149763
2023-01-03 13:31: Train Epoch 1: 323/634 Loss: 0.163085
2023-01-03 13:31: Train Epoch 1: 327/634 Loss: 0.171518
2023-01-03 13:32: Train Epoch 1: 331/634 Loss: 0.175292
2023-01-03 13:32: Train Epoch 1: 335/634 Loss: 0.141671
2023-01-03 13:32: Train Epoch 1: 339/634 Loss: 0.157410
2023-01-03 13:32: Train Epoch 1: 343/634 Loss: 0.149494
2023-01-03 13:32: Train Epoch 1: 347/634 Loss: 0.169927
2023-01-03 13:32: Train Epoch 1: 351/634 Loss: 0.150275
2023-01-03 13:33: Train Epoch 1: 355/634 Loss: 0.168944
2023-01-03 13:33: Train Epoch 1: 359/634 Loss: 0.153637
2023-01-03 13:33: Train Epoch 1: 363/634 Loss: 0.135974
2023-01-03 13:33: Train Epoch 1: 367/634 Loss: 0.173065
2023-01-03 13:33: Train Epoch 1: 371/634 Loss: 0.185584
2023-01-03 13:33: Train Epoch 1: 375/634 Loss: 0.176402
2023-01-03 13:34: Train Epoch 1: 379/634 Loss: 0.166559
2023-01-03 13:34: Train Epoch 1: 383/634 Loss: 0.149266
2023-01-03 13:34: Train Epoch 1: 387/634 Loss: 0.185002
2023-01-03 13:34: Train Epoch 1: 391/634 Loss: 0.145175
2023-01-03 13:34: Train Epoch 1: 395/634 Loss: 0.155282
2023-01-03 13:34: Train Epoch 1: 399/634 Loss: 0.161823
2023-01-03 13:35: Train Epoch 1: 403/634 Loss: 0.152291
2023-01-03 13:35: Train Epoch 1: 407/634 Loss: 0.151020
2023-01-03 13:35: Train Epoch 1: 411/634 Loss: 0.134238
2023-01-03 13:35: Train Epoch 1: 415/634 Loss: 0.146431
2023-01-03 13:35: Train Epoch 1: 419/634 Loss: 0.166424
2023-01-03 13:35: Train Epoch 1: 423/634 Loss: 0.179216
2023-01-03 13:35: Train Epoch 1: 427/634 Loss: 0.152947
2023-01-03 13:36: Train Epoch 1: 431/634 Loss: 0.185515
2023-01-03 13:36: Train Epoch 1: 435/634 Loss: 0.147518
2023-01-03 13:36: Train Epoch 1: 439/634 Loss: 0.172451
2023-01-03 13:36: Train Epoch 1: 443/634 Loss: 0.144881
2023-01-03 13:36: Train Epoch 1: 447/634 Loss: 0.147955
2023-01-03 13:36: Train Epoch 1: 451/634 Loss: 0.165612
2023-01-03 13:37: Train Epoch 1: 455/634 Loss: 0.155972
2023-01-03 13:37: Train Epoch 1: 459/634 Loss: 0.164964
2023-01-03 13:37: Train Epoch 1: 463/634 Loss: 0.179110
2023-01-03 13:37: Train Epoch 1: 467/634 Loss: 0.152686
2023-01-03 13:37: Train Epoch 1: 471/634 Loss: 0.147795
2023-01-03 13:37: Train Epoch 1: 475/634 Loss: 0.143715
2023-01-03 13:38: Train Epoch 1: 479/634 Loss: 0.157972
2023-01-03 13:38: Train Epoch 1: 483/634 Loss: 0.153237
2023-01-03 13:38: Train Epoch 1: 487/634 Loss: 0.136342
2023-01-03 13:38: Train Epoch 1: 491/634 Loss: 0.150835
2023-01-03 13:38: Train Epoch 1: 495/634 Loss: 0.143670
2023-01-03 13:38: Train Epoch 1: 499/634 Loss: 0.156494
2023-01-03 13:39: Train Epoch 1: 503/634 Loss: 0.163570
2023-01-03 13:39: Train Epoch 1: 507/634 Loss: 0.165117
2023-01-03 13:39: Train Epoch 1: 511/634 Loss: 0.183110
2023-01-03 13:39: Train Epoch 1: 515/634 Loss: 0.146583
2023-01-03 13:39: Train Epoch 1: 519/634 Loss: 0.179607
2023-01-03 13:39: Train Epoch 1: 523/634 Loss: 0.170058
2023-01-03 13:39: Train Epoch 1: 527/634 Loss: 0.141365
2023-01-03 13:40: Train Epoch 1: 531/634 Loss: 0.161667
2023-01-03 13:40: Train Epoch 1: 535/634 Loss: 0.137381
2023-01-03 13:40: Train Epoch 1: 539/634 Loss: 0.149813
2023-01-03 13:40: Train Epoch 1: 543/634 Loss: 0.168424
2023-01-03 13:40: Train Epoch 1: 547/634 Loss: 0.128481
2023-01-03 13:40: Train Epoch 1: 551/634 Loss: 0.157367
2023-01-03 13:41: Train Epoch 1: 555/634 Loss: 0.139503
2023-01-03 13:41: Train Epoch 1: 559/634 Loss: 0.146277
2023-01-03 13:41: Train Epoch 1: 563/634 Loss: 0.128254
2023-01-03 13:41: Train Epoch 1: 567/634 Loss: 0.148158
2023-01-03 13:41: Train Epoch 1: 571/634 Loss: 0.151692
2023-01-03 13:41: Train Epoch 1: 575/634 Loss: 0.167365
2023-01-03 13:42: Train Epoch 1: 579/634 Loss: 0.124147
2023-01-03 13:42: Train Epoch 1: 583/634 Loss: 0.123825
2023-01-03 13:42: Train Epoch 1: 587/634 Loss: 0.133128
2023-01-03 13:42: Train Epoch 1: 591/634 Loss: 0.150653
2023-01-03 13:42: Train Epoch 1: 595/634 Loss: 0.140486
2023-01-03 13:42: Train Epoch 1: 599/634 Loss: 0.157281
2023-01-03 13:43: Train Epoch 1: 603/634 Loss: 0.136608
2023-01-03 13:43: Train Epoch 1: 607/634 Loss: 0.153868
2023-01-03 13:43: Train Epoch 1: 611/634 Loss: 0.142531
2023-01-03 13:43: Train Epoch 1: 615/634 Loss: 0.164283
2023-01-03 13:43: Train Epoch 1: 619/634 Loss: 0.145181
2023-01-03 13:43: Train Epoch 1: 623/634 Loss: 0.119772
2023-01-03 13:43: Train Epoch 1: 627/634 Loss: 0.167156
2023-01-03 13:44: Train Epoch 1: 631/634 Loss: 0.153931
2023-01-03 13:44: Train Epoch 1: 633/634 Loss: 0.058184
2023-01-03 13:44: **********Train Epoch 1: averaged Loss: 0.185314 
2023-01-03 13:44: 
Epoch time elapsed: 1557.3027470111847

2023-01-03 13:45: 
 metrics validation: {'precision': 0.7058340180772391, 'recall': 0.6607692307692308, 'f1-score': 0.6825586015097338, 'support': 1300, 'AUC': 0.8389550295857988, 'AUCPR': 0.7598456739498025, 'TP': 859, 'FP': 358, 'TN': 2242, 'FN': 441} 

2023-01-03 13:45: **********Val Epoch 1: average Loss: 0.237921
2023-01-03 13:45: *********************************Current best model saved!
2023-01-03 13:46: 
 Testing metrics {'precision': 0.7495361781076066, 'recall': 0.6579804560260586, 'f1-score': 0.7007805724197744, 'support': 1228, 'AUC': 0.8620943590913432, 'AUCPR': 0.7761471174049772, 'TP': 808, 'FP': 270, 'TN': 2186, 'FN': 420} 

2023-01-03 13:49: 
 Testing metrics {'precision': 0.8705258506407424, 'recall': 0.8940322214658498, 'f1-score': 0.8821224672562409, 'support': 4407, 'AUC': 0.9639009411610724, 'AUCPR': 0.9238585897121007, 'TP': 3940, 'FP': 586, 'TN': 8228, 'FN': 467} 

2023-01-03 13:49: Train Epoch 2: 3/634 Loss: 0.136365
2023-01-03 13:50: Train Epoch 2: 7/634 Loss: 0.150396
2023-01-03 13:50: Train Epoch 2: 11/634 Loss: 0.128625
2023-01-03 13:50: Train Epoch 2: 15/634 Loss: 0.135925
2023-01-03 13:50: Train Epoch 2: 19/634 Loss: 0.146011
2023-01-03 13:51: Train Epoch 2: 23/634 Loss: 0.140480
2023-01-03 13:51: Train Epoch 2: 27/634 Loss: 0.146522
2023-01-03 13:51: Train Epoch 2: 31/634 Loss: 0.158027
2023-01-03 13:51: Train Epoch 2: 35/634 Loss: 0.152876
2023-01-03 13:52: Train Epoch 2: 39/634 Loss: 0.140654
2023-01-03 13:52: Train Epoch 2: 43/634 Loss: 0.132929
2023-01-03 13:52: Train Epoch 2: 47/634 Loss: 0.164187
2023-01-03 13:52: Train Epoch 2: 51/634 Loss: 0.136275
2023-01-03 13:53: Train Epoch 2: 55/634 Loss: 0.124357
2023-01-03 13:53: Train Epoch 2: 59/634 Loss: 0.148531
2023-01-03 13:53: Train Epoch 2: 63/634 Loss: 0.145352
2023-01-03 13:53: Train Epoch 2: 67/634 Loss: 0.124138
2023-01-03 13:53: Train Epoch 2: 71/634 Loss: 0.121866
2023-01-03 13:54: Train Epoch 2: 75/634 Loss: 0.124403
2023-01-03 13:54: Train Epoch 2: 79/634 Loss: 0.142551
2023-01-03 13:54: Train Epoch 2: 83/634 Loss: 0.139626
2023-01-03 13:54: Train Epoch 2: 87/634 Loss: 0.154985
2023-01-03 13:55: Train Epoch 2: 91/634 Loss: 0.163331
2023-01-03 13:55: Train Epoch 2: 95/634 Loss: 0.145489
2023-01-03 13:55: Train Epoch 2: 99/634 Loss: 0.146735
2023-01-03 13:55: Train Epoch 2: 103/634 Loss: 0.106769
2023-01-03 13:56: Train Epoch 2: 107/634 Loss: 0.141016
2023-01-03 13:56: Train Epoch 2: 111/634 Loss: 0.163379
2023-01-03 13:56: Train Epoch 2: 115/634 Loss: 0.153321
2023-01-03 13:56: Train Epoch 2: 119/634 Loss: 0.178467
2023-01-03 13:57: Train Epoch 2: 123/634 Loss: 0.165226
2023-01-03 13:57: Train Epoch 2: 127/634 Loss: 0.160921
2023-01-03 13:57: Train Epoch 2: 131/634 Loss: 0.138934
2023-01-03 13:57: Train Epoch 2: 135/634 Loss: 0.131331
2023-01-03 13:57: Train Epoch 2: 139/634 Loss: 0.115746
2023-01-03 13:58: Train Epoch 2: 143/634 Loss: 0.170706
2023-01-03 13:58: Train Epoch 2: 147/634 Loss: 0.151153
2023-01-03 13:58: Train Epoch 2: 151/634 Loss: 0.134888
2023-01-03 13:58: Train Epoch 2: 155/634 Loss: 0.138021
2023-01-03 13:59: Train Epoch 2: 159/634 Loss: 0.152490
2023-01-03 13:59: Train Epoch 2: 163/634 Loss: 0.158042
2023-01-03 13:59: Train Epoch 2: 167/634 Loss: 0.168834
2023-01-03 13:59: Train Epoch 2: 171/634 Loss: 0.141200
2023-01-03 13:59: Train Epoch 2: 175/634 Loss: 0.116166
2023-01-03 14:00: Train Epoch 2: 179/634 Loss: 0.142232
2023-01-03 14:00: Train Epoch 2: 183/634 Loss: 0.129266
2023-01-03 14:00: Train Epoch 2: 187/634 Loss: 0.143602
2023-01-03 14:00: Train Epoch 2: 191/634 Loss: 0.125486
2023-01-03 14:01: Train Epoch 2: 195/634 Loss: 0.147020
2023-01-03 14:01: Train Epoch 2: 199/634 Loss: 0.158919
2023-01-03 14:01: Train Epoch 2: 203/634 Loss: 0.127277
2023-01-03 14:01: Train Epoch 2: 207/634 Loss: 0.158789
2023-01-03 14:02: Train Epoch 2: 211/634 Loss: 0.139237
2023-01-03 14:02: Train Epoch 2: 215/634 Loss: 0.146061
2023-01-03 14:02: Train Epoch 2: 219/634 Loss: 0.142132
2023-01-03 14:02: Train Epoch 2: 223/634 Loss: 0.154674
2023-01-03 14:03: Train Epoch 2: 227/634 Loss: 0.141693
2023-01-03 14:03: Train Epoch 2: 231/634 Loss: 0.165400
2023-01-03 14:03: Train Epoch 2: 235/634 Loss: 0.166203
2023-01-03 14:03: Train Epoch 2: 239/634 Loss: 0.137627
2023-01-03 14:03: Train Epoch 2: 243/634 Loss: 0.124046
2023-01-03 14:04: Train Epoch 2: 247/634 Loss: 0.134289
2023-01-03 14:04: Train Epoch 2: 251/634 Loss: 0.148174
2023-01-03 14:04: Train Epoch 2: 255/634 Loss: 0.143773
2023-01-03 14:04: Train Epoch 2: 259/634 Loss: 0.133234
2023-01-03 14:05: Train Epoch 2: 263/634 Loss: 0.179679
2023-01-03 14:05: Train Epoch 2: 267/634 Loss: 0.165000
2023-01-03 14:05: Train Epoch 2: 271/634 Loss: 0.132670
2023-01-03 14:05: Train Epoch 2: 275/634 Loss: 0.142003
2023-01-03 14:06: Train Epoch 2: 279/634 Loss: 0.128862
2023-01-03 14:06: Train Epoch 2: 283/634 Loss: 0.155624
2023-01-03 14:06: Train Epoch 2: 287/634 Loss: 0.128213
2023-01-03 14:06: Train Epoch 2: 291/634 Loss: 0.129459
2023-01-03 14:06: Train Epoch 2: 295/634 Loss: 0.157854
2023-01-03 14:07: Train Epoch 2: 299/634 Loss: 0.141694
2023-01-03 14:07: Train Epoch 2: 303/634 Loss: 0.150542
2023-01-03 14:07: Train Epoch 2: 307/634 Loss: 0.119778
2023-01-03 14:07: Train Epoch 2: 311/634 Loss: 0.163175
2023-01-03 14:08: Train Epoch 2: 315/634 Loss: 0.135027
2023-01-03 14:08: Train Epoch 2: 319/634 Loss: 0.116733
2023-01-03 14:08: Train Epoch 2: 323/634 Loss: 0.110949
2023-01-03 14:08: Train Epoch 2: 327/634 Loss: 0.129936
2023-01-03 14:09: Train Epoch 2: 331/634 Loss: 0.149895
2023-01-03 14:09: Train Epoch 2: 335/634 Loss: 0.116675
2023-01-03 14:09: Train Epoch 2: 339/634 Loss: 0.125886
2023-01-03 14:09: Train Epoch 2: 343/634 Loss: 0.156354
2023-01-03 14:09: Train Epoch 2: 347/634 Loss: 0.135112
2023-01-03 14:10: Train Epoch 2: 351/634 Loss: 0.136673
2023-01-03 14:10: Train Epoch 2: 355/634 Loss: 0.156293
2023-01-03 14:10: Train Epoch 2: 359/634 Loss: 0.123384
2023-01-03 14:10: Train Epoch 2: 363/634 Loss: 0.126341
2023-01-03 14:11: Train Epoch 2: 367/634 Loss: 0.187238
2023-01-03 14:11: Train Epoch 2: 371/634 Loss: 0.129812
2023-01-03 14:11: Train Epoch 2: 375/634 Loss: 0.133179
2023-01-03 14:11: Train Epoch 2: 379/634 Loss: 0.144242
2023-01-03 14:12: Train Epoch 2: 383/634 Loss: 0.094872
2023-01-03 14:12: Train Epoch 2: 387/634 Loss: 0.162236
2023-01-03 14:12: Train Epoch 2: 391/634 Loss: 0.152393
2023-01-03 14:12: Train Epoch 2: 395/634 Loss: 0.119879
2023-01-03 14:12: Train Epoch 2: 399/634 Loss: 0.174369
2023-01-03 14:13: Train Epoch 2: 403/634 Loss: 0.134640
2023-01-03 14:13: Train Epoch 2: 407/634 Loss: 0.165014
2023-01-03 14:13: Train Epoch 2: 411/634 Loss: 0.182624
2023-01-03 14:13: Train Epoch 2: 415/634 Loss: 0.163541
2023-01-03 14:14: Train Epoch 2: 419/634 Loss: 0.131433
2023-01-03 14:14: Train Epoch 2: 423/634 Loss: 0.119518
2023-01-03 14:14: Train Epoch 2: 427/634 Loss: 0.139945
2023-01-03 14:14: Train Epoch 2: 431/634 Loss: 0.136818
2023-01-03 14:14: Train Epoch 2: 435/634 Loss: 0.135515
2023-01-03 14:15: Train Epoch 2: 439/634 Loss: 0.130160
2023-01-03 14:15: Train Epoch 2: 443/634 Loss: 0.130565
2023-01-03 14:15: Train Epoch 2: 447/634 Loss: 0.103246
2023-01-03 14:15: Train Epoch 2: 451/634 Loss: 0.152320
2023-01-03 14:16: Train Epoch 2: 455/634 Loss: 0.142977
2023-01-03 14:16: Train Epoch 2: 459/634 Loss: 0.182841
2023-01-03 14:16: Train Epoch 2: 463/634 Loss: 0.124497
2023-01-03 14:16: Train Epoch 2: 467/634 Loss: 0.150182
2023-01-03 14:17: Train Epoch 2: 471/634 Loss: 0.143361
2023-01-03 14:17: Train Epoch 2: 475/634 Loss: 0.163667
2023-01-03 14:17: Train Epoch 2: 479/634 Loss: 0.135432
2023-01-03 14:17: Train Epoch 2: 483/634 Loss: 0.162158
2023-01-03 14:17: Train Epoch 2: 487/634 Loss: 0.122133
2023-01-03 14:18: Train Epoch 2: 491/634 Loss: 0.120409
2023-01-03 14:18: Train Epoch 2: 495/634 Loss: 0.106748
2023-01-03 14:18: Train Epoch 2: 499/634 Loss: 0.117095
2023-01-03 14:18: Train Epoch 2: 503/634 Loss: 0.155589
2023-01-03 14:19: Train Epoch 2: 507/634 Loss: 0.132344
2023-01-03 14:19: Train Epoch 2: 511/634 Loss: 0.135263
2023-01-03 14:19: Train Epoch 2: 515/634 Loss: 0.114060
2023-01-03 14:19: Train Epoch 2: 519/634 Loss: 0.125829
2023-01-03 14:20: Train Epoch 2: 523/634 Loss: 0.121307
2023-01-03 14:20: Train Epoch 2: 527/634 Loss: 0.140658
2023-01-03 14:20: Train Epoch 2: 531/634 Loss: 0.121082
2023-01-03 14:20: Train Epoch 2: 535/634 Loss: 0.129313
2023-01-03 14:21: Train Epoch 2: 539/634 Loss: 0.142934
2023-01-03 14:21: Train Epoch 2: 543/634 Loss: 0.110185
2023-01-03 14:21: Train Epoch 2: 547/634 Loss: 0.143292
2023-01-03 14:21: Train Epoch 2: 551/634 Loss: 0.141394
2023-01-03 14:21: Train Epoch 2: 555/634 Loss: 0.134608
2023-01-03 14:22: Train Epoch 2: 559/634 Loss: 0.112313
2023-01-03 14:22: Train Epoch 2: 563/634 Loss: 0.155199
2023-01-03 14:22: Train Epoch 2: 567/634 Loss: 0.154695
2023-01-03 14:22: Train Epoch 2: 571/634 Loss: 0.128261
2023-01-03 14:23: Train Epoch 2: 575/634 Loss: 0.144075
2023-01-03 14:23: Train Epoch 2: 579/634 Loss: 0.103930
2023-01-03 14:23: Train Epoch 2: 583/634 Loss: 0.117843
2023-01-03 14:23: Train Epoch 2: 587/634 Loss: 0.131796
2023-01-03 14:24: Train Epoch 2: 591/634 Loss: 0.160192
2023-01-03 14:24: Train Epoch 2: 595/634 Loss: 0.129082
2023-01-03 14:24: Train Epoch 2: 599/634 Loss: 0.115643
2023-01-03 14:24: Train Epoch 2: 603/634 Loss: 0.161183
2023-01-03 14:24: Train Epoch 2: 607/634 Loss: 0.133962
2023-01-03 14:25: Train Epoch 2: 611/634 Loss: 0.148672
2023-01-03 14:25: Train Epoch 2: 615/634 Loss: 0.115745
2023-01-03 14:25: Train Epoch 2: 619/634 Loss: 0.144346
2023-01-03 14:25: Train Epoch 2: 623/634 Loss: 0.148438
2023-01-03 14:26: Train Epoch 2: 627/634 Loss: 0.149819
2023-01-03 14:26: Train Epoch 2: 631/634 Loss: 0.123352
2023-01-03 14:26: Train Epoch 2: 633/634 Loss: 0.068375
2023-01-03 14:26: **********Train Epoch 2: averaged Loss: 0.139937 
2023-01-03 14:26: 
Epoch time elapsed: 2208.461014032364

2023-01-03 14:27: 
 metrics validation: {'precision': 0.7959798994974875, 'recall': 0.6092307692307692, 'f1-score': 0.6901960784313727, 'support': 1300, 'AUC': 0.8598497041420118, 'AUCPR': 0.786746579167765, 'TP': 792, 'FP': 203, 'TN': 2397, 'FN': 508} 

2023-01-03 14:27: **********Val Epoch 2: average Loss: 0.232013
2023-01-03 14:27: *********************************Current best model saved!
2023-01-03 14:28: 
 Testing metrics {'precision': 0.8245412844036697, 'recall': 0.5855048859934854, 'f1-score': 0.6847619047619048, 'support': 1228, 'AUC': 0.8752322637375463, 'AUCPR': 0.7997754822413753, 'TP': 719, 'FP': 153, 'TN': 2303, 'FN': 509} 

2023-01-03 14:32: 
 Testing metrics {'precision': 0.9124595871673713, 'recall': 0.8325391422736556, 'f1-score': 0.8706691979117228, 'support': 4407, 'AUC': 0.9681812548460742, 'AUCPR': 0.9338775131089453, 'TP': 3669, 'FP': 352, 'TN': 8462, 'FN': 738} 

2023-01-03 14:32: Train Epoch 3: 3/634 Loss: 0.155672
2023-01-03 14:32: Train Epoch 3: 7/634 Loss: 0.158942
2023-01-03 14:32: Train Epoch 3: 11/634 Loss: 0.118677
2023-01-03 14:33: Train Epoch 3: 15/634 Loss: 0.109171
2023-01-03 14:33: Train Epoch 3: 19/634 Loss: 0.127377
2023-01-03 14:33: Train Epoch 3: 23/634 Loss: 0.153841
2023-01-03 14:33: Train Epoch 3: 27/634 Loss: 0.131073
2023-01-03 14:34: Train Epoch 3: 31/634 Loss: 0.165514
2023-01-03 14:34: Train Epoch 3: 35/634 Loss: 0.154344
2023-01-03 14:34: Train Epoch 3: 39/634 Loss: 0.126114
2023-01-03 14:34: Train Epoch 3: 43/634 Loss: 0.115368
2023-01-03 14:35: Train Epoch 3: 47/634 Loss: 0.121905
2023-01-03 14:35: Train Epoch 3: 51/634 Loss: 0.157479
2023-01-03 14:35: Train Epoch 3: 55/634 Loss: 0.143387
2023-01-03 14:35: Train Epoch 3: 59/634 Loss: 0.123031
2023-01-03 14:35: Train Epoch 3: 63/634 Loss: 0.112736
2023-01-03 14:36: Train Epoch 3: 67/634 Loss: 0.125065
2023-01-03 14:36: Train Epoch 3: 71/634 Loss: 0.118536
2023-01-03 14:36: Train Epoch 3: 75/634 Loss: 0.117852
2023-01-03 14:36: Train Epoch 3: 79/634 Loss: 0.142036
2023-01-03 14:37: Train Epoch 3: 83/634 Loss: 0.135092
2023-01-03 14:37: Train Epoch 3: 87/634 Loss: 0.127709
2023-01-03 14:37: Train Epoch 3: 91/634 Loss: 0.137361
2023-01-03 14:37: Train Epoch 3: 95/634 Loss: 0.129020
2023-01-03 14:38: Train Epoch 3: 99/634 Loss: 0.110841
2023-01-03 14:38: Train Epoch 3: 103/634 Loss: 0.142056
2023-01-03 14:38: Train Epoch 3: 107/634 Loss: 0.128536
2023-01-03 14:38: Train Epoch 3: 111/634 Loss: 0.138838
2023-01-03 14:38: Train Epoch 3: 115/634 Loss: 0.130966
2023-01-03 14:39: Train Epoch 3: 119/634 Loss: 0.122942
2023-01-03 14:39: Train Epoch 3: 123/634 Loss: 0.131723
2023-01-03 14:39: Train Epoch 3: 127/634 Loss: 0.126601
2023-01-03 14:39: Train Epoch 3: 131/634 Loss: 0.134154
2023-01-03 14:40: Train Epoch 3: 135/634 Loss: 0.120871
2023-01-03 14:40: Train Epoch 3: 139/634 Loss: 0.115820
2023-01-03 14:40: Train Epoch 3: 143/634 Loss: 0.134008
2023-01-03 14:40: Train Epoch 3: 147/634 Loss: 0.125487
2023-01-03 14:40: Train Epoch 3: 151/634 Loss: 0.126189
2023-01-03 14:41: Train Epoch 3: 155/634 Loss: 0.161978
2023-01-03 14:41: Train Epoch 3: 159/634 Loss: 0.116692
2023-01-03 14:41: Train Epoch 3: 163/634 Loss: 0.113256
2023-01-03 14:41: Train Epoch 3: 167/634 Loss: 0.115584
2023-01-03 14:42: Train Epoch 3: 171/634 Loss: 0.139831
2023-01-03 14:42: Train Epoch 3: 175/634 Loss: 0.104122
2023-01-03 14:42: Train Epoch 3: 179/634 Loss: 0.120861
2023-01-03 14:42: Train Epoch 3: 183/634 Loss: 0.154134
2023-01-03 14:43: Train Epoch 3: 187/634 Loss: 0.151038
2023-01-03 14:43: Train Epoch 3: 191/634 Loss: 0.113401
2023-01-03 14:43: Train Epoch 3: 195/634 Loss: 0.153185
2023-01-03 14:43: Train Epoch 3: 199/634 Loss: 0.128412
2023-01-03 14:44: Train Epoch 3: 203/634 Loss: 0.119627
2023-01-03 14:44: Train Epoch 3: 207/634 Loss: 0.135224
2023-01-03 14:44: Train Epoch 3: 211/634 Loss: 0.143596
2023-01-03 14:44: Train Epoch 3: 215/634 Loss: 0.113417
2023-01-03 14:44: Train Epoch 3: 219/634 Loss: 0.108185
2023-01-03 14:45: Train Epoch 3: 223/634 Loss: 0.165867
2023-01-03 14:45: Train Epoch 3: 227/634 Loss: 0.146754
2023-01-03 14:45: Train Epoch 3: 231/634 Loss: 0.116826
2023-01-03 14:45: Train Epoch 3: 235/634 Loss: 0.141980
2023-01-03 14:46: Train Epoch 3: 239/634 Loss: 0.123361
2023-01-03 14:46: Train Epoch 3: 243/634 Loss: 0.117989
2023-01-03 14:46: Train Epoch 3: 247/634 Loss: 0.142982
2023-01-03 14:46: Train Epoch 3: 251/634 Loss: 0.144208
2023-01-03 14:47: Train Epoch 3: 255/634 Loss: 0.112271
2023-01-03 14:47: Train Epoch 3: 259/634 Loss: 0.115191
2023-01-03 14:47: Train Epoch 3: 263/634 Loss: 0.138660
2023-01-03 14:47: Train Epoch 3: 267/634 Loss: 0.126683
2023-01-03 14:48: Train Epoch 3: 271/634 Loss: 0.141523
2023-01-03 14:48: Train Epoch 3: 275/634 Loss: 0.133442
2023-01-03 14:48: Train Epoch 3: 279/634 Loss: 0.120765
2023-01-03 14:48: Train Epoch 3: 283/634 Loss: 0.126999
2023-01-03 14:49: Train Epoch 3: 287/634 Loss: 0.124697
2023-01-03 14:49: Train Epoch 3: 291/634 Loss: 0.128031
2023-01-03 14:49: Train Epoch 3: 295/634 Loss: 0.131765
2023-01-03 14:49: Train Epoch 3: 299/634 Loss: 0.133408
2023-01-03 14:50: Train Epoch 3: 303/634 Loss: 0.129881
2023-01-03 14:50: Train Epoch 3: 307/634 Loss: 0.137116
2023-01-03 14:50: Train Epoch 3: 311/634 Loss: 0.130960
2023-01-03 14:50: Train Epoch 3: 315/634 Loss: 0.110786
2023-01-03 14:51: Train Epoch 3: 319/634 Loss: 0.118563
2023-01-03 14:51: Train Epoch 3: 323/634 Loss: 0.137066
2023-01-03 14:51: Train Epoch 3: 327/634 Loss: 0.138764
2023-01-03 14:51: Train Epoch 3: 331/634 Loss: 0.108494
2023-01-03 14:52: Train Epoch 3: 335/634 Loss: 0.113587
2023-01-03 14:52: Train Epoch 3: 339/634 Loss: 0.127994
2023-01-03 14:52: Train Epoch 3: 343/634 Loss: 0.111101
2023-01-03 14:52: Train Epoch 3: 347/634 Loss: 0.146254
2023-01-03 14:53: Train Epoch 3: 351/634 Loss: 0.117810
2023-01-03 14:53: Train Epoch 3: 355/634 Loss: 0.137662
2023-01-03 14:53: Train Epoch 3: 359/634 Loss: 0.153034
2023-01-03 14:53: Train Epoch 3: 363/634 Loss: 0.103520
2023-01-03 14:54: Train Epoch 3: 367/634 Loss: 0.121535
2023-01-03 14:54: Train Epoch 3: 371/634 Loss: 0.120461
2023-01-03 14:54: Train Epoch 3: 375/634 Loss: 0.142779
2023-01-03 14:54: Train Epoch 3: 379/634 Loss: 0.114329
2023-01-03 14:55: Train Epoch 3: 383/634 Loss: 0.113925
2023-01-03 14:55: Train Epoch 3: 387/634 Loss: 0.132919
2023-01-03 14:55: Train Epoch 3: 391/634 Loss: 0.118184
2023-01-03 14:55: Train Epoch 3: 395/634 Loss: 0.144767
2023-01-03 14:56: Train Epoch 3: 399/634 Loss: 0.126248
2023-01-03 14:56: Train Epoch 3: 403/634 Loss: 0.083752
2023-01-03 14:56: Train Epoch 3: 407/634 Loss: 0.131210
2023-01-03 14:56: Train Epoch 3: 411/634 Loss: 0.134238
2023-01-03 14:56: Train Epoch 3: 415/634 Loss: 0.133926
2023-01-03 14:57: Train Epoch 3: 419/634 Loss: 0.139471
2023-01-03 14:57: Train Epoch 3: 423/634 Loss: 0.146301
2023-01-03 14:57: Train Epoch 3: 427/634 Loss: 0.110890
2023-01-03 14:57: Train Epoch 3: 431/634 Loss: 0.128907
2023-01-03 14:58: Train Epoch 3: 435/634 Loss: 0.117944
2023-01-03 14:58: Train Epoch 3: 439/634 Loss: 0.137519
2023-01-03 14:58: Train Epoch 3: 443/634 Loss: 0.119184
2023-01-03 14:58: Train Epoch 3: 447/634 Loss: 0.158708
2023-01-03 14:59: Train Epoch 3: 451/634 Loss: 0.123350
2023-01-03 14:59: Train Epoch 3: 455/634 Loss: 0.144094
2023-01-03 14:59: Train Epoch 3: 459/634 Loss: 0.150277
2023-01-03 14:59: Train Epoch 3: 463/634 Loss: 0.120381
2023-01-03 14:59: Train Epoch 3: 467/634 Loss: 0.095732
2023-01-03 15:00: Train Epoch 3: 471/634 Loss: 0.108506
2023-01-03 15:00: Train Epoch 3: 475/634 Loss: 0.114864
2023-01-03 15:00: Train Epoch 3: 479/634 Loss: 0.102710
2023-01-03 15:00: Train Epoch 3: 483/634 Loss: 0.118769
2023-01-03 15:01: Train Epoch 3: 487/634 Loss: 0.138434
2023-01-03 15:01: Train Epoch 3: 491/634 Loss: 0.118655
2023-01-03 15:01: Train Epoch 3: 495/634 Loss: 0.100212
2023-01-03 15:01: Train Epoch 3: 499/634 Loss: 0.150002
2023-01-03 15:02: Train Epoch 3: 503/634 Loss: 0.119595
2023-01-03 15:02: Train Epoch 3: 507/634 Loss: 0.123945
2023-01-03 15:02: Train Epoch 3: 511/634 Loss: 0.117262
2023-01-03 15:02: Train Epoch 3: 515/634 Loss: 0.142335
2023-01-03 15:02: Train Epoch 3: 519/634 Loss: 0.134372
2023-01-03 15:03: Train Epoch 3: 523/634 Loss: 0.113848
2023-01-03 15:03: Train Epoch 3: 527/634 Loss: 0.136542
2023-01-03 15:03: Train Epoch 3: 531/634 Loss: 0.109525
2023-01-03 15:03: Train Epoch 3: 535/634 Loss: 0.128982
2023-01-03 15:04: Train Epoch 3: 539/634 Loss: 0.115035
2023-01-03 15:04: Train Epoch 3: 543/634 Loss: 0.143477
2023-01-03 15:04: Train Epoch 3: 547/634 Loss: 0.124488
2023-01-03 15:04: Train Epoch 3: 551/634 Loss: 0.121856
2023-01-03 15:04: Train Epoch 3: 555/634 Loss: 0.100816
2023-01-03 15:05: Train Epoch 3: 559/634 Loss: 0.125704
2023-01-03 15:05: Train Epoch 3: 563/634 Loss: 0.129401
2023-01-03 15:05: Train Epoch 3: 567/634 Loss: 0.139142
2023-01-03 15:05: Train Epoch 3: 571/634 Loss: 0.110546
2023-01-03 15:06: Train Epoch 3: 575/634 Loss: 0.113109
2023-01-03 15:06: Train Epoch 3: 579/634 Loss: 0.132092
2023-01-03 15:06: Train Epoch 3: 583/634 Loss: 0.134496
2023-01-03 15:06: Train Epoch 3: 587/634 Loss: 0.107925
2023-01-03 15:07: Train Epoch 3: 591/634 Loss: 0.144310
2023-01-03 15:07: Train Epoch 3: 595/634 Loss: 0.140626
2023-01-03 15:07: Train Epoch 3: 599/634 Loss: 0.136239
2023-01-03 15:07: Train Epoch 3: 603/634 Loss: 0.127404
2023-01-03 15:07: Train Epoch 3: 607/634 Loss: 0.134649
2023-01-03 15:08: Train Epoch 3: 611/634 Loss: 0.115885
2023-01-03 15:08: Train Epoch 3: 615/634 Loss: 0.120754
2023-01-03 15:08: Train Epoch 3: 619/634 Loss: 0.130591
2023-01-03 15:08: Train Epoch 3: 623/634 Loss: 0.137422
2023-01-03 15:09: Train Epoch 3: 627/634 Loss: 0.098840
2023-01-03 15:09: Train Epoch 3: 631/634 Loss: 0.120784
2023-01-03 15:09: Train Epoch 3: 633/634 Loss: 0.047076
2023-01-03 15:09: **********Train Epoch 3: averaged Loss: 0.127592 
2023-01-03 15:09: 
Epoch time elapsed: 2231.690540075302

2023-01-03 15:10: 
 metrics validation: {'precision': 0.8181818181818182, 'recall': 0.6161538461538462, 'f1-score': 0.702939885914875, 'support': 1300, 'AUC': 0.8736985207100592, 'AUCPR': 0.7998999665200156, 'TP': 801, 'FP': 178, 'TN': 2422, 'FN': 499} 

2023-01-03 15:10: **********Val Epoch 3: average Loss: 0.224794
2023-01-03 15:10: *********************************Current best model saved!
2023-01-03 15:11: 
 Testing metrics {'precision': 0.8454106280193237, 'recall': 0.5700325732899023, 'f1-score': 0.6809338521400778, 'support': 1228, 'AUC': 0.8796084706469035, 'AUCPR': 0.8053197693686418, 'TP': 700, 'FP': 128, 'TN': 2328, 'FN': 528} 

2023-01-03 15:15: 
 Testing metrics {'precision': 0.9184911632814561, 'recall': 0.7901066485137281, 'f1-score': 0.8494754818248353, 'support': 4407, 'AUC': 0.9695188858577353, 'AUCPR': 0.9367816562284045, 'TP': 3482, 'FP': 309, 'TN': 8505, 'FN': 925} 

2023-01-03 15:15: Train Epoch 4: 3/634 Loss: 0.149072
2023-01-03 15:15: Train Epoch 4: 7/634 Loss: 0.127704
2023-01-03 15:15: Train Epoch 4: 11/634 Loss: 0.113328
2023-01-03 15:16: Train Epoch 4: 15/634 Loss: 0.141274
2023-01-03 15:16: Train Epoch 4: 19/634 Loss: 0.120616
2023-01-03 15:16: Train Epoch 4: 23/634 Loss: 0.097514
2023-01-03 15:16: Train Epoch 4: 27/634 Loss: 0.105444
2023-01-03 15:16: Train Epoch 4: 31/634 Loss: 0.110376
2023-01-03 15:17: Train Epoch 4: 35/634 Loss: 0.128973
2023-01-03 15:17: Train Epoch 4: 39/634 Loss: 0.138262
2023-01-03 15:17: Train Epoch 4: 43/634 Loss: 0.119737
2023-01-03 15:17: Train Epoch 4: 47/634 Loss: 0.109738
2023-01-03 15:17: Train Epoch 4: 51/634 Loss: 0.105326
2023-01-03 15:18: Train Epoch 4: 55/634 Loss: 0.113819
2023-01-03 15:18: Train Epoch 4: 59/634 Loss: 0.145295
2023-01-03 15:18: Train Epoch 4: 63/634 Loss: 0.117923
2023-01-03 15:18: Train Epoch 4: 67/634 Loss: 0.125700
2023-01-03 15:18: Train Epoch 4: 71/634 Loss: 0.109397
2023-01-03 15:19: Train Epoch 4: 75/634 Loss: 0.135869
2023-01-03 15:19: Train Epoch 4: 79/634 Loss: 0.133863
2023-01-03 15:19: Train Epoch 4: 83/634 Loss: 0.114855
2023-01-03 15:19: Train Epoch 4: 87/634 Loss: 0.115451
2023-01-03 15:19: Train Epoch 4: 91/634 Loss: 0.108186
2023-01-03 15:20: Train Epoch 4: 95/634 Loss: 0.135985
2023-01-03 15:20: Train Epoch 4: 99/634 Loss: 0.115820
2023-01-03 15:20: Train Epoch 4: 103/634 Loss: 0.130046
2023-01-03 15:20: Train Epoch 4: 107/634 Loss: 0.107497
2023-01-03 15:20: Train Epoch 4: 111/634 Loss: 0.111034
2023-01-03 15:21: Train Epoch 4: 115/634 Loss: 0.135564
2023-01-03 15:21: Train Epoch 4: 119/634 Loss: 0.122519
2023-01-03 15:21: Train Epoch 4: 123/634 Loss: 0.113074
2023-01-03 15:21: Train Epoch 4: 127/634 Loss: 0.090282
2023-01-03 15:21: Train Epoch 4: 131/634 Loss: 0.108772
2023-01-03 15:22: Train Epoch 4: 135/634 Loss: 0.134645
2023-01-03 15:22: Train Epoch 4: 139/634 Loss: 0.116145
2023-01-03 15:22: Train Epoch 4: 143/634 Loss: 0.111515
2023-01-03 15:22: Train Epoch 4: 147/634 Loss: 0.154051
2023-01-03 15:23: Train Epoch 4: 151/634 Loss: 0.094176
2023-01-03 15:23: Train Epoch 4: 155/634 Loss: 0.136366
2023-01-03 15:23: Train Epoch 4: 159/634 Loss: 0.129899
2023-01-03 15:23: Train Epoch 4: 163/634 Loss: 0.120817
2023-01-03 15:23: Train Epoch 4: 167/634 Loss: 0.084918
2023-01-03 15:24: Train Epoch 4: 171/634 Loss: 0.129282
2023-01-03 15:24: Train Epoch 4: 175/634 Loss: 0.099468
2023-01-03 15:24: Train Epoch 4: 179/634 Loss: 0.116810
2023-01-03 15:24: Train Epoch 4: 183/634 Loss: 0.119163
2023-01-03 15:24: Train Epoch 4: 187/634 Loss: 0.121917
2023-01-03 15:25: Train Epoch 4: 191/634 Loss: 0.107583
2023-01-03 15:25: Train Epoch 4: 195/634 Loss: 0.124756
2023-01-03 15:25: Train Epoch 4: 199/634 Loss: 0.131712
2023-01-03 15:25: Train Epoch 4: 203/634 Loss: 0.108447
2023-01-03 15:25: Train Epoch 4: 207/634 Loss: 0.107362
2023-01-03 15:26: Train Epoch 4: 211/634 Loss: 0.116833
2023-01-03 15:26: Train Epoch 4: 215/634 Loss: 0.191530
2023-01-03 15:26: Train Epoch 4: 219/634 Loss: 0.156694
2023-01-03 15:26: Train Epoch 4: 223/634 Loss: 0.112186
2023-01-03 15:26: Train Epoch 4: 227/634 Loss: 0.119235
2023-01-03 15:27: Train Epoch 4: 231/634 Loss: 0.120517
2023-01-03 15:27: Train Epoch 4: 235/634 Loss: 0.134700
2023-01-03 15:27: Train Epoch 4: 239/634 Loss: 0.140827
2023-01-03 15:27: Train Epoch 4: 243/634 Loss: 0.117013
2023-01-03 15:27: Train Epoch 4: 247/634 Loss: 0.116846
2023-01-03 15:28: Train Epoch 4: 251/634 Loss: 0.136858
2023-01-03 15:28: Train Epoch 4: 255/634 Loss: 0.150846
2023-01-03 15:28: Train Epoch 4: 259/634 Loss: 0.097030
2023-01-03 15:28: Train Epoch 4: 263/634 Loss: 0.155849
2023-01-03 15:28: Train Epoch 4: 267/634 Loss: 0.117249
2023-01-03 15:29: Train Epoch 4: 271/634 Loss: 0.112466
2023-01-03 15:29: Train Epoch 4: 275/634 Loss: 0.107902
2023-01-03 15:29: Train Epoch 4: 279/634 Loss: 0.137332
2023-01-03 15:29: Train Epoch 4: 283/634 Loss: 0.135572
2023-01-03 15:29: Train Epoch 4: 287/634 Loss: 0.129308
2023-01-03 15:30: Train Epoch 4: 291/634 Loss: 0.104847
2023-01-03 15:30: Train Epoch 4: 295/634 Loss: 0.128376
2023-01-03 15:30: Train Epoch 4: 299/634 Loss: 0.139008
2023-01-03 15:30: Train Epoch 4: 303/634 Loss: 0.126631
2023-01-03 15:31: Train Epoch 4: 307/634 Loss: 0.125106
2023-01-03 15:31: Train Epoch 4: 311/634 Loss: 0.126165
2023-01-03 15:31: Train Epoch 4: 315/634 Loss: 0.095153
2023-01-03 15:31: Train Epoch 4: 319/634 Loss: 0.114239
2023-01-03 15:31: Train Epoch 4: 323/634 Loss: 0.080938
2023-01-03 15:32: Train Epoch 4: 327/634 Loss: 0.093912
2023-01-03 15:32: Train Epoch 4: 331/634 Loss: 0.137908
2023-01-03 15:32: Train Epoch 4: 335/634 Loss: 0.123308
2023-01-03 15:32: Train Epoch 4: 339/634 Loss: 0.129058
2023-01-03 15:32: Train Epoch 4: 343/634 Loss: 0.114664
2023-01-03 15:33: Train Epoch 4: 347/634 Loss: 0.124440
2023-01-03 15:33: Train Epoch 4: 351/634 Loss: 0.113762
2023-01-03 15:33: Train Epoch 4: 355/634 Loss: 0.130922
2023-01-03 15:33: Train Epoch 4: 359/634 Loss: 0.126324
2023-01-03 15:33: Train Epoch 4: 363/634 Loss: 0.126634
2023-01-03 15:34: Train Epoch 4: 367/634 Loss: 0.111818
2023-01-03 15:34: Train Epoch 4: 371/634 Loss: 0.104255
2023-01-03 15:34: Train Epoch 4: 375/634 Loss: 0.097190
2023-01-03 15:34: Train Epoch 4: 379/634 Loss: 0.100671
2023-01-03 15:34: Train Epoch 4: 383/634 Loss: 0.127130
2023-01-03 15:34: Train Epoch 4: 387/634 Loss: 0.129455
2023-01-03 15:35: Train Epoch 4: 391/634 Loss: 0.102906
2023-01-03 15:35: Train Epoch 4: 395/634 Loss: 0.103344
2023-01-03 15:35: Train Epoch 4: 399/634 Loss: 0.104618
2023-01-03 15:35: Train Epoch 4: 403/634 Loss: 0.135580
2023-01-03 15:35: Train Epoch 4: 407/634 Loss: 0.104305
2023-01-03 15:36: Train Epoch 4: 411/634 Loss: 0.114426
2023-01-03 15:36: Train Epoch 4: 415/634 Loss: 0.114056
2023-01-03 15:36: Train Epoch 4: 419/634 Loss: 0.097103
2023-01-03 15:36: Train Epoch 4: 423/634 Loss: 0.108731
2023-01-03 15:36: Train Epoch 4: 427/634 Loss: 0.114474
2023-01-03 15:37: Train Epoch 4: 431/634 Loss: 0.114836
2023-01-03 15:37: Train Epoch 4: 435/634 Loss: 0.120208
2023-01-03 15:37: Train Epoch 4: 439/634 Loss: 0.128254
2023-01-03 15:37: Train Epoch 4: 443/634 Loss: 0.117022
2023-01-03 15:37: Train Epoch 4: 447/634 Loss: 0.125339
2023-01-03 15:38: Train Epoch 4: 451/634 Loss: 0.127528
2023-01-03 15:38: Train Epoch 4: 455/634 Loss: 0.108159
2023-01-03 15:38: Train Epoch 4: 459/634 Loss: 0.110863
2023-01-03 15:38: Train Epoch 4: 463/634 Loss: 0.114829
2023-01-03 15:38: Train Epoch 4: 467/634 Loss: 0.129538
2023-01-03 15:39: Train Epoch 4: 471/634 Loss: 0.114992
2023-01-03 15:39: Train Epoch 4: 475/634 Loss: 0.103903
2023-01-03 15:39: Train Epoch 4: 479/634 Loss: 0.099620
2023-01-03 15:39: Train Epoch 4: 483/634 Loss: 0.113822
2023-01-03 15:39: Train Epoch 4: 487/634 Loss: 0.110669
2023-01-03 15:40: Train Epoch 4: 491/634 Loss: 0.130507
2023-01-03 15:40: Train Epoch 4: 495/634 Loss: 0.120720
2023-01-03 15:40: Train Epoch 4: 499/634 Loss: 0.093952
2023-01-03 15:40: Train Epoch 4: 503/634 Loss: 0.110121
2023-01-03 15:40: Train Epoch 4: 507/634 Loss: 0.117083
2023-01-03 15:41: Train Epoch 4: 511/634 Loss: 0.085617
2023-01-03 15:41: Train Epoch 4: 515/634 Loss: 0.127046
2023-01-03 15:41: Train Epoch 4: 519/634 Loss: 0.090988
2023-01-03 15:41: Train Epoch 4: 523/634 Loss: 0.119500
2023-01-03 15:41: Train Epoch 4: 527/634 Loss: 0.120537
2023-01-03 15:42: Train Epoch 4: 531/634 Loss: 0.124488
2023-01-03 15:42: Train Epoch 4: 535/634 Loss: 0.131032
2023-01-03 15:42: Train Epoch 4: 539/634 Loss: 0.157678
2023-01-03 15:42: Train Epoch 4: 543/634 Loss: 0.118798
2023-01-03 15:42: Train Epoch 4: 547/634 Loss: 0.113452
2023-01-03 15:43: Train Epoch 4: 551/634 Loss: 0.112401
2023-01-03 15:43: Train Epoch 4: 555/634 Loss: 0.122777
2023-01-03 15:43: Train Epoch 4: 559/634 Loss: 0.135690
2023-01-03 15:43: Train Epoch 4: 563/634 Loss: 0.109964
2023-01-03 15:43: Train Epoch 4: 567/634 Loss: 0.104378
2023-01-03 15:44: Train Epoch 4: 571/634 Loss: 0.108973
2023-01-03 15:44: Train Epoch 4: 575/634 Loss: 0.109060
2023-01-03 15:44: Train Epoch 4: 579/634 Loss: 0.103709
2023-01-03 15:44: Train Epoch 4: 583/634 Loss: 0.106816
2023-01-03 15:44: Train Epoch 4: 587/634 Loss: 0.119317
2023-01-03 15:44: Train Epoch 4: 591/634 Loss: 0.124341
2023-01-03 15:45: Train Epoch 4: 595/634 Loss: 0.124987
2023-01-03 15:45: Train Epoch 4: 599/634 Loss: 0.095796
2023-01-03 15:45: Train Epoch 4: 603/634 Loss: 0.102992
2023-01-03 15:45: Train Epoch 4: 607/634 Loss: 0.129261
2023-01-03 15:45: Train Epoch 4: 611/634 Loss: 0.101368
2023-01-03 15:46: Train Epoch 4: 615/634 Loss: 0.127940
2023-01-03 15:46: Train Epoch 4: 619/634 Loss: 0.113945
2023-01-03 15:46: Train Epoch 4: 623/634 Loss: 0.128975
2023-01-03 15:46: Train Epoch 4: 627/634 Loss: 0.106388
2023-01-03 15:46: Train Epoch 4: 631/634 Loss: 0.122398
2023-01-03 15:47: Train Epoch 4: 633/634 Loss: 0.028968
2023-01-03 15:47: **********Train Epoch 4: averaged Loss: 0.118158 
2023-01-03 15:47: 
Epoch time elapsed: 1918.557514667511

2023-01-03 15:48: 
 metrics validation: {'precision': 0.8136067101584343, 'recall': 0.6715384615384615, 'f1-score': 0.7357774968394437, 'support': 1300, 'AUC': 0.8911316568047336, 'AUCPR': 0.8244508716502477, 'TP': 873, 'FP': 200, 'TN': 2400, 'FN': 427} 

2023-01-03 15:48: **********Val Epoch 4: average Loss: 0.200236
2023-01-03 15:48: *********************************Current best model saved!
2023-01-03 15:49: 
 Testing metrics {'precision': 0.8329596412556054, 'recall': 0.6050488599348535, 'f1-score': 0.7009433962264151, 'support': 1228, 'AUC': 0.8806817578966354, 'AUCPR': 0.8067075498371556, 'TP': 743, 'FP': 149, 'TN': 2307, 'FN': 485} 

2023-01-03 15:52: 
 Testing metrics {'precision': 0.9025062656641604, 'recall': 0.8171091445427728, 'f1-score': 0.857687269262832, 'support': 4407, 'AUC': 0.9681677518731803, 'AUCPR': 0.9338122435291742, 'TP': 3601, 'FP': 389, 'TN': 8425, 'FN': 806} 

2023-01-03 15:52: Train Epoch 5: 3/634 Loss: 0.128784
2023-01-03 15:52: Train Epoch 5: 7/634 Loss: 0.100264
2023-01-03 15:52: Train Epoch 5: 11/634 Loss: 0.137106
2023-01-03 15:53: Train Epoch 5: 15/634 Loss: 0.118422
2023-01-03 15:53: Train Epoch 5: 19/634 Loss: 0.113003
2023-01-03 15:53: Train Epoch 5: 23/634 Loss: 0.107099
2023-01-03 15:53: Train Epoch 5: 27/634 Loss: 0.116593
2023-01-03 15:53: Train Epoch 5: 31/634 Loss: 0.098518
2023-01-03 15:54: Train Epoch 5: 35/634 Loss: 0.074810
2023-01-03 15:54: Train Epoch 5: 39/634 Loss: 0.100145
2023-01-03 15:54: Train Epoch 5: 43/634 Loss: 0.121736
2023-01-03 15:54: Train Epoch 5: 47/634 Loss: 0.102903
2023-01-03 15:54: Train Epoch 5: 51/634 Loss: 0.099929
2023-01-03 15:55: Train Epoch 5: 55/634 Loss: 0.122398
2023-01-03 15:55: Train Epoch 5: 59/634 Loss: 0.117388
2023-01-03 15:55: Train Epoch 5: 63/634 Loss: 0.112145
2023-01-03 15:55: Train Epoch 5: 67/634 Loss: 0.096676
2023-01-03 15:55: Train Epoch 5: 71/634 Loss: 0.094754
2023-01-03 15:56: Train Epoch 5: 75/634 Loss: 0.107039
2023-01-03 15:56: Train Epoch 5: 79/634 Loss: 0.107632
2023-01-03 15:56: Train Epoch 5: 83/634 Loss: 0.104549
2023-01-03 15:56: Train Epoch 5: 87/634 Loss: 0.099471
2023-01-03 15:56: Train Epoch 5: 91/634 Loss: 0.106069
2023-01-03 15:57: Train Epoch 5: 95/634 Loss: 0.108459
2023-01-03 15:57: Train Epoch 5: 99/634 Loss: 0.107592
2023-01-03 15:57: Train Epoch 5: 103/634 Loss: 0.113209
2023-01-03 15:57: Train Epoch 5: 107/634 Loss: 0.093562
2023-01-03 15:57: Train Epoch 5: 111/634 Loss: 0.114397
2023-01-03 15:58: Train Epoch 5: 115/634 Loss: 0.120136
2023-01-03 15:58: Train Epoch 5: 119/634 Loss: 0.130184
2023-01-03 15:58: Train Epoch 5: 123/634 Loss: 0.118909
2023-01-03 15:58: Train Epoch 5: 127/634 Loss: 0.119222
2023-01-03 15:58: Train Epoch 5: 131/634 Loss: 0.110455
2023-01-03 15:59: Train Epoch 5: 135/634 Loss: 0.111038
2023-01-03 15:59: Train Epoch 5: 139/634 Loss: 0.134439
2023-01-03 15:59: Train Epoch 5: 143/634 Loss: 0.091213
2023-01-03 15:59: Train Epoch 5: 147/634 Loss: 0.104482
2023-01-03 15:59: Train Epoch 5: 151/634 Loss: 0.121344
2023-01-03 15:59: Train Epoch 5: 155/634 Loss: 0.123500
2023-01-03 16:00: Train Epoch 5: 159/634 Loss: 0.114139
2023-01-03 16:00: Train Epoch 5: 163/634 Loss: 0.098822
2023-01-03 16:00: Train Epoch 5: 167/634 Loss: 0.108335
2023-01-03 16:00: Train Epoch 5: 171/634 Loss: 0.140988
2023-01-03 16:00: Train Epoch 5: 175/634 Loss: 0.104827
2023-01-03 16:01: Train Epoch 5: 179/634 Loss: 0.103458
2023-01-03 16:01: Train Epoch 5: 183/634 Loss: 0.098590
2023-01-03 16:01: Train Epoch 5: 187/634 Loss: 0.114594
2023-01-03 16:01: Train Epoch 5: 191/634 Loss: 0.131313
2023-01-03 16:01: Train Epoch 5: 195/634 Loss: 0.111679
2023-01-03 16:02: Train Epoch 5: 199/634 Loss: 0.128414
2023-01-03 16:02: Train Epoch 5: 203/634 Loss: 0.097442
2023-01-03 16:02: Train Epoch 5: 207/634 Loss: 0.081722
2023-01-03 16:02: Train Epoch 5: 211/634 Loss: 0.101192
2023-01-03 16:02: Train Epoch 5: 215/634 Loss: 0.096291
2023-01-03 16:02: Train Epoch 5: 219/634 Loss: 0.142446
2023-01-03 16:03: Train Epoch 5: 223/634 Loss: 0.115770
2023-01-03 16:03: Train Epoch 5: 227/634 Loss: 0.105131
2023-01-03 16:03: Train Epoch 5: 231/634 Loss: 0.096274
2023-01-03 16:03: Train Epoch 5: 235/634 Loss: 0.103570
2023-01-03 16:03: Train Epoch 5: 239/634 Loss: 0.092643
2023-01-03 16:04: Train Epoch 5: 243/634 Loss: 0.107147
2023-01-03 16:04: Train Epoch 5: 247/634 Loss: 0.131454
2023-01-03 16:04: Train Epoch 5: 251/634 Loss: 0.110357
2023-01-03 16:04: Train Epoch 5: 255/634 Loss: 0.147683
2023-01-03 16:04: Train Epoch 5: 259/634 Loss: 0.106697
2023-01-03 16:05: Train Epoch 5: 263/634 Loss: 0.127790
2023-01-03 16:05: Train Epoch 5: 267/634 Loss: 0.115118
2023-01-03 16:05: Train Epoch 5: 271/634 Loss: 0.102899
2023-01-03 16:05: Train Epoch 5: 275/634 Loss: 0.092213
2023-01-03 16:05: Train Epoch 5: 279/634 Loss: 0.102516
2023-01-03 16:05: Train Epoch 5: 283/634 Loss: 0.104964
2023-01-03 16:06: Train Epoch 5: 287/634 Loss: 0.118082
2023-01-03 16:06: Train Epoch 5: 291/634 Loss: 0.137319
2023-01-03 16:06: Train Epoch 5: 295/634 Loss: 0.110394
2023-01-03 16:06: Train Epoch 5: 299/634 Loss: 0.102049
2023-01-03 16:06: Train Epoch 5: 303/634 Loss: 0.122134
2023-01-03 16:07: Train Epoch 5: 307/634 Loss: 0.101682
2023-01-03 16:07: Train Epoch 5: 311/634 Loss: 0.119916
2023-01-03 16:07: Train Epoch 5: 315/634 Loss: 0.125145
2023-01-03 16:07: Train Epoch 5: 319/634 Loss: 0.112124
2023-01-03 16:07: Train Epoch 5: 323/634 Loss: 0.098650
2023-01-03 16:07: Train Epoch 5: 327/634 Loss: 0.131420
2023-01-03 16:08: Train Epoch 5: 331/634 Loss: 0.108755
2023-01-03 16:08: Train Epoch 5: 335/634 Loss: 0.106251
2023-01-03 16:08: Train Epoch 5: 339/634 Loss: 0.093983
2023-01-03 16:08: Train Epoch 5: 343/634 Loss: 0.102542
2023-01-03 16:08: Train Epoch 5: 347/634 Loss: 0.109136
2023-01-03 16:08: Train Epoch 5: 351/634 Loss: 0.119081
2023-01-03 16:09: Train Epoch 5: 355/634 Loss: 0.125926
2023-01-03 16:09: Train Epoch 5: 359/634 Loss: 0.097301
2023-01-03 16:09: Train Epoch 5: 363/634 Loss: 0.099859
2023-01-03 16:09: Train Epoch 5: 367/634 Loss: 0.124117
2023-01-03 16:09: Train Epoch 5: 371/634 Loss: 0.104239
2023-01-03 16:09: Train Epoch 5: 375/634 Loss: 0.108800
2023-01-03 16:10: Train Epoch 5: 379/634 Loss: 0.104552
2023-01-03 16:10: Train Epoch 5: 383/634 Loss: 0.090127
2023-01-03 16:10: Train Epoch 5: 387/634 Loss: 0.116137
2023-01-03 16:10: Train Epoch 5: 391/634 Loss: 0.153320
2023-01-03 16:10: Train Epoch 5: 395/634 Loss: 0.097720
2023-01-03 16:11: Train Epoch 5: 399/634 Loss: 0.116217
2023-01-03 16:11: Train Epoch 5: 403/634 Loss: 0.095165
2023-01-03 16:11: Train Epoch 5: 407/634 Loss: 0.124721
2023-01-03 16:11: Train Epoch 5: 411/634 Loss: 0.102967
2023-01-03 16:11: Train Epoch 5: 415/634 Loss: 0.096351
2023-01-03 16:11: Train Epoch 5: 419/634 Loss: 0.104800
2023-01-03 16:12: Train Epoch 5: 423/634 Loss: 0.114941
2023-01-03 16:12: Train Epoch 5: 427/634 Loss: 0.120038
2023-01-03 16:12: Train Epoch 5: 431/634 Loss: 0.115579
2023-01-03 16:12: Train Epoch 5: 435/634 Loss: 0.100532
2023-01-03 16:12: Train Epoch 5: 439/634 Loss: 0.094759
2023-01-03 16:12: Train Epoch 5: 443/634 Loss: 0.120868
2023-01-03 16:13: Train Epoch 5: 447/634 Loss: 0.110526
2023-01-03 16:13: Train Epoch 5: 451/634 Loss: 0.081725
2023-01-03 16:13: Train Epoch 5: 455/634 Loss: 0.103792
2023-01-03 16:13: Train Epoch 5: 459/634 Loss: 0.097737
2023-01-03 16:13: Train Epoch 5: 463/634 Loss: 0.118332
2023-01-03 16:13: Train Epoch 5: 467/634 Loss: 0.109151
2023-01-03 16:14: Train Epoch 5: 471/634 Loss: 0.096591
2023-01-03 16:14: Train Epoch 5: 475/634 Loss: 0.115118
2023-01-03 16:14: Train Epoch 5: 479/634 Loss: 0.117685
2023-01-03 16:14: Train Epoch 5: 483/634 Loss: 0.094804
2023-01-03 16:14: Train Epoch 5: 487/634 Loss: 0.095745
2023-01-03 16:14: Train Epoch 5: 491/634 Loss: 0.095374
2023-01-03 16:15: Train Epoch 5: 495/634 Loss: 0.120562
2023-01-03 16:15: Train Epoch 5: 499/634 Loss: 0.108578
2023-01-03 16:15: Train Epoch 5: 503/634 Loss: 0.159240
2023-01-03 16:15: Train Epoch 5: 507/634 Loss: 0.100782
2023-01-03 16:15: Train Epoch 5: 511/634 Loss: 0.148777
2023-01-03 16:15: Train Epoch 5: 515/634 Loss: 0.126759
2023-01-03 16:15: Train Epoch 5: 519/634 Loss: 0.114584
2023-01-03 16:16: Train Epoch 5: 523/634 Loss: 0.107537
2023-01-03 16:16: Train Epoch 5: 527/634 Loss: 0.118450
2023-01-03 16:16: Train Epoch 5: 531/634 Loss: 0.110674
2023-01-03 16:16: Train Epoch 5: 535/634 Loss: 0.099297
2023-01-03 16:16: Train Epoch 5: 539/634 Loss: 0.119906
2023-01-03 16:16: Train Epoch 5: 543/634 Loss: 0.111447
2023-01-03 16:17: Train Epoch 5: 547/634 Loss: 0.118892
2023-01-03 16:17: Train Epoch 5: 551/634 Loss: 0.082821
2023-01-03 16:17: Train Epoch 5: 555/634 Loss: 0.103469
2023-01-03 16:17: Train Epoch 5: 559/634 Loss: 0.130967
2023-01-03 16:17: Train Epoch 5: 563/634 Loss: 0.097154
2023-01-03 16:17: Train Epoch 5: 567/634 Loss: 0.119982
2023-01-03 16:17: Train Epoch 5: 571/634 Loss: 0.098934
2023-01-03 16:18: Train Epoch 5: 575/634 Loss: 0.134394
2023-01-03 16:18: Train Epoch 5: 579/634 Loss: 0.077278
2023-01-03 16:18: Train Epoch 5: 583/634 Loss: 0.092517
2023-01-03 16:18: Train Epoch 5: 587/634 Loss: 0.119916
2023-01-03 16:18: Train Epoch 5: 591/634 Loss: 0.135565
2023-01-03 16:18: Train Epoch 5: 595/634 Loss: 0.142841
2023-01-03 16:19: Train Epoch 5: 599/634 Loss: 0.103610
2023-01-03 16:19: Train Epoch 5: 603/634 Loss: 0.088037
2023-01-03 16:19: Train Epoch 5: 607/634 Loss: 0.100634
2023-01-03 16:19: Train Epoch 5: 611/634 Loss: 0.141450
2023-01-03 16:19: Train Epoch 5: 615/634 Loss: 0.114248
2023-01-03 16:19: Train Epoch 5: 619/634 Loss: 0.106568
2023-01-03 16:19: Train Epoch 5: 623/634 Loss: 0.076085
2023-01-03 16:20: Train Epoch 5: 627/634 Loss: 0.143857
2023-01-03 16:20: Train Epoch 5: 631/634 Loss: 0.131778
2023-01-03 16:20: Train Epoch 5: 633/634 Loss: 0.040169
2023-01-03 16:20: **********Train Epoch 5: averaged Loss: 0.110554 
2023-01-03 16:20: 
Epoch time elapsed: 1689.6966774463654

2023-01-03 16:21: 
 metrics validation: {'precision': 0.8249744114636642, 'recall': 0.62, 'f1-score': 0.7079490557751427, 'support': 1300, 'AUC': 0.89458224852071, 'AUCPR': 0.8191252135679458, 'TP': 806, 'FP': 171, 'TN': 2429, 'FN': 494} 

2023-01-03 16:21: **********Val Epoch 5: average Loss: 0.210450
2023-01-03 16:21: 
 Testing metrics {'precision': 0.8329596412556054, 'recall': 0.6050488599348535, 'f1-score': 0.7009433962264151, 'support': 1228, 'AUC': 0.8806817578966354, 'AUCPR': 0.8067075498371556, 'TP': 743, 'FP': 149, 'TN': 2307, 'FN': 485} 

2023-01-03 16:24: 
 Testing metrics {'precision': 0.9025062656641604, 'recall': 0.8171091445427728, 'f1-score': 0.857687269262832, 'support': 4407, 'AUC': 0.9681677518731803, 'AUCPR': 0.9338122435291742, 'TP': 3601, 'FP': 389, 'TN': 8425, 'FN': 806} 

2023-01-03 16:24: Train Epoch 6: 3/634 Loss: 0.102231
2023-01-03 16:24: Train Epoch 6: 7/634 Loss: 0.163592
2023-01-03 16:24: Train Epoch 6: 11/634 Loss: 0.119754
2023-01-03 16:24: Train Epoch 6: 15/634 Loss: 0.084883
2023-01-03 16:25: Train Epoch 6: 19/634 Loss: 0.088730
2023-01-03 16:25: Train Epoch 6: 23/634 Loss: 0.099312
2023-01-03 16:25: Train Epoch 6: 27/634 Loss: 0.140034
2023-01-03 16:25: Train Epoch 6: 31/634 Loss: 0.105426
2023-01-03 16:25: Train Epoch 6: 35/634 Loss: 0.126933
2023-01-03 16:25: Train Epoch 6: 39/634 Loss: 0.127958
2023-01-03 16:26: Train Epoch 6: 43/634 Loss: 0.129564
2023-01-03 16:26: Train Epoch 6: 47/634 Loss: 0.095179
2023-01-03 16:26: Train Epoch 6: 51/634 Loss: 0.131911
2023-01-03 16:26: Train Epoch 6: 55/634 Loss: 0.107924
2023-01-03 16:26: Train Epoch 6: 59/634 Loss: 0.099326
2023-01-03 16:26: Train Epoch 6: 63/634 Loss: 0.104257
2023-01-03 16:26: Train Epoch 6: 67/634 Loss: 0.121488
2023-01-03 16:27: Train Epoch 6: 71/634 Loss: 0.099367
2023-01-03 16:27: Train Epoch 6: 75/634 Loss: 0.123081
2023-01-03 16:27: Train Epoch 6: 79/634 Loss: 0.148362
2023-01-03 16:27: Train Epoch 6: 83/634 Loss: 0.104394
2023-01-03 16:27: Train Epoch 6: 87/634 Loss: 0.133412
2023-01-03 16:27: Train Epoch 6: 91/634 Loss: 0.122291
2023-01-03 16:27: Train Epoch 6: 95/634 Loss: 0.106717
2023-01-03 16:28: Train Epoch 6: 99/634 Loss: 0.111843
2023-01-03 16:28: Train Epoch 6: 103/634 Loss: 0.080376
2023-01-03 16:28: Train Epoch 6: 107/634 Loss: 0.113832
2023-01-03 16:28: Train Epoch 6: 111/634 Loss: 0.146579
2023-01-03 16:28: Train Epoch 6: 115/634 Loss: 0.134045
2023-01-03 16:28: Train Epoch 6: 119/634 Loss: 0.121720
2023-01-03 16:29: Train Epoch 6: 123/634 Loss: 0.105106
2023-01-03 16:29: Train Epoch 6: 127/634 Loss: 0.145530
2023-01-03 16:29: Train Epoch 6: 131/634 Loss: 0.115951
2023-01-03 16:29: Train Epoch 6: 135/634 Loss: 0.100357
2023-01-03 16:29: Train Epoch 6: 139/634 Loss: 0.118962
2023-01-03 16:29: Train Epoch 6: 143/634 Loss: 0.106056
2023-01-03 16:29: Train Epoch 6: 147/634 Loss: 0.098019
2023-01-03 16:30: Train Epoch 6: 151/634 Loss: 0.109071
2023-01-03 16:30: Train Epoch 6: 155/634 Loss: 0.103235
2023-01-03 16:30: Train Epoch 6: 159/634 Loss: 0.102965
2023-01-03 16:30: Train Epoch 6: 163/634 Loss: 0.129049
2023-01-03 16:30: Train Epoch 6: 167/634 Loss: 0.103668
2023-01-03 16:30: Train Epoch 6: 171/634 Loss: 0.131438
2023-01-03 16:31: Train Epoch 6: 175/634 Loss: 0.096985
2023-01-03 16:31: Train Epoch 6: 179/634 Loss: 0.123011
2023-01-03 16:31: Train Epoch 6: 183/634 Loss: 0.110957
2023-01-03 16:31: Train Epoch 6: 187/634 Loss: 0.130224
2023-01-03 16:31: Train Epoch 6: 191/634 Loss: 0.115314
2023-01-03 16:31: Train Epoch 6: 195/634 Loss: 0.121350
2023-01-03 16:31: Train Epoch 6: 199/634 Loss: 0.088521
2023-01-03 16:32: Train Epoch 6: 203/634 Loss: 0.107750
2023-01-03 16:32: Train Epoch 6: 207/634 Loss: 0.131511
2023-01-03 16:32: Train Epoch 6: 211/634 Loss: 0.117742
2023-01-03 16:32: Train Epoch 6: 215/634 Loss: 0.081386
2023-01-03 16:32: Train Epoch 6: 219/634 Loss: 0.116535
2023-01-03 16:32: Train Epoch 6: 223/634 Loss: 0.103960
2023-01-03 16:33: Train Epoch 6: 227/634 Loss: 0.127218
2023-01-03 16:33: Train Epoch 6: 231/634 Loss: 0.089863
2023-01-03 16:33: Train Epoch 6: 235/634 Loss: 0.106182
2023-01-03 16:33: Train Epoch 6: 239/634 Loss: 0.109694
2023-01-03 16:33: Train Epoch 6: 243/634 Loss: 0.098410
2023-01-03 16:33: Train Epoch 6: 247/634 Loss: 0.134962
2023-01-03 16:33: Train Epoch 6: 251/634 Loss: 0.141916
2023-01-03 16:34: Train Epoch 6: 255/634 Loss: 0.098562
2023-01-03 16:34: Train Epoch 6: 259/634 Loss: 0.152688
2023-01-03 16:34: Train Epoch 6: 263/634 Loss: 0.106313
2023-01-03 16:34: Train Epoch 6: 267/634 Loss: 0.091119
2023-01-03 16:34: Train Epoch 6: 271/634 Loss: 0.104144
2023-01-03 16:34: Train Epoch 6: 275/634 Loss: 0.126017
2023-01-03 16:34: Train Epoch 6: 279/634 Loss: 0.118670
2023-01-03 16:35: Train Epoch 6: 283/634 Loss: 0.133254
2023-01-03 16:35: Train Epoch 6: 287/634 Loss: 0.125460
2023-01-03 16:35: Train Epoch 6: 291/634 Loss: 0.115893
2023-01-03 16:35: Train Epoch 6: 295/634 Loss: 0.111845
2023-01-03 16:35: Train Epoch 6: 299/634 Loss: 0.121106
2023-01-03 16:35: Train Epoch 6: 303/634 Loss: 0.142561
2023-01-03 16:35: Train Epoch 6: 307/634 Loss: 0.122905
2023-01-03 16:36: Train Epoch 6: 311/634 Loss: 0.126650
2023-01-03 16:36: Train Epoch 6: 315/634 Loss: 0.098347
2023-01-03 16:36: Train Epoch 6: 319/634 Loss: 0.119468
2023-01-03 16:36: Train Epoch 6: 323/634 Loss: 0.093745
2023-01-03 16:36: Train Epoch 6: 327/634 Loss: 0.099060
2023-01-03 16:36: Train Epoch 6: 331/634 Loss: 0.109001
2023-01-03 16:37: Train Epoch 6: 335/634 Loss: 0.095207
2023-01-03 16:37: Train Epoch 6: 339/634 Loss: 0.116408
2023-01-03 16:37: Train Epoch 6: 343/634 Loss: 0.107692
2023-01-03 16:37: Train Epoch 6: 347/634 Loss: 0.108416
2023-01-03 16:37: Train Epoch 6: 351/634 Loss: 0.098460
2023-01-03 16:37: Train Epoch 6: 355/634 Loss: 0.128565
2023-01-03 16:37: Train Epoch 6: 359/634 Loss: 0.107485
2023-01-03 16:38: Train Epoch 6: 363/634 Loss: 0.105724
2023-01-03 16:38: Train Epoch 6: 367/634 Loss: 0.139006
2023-01-03 16:38: Train Epoch 6: 371/634 Loss: 0.089748
2023-01-03 16:38: Train Epoch 6: 375/634 Loss: 0.115977
2023-01-03 16:38: Train Epoch 6: 379/634 Loss: 0.113258
2023-01-03 16:38: Train Epoch 6: 383/634 Loss: 0.090606
2023-01-03 16:38: Train Epoch 6: 387/634 Loss: 0.098702
2023-01-03 16:39: Train Epoch 6: 391/634 Loss: 0.108019
2023-01-03 16:39: Train Epoch 6: 395/634 Loss: 0.096275
2023-01-03 16:39: Train Epoch 6: 399/634 Loss: 0.096662
2023-01-03 16:39: Train Epoch 6: 403/634 Loss: 0.125091
2023-01-03 16:39: Train Epoch 6: 407/634 Loss: 0.133108
2023-01-03 16:39: Train Epoch 6: 411/634 Loss: 0.125759
2023-01-03 16:40: Train Epoch 6: 415/634 Loss: 0.087750
2023-01-03 16:40: Train Epoch 6: 419/634 Loss: 0.086643
2023-01-03 16:40: Train Epoch 6: 423/634 Loss: 0.126226
2023-01-03 16:40: Train Epoch 6: 427/634 Loss: 0.119539
2023-01-03 16:40: Train Epoch 6: 431/634 Loss: 0.114242
2023-01-03 16:40: Train Epoch 6: 435/634 Loss: 0.106544
2023-01-03 16:40: Train Epoch 6: 439/634 Loss: 0.084272
2023-01-03 16:41: Train Epoch 6: 443/634 Loss: 0.077545
2023-01-03 16:41: Train Epoch 6: 447/634 Loss: 0.125604
2023-01-03 16:41: Train Epoch 6: 451/634 Loss: 0.091410
2023-01-03 16:41: Train Epoch 6: 455/634 Loss: 0.106467
2023-01-03 16:41: Train Epoch 6: 459/634 Loss: 0.093312
2023-01-03 16:41: Train Epoch 6: 463/634 Loss: 0.090781
2023-01-03 16:42: Train Epoch 6: 467/634 Loss: 0.125128
2023-01-03 16:42: Train Epoch 6: 471/634 Loss: 0.105436
2023-01-03 16:42: Train Epoch 6: 475/634 Loss: 0.114556
2023-01-03 16:42: Train Epoch 6: 479/634 Loss: 0.122059
2023-01-03 16:42: Train Epoch 6: 483/634 Loss: 0.103875
2023-01-03 16:42: Train Epoch 6: 487/634 Loss: 0.088706
2023-01-03 16:42: Train Epoch 6: 491/634 Loss: 0.098078
2023-01-03 16:43: Train Epoch 6: 495/634 Loss: 0.096966
2023-01-03 16:43: Train Epoch 6: 499/634 Loss: 0.113591
2023-01-03 16:43: Train Epoch 6: 503/634 Loss: 0.097845
2023-01-03 16:43: Train Epoch 6: 507/634 Loss: 0.108723
2023-01-03 16:43: Train Epoch 6: 511/634 Loss: 0.083521
2023-01-03 16:43: Train Epoch 6: 515/634 Loss: 0.097578
2023-01-03 16:43: Train Epoch 6: 519/634 Loss: 0.094613
2023-01-03 16:44: Train Epoch 6: 523/634 Loss: 0.118288
2023-01-03 16:44: Train Epoch 6: 527/634 Loss: 0.108764
2023-01-03 16:44: Train Epoch 6: 531/634 Loss: 0.104662
2023-01-03 16:44: Train Epoch 6: 535/634 Loss: 0.119295
2023-01-03 16:44: Train Epoch 6: 539/634 Loss: 0.131569
2023-01-03 16:44: Train Epoch 6: 543/634 Loss: 0.097665
2023-01-03 16:45: Train Epoch 6: 547/634 Loss: 0.089776
2023-01-03 16:45: Train Epoch 6: 551/634 Loss: 0.111851
2023-01-03 16:45: Train Epoch 6: 555/634 Loss: 0.125082
2023-01-03 16:45: Train Epoch 6: 559/634 Loss: 0.102562
2023-01-03 16:45: Train Epoch 6: 563/634 Loss: 0.118951
2023-01-03 16:45: Train Epoch 6: 567/634 Loss: 0.081087
2023-01-03 16:45: Train Epoch 6: 571/634 Loss: 0.106912
2023-01-03 16:46: Train Epoch 6: 575/634 Loss: 0.103281
2023-01-03 16:46: Train Epoch 6: 579/634 Loss: 0.092486
2023-01-03 16:46: Train Epoch 6: 583/634 Loss: 0.117430
2023-01-03 16:46: Train Epoch 6: 587/634 Loss: 0.096255
2023-01-03 16:46: Train Epoch 6: 591/634 Loss: 0.148491
2023-01-03 16:46: Train Epoch 6: 595/634 Loss: 0.113035
2023-01-03 16:46: Train Epoch 6: 599/634 Loss: 0.103385
2023-01-03 16:47: Train Epoch 6: 603/634 Loss: 0.118316
2023-01-03 16:47: Train Epoch 6: 607/634 Loss: 0.101407
2023-01-03 16:47: Train Epoch 6: 611/634 Loss: 0.102708
2023-01-03 16:47: Train Epoch 6: 615/634 Loss: 0.092971
2023-01-03 16:47: Train Epoch 6: 619/634 Loss: 0.106537
2023-01-03 16:47: Train Epoch 6: 623/634 Loss: 0.104782
2023-01-03 16:47: Train Epoch 6: 627/634 Loss: 0.116657
2023-01-03 16:48: Train Epoch 6: 631/634 Loss: 0.109957
2023-01-03 16:48: Train Epoch 6: 633/634 Loss: 0.052770
2023-01-03 16:48: **********Train Epoch 6: averaged Loss: 0.110644 
2023-01-03 16:48: 
Epoch time elapsed: 1431.5629024505615

2023-01-03 16:49: 
 metrics validation: {'precision': 0.7716933445661331, 'recall': 0.7046153846153846, 'f1-score': 0.7366304784881385, 'support': 1300, 'AUC': 0.8929174556213018, 'AUCPR': 0.8255533776652403, 'TP': 916, 'FP': 271, 'TN': 2329, 'FN': 384} 

2023-01-03 16:49: **********Val Epoch 6: average Loss: 0.197854
2023-01-03 16:49: *********************************Current best model saved!
2023-01-03 16:49: 
 Testing metrics {'precision': 0.8088669950738916, 'recall': 0.6685667752442996, 'f1-score': 0.732055283102987, 'support': 1228, 'AUC': 0.8853800836083141, 'AUCPR': 0.8153116276464685, 'TP': 821, 'FP': 194, 'TN': 2262, 'FN': 407} 

2023-01-03 16:52: 
 Testing metrics {'precision': 0.8911426639621366, 'recall': 0.897208985704561, 'f1-score': 0.8941655359565808, 'support': 4407, 'AUC': 0.9704129397045533, 'AUCPR': 0.9395138615421204, 'TP': 3954, 'FP': 483, 'TN': 8331, 'FN': 453} 

2023-01-03 16:52: Train Epoch 7: 3/634 Loss: 0.102290
2023-01-03 16:52: Train Epoch 7: 7/634 Loss: 0.112849
2023-01-03 16:52: Train Epoch 7: 11/634 Loss: 0.100362
2023-01-03 16:53: Train Epoch 7: 15/634 Loss: 0.089472
2023-01-03 16:53: Train Epoch 7: 19/634 Loss: 0.102086
2023-01-03 16:53: Train Epoch 7: 23/634 Loss: 0.125970
2023-01-03 16:53: Train Epoch 7: 27/634 Loss: 0.124312
2023-01-03 16:53: Train Epoch 7: 31/634 Loss: 0.102109
2023-01-03 16:53: Train Epoch 7: 35/634 Loss: 0.095078
2023-01-03 16:53: Train Epoch 7: 39/634 Loss: 0.090555
2023-01-03 16:54: Train Epoch 7: 43/634 Loss: 0.108250
2023-01-03 16:54: Train Epoch 7: 47/634 Loss: 0.122241
2023-01-03 16:54: Train Epoch 7: 51/634 Loss: 0.122246
2023-01-03 16:54: Train Epoch 7: 55/634 Loss: 0.146038
2023-01-03 16:54: Train Epoch 7: 59/634 Loss: 0.089679
2023-01-03 16:54: Train Epoch 7: 63/634 Loss: 0.097128
2023-01-03 16:55: Train Epoch 7: 67/634 Loss: 0.101772
2023-01-03 16:55: Train Epoch 7: 71/634 Loss: 0.090627
2023-01-03 16:55: Train Epoch 7: 75/634 Loss: 0.120603
2023-01-03 16:55: Train Epoch 7: 79/634 Loss: 0.096326
2023-01-03 16:55: Train Epoch 7: 83/634 Loss: 0.093479
2023-01-03 16:55: Train Epoch 7: 87/634 Loss: 0.089753
2023-01-03 16:55: Train Epoch 7: 91/634 Loss: 0.085986
2023-01-03 16:56: Train Epoch 7: 95/634 Loss: 0.093269
2023-01-03 16:56: Train Epoch 7: 99/634 Loss: 0.105874
2023-01-03 16:56: Train Epoch 7: 103/634 Loss: 0.122322
2023-01-03 16:56: Train Epoch 7: 107/634 Loss: 0.119280
2023-01-03 16:56: Train Epoch 7: 111/634 Loss: 0.104873
2023-01-03 16:56: Train Epoch 7: 115/634 Loss: 0.106487
2023-01-03 16:56: Train Epoch 7: 119/634 Loss: 0.104791
2023-01-03 16:57: Train Epoch 7: 123/634 Loss: 0.108522
2023-01-03 16:57: Train Epoch 7: 127/634 Loss: 0.100629
2023-01-03 16:57: Train Epoch 7: 131/634 Loss: 0.109690
2023-01-03 16:57: Train Epoch 7: 135/634 Loss: 0.104431
2023-01-03 16:57: Train Epoch 7: 139/634 Loss: 0.092655
2023-01-03 16:57: Train Epoch 7: 143/634 Loss: 0.097934
2023-01-03 16:58: Train Epoch 7: 147/634 Loss: 0.128523
2023-01-03 16:58: Train Epoch 7: 151/634 Loss: 0.107026
2023-01-03 16:58: Train Epoch 7: 155/634 Loss: 0.106163
2023-01-03 16:58: Train Epoch 7: 159/634 Loss: 0.109856
2023-01-03 16:58: Train Epoch 7: 163/634 Loss: 0.103998
2023-01-03 16:58: Train Epoch 7: 167/634 Loss: 0.080514
2023-01-03 16:58: Train Epoch 7: 171/634 Loss: 0.109792
2023-01-03 16:59: Train Epoch 7: 175/634 Loss: 0.107376
2023-01-03 16:59: Train Epoch 7: 179/634 Loss: 0.124799
2023-01-03 16:59: Train Epoch 7: 183/634 Loss: 0.113295
2023-01-03 16:59: Train Epoch 7: 187/634 Loss: 0.086910
2023-01-03 16:59: Train Epoch 7: 191/634 Loss: 0.123785
2023-01-03 16:59: Train Epoch 7: 195/634 Loss: 0.109628
2023-01-03 16:59: Train Epoch 7: 199/634 Loss: 0.088477
2023-01-03 17:00: Train Epoch 7: 203/634 Loss: 0.109474
2023-01-03 17:00: Train Epoch 7: 207/634 Loss: 0.105420
2023-01-03 17:00: Train Epoch 7: 211/634 Loss: 0.091026
2023-01-03 17:00: Train Epoch 7: 215/634 Loss: 0.123820
2023-01-03 17:00: Train Epoch 7: 219/634 Loss: 0.093031
2023-01-03 17:01: Train Epoch 7: 223/634 Loss: 0.101798
2023-01-03 17:01: Train Epoch 7: 227/634 Loss: 0.131597
2023-01-03 17:01: Train Epoch 7: 231/634 Loss: 0.097966
2023-01-03 17:01: Train Epoch 7: 235/634 Loss: 0.078231
2023-01-03 17:01: Train Epoch 7: 239/634 Loss: 0.135207
2023-01-03 17:01: Train Epoch 7: 243/634 Loss: 0.111451
2023-01-03 17:01: Train Epoch 7: 247/634 Loss: 0.105737
2023-01-03 17:02: Train Epoch 7: 251/634 Loss: 0.089722
2023-01-03 17:02: Train Epoch 7: 255/634 Loss: 0.104676
2023-01-03 17:02: Train Epoch 7: 259/634 Loss: 0.103124
2023-01-03 17:02: Train Epoch 7: 263/634 Loss: 0.136880
2023-01-03 17:02: Train Epoch 7: 267/634 Loss: 0.107078
2023-01-03 17:02: Train Epoch 7: 271/634 Loss: 0.131365
2023-01-03 17:02: Train Epoch 7: 275/634 Loss: 0.116305
2023-01-03 17:03: Train Epoch 7: 279/634 Loss: 0.125213
2023-01-03 17:03: Train Epoch 7: 283/634 Loss: 0.124223
2023-01-03 17:03: Train Epoch 7: 287/634 Loss: 0.090895
2023-01-03 17:03: Train Epoch 7: 291/634 Loss: 0.088271
2023-01-03 17:03: Train Epoch 7: 295/634 Loss: 0.106643
2023-01-03 17:03: Train Epoch 7: 299/634 Loss: 0.140312
2023-01-03 17:04: Train Epoch 7: 303/634 Loss: 0.104684
2023-01-03 17:04: Train Epoch 7: 307/634 Loss: 0.125378
2023-01-03 17:04: Train Epoch 7: 311/634 Loss: 0.105316
2023-01-03 17:04: Train Epoch 7: 315/634 Loss: 0.108507
2023-01-03 17:04: Train Epoch 7: 319/634 Loss: 0.093956
2023-01-03 17:04: Train Epoch 7: 323/634 Loss: 0.136227
2023-01-03 17:04: Train Epoch 7: 327/634 Loss: 0.089647
2023-01-03 17:05: Train Epoch 7: 331/634 Loss: 0.081614
2023-01-03 17:05: Train Epoch 7: 335/634 Loss: 0.094995
2023-01-03 17:05: Train Epoch 7: 339/634 Loss: 0.103534
2023-01-03 17:05: Train Epoch 7: 343/634 Loss: 0.071343
2023-01-03 17:05: Train Epoch 7: 347/634 Loss: 0.097740
2023-01-03 17:05: Train Epoch 7: 351/634 Loss: 0.079226
2023-01-03 17:05: Train Epoch 7: 355/634 Loss: 0.088886
2023-01-03 17:06: Train Epoch 7: 359/634 Loss: 0.126709
2023-01-03 17:06: Train Epoch 7: 363/634 Loss: 0.118608
2023-01-03 17:06: Train Epoch 7: 367/634 Loss: 0.103220
2023-01-03 17:06: Train Epoch 7: 371/634 Loss: 0.114947
2023-01-03 17:06: Train Epoch 7: 375/634 Loss: 0.114949
2023-01-03 17:06: Train Epoch 7: 379/634 Loss: 0.131567
2023-01-03 17:06: Train Epoch 7: 383/634 Loss: 0.088996
2023-01-03 17:07: Train Epoch 7: 387/634 Loss: 0.110840
2023-01-03 17:07: Train Epoch 7: 391/634 Loss: 0.097820
2023-01-03 17:07: Train Epoch 7: 395/634 Loss: 0.084487
2023-01-03 17:07: Train Epoch 7: 399/634 Loss: 0.128271
2023-01-03 17:07: Train Epoch 7: 403/634 Loss: 0.108172
2023-01-03 17:07: Train Epoch 7: 407/634 Loss: 0.102858
2023-01-03 17:07: Train Epoch 7: 411/634 Loss: 0.100530
2023-01-03 17:08: Train Epoch 7: 415/634 Loss: 0.107659
2023-01-03 17:08: Train Epoch 7: 419/634 Loss: 0.098629
2023-01-03 17:08: Train Epoch 7: 423/634 Loss: 0.108637
2023-01-03 17:08: Train Epoch 7: 427/634 Loss: 0.111040
2023-01-03 17:08: Train Epoch 7: 431/634 Loss: 0.108945
2023-01-03 17:08: Train Epoch 7: 435/634 Loss: 0.116110
2023-01-03 17:09: Train Epoch 7: 439/634 Loss: 0.079400
2023-01-03 17:09: Train Epoch 7: 443/634 Loss: 0.103360
2023-01-03 17:09: Train Epoch 7: 447/634 Loss: 0.096016
2023-01-03 17:09: Train Epoch 7: 451/634 Loss: 0.111833
2023-01-03 17:09: Train Epoch 7: 455/634 Loss: 0.082490
2023-01-03 17:09: Train Epoch 7: 459/634 Loss: 0.087658
2023-01-03 17:09: Train Epoch 7: 463/634 Loss: 0.089495
2023-01-03 17:10: Train Epoch 7: 467/634 Loss: 0.097878
2023-01-03 17:10: Train Epoch 7: 471/634 Loss: 0.104678
2023-01-03 17:10: Train Epoch 7: 475/634 Loss: 0.101374
2023-01-03 17:10: Train Epoch 7: 479/634 Loss: 0.101384
2023-01-03 17:10: Train Epoch 7: 483/634 Loss: 0.125196
2023-01-03 17:10: Train Epoch 7: 487/634 Loss: 0.099363
2023-01-03 17:11: Train Epoch 7: 491/634 Loss: 0.089574
2023-01-03 17:11: Train Epoch 7: 495/634 Loss: 0.082854
2023-01-03 17:11: Train Epoch 7: 499/634 Loss: 0.114134
2023-01-03 17:11: Train Epoch 7: 503/634 Loss: 0.131741
2023-01-03 17:11: Train Epoch 7: 507/634 Loss: 0.120142
2023-01-03 17:11: Train Epoch 7: 511/634 Loss: 0.117098
2023-01-03 17:11: Train Epoch 7: 515/634 Loss: 0.112565
2023-01-03 17:12: Train Epoch 7: 519/634 Loss: 0.094708
2023-01-03 17:12: Train Epoch 7: 523/634 Loss: 0.109950
2023-01-03 17:12: Train Epoch 7: 527/634 Loss: 0.099178
2023-01-03 17:12: Train Epoch 7: 531/634 Loss: 0.114136
2023-01-03 17:12: Train Epoch 7: 535/634 Loss: 0.120822
2023-01-03 17:12: Train Epoch 7: 539/634 Loss: 0.116434
2023-01-03 17:13: Train Epoch 7: 543/634 Loss: 0.112254
2023-01-03 17:13: Train Epoch 7: 547/634 Loss: 0.112366
2023-01-03 17:13: Train Epoch 7: 551/634 Loss: 0.095339
2023-01-03 17:13: Train Epoch 7: 555/634 Loss: 0.113792
2023-01-03 17:13: Train Epoch 7: 559/634 Loss: 0.105083
2023-01-03 17:13: Train Epoch 7: 563/634 Loss: 0.109884
2023-01-03 17:13: Train Epoch 7: 567/634 Loss: 0.106633
2023-01-03 17:14: Train Epoch 7: 571/634 Loss: 0.101859
2023-01-03 17:14: Train Epoch 7: 575/634 Loss: 0.110050
2023-01-03 17:14: Train Epoch 7: 579/634 Loss: 0.116989
2023-01-03 17:14: Train Epoch 7: 583/634 Loss: 0.106467
2023-01-03 17:14: Train Epoch 7: 587/634 Loss: 0.091086
2023-01-03 17:14: Train Epoch 7: 591/634 Loss: 0.101978
2023-01-03 17:14: Train Epoch 7: 595/634 Loss: 0.094515
2023-01-03 17:15: Train Epoch 7: 599/634 Loss: 0.097483
2023-01-03 17:15: Train Epoch 7: 603/634 Loss: 0.079022
2023-01-03 17:15: Train Epoch 7: 607/634 Loss: 0.093072
2023-01-03 17:15: Train Epoch 7: 611/634 Loss: 0.084953
2023-01-03 17:15: Train Epoch 7: 615/634 Loss: 0.099600
2023-01-03 17:15: Train Epoch 7: 619/634 Loss: 0.096873
2023-01-03 17:16: Train Epoch 7: 623/634 Loss: 0.095495
2023-01-03 17:16: Train Epoch 7: 627/634 Loss: 0.104032
2023-01-03 17:16: Train Epoch 7: 631/634 Loss: 0.093537
2023-01-03 17:16: Train Epoch 7: 633/634 Loss: 0.035676
2023-01-03 17:16: **********Train Epoch 7: averaged Loss: 0.104749 
2023-01-03 17:16: 
Epoch time elapsed: 1442.4318661689758

2023-01-03 17:17: 
 metrics validation: {'precision': 0.8016230838593328, 'recall': 0.6838461538461539, 'f1-score': 0.738065587380656, 'support': 1300, 'AUC': 0.9038775147928994, 'AUCPR': 0.8335307993324547, 'TP': 889, 'FP': 220, 'TN': 2380, 'FN': 411} 

2023-01-03 17:17: **********Val Epoch 7: average Loss: 0.188478
2023-01-03 17:17: *********************************Current best model saved!
2023-01-03 17:18: 
 Testing metrics {'precision': 0.8364779874213837, 'recall': 0.6498371335504886, 'f1-score': 0.7314390467461044, 'support': 1228, 'AUC': 0.8920180850725208, 'AUCPR': 0.8241536694255618, 'TP': 798, 'FP': 156, 'TN': 2300, 'FN': 430} 

2023-01-03 17:20: 
 Testing metrics {'precision': 0.9045819555975437, 'recall': 0.8690719310188336, 'f1-score': 0.8864714732091193, 'support': 4407, 'AUC': 0.9717743714758722, 'AUCPR': 0.9414342640888056, 'TP': 3830, 'FP': 404, 'TN': 8410, 'FN': 577} 

2023-01-03 17:21: Train Epoch 8: 3/634 Loss: 0.102371
2023-01-03 17:21: Train Epoch 8: 7/634 Loss: 0.117105
2023-01-03 17:21: Train Epoch 8: 11/634 Loss: 0.096048
2023-01-03 17:21: Train Epoch 8: 15/634 Loss: 0.090817
2023-01-03 17:21: Train Epoch 8: 19/634 Loss: 0.107120
2023-01-03 17:21: Train Epoch 8: 23/634 Loss: 0.104270
2023-01-03 17:22: Train Epoch 8: 27/634 Loss: 0.080067
2023-01-03 17:22: Train Epoch 8: 31/634 Loss: 0.106546
2023-01-03 17:22: Train Epoch 8: 35/634 Loss: 0.115698
2023-01-03 17:22: Train Epoch 8: 39/634 Loss: 0.105098
2023-01-03 17:22: Train Epoch 8: 43/634 Loss: 0.130657
2023-01-03 17:22: Train Epoch 8: 47/634 Loss: 0.120634
2023-01-03 17:22: Train Epoch 8: 51/634 Loss: 0.133589
2023-01-03 17:23: Train Epoch 8: 55/634 Loss: 0.103680
2023-01-03 17:23: Train Epoch 8: 59/634 Loss: 0.093574
2023-01-03 17:23: Train Epoch 8: 63/634 Loss: 0.083619
2023-01-03 17:23: Train Epoch 8: 67/634 Loss: 0.087958
2023-01-03 17:23: Train Epoch 8: 71/634 Loss: 0.091385
2023-01-03 17:23: Train Epoch 8: 75/634 Loss: 0.105685
2023-01-03 17:23: Train Epoch 8: 79/634 Loss: 0.094188
2023-01-03 17:24: Train Epoch 8: 83/634 Loss: 0.074922
2023-01-03 17:24: Train Epoch 8: 87/634 Loss: 0.099705
2023-01-03 17:24: Train Epoch 8: 91/634 Loss: 0.083456
2023-01-03 17:24: Train Epoch 8: 95/634 Loss: 0.099373
2023-01-03 17:24: Train Epoch 8: 99/634 Loss: 0.141291
2023-01-03 17:24: Train Epoch 8: 103/634 Loss: 0.092704
2023-01-03 17:25: Train Epoch 8: 107/634 Loss: 0.101134
2023-01-03 17:25: Train Epoch 8: 111/634 Loss: 0.104303
2023-01-03 17:25: Train Epoch 8: 115/634 Loss: 0.128678
2023-01-03 17:25: Train Epoch 8: 119/634 Loss: 0.090287
2023-01-03 17:25: Train Epoch 8: 123/634 Loss: 0.117652
2023-01-03 17:25: Train Epoch 8: 127/634 Loss: 0.087895
2023-01-03 17:25: Train Epoch 8: 131/634 Loss: 0.117998
2023-01-03 17:26: Train Epoch 8: 135/634 Loss: 0.103072
2023-01-03 17:26: Train Epoch 8: 139/634 Loss: 0.081505
2023-01-03 17:26: Train Epoch 8: 143/634 Loss: 0.097629
2023-01-03 17:26: Train Epoch 8: 147/634 Loss: 0.089885
2023-01-03 17:26: Train Epoch 8: 151/634 Loss: 0.109448
2023-01-03 17:26: Train Epoch 8: 155/634 Loss: 0.108850
2023-01-03 17:27: Train Epoch 8: 159/634 Loss: 0.113685
2023-01-03 17:27: Train Epoch 8: 163/634 Loss: 0.130302
2023-01-03 17:27: Train Epoch 8: 167/634 Loss: 0.106576
2023-01-03 17:27: Train Epoch 8: 171/634 Loss: 0.094309
2023-01-03 17:27: Train Epoch 8: 175/634 Loss: 0.095125
2023-01-03 17:27: Train Epoch 8: 179/634 Loss: 0.109223
2023-01-03 17:27: Train Epoch 8: 183/634 Loss: 0.106646
2023-01-03 17:28: Train Epoch 8: 187/634 Loss: 0.102926
2023-01-03 17:28: Train Epoch 8: 191/634 Loss: 0.090629
2023-01-03 17:28: Train Epoch 8: 195/634 Loss: 0.087859
2023-01-03 17:28: Train Epoch 8: 199/634 Loss: 0.089190
2023-01-03 17:28: Train Epoch 8: 203/634 Loss: 0.073682
2023-01-03 17:28: Train Epoch 8: 207/634 Loss: 0.101930
2023-01-03 17:29: Train Epoch 8: 211/634 Loss: 0.098186
2023-01-03 17:29: Train Epoch 8: 215/634 Loss: 0.111127
2023-01-03 17:29: Train Epoch 8: 219/634 Loss: 0.127508
2023-01-03 17:29: Train Epoch 8: 223/634 Loss: 0.093913
2023-01-03 17:29: Train Epoch 8: 227/634 Loss: 0.076395
2023-01-03 17:29: Train Epoch 8: 231/634 Loss: 0.107836
2023-01-03 17:29: Train Epoch 8: 235/634 Loss: 0.113993
2023-01-03 17:30: Train Epoch 8: 239/634 Loss: 0.094504
2023-01-03 17:30: Train Epoch 8: 243/634 Loss: 0.098063
2023-01-03 17:30: Train Epoch 8: 247/634 Loss: 0.076466
2023-01-03 17:30: Train Epoch 8: 251/634 Loss: 0.108545
2023-01-03 17:30: Train Epoch 8: 255/634 Loss: 0.073234
2023-01-03 17:30: Train Epoch 8: 259/634 Loss: 0.084268
2023-01-03 17:31: Train Epoch 8: 263/634 Loss: 0.107093
2023-01-03 17:31: Train Epoch 8: 267/634 Loss: 0.082797
2023-01-03 17:31: Train Epoch 8: 271/634 Loss: 0.105070
2023-01-03 17:31: Train Epoch 8: 275/634 Loss: 0.099636
2023-01-03 17:31: Train Epoch 8: 279/634 Loss: 0.108058
2023-01-03 17:31: Train Epoch 8: 283/634 Loss: 0.122580
2023-01-03 17:32: Train Epoch 8: 287/634 Loss: 0.096852
2023-01-03 17:32: Train Epoch 8: 291/634 Loss: 0.106957
2023-01-03 17:32: Train Epoch 8: 295/634 Loss: 0.123684
2023-01-03 17:32: Train Epoch 8: 299/634 Loss: 0.111798
2023-01-03 17:32: Train Epoch 8: 303/634 Loss: 0.088461
2023-01-03 17:32: Train Epoch 8: 307/634 Loss: 0.086768
2023-01-03 17:32: Train Epoch 8: 311/634 Loss: 0.088680
2023-01-03 17:33: Train Epoch 8: 315/634 Loss: 0.120450
2023-01-03 17:33: Train Epoch 8: 319/634 Loss: 0.128743
2023-01-03 17:33: Train Epoch 8: 323/634 Loss: 0.086886
2023-01-03 17:33: Train Epoch 8: 327/634 Loss: 0.116095
2023-01-03 17:33: Train Epoch 8: 331/634 Loss: 0.090271
2023-01-03 17:33: Train Epoch 8: 335/634 Loss: 0.106802
2023-01-03 17:34: Train Epoch 8: 339/634 Loss: 0.071606
2023-01-03 17:34: Train Epoch 8: 343/634 Loss: 0.081894
2023-01-03 17:34: Train Epoch 8: 347/634 Loss: 0.075582
2023-01-03 17:34: Train Epoch 8: 351/634 Loss: 0.088567
2023-01-03 17:34: Train Epoch 8: 355/634 Loss: 0.095726
2023-01-03 17:34: Train Epoch 8: 359/634 Loss: 0.074737
2023-01-03 17:34: Train Epoch 8: 363/634 Loss: 0.084312
2023-01-03 17:35: Train Epoch 8: 367/634 Loss: 0.106523
2023-01-03 17:35: Train Epoch 8: 371/634 Loss: 0.069090
2023-01-03 17:35: Train Epoch 8: 375/634 Loss: 0.080949
2023-01-03 17:35: Train Epoch 8: 379/634 Loss: 0.102243
2023-01-03 17:35: Train Epoch 8: 383/634 Loss: 0.100469
2023-01-03 17:35: Train Epoch 8: 387/634 Loss: 0.098374
2023-01-03 17:35: Train Epoch 8: 391/634 Loss: 0.099386
2023-01-03 17:36: Train Epoch 8: 395/634 Loss: 0.109116
2023-01-03 17:36: Train Epoch 8: 399/634 Loss: 0.117190
2023-01-03 17:36: Train Epoch 8: 403/634 Loss: 0.080085
2023-01-03 17:36: Train Epoch 8: 407/634 Loss: 0.069218
2023-01-03 17:36: Train Epoch 8: 411/634 Loss: 0.106794
2023-01-03 17:36: Train Epoch 8: 415/634 Loss: 0.107296
2023-01-03 17:37: Train Epoch 8: 419/634 Loss: 0.104807
2023-01-03 17:37: Train Epoch 8: 423/634 Loss: 0.078795
2023-01-03 17:37: Train Epoch 8: 427/634 Loss: 0.108976
2023-01-03 17:37: Train Epoch 8: 431/634 Loss: 0.100511
2023-01-03 17:37: Train Epoch 8: 435/634 Loss: 0.098780
2023-01-03 17:37: Train Epoch 8: 439/634 Loss: 0.087222
2023-01-03 17:37: Train Epoch 8: 443/634 Loss: 0.082629
2023-01-03 17:38: Train Epoch 8: 447/634 Loss: 0.069494
2023-01-03 17:38: Train Epoch 8: 451/634 Loss: 0.102577
2023-01-03 17:38: Train Epoch 8: 455/634 Loss: 0.078684
2023-01-03 17:38: Train Epoch 8: 459/634 Loss: 0.095504
2023-01-03 17:38: Train Epoch 8: 463/634 Loss: 0.099822
2023-01-03 17:38: Train Epoch 8: 467/634 Loss: 0.101256
2023-01-03 17:39: Train Epoch 8: 471/634 Loss: 0.108609
2023-01-03 17:39: Train Epoch 8: 475/634 Loss: 0.100770
2023-01-03 17:39: Train Epoch 8: 479/634 Loss: 0.087692
2023-01-03 17:39: Train Epoch 8: 483/634 Loss: 0.138741
2023-01-03 17:39: Train Epoch 8: 487/634 Loss: 0.090097
2023-01-03 17:39: Train Epoch 8: 491/634 Loss: 0.081149
2023-01-03 17:39: Train Epoch 8: 495/634 Loss: 0.098478
2023-01-03 17:40: Train Epoch 8: 499/634 Loss: 0.086828
2023-01-03 17:40: Train Epoch 8: 503/634 Loss: 0.110807
2023-01-03 17:40: Train Epoch 8: 507/634 Loss: 0.078781
2023-01-03 17:40: Train Epoch 8: 511/634 Loss: 0.103307
2023-01-03 17:40: Train Epoch 8: 515/634 Loss: 0.104201
2023-01-03 17:40: Train Epoch 8: 519/634 Loss: 0.098480
2023-01-03 17:41: Train Epoch 8: 523/634 Loss: 0.088053
2023-01-03 17:41: Train Epoch 8: 527/634 Loss: 0.078677
2023-01-03 17:41: Train Epoch 8: 531/634 Loss: 0.077664
2023-01-03 17:41: Train Epoch 8: 535/634 Loss: 0.082929
2023-01-03 17:41: Train Epoch 8: 539/634 Loss: 0.101691
2023-01-03 17:41: Train Epoch 8: 543/634 Loss: 0.107080
2023-01-03 17:42: Train Epoch 8: 547/634 Loss: 0.108336
2023-01-03 17:42: Train Epoch 8: 551/634 Loss: 0.103860
2023-01-03 17:42: Train Epoch 8: 555/634 Loss: 0.072726
2023-01-03 17:42: Train Epoch 8: 559/634 Loss: 0.092329
2023-01-03 17:42: Train Epoch 8: 563/634 Loss: 0.081149
2023-01-03 17:42: Train Epoch 8: 567/634 Loss: 0.080799
2023-01-03 17:43: Train Epoch 8: 571/634 Loss: 0.119127
2023-01-03 17:43: Train Epoch 8: 575/634 Loss: 0.107063
2023-01-03 17:43: Train Epoch 8: 579/634 Loss: 0.085117
2023-01-03 17:43: Train Epoch 8: 583/634 Loss: 0.092976
2023-01-03 17:43: Train Epoch 8: 587/634 Loss: 0.073313
2023-01-03 17:43: Train Epoch 8: 591/634 Loss: 0.097264
2023-01-03 17:43: Train Epoch 8: 595/634 Loss: 0.108653
2023-01-03 17:44: Train Epoch 8: 599/634 Loss: 0.102806
2023-01-03 17:44: Train Epoch 8: 603/634 Loss: 0.109674
2023-01-03 17:44: Train Epoch 8: 607/634 Loss: 0.107629
2023-01-03 17:44: Train Epoch 8: 611/634 Loss: 0.109855
2023-01-03 17:44: Train Epoch 8: 615/634 Loss: 0.092334
2023-01-03 17:44: Train Epoch 8: 619/634 Loss: 0.086311
2023-01-03 17:44: Train Epoch 8: 623/634 Loss: 0.135824
2023-01-03 17:45: Train Epoch 8: 627/634 Loss: 0.114421
2023-01-03 17:45: Train Epoch 8: 631/634 Loss: 0.084083
2023-01-03 17:45: Train Epoch 8: 633/634 Loss: 0.034111
2023-01-03 17:45: **********Train Epoch 8: averaged Loss: 0.098086 
2023-01-03 17:45: 
Epoch time elapsed: 1460.5457000732422

2023-01-03 17:46: 
 metrics validation: {'precision': 0.7975352112676056, 'recall': 0.696923076923077, 'f1-score': 0.7438423645320197, 'support': 1300, 'AUC': 0.9093130177514791, 'AUCPR': 0.8407099102985135, 'TP': 906, 'FP': 230, 'TN': 2370, 'FN': 394} 

2023-01-03 17:46: **********Val Epoch 8: average Loss: 0.177491
2023-01-03 17:46: *********************************Current best model saved!
2023-01-03 17:46: 
 Testing metrics {'precision': 0.8317853457172343, 'recall': 0.6563517915309446, 'f1-score': 0.7337278106508875, 'support': 1228, 'AUC': 0.8932057634563761, 'AUCPR': 0.8280634275305611, 'TP': 806, 'FP': 163, 'TN': 2293, 'FN': 422} 

2023-01-03 17:49: 
 Testing metrics {'precision': 0.8994082840236687, 'recall': 0.8622645790787383, 'f1-score': 0.8804448563484707, 'support': 4407, 'AUC': 0.9701584299046904, 'AUCPR': 0.9377668214608286, 'TP': 3800, 'FP': 425, 'TN': 8389, 'FN': 607} 

2023-01-03 17:49: Train Epoch 9: 3/634 Loss: 0.109248
2023-01-03 17:49: Train Epoch 9: 7/634 Loss: 0.105064
2023-01-03 17:49: Train Epoch 9: 11/634 Loss: 0.109670
2023-01-03 17:49: Train Epoch 9: 15/634 Loss: 0.109968
2023-01-03 17:49: Train Epoch 9: 19/634 Loss: 0.080262
2023-01-03 17:50: Train Epoch 9: 23/634 Loss: 0.111519
2023-01-03 17:50: Train Epoch 9: 27/634 Loss: 0.060373
2023-01-03 17:50: Train Epoch 9: 31/634 Loss: 0.076512
2023-01-03 17:50: Train Epoch 9: 35/634 Loss: 0.101871
2023-01-03 17:50: Train Epoch 9: 39/634 Loss: 0.076319
2023-01-03 17:50: Train Epoch 9: 43/634 Loss: 0.102241
2023-01-03 17:51: Train Epoch 9: 47/634 Loss: 0.070057
2023-01-03 17:51: Train Epoch 9: 51/634 Loss: 0.107490
2023-01-03 17:51: Train Epoch 9: 55/634 Loss: 0.112932
2023-01-03 17:51: Train Epoch 9: 59/634 Loss: 0.089506
2023-01-03 17:51: Train Epoch 9: 63/634 Loss: 0.094289
2023-01-03 17:51: Train Epoch 9: 67/634 Loss: 0.097724
2023-01-03 17:52: Train Epoch 9: 71/634 Loss: 0.067532
2023-01-03 17:52: Train Epoch 9: 75/634 Loss: 0.079271
2023-01-03 17:52: Train Epoch 9: 79/634 Loss: 0.100133
2023-01-03 17:52: Train Epoch 9: 83/634 Loss: 0.113962
2023-01-03 17:52: Train Epoch 9: 87/634 Loss: 0.096576
2023-01-03 17:52: Train Epoch 9: 91/634 Loss: 0.104470
2023-01-03 17:52: Train Epoch 9: 95/634 Loss: 0.105349
2023-01-03 17:53: Train Epoch 9: 99/634 Loss: 0.078405
2023-01-03 17:53: Train Epoch 9: 103/634 Loss: 0.078009
2023-01-03 17:53: Train Epoch 9: 107/634 Loss: 0.097634
2023-01-03 17:53: Train Epoch 9: 111/634 Loss: 0.070008
2023-01-03 17:53: Train Epoch 9: 115/634 Loss: 0.085432
2023-01-03 17:53: Train Epoch 9: 119/634 Loss: 0.111242
2023-01-03 17:54: Train Epoch 9: 123/634 Loss: 0.099327
2023-01-03 17:54: Train Epoch 9: 127/634 Loss: 0.073517
2023-01-03 17:54: Train Epoch 9: 131/634 Loss: 0.129055
2023-01-03 17:54: Train Epoch 9: 135/634 Loss: 0.099715
2023-01-03 17:54: Train Epoch 9: 139/634 Loss: 0.090752
2023-01-03 17:54: Train Epoch 9: 143/634 Loss: 0.107403
2023-01-03 17:54: Train Epoch 9: 147/634 Loss: 0.083102
2023-01-03 17:55: Train Epoch 9: 151/634 Loss: 0.104115
2023-01-03 17:55: Train Epoch 9: 155/634 Loss: 0.085960
2023-01-03 17:55: Train Epoch 9: 159/634 Loss: 0.109820
2023-01-03 17:55: Train Epoch 9: 163/634 Loss: 0.085910
2023-01-03 17:55: Train Epoch 9: 167/634 Loss: 0.091394
2023-01-03 17:55: Train Epoch 9: 171/634 Loss: 0.088624
2023-01-03 17:55: Train Epoch 9: 175/634 Loss: 0.113415
2023-01-03 17:56: Train Epoch 9: 179/634 Loss: 0.090249
2023-01-03 17:56: Train Epoch 9: 183/634 Loss: 0.071649
2023-01-03 17:56: Train Epoch 9: 187/634 Loss: 0.115269
2023-01-03 17:56: Train Epoch 9: 191/634 Loss: 0.094823
2023-01-03 17:56: Train Epoch 9: 195/634 Loss: 0.103891
2023-01-03 17:56: Train Epoch 9: 199/634 Loss: 0.089287
2023-01-03 17:57: Train Epoch 9: 203/634 Loss: 0.105238
2023-01-03 17:57: Train Epoch 9: 207/634 Loss: 0.106264
2023-01-03 17:57: Train Epoch 9: 211/634 Loss: 0.078140
2023-01-03 17:57: Train Epoch 9: 215/634 Loss: 0.118010
2023-01-03 17:57: Train Epoch 9: 219/634 Loss: 0.107265
2023-01-03 17:57: Train Epoch 9: 223/634 Loss: 0.097132
2023-01-03 17:57: Train Epoch 9: 227/634 Loss: 0.084450
2023-01-03 17:58: Train Epoch 9: 231/634 Loss: 0.120351
2023-01-03 17:58: Train Epoch 9: 235/634 Loss: 0.105181
2023-01-03 17:58: Train Epoch 9: 239/634 Loss: 0.122149
2023-01-03 17:58: Train Epoch 9: 243/634 Loss: 0.093129
2023-01-03 17:58: Train Epoch 9: 247/634 Loss: 0.084281
2023-01-03 17:58: Train Epoch 9: 251/634 Loss: 0.094317
2023-01-03 17:58: Train Epoch 9: 255/634 Loss: 0.106259
2023-01-03 17:59: Train Epoch 9: 259/634 Loss: 0.122251
2023-01-03 17:59: Train Epoch 9: 263/634 Loss: 0.067697
2023-01-03 17:59: Train Epoch 9: 267/634 Loss: 0.080797
2023-01-03 17:59: Train Epoch 9: 271/634 Loss: 0.099330
2023-01-03 17:59: Train Epoch 9: 275/634 Loss: 0.125224
2023-01-03 17:59: Train Epoch 9: 279/634 Loss: 0.076909
2023-01-03 18:00: Train Epoch 9: 283/634 Loss: 0.090531
2023-01-03 18:00: Train Epoch 9: 287/634 Loss: 0.098968
2023-01-03 18:00: Train Epoch 9: 291/634 Loss: 0.101843
2023-01-03 18:00: Train Epoch 9: 295/634 Loss: 0.117112
2023-01-03 18:00: Train Epoch 9: 299/634 Loss: 0.098025
2023-01-03 18:00: Train Epoch 9: 303/634 Loss: 0.091335
2023-01-03 18:01: Train Epoch 9: 307/634 Loss: 0.085895
2023-01-03 18:01: Train Epoch 9: 311/634 Loss: 0.089601
2023-01-03 18:01: Train Epoch 9: 315/634 Loss: 0.103285
2023-01-03 18:01: Train Epoch 9: 319/634 Loss: 0.095013
2023-01-03 18:01: Train Epoch 9: 323/634 Loss: 0.085049
2023-01-03 18:01: Train Epoch 9: 327/634 Loss: 0.088477
2023-01-03 18:01: Train Epoch 9: 331/634 Loss: 0.068060
2023-01-03 18:02: Train Epoch 9: 335/634 Loss: 0.094163
2023-01-03 18:02: Train Epoch 9: 339/634 Loss: 0.085773
2023-01-03 18:02: Train Epoch 9: 343/634 Loss: 0.110465
2023-01-03 18:02: Train Epoch 9: 347/634 Loss: 0.102636
2023-01-03 18:02: Train Epoch 9: 351/634 Loss: 0.080650
2023-01-03 18:02: Train Epoch 9: 355/634 Loss: 0.097512
2023-01-03 18:02: Train Epoch 9: 359/634 Loss: 0.091963
2023-01-03 18:03: Train Epoch 9: 363/634 Loss: 0.095426
2023-01-03 18:03: Train Epoch 9: 367/634 Loss: 0.119551
2023-01-03 18:03: Train Epoch 9: 371/634 Loss: 0.092274
2023-01-03 18:03: Train Epoch 9: 375/634 Loss: 0.081694
2023-01-03 18:03: Train Epoch 9: 379/634 Loss: 0.113135
2023-01-03 18:03: Train Epoch 9: 383/634 Loss: 0.095019
2023-01-03 18:04: Train Epoch 9: 387/634 Loss: 0.085921
2023-01-03 18:04: Train Epoch 9: 391/634 Loss: 0.091832
2023-01-03 18:04: Train Epoch 9: 395/634 Loss: 0.099603
2023-01-03 18:04: Train Epoch 9: 399/634 Loss: 0.082422
2023-01-03 18:04: Train Epoch 9: 403/634 Loss: 0.081409
2023-01-03 18:04: Train Epoch 9: 407/634 Loss: 0.098686
2023-01-03 18:04: Train Epoch 9: 411/634 Loss: 0.082597
2023-01-03 18:05: Train Epoch 9: 415/634 Loss: 0.097870
2023-01-03 18:05: Train Epoch 9: 419/634 Loss: 0.081401
2023-01-03 18:05: Train Epoch 9: 423/634 Loss: 0.104523
2023-01-03 18:05: Train Epoch 9: 427/634 Loss: 0.071261
2023-01-03 18:05: Train Epoch 9: 431/634 Loss: 0.093522
2023-01-03 18:05: Train Epoch 9: 435/634 Loss: 0.114134
2023-01-03 18:06: Train Epoch 9: 439/634 Loss: 0.096758
2023-01-03 18:06: Train Epoch 9: 443/634 Loss: 0.103369
2023-01-03 18:06: Train Epoch 9: 447/634 Loss: 0.090578
2023-01-03 18:06: Train Epoch 9: 451/634 Loss: 0.079991
2023-01-03 18:06: Train Epoch 9: 455/634 Loss: 0.087090
2023-01-03 18:06: Train Epoch 9: 459/634 Loss: 0.105684
2023-01-03 18:06: Train Epoch 9: 463/634 Loss: 0.077732
2023-01-03 18:07: Train Epoch 9: 467/634 Loss: 0.104623
2023-01-03 18:07: Train Epoch 9: 471/634 Loss: 0.096852
2023-01-03 18:07: Train Epoch 9: 475/634 Loss: 0.115969
2023-01-03 18:07: Train Epoch 9: 479/634 Loss: 0.081098
2023-01-03 18:07: Train Epoch 9: 483/634 Loss: 0.093923
2023-01-03 18:07: Train Epoch 9: 487/634 Loss: 0.092496
2023-01-03 18:08: Train Epoch 9: 491/634 Loss: 0.092853
2023-01-03 18:08: Train Epoch 9: 495/634 Loss: 0.068553
2023-01-03 18:08: Train Epoch 9: 499/634 Loss: 0.075929
2023-01-03 18:08: Train Epoch 9: 503/634 Loss: 0.079269
2023-01-03 18:08: Train Epoch 9: 507/634 Loss: 0.103100
2023-01-03 18:08: Train Epoch 9: 511/634 Loss: 0.087730
2023-01-03 18:08: Train Epoch 9: 515/634 Loss: 0.079912
2023-01-03 18:09: Train Epoch 9: 519/634 Loss: 0.091090
2023-01-03 18:09: Train Epoch 9: 523/634 Loss: 0.094627
2023-01-03 18:09: Train Epoch 9: 527/634 Loss: 0.097118
2023-01-03 18:09: Train Epoch 9: 531/634 Loss: 0.085838
2023-01-03 18:09: Train Epoch 9: 535/634 Loss: 0.095680
2023-01-03 18:09: Train Epoch 9: 539/634 Loss: 0.097459
2023-01-03 18:10: Train Epoch 9: 543/634 Loss: 0.068526
2023-01-03 18:10: Train Epoch 9: 547/634 Loss: 0.096475
2023-01-03 18:10: Train Epoch 9: 551/634 Loss: 0.064733
2023-01-03 18:10: Train Epoch 9: 555/634 Loss: 0.091067
2023-01-03 18:10: Train Epoch 9: 559/634 Loss: 0.088831
2023-01-03 18:10: Train Epoch 9: 563/634 Loss: 0.100191
2023-01-03 18:11: Train Epoch 9: 567/634 Loss: 0.095197
2023-01-03 18:11: Train Epoch 9: 571/634 Loss: 0.089521
2023-01-03 18:11: Train Epoch 9: 575/634 Loss: 0.087322
2023-01-03 18:11: Train Epoch 9: 579/634 Loss: 0.080293
2023-01-03 18:11: Train Epoch 9: 583/634 Loss: 0.125334
2023-01-03 18:11: Train Epoch 9: 587/634 Loss: 0.095956
2023-01-03 18:11: Train Epoch 9: 591/634 Loss: 0.112406
2023-01-03 18:12: Train Epoch 9: 595/634 Loss: 0.092390
2023-01-03 18:12: Train Epoch 9: 599/634 Loss: 0.089631
2023-01-03 18:12: Train Epoch 9: 603/634 Loss: 0.076947
2023-01-03 18:12: Train Epoch 9: 607/634 Loss: 0.098228
2023-01-03 18:12: Train Epoch 9: 611/634 Loss: 0.071975
2023-01-03 18:12: Train Epoch 9: 615/634 Loss: 0.085943
2023-01-03 18:12: Train Epoch 9: 619/634 Loss: 0.088280
2023-01-03 18:13: Train Epoch 9: 623/634 Loss: 0.105148
2023-01-03 18:13: Train Epoch 9: 627/634 Loss: 0.076883
2023-01-03 18:13: Train Epoch 9: 631/634 Loss: 0.097982
2023-01-03 18:13: Train Epoch 9: 633/634 Loss: 0.038953
2023-01-03 18:13: **********Train Epoch 9: averaged Loss: 0.093565 
2023-01-03 18:13: 
Epoch time elapsed: 1454.525099992752

2023-01-03 18:14: 
 metrics validation: {'precision': 0.8433734939759037, 'recall': 0.6461538461538462, 'f1-score': 0.7317073170731707, 'support': 1300, 'AUC': 0.9171272189349113, 'AUCPR': 0.8519604495925828, 'TP': 840, 'FP': 156, 'TN': 2444, 'FN': 460} 

2023-01-03 18:14: **********Val Epoch 9: average Loss: 0.184026
2023-01-03 18:15: 
 Testing metrics {'precision': 0.8317853457172343, 'recall': 0.6563517915309446, 'f1-score': 0.7337278106508875, 'support': 1228, 'AUC': 0.8932057634563761, 'AUCPR': 0.8280634275305611, 'TP': 806, 'FP': 163, 'TN': 2293, 'FN': 422} 

2023-01-03 18:17: 
 Testing metrics {'precision': 0.8994082840236687, 'recall': 0.8622645790787383, 'f1-score': 0.8804448563484707, 'support': 4407, 'AUC': 0.9701584299046904, 'AUCPR': 0.9377668214608286, 'TP': 3800, 'FP': 425, 'TN': 8389, 'FN': 607} 

2023-01-03 18:17: Train Epoch 10: 3/634 Loss: 0.073933
2023-01-03 18:17: Train Epoch 10: 7/634 Loss: 0.088324
2023-01-03 18:18: Train Epoch 10: 11/634 Loss: 0.095565
2023-01-03 18:18: Train Epoch 10: 15/634 Loss: 0.068868
2023-01-03 18:18: Train Epoch 10: 19/634 Loss: 0.103723
2023-01-03 18:18: Train Epoch 10: 23/634 Loss: 0.097551
2023-01-03 18:18: Train Epoch 10: 27/634 Loss: 0.096495
2023-01-03 18:18: Train Epoch 10: 31/634 Loss: 0.099712
2023-01-03 18:18: Train Epoch 10: 35/634 Loss: 0.081150
2023-01-03 18:19: Train Epoch 10: 39/634 Loss: 0.111338
2023-01-03 18:19: Train Epoch 10: 43/634 Loss: 0.090596
2023-01-03 18:19: Train Epoch 10: 47/634 Loss: 0.098329
2023-01-03 18:19: Train Epoch 10: 51/634 Loss: 0.108696
2023-01-03 18:19: Train Epoch 10: 55/634 Loss: 0.092319
2023-01-03 18:19: Train Epoch 10: 59/634 Loss: 0.088419
2023-01-03 18:20: Train Epoch 10: 63/634 Loss: 0.095615
2023-01-03 18:20: Train Epoch 10: 67/634 Loss: 0.093406
2023-01-03 18:20: Train Epoch 10: 71/634 Loss: 0.084906
2023-01-03 18:20: Train Epoch 10: 75/634 Loss: 0.094460
2023-01-03 18:20: Train Epoch 10: 79/634 Loss: 0.105090
2023-01-03 18:20: Train Epoch 10: 83/634 Loss: 0.079741
2023-01-03 18:21: Train Epoch 10: 87/634 Loss: 0.108005
2023-01-03 18:21: Train Epoch 10: 91/634 Loss: 0.081703
2023-01-03 18:21: Train Epoch 10: 95/634 Loss: 0.102584
2023-01-03 18:21: Train Epoch 10: 99/634 Loss: 0.077043
2023-01-03 18:21: Train Epoch 10: 103/634 Loss: 0.085960
2023-01-03 18:21: Train Epoch 10: 107/634 Loss: 0.103533
2023-01-03 18:22: Train Epoch 10: 111/634 Loss: 0.095561
2023-01-03 18:22: Train Epoch 10: 115/634 Loss: 0.081559
2023-01-03 18:22: Train Epoch 10: 119/634 Loss: 0.104551
2023-01-03 18:22: Train Epoch 10: 123/634 Loss: 0.074538
2023-01-03 18:22: Train Epoch 10: 127/634 Loss: 0.097631
2023-01-03 18:22: Train Epoch 10: 131/634 Loss: 0.104181
2023-01-03 18:23: Train Epoch 10: 135/634 Loss: 0.085736
2023-01-03 18:23: Train Epoch 10: 139/634 Loss: 0.080955
2023-01-03 18:23: Train Epoch 10: 143/634 Loss: 0.126697
2023-01-03 18:23: Train Epoch 10: 147/634 Loss: 0.104123
2023-01-03 18:23: Train Epoch 10: 151/634 Loss: 0.086874
2023-01-03 18:23: Train Epoch 10: 155/634 Loss: 0.084524
2023-01-03 18:24: Train Epoch 10: 159/634 Loss: 0.106839
2023-01-03 18:24: Train Epoch 10: 163/634 Loss: 0.074891
2023-01-03 18:24: Train Epoch 10: 167/634 Loss: 0.069767
2023-01-03 18:24: Train Epoch 10: 171/634 Loss: 0.081811
2023-01-03 18:24: Train Epoch 10: 175/634 Loss: 0.099791
2023-01-03 18:24: Train Epoch 10: 179/634 Loss: 0.098301
2023-01-03 18:25: Train Epoch 10: 183/634 Loss: 0.097861
2023-01-03 18:25: Train Epoch 10: 187/634 Loss: 0.106581
2023-01-03 18:25: Train Epoch 10: 191/634 Loss: 0.095132
2023-01-03 18:25: Train Epoch 10: 195/634 Loss: 0.079739
2023-01-03 18:25: Train Epoch 10: 199/634 Loss: 0.127563
2023-01-03 18:25: Train Epoch 10: 203/634 Loss: 0.085290
2023-01-03 18:26: Train Epoch 10: 207/634 Loss: 0.096102
2023-01-03 18:26: Train Epoch 10: 211/634 Loss: 0.094924
2023-01-03 18:26: Train Epoch 10: 215/634 Loss: 0.077183
2023-01-03 18:26: Train Epoch 10: 219/634 Loss: 0.076248
2023-01-03 18:26: Train Epoch 10: 223/634 Loss: 0.082544
2023-01-03 18:26: Train Epoch 10: 227/634 Loss: 0.096212
2023-01-03 18:27: Train Epoch 10: 231/634 Loss: 0.077536
2023-01-03 18:27: Train Epoch 10: 235/634 Loss: 0.102087
2023-01-03 18:27: Train Epoch 10: 239/634 Loss: 0.092238
2023-01-03 18:27: Train Epoch 10: 243/634 Loss: 0.091955
2023-01-03 18:27: Train Epoch 10: 247/634 Loss: 0.099240
2023-01-03 18:27: Train Epoch 10: 251/634 Loss: 0.083678
2023-01-03 18:27: Train Epoch 10: 255/634 Loss: 0.105596
2023-01-03 18:28: Train Epoch 10: 259/634 Loss: 0.089568
2023-01-03 18:28: Train Epoch 10: 263/634 Loss: 0.093552
2023-01-03 18:28: Train Epoch 10: 267/634 Loss: 0.104362
2023-01-03 18:28: Train Epoch 10: 271/634 Loss: 0.089271
2023-01-03 18:28: Train Epoch 10: 275/634 Loss: 0.107848
2023-01-03 18:28: Train Epoch 10: 279/634 Loss: 0.094416
2023-01-03 18:29: Train Epoch 10: 283/634 Loss: 0.111640
2023-01-03 18:29: Train Epoch 10: 287/634 Loss: 0.087018
2023-01-03 18:29: Train Epoch 10: 291/634 Loss: 0.092462
2023-01-03 18:29: Train Epoch 10: 295/634 Loss: 0.084672
2023-01-03 18:29: Train Epoch 10: 299/634 Loss: 0.090386
2023-01-03 18:29: Train Epoch 10: 303/634 Loss: 0.105694
2023-01-03 18:29: Train Epoch 10: 307/634 Loss: 0.089265
2023-01-03 18:30: Train Epoch 10: 311/634 Loss: 0.110272
2023-01-03 18:30: Train Epoch 10: 315/634 Loss: 0.097777
2023-01-03 18:30: Train Epoch 10: 319/634 Loss: 0.113092
2023-01-03 18:30: Train Epoch 10: 323/634 Loss: 0.110879
2023-01-03 18:30: Train Epoch 10: 327/634 Loss: 0.071249
2023-01-03 18:31: Train Epoch 10: 331/634 Loss: 0.083020
2023-01-03 18:31: Train Epoch 10: 335/634 Loss: 0.110112
2023-01-03 18:31: Train Epoch 10: 339/634 Loss: 0.101801
2023-01-03 18:31: Train Epoch 10: 343/634 Loss: 0.076471
2023-01-03 18:31: Train Epoch 10: 347/634 Loss: 0.111818
2023-01-03 18:31: Train Epoch 10: 351/634 Loss: 0.088963
2023-01-03 18:31: Train Epoch 10: 355/634 Loss: 0.101912
2023-01-03 18:32: Train Epoch 10: 359/634 Loss: 0.114497
2023-01-03 18:32: Train Epoch 10: 363/634 Loss: 0.108286
2023-01-03 18:32: Train Epoch 10: 367/634 Loss: 0.096074
2023-01-03 18:32: Train Epoch 10: 371/634 Loss: 0.081326
2023-01-03 18:32: Train Epoch 10: 375/634 Loss: 0.086208
2023-01-03 18:32: Train Epoch 10: 379/634 Loss: 0.098673
2023-01-03 18:33: Train Epoch 10: 383/634 Loss: 0.112273
2023-01-03 18:33: Train Epoch 10: 387/634 Loss: 0.082680
2023-01-03 18:33: Train Epoch 10: 391/634 Loss: 0.075813
2023-01-03 18:33: Train Epoch 10: 395/634 Loss: 0.075605
2023-01-03 18:33: Train Epoch 10: 399/634 Loss: 0.096853
2023-01-03 18:33: Train Epoch 10: 403/634 Loss: 0.082646
2023-01-03 18:33: Train Epoch 10: 407/634 Loss: 0.101561
2023-01-03 18:34: Train Epoch 10: 411/634 Loss: 0.072890
2023-01-03 18:34: Train Epoch 10: 415/634 Loss: 0.107027
2023-01-03 18:34: Train Epoch 10: 419/634 Loss: 0.090922
2023-01-03 18:34: Train Epoch 10: 423/634 Loss: 0.111719
2023-01-03 18:34: Train Epoch 10: 427/634 Loss: 0.101867
2023-01-03 18:34: Train Epoch 10: 431/634 Loss: 0.095929
2023-01-03 18:35: Train Epoch 10: 435/634 Loss: 0.104252
2023-01-03 18:35: Train Epoch 10: 439/634 Loss: 0.095039
2023-01-03 18:35: Train Epoch 10: 443/634 Loss: 0.120226
2023-01-03 18:35: Train Epoch 10: 447/634 Loss: 0.101330
2023-01-03 18:35: Train Epoch 10: 451/634 Loss: 0.085601
2023-01-03 18:35: Train Epoch 10: 455/634 Loss: 0.076841
2023-01-03 18:35: Train Epoch 10: 459/634 Loss: 0.080778
2023-01-03 18:36: Train Epoch 10: 463/634 Loss: 0.113810
2023-01-03 18:36: Train Epoch 10: 467/634 Loss: 0.107351
2023-01-03 18:36: Train Epoch 10: 471/634 Loss: 0.080192
2023-01-03 18:36: Train Epoch 10: 475/634 Loss: 0.079201
2023-01-03 18:36: Train Epoch 10: 479/634 Loss: 0.104561
2023-01-03 18:36: Train Epoch 10: 483/634 Loss: 0.105353
2023-01-03 18:37: Train Epoch 10: 487/634 Loss: 0.114029
2023-01-03 18:37: Train Epoch 10: 491/634 Loss: 0.084901
2023-01-03 18:37: Train Epoch 10: 495/634 Loss: 0.094136
2023-01-03 18:37: Train Epoch 10: 499/634 Loss: 0.081845
2023-01-03 18:37: Train Epoch 10: 503/634 Loss: 0.081384
2023-01-03 18:37: Train Epoch 10: 507/634 Loss: 0.097591
2023-01-03 18:37: Train Epoch 10: 511/634 Loss: 0.091046
2023-01-03 18:38: Train Epoch 10: 515/634 Loss: 0.099503
2023-01-03 18:38: Train Epoch 10: 519/634 Loss: 0.092770
2023-01-03 18:38: Train Epoch 10: 523/634 Loss: 0.095392
2023-01-03 18:38: Train Epoch 10: 527/634 Loss: 0.110662
2023-01-03 18:38: Train Epoch 10: 531/634 Loss: 0.119831
2023-01-03 18:38: Train Epoch 10: 535/634 Loss: 0.074981
2023-01-03 18:39: Train Epoch 10: 539/634 Loss: 0.104506
2023-01-03 18:39: Train Epoch 10: 543/634 Loss: 0.103790
2023-01-03 18:39: Train Epoch 10: 547/634 Loss: 0.093746
2023-01-03 18:39: Train Epoch 10: 551/634 Loss: 0.096158
2023-01-03 18:39: Train Epoch 10: 555/634 Loss: 0.096021
2023-01-03 18:39: Train Epoch 10: 559/634 Loss: 0.084528
2023-01-03 18:39: Train Epoch 10: 563/634 Loss: 0.082880
2023-01-03 18:40: Train Epoch 10: 567/634 Loss: 0.093914
2023-01-03 18:40: Train Epoch 10: 571/634 Loss: 0.068330
2023-01-03 18:40: Train Epoch 10: 575/634 Loss: 0.127973
2023-01-03 18:40: Train Epoch 10: 579/634 Loss: 0.079137
2023-01-03 18:40: Train Epoch 10: 583/634 Loss: 0.092848
2023-01-03 18:41: Train Epoch 10: 587/634 Loss: 0.101304
2023-01-03 18:41: Train Epoch 10: 591/634 Loss: 0.107679
2023-01-03 18:41: Train Epoch 10: 595/634 Loss: 0.078172
2023-01-03 18:41: Train Epoch 10: 599/634 Loss: 0.086232
2023-01-03 18:41: Train Epoch 10: 603/634 Loss: 0.073820
2023-01-03 18:41: Train Epoch 10: 607/634 Loss: 0.096479
2023-01-03 18:41: Train Epoch 10: 611/634 Loss: 0.096844
2023-01-03 18:42: Train Epoch 10: 615/634 Loss: 0.076137
2023-01-03 18:42: Train Epoch 10: 619/634 Loss: 0.099862
2023-01-03 18:42: Train Epoch 10: 623/634 Loss: 0.094019
2023-01-03 18:42: Train Epoch 10: 627/634 Loss: 0.066289
2023-01-03 18:42: Train Epoch 10: 631/634 Loss: 0.116497
2023-01-03 18:42: Train Epoch 10: 633/634 Loss: 0.028375
2023-01-03 18:42: **********Train Epoch 10: averaged Loss: 0.093595 
2023-01-03 18:42: 
Epoch time elapsed: 1507.9672770500183

2023-01-03 18:43: 
 metrics validation: {'precision': 0.8340248962655602, 'recall': 0.6184615384615385, 'f1-score': 0.7102473498233216, 'support': 1300, 'AUC': 0.9098396449704143, 'AUCPR': 0.8398057543829003, 'TP': 804, 'FP': 160, 'TN': 2440, 'FN': 496} 

2023-01-03 18:43: **********Val Epoch 10: average Loss: 0.196036
2023-01-03 18:44: 
 Testing metrics {'precision': 0.8317853457172343, 'recall': 0.6563517915309446, 'f1-score': 0.7337278106508875, 'support': 1228, 'AUC': 0.8932057634563761, 'AUCPR': 0.8280634275305611, 'TP': 806, 'FP': 163, 'TN': 2293, 'FN': 422} 

2023-01-03 18:46: 
 Testing metrics {'precision': 0.8994082840236687, 'recall': 0.8622645790787383, 'f1-score': 0.8804448563484707, 'support': 4407, 'AUC': 0.9701584299046904, 'AUCPR': 0.9377668214608286, 'TP': 3800, 'FP': 425, 'TN': 8389, 'FN': 607} 

2023-01-03 18:46: Train Epoch 11: 3/634 Loss: 0.093899
2023-01-03 18:47: Train Epoch 11: 7/634 Loss: 0.083596
2023-01-03 18:47: Train Epoch 11: 11/634 Loss: 0.122372
2023-01-03 18:47: Train Epoch 11: 15/634 Loss: 0.130225
2023-01-03 18:47: Train Epoch 11: 19/634 Loss: 0.108644
2023-01-03 18:47: Train Epoch 11: 23/634 Loss: 0.088765
2023-01-03 18:47: Train Epoch 11: 27/634 Loss: 0.074334
2023-01-03 18:47: Train Epoch 11: 31/634 Loss: 0.103368
2023-01-03 18:48: Train Epoch 11: 35/634 Loss: 0.072710
2023-01-03 18:48: Train Epoch 11: 39/634 Loss: 0.081858
2023-01-03 18:48: Train Epoch 11: 43/634 Loss: 0.110050
2023-01-03 18:48: Train Epoch 11: 47/634 Loss: 0.089079
2023-01-03 18:48: Train Epoch 11: 51/634 Loss: 0.101109
2023-01-03 18:48: Train Epoch 11: 55/634 Loss: 0.080998
2023-01-03 18:48: Train Epoch 11: 59/634 Loss: 0.091485
2023-01-03 18:49: Train Epoch 11: 63/634 Loss: 0.117749
2023-01-03 18:49: Train Epoch 11: 67/634 Loss: 0.103075
2023-01-03 18:49: Train Epoch 11: 71/634 Loss: 0.084415
2023-01-03 18:49: Train Epoch 11: 75/634 Loss: 0.078577
2023-01-03 18:49: Train Epoch 11: 79/634 Loss: 0.118661
2023-01-03 18:49: Train Epoch 11: 83/634 Loss: 0.084634
2023-01-03 18:50: Train Epoch 11: 87/634 Loss: 0.091318
2023-01-03 18:50: Train Epoch 11: 91/634 Loss: 0.102390
2023-01-03 18:50: Train Epoch 11: 95/634 Loss: 0.119023
2023-01-03 18:50: Train Epoch 11: 99/634 Loss: 0.085658
2023-01-03 18:50: Train Epoch 11: 103/634 Loss: 0.103897
2023-01-03 18:50: Train Epoch 11: 107/634 Loss: 0.096303
2023-01-03 18:51: Train Epoch 11: 111/634 Loss: 0.094199
2023-01-03 18:51: Train Epoch 11: 115/634 Loss: 0.102270
2023-01-03 18:51: Train Epoch 11: 119/634 Loss: 0.083401
2023-01-03 18:51: Train Epoch 11: 123/634 Loss: 0.090329
2023-01-03 18:51: Train Epoch 11: 127/634 Loss: 0.085383
2023-01-03 18:51: Train Epoch 11: 131/634 Loss: 0.085552
2023-01-03 18:51: Train Epoch 11: 135/634 Loss: 0.086370
2023-01-03 18:52: Train Epoch 11: 139/634 Loss: 0.102585
2023-01-03 18:52: Train Epoch 11: 143/634 Loss: 0.117788
2023-01-03 18:52: Train Epoch 11: 147/634 Loss: 0.068813
2023-01-03 18:52: Train Epoch 11: 151/634 Loss: 0.085671
2023-01-03 18:52: Train Epoch 11: 155/634 Loss: 0.103422
2023-01-03 18:52: Train Epoch 11: 159/634 Loss: 0.101124
2023-01-03 18:53: Train Epoch 11: 163/634 Loss: 0.089518
2023-01-03 18:53: Train Epoch 11: 167/634 Loss: 0.081385
2023-01-03 18:53: Train Epoch 11: 171/634 Loss: 0.092154
2023-01-03 18:53: Train Epoch 11: 175/634 Loss: 0.093540
2023-01-03 18:53: Train Epoch 11: 179/634 Loss: 0.083654
2023-01-03 18:53: Train Epoch 11: 183/634 Loss: 0.075317
2023-01-03 18:53: Train Epoch 11: 187/634 Loss: 0.090022
2023-01-03 18:54: Train Epoch 11: 191/634 Loss: 0.107472
2023-01-03 18:54: Train Epoch 11: 195/634 Loss: 0.081375
2023-01-03 18:54: Train Epoch 11: 199/634 Loss: 0.095218
2023-01-03 18:54: Train Epoch 11: 203/634 Loss: 0.092531
2023-01-03 18:54: Train Epoch 11: 207/634 Loss: 0.079990
2023-01-03 18:54: Train Epoch 11: 211/634 Loss: 0.101373
2023-01-03 18:55: Train Epoch 11: 215/634 Loss: 0.087506
2023-01-03 18:55: Train Epoch 11: 219/634 Loss: 0.109153
2023-01-03 18:55: Train Epoch 11: 223/634 Loss: 0.093096
2023-01-03 18:55: Train Epoch 11: 227/634 Loss: 0.124315
2023-01-03 18:55: Train Epoch 11: 231/634 Loss: 0.097463
2023-01-03 18:55: Train Epoch 11: 235/634 Loss: 0.089202
2023-01-03 18:55: Train Epoch 11: 239/634 Loss: 0.111768
2023-01-03 18:56: Train Epoch 11: 243/634 Loss: 0.101135
2023-01-03 18:56: Train Epoch 11: 247/634 Loss: 0.073213
2023-01-03 18:56: Train Epoch 11: 251/634 Loss: 0.106288
2023-01-03 18:56: Train Epoch 11: 255/634 Loss: 0.065296
2023-01-03 18:56: Train Epoch 11: 259/634 Loss: 0.094657
2023-01-03 18:56: Train Epoch 11: 263/634 Loss: 0.100998
2023-01-03 18:57: Train Epoch 11: 267/634 Loss: 0.101492
2023-01-03 18:57: Train Epoch 11: 271/634 Loss: 0.076128
2023-01-03 18:57: Train Epoch 11: 275/634 Loss: 0.093173
2023-01-03 18:57: Train Epoch 11: 279/634 Loss: 0.071288
2023-01-03 18:57: Train Epoch 11: 283/634 Loss: 0.114667
2023-01-03 18:57: Train Epoch 11: 287/634 Loss: 0.091722
2023-01-03 18:57: Train Epoch 11: 291/634 Loss: 0.093348
2023-01-03 18:58: Train Epoch 11: 295/634 Loss: 0.073794
2023-01-03 18:58: Train Epoch 11: 299/634 Loss: 0.103663
2023-01-03 18:58: Train Epoch 11: 303/634 Loss: 0.108013
2023-01-03 18:58: Train Epoch 11: 307/634 Loss: 0.092411
2023-01-03 18:58: Train Epoch 11: 311/634 Loss: 0.095092
2023-01-03 18:58: Train Epoch 11: 315/634 Loss: 0.106992
2023-01-03 18:59: Train Epoch 11: 319/634 Loss: 0.131825
2023-01-03 18:59: Train Epoch 11: 323/634 Loss: 0.074883
2023-01-03 18:59: Train Epoch 11: 327/634 Loss: 0.101101
2023-01-03 18:59: Train Epoch 11: 331/634 Loss: 0.111142
2023-01-03 18:59: Train Epoch 11: 335/634 Loss: 0.099244
2023-01-03 18:59: Train Epoch 11: 339/634 Loss: 0.091945
2023-01-03 18:59: Train Epoch 11: 343/634 Loss: 0.070674
2023-01-03 19:00: Train Epoch 11: 347/634 Loss: 0.128379
2023-01-03 19:00: Train Epoch 11: 351/634 Loss: 0.068065
2023-01-03 19:00: Train Epoch 11: 355/634 Loss: 0.121076
2023-01-03 19:00: Train Epoch 11: 359/634 Loss: 0.091590
2023-01-03 19:00: Train Epoch 11: 363/634 Loss: 0.092414
2023-01-03 19:00: Train Epoch 11: 367/634 Loss: 0.110728
2023-01-03 19:01: Train Epoch 11: 371/634 Loss: 0.123360
2023-01-03 19:01: Train Epoch 11: 375/634 Loss: 0.082385
2023-01-03 19:01: Train Epoch 11: 379/634 Loss: 0.093125
2023-01-03 19:01: Train Epoch 11: 383/634 Loss: 0.124236
2023-01-03 19:01: Train Epoch 11: 387/634 Loss: 0.074347
2023-01-03 19:01: Train Epoch 11: 391/634 Loss: 0.084416
2023-01-03 19:02: Train Epoch 11: 395/634 Loss: 0.093645
2023-01-03 19:02: Train Epoch 11: 399/634 Loss: 0.088409
2023-01-03 19:02: Train Epoch 11: 403/634 Loss: 0.075027
2023-01-03 19:02: Train Epoch 11: 407/634 Loss: 0.099507
2023-01-03 19:02: Train Epoch 11: 411/634 Loss: 0.086388
2023-01-03 19:02: Train Epoch 11: 415/634 Loss: 0.079392
2023-01-03 19:02: Train Epoch 11: 419/634 Loss: 0.107680
2023-01-03 19:03: Train Epoch 11: 423/634 Loss: 0.069289
2023-01-03 19:03: Train Epoch 11: 427/634 Loss: 0.076718
2023-01-03 19:03: Train Epoch 11: 431/634 Loss: 0.106106
2023-01-03 19:03: Train Epoch 11: 435/634 Loss: 0.076392
2023-01-03 19:03: Train Epoch 11: 439/634 Loss: 0.113763
2023-01-03 19:03: Train Epoch 11: 443/634 Loss: 0.094448
2023-01-03 19:04: Train Epoch 11: 447/634 Loss: 0.096216
2023-01-03 19:04: Train Epoch 11: 451/634 Loss: 0.097293
2023-01-03 19:04: Train Epoch 11: 455/634 Loss: 0.095748
2023-01-03 19:04: Train Epoch 11: 459/634 Loss: 0.096557
2023-01-03 19:04: Train Epoch 11: 463/634 Loss: 0.104414
2023-01-03 19:04: Train Epoch 11: 467/634 Loss: 0.092552
2023-01-03 19:04: Train Epoch 11: 471/634 Loss: 0.096534
2023-01-03 19:05: Train Epoch 11: 475/634 Loss: 0.093853
2023-01-03 19:05: Train Epoch 11: 479/634 Loss: 0.115568
2023-01-03 19:05: Train Epoch 11: 483/634 Loss: 0.094431
2023-01-03 19:05: Train Epoch 11: 487/634 Loss: 0.088939
2023-01-03 19:05: Train Epoch 11: 491/634 Loss: 0.104102
2023-01-03 19:05: Train Epoch 11: 495/634 Loss: 0.098893
2023-01-03 19:06: Train Epoch 11: 499/634 Loss: 0.097501
2023-01-03 19:06: Train Epoch 11: 503/634 Loss: 0.073883
2023-01-03 19:06: Train Epoch 11: 507/634 Loss: 0.108035
2023-01-03 19:06: Train Epoch 11: 511/634 Loss: 0.091326
2023-01-03 19:06: Train Epoch 11: 515/634 Loss: 0.096409
2023-01-03 19:06: Train Epoch 11: 519/634 Loss: 0.102008
2023-01-03 19:06: Train Epoch 11: 523/634 Loss: 0.077541
2023-01-03 19:07: Train Epoch 11: 527/634 Loss: 0.078514
2023-01-03 19:07: Train Epoch 11: 531/634 Loss: 0.084686
2023-01-03 19:07: Train Epoch 11: 535/634 Loss: 0.094269
2023-01-03 19:07: Train Epoch 11: 539/634 Loss: 0.104634
2023-01-03 19:07: Train Epoch 11: 543/634 Loss: 0.080149
2023-01-03 19:07: Train Epoch 11: 547/634 Loss: 0.097261
2023-01-03 19:08: Train Epoch 11: 551/634 Loss: 0.074065
2023-01-03 19:08: Train Epoch 11: 555/634 Loss: 0.083414
2023-01-03 19:08: Train Epoch 11: 559/634 Loss: 0.068055
2023-01-03 19:08: Train Epoch 11: 563/634 Loss: 0.076471
2023-01-03 19:08: Train Epoch 11: 567/634 Loss: 0.094783
2023-01-03 19:08: Train Epoch 11: 571/634 Loss: 0.092976
2023-01-03 19:08: Train Epoch 11: 575/634 Loss: 0.128889
2023-01-03 19:09: Train Epoch 11: 579/634 Loss: 0.087183
2023-01-03 19:09: Train Epoch 11: 583/634 Loss: 0.096233
2023-01-03 19:09: Train Epoch 11: 587/634 Loss: 0.094246
2023-01-03 19:09: Train Epoch 11: 591/634 Loss: 0.095065
2023-01-03 19:09: Train Epoch 11: 595/634 Loss: 0.100726
2023-01-03 19:09: Train Epoch 11: 599/634 Loss: 0.083582
2023-01-03 19:10: Train Epoch 11: 603/634 Loss: 0.089560
2023-01-03 19:10: Train Epoch 11: 607/634 Loss: 0.105377
2023-01-03 19:10: Train Epoch 11: 611/634 Loss: 0.103270
2023-01-03 19:10: Train Epoch 11: 615/634 Loss: 0.108485
2023-01-03 19:10: Train Epoch 11: 619/634 Loss: 0.095727
2023-01-03 19:10: Train Epoch 11: 623/634 Loss: 0.102850
2023-01-03 19:10: Train Epoch 11: 627/634 Loss: 0.111787
2023-01-03 19:11: Train Epoch 11: 631/634 Loss: 0.093304
2023-01-03 19:11: Train Epoch 11: 633/634 Loss: 0.026734
2023-01-03 19:11: **********Train Epoch 11: averaged Loss: 0.094216 
2023-01-03 19:11: 
Epoch time elapsed: 1472.5916471481323

2023-01-03 19:12: 
 metrics validation: {'precision': 0.8084112149532711, 'recall': 0.6653846153846154, 'f1-score': 0.729957805907173, 'support': 1300, 'AUC': 0.9102405325443788, 'AUCPR': 0.8383752515217953, 'TP': 865, 'FP': 205, 'TN': 2395, 'FN': 435} 

2023-01-03 19:12: **********Val Epoch 11: average Loss: 0.183033
2023-01-03 19:12: 
 Testing metrics {'precision': 0.8317853457172343, 'recall': 0.6563517915309446, 'f1-score': 0.7337278106508875, 'support': 1228, 'AUC': 0.8932057634563761, 'AUCPR': 0.8280634275305611, 'TP': 806, 'FP': 163, 'TN': 2293, 'FN': 422} 

2023-01-03 19:15: 
 Testing metrics {'precision': 0.8994082840236687, 'recall': 0.8622645790787383, 'f1-score': 0.8804448563484707, 'support': 4407, 'AUC': 0.9701584299046904, 'AUCPR': 0.9377668214608286, 'TP': 3800, 'FP': 425, 'TN': 8389, 'FN': 607} 

2023-01-03 19:15: Train Epoch 12: 3/634 Loss: 0.099810
2023-01-03 19:15: Train Epoch 12: 7/634 Loss: 0.062045
2023-01-03 19:15: Train Epoch 12: 11/634 Loss: 0.067542
2023-01-03 19:15: Train Epoch 12: 15/634 Loss: 0.119417
2023-01-03 19:16: Train Epoch 12: 19/634 Loss: 0.091592
2023-01-03 19:16: Train Epoch 12: 23/634 Loss: 0.106843
2023-01-03 19:16: Train Epoch 12: 27/634 Loss: 0.091328
2023-01-03 19:16: Train Epoch 12: 31/634 Loss: 0.099479
2023-01-03 19:16: Train Epoch 12: 35/634 Loss: 0.133517
2023-01-03 19:16: Train Epoch 12: 39/634 Loss: 0.090577
2023-01-03 19:17: Train Epoch 12: 43/634 Loss: 0.073587
2023-01-03 19:17: Train Epoch 12: 47/634 Loss: 0.117151
2023-01-03 19:17: Train Epoch 12: 51/634 Loss: 0.085372
2023-01-03 19:17: Train Epoch 12: 55/634 Loss: 0.110568
2023-01-03 19:17: Train Epoch 12: 59/634 Loss: 0.101975
2023-01-03 19:17: Train Epoch 12: 63/634 Loss: 0.093113
2023-01-03 19:17: Train Epoch 12: 67/634 Loss: 0.105493
2023-01-03 19:18: Train Epoch 12: 71/634 Loss: 0.115580
2023-01-03 19:18: Train Epoch 12: 75/634 Loss: 0.100584
2023-01-03 19:18: Train Epoch 12: 79/634 Loss: 0.095580
2023-01-03 19:18: Train Epoch 12: 83/634 Loss: 0.108859
2023-01-03 19:18: Train Epoch 12: 87/634 Loss: 0.083692
2023-01-03 19:18: Train Epoch 12: 91/634 Loss: 0.095538
2023-01-03 19:19: Train Epoch 12: 95/634 Loss: 0.097173
2023-01-03 19:19: Train Epoch 12: 99/634 Loss: 0.137680
2023-01-03 19:19: Train Epoch 12: 103/634 Loss: 0.104006
2023-01-03 19:19: Train Epoch 12: 107/634 Loss: 0.079268
2023-01-03 19:19: Train Epoch 12: 111/634 Loss: 0.117069
2023-01-03 19:19: Train Epoch 12: 115/634 Loss: 0.093586
2023-01-03 19:19: Train Epoch 12: 119/634 Loss: 0.106282
2023-01-03 19:20: Train Epoch 12: 123/634 Loss: 0.096905
2023-01-03 19:20: Train Epoch 12: 127/634 Loss: 0.102093
2023-01-03 19:20: Train Epoch 12: 131/634 Loss: 0.075784
2023-01-03 19:20: Train Epoch 12: 135/634 Loss: 0.096911
2023-01-03 19:20: Train Epoch 12: 139/634 Loss: 0.075962
2023-01-03 19:20: Train Epoch 12: 143/634 Loss: 0.074818
2023-01-03 19:21: Train Epoch 12: 147/634 Loss: 0.094189
2023-01-03 19:21: Train Epoch 12: 151/634 Loss: 0.105189
2023-01-03 19:21: Train Epoch 12: 155/634 Loss: 0.084903
2023-01-03 19:21: Train Epoch 12: 159/634 Loss: 0.101623
2023-01-03 19:21: Train Epoch 12: 163/634 Loss: 0.092358
2023-01-03 19:21: Train Epoch 12: 167/634 Loss: 0.079717
2023-01-03 19:21: Train Epoch 12: 171/634 Loss: 0.094204
2023-01-03 19:22: Train Epoch 12: 175/634 Loss: 0.073704
2023-01-03 19:22: Train Epoch 12: 179/634 Loss: 0.083321
2023-01-03 19:22: Train Epoch 12: 183/634 Loss: 0.122768
2023-01-03 19:22: Train Epoch 12: 187/634 Loss: 0.098860
2023-01-03 19:22: Train Epoch 12: 191/634 Loss: 0.111070
2023-01-03 19:22: Train Epoch 12: 195/634 Loss: 0.090845
2023-01-03 19:23: Train Epoch 12: 199/634 Loss: 0.104321
2023-01-03 19:23: Train Epoch 12: 203/634 Loss: 0.087539
2023-01-03 19:23: Train Epoch 12: 207/634 Loss: 0.107638
2023-01-03 19:23: Train Epoch 12: 211/634 Loss: 0.079085
2023-01-03 19:23: Train Epoch 12: 215/634 Loss: 0.083789
2023-01-03 19:23: Train Epoch 12: 219/634 Loss: 0.092731
2023-01-03 19:23: Train Epoch 12: 223/634 Loss: 0.093767
2023-01-03 19:24: Train Epoch 12: 227/634 Loss: 0.096501
2023-01-03 19:24: Train Epoch 12: 231/634 Loss: 0.088739
2023-01-03 19:24: Train Epoch 12: 235/634 Loss: 0.083004
2023-01-03 19:24: Train Epoch 12: 239/634 Loss: 0.093524
2023-01-03 19:24: Train Epoch 12: 243/634 Loss: 0.094901
2023-01-03 19:24: Train Epoch 12: 247/634 Loss: 0.093937
2023-01-03 19:25: Train Epoch 12: 251/634 Loss: 0.077286
2023-01-03 19:25: Train Epoch 12: 255/634 Loss: 0.084588
2023-01-03 19:25: Train Epoch 12: 259/634 Loss: 0.078023
2023-01-03 19:25: Train Epoch 12: 263/634 Loss: 0.108443
2023-01-03 19:25: Train Epoch 12: 267/634 Loss: 0.107098
2023-01-03 19:25: Train Epoch 12: 271/634 Loss: 0.100620
2023-01-03 19:26: Train Epoch 12: 275/634 Loss: 0.082172
2023-01-03 19:26: Train Epoch 12: 279/634 Loss: 0.084597
2023-01-03 19:26: Train Epoch 12: 283/634 Loss: 0.097598
2023-01-03 19:26: Train Epoch 12: 287/634 Loss: 0.098849
2023-01-03 19:26: Train Epoch 12: 291/634 Loss: 0.112721
2023-01-03 19:26: Train Epoch 12: 295/634 Loss: 0.096008
2023-01-03 19:26: Train Epoch 12: 299/634 Loss: 0.106766
2023-01-03 19:27: Train Epoch 12: 303/634 Loss: 0.094666
2023-01-03 19:27: Train Epoch 12: 307/634 Loss: 0.084864
2023-01-03 19:27: Train Epoch 12: 311/634 Loss: 0.105542
2023-01-03 19:27: Train Epoch 12: 315/634 Loss: 0.088867
2023-01-03 19:27: Train Epoch 12: 319/634 Loss: 0.089116
2023-01-03 19:27: Train Epoch 12: 323/634 Loss: 0.097842
2023-01-03 19:28: Train Epoch 12: 327/634 Loss: 0.098410
2023-01-03 19:28: Train Epoch 12: 331/634 Loss: 0.093992
2023-01-03 19:28: Train Epoch 12: 335/634 Loss: 0.077642
2023-01-03 19:28: Train Epoch 12: 339/634 Loss: 0.094079
2023-01-03 19:28: Train Epoch 12: 343/634 Loss: 0.095202
2023-01-03 19:28: Train Epoch 12: 347/634 Loss: 0.140203
2023-01-03 19:29: Train Epoch 12: 351/634 Loss: 0.094423
2023-01-03 19:29: Train Epoch 12: 355/634 Loss: 0.095419
2023-01-03 19:29: Train Epoch 12: 359/634 Loss: 0.098419
2023-01-03 19:29: Train Epoch 12: 363/634 Loss: 0.109533
2023-01-03 19:29: Train Epoch 12: 367/634 Loss: 0.106908
2023-01-03 19:29: Train Epoch 12: 371/634 Loss: 0.089727
2023-01-03 19:29: Train Epoch 12: 375/634 Loss: 0.109843
2023-01-03 19:30: Train Epoch 12: 379/634 Loss: 0.087100
2023-01-03 19:30: Train Epoch 12: 383/634 Loss: 0.154593
2023-01-03 19:30: Train Epoch 12: 387/634 Loss: 0.108198
2023-01-03 19:30: Train Epoch 12: 391/634 Loss: 0.070695
2023-01-03 19:30: Train Epoch 12: 395/634 Loss: 0.092714
2023-01-03 19:31: Train Epoch 12: 399/634 Loss: 0.091541
2023-01-03 19:31: Train Epoch 12: 403/634 Loss: 0.089053
2023-01-03 19:31: Train Epoch 12: 407/634 Loss: 0.105366
2023-01-03 19:31: Train Epoch 12: 411/634 Loss: 0.099787
2023-01-03 19:31: Train Epoch 12: 415/634 Loss: 0.097150
2023-01-03 19:31: Train Epoch 12: 419/634 Loss: 0.073799
2023-01-03 19:32: Train Epoch 12: 423/634 Loss: 0.080698
2023-01-03 19:32: Train Epoch 12: 427/634 Loss: 0.099156
2023-01-03 19:32: Train Epoch 12: 431/634 Loss: 0.073972
2023-01-03 19:32: Train Epoch 12: 435/634 Loss: 0.080494
2023-01-03 19:32: Train Epoch 12: 439/634 Loss: 0.087828
2023-01-03 19:32: Train Epoch 12: 443/634 Loss: 0.079623
2023-01-03 19:33: Train Epoch 12: 447/634 Loss: 0.078626
2023-01-03 19:33: Train Epoch 12: 451/634 Loss: 0.096278
2023-01-03 19:33: Train Epoch 12: 455/634 Loss: 0.075911
2023-01-03 19:33: Train Epoch 12: 459/634 Loss: 0.091575
2023-01-03 19:33: Train Epoch 12: 463/634 Loss: 0.115271
2023-01-03 19:34: Train Epoch 12: 467/634 Loss: 0.098502
2023-01-03 19:34: Train Epoch 12: 471/634 Loss: 0.089223
2023-01-03 19:34: Train Epoch 12: 475/634 Loss: 0.064512
2023-01-03 19:34: Train Epoch 12: 479/634 Loss: 0.094970
2023-01-03 19:34: Train Epoch 12: 483/634 Loss: 0.084762
2023-01-03 19:34: Train Epoch 12: 487/634 Loss: 0.099525
2023-01-03 19:35: Train Epoch 12: 491/634 Loss: 0.096437
2023-01-03 19:35: Train Epoch 12: 495/634 Loss: 0.084591
2023-01-03 19:35: Train Epoch 12: 499/634 Loss: 0.111877
2023-01-03 19:35: Train Epoch 12: 503/634 Loss: 0.073478
2023-01-03 19:35: Train Epoch 12: 507/634 Loss: 0.078736
2023-01-03 19:35: Train Epoch 12: 511/634 Loss: 0.067202
2023-01-03 19:36: Train Epoch 12: 515/634 Loss: 0.080673
2023-01-03 19:36: Train Epoch 12: 519/634 Loss: 0.088662
2023-01-03 19:36: Train Epoch 12: 523/634 Loss: 0.080980
2023-01-03 19:36: Train Epoch 12: 527/634 Loss: 0.102002
2023-01-03 19:36: Train Epoch 12: 531/634 Loss: 0.109961
2023-01-03 19:37: Train Epoch 12: 535/634 Loss: 0.092306
2023-01-03 19:37: Train Epoch 12: 539/634 Loss: 0.103078
2023-01-03 19:37: Train Epoch 12: 543/634 Loss: 0.083929
2023-01-03 19:37: Train Epoch 12: 547/634 Loss: 0.075239
2023-01-03 19:37: Train Epoch 12: 551/634 Loss: 0.093610
2023-01-03 19:37: Train Epoch 12: 555/634 Loss: 0.079776
2023-01-03 19:38: Train Epoch 12: 559/634 Loss: 0.096375
2023-01-03 19:38: Train Epoch 12: 563/634 Loss: 0.092738
2023-01-03 19:38: Train Epoch 12: 567/634 Loss: 0.128499
2023-01-03 19:38: Train Epoch 12: 571/634 Loss: 0.101704
2023-01-03 19:38: Train Epoch 12: 575/634 Loss: 0.078741
2023-01-03 19:38: Train Epoch 12: 579/634 Loss: 0.091496
2023-01-03 19:39: Train Epoch 12: 583/634 Loss: 0.126375
2023-01-03 19:39: Train Epoch 12: 587/634 Loss: 0.087792
2023-01-03 19:39: Train Epoch 12: 591/634 Loss: 0.085858
2023-01-03 19:39: Train Epoch 12: 595/634 Loss: 0.082326
2023-01-03 19:39: Train Epoch 12: 599/634 Loss: 0.100423
2023-01-03 19:39: Train Epoch 12: 603/634 Loss: 0.095305
2023-01-03 19:40: Train Epoch 12: 607/634 Loss: 0.084600
2023-01-03 19:40: Train Epoch 12: 611/634 Loss: 0.117409
2023-01-03 19:40: Train Epoch 12: 615/634 Loss: 0.083480
2023-01-03 19:40: Train Epoch 12: 619/634 Loss: 0.090292
2023-01-03 19:40: Train Epoch 12: 623/634 Loss: 0.108304
2023-01-03 19:40: Train Epoch 12: 627/634 Loss: 0.103248
2023-01-03 19:40: Train Epoch 12: 631/634 Loss: 0.108970
2023-01-03 19:41: Train Epoch 12: 633/634 Loss: 0.030975
2023-01-03 19:41: **********Train Epoch 12: averaged Loss: 0.094320 
2023-01-03 19:41: 
Epoch time elapsed: 1540.964540719986

2023-01-03 19:41: 
 metrics validation: {'precision': 0.8041704442429737, 'recall': 0.6823076923076923, 'f1-score': 0.7382438618393675, 'support': 1300, 'AUC': 0.9140579881656805, 'AUCPR': 0.8465966601697213, 'TP': 887, 'FP': 216, 'TN': 2384, 'FN': 413} 

2023-01-03 19:41: **********Val Epoch 12: average Loss: 0.174957
2023-01-03 19:41: *********************************Current best model saved!
2023-01-03 19:42: 
 Testing metrics {'precision': 0.8382045929018789, 'recall': 0.6539087947882736, 'f1-score': 0.7346752058554437, 'support': 1228, 'AUC': 0.8971202612229306, 'AUCPR': 0.8353423276968397, 'TP': 803, 'FP': 155, 'TN': 2301, 'FN': 425} 

2023-01-03 19:45: 
 Testing metrics {'precision': 0.9028627355028138, 'recall': 0.8373042886317222, 'f1-score': 0.8688485990110666, 'support': 4407, 'AUC': 0.9702172560115776, 'AUCPR': 0.9371427967906424, 'TP': 3690, 'FP': 397, 'TN': 8417, 'FN': 717} 

2023-01-03 19:45: Train Epoch 13: 3/634 Loss: 0.098895
2023-01-03 19:45: Train Epoch 13: 7/634 Loss: 0.101396
2023-01-03 19:45: Train Epoch 13: 11/634 Loss: 0.090183
2023-01-03 19:45: Train Epoch 13: 15/634 Loss: 0.096996
2023-01-03 19:45: Train Epoch 13: 19/634 Loss: 0.081214
2023-01-03 19:45: Train Epoch 13: 23/634 Loss: 0.087382
2023-01-03 19:46: Train Epoch 13: 27/634 Loss: 0.078973
2023-01-03 19:46: Train Epoch 13: 31/634 Loss: 0.096488
2023-01-03 19:46: Train Epoch 13: 35/634 Loss: 0.093443
2023-01-03 19:46: Train Epoch 13: 39/634 Loss: 0.084017
2023-01-03 19:46: Train Epoch 13: 43/634 Loss: 0.092380
2023-01-03 19:46: Train Epoch 13: 47/634 Loss: 0.091204
2023-01-03 19:47: Train Epoch 13: 51/634 Loss: 0.099648
2023-01-03 19:47: Train Epoch 13: 55/634 Loss: 0.078551
2023-01-03 19:47: Train Epoch 13: 59/634 Loss: 0.080067
2023-01-03 19:47: Train Epoch 13: 63/634 Loss: 0.109892
2023-01-03 19:47: Train Epoch 13: 67/634 Loss: 0.080882
2023-01-03 19:47: Train Epoch 13: 71/634 Loss: 0.106455
2023-01-03 19:47: Train Epoch 13: 75/634 Loss: 0.107505
2023-01-03 19:48: Train Epoch 13: 79/634 Loss: 0.069100
2023-01-03 19:48: Train Epoch 13: 83/634 Loss: 0.077002
2023-01-03 19:48: Train Epoch 13: 87/634 Loss: 0.091117
2023-01-03 19:48: Train Epoch 13: 91/634 Loss: 0.125322
2023-01-03 19:48: Train Epoch 13: 95/634 Loss: 0.065400
2023-01-03 19:48: Train Epoch 13: 99/634 Loss: 0.097934
2023-01-03 19:48: Train Epoch 13: 103/634 Loss: 0.092725
2023-01-03 19:49: Train Epoch 13: 107/634 Loss: 0.077154
2023-01-03 19:49: Train Epoch 13: 111/634 Loss: 0.091103
2023-01-03 19:49: Train Epoch 13: 115/634 Loss: 0.083487
2023-01-03 19:49: Train Epoch 13: 119/634 Loss: 0.102917
2023-01-03 19:49: Train Epoch 13: 123/634 Loss: 0.081776
2023-01-03 19:49: Train Epoch 13: 127/634 Loss: 0.122297
2023-01-03 19:50: Train Epoch 13: 131/634 Loss: 0.101425
2023-01-03 19:50: Train Epoch 13: 135/634 Loss: 0.100712
2023-01-03 19:50: Train Epoch 13: 139/634 Loss: 0.106776
2023-01-03 19:50: Train Epoch 13: 143/634 Loss: 0.114118
2023-01-03 19:50: Train Epoch 13: 147/634 Loss: 0.078854
2023-01-03 19:50: Train Epoch 13: 151/634 Loss: 0.117083
2023-01-03 19:51: Train Epoch 13: 155/634 Loss: 0.092408
2023-01-03 19:51: Train Epoch 13: 159/634 Loss: 0.074966
2023-01-03 19:51: Train Epoch 13: 163/634 Loss: 0.075584
2023-01-03 19:51: Train Epoch 13: 167/634 Loss: 0.089960
2023-01-03 19:51: Train Epoch 13: 171/634 Loss: 0.087666
2023-01-03 19:51: Train Epoch 13: 175/634 Loss: 0.093242
2023-01-03 19:52: Train Epoch 13: 179/634 Loss: 0.087148
2023-01-03 19:52: Train Epoch 13: 183/634 Loss: 0.104990
2023-01-03 19:52: Train Epoch 13: 187/634 Loss: 0.085959
2023-01-03 19:52: Train Epoch 13: 191/634 Loss: 0.099389
2023-01-03 19:52: Train Epoch 13: 195/634 Loss: 0.082424
2023-01-03 19:52: Train Epoch 13: 199/634 Loss: 0.101420
2023-01-03 19:52: Train Epoch 13: 203/634 Loss: 0.091391
2023-01-03 19:53: Train Epoch 13: 207/634 Loss: 0.089464
2023-01-03 19:53: Train Epoch 13: 211/634 Loss: 0.086699
2023-01-03 19:53: Train Epoch 13: 215/634 Loss: 0.073165
2023-01-03 19:53: Train Epoch 13: 219/634 Loss: 0.087145
2023-01-03 19:53: Train Epoch 13: 223/634 Loss: 0.094117
2023-01-03 19:53: Train Epoch 13: 227/634 Loss: 0.089512
2023-01-03 19:54: Train Epoch 13: 231/634 Loss: 0.101141
2023-01-03 19:54: Train Epoch 13: 235/634 Loss: 0.084214
2023-01-03 19:54: Train Epoch 13: 239/634 Loss: 0.078507
2023-01-03 19:54: Train Epoch 13: 243/634 Loss: 0.073099
2023-01-03 19:54: Train Epoch 13: 247/634 Loss: 0.096800
2023-01-03 19:54: Train Epoch 13: 251/634 Loss: 0.060171
2023-01-03 19:55: Train Epoch 13: 255/634 Loss: 0.062309
2023-01-03 19:55: Train Epoch 13: 259/634 Loss: 0.077322
2023-01-03 19:55: Train Epoch 13: 263/634 Loss: 0.064896
2023-01-03 19:55: Train Epoch 13: 267/634 Loss: 0.102522
2023-01-03 19:55: Train Epoch 13: 271/634 Loss: 0.101522
2023-01-03 19:55: Train Epoch 13: 275/634 Loss: 0.088901
2023-01-03 19:56: Train Epoch 13: 279/634 Loss: 0.106139
2023-01-03 19:56: Train Epoch 13: 283/634 Loss: 0.079792
2023-01-03 19:56: Train Epoch 13: 287/634 Loss: 0.074072
2023-01-03 19:56: Train Epoch 13: 291/634 Loss: 0.077163
2023-01-03 19:56: Train Epoch 13: 295/634 Loss: 0.079427
2023-01-03 19:56: Train Epoch 13: 299/634 Loss: 0.096573
