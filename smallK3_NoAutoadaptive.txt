2023-01-06 20:07: log dir: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010620074027871369386
2023-01-06 20:07: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010620074027871369386
2023-01-06 20:07: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=64, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=3, log_dir='/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010620074027871369386', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=48, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-06 20:07: Argument batch_size: 256
2023-01-06 20:07: Argument clc: 'vec'
2023-01-06 20:07: Argument cuda: True
2023-01-06 20:07: Argument dataset: '2020'
2023-01-06 20:07: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-06 20:07: Argument debug: False
2023-01-06 20:07: Argument default_graph: True
2023-01-06 20:07: Argument device: 'cpu'
2023-01-06 20:07: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-06 20:07: Argument early_stop: True
2023-01-06 20:07: Argument early_stop_patience: 8
2023-01-06 20:07: Argument embed_dim: 64
2023-01-06 20:07: Argument epochs: 30
2023-01-06 20:07: Argument grad_norm: False
2023-01-06 20:07: Argument horizon: 1
2023-01-06 20:07: Argument input_dim: 25
2023-01-06 20:07: Argument lag: 10
2023-01-06 20:07: Argument link_len: 3
2023-01-06 20:07: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010620074027871369386'
2023-01-06 20:07: Argument log_step: 1
2023-01-06 20:07: Argument loss_func: 'nllloss'
2023-01-06 20:07: Argument lr_decay: True
2023-01-06 20:07: Argument lr_decay_rate: 0.1
2023-01-06 20:07: Argument lr_decay_step: '20'
2023-01-06 20:07: Argument lr_init: 0.0001
2023-01-06 20:07: Argument max_grad_norm: 5
2023-01-06 20:07: Argument minbatch_size: 64
2023-01-06 20:07: Argument mode: 'train'
2023-01-06 20:07: Argument model: 'fire_GCN'
2023-01-06 20:07: Argument nan_fill: -1.0
2023-01-06 20:07: Argument num_layers: 1
2023-01-06 20:07: Argument num_nodes: 625
2023-01-06 20:07: Argument num_workers: 12
2023-01-06 20:07: Argument output_dim: 2
2023-01-06 20:07: Argument patch_height: 25
2023-01-06 20:07: Argument patch_width: 25
2023-01-06 20:07: Argument persistent_workers: True
2023-01-06 20:07: Argument pin_memory: True
2023-01-06 20:07: Argument plot: False
2023-01-06 20:07: Argument positive_weight: 0.5
2023-01-06 20:07: Argument prefetch_factor: 2
2023-01-06 20:07: Argument real_value: True
2023-01-06 20:07: Argument rnn_units: 48
2023-01-06 20:07: Argument seed: 10000
2023-01-06 20:07: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-06 20:07: Argument teacher_forcing: False
2023-01-06 20:07: Argument weight_decay: 0.0
2023-01-06 20:07: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 64]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool_adj torch.Size([64, 3, 73, 48]) True
encoder.cell_list.0.gate.weights_window torch.Size([64, 1, 48]) True
encoder.cell_list.0.gate.bias_pool_adj torch.Size([64, 96]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool_adj torch.Size([64, 3, 73, 24]) True
encoder.cell_list.0.update.weights_window torch.Size([64, 1, 24]) True
encoder.cell_list.0.update.bias_pool_adj torch.Size([64, 48]) True
encoder.cell_list.0.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 30000]) True
fc1.bias torch.Size([2]) True
Total params num: 1123048
*****************Finish Parameter****************
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Positives: 500 / Negatives: 1000
Dataset length 1500
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010620074027871369386/run.log
2023-01-06 20:07: Train Epoch 1: 3/24 Loss: 0.341361
2023-01-06 20:08: Train Epoch 1: 7/24 Loss: 0.352442
2023-01-06 20:08: Train Epoch 1: 11/24 Loss: 0.312072
2023-01-06 20:08: Train Epoch 1: 15/24 Loss: 0.328446
2023-01-06 20:08: Train Epoch 1: 19/24 Loss: 0.261619
2023-01-06 20:08: Train Epoch 1: 23/24 Loss: 0.241529
2023-01-06 20:08: **********Train Epoch 1: averaged Loss: 0.306245 
2023-01-06 20:08: 
Epoch time elapsed: 69.33880233764648

2023-01-06 20:09: 
 metrics validation: {'precision': 0.5483870967741935, 'recall': 0.782, 'f1-score': 0.6446826051112943, 'support': 500, 'AUC': 0.772424, 'AUCPR': 0.636812945468568, 'TP': 391, 'FP': 322, 'TN': 678, 'FN': 109} 

2023-01-06 20:09: **********Val Epoch 1: average Loss: 0.279544
2023-01-06 20:09: *********************************Current best model saved!
2023-01-06 20:09: 
 Testing metrics {'precision': 0.5730337078651685, 'recall': 0.816, 'f1-score': 0.6732673267326732, 'support': 500, 'AUC': 0.860126, 'AUCPR': 0.7787034872786197, 'TP': 408, 'FP': 304, 'TN': 696, 'FN': 92} 

2023-01-06 20:09: 
 Testing metrics {'precision': 0.6974664679582713, 'recall': 0.936, 'f1-score': 0.7993168232280103, 'support': 500, 'AUC': 0.951786, 'AUCPR': 0.9232804974455182, 'TP': 468, 'FP': 203, 'TN': 797, 'FN': 32} 

2023-01-06 20:10: Train Epoch 2: 3/24 Loss: 0.279703
2023-01-06 20:10: Train Epoch 2: 7/24 Loss: 0.264176
2023-01-06 20:10: Train Epoch 2: 11/24 Loss: 0.233633
2023-01-06 20:10: Train Epoch 2: 15/24 Loss: 0.232762
2023-01-06 20:10: Train Epoch 2: 19/24 Loss: 0.250848
2023-01-06 20:11: Train Epoch 2: 23/24 Loss: 0.215622
2023-01-06 20:11: **********Train Epoch 2: averaged Loss: 0.246124 
2023-01-06 20:11: 
Epoch time elapsed: 68.39272475242615

2023-01-06 20:11: 
 metrics validation: {'precision': 0.7346938775510204, 'recall': 0.432, 'f1-score': 0.544080604534005, 'support': 500, 'AUC': 0.780928, 'AUCPR': 0.6508346282278453, 'TP': 216, 'FP': 78, 'TN': 922, 'FN': 284} 

2023-01-06 20:11: **********Val Epoch 2: average Loss: 0.271577
2023-01-06 20:11: *********************************Current best model saved!
2023-01-06 20:11: 
 Testing metrics {'precision': 0.8187311178247734, 'recall': 0.542, 'f1-score': 0.6522262334536703, 'support': 500, 'AUC': 0.862806, 'AUCPR': 0.7830229550710208, 'TP': 271, 'FP': 60, 'TN': 940, 'FN': 229} 

2023-01-06 20:12: 
 Testing metrics {'precision': 0.9035087719298246, 'recall': 0.824, 'f1-score': 0.8619246861924686, 'support': 500, 'AUC': 0.9561240000000001, 'AUCPR': 0.9326537602317428, 'TP': 412, 'FP': 44, 'TN': 956, 'FN': 88} 

2023-01-06 20:12: Train Epoch 3: 3/24 Loss: 0.257450
2023-01-06 20:12: Train Epoch 3: 7/24 Loss: 0.229497
2023-01-06 20:12: Train Epoch 3: 11/24 Loss: 0.254155
2023-01-06 20:12: Train Epoch 3: 15/24 Loss: 0.225650
2023-01-06 20:12: Train Epoch 3: 19/24 Loss: 0.223641
2023-01-06 20:13: Train Epoch 3: 23/24 Loss: 0.192742
2023-01-06 20:13: **********Train Epoch 3: averaged Loss: 0.230522 
2023-01-06 20:13: 
Epoch time elapsed: 62.395259141922

2023-01-06 20:13: 
 metrics validation: {'precision': 0.6566820276497696, 'recall': 0.57, 'f1-score': 0.6102783725910065, 'support': 500, 'AUC': 0.7925139999999999, 'AUCPR': 0.6663982527528568, 'TP': 285, 'FP': 149, 'TN': 851, 'FN': 215} 

2023-01-06 20:13: **********Val Epoch 3: average Loss: 0.262022
2023-01-06 20:13: *********************************Current best model saved!
2023-01-06 20:13: 
 Testing metrics {'precision': 0.7695473251028807, 'recall': 0.748, 'f1-score': 0.7586206896551725, 'support': 500, 'AUC': 0.864026, 'AUCPR': 0.7857147800134517, 'TP': 374, 'FP': 112, 'TN': 888, 'FN': 126} 

2023-01-06 20:14: 
 Testing metrics {'precision': 0.8557692307692307, 'recall': 0.89, 'f1-score': 0.8725490196078431, 'support': 500, 'AUC': 0.9587859999999999, 'AUCPR': 0.9368586822936253, 'TP': 445, 'FP': 75, 'TN': 925, 'FN': 55} 

2023-01-06 20:14: Train Epoch 4: 3/24 Loss: 0.225002
2023-01-06 20:14: Train Epoch 4: 7/24 Loss: 0.219304
2023-01-06 20:14: Train Epoch 4: 11/24 Loss: 0.246448
2023-01-06 20:14: Train Epoch 4: 15/24 Loss: 0.238491
2023-01-06 20:14: Train Epoch 4: 19/24 Loss: 0.227378
2023-01-06 20:15: Train Epoch 4: 23/24 Loss: 0.176167
2023-01-06 20:15: **********Train Epoch 4: averaged Loss: 0.222132 
2023-01-06 20:15: 
Epoch time elapsed: 61.57414889335632

2023-01-06 20:15: 
 metrics validation: {'precision': 0.6591375770020534, 'recall': 0.642, 'f1-score': 0.6504559270516718, 'support': 500, 'AUC': 0.800806, 'AUCPR': 0.6767443609991657, 'TP': 321, 'FP': 166, 'TN': 834, 'FN': 179} 

2023-01-06 20:15: **********Val Epoch 4: average Loss: 0.258972
2023-01-06 20:15: *********************************Current best model saved!
2023-01-06 20:15: 
 Testing metrics {'precision': 0.7525150905432596, 'recall': 0.748, 'f1-score': 0.7502507522567703, 'support': 500, 'AUC': 0.86452, 'AUCPR': 0.7857507296139692, 'TP': 374, 'FP': 123, 'TN': 877, 'FN': 126} 

2023-01-06 20:16: 
 Testing metrics {'precision': 0.8408239700374532, 'recall': 0.898, 'f1-score': 0.8684719535783366, 'support': 500, 'AUC': 0.960844, 'AUCPR': 0.9393814602318796, 'TP': 449, 'FP': 85, 'TN': 915, 'FN': 51} 

2023-01-06 20:16: Train Epoch 5: 3/24 Loss: 0.199104
2023-01-06 20:16: Train Epoch 5: 7/24 Loss: 0.218166
2023-01-06 20:16: Train Epoch 5: 11/24 Loss: 0.232771
2023-01-06 20:16: Train Epoch 5: 15/24 Loss: 0.242460
2023-01-06 20:16: Train Epoch 5: 19/24 Loss: 0.221916
2023-01-06 20:17: Train Epoch 5: 23/24 Loss: 0.182653
2023-01-06 20:17: **********Train Epoch 5: averaged Loss: 0.216178 
2023-01-06 20:17: 
Epoch time elapsed: 63.52508878707886

2023-01-06 20:17: 
 metrics validation: {'precision': 0.7492447129909365, 'recall': 0.496, 'f1-score': 0.5968712394705175, 'support': 500, 'AUC': 0.805018, 'AUCPR': 0.6897717156932278, 'TP': 248, 'FP': 83, 'TN': 917, 'FN': 252} 

2023-01-06 20:17: **********Val Epoch 5: average Loss: 0.268838
2023-01-06 20:17: Train Epoch 6: 3/24 Loss: 0.243667
2023-01-06 20:17: Train Epoch 6: 7/24 Loss: 0.200911
2023-01-06 20:17: Train Epoch 6: 11/24 Loss: 0.238123
2023-01-06 20:18: Train Epoch 6: 15/24 Loss: 0.217800
2023-01-06 20:18: Train Epoch 6: 19/24 Loss: 0.207157
2023-01-06 20:18: Train Epoch 6: 23/24 Loss: 0.165234
2023-01-06 20:18: **********Train Epoch 6: averaged Loss: 0.212149 
2023-01-06 20:18: 
Epoch time elapsed: 63.714380502700806

2023-01-06 20:18: 
 metrics validation: {'precision': 0.6785714285714286, 'recall': 0.646, 'f1-score': 0.6618852459016393, 'support': 500, 'AUC': 0.8039, 'AUCPR': 0.6880462433086438, 'TP': 323, 'FP': 153, 'TN': 847, 'FN': 177} 

2023-01-06 20:18: **********Val Epoch 6: average Loss: 0.256081
2023-01-06 20:18: *********************************Current best model saved!
2023-01-06 20:19: 
 Testing metrics {'precision': 0.7827004219409283, 'recall': 0.742, 'f1-score': 0.7618069815195072, 'support': 500, 'AUC': 0.8656860000000001, 'AUCPR': 0.7891830906514453, 'TP': 371, 'FP': 103, 'TN': 897, 'FN': 129} 

2023-01-06 20:19: 
 Testing metrics {'precision': 0.8477443609022557, 'recall': 0.902, 'f1-score': 0.874031007751938, 'support': 500, 'AUC': 0.9621999999999999, 'AUCPR': 0.9397009290681979, 'TP': 451, 'FP': 81, 'TN': 919, 'FN': 49} 

2023-01-06 20:19: Train Epoch 7: 3/24 Loss: 0.192869
2023-01-06 20:19: Train Epoch 7: 7/24 Loss: 0.195739
2023-01-06 20:20: Train Epoch 7: 11/24 Loss: 0.246637
2023-01-06 20:20: Train Epoch 7: 15/24 Loss: 0.183539
2023-01-06 20:20: Train Epoch 7: 19/24 Loss: 0.228704
2023-01-06 20:20: Train Epoch 7: 23/24 Loss: 0.172052
2023-01-06 20:20: **********Train Epoch 7: averaged Loss: 0.203257 
2023-01-06 20:20: 
Epoch time elapsed: 65.30975270271301

2023-01-06 20:20: 
 metrics validation: {'precision': 0.7280453257790368, 'recall': 0.514, 'f1-score': 0.6025791324736226, 'support': 500, 'AUC': 0.8042039999999999, 'AUCPR': 0.6995558711688681, 'TP': 257, 'FP': 96, 'TN': 904, 'FN': 243} 

2023-01-06 20:20: **********Val Epoch 7: average Loss: 0.261322
2023-01-06 20:21: Train Epoch 8: 3/24 Loss: 0.214975
2023-01-06 20:21: Train Epoch 8: 7/24 Loss: 0.233483
2023-01-06 20:21: Train Epoch 8: 11/24 Loss: 0.214267
2023-01-06 20:21: Train Epoch 8: 15/24 Loss: 0.210701
2023-01-06 20:21: Train Epoch 8: 19/24 Loss: 0.223934
2023-01-06 20:21: Train Epoch 8: 23/24 Loss: 0.159587
2023-01-06 20:21: **********Train Epoch 8: averaged Loss: 0.209491 
2023-01-06 20:21: 
Epoch time elapsed: 61.940805435180664

2023-01-06 20:22: 
 metrics validation: {'precision': 0.7, 'recall': 0.616, 'f1-score': 0.6553191489361703, 'support': 500, 'AUC': 0.8065439999999999, 'AUCPR': 0.7020806574173727, 'TP': 308, 'FP': 132, 'TN': 868, 'FN': 192} 

2023-01-06 20:22: **********Val Epoch 8: average Loss: 0.253424
2023-01-06 20:22: *********************************Current best model saved!
2023-01-06 20:22: 
 Testing metrics {'precision': 0.7955056179775281, 'recall': 0.708, 'f1-score': 0.7492063492063493, 'support': 500, 'AUC': 0.866968, 'AUCPR': 0.7917901615577356, 'TP': 354, 'FP': 91, 'TN': 909, 'FN': 146} 

2023-01-06 20:22: 
 Testing metrics {'precision': 0.8604206500956023, 'recall': 0.9, 'f1-score': 0.8797653958944281, 'support': 500, 'AUC': 0.963786, 'AUCPR': 0.9398533646743445, 'TP': 450, 'FP': 73, 'TN': 927, 'FN': 50} 

2023-01-06 20:23: Train Epoch 9: 3/24 Loss: 0.203546
2023-01-06 20:23: Train Epoch 9: 7/24 Loss: 0.210512
2023-01-06 20:23: Train Epoch 9: 11/24 Loss: 0.218910
2023-01-06 20:23: Train Epoch 9: 15/24 Loss: 0.186169
2023-01-06 20:23: Train Epoch 9: 19/24 Loss: 0.201716
2023-01-06 20:23: Train Epoch 9: 23/24 Loss: 0.175769
2023-01-06 20:23: **********Train Epoch 9: averaged Loss: 0.199437 
2023-01-06 20:23: 
Epoch time elapsed: 63.63139200210571

2023-01-06 20:24: 
 metrics validation: {'precision': 0.6991341991341992, 'recall': 0.646, 'f1-score': 0.6715176715176715, 'support': 500, 'AUC': 0.805376, 'AUCPR': 0.7070028590316225, 'TP': 323, 'FP': 139, 'TN': 861, 'FN': 177} 

2023-01-06 20:24: **********Val Epoch 9: average Loss: 0.253785
2023-01-06 20:24: Train Epoch 10: 3/24 Loss: 0.205086
2023-01-06 20:24: Train Epoch 10: 7/24 Loss: 0.198937
2023-01-06 20:24: Train Epoch 10: 11/24 Loss: 0.192420
2023-01-06 20:24: Train Epoch 10: 15/24 Loss: 0.220677
2023-01-06 20:25: Train Epoch 10: 19/24 Loss: 0.216446
2023-01-06 20:25: Train Epoch 10: 23/24 Loss: 0.169762
2023-01-06 20:25: **********Train Epoch 10: averaged Loss: 0.200555 
2023-01-06 20:25: 
Epoch time elapsed: 60.1001615524292

2023-01-06 20:25: 
 metrics validation: {'precision': 0.6926147704590818, 'recall': 0.694, 'f1-score': 0.6933066933066934, 'support': 500, 'AUC': 0.8072159999999999, 'AUCPR': 0.707450971503239, 'TP': 347, 'FP': 154, 'TN': 846, 'FN': 153} 

2023-01-06 20:25: **********Val Epoch 10: average Loss: 0.253677
2023-01-06 20:25: Train Epoch 11: 3/24 Loss: 0.179563
2023-01-06 20:25: Train Epoch 11: 7/24 Loss: 0.217937
2023-01-06 20:26: Train Epoch 11: 11/24 Loss: 0.198773
2023-01-06 20:26: Train Epoch 11: 15/24 Loss: 0.252838
2023-01-06 20:26: Train Epoch 11: 19/24 Loss: 0.199887
2023-01-06 20:26: Train Epoch 11: 23/24 Loss: 0.206576
2023-01-06 20:26: **********Train Epoch 11: averaged Loss: 0.209262 
2023-01-06 20:26: 
Epoch time elapsed: 65.19588780403137

2023-01-06 20:27: 
 metrics validation: {'precision': 0.694331983805668, 'recall': 0.686, 'f1-score': 0.6901408450704226, 'support': 500, 'AUC': 0.807094, 'AUCPR': 0.7087938583225167, 'TP': 343, 'FP': 151, 'TN': 849, 'FN': 157} 

2023-01-06 20:27: **********Val Epoch 11: average Loss: 0.253114
2023-01-06 20:27: *********************************Current best model saved!
2023-01-06 20:27: 
 Testing metrics {'precision': 0.7716049382716049, 'recall': 0.75, 'f1-score': 0.7606490872210954, 'support': 500, 'AUC': 0.867744, 'AUCPR': 0.7949237999501322, 'TP': 375, 'FP': 111, 'TN': 889, 'FN': 125} 

2023-01-06 20:27: 
 Testing metrics {'precision': 0.8478664192949907, 'recall': 0.914, 'f1-score': 0.8796920115495669, 'support': 500, 'AUC': 0.9648779999999999, 'AUCPR': 0.9406443890133228, 'TP': 457, 'FP': 82, 'TN': 918, 'FN': 43} 

2023-01-06 20:27: Train Epoch 12: 3/24 Loss: 0.195621
2023-01-06 20:28: Train Epoch 12: 7/24 Loss: 0.206668
2023-01-06 20:28: Train Epoch 12: 11/24 Loss: 0.189113
2023-01-06 20:28: Train Epoch 12: 15/24 Loss: 0.202206
2023-01-06 20:28: Train Epoch 12: 19/24 Loss: 0.195422
2023-01-06 20:28: Train Epoch 12: 23/24 Loss: 0.201394
2023-01-06 20:28: **********Train Epoch 12: averaged Loss: 0.198404 
2023-01-06 20:28: 
Epoch time elapsed: 63.0158896446228

2023-01-06 20:29: 
 metrics validation: {'precision': 0.7375690607734806, 'recall': 0.534, 'f1-score': 0.6194895591647331, 'support': 500, 'AUC': 0.805776, 'AUCPR': 0.7127448014552419, 'TP': 267, 'FP': 95, 'TN': 905, 'FN': 233} 

2023-01-06 20:29: **********Val Epoch 12: average Loss: 0.258644
2023-01-06 20:29: Train Epoch 13: 3/24 Loss: 0.208680
2023-01-06 20:29: Train Epoch 13: 7/24 Loss: 0.211180
2023-01-06 20:29: Train Epoch 13: 11/24 Loss: 0.193785
2023-01-06 20:29: Train Epoch 13: 15/24 Loss: 0.211645
2023-01-06 20:29: Train Epoch 13: 19/24 Loss: 0.231146
2023-01-06 20:30: Train Epoch 13: 23/24 Loss: 0.167859
2023-01-06 20:30: **********Train Epoch 13: averaged Loss: 0.204049 
2023-01-06 20:30: 
Epoch time elapsed: 61.72477078437805

2023-01-06 20:30: 
 metrics validation: {'precision': 0.7121951219512195, 'recall': 0.584, 'f1-score': 0.6417582417582418, 'support': 500, 'AUC': 0.803308, 'AUCPR': 0.7103306323275329, 'TP': 292, 'FP': 118, 'TN': 882, 'FN': 208} 

2023-01-06 20:30: **********Val Epoch 13: average Loss: 0.257914
2023-01-06 20:30: Train Epoch 14: 3/24 Loss: 0.192901
2023-01-06 20:30: Train Epoch 14: 7/24 Loss: 0.216133
2023-01-06 20:30: Train Epoch 14: 11/24 Loss: 0.216229
2023-01-06 20:31: Train Epoch 14: 15/24 Loss: 0.180646
2023-01-06 20:31: Train Epoch 14: 19/24 Loss: 0.198083
2023-01-06 20:31: Train Epoch 14: 23/24 Loss: 0.207716
2023-01-06 20:31: **********Train Epoch 14: averaged Loss: 0.201951 
2023-01-06 20:31: 
Epoch time elapsed: 65.11019206047058

2023-01-06 20:31: 
 metrics validation: {'precision': 0.7286063569682152, 'recall': 0.596, 'f1-score': 0.6556655665566556, 'support': 500, 'AUC': 0.8065659999999999, 'AUCPR': 0.7128771684584744, 'TP': 298, 'FP': 111, 'TN': 889, 'FN': 202} 

2023-01-06 20:31: **********Val Epoch 14: average Loss: 0.256753
2023-01-06 20:32: Train Epoch 15: 3/24 Loss: 0.196760
2023-01-06 20:32: Train Epoch 15: 7/24 Loss: 0.215139
2023-01-06 20:32: Train Epoch 15: 11/24 Loss: 0.194870
2023-01-06 20:32: Train Epoch 15: 15/24 Loss: 0.251633
2023-01-06 20:32: Train Epoch 15: 19/24 Loss: 0.230130
2023-01-06 20:32: Train Epoch 15: 23/24 Loss: 0.159354
2023-01-06 20:32: **********Train Epoch 15: averaged Loss: 0.207981 
2023-01-06 20:32: 
Epoch time elapsed: 62.117812395095825

2023-01-06 20:33: 
 metrics validation: {'precision': 0.7486187845303868, 'recall': 0.542, 'f1-score': 0.6287703016241301, 'support': 500, 'AUC': 0.8056260000000001, 'AUCPR': 0.7116295638423283, 'TP': 271, 'FP': 91, 'TN': 909, 'FN': 229} 

2023-01-06 20:33: **********Val Epoch 15: average Loss: 0.258505
2023-01-06 20:33: Train Epoch 16: 3/24 Loss: 0.232665
2023-01-06 20:33: Train Epoch 16: 7/24 Loss: 0.214521
2023-01-06 20:33: Train Epoch 16: 11/24 Loss: 0.192969
2023-01-06 20:33: Train Epoch 16: 15/24 Loss: 0.213232
2023-01-06 20:33: Train Epoch 16: 19/24 Loss: 0.208602
2023-01-06 20:34: Train Epoch 16: 23/24 Loss: 0.173361
2023-01-06 20:34: **********Train Epoch 16: averaged Loss: 0.205892 
2023-01-06 20:34: 
Epoch time elapsed: 56.65904664993286

2023-01-06 20:34: 
 metrics validation: {'precision': 0.6377551020408163, 'recall': 0.75, 'f1-score': 0.6893382352941176, 'support': 500, 'AUC': 0.8031320000000001, 'AUCPR': 0.7097579635617397, 'TP': 375, 'FP': 213, 'TN': 787, 'FN': 125} 

2023-01-06 20:34: **********Val Epoch 16: average Loss: 0.261741
2023-01-06 20:34: Train Epoch 17: 3/24 Loss: 0.223909
2023-01-06 20:34: Train Epoch 17: 7/24 Loss: 0.219923
2023-01-06 20:34: Train Epoch 17: 11/24 Loss: 0.187439
2023-01-06 20:35: Train Epoch 17: 15/24 Loss: 0.202512
2023-01-06 20:35: Train Epoch 17: 19/24 Loss: 0.190609
2023-01-06 20:35: Train Epoch 17: 23/24 Loss: 0.189919
2023-01-06 20:35: **********Train Epoch 17: averaged Loss: 0.202385 
2023-01-06 20:35: 
Epoch time elapsed: 63.88862085342407

2023-01-06 20:35: 
 metrics validation: {'precision': 0.7320954907161804, 'recall': 0.552, 'f1-score': 0.6294184720638542, 'support': 500, 'AUC': 0.8007660000000001, 'AUCPR': 0.7063331447203584, 'TP': 276, 'FP': 101, 'TN': 899, 'FN': 224} 

2023-01-06 20:35: **********Val Epoch 17: average Loss: 0.262999
2023-01-06 20:36: Train Epoch 18: 3/24 Loss: 0.203734
2023-01-06 20:36: Train Epoch 18: 7/24 Loss: 0.209329
2023-01-06 20:36: Train Epoch 18: 11/24 Loss: 0.205041
2023-01-06 20:36: Train Epoch 18: 15/24 Loss: 0.218804
2023-01-06 20:36: Train Epoch 18: 19/24 Loss: 0.215170
2023-01-06 20:36: Train Epoch 18: 23/24 Loss: 0.198451
2023-01-06 20:36: **********Train Epoch 18: averaged Loss: 0.208421 
2023-01-06 20:36: 
Epoch time elapsed: 63.121005058288574

2023-01-06 20:37: 
 metrics validation: {'precision': 0.6875, 'recall': 0.66, 'f1-score': 0.673469387755102, 'support': 500, 'AUC': 0.80528, 'AUCPR': 0.7103908364283086, 'TP': 330, 'FP': 150, 'TN': 850, 'FN': 170} 

2023-01-06 20:37: **********Val Epoch 18: average Loss: 0.255543
2023-01-06 20:37: Train Epoch 19: 3/24 Loss: 0.204335
2023-01-06 20:37: Train Epoch 19: 7/24 Loss: 0.192329
2023-01-06 20:37: Train Epoch 19: 11/24 Loss: 0.239747
2023-01-06 20:37: Train Epoch 19: 15/24 Loss: 0.198200
2023-01-06 20:38: Train Epoch 19: 19/24 Loss: 0.190958
2023-01-06 20:38: Train Epoch 19: 23/24 Loss: 0.189328
2023-01-06 20:38: **********Train Epoch 19: averaged Loss: 0.202483 
2023-01-06 20:38: 
Epoch time elapsed: 63.04985594749451

2023-01-06 20:38: 
 metrics validation: {'precision': 0.7551622418879056, 'recall': 0.512, 'f1-score': 0.6102502979737783, 'support': 500, 'AUC': 0.8031280000000001, 'AUCPR': 0.7093902917459691, 'TP': 256, 'FP': 83, 'TN': 917, 'FN': 244} 

2023-01-06 20:38: **********Val Epoch 19: average Loss: 0.264912
2023-01-06 20:38: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-06 20:38: Total training time: 30.9533min, best loss: 0.253114
2023-01-06 20:38: Saving current best model to /home/joel.chacon/tmp/WildFire_GCNv2/experiments/2020/2023010620074027871369386/best_model.pth
2023-01-06 20:38: 
 Testing metrics {'precision': 0.7716049382716049, 'recall': 0.75, 'f1-score': 0.7606490872210954, 'support': 500, 'AUC': 0.867744, 'AUCPR': 0.7949237999501322, 'TP': 375, 'FP': 111, 'TN': 889, 'FN': 125} 

2023-01-06 20:39: 
 Testing metrics {'precision': 0.8478664192949907, 'recall': 0.914, 'f1-score': 0.8796920115495669, 'support': 500, 'AUC': 0.9648779999999999, 'AUCPR': 0.9406443890133228, 'TP': 457, 'FP': 82, 'TN': 918, 'FN': 43} 

