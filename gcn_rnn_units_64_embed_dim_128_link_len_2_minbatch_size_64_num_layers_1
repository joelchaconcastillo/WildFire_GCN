2023-01-01 10:16: log dir: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010110162104625054013
2023-01-01 10:16: Experiment log path in: /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010110162104625054013
2023-01-01 10:16: Argument: Namespace(batch_size=256, clc='vec', cuda=True, dataset='2020', dataset_root='/home/joel.chacon/tmp/datasets_grl/', debug=False, default_graph=True, device='cpu', dynamic_features=['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh'], early_stop=True, early_stop_patience=8, embed_dim=128, epochs=30, grad_norm=False, horizon=1, input_dim=25, lag=10, link_len=2, log_dir='/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010110162104625054013', log_step=1, loss_func='nllloss', lr_decay=True, lr_decay_rate=0.1, lr_decay_step='15, 20', lr_init=0.0001, max_grad_norm=5, minbatch_size=64, mode='train', model='fire_GCN', nan_fill=-1.0, num_layers=1, num_nodes=625, num_workers=12, output_dim=2, patch_height=25, patch_width=25, persistent_workers=True, pin_memory=True, plot=False, positive_weight=0.5, prefetch_factor=2, real_value=True, rnn_units=64, seed=10000, static_features=['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density'], teacher_forcing=False, weight_decay=0.0, window_len=10)
2023-01-01 10:16: Argument batch_size: 256
2023-01-01 10:16: Argument clc: 'vec'
2023-01-01 10:16: Argument cuda: True
2023-01-01 10:16: Argument dataset: '2020'
2023-01-01 10:16: Argument dataset_root: '/home/joel.chacon/tmp/datasets_grl/'
2023-01-01 10:16: Argument debug: False
2023-01-01 10:16: Argument default_graph: True
2023-01-01 10:16: Argument device: 'cpu'
2023-01-01 10:16: Argument dynamic_features: ['1 km 16 days NDVI', 'LST_Day_1km', 'LST_Night_1km', 'era5_max_d2m', 'era5_max_t2m', 'era5_max_sp', 'era5_max_tp', 'sminx', 'era5_max_wind_speed', 'era5_min_rh']
2023-01-01 10:16: Argument early_stop: True
2023-01-01 10:16: Argument early_stop_patience: 8
2023-01-01 10:16: Argument embed_dim: 128
2023-01-01 10:16: Argument epochs: 30
2023-01-01 10:16: Argument grad_norm: False
2023-01-01 10:16: Argument horizon: 1
2023-01-01 10:16: Argument input_dim: 25
2023-01-01 10:16: Argument lag: 10
2023-01-01 10:16: Argument link_len: 2
2023-01-01 10:16: Argument log_dir: '/home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010110162104625054013'
2023-01-01 10:16: Argument log_step: 1
2023-01-01 10:16: Argument loss_func: 'nllloss'
2023-01-01 10:16: Argument lr_decay: True
2023-01-01 10:16: Argument lr_decay_rate: 0.1
2023-01-01 10:16: Argument lr_decay_step: '15, 20'
2023-01-01 10:16: Argument lr_init: 0.0001
2023-01-01 10:16: Argument max_grad_norm: 5
2023-01-01 10:16: Argument minbatch_size: 64
2023-01-01 10:16: Argument mode: 'train'
2023-01-01 10:16: Argument model: 'fire_GCN'
2023-01-01 10:16: Argument nan_fill: -1.0
2023-01-01 10:16: Argument num_layers: 1
2023-01-01 10:16: Argument num_nodes: 625
2023-01-01 10:16: Argument num_workers: 12
2023-01-01 10:16: Argument output_dim: 2
2023-01-01 10:16: Argument patch_height: 25
2023-01-01 10:16: Argument patch_width: 25
2023-01-01 10:16: Argument persistent_workers: True
2023-01-01 10:16: Argument pin_memory: True
2023-01-01 10:16: Argument plot: False
2023-01-01 10:16: Argument positive_weight: 0.5
2023-01-01 10:16: Argument prefetch_factor: 2
2023-01-01 10:16: Argument real_value: True
2023-01-01 10:16: Argument rnn_units: 64
2023-01-01 10:16: Argument seed: 10000
2023-01-01 10:16: Argument static_features: ['dem_mean', 'slope_mean', 'roads_distance', 'waterway_distance', 'population_density']
2023-01-01 10:16: Argument teacher_forcing: False
2023-01-01 10:16: Argument weight_decay: 0.0
2023-01-01 10:16: Argument window_len: 10
++++++++++++++
2020_fire_GCN.conf
++++++++++++++
*****************Model Parameter*****************
node_embeddings torch.Size([625, 128]) True
ln1.weight torch.Size([25]) True
ln1.bias torch.Size([25]) True
encoder.cell_list.0.gate.weights_pool torch.Size([128, 2, 89, 64]) True
encoder.cell_list.0.gate.weights_window torch.Size([128, 1, 64]) True
encoder.cell_list.0.gate.bias_pool torch.Size([128, 128]) True
encoder.cell_list.0.gate.T torch.Size([10]) True
encoder.cell_list.0.update.weights_pool torch.Size([128, 2, 89, 32]) True
encoder.cell_list.0.update.weights_window torch.Size([128, 1, 32]) True
encoder.cell_list.0.update.bias_pool torch.Size([128, 64]) True
encoder.cell_list.0.update.T torch.Size([10]) True
fc1.weight torch.Size([2, 40000]) True
fc1.bias torch.Size([2]) True
Total params num: 2384200
*****************Finish Parameter****************
Positives: 13518 / Negatives: 27036
Dataset length 40554
Positives: 1300 / Negatives: 2600
Dataset length 3900
Positives: 1228 / Negatives: 2456
Dataset length 3684
Positives: 4407 / Negatives: 8814
Dataset length 13221
Applying learning rate decay.
Creat Log File in:  /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010110162104625054013/run.log
2023-01-01 10:16: Train Epoch 1: 3/634 Loss: 0.330515
2023-01-01 10:16: Train Epoch 1: 7/634 Loss: 1.660854
2023-01-01 10:17: Train Epoch 1: 11/634 Loss: 0.606771
2023-01-01 10:17: Train Epoch 1: 15/634 Loss: 0.464831
2023-01-01 10:17: Train Epoch 1: 19/634 Loss: 0.408191
2023-01-01 10:17: Train Epoch 1: 23/634 Loss: 0.513422
2023-01-01 10:18: Train Epoch 1: 27/634 Loss: 0.401451
2023-01-01 10:18: Train Epoch 1: 31/634 Loss: 0.384044
2023-01-01 10:18: Train Epoch 1: 35/634 Loss: 0.247023
2023-01-01 10:19: Train Epoch 1: 39/634 Loss: 0.308489
2023-01-01 10:19: Train Epoch 1: 43/634 Loss: 0.306751
2023-01-01 10:19: Train Epoch 1: 47/634 Loss: 0.306618
2023-01-01 10:19: Train Epoch 1: 51/634 Loss: 0.410653
2023-01-01 10:19: Train Epoch 1: 55/634 Loss: 0.228625
2023-01-01 10:20: Train Epoch 1: 59/634 Loss: 0.268093
2023-01-01 10:20: Train Epoch 1: 63/634 Loss: 0.237818
2023-01-01 10:20: Train Epoch 1: 67/634 Loss: 0.234919
2023-01-01 10:21: Train Epoch 1: 71/634 Loss: 0.242058
2023-01-01 10:21: Train Epoch 1: 75/634 Loss: 0.299993
2023-01-01 10:21: Train Epoch 1: 79/634 Loss: 0.253850
2023-01-01 10:21: Train Epoch 1: 83/634 Loss: 0.244910
2023-01-01 10:21: Train Epoch 1: 87/634 Loss: 0.251698
2023-01-01 10:22: Train Epoch 1: 91/634 Loss: 0.273691
2023-01-01 10:22: Train Epoch 1: 95/634 Loss: 0.218982
2023-01-01 10:22: Train Epoch 1: 99/634 Loss: 0.226943
2023-01-01 10:22: Train Epoch 1: 103/634 Loss: 0.293844
2023-01-01 10:23: Train Epoch 1: 107/634 Loss: 0.188936
2023-01-01 10:23: Train Epoch 1: 111/634 Loss: 0.224807
2023-01-01 10:23: Train Epoch 1: 115/634 Loss: 0.210664
2023-01-01 10:23: Train Epoch 1: 119/634 Loss: 0.195689
2023-01-01 10:24: Train Epoch 1: 123/634 Loss: 0.224227
2023-01-01 10:24: Train Epoch 1: 127/634 Loss: 0.182853
2023-01-01 10:24: Train Epoch 1: 131/634 Loss: 0.208591
2023-01-01 10:24: Train Epoch 1: 135/634 Loss: 0.276448
2023-01-01 10:25: Train Epoch 1: 139/634 Loss: 0.231791
2023-01-01 10:25: Train Epoch 1: 143/634 Loss: 0.209436
2023-01-01 10:25: Train Epoch 1: 147/634 Loss: 0.246907
2023-01-01 10:25: Train Epoch 1: 151/634 Loss: 0.209830
2023-01-01 10:26: Train Epoch 1: 155/634 Loss: 0.207755
2023-01-01 10:26: Train Epoch 1: 159/634 Loss: 0.212734
2023-01-01 10:26: Train Epoch 1: 163/634 Loss: 0.237554
2023-01-01 10:26: Train Epoch 1: 167/634 Loss: 0.187019
2023-01-01 10:27: Train Epoch 1: 171/634 Loss: 0.222192
2023-01-01 10:27: Train Epoch 1: 175/634 Loss: 0.227736
2023-01-01 10:27: Train Epoch 1: 179/634 Loss: 0.241716
2023-01-01 10:27: Train Epoch 1: 183/634 Loss: 0.212628
2023-01-01 10:28: Train Epoch 1: 187/634 Loss: 0.215531
2023-01-01 10:28: Train Epoch 1: 191/634 Loss: 0.204043
2023-01-01 10:28: Train Epoch 1: 195/634 Loss: 0.200435
2023-01-01 10:28: Train Epoch 1: 199/634 Loss: 0.206247
2023-01-01 10:28: Train Epoch 1: 203/634 Loss: 0.189888
2023-01-01 10:29: Train Epoch 1: 207/634 Loss: 0.219111
2023-01-01 10:29: Train Epoch 1: 211/634 Loss: 0.205112
2023-01-01 10:29: Train Epoch 1: 215/634 Loss: 0.188313
2023-01-01 10:29: Train Epoch 1: 219/634 Loss: 0.211665
2023-01-01 10:30: Train Epoch 1: 223/634 Loss: 0.220103
2023-01-01 10:30: Train Epoch 1: 227/634 Loss: 0.181289
2023-01-01 10:30: Train Epoch 1: 231/634 Loss: 0.173928
2023-01-01 10:30: Train Epoch 1: 235/634 Loss: 0.169215
2023-01-01 10:31: Train Epoch 1: 239/634 Loss: 0.215192
2023-01-01 10:31: Train Epoch 1: 243/634 Loss: 0.207220
2023-01-01 10:31: Train Epoch 1: 247/634 Loss: 0.191251
2023-01-01 10:31: Train Epoch 1: 251/634 Loss: 0.181834
2023-01-01 10:32: Train Epoch 1: 255/634 Loss: 0.208038
2023-01-01 10:32: Train Epoch 1: 259/634 Loss: 0.205403
2023-01-01 10:32: Train Epoch 1: 263/634 Loss: 0.175291
2023-01-01 10:32: Train Epoch 1: 267/634 Loss: 0.241347
2023-01-01 10:33: Train Epoch 1: 271/634 Loss: 0.172093
2023-01-01 10:33: Train Epoch 1: 275/634 Loss: 0.190527
2023-01-01 10:33: Train Epoch 1: 279/634 Loss: 0.224764
2023-01-01 10:33: Train Epoch 1: 283/634 Loss: 0.173874
2023-01-01 10:34: Train Epoch 1: 287/634 Loss: 0.172751
2023-01-01 10:34: Train Epoch 1: 291/634 Loss: 0.184853
2023-01-01 10:34: Train Epoch 1: 295/634 Loss: 0.190592
2023-01-01 10:34: Train Epoch 1: 299/634 Loss: 0.199026
2023-01-01 10:34: Train Epoch 1: 303/634 Loss: 0.203468
2023-01-01 10:35: Train Epoch 1: 307/634 Loss: 0.183967
2023-01-01 10:35: Train Epoch 1: 311/634 Loss: 0.181273
2023-01-01 10:35: Train Epoch 1: 315/634 Loss: 0.192743
2023-01-01 10:35: Train Epoch 1: 319/634 Loss: 0.188005
2023-01-01 10:36: Train Epoch 1: 323/634 Loss: 0.195043
2023-01-01 10:36: Train Epoch 1: 327/634 Loss: 0.224650
2023-01-01 10:36: Train Epoch 1: 331/634 Loss: 0.152595
2023-01-01 10:36: Train Epoch 1: 335/634 Loss: 0.207632
2023-01-01 10:37: Train Epoch 1: 339/634 Loss: 0.168736
2023-01-01 10:37: Train Epoch 1: 343/634 Loss: 0.232870
2023-01-01 10:37: Train Epoch 1: 347/634 Loss: 0.212411
2023-01-01 10:37: Train Epoch 1: 351/634 Loss: 0.180241
2023-01-01 10:38: Train Epoch 1: 355/634 Loss: 0.175101
2023-01-01 10:38: Train Epoch 1: 359/634 Loss: 0.175424
2023-01-01 10:38: Train Epoch 1: 363/634 Loss: 0.193937
2023-01-01 10:38: Train Epoch 1: 367/634 Loss: 0.166656
2023-01-01 10:39: Train Epoch 1: 371/634 Loss: 0.182288
2023-01-01 10:39: Train Epoch 1: 375/634 Loss: 0.190375
2023-01-01 10:39: Train Epoch 1: 379/634 Loss: 0.194369
2023-01-01 10:39: Train Epoch 1: 383/634 Loss: 0.198382
2023-01-01 10:40: Train Epoch 1: 387/634 Loss: 0.214542
2023-01-01 10:40: Train Epoch 1: 391/634 Loss: 0.208524
2023-01-01 10:40: Train Epoch 1: 395/634 Loss: 0.194616
2023-01-01 10:40: Train Epoch 1: 399/634 Loss: 0.201652
2023-01-01 10:41: Train Epoch 1: 403/634 Loss: 0.259928
2023-01-01 10:41: Train Epoch 1: 407/634 Loss: 0.192021
2023-01-01 10:41: Train Epoch 1: 411/634 Loss: 0.204583
2023-01-01 10:41: Train Epoch 1: 415/634 Loss: 0.192424
2023-01-01 10:42: Train Epoch 1: 419/634 Loss: 0.201735
2023-01-01 10:42: Train Epoch 1: 423/634 Loss: 0.194409
2023-01-01 10:42: Train Epoch 1: 427/634 Loss: 0.187713
2023-01-01 10:42: Train Epoch 1: 431/634 Loss: 0.191141
2023-01-01 10:43: Train Epoch 1: 435/634 Loss: 0.193668
2023-01-01 10:43: Train Epoch 1: 439/634 Loss: 0.205398
2023-01-01 10:43: Train Epoch 1: 443/634 Loss: 0.204972
2023-01-01 10:43: Train Epoch 1: 447/634 Loss: 0.191206
2023-01-01 10:44: Train Epoch 1: 451/634 Loss: 0.178364
2023-01-01 10:44: Train Epoch 1: 455/634 Loss: 0.177906
2023-01-01 10:44: Train Epoch 1: 459/634 Loss: 0.181938
2023-01-01 10:44: Train Epoch 1: 463/634 Loss: 0.169418
2023-01-01 10:45: Train Epoch 1: 467/634 Loss: 0.202210
2023-01-01 10:45: Train Epoch 1: 471/634 Loss: 0.200901
2023-01-01 10:45: Train Epoch 1: 475/634 Loss: 0.194083
2023-01-01 10:45: Train Epoch 1: 479/634 Loss: 0.174188
2023-01-01 10:46: Train Epoch 1: 483/634 Loss: 0.195716
2023-01-01 10:46: Train Epoch 1: 487/634 Loss: 0.218744
2023-01-01 10:46: Train Epoch 1: 491/634 Loss: 0.172726
2023-01-01 10:46: Train Epoch 1: 495/634 Loss: 0.187755
2023-01-01 10:47: Train Epoch 1: 499/634 Loss: 0.171128
2023-01-01 10:47: Train Epoch 1: 503/634 Loss: 0.229299
2023-01-01 10:47: Train Epoch 1: 507/634 Loss: 0.200173
2023-01-01 10:47: Train Epoch 1: 511/634 Loss: 0.167761
2023-01-01 10:48: Train Epoch 1: 515/634 Loss: 0.175944
2023-01-01 10:48: Train Epoch 1: 519/634 Loss: 0.181535
2023-01-01 10:48: Train Epoch 1: 523/634 Loss: 0.225053
2023-01-01 10:48: Train Epoch 1: 527/634 Loss: 0.175531
2023-01-01 10:49: Train Epoch 1: 531/634 Loss: 0.211514
2023-01-01 10:49: Train Epoch 1: 535/634 Loss: 0.207319
2023-01-01 10:49: Train Epoch 1: 539/634 Loss: 0.208626
2023-01-01 10:50: Train Epoch 1: 543/634 Loss: 0.200404
2023-01-01 10:50: Train Epoch 1: 547/634 Loss: 0.190346
2023-01-01 10:50: Train Epoch 1: 551/634 Loss: 0.180624
2023-01-01 10:50: Train Epoch 1: 555/634 Loss: 0.175763
2023-01-01 10:51: Train Epoch 1: 559/634 Loss: 0.177269
2023-01-01 10:51: Train Epoch 1: 563/634 Loss: 0.191850
2023-01-01 10:51: Train Epoch 1: 567/634 Loss: 0.179777
2023-01-01 10:51: Train Epoch 1: 571/634 Loss: 0.183946
2023-01-01 10:52: Train Epoch 1: 575/634 Loss: 0.180445
2023-01-01 10:52: Train Epoch 1: 579/634 Loss: 0.206822
2023-01-01 10:52: Train Epoch 1: 583/634 Loss: 0.236769
2023-01-01 10:52: Train Epoch 1: 587/634 Loss: 0.200786
2023-01-01 10:52: Train Epoch 1: 591/634 Loss: 0.218056
2023-01-01 10:53: Train Epoch 1: 595/634 Loss: 0.193293
2023-01-01 10:53: Train Epoch 1: 599/634 Loss: 0.231731
2023-01-01 10:53: Train Epoch 1: 603/634 Loss: 0.247635
2023-01-01 10:54: Train Epoch 1: 607/634 Loss: 0.191273
2023-01-01 10:54: Train Epoch 1: 611/634 Loss: 0.209094
2023-01-01 10:54: Train Epoch 1: 615/634 Loss: 0.217015
2023-01-01 10:54: Train Epoch 1: 619/634 Loss: 0.205487
2023-01-01 10:54: Train Epoch 1: 623/634 Loss: 0.204394
2023-01-01 10:55: Train Epoch 1: 627/634 Loss: 0.166038
2023-01-01 10:55: Train Epoch 1: 631/634 Loss: 0.203278
2023-01-01 10:55: Train Epoch 1: 633/634 Loss: 0.075445
2023-01-01 10:55: **********Train Epoch 1: averaged Loss: 0.226526 
2023-01-01 10:55: 
Epoch time elapsed: 2352.484865665436

2023-01-01 10:56: 
 metrics validation: {'precision': 0.8042269187986651, 'recall': 0.5561538461538461, 'f1-score': 0.6575716234652115, 'support': 1300, 'AUC': 0.8569224852071005, 'AUCPR': 0.7667216657768001, 'TP': 723, 'FP': 176, 'TN': 2424, 'FN': 577} 

2023-01-01 10:56: **********Val Epoch 1: average Loss: 0.240650
2023-01-01 10:56: *********************************Current best model saved!
2023-01-01 10:57: 
 Testing metrics {'precision': 0.8697850821744627, 'recall': 0.5602605863192183, 'f1-score': 0.6815255076770678, 'support': 1228, 'AUC': 0.8799410338571233, 'AUCPR': 0.81317340830508, 'TP': 688, 'FP': 103, 'TN': 2353, 'FN': 540} 

2023-01-01 11:01: 
 Testing metrics {'precision': 0.9405697445972495, 'recall': 0.8690719310188336, 'f1-score': 0.9034084208043401, 'support': 4407, 'AUC': 0.9755263443387325, 'AUCPR': 0.9600159947573215, 'TP': 3830, 'FP': 242, 'TN': 8572, 'FN': 577} 

2023-01-01 11:02: Train Epoch 2: 3/634 Loss: 0.199666
2023-01-01 11:02: Train Epoch 2: 7/634 Loss: 0.200435
2023-01-01 11:02: Train Epoch 2: 11/634 Loss: 0.155068
2023-01-01 11:02: Train Epoch 2: 15/634 Loss: 0.196274
2023-01-01 11:03: Train Epoch 2: 19/634 Loss: 0.196411
2023-01-01 11:03: Train Epoch 2: 23/634 Loss: 0.186939
2023-01-01 11:03: Train Epoch 2: 27/634 Loss: 0.223976
2023-01-01 11:03: Train Epoch 2: 31/634 Loss: 0.227259
2023-01-01 11:03: Train Epoch 2: 35/634 Loss: 0.184443
2023-01-01 11:04: Train Epoch 2: 39/634 Loss: 0.203660
2023-01-01 11:04: Train Epoch 2: 43/634 Loss: 0.199297
2023-01-01 11:04: Train Epoch 2: 47/634 Loss: 0.204146
2023-01-01 11:04: Train Epoch 2: 51/634 Loss: 0.194256
2023-01-01 11:05: Train Epoch 2: 55/634 Loss: 0.186748
2023-01-01 11:05: Train Epoch 2: 59/634 Loss: 0.194006
2023-01-01 11:05: Train Epoch 2: 63/634 Loss: 0.229964
2023-01-01 11:05: Train Epoch 2: 67/634 Loss: 0.198316
2023-01-01 11:06: Train Epoch 2: 71/634 Loss: 0.186372
2023-01-01 11:06: Train Epoch 2: 75/634 Loss: 0.188965
2023-01-01 11:06: Train Epoch 2: 79/634 Loss: 0.186473
2023-01-01 11:06: Train Epoch 2: 83/634 Loss: 0.212190
2023-01-01 11:07: Train Epoch 2: 87/634 Loss: 0.185959
2023-01-01 11:07: Train Epoch 2: 91/634 Loss: 0.199574
2023-01-01 11:07: Train Epoch 2: 95/634 Loss: 0.209314
2023-01-01 11:07: Train Epoch 2: 99/634 Loss: 0.189278
2023-01-01 11:08: Train Epoch 2: 103/634 Loss: 0.249797
2023-01-01 11:08: Train Epoch 2: 107/634 Loss: 0.165985
2023-01-01 11:08: Train Epoch 2: 111/634 Loss: 0.199083
2023-01-01 11:08: Train Epoch 2: 115/634 Loss: 0.189507
2023-01-01 11:09: Train Epoch 2: 119/634 Loss: 0.205069
2023-01-01 11:09: Train Epoch 2: 123/634 Loss: 0.198989
2023-01-01 11:09: Train Epoch 2: 127/634 Loss: 0.196375
2023-01-01 11:10: Train Epoch 2: 131/634 Loss: 0.199109
2023-01-01 11:10: Train Epoch 2: 135/634 Loss: 0.179762
2023-01-01 11:10: Train Epoch 2: 139/634 Loss: 0.153432
2023-01-01 11:10: Train Epoch 2: 143/634 Loss: 0.204524
2023-01-01 11:11: Train Epoch 2: 147/634 Loss: 0.180570
2023-01-01 11:11: Train Epoch 2: 151/634 Loss: 0.215976
2023-01-01 11:11: Train Epoch 2: 155/634 Loss: 0.221919
2023-01-01 11:11: Train Epoch 2: 159/634 Loss: 0.193164
2023-01-01 11:12: Train Epoch 2: 163/634 Loss: 0.168485
2023-01-01 11:12: Train Epoch 2: 167/634 Loss: 0.181929
2023-01-01 11:12: Train Epoch 2: 171/634 Loss: 0.194384
2023-01-01 11:12: Train Epoch 2: 175/634 Loss: 0.193810
2023-01-01 11:13: Train Epoch 2: 179/634 Loss: 0.174615
2023-01-01 11:13: Train Epoch 2: 183/634 Loss: 0.180029
2023-01-01 11:13: Train Epoch 2: 187/634 Loss: 0.200341
2023-01-01 11:14: Train Epoch 2: 191/634 Loss: 0.231663
2023-01-01 11:14: Train Epoch 2: 195/634 Loss: 0.158827
2023-01-01 11:14: Train Epoch 2: 199/634 Loss: 0.189211
2023-01-01 11:14: Train Epoch 2: 203/634 Loss: 0.188049
2023-01-01 11:15: Train Epoch 2: 207/634 Loss: 0.187004
2023-01-01 11:15: Train Epoch 2: 211/634 Loss: 0.165047
2023-01-01 11:15: Train Epoch 2: 215/634 Loss: 0.174538
2023-01-01 11:15: Train Epoch 2: 219/634 Loss: 0.218194
2023-01-01 11:16: Train Epoch 2: 223/634 Loss: 0.187674
2023-01-01 11:16: Train Epoch 2: 227/634 Loss: 0.194038
2023-01-01 11:16: Train Epoch 2: 231/634 Loss: 0.198942
2023-01-01 11:16: Train Epoch 2: 235/634 Loss: 0.207649
2023-01-01 11:17: Train Epoch 2: 239/634 Loss: 0.199160
2023-01-01 11:17: Train Epoch 2: 243/634 Loss: 0.209672
2023-01-01 11:17: Train Epoch 2: 247/634 Loss: 0.173919
2023-01-01 11:17: Train Epoch 2: 251/634 Loss: 0.210988
2023-01-01 11:18: Train Epoch 2: 255/634 Loss: 0.184888
2023-01-01 11:18: Train Epoch 2: 259/634 Loss: 0.177868
2023-01-01 11:18: Train Epoch 2: 263/634 Loss: 0.178677
2023-01-01 11:18: Train Epoch 2: 267/634 Loss: 0.170881
2023-01-01 11:19: Train Epoch 2: 271/634 Loss: 0.190149
2023-01-01 11:19: Train Epoch 2: 275/634 Loss: 0.182146
2023-01-01 11:19: Train Epoch 2: 279/634 Loss: 0.174775
2023-01-01 11:19: Train Epoch 2: 283/634 Loss: 0.174679
2023-01-01 11:20: Train Epoch 2: 287/634 Loss: 0.186394
2023-01-01 11:20: Train Epoch 2: 291/634 Loss: 0.181692
2023-01-01 11:20: Train Epoch 2: 295/634 Loss: 0.189796
2023-01-01 11:20: Train Epoch 2: 299/634 Loss: 0.187680
2023-01-01 11:21: Train Epoch 2: 303/634 Loss: 0.197372
2023-01-01 11:21: Train Epoch 2: 307/634 Loss: 0.166708
2023-01-01 11:21: Train Epoch 2: 311/634 Loss: 0.154632
2023-01-01 11:21: Train Epoch 2: 315/634 Loss: 0.169060
2023-01-01 11:22: Train Epoch 2: 319/634 Loss: 0.218089
2023-01-01 11:22: Train Epoch 2: 323/634 Loss: 0.189526
2023-01-01 11:22: Train Epoch 2: 327/634 Loss: 0.191469
2023-01-01 11:22: Train Epoch 2: 331/634 Loss: 0.182303
2023-01-01 11:23: Train Epoch 2: 335/634 Loss: 0.180676
2023-01-01 11:23: Train Epoch 2: 339/634 Loss: 0.183594
2023-01-01 11:23: Train Epoch 2: 343/634 Loss: 0.204955
2023-01-01 11:23: Train Epoch 2: 347/634 Loss: 0.198275
2023-01-01 11:24: Train Epoch 2: 351/634 Loss: 0.194782
2023-01-01 11:24: Train Epoch 2: 355/634 Loss: 0.208248
2023-01-01 11:24: Train Epoch 2: 359/634 Loss: 0.168165
2023-01-01 11:24: Train Epoch 2: 363/634 Loss: 0.224746
2023-01-01 11:25: Train Epoch 2: 367/634 Loss: 0.182854
2023-01-01 11:25: Train Epoch 2: 371/634 Loss: 0.227382
2023-01-01 11:25: Train Epoch 2: 375/634 Loss: 0.230527
2023-01-01 11:25: Train Epoch 2: 379/634 Loss: 0.160766
2023-01-01 11:26: Train Epoch 2: 383/634 Loss: 0.228643
2023-01-01 11:26: Train Epoch 2: 387/634 Loss: 0.204020
2023-01-01 11:26: Train Epoch 2: 391/634 Loss: 0.174426
2023-01-01 11:26: Train Epoch 2: 395/634 Loss: 0.223696
2023-01-01 11:27: Train Epoch 2: 399/634 Loss: 0.219257
2023-01-01 11:27: Train Epoch 2: 403/634 Loss: 0.156279
2023-01-01 11:27: Train Epoch 2: 407/634 Loss: 0.225724
2023-01-01 11:27: Train Epoch 2: 411/634 Loss: 0.194512
2023-01-01 11:28: Train Epoch 2: 415/634 Loss: 0.163062
2023-01-01 11:28: Train Epoch 2: 419/634 Loss: 0.186524
2023-01-01 11:28: Train Epoch 2: 423/634 Loss: 0.177009
2023-01-01 11:28: Train Epoch 2: 427/634 Loss: 0.175248
2023-01-01 11:29: Train Epoch 2: 431/634 Loss: 0.185151
2023-01-01 11:29: Train Epoch 2: 435/634 Loss: 0.167776
2023-01-01 11:29: Train Epoch 2: 439/634 Loss: 0.196929
2023-01-01 11:29: Train Epoch 2: 443/634 Loss: 0.182226
2023-01-01 11:29: Train Epoch 2: 447/634 Loss: 0.201530
2023-01-01 11:30: Train Epoch 2: 451/634 Loss: 0.177814
2023-01-01 11:30: Train Epoch 2: 455/634 Loss: 0.213275
2023-01-01 11:30: Train Epoch 2: 459/634 Loss: 0.177475
2023-01-01 11:30: Train Epoch 2: 463/634 Loss: 0.189022
2023-01-01 11:31: Train Epoch 2: 467/634 Loss: 0.151236
2023-01-01 11:31: Train Epoch 2: 471/634 Loss: 0.178594
2023-01-01 11:31: Train Epoch 2: 475/634 Loss: 0.175535
2023-01-01 11:31: Train Epoch 2: 479/634 Loss: 0.170483
2023-01-01 11:32: Train Epoch 2: 483/634 Loss: 0.174169
2023-01-01 11:32: Train Epoch 2: 487/634 Loss: 0.217458
2023-01-01 11:32: Train Epoch 2: 491/634 Loss: 0.209281
2023-01-01 11:32: Train Epoch 2: 495/634 Loss: 0.178897
2023-01-01 11:33: Train Epoch 2: 499/634 Loss: 0.164672
2023-01-01 11:33: Train Epoch 2: 503/634 Loss: 0.189760
2023-01-01 11:33: Train Epoch 2: 507/634 Loss: 0.211407
2023-01-01 11:33: Train Epoch 2: 511/634 Loss: 0.233899
2023-01-01 11:34: Train Epoch 2: 515/634 Loss: 0.199704
2023-01-01 11:34: Train Epoch 2: 519/634 Loss: 0.167872
2023-01-01 11:34: Train Epoch 2: 523/634 Loss: 0.183001
2023-01-01 11:34: Train Epoch 2: 527/634 Loss: 0.171604
2023-01-01 11:35: Train Epoch 2: 531/634 Loss: 0.218568
2023-01-01 11:35: Train Epoch 2: 535/634 Loss: 0.171308
2023-01-01 11:35: Train Epoch 2: 539/634 Loss: 0.183191
2023-01-01 11:35: Train Epoch 2: 543/634 Loss: 0.191740
2023-01-01 11:35: Train Epoch 2: 547/634 Loss: 0.170956
2023-01-01 11:36: Train Epoch 2: 551/634 Loss: 0.158676
2023-01-01 11:36: Train Epoch 2: 555/634 Loss: 0.178849
2023-01-01 11:36: Train Epoch 2: 559/634 Loss: 0.168446
2023-01-01 11:36: Train Epoch 2: 563/634 Loss: 0.169859
2023-01-01 11:37: Train Epoch 2: 567/634 Loss: 0.183530
2023-01-01 11:37: Train Epoch 2: 571/634 Loss: 0.178807
2023-01-01 11:37: Train Epoch 2: 575/634 Loss: 0.178083
2023-01-01 11:37: Train Epoch 2: 579/634 Loss: 0.191219
2023-01-01 11:38: Train Epoch 2: 583/634 Loss: 0.202568
2023-01-01 11:38: Train Epoch 2: 587/634 Loss: 0.152863
2023-01-01 11:38: Train Epoch 2: 591/634 Loss: 0.197691
2023-01-01 11:38: Train Epoch 2: 595/634 Loss: 0.160307
2023-01-01 11:39: Train Epoch 2: 599/634 Loss: 0.173920
2023-01-01 11:39: Train Epoch 2: 603/634 Loss: 0.177969
2023-01-01 11:39: Train Epoch 2: 607/634 Loss: 0.187769
2023-01-01 11:39: Train Epoch 2: 611/634 Loss: 0.220430
2023-01-01 11:40: Train Epoch 2: 615/634 Loss: 0.185885
2023-01-01 11:40: Train Epoch 2: 619/634 Loss: 0.172991
2023-01-01 11:40: Train Epoch 2: 623/634 Loss: 0.199991
2023-01-01 11:40: Train Epoch 2: 627/634 Loss: 0.179975
2023-01-01 11:40: Train Epoch 2: 631/634 Loss: 0.169810
2023-01-01 11:41: Train Epoch 2: 633/634 Loss: 0.066805
2023-01-01 11:41: **********Train Epoch 2: averaged Loss: 0.189205 
2023-01-01 11:41: 
Epoch time elapsed: 2359.4664359092712

2023-01-01 11:42: 
 metrics validation: {'precision': 0.7598684210526315, 'recall': 0.7107692307692308, 'f1-score': 0.7344992050874404, 'support': 1300, 'AUC': 0.8863186390532545, 'AUCPR': 0.8012176042847692, 'TP': 924, 'FP': 292, 'TN': 2308, 'FN': 376} 

2023-01-01 11:42: **********Val Epoch 2: average Loss: 0.194725
2023-01-01 11:42: *********************************Current best model saved!
2023-01-01 11:43: 
 Testing metrics {'precision': 0.7952153110047847, 'recall': 0.6767100977198697, 'f1-score': 0.7311922569291686, 'support': 1228, 'AUC': 0.8973493750596823, 'AUCPR': 0.8344388055489773, 'TP': 831, 'FP': 214, 'TN': 2242, 'FN': 397} 

2023-01-01 11:47: 
 Testing metrics {'precision': 0.884326710816777, 'recall': 0.9090083957340594, 'f1-score': 0.8964977061653799, 'support': 4407, 'AUC': 0.9757951037010297, 'AUCPR': 0.9562028477807009, 'TP': 4006, 'FP': 524, 'TN': 8290, 'FN': 401} 

2023-01-01 11:47: Train Epoch 3: 3/634 Loss: 0.206229
2023-01-01 11:47: Train Epoch 3: 7/634 Loss: 0.194704
2023-01-01 11:47: Train Epoch 3: 11/634 Loss: 0.182416
2023-01-01 11:48: Train Epoch 3: 15/634 Loss: 0.194513
2023-01-01 11:48: Train Epoch 3: 19/634 Loss: 0.180153
2023-01-01 11:48: Train Epoch 3: 23/634 Loss: 0.186050
2023-01-01 11:48: Train Epoch 3: 27/634 Loss: 0.201781
2023-01-01 11:49: Train Epoch 3: 31/634 Loss: 0.201293
2023-01-01 11:49: Train Epoch 3: 35/634 Loss: 0.184526
2023-01-01 11:49: Train Epoch 3: 39/634 Loss: 0.141339
2023-01-01 11:49: Train Epoch 3: 43/634 Loss: 0.184264
2023-01-01 11:50: Train Epoch 3: 47/634 Loss: 0.210054
2023-01-01 11:50: Train Epoch 3: 51/634 Loss: 0.163507
2023-01-01 11:50: Train Epoch 3: 55/634 Loss: 0.209776
2023-01-01 11:50: Train Epoch 3: 59/634 Loss: 0.192780
2023-01-01 11:51: Train Epoch 3: 63/634 Loss: 0.206311
2023-01-01 11:51: Train Epoch 3: 67/634 Loss: 0.234792
2023-01-01 11:51: Train Epoch 3: 71/634 Loss: 0.183985
2023-01-01 11:51: Train Epoch 3: 75/634 Loss: 0.169623
2023-01-01 11:52: Train Epoch 3: 79/634 Loss: 0.195702
2023-01-01 11:52: Train Epoch 3: 83/634 Loss: 0.192043
2023-01-01 11:52: Train Epoch 3: 87/634 Loss: 0.181166
2023-01-01 11:52: Train Epoch 3: 91/634 Loss: 0.204067
2023-01-01 11:53: Train Epoch 3: 95/634 Loss: 0.149947
2023-01-01 11:53: Train Epoch 3: 99/634 Loss: 0.202893
2023-01-01 11:53: Train Epoch 3: 103/634 Loss: 0.175645
2023-01-01 11:53: Train Epoch 3: 107/634 Loss: 0.190122
2023-01-01 11:54: Train Epoch 3: 111/634 Loss: 0.186044
2023-01-01 11:54: Train Epoch 3: 115/634 Loss: 0.186182
2023-01-01 11:54: Train Epoch 3: 119/634 Loss: 0.173353
2023-01-01 11:54: Train Epoch 3: 123/634 Loss: 0.165469
2023-01-01 11:55: Train Epoch 3: 127/634 Loss: 0.178831
2023-01-01 11:55: Train Epoch 3: 131/634 Loss: 0.182194
2023-01-01 11:55: Train Epoch 3: 135/634 Loss: 0.174900
2023-01-01 11:55: Train Epoch 3: 139/634 Loss: 0.155443
2023-01-01 11:56: Train Epoch 3: 143/634 Loss: 0.162296
2023-01-01 11:56: Train Epoch 3: 147/634 Loss: 0.175182
2023-01-01 11:56: Train Epoch 3: 151/634 Loss: 0.174491
2023-01-01 11:56: Train Epoch 3: 155/634 Loss: 0.174507
2023-01-01 11:57: Train Epoch 3: 159/634 Loss: 0.185792
2023-01-01 11:57: Train Epoch 3: 163/634 Loss: 0.183508
2023-01-01 11:57: Train Epoch 3: 167/634 Loss: 0.189266
2023-01-01 11:57: Train Epoch 3: 171/634 Loss: 0.199611
2023-01-01 11:58: Train Epoch 3: 175/634 Loss: 0.196034
2023-01-01 11:58: Train Epoch 3: 179/634 Loss: 0.205685
2023-01-01 11:58: Train Epoch 3: 183/634 Loss: 0.155584
2023-01-01 11:58: Train Epoch 3: 187/634 Loss: 0.166492
2023-01-01 11:59: Train Epoch 3: 191/634 Loss: 0.191996
2023-01-01 11:59: Train Epoch 3: 195/634 Loss: 0.172812
2023-01-01 11:59: Train Epoch 3: 199/634 Loss: 0.162343
2023-01-01 11:59: Train Epoch 3: 203/634 Loss: 0.183812
2023-01-01 12:00: Train Epoch 3: 207/634 Loss: 0.161518
2023-01-01 12:00: Train Epoch 3: 211/634 Loss: 0.192636
2023-01-01 12:00: Train Epoch 3: 215/634 Loss: 0.162568
2023-01-01 12:00: Train Epoch 3: 219/634 Loss: 0.192153
2023-01-01 12:01: Train Epoch 3: 223/634 Loss: 0.198139
2023-01-01 12:01: Train Epoch 3: 227/634 Loss: 0.197438
2023-01-01 12:01: Train Epoch 3: 231/634 Loss: 0.203983
2023-01-01 12:01: Train Epoch 3: 235/634 Loss: 0.163499
2023-01-01 12:02: Train Epoch 3: 239/634 Loss: 0.169167
2023-01-01 12:02: Train Epoch 3: 243/634 Loss: 0.178733
2023-01-01 12:02: Train Epoch 3: 247/634 Loss: 0.176113
2023-01-01 12:02: Train Epoch 3: 251/634 Loss: 0.192208
2023-01-01 12:02: Train Epoch 3: 255/634 Loss: 0.197635
2023-01-01 12:03: Train Epoch 3: 259/634 Loss: 0.231867
2023-01-01 12:03: Train Epoch 3: 263/634 Loss: 0.166856
2023-01-01 12:03: Train Epoch 3: 267/634 Loss: 0.169629
2023-01-01 12:03: Train Epoch 3: 271/634 Loss: 0.195784
2023-01-01 12:04: Train Epoch 3: 275/634 Loss: 0.198966
2023-01-01 12:04: Train Epoch 3: 279/634 Loss: 0.154433
2023-01-01 12:04: Train Epoch 3: 283/634 Loss: 0.221545
2023-01-01 12:04: Train Epoch 3: 287/634 Loss: 0.188824
2023-01-01 12:05: Train Epoch 3: 291/634 Loss: 0.154806
2023-01-01 12:05: Train Epoch 3: 295/634 Loss: 0.189007
2023-01-01 12:05: Train Epoch 3: 299/634 Loss: 0.195092
2023-01-01 12:05: Train Epoch 3: 303/634 Loss: 0.180373
2023-01-01 12:06: Train Epoch 3: 307/634 Loss: 0.199597
2023-01-01 12:06: Train Epoch 3: 311/634 Loss: 0.192778
2023-01-01 12:06: Train Epoch 3: 315/634 Loss: 0.173576
2023-01-01 12:06: Train Epoch 3: 319/634 Loss: 0.205493
2023-01-01 12:07: Train Epoch 3: 323/634 Loss: 0.178776
2023-01-01 12:07: Train Epoch 3: 327/634 Loss: 0.205794
2023-01-01 12:07: Train Epoch 3: 331/634 Loss: 0.195448
2023-01-01 12:07: Train Epoch 3: 335/634 Loss: 0.192632
2023-01-01 12:08: Train Epoch 3: 339/634 Loss: 0.193735
2023-01-01 12:08: Train Epoch 3: 343/634 Loss: 0.163025
2023-01-01 12:08: Train Epoch 3: 347/634 Loss: 0.159676
2023-01-01 12:08: Train Epoch 3: 351/634 Loss: 0.172979
2023-01-01 12:09: Train Epoch 3: 355/634 Loss: 0.177846
2023-01-01 12:09: Train Epoch 3: 359/634 Loss: 0.177145
2023-01-01 12:09: Train Epoch 3: 363/634 Loss: 0.212987
2023-01-01 12:09: Train Epoch 3: 367/634 Loss: 0.190938
2023-01-01 12:10: Train Epoch 3: 371/634 Loss: 0.199076
2023-01-01 12:10: Train Epoch 3: 375/634 Loss: 0.191260
2023-01-01 12:10: Train Epoch 3: 379/634 Loss: 0.189756
2023-01-01 12:10: Train Epoch 3: 383/634 Loss: 0.145544
2023-01-01 12:11: Train Epoch 3: 387/634 Loss: 0.200276
2023-01-01 12:11: Train Epoch 3: 391/634 Loss: 0.168278
2023-01-01 12:11: Train Epoch 3: 395/634 Loss: 0.171538
2023-01-01 12:11: Train Epoch 3: 399/634 Loss: 0.149680
2023-01-01 12:12: Train Epoch 3: 403/634 Loss: 0.152427
2023-01-01 12:12: Train Epoch 3: 407/634 Loss: 0.148586
2023-01-01 12:12: Train Epoch 3: 411/634 Loss: 0.223005
2023-01-01 12:12: Train Epoch 3: 415/634 Loss: 0.176529
2023-01-01 12:13: Train Epoch 3: 419/634 Loss: 0.185383
2023-01-01 12:13: Train Epoch 3: 423/634 Loss: 0.186101
2023-01-01 12:13: Train Epoch 3: 427/634 Loss: 0.167961
2023-01-01 12:13: Train Epoch 3: 431/634 Loss: 0.205380
2023-01-01 12:14: Train Epoch 3: 435/634 Loss: 0.183828
2023-01-01 12:14: Train Epoch 3: 439/634 Loss: 0.164726
2023-01-01 12:14: Train Epoch 3: 443/634 Loss: 0.190973
2023-01-01 12:14: Train Epoch 3: 447/634 Loss: 0.157808
2023-01-01 12:15: Train Epoch 3: 451/634 Loss: 0.218367
2023-01-01 12:15: Train Epoch 3: 455/634 Loss: 0.178454
2023-01-01 12:15: Train Epoch 3: 459/634 Loss: 0.172566
2023-01-01 12:15: Train Epoch 3: 463/634 Loss: 0.174779
2023-01-01 12:16: Train Epoch 3: 467/634 Loss: 0.156381
2023-01-01 12:16: Train Epoch 3: 471/634 Loss: 0.229268
2023-01-01 12:16: Train Epoch 3: 475/634 Loss: 0.184295
2023-01-01 12:16: Train Epoch 3: 479/634 Loss: 0.187334
2023-01-01 12:17: Train Epoch 3: 483/634 Loss: 0.177008
2023-01-01 12:17: Train Epoch 3: 487/634 Loss: 0.171638
2023-01-01 12:17: Train Epoch 3: 491/634 Loss: 0.176790
2023-01-01 12:17: Train Epoch 3: 495/634 Loss: 0.173129
2023-01-01 12:18: Train Epoch 3: 499/634 Loss: 0.177123
2023-01-01 12:18: Train Epoch 3: 503/634 Loss: 0.172784
2023-01-01 12:18: Train Epoch 3: 507/634 Loss: 0.182750
2023-01-01 12:18: Train Epoch 3: 511/634 Loss: 0.159423
2023-01-01 12:19: Train Epoch 3: 515/634 Loss: 0.190448
2023-01-01 12:19: Train Epoch 3: 519/634 Loss: 0.178474
2023-01-01 12:19: Train Epoch 3: 523/634 Loss: 0.189009
2023-01-01 12:19: Train Epoch 3: 527/634 Loss: 0.153331
2023-01-01 12:20: Train Epoch 3: 531/634 Loss: 0.168357
2023-01-01 12:20: Train Epoch 3: 535/634 Loss: 0.176315
2023-01-01 12:20: Train Epoch 3: 539/634 Loss: 0.172181
2023-01-01 12:20: Train Epoch 3: 543/634 Loss: 0.156180
2023-01-01 12:21: Train Epoch 3: 547/634 Loss: 0.174982
2023-01-01 12:21: Train Epoch 3: 551/634 Loss: 0.199427
2023-01-01 12:21: Train Epoch 3: 555/634 Loss: 0.181085
2023-01-01 12:21: Train Epoch 3: 559/634 Loss: 0.185513
2023-01-01 12:22: Train Epoch 3: 563/634 Loss: 0.185891
2023-01-01 12:22: Train Epoch 3: 567/634 Loss: 0.178396
2023-01-01 12:22: Train Epoch 3: 571/634 Loss: 0.187603
2023-01-01 12:22: Train Epoch 3: 575/634 Loss: 0.153127
2023-01-01 12:23: Train Epoch 3: 579/634 Loss: 0.160798
2023-01-01 12:23: Train Epoch 3: 583/634 Loss: 0.195085
2023-01-01 12:23: Train Epoch 3: 587/634 Loss: 0.167152
2023-01-01 12:23: Train Epoch 3: 591/634 Loss: 0.178949
2023-01-01 12:24: Train Epoch 3: 595/634 Loss: 0.160105
2023-01-01 12:24: Train Epoch 3: 599/634 Loss: 0.165536
2023-01-01 12:24: Train Epoch 3: 603/634 Loss: 0.179112
2023-01-01 12:24: Train Epoch 3: 607/634 Loss: 0.200986
2023-01-01 12:25: Train Epoch 3: 611/634 Loss: 0.147882
2023-01-01 12:25: Train Epoch 3: 615/634 Loss: 0.196050
2023-01-01 12:25: Train Epoch 3: 619/634 Loss: 0.179046
2023-01-01 12:25: Train Epoch 3: 623/634 Loss: 0.176762
2023-01-01 12:26: Train Epoch 3: 627/634 Loss: 0.152679
2023-01-01 12:26: Train Epoch 3: 631/634 Loss: 0.184657
2023-01-01 12:26: Train Epoch 3: 633/634 Loss: 0.055536
2023-01-01 12:26: **********Train Epoch 3: averaged Loss: 0.181181 
2023-01-01 12:26: 
Epoch time elapsed: 2354.9157807826996

2023-01-01 12:27: 
 metrics validation: {'precision': 0.7148387096774194, 'recall': 0.8523076923076923, 'f1-score': 0.7775438596491229, 'support': 1300, 'AUC': 0.9157242603550296, 'AUCPR': 0.8399584286474104, 'TP': 1108, 'FP': 442, 'TN': 2158, 'FN': 192} 

2023-01-01 12:27: **********Val Epoch 3: average Loss: 0.175195
2023-01-01 12:27: *********************************Current best model saved!
2023-01-01 12:28: 
 Testing metrics {'precision': 0.7291828793774319, 'recall': 0.7630293159609121, 'f1-score': 0.7457222443294866, 'support': 1228, 'AUC': 0.9061521872911119, 'AUCPR': 0.8486087149976833, 'TP': 937, 'FP': 348, 'TN': 2108, 'FN': 291} 

2023-01-01 12:32: 
 Testing metrics {'precision': 0.8267700875099443, 'recall': 0.9432720671658725, 'f1-score': 0.8811870694223637, 'support': 4407, 'AUC': 0.9760720240593371, 'AUCPR': 0.9550161343637906, 'TP': 4157, 'FP': 871, 'TN': 7943, 'FN': 250} 

2023-01-01 12:32: Train Epoch 4: 3/634 Loss: 0.178165
2023-01-01 12:32: Train Epoch 4: 7/634 Loss: 0.184752
2023-01-01 12:33: Train Epoch 4: 11/634 Loss: 0.185170
2023-01-01 12:33: Train Epoch 4: 15/634 Loss: 0.195936
2023-01-01 12:33: Train Epoch 4: 19/634 Loss: 0.227730
2023-01-01 12:33: Train Epoch 4: 23/634 Loss: 0.162696
2023-01-01 12:34: Train Epoch 4: 27/634 Loss: 0.174647
2023-01-01 12:34: Train Epoch 4: 31/634 Loss: 0.166006
2023-01-01 12:34: Train Epoch 4: 35/634 Loss: 0.181837
2023-01-01 12:34: Train Epoch 4: 39/634 Loss: 0.167809
2023-01-01 12:35: Train Epoch 4: 43/634 Loss: 0.166513
2023-01-01 12:35: Train Epoch 4: 47/634 Loss: 0.171270
2023-01-01 12:35: Train Epoch 4: 51/634 Loss: 0.164736
2023-01-01 12:35: Train Epoch 4: 55/634 Loss: 0.157349
2023-01-01 12:36: Train Epoch 4: 59/634 Loss: 0.168489
2023-01-01 12:36: Train Epoch 4: 63/634 Loss: 0.202856
2023-01-01 12:36: Train Epoch 4: 67/634 Loss: 0.181318
2023-01-01 12:36: Train Epoch 4: 71/634 Loss: 0.183077
2023-01-01 12:37: Train Epoch 4: 75/634 Loss: 0.166718
2023-01-01 12:37: Train Epoch 4: 79/634 Loss: 0.172573
2023-01-01 12:37: Train Epoch 4: 83/634 Loss: 0.163798
2023-01-01 12:37: Train Epoch 4: 87/634 Loss: 0.174197
2023-01-01 12:38: Train Epoch 4: 91/634 Loss: 0.182246
2023-01-01 12:38: Train Epoch 4: 95/634 Loss: 0.206109
2023-01-01 12:38: Train Epoch 4: 99/634 Loss: 0.184867
2023-01-01 12:38: Train Epoch 4: 103/634 Loss: 0.157158
2023-01-01 12:39: Train Epoch 4: 107/634 Loss: 0.167796
2023-01-01 12:39: Train Epoch 4: 111/634 Loss: 0.189906
2023-01-01 12:39: Train Epoch 4: 115/634 Loss: 0.197260
2023-01-01 12:39: Train Epoch 4: 119/634 Loss: 0.201527
2023-01-01 12:40: Train Epoch 4: 123/634 Loss: 0.183496
2023-01-01 12:40: Train Epoch 4: 127/634 Loss: 0.220516
2023-01-01 12:40: Train Epoch 4: 131/634 Loss: 0.163021
2023-01-01 12:40: Train Epoch 4: 135/634 Loss: 0.190833
2023-01-01 12:41: Train Epoch 4: 139/634 Loss: 0.174461
2023-01-01 12:41: Train Epoch 4: 143/634 Loss: 0.192480
2023-01-01 12:41: Train Epoch 4: 147/634 Loss: 0.178596
2023-01-01 12:42: Train Epoch 4: 151/634 Loss: 0.179918
2023-01-01 12:42: Train Epoch 4: 155/634 Loss: 0.184218
2023-01-01 12:42: Train Epoch 4: 159/634 Loss: 0.184032
2023-01-01 12:42: Train Epoch 4: 163/634 Loss: 0.178275
2023-01-01 12:43: Train Epoch 4: 167/634 Loss: 0.142628
2023-01-01 12:43: Train Epoch 4: 171/634 Loss: 0.167629
2023-01-01 12:43: Train Epoch 4: 175/634 Loss: 0.177450
2023-01-01 12:43: Train Epoch 4: 179/634 Loss: 0.170496
2023-01-01 12:44: Train Epoch 4: 183/634 Loss: 0.149477
2023-01-01 12:44: Train Epoch 4: 187/634 Loss: 0.154381
2023-01-01 12:44: Train Epoch 4: 191/634 Loss: 0.213343
2023-01-01 12:44: Train Epoch 4: 195/634 Loss: 0.161551
2023-01-01 12:45: Train Epoch 4: 199/634 Loss: 0.184998
2023-01-01 12:45: Train Epoch 4: 203/634 Loss: 0.209495
2023-01-01 12:45: Train Epoch 4: 207/634 Loss: 0.186196
2023-01-01 12:45: Train Epoch 4: 211/634 Loss: 0.176406
2023-01-01 12:46: Train Epoch 4: 215/634 Loss: 0.206982
2023-01-01 12:46: Train Epoch 4: 219/634 Loss: 0.164887
2023-01-01 12:46: Train Epoch 4: 223/634 Loss: 0.168348
2023-01-01 12:46: Train Epoch 4: 227/634 Loss: 0.180925
2023-01-01 12:47: Train Epoch 4: 231/634 Loss: 0.180105
2023-01-01 12:47: Train Epoch 4: 235/634 Loss: 0.200568
2023-01-01 12:47: Train Epoch 4: 239/634 Loss: 0.160505
2023-01-01 12:47: Train Epoch 4: 243/634 Loss: 0.201019
2023-01-01 12:48: Train Epoch 4: 247/634 Loss: 0.168579
2023-01-01 12:48: Train Epoch 4: 251/634 Loss: 0.164642
2023-01-01 12:48: Train Epoch 4: 255/634 Loss: 0.153120
2023-01-01 12:48: Train Epoch 4: 259/634 Loss: 0.174154
2023-01-01 12:49: Train Epoch 4: 263/634 Loss: 0.173986
2023-01-01 12:49: Train Epoch 4: 267/634 Loss: 0.139100
2023-01-01 12:49: Train Epoch 4: 271/634 Loss: 0.152285
2023-01-01 12:49: Train Epoch 4: 275/634 Loss: 0.147468
2023-01-01 12:50: Train Epoch 4: 279/634 Loss: 0.167811
2023-01-01 12:50: Train Epoch 4: 283/634 Loss: 0.157113
2023-01-01 12:50: Train Epoch 4: 287/634 Loss: 0.167615
2023-01-01 12:50: Train Epoch 4: 291/634 Loss: 0.175152
2023-01-01 12:51: Train Epoch 4: 295/634 Loss: 0.174214
2023-01-01 12:51: Train Epoch 4: 299/634 Loss: 0.193020
2023-01-01 12:51: Train Epoch 4: 303/634 Loss: 0.202718
2023-01-01 12:51: Train Epoch 4: 307/634 Loss: 0.167368
2023-01-01 12:51: Train Epoch 4: 311/634 Loss: 0.201849
2023-01-01 12:52: Train Epoch 4: 315/634 Loss: 0.160936
2023-01-01 12:52: Train Epoch 4: 319/634 Loss: 0.159503
2023-01-01 12:52: Train Epoch 4: 323/634 Loss: 0.172869
2023-01-01 12:52: Train Epoch 4: 327/634 Loss: 0.144478
2023-01-01 12:53: Train Epoch 4: 331/634 Loss: 0.174484
2023-01-01 12:53: Train Epoch 4: 335/634 Loss: 0.173052
2023-01-01 12:53: Train Epoch 4: 339/634 Loss: 0.164182
2023-01-01 12:54: Train Epoch 4: 343/634 Loss: 0.175682
2023-01-01 12:54: Train Epoch 4: 347/634 Loss: 0.229133
2023-01-01 12:54: Train Epoch 4: 351/634 Loss: 0.161933
2023-01-01 12:54: Train Epoch 4: 355/634 Loss: 0.168538
2023-01-01 12:55: Train Epoch 4: 359/634 Loss: 0.182412
2023-01-01 12:55: Train Epoch 4: 363/634 Loss: 0.151912
2023-01-01 12:55: Train Epoch 4: 367/634 Loss: 0.179376
2023-01-01 12:55: Train Epoch 4: 371/634 Loss: 0.225587
2023-01-01 12:56: Train Epoch 4: 375/634 Loss: 0.167675
2023-01-01 12:56: Train Epoch 4: 379/634 Loss: 0.173170
2023-01-01 12:56: Train Epoch 4: 383/634 Loss: 0.191965
2023-01-01 12:56: Train Epoch 4: 387/634 Loss: 0.169495
2023-01-01 12:57: Train Epoch 4: 391/634 Loss: 0.238496
2023-01-01 12:57: Train Epoch 4: 395/634 Loss: 0.161154
2023-01-01 12:57: Train Epoch 4: 399/634 Loss: 0.219827
2023-01-01 12:57: Train Epoch 4: 403/634 Loss: 0.177013
2023-01-01 12:58: Train Epoch 4: 407/634 Loss: 0.156350
2023-01-01 12:58: Train Epoch 4: 411/634 Loss: 0.188628
2023-01-01 12:58: Train Epoch 4: 415/634 Loss: 0.165879
2023-01-01 12:58: Train Epoch 4: 419/634 Loss: 0.208751
2023-01-01 12:59: Train Epoch 4: 423/634 Loss: 0.165568
2023-01-01 12:59: Train Epoch 4: 427/634 Loss: 0.203560
2023-01-01 12:59: Train Epoch 4: 431/634 Loss: 0.165550
2023-01-01 13:00: Train Epoch 4: 435/634 Loss: 0.160270
2023-01-01 13:00: Train Epoch 4: 439/634 Loss: 0.191334
2023-01-01 13:00: Train Epoch 4: 443/634 Loss: 0.187702
2023-01-01 13:00: Train Epoch 4: 447/634 Loss: 0.181222
2023-01-01 13:01: Train Epoch 4: 451/634 Loss: 0.191070
2023-01-01 13:01: Train Epoch 4: 455/634 Loss: 0.195579
2023-01-01 13:01: Train Epoch 4: 459/634 Loss: 0.163241
2023-01-01 13:01: Train Epoch 4: 463/634 Loss: 0.153101
2023-01-01 13:02: Train Epoch 4: 467/634 Loss: 0.147966
2023-01-01 13:02: Train Epoch 4: 471/634 Loss: 0.247211
2023-01-01 13:02: Train Epoch 4: 475/634 Loss: 0.177503
2023-01-01 13:03: Train Epoch 4: 479/634 Loss: 0.177010
2023-01-01 13:03: Train Epoch 4: 483/634 Loss: 0.169054
2023-01-01 13:03: Train Epoch 4: 487/634 Loss: 0.201441
2023-01-01 13:03: Train Epoch 4: 491/634 Loss: 0.215090
2023-01-01 13:04: Train Epoch 4: 495/634 Loss: 0.160330
2023-01-01 13:04: Train Epoch 4: 499/634 Loss: 0.175885
2023-01-01 13:04: Train Epoch 4: 503/634 Loss: 0.176885
2023-01-01 13:04: Train Epoch 4: 507/634 Loss: 0.160374
2023-01-01 13:05: Train Epoch 4: 511/634 Loss: 0.187899
2023-01-01 13:05: Train Epoch 4: 515/634 Loss: 0.172541
2023-01-01 13:05: Train Epoch 4: 519/634 Loss: 0.152118
2023-01-01 13:05: Train Epoch 4: 523/634 Loss: 0.167565
2023-01-01 13:06: Train Epoch 4: 527/634 Loss: 0.182201
2023-01-01 13:06: Train Epoch 4: 531/634 Loss: 0.169128
2023-01-01 13:06: Train Epoch 4: 535/634 Loss: 0.139385
2023-01-01 13:06: Train Epoch 4: 539/634 Loss: 0.160810
2023-01-01 13:07: Train Epoch 4: 543/634 Loss: 0.161607
2023-01-01 13:07: Train Epoch 4: 547/634 Loss: 0.191163
2023-01-01 13:07: Train Epoch 4: 551/634 Loss: 0.177653
2023-01-01 13:07: Train Epoch 4: 555/634 Loss: 0.158772
2023-01-01 13:07: Train Epoch 4: 559/634 Loss: 0.165014
2023-01-01 13:08: Train Epoch 4: 563/634 Loss: 0.147225
2023-01-01 13:08: Train Epoch 4: 567/634 Loss: 0.166271
2023-01-01 13:08: Train Epoch 4: 571/634 Loss: 0.156094
2023-01-01 13:08: Train Epoch 4: 575/634 Loss: 0.166196
2023-01-01 13:09: Train Epoch 4: 579/634 Loss: 0.171877
2023-01-01 13:09: Train Epoch 4: 583/634 Loss: 0.170069
2023-01-01 13:09: Train Epoch 4: 587/634 Loss: 0.152843
2023-01-01 13:09: Train Epoch 4: 591/634 Loss: 0.173581
2023-01-01 13:10: Train Epoch 4: 595/634 Loss: 0.149006
2023-01-01 13:10: Train Epoch 4: 599/634 Loss: 0.194560
2023-01-01 13:10: Train Epoch 4: 603/634 Loss: 0.149805
2023-01-01 13:11: Train Epoch 4: 607/634 Loss: 0.163796
2023-01-01 13:11: Train Epoch 4: 611/634 Loss: 0.160071
2023-01-01 13:11: Train Epoch 4: 615/634 Loss: 0.160132
2023-01-01 13:11: Train Epoch 4: 619/634 Loss: 0.229813
2023-01-01 13:11: Train Epoch 4: 623/634 Loss: 0.196451
2023-01-01 13:12: Train Epoch 4: 627/634 Loss: 0.133817
2023-01-01 13:12: Train Epoch 4: 631/634 Loss: 0.204634
2023-01-01 13:12: Train Epoch 4: 633/634 Loss: 0.073448
2023-01-01 13:12: **********Train Epoch 4: averaged Loss: 0.175893 
2023-01-01 13:12: 
Epoch time elapsed: 2406.86070728302

2023-01-01 13:13: 
 metrics validation: {'precision': 0.7454010301692421, 'recall': 0.7792307692307693, 'f1-score': 0.7619405791650997, 'support': 1300, 'AUC': 0.9146934911242602, 'AUCPR': 0.8419428108185162, 'TP': 1013, 'FP': 346, 'TN': 2254, 'FN': 287} 

2023-01-01 13:13: **********Val Epoch 4: average Loss: 0.167461
2023-01-01 13:13: *********************************Current best model saved!
2023-01-01 13:14: 
 Testing metrics {'precision': 0.7758037225042301, 'recall': 0.746742671009772, 'f1-score': 0.7609958506224067, 'support': 1228, 'AUC': 0.9119914402274826, 'AUCPR': 0.86610071674624, 'TP': 917, 'FP': 265, 'TN': 2191, 'FN': 311} 

2023-01-01 13:18: 
 Testing metrics {'precision': 0.8606830487296959, 'recall': 0.9378261856137963, 'f1-score': 0.8976001737430773, 'support': 4407, 'AUC': 0.9791695082122018, 'AUCPR': 0.9625761494256462, 'TP': 4133, 'FP': 669, 'TN': 8145, 'FN': 274} 

2023-01-01 13:18: Train Epoch 5: 3/634 Loss: 0.166042
2023-01-01 13:19: Train Epoch 5: 7/634 Loss: 0.194600
2023-01-01 13:19: Train Epoch 5: 11/634 Loss: 0.144346
2023-01-01 13:19: Train Epoch 5: 15/634 Loss: 0.173192
2023-01-01 13:19: Train Epoch 5: 19/634 Loss: 0.186810
2023-01-01 13:20: Train Epoch 5: 23/634 Loss: 0.191622
2023-01-01 13:20: Train Epoch 5: 27/634 Loss: 0.186796
2023-01-01 13:20: Train Epoch 5: 31/634 Loss: 0.229870
2023-01-01 13:20: Train Epoch 5: 35/634 Loss: 0.174614
2023-01-01 13:21: Train Epoch 5: 39/634 Loss: 0.261894
2023-01-01 13:21: Train Epoch 5: 43/634 Loss: 0.152477
2023-01-01 13:21: Train Epoch 5: 47/634 Loss: 0.194633
2023-01-01 13:21: Train Epoch 5: 51/634 Loss: 0.207381
2023-01-01 13:22: Train Epoch 5: 55/634 Loss: 0.164890
2023-01-01 13:22: Train Epoch 5: 59/634 Loss: 0.163421
2023-01-01 13:22: Train Epoch 5: 63/634 Loss: 0.174210
2023-01-01 13:22: Train Epoch 5: 67/634 Loss: 0.193048
2023-01-01 13:23: Train Epoch 5: 71/634 Loss: 0.178829
2023-01-01 13:23: Train Epoch 5: 75/634 Loss: 0.143731
2023-01-01 13:23: Train Epoch 5: 79/634 Loss: 0.162203
2023-01-01 13:23: Train Epoch 5: 83/634 Loss: 0.195007
2023-01-01 13:24: Train Epoch 5: 87/634 Loss: 0.167643
2023-01-01 13:24: Train Epoch 5: 91/634 Loss: 0.155382
2023-01-01 13:24: Train Epoch 5: 95/634 Loss: 0.163363
2023-01-01 13:24: Train Epoch 5: 99/634 Loss: 0.161834
2023-01-01 13:25: Train Epoch 5: 103/634 Loss: 0.155599
2023-01-01 13:25: Train Epoch 5: 107/634 Loss: 0.156737
2023-01-01 13:25: Train Epoch 5: 111/634 Loss: 0.149384
2023-01-01 13:25: Train Epoch 5: 115/634 Loss: 0.154316
2023-01-01 13:26: Train Epoch 5: 119/634 Loss: 0.182651
2023-01-01 13:26: Train Epoch 5: 123/634 Loss: 0.175762
2023-01-01 13:26: Train Epoch 5: 127/634 Loss: 0.163630
2023-01-01 13:26: Train Epoch 5: 131/634 Loss: 0.177440
2023-01-01 13:27: Train Epoch 5: 135/634 Loss: 0.171009
2023-01-01 13:27: Train Epoch 5: 139/634 Loss: 0.132399
2023-01-01 13:27: Train Epoch 5: 143/634 Loss: 0.174219
2023-01-01 13:27: Train Epoch 5: 147/634 Loss: 0.200456
2023-01-01 13:28: Train Epoch 5: 151/634 Loss: 0.161365
2023-01-01 13:28: Train Epoch 5: 155/634 Loss: 0.153563
2023-01-01 13:28: Train Epoch 5: 159/634 Loss: 0.144118
2023-01-01 13:28: Train Epoch 5: 163/634 Loss: 0.158729
2023-01-01 13:29: Train Epoch 5: 167/634 Loss: 0.154000
2023-01-01 13:29: Train Epoch 5: 171/634 Loss: 0.146205
2023-01-01 13:29: Train Epoch 5: 175/634 Loss: 0.162574
2023-01-01 13:29: Train Epoch 5: 179/634 Loss: 0.176478
2023-01-01 13:30: Train Epoch 5: 183/634 Loss: 0.165999
2023-01-01 13:30: Train Epoch 5: 187/634 Loss: 0.187814
2023-01-01 13:30: Train Epoch 5: 191/634 Loss: 0.164452
2023-01-01 13:30: Train Epoch 5: 195/634 Loss: 0.145359
2023-01-01 13:31: Train Epoch 5: 199/634 Loss: 0.160936
2023-01-01 13:31: Train Epoch 5: 203/634 Loss: 0.152997
2023-01-01 13:31: Train Epoch 5: 207/634 Loss: 0.159889
2023-01-01 13:31: Train Epoch 5: 211/634 Loss: 0.172447
2023-01-01 13:32: Train Epoch 5: 215/634 Loss: 0.151569
2023-01-01 13:32: Train Epoch 5: 219/634 Loss: 0.128445
2023-01-01 13:32: Train Epoch 5: 223/634 Loss: 0.185753
2023-01-01 13:32: Train Epoch 5: 227/634 Loss: 0.140648
2023-01-01 13:33: Train Epoch 5: 231/634 Loss: 0.168122
2023-01-01 13:33: Train Epoch 5: 235/634 Loss: 0.205657
2023-01-01 13:33: Train Epoch 5: 239/634 Loss: 0.155950
2023-01-01 13:33: Train Epoch 5: 243/634 Loss: 0.154600
2023-01-01 13:34: Train Epoch 5: 247/634 Loss: 0.167491
2023-01-01 13:34: Train Epoch 5: 251/634 Loss: 0.145745
2023-01-01 13:34: Train Epoch 5: 255/634 Loss: 0.150735
2023-01-01 13:34: Train Epoch 5: 259/634 Loss: 0.143779
2023-01-01 13:34: Train Epoch 5: 263/634 Loss: 0.155393
2023-01-01 13:35: Train Epoch 5: 267/634 Loss: 0.195377
2023-01-01 13:35: Train Epoch 5: 271/634 Loss: 0.177157
2023-01-01 13:35: Train Epoch 5: 275/634 Loss: 0.147404
2023-01-01 13:35: Train Epoch 5: 279/634 Loss: 0.182840
2023-01-01 13:36: Train Epoch 5: 283/634 Loss: 0.153797
2023-01-01 13:36: Train Epoch 5: 287/634 Loss: 0.144662
2023-01-01 13:36: Train Epoch 5: 291/634 Loss: 0.159063
2023-01-01 13:36: Train Epoch 5: 295/634 Loss: 0.187905
2023-01-01 13:37: Train Epoch 5: 299/634 Loss: 0.177227
2023-01-01 13:37: Train Epoch 5: 303/634 Loss: 0.153067
2023-01-01 13:37: Train Epoch 5: 307/634 Loss: 0.152921
2023-01-01 13:37: Train Epoch 5: 311/634 Loss: 0.178632
2023-01-01 13:38: Train Epoch 5: 315/634 Loss: 0.185875
2023-01-01 13:38: Train Epoch 5: 319/634 Loss: 0.156939
2023-01-01 13:38: Train Epoch 5: 323/634 Loss: 0.164581
2023-01-01 13:38: Train Epoch 5: 327/634 Loss: 0.197578
2023-01-01 13:39: Train Epoch 5: 331/634 Loss: 0.166996
2023-01-01 13:39: Train Epoch 5: 335/634 Loss: 0.159444
2023-01-01 13:39: Train Epoch 5: 339/634 Loss: 0.167532
2023-01-01 13:39: Train Epoch 5: 343/634 Loss: 0.161517
2023-01-01 13:40: Train Epoch 5: 347/634 Loss: 0.157673
2023-01-01 13:40: Train Epoch 5: 351/634 Loss: 0.165801
2023-01-01 13:40: Train Epoch 5: 355/634 Loss: 0.140349
2023-01-01 13:41: Train Epoch 5: 359/634 Loss: 0.144444
2023-01-01 13:41: Train Epoch 5: 363/634 Loss: 0.196761
2023-01-01 13:41: Train Epoch 5: 367/634 Loss: 0.184897
2023-01-01 13:41: Train Epoch 5: 371/634 Loss: 0.165206
2023-01-01 13:42: Train Epoch 5: 375/634 Loss: 0.149371
2023-01-01 13:42: Train Epoch 5: 379/634 Loss: 0.145820
2023-01-01 13:42: Train Epoch 5: 383/634 Loss: 0.178378
2023-01-01 13:42: Train Epoch 5: 387/634 Loss: 0.148234
2023-01-01 13:43: Train Epoch 5: 391/634 Loss: 0.180854
2023-01-01 13:43: Train Epoch 5: 395/634 Loss: 0.183323
2023-01-01 13:43: Train Epoch 5: 399/634 Loss: 0.206350
2023-01-01 13:43: Train Epoch 5: 403/634 Loss: 0.155802
2023-01-01 13:43: Train Epoch 5: 407/634 Loss: 0.171066
2023-01-01 13:44: Train Epoch 5: 411/634 Loss: 0.167302
2023-01-01 13:44: Train Epoch 5: 415/634 Loss: 0.180346
2023-01-01 13:44: Train Epoch 5: 419/634 Loss: 0.129028
2023-01-01 13:45: Train Epoch 5: 423/634 Loss: 0.187231
2023-01-01 13:45: Train Epoch 5: 427/634 Loss: 0.164324
2023-01-01 13:45: Train Epoch 5: 431/634 Loss: 0.208068
2023-01-01 13:45: Train Epoch 5: 435/634 Loss: 0.197334
2023-01-01 13:45: Train Epoch 5: 439/634 Loss: 0.143862
2023-01-01 13:46: Train Epoch 5: 443/634 Loss: 0.216443
2023-01-01 13:46: Train Epoch 5: 447/634 Loss: 0.174873
2023-01-01 13:46: Train Epoch 5: 451/634 Loss: 0.145158
2023-01-01 13:47: Train Epoch 5: 455/634 Loss: 0.206915
2023-01-01 13:47: Train Epoch 5: 459/634 Loss: 0.154338
2023-01-01 13:47: Train Epoch 5: 463/634 Loss: 0.169714
2023-01-01 13:47: Train Epoch 5: 467/634 Loss: 0.193559
2023-01-01 13:47: Train Epoch 5: 471/634 Loss: 0.136089
2023-01-01 13:48: Train Epoch 5: 475/634 Loss: 0.129519
2023-01-01 13:48: Train Epoch 5: 479/634 Loss: 0.164528
2023-01-01 13:48: Train Epoch 5: 483/634 Loss: 0.213283
2023-01-01 13:48: Train Epoch 5: 487/634 Loss: 0.188986
2023-01-01 13:49: Train Epoch 5: 491/634 Loss: 0.198943
2023-01-01 13:49: Train Epoch 5: 495/634 Loss: 0.194470
2023-01-01 13:49: Train Epoch 5: 499/634 Loss: 0.147834
2023-01-01 13:49: Train Epoch 5: 503/634 Loss: 0.227956
2023-01-01 13:50: Train Epoch 5: 507/634 Loss: 0.146295
2023-01-01 13:50: Train Epoch 5: 511/634 Loss: 0.150837
2023-01-01 13:50: Train Epoch 5: 515/634 Loss: 0.142579
2023-01-01 13:51: Train Epoch 5: 519/634 Loss: 0.165758
2023-01-01 13:51: Train Epoch 5: 523/634 Loss: 0.176157
2023-01-01 13:51: Train Epoch 5: 527/634 Loss: 0.167554
2023-01-01 13:51: Train Epoch 5: 531/634 Loss: 0.182674
2023-01-01 13:52: Train Epoch 5: 535/634 Loss: 0.171148
2023-01-01 13:52: Train Epoch 5: 539/634 Loss: 0.153667
2023-01-01 13:52: Train Epoch 5: 543/634 Loss: 0.190498
2023-01-01 13:52: Train Epoch 5: 547/634 Loss: 0.160029
2023-01-01 13:53: Train Epoch 5: 551/634 Loss: 0.172561
2023-01-01 13:53: Train Epoch 5: 555/634 Loss: 0.151227
2023-01-01 13:53: Train Epoch 5: 559/634 Loss: 0.177975
2023-01-01 13:53: Train Epoch 5: 563/634 Loss: 0.171262
2023-01-01 13:53: Train Epoch 5: 567/634 Loss: 0.156493
2023-01-01 13:54: Train Epoch 5: 571/634 Loss: 0.177609
2023-01-01 13:54: Train Epoch 5: 575/634 Loss: 0.162253
2023-01-01 13:54: Train Epoch 5: 579/634 Loss: 0.153855
2023-01-01 13:54: Train Epoch 5: 583/634 Loss: 0.148057
2023-01-01 13:55: Train Epoch 5: 587/634 Loss: 0.167283
2023-01-01 13:55: Train Epoch 5: 591/634 Loss: 0.175826
2023-01-01 13:55: Train Epoch 5: 595/634 Loss: 0.157096
2023-01-01 13:55: Train Epoch 5: 599/634 Loss: 0.155077
2023-01-01 13:56: Train Epoch 5: 603/634 Loss: 0.165437
2023-01-01 13:56: Train Epoch 5: 607/634 Loss: 0.182957
2023-01-01 13:56: Train Epoch 5: 611/634 Loss: 0.171644
2023-01-01 13:56: Train Epoch 5: 615/634 Loss: 0.155179
2023-01-01 13:57: Train Epoch 5: 619/634 Loss: 0.165948
2023-01-01 13:57: Train Epoch 5: 623/634 Loss: 0.179050
2023-01-01 13:57: Train Epoch 5: 627/634 Loss: 0.198920
2023-01-01 13:57: Train Epoch 5: 631/634 Loss: 0.138397
2023-01-01 13:57: Train Epoch 5: 633/634 Loss: 0.065335
2023-01-01 13:57: **********Train Epoch 5: averaged Loss: 0.168200 
2023-01-01 13:57: 
Epoch time elapsed: 2357.0052812099457

2023-01-01 13:59: 
 metrics validation: {'precision': 0.8533724340175953, 'recall': 0.6715384615384615, 'f1-score': 0.751614291863969, 'support': 1300, 'AUC': 0.9288463017751479, 'AUCPR': 0.8602288981267812, 'TP': 873, 'FP': 150, 'TN': 2450, 'FN': 427} 

2023-01-01 13:59: **********Val Epoch 5: average Loss: 0.161517
2023-01-01 13:59: *********************************Current best model saved!
2023-01-01 14:00: 
 Testing metrics {'precision': 0.8845338983050848, 'recall': 0.6799674267100977, 'f1-score': 0.768876611418048, 'support': 1228, 'AUC': 0.9238440195651942, 'AUCPR': 0.8792700206988953, 'TP': 835, 'FP': 109, 'TN': 2347, 'FN': 393} 

2023-01-01 14:04: 
 Testing metrics {'precision': 0.9349380362249762, 'recall': 0.8901747220331291, 'f1-score': 0.9120074392653725, 'support': 4407, 'AUC': 0.9817518970711498, 'AUCPR': 0.968919557176755, 'TP': 3923, 'FP': 273, 'TN': 8541, 'FN': 484} 

2023-01-01 14:04: Train Epoch 6: 3/634 Loss: 0.173544
2023-01-01 14:04: Train Epoch 6: 7/634 Loss: 0.181960
2023-01-01 14:04: Train Epoch 6: 11/634 Loss: 0.159564
2023-01-01 14:04: Train Epoch 6: 15/634 Loss: 0.138885
2023-01-01 14:05: Train Epoch 6: 19/634 Loss: 0.171285
2023-01-01 14:05: Train Epoch 6: 23/634 Loss: 0.191557
2023-01-01 14:05: Train Epoch 6: 27/634 Loss: 0.160713
2023-01-01 14:05: Train Epoch 6: 31/634 Loss: 0.208837
2023-01-01 14:06: Train Epoch 6: 35/634 Loss: 0.155568
2023-01-01 14:06: Train Epoch 6: 39/634 Loss: 0.151602
2023-01-01 14:06: Train Epoch 6: 43/634 Loss: 0.174235
2023-01-01 14:06: Train Epoch 6: 47/634 Loss: 0.168454
2023-01-01 14:07: Train Epoch 6: 51/634 Loss: 0.174661
2023-01-01 14:07: Train Epoch 6: 55/634 Loss: 0.167713
2023-01-01 14:07: Train Epoch 6: 59/634 Loss: 0.134573
2023-01-01 14:07: Train Epoch 6: 63/634 Loss: 0.154668
2023-01-01 14:08: Train Epoch 6: 67/634 Loss: 0.193905
2023-01-01 14:08: Train Epoch 6: 71/634 Loss: 0.152885
2023-01-01 14:08: Train Epoch 6: 75/634 Loss: 0.169444
2023-01-01 14:08: Train Epoch 6: 79/634 Loss: 0.147298
2023-01-01 14:09: Train Epoch 6: 83/634 Loss: 0.210159
2023-01-01 14:09: Train Epoch 6: 87/634 Loss: 0.124038
2023-01-01 14:09: Train Epoch 6: 91/634 Loss: 0.186668
2023-01-01 14:09: Train Epoch 6: 95/634 Loss: 0.172853
2023-01-01 14:10: Train Epoch 6: 99/634 Loss: 0.142631
2023-01-01 14:10: Train Epoch 6: 103/634 Loss: 0.200821
2023-01-01 14:10: Train Epoch 6: 107/634 Loss: 0.136197
2023-01-01 14:10: Train Epoch 6: 111/634 Loss: 0.147216
2023-01-01 14:11: Train Epoch 6: 115/634 Loss: 0.171230
2023-01-01 14:11: Train Epoch 6: 119/634 Loss: 0.179709
2023-01-01 14:11: Train Epoch 6: 123/634 Loss: 0.132491
2023-01-01 14:11: Train Epoch 6: 127/634 Loss: 0.147115
2023-01-01 14:12: Train Epoch 6: 131/634 Loss: 0.148329
2023-01-01 14:12: Train Epoch 6: 135/634 Loss: 0.160229
2023-01-01 14:12: Train Epoch 6: 139/634 Loss: 0.122495
2023-01-01 14:12: Train Epoch 6: 143/634 Loss: 0.156001
2023-01-01 14:13: Train Epoch 6: 147/634 Loss: 0.178741
2023-01-01 14:13: Train Epoch 6: 151/634 Loss: 0.169181
2023-01-01 14:13: Train Epoch 6: 155/634 Loss: 0.133640
2023-01-01 14:13: Train Epoch 6: 159/634 Loss: 0.169014
2023-01-01 14:14: Train Epoch 6: 163/634 Loss: 0.173830
2023-01-01 14:14: Train Epoch 6: 167/634 Loss: 0.161624
2023-01-01 14:14: Train Epoch 6: 171/634 Loss: 0.157325
2023-01-01 14:14: Train Epoch 6: 175/634 Loss: 0.148132
2023-01-01 14:15: Train Epoch 6: 179/634 Loss: 0.171598
2023-01-01 14:15: Train Epoch 6: 183/634 Loss: 0.186466
2023-01-01 14:15: Train Epoch 6: 187/634 Loss: 0.156311
2023-01-01 14:15: Train Epoch 6: 191/634 Loss: 0.203510
2023-01-01 14:16: Train Epoch 6: 195/634 Loss: 0.156358
2023-01-01 14:16: Train Epoch 6: 199/634 Loss: 0.180723
2023-01-01 14:16: Train Epoch 6: 203/634 Loss: 0.244194
2023-01-01 14:16: Train Epoch 6: 207/634 Loss: 0.166923
2023-01-01 14:17: Train Epoch 6: 211/634 Loss: 0.140548
2023-01-01 14:17: Train Epoch 6: 215/634 Loss: 0.186631
2023-01-01 14:17: Train Epoch 6: 219/634 Loss: 0.186106
2023-01-01 14:17: Train Epoch 6: 223/634 Loss: 0.133675
2023-01-01 14:18: Train Epoch 6: 227/634 Loss: 0.222125
2023-01-01 14:18: Train Epoch 6: 231/634 Loss: 0.204344
2023-01-01 14:18: Train Epoch 6: 235/634 Loss: 0.185407
2023-01-01 14:18: Train Epoch 6: 239/634 Loss: 0.164638
2023-01-01 14:19: Train Epoch 6: 243/634 Loss: 0.204964
2023-01-01 14:19: Train Epoch 6: 247/634 Loss: 0.231613
2023-01-01 14:19: Train Epoch 6: 251/634 Loss: 0.158177
2023-01-01 14:19: Train Epoch 6: 255/634 Loss: 0.183739
2023-01-01 14:19: Train Epoch 6: 259/634 Loss: 0.273872
2023-01-01 14:20: Train Epoch 6: 263/634 Loss: 0.149565
2023-01-01 14:20: Train Epoch 6: 267/634 Loss: 0.162687
2023-01-01 14:20: Train Epoch 6: 271/634 Loss: 0.313479
2023-01-01 14:21: Train Epoch 6: 275/634 Loss: 0.215116
2023-01-01 14:21: Train Epoch 6: 279/634 Loss: 0.194613
2023-01-01 14:21: Train Epoch 6: 283/634 Loss: 0.212363
2023-01-01 14:21: Train Epoch 6: 287/634 Loss: 0.203489
2023-01-01 14:21: Train Epoch 6: 291/634 Loss: 0.196325
2023-01-01 14:22: Train Epoch 6: 295/634 Loss: 0.146026
2023-01-01 14:22: Train Epoch 6: 299/634 Loss: 0.207445
2023-01-01 14:22: Train Epoch 6: 303/634 Loss: 0.185022
2023-01-01 14:22: Train Epoch 6: 307/634 Loss: 0.119527
2023-01-01 14:23: Train Epoch 6: 311/634 Loss: 0.181853
2023-01-01 14:23: Train Epoch 6: 315/634 Loss: 0.157026
2023-01-01 14:23: Train Epoch 6: 319/634 Loss: 0.154325
2023-01-01 14:23: Train Epoch 6: 323/634 Loss: 0.144090
2023-01-01 14:24: Train Epoch 6: 327/634 Loss: 0.157682
2023-01-01 14:24: Train Epoch 6: 331/634 Loss: 0.173158
2023-01-01 14:24: Train Epoch 6: 335/634 Loss: 0.166315
2023-01-01 14:24: Train Epoch 6: 339/634 Loss: 0.161105
2023-01-01 14:25: Train Epoch 6: 343/634 Loss: 0.162088
2023-01-01 14:25: Train Epoch 6: 347/634 Loss: 0.135974
2023-01-01 14:25: Train Epoch 6: 351/634 Loss: 0.180253
2023-01-01 14:25: Train Epoch 6: 355/634 Loss: 0.181744
2023-01-01 14:26: Train Epoch 6: 359/634 Loss: 0.153335
2023-01-01 14:26: Train Epoch 6: 363/634 Loss: 0.142515
2023-01-01 14:26: Train Epoch 6: 367/634 Loss: 0.147694
2023-01-01 14:26: Train Epoch 6: 371/634 Loss: 0.143918
2023-01-01 14:27: Train Epoch 6: 375/634 Loss: 0.189563
2023-01-01 14:27: Train Epoch 6: 379/634 Loss: 0.168372
2023-01-01 14:27: Train Epoch 6: 383/634 Loss: 0.160290
2023-01-01 14:27: Train Epoch 6: 387/634 Loss: 0.169256
2023-01-01 14:28: Train Epoch 6: 391/634 Loss: 0.162105
2023-01-01 14:28: Train Epoch 6: 395/634 Loss: 0.161535
2023-01-01 14:28: Train Epoch 6: 399/634 Loss: 0.174239
2023-01-01 14:28: Train Epoch 6: 403/634 Loss: 0.146332
2023-01-01 14:29: Train Epoch 6: 407/634 Loss: 0.166635
2023-01-01 14:29: Train Epoch 6: 411/634 Loss: 0.161113
2023-01-01 14:29: Train Epoch 6: 415/634 Loss: 0.177626
2023-01-01 14:29: Train Epoch 6: 419/634 Loss: 0.149035
2023-01-01 14:30: Train Epoch 6: 423/634 Loss: 0.137079
2023-01-01 14:30: Train Epoch 6: 427/634 Loss: 0.164399
2023-01-01 14:30: Train Epoch 6: 431/634 Loss: 0.195493
2023-01-01 14:30: Train Epoch 6: 435/634 Loss: 0.144046
2023-01-01 14:31: Train Epoch 6: 439/634 Loss: 0.158670
2023-01-01 14:31: Train Epoch 6: 443/634 Loss: 0.165198
2023-01-01 14:31: Train Epoch 6: 447/634 Loss: 0.176604
2023-01-01 14:31: Train Epoch 6: 451/634 Loss: 0.155064
2023-01-01 14:32: Train Epoch 6: 455/634 Loss: 0.146285
2023-01-01 14:32: Train Epoch 6: 459/634 Loss: 0.163866
2023-01-01 14:32: Train Epoch 6: 463/634 Loss: 0.179262
2023-01-01 14:32: Train Epoch 6: 467/634 Loss: 0.148356
2023-01-01 14:33: Train Epoch 6: 471/634 Loss: 0.148591
2023-01-01 14:33: Train Epoch 6: 475/634 Loss: 0.155141
2023-01-01 14:33: Train Epoch 6: 479/634 Loss: 0.181660
2023-01-01 14:33: Train Epoch 6: 483/634 Loss: 0.134226
2023-01-01 14:34: Train Epoch 6: 487/634 Loss: 0.125047
2023-01-01 14:34: Train Epoch 6: 491/634 Loss: 0.153686
2023-01-01 14:34: Train Epoch 6: 495/634 Loss: 0.138126
2023-01-01 14:34: Train Epoch 6: 499/634 Loss: 0.195769
2023-01-01 14:35: Train Epoch 6: 503/634 Loss: 0.130995
2023-01-01 14:35: Train Epoch 6: 507/634 Loss: 0.160820
2023-01-01 14:35: Train Epoch 6: 511/634 Loss: 0.161908
2023-01-01 14:35: Train Epoch 6: 515/634 Loss: 0.126747
2023-01-01 14:35: Train Epoch 6: 519/634 Loss: 0.131378
2023-01-01 14:36: Train Epoch 6: 523/634 Loss: 0.137253
2023-01-01 14:36: Train Epoch 6: 527/634 Loss: 0.145994
2023-01-01 14:36: Train Epoch 6: 531/634 Loss: 0.159454
2023-01-01 14:36: Train Epoch 6: 535/634 Loss: 0.173651
2023-01-01 14:37: Train Epoch 6: 539/634 Loss: 0.148822
2023-01-01 14:37: Train Epoch 6: 543/634 Loss: 0.151990
2023-01-01 14:37: Train Epoch 6: 547/634 Loss: 0.183320
2023-01-01 14:37: Train Epoch 6: 551/634 Loss: 0.166367
2023-01-01 14:38: Train Epoch 6: 555/634 Loss: 0.162351
2023-01-01 14:38: Train Epoch 6: 559/634 Loss: 0.180337
2023-01-01 14:38: Train Epoch 6: 563/634 Loss: 0.145051
2023-01-01 14:39: Train Epoch 6: 567/634 Loss: 0.178178
2023-01-01 14:39: Train Epoch 6: 571/634 Loss: 0.161487
2023-01-01 14:39: Train Epoch 6: 575/634 Loss: 0.164125
2023-01-01 14:39: Train Epoch 6: 579/634 Loss: 0.161353
2023-01-01 14:40: Train Epoch 6: 583/634 Loss: 0.156548
2023-01-01 14:40: Train Epoch 6: 587/634 Loss: 0.152395
2023-01-01 14:40: Train Epoch 6: 591/634 Loss: 0.162487
2023-01-01 14:40: Train Epoch 6: 595/634 Loss: 0.161100
2023-01-01 14:41: Train Epoch 6: 599/634 Loss: 0.162765
2023-01-01 14:41: Train Epoch 6: 603/634 Loss: 0.157929
2023-01-01 14:41: Train Epoch 6: 607/634 Loss: 0.139490
2023-01-01 14:41: Train Epoch 6: 611/634 Loss: 0.157955
2023-01-01 14:42: Train Epoch 6: 615/634 Loss: 0.162825
2023-01-01 14:42: Train Epoch 6: 619/634 Loss: 0.152364
2023-01-01 14:42: Train Epoch 6: 623/634 Loss: 0.139011
2023-01-01 14:43: Train Epoch 6: 627/634 Loss: 0.158315
2023-01-01 14:43: Train Epoch 6: 631/634 Loss: 0.159394
2023-01-01 14:43: Train Epoch 6: 633/634 Loss: 0.069567
2023-01-01 14:43: **********Train Epoch 6: averaged Loss: 0.165585 
2023-01-01 14:43: 
Epoch time elapsed: 2361.9902803897858

2023-01-01 14:44: 
 metrics validation: {'precision': 0.8391787852865698, 'recall': 0.7546153846153846, 'f1-score': 0.7946537059538274, 'support': 1300, 'AUC': 0.9314011834319527, 'AUCPR': 0.8726945643090764, 'TP': 981, 'FP': 188, 'TN': 2412, 'FN': 319} 

2023-01-01 14:44: **********Val Epoch 6: average Loss: 0.152474
2023-01-01 14:44: *********************************Current best model saved!
2023-01-01 14:45: 
 Testing metrics {'precision': 0.8534836065573771, 'recall': 0.6783387622149837, 'f1-score': 0.7558983666061707, 'support': 1228, 'AUC': 0.9207591061974133, 'AUCPR': 0.874204817823803, 'TP': 833, 'FP': 143, 'TN': 2313, 'FN': 395} 

2023-01-01 14:49: 
 Testing metrics {'precision': 0.9195642095503014, 'recall': 0.9001588382119355, 'f1-score': 0.9097580552688911, 'support': 4407, 'AUC': 0.9796406062121709, 'AUCPR': 0.9622205860379296, 'TP': 3967, 'FP': 347, 'TN': 8467, 'FN': 440} 

2023-01-01 14:50: Train Epoch 7: 3/634 Loss: 0.148618
2023-01-01 14:50: Train Epoch 7: 7/634 Loss: 0.175889
2023-01-01 14:50: Train Epoch 7: 11/634 Loss: 0.138630
2023-01-01 14:50: Train Epoch 7: 15/634 Loss: 0.155717
2023-01-01 14:51: Train Epoch 7: 19/634 Loss: 0.158792
2023-01-01 14:51: Train Epoch 7: 23/634 Loss: 0.141012
2023-01-01 14:51: Train Epoch 7: 27/634 Loss: 0.169436
2023-01-01 14:51: Train Epoch 7: 31/634 Loss: 0.134260
2023-01-01 14:52: Train Epoch 7: 35/634 Loss: 0.160168
2023-01-01 14:52: Train Epoch 7: 39/634 Loss: 0.154816
2023-01-01 14:52: Train Epoch 7: 43/634 Loss: 0.143747
2023-01-01 14:52: Train Epoch 7: 47/634 Loss: 0.159638
2023-01-01 14:53: Train Epoch 7: 51/634 Loss: 0.166076
2023-01-01 14:53: Train Epoch 7: 55/634 Loss: 0.163949
2023-01-01 14:53: Train Epoch 7: 59/634 Loss: 0.158335
2023-01-01 14:53: Train Epoch 7: 63/634 Loss: 0.155124
2023-01-01 14:54: Train Epoch 7: 67/634 Loss: 0.137830
2023-01-01 14:54: Train Epoch 7: 71/634 Loss: 0.146866
2023-01-01 14:54: Train Epoch 7: 75/634 Loss: 0.160175
2023-01-01 14:54: Train Epoch 7: 79/634 Loss: 0.148096
2023-01-01 14:55: Train Epoch 7: 83/634 Loss: 0.150816
2023-01-01 14:55: Train Epoch 7: 87/634 Loss: 0.147620
2023-01-01 14:55: Train Epoch 7: 91/634 Loss: 0.164337
2023-01-01 14:55: Train Epoch 7: 95/634 Loss: 0.156922
2023-01-01 14:56: Train Epoch 7: 99/634 Loss: 0.155706
2023-01-01 14:56: Train Epoch 7: 103/634 Loss: 0.119712
2023-01-01 14:56: Train Epoch 7: 107/634 Loss: 0.167012
2023-01-01 14:56: Train Epoch 7: 111/634 Loss: 0.147905
2023-01-01 14:57: Train Epoch 7: 115/634 Loss: 0.139494
2023-01-01 14:57: Train Epoch 7: 119/634 Loss: 0.150203
2023-01-01 14:57: Train Epoch 7: 123/634 Loss: 0.154795
2023-01-01 14:57: Train Epoch 7: 127/634 Loss: 0.148025
2023-01-01 14:58: Train Epoch 7: 131/634 Loss: 0.162632
2023-01-01 14:58: Train Epoch 7: 135/634 Loss: 0.189250
2023-01-01 14:58: Train Epoch 7: 139/634 Loss: 0.138633
2023-01-01 14:58: Train Epoch 7: 143/634 Loss: 0.137022
2023-01-01 14:59: Train Epoch 7: 147/634 Loss: 0.161957
2023-01-01 14:59: Train Epoch 7: 151/634 Loss: 0.151156
2023-01-01 14:59: Train Epoch 7: 155/634 Loss: 0.136895
2023-01-01 14:59: Train Epoch 7: 159/634 Loss: 0.164867
2023-01-01 15:00: Train Epoch 7: 163/634 Loss: 0.147397
2023-01-01 15:00: Train Epoch 7: 167/634 Loss: 0.158018
2023-01-01 15:00: Train Epoch 7: 171/634 Loss: 0.156778
2023-01-01 15:00: Train Epoch 7: 175/634 Loss: 0.155820
2023-01-01 15:01: Train Epoch 7: 179/634 Loss: 0.154778
2023-01-01 15:01: Train Epoch 7: 183/634 Loss: 0.146455
2023-01-01 15:01: Train Epoch 7: 187/634 Loss: 0.172841
2023-01-01 15:01: Train Epoch 7: 191/634 Loss: 0.132544
2023-01-01 15:02: Train Epoch 7: 195/634 Loss: 0.178026
2023-01-01 15:02: Train Epoch 7: 199/634 Loss: 0.165570
2023-01-01 15:02: Train Epoch 7: 203/634 Loss: 0.122039
2023-01-01 15:02: Train Epoch 7: 207/634 Loss: 0.165199
2023-01-01 15:03: Train Epoch 7: 211/634 Loss: 0.160391
2023-01-01 15:03: Train Epoch 7: 215/634 Loss: 0.160875
2023-01-01 15:03: Train Epoch 7: 219/634 Loss: 0.153072
2023-01-01 15:03: Train Epoch 7: 223/634 Loss: 0.160420
2023-01-01 15:04: Train Epoch 7: 227/634 Loss: 0.147203
2023-01-01 15:04: Train Epoch 7: 231/634 Loss: 0.180585
2023-01-01 15:04: Train Epoch 7: 235/634 Loss: 0.152884
2023-01-01 15:04: Train Epoch 7: 239/634 Loss: 0.155557
2023-01-01 15:05: Train Epoch 7: 243/634 Loss: 0.178665
2023-01-01 15:05: Train Epoch 7: 247/634 Loss: 0.182562
2023-01-01 15:05: Train Epoch 7: 251/634 Loss: 0.155242
2023-01-01 15:05: Train Epoch 7: 255/634 Loss: 0.177772
2023-01-01 15:06: Train Epoch 7: 259/634 Loss: 0.133759
2023-01-01 15:06: Train Epoch 7: 263/634 Loss: 0.161914
2023-01-01 15:06: Train Epoch 7: 267/634 Loss: 0.178291
2023-01-01 15:06: Train Epoch 7: 271/634 Loss: 0.190372
2023-01-01 15:07: Train Epoch 7: 275/634 Loss: 0.160230
2023-01-01 15:07: Train Epoch 7: 279/634 Loss: 0.158306
2023-01-01 15:07: Train Epoch 7: 283/634 Loss: 0.157580
2023-01-01 15:07: Train Epoch 7: 287/634 Loss: 0.139073
2023-01-01 15:08: Train Epoch 7: 291/634 Loss: 0.170882
2023-01-01 15:08: Train Epoch 7: 295/634 Loss: 0.152963
2023-01-01 15:08: Train Epoch 7: 299/634 Loss: 0.162042
2023-01-01 15:08: Train Epoch 7: 303/634 Loss: 0.143324
2023-01-01 15:09: Train Epoch 7: 307/634 Loss: 0.174529
2023-01-01 15:09: Train Epoch 7: 311/634 Loss: 0.133201
2023-01-01 15:09: Train Epoch 7: 315/634 Loss: 0.136779
2023-01-01 15:09: Train Epoch 7: 319/634 Loss: 0.173813
2023-01-01 15:10: Train Epoch 7: 323/634 Loss: 0.124982
2023-01-01 15:10: Train Epoch 7: 327/634 Loss: 0.140863
2023-01-01 15:10: Train Epoch 7: 331/634 Loss: 0.183370
2023-01-01 15:10: Train Epoch 7: 335/634 Loss: 0.146380
2023-01-01 15:11: Train Epoch 7: 339/634 Loss: 0.156928
2023-01-01 15:11: Train Epoch 7: 343/634 Loss: 0.145364
2023-01-01 15:11: Train Epoch 7: 347/634 Loss: 0.174449
2023-01-01 15:11: Train Epoch 7: 351/634 Loss: 0.153610
2023-01-01 15:12: Train Epoch 7: 355/634 Loss: 0.163446
2023-01-01 15:12: Train Epoch 7: 359/634 Loss: 0.131348
2023-01-01 15:12: Train Epoch 7: 363/634 Loss: 0.144407
2023-01-01 15:12: Train Epoch 7: 367/634 Loss: 0.145498
2023-01-01 15:13: Train Epoch 7: 371/634 Loss: 0.148358
2023-01-01 15:13: Train Epoch 7: 375/634 Loss: 0.157704
2023-01-01 15:13: Train Epoch 7: 379/634 Loss: 0.195976
2023-01-01 15:13: Train Epoch 7: 383/634 Loss: 0.134747
2023-01-01 15:14: Train Epoch 7: 387/634 Loss: 0.186359
2023-01-01 15:14: Train Epoch 7: 391/634 Loss: 0.148860
2023-01-01 15:14: Train Epoch 7: 395/634 Loss: 0.155216
2023-01-01 15:14: Train Epoch 7: 399/634 Loss: 0.213038
2023-01-01 15:15: Train Epoch 7: 403/634 Loss: 0.158465
2023-01-01 15:15: Train Epoch 7: 407/634 Loss: 0.163714
2023-01-01 15:15: Train Epoch 7: 411/634 Loss: 0.175740
2023-01-01 15:15: Train Epoch 7: 415/634 Loss: 0.188170
2023-01-01 15:15: Train Epoch 7: 419/634 Loss: 0.165444
2023-01-01 15:16: Train Epoch 7: 423/634 Loss: 0.179913
2023-01-01 15:16: Train Epoch 7: 427/634 Loss: 0.138638
2023-01-01 15:16: Train Epoch 7: 431/634 Loss: 0.141463
2023-01-01 15:16: Train Epoch 7: 435/634 Loss: 0.128514
2023-01-01 15:17: Train Epoch 7: 439/634 Loss: 0.145729
2023-01-01 15:17: Train Epoch 7: 443/634 Loss: 0.123490
2023-01-01 15:17: Train Epoch 7: 447/634 Loss: 0.173629
2023-01-01 15:17: Train Epoch 7: 451/634 Loss: 0.128748
2023-01-01 15:18: Train Epoch 7: 455/634 Loss: 0.136869
2023-01-01 15:18: Train Epoch 7: 459/634 Loss: 0.160043
2023-01-01 15:18: Train Epoch 7: 463/634 Loss: 0.186566
2023-01-01 15:18: Train Epoch 7: 467/634 Loss: 0.148308
2023-01-01 15:19: Train Epoch 7: 471/634 Loss: 0.148681
2023-01-01 15:19: Train Epoch 7: 475/634 Loss: 0.162995
2023-01-01 15:19: Train Epoch 7: 479/634 Loss: 0.155190
2023-01-01 15:19: Train Epoch 7: 483/634 Loss: 0.166964
2023-01-01 15:20: Train Epoch 7: 487/634 Loss: 0.140870
2023-01-01 15:20: Train Epoch 7: 491/634 Loss: 0.190148
2023-01-01 15:20: Train Epoch 7: 495/634 Loss: 0.131928
2023-01-01 15:20: Train Epoch 7: 499/634 Loss: 0.158471
2023-01-01 15:21: Train Epoch 7: 503/634 Loss: 0.166380
2023-01-01 15:21: Train Epoch 7: 507/634 Loss: 0.124147
2023-01-01 15:21: Train Epoch 7: 511/634 Loss: 0.164161
2023-01-01 15:21: Train Epoch 7: 515/634 Loss: 0.160537
2023-01-01 15:22: Train Epoch 7: 519/634 Loss: 0.143930
2023-01-01 15:22: Train Epoch 7: 523/634 Loss: 0.161587
2023-01-01 15:22: Train Epoch 7: 527/634 Loss: 0.159107
2023-01-01 15:22: Train Epoch 7: 531/634 Loss: 0.131642
2023-01-01 15:23: Train Epoch 7: 535/634 Loss: 0.159048
2023-01-01 15:23: Train Epoch 7: 539/634 Loss: 0.164250
2023-01-01 15:23: Train Epoch 7: 543/634 Loss: 0.145148
2023-01-01 15:23: Train Epoch 7: 547/634 Loss: 0.155106
2023-01-01 15:24: Train Epoch 7: 551/634 Loss: 0.158709
2023-01-01 15:24: Train Epoch 7: 555/634 Loss: 0.152900
2023-01-01 15:24: Train Epoch 7: 559/634 Loss: 0.148204
2023-01-01 15:24: Train Epoch 7: 563/634 Loss: 0.146341
2023-01-01 15:25: Train Epoch 7: 567/634 Loss: 0.155538
2023-01-01 15:25: Train Epoch 7: 571/634 Loss: 0.153836
2023-01-01 15:25: Train Epoch 7: 575/634 Loss: 0.176113
2023-01-01 15:25: Train Epoch 7: 579/634 Loss: 0.142640
2023-01-01 15:26: Train Epoch 7: 583/634 Loss: 0.146997
2023-01-01 15:26: Train Epoch 7: 587/634 Loss: 0.149319
2023-01-01 15:26: Train Epoch 7: 591/634 Loss: 0.166153
2023-01-01 15:26: Train Epoch 7: 595/634 Loss: 0.151066
2023-01-01 15:27: Train Epoch 7: 599/634 Loss: 0.160943
2023-01-01 15:27: Train Epoch 7: 603/634 Loss: 0.149709
2023-01-01 15:27: Train Epoch 7: 607/634 Loss: 0.154103
2023-01-01 15:27: Train Epoch 7: 611/634 Loss: 0.163070
2023-01-01 15:28: Train Epoch 7: 615/634 Loss: 0.145654
2023-01-01 15:28: Train Epoch 7: 619/634 Loss: 0.136412
2023-01-01 15:28: Train Epoch 7: 623/634 Loss: 0.180069
2023-01-01 15:28: Train Epoch 7: 627/634 Loss: 0.153909
2023-01-01 15:29: Train Epoch 7: 631/634 Loss: 0.189731
2023-01-01 15:29: Train Epoch 7: 633/634 Loss: 0.073887
2023-01-01 15:29: **********Train Epoch 7: averaged Loss: 0.155408 
2023-01-01 15:29: 
Epoch time elapsed: 2359.1837344169617

2023-01-01 15:30: 
 metrics validation: {'precision': 0.7921390778533636, 'recall': 0.8061538461538461, 'f1-score': 0.7990850171559283, 'support': 1300, 'AUC': 0.9299603550295857, 'AUCPR': 0.8558822211107109, 'TP': 1048, 'FP': 275, 'TN': 2325, 'FN': 252} 

2023-01-01 15:30: **********Val Epoch 7: average Loss: 0.151703
2023-01-01 15:30: *********************************Current best model saved!
2023-01-01 15:31: 
 Testing metrics {'precision': 0.808455565142364, 'recall': 0.7630293159609121, 'f1-score': 0.7850858818600753, 'support': 1228, 'AUC': 0.9259670527008244, 'AUCPR': 0.8803436726643092, 'TP': 937, 'FP': 222, 'TN': 2234, 'FN': 291} 

2023-01-01 15:35: 
 Testing metrics {'precision': 0.8795936013834846, 'recall': 0.9233038348082596, 'f1-score': 0.9009188530942102, 'support': 4407, 'AUC': 0.9789676715916347, 'AUCPR': 0.9615063895698949, 'TP': 4069, 'FP': 557, 'TN': 8257, 'FN': 338} 

2023-01-01 15:35: Train Epoch 8: 3/634 Loss: 0.159202
2023-01-01 15:35: Train Epoch 8: 7/634 Loss: 0.156055
2023-01-01 15:36: Train Epoch 8: 11/634 Loss: 0.177876
2023-01-01 15:36: Train Epoch 8: 15/634 Loss: 0.170270
2023-01-01 15:36: Train Epoch 8: 19/634 Loss: 0.133381
2023-01-01 15:36: Train Epoch 8: 23/634 Loss: 0.167313
2023-01-01 15:37: Train Epoch 8: 27/634 Loss: 0.147745
2023-01-01 15:37: Train Epoch 8: 31/634 Loss: 0.148282
2023-01-01 15:37: Train Epoch 8: 35/634 Loss: 0.167446
2023-01-01 15:37: Train Epoch 8: 39/634 Loss: 0.165245
2023-01-01 15:38: Train Epoch 8: 43/634 Loss: 0.145027
2023-01-01 15:38: Train Epoch 8: 47/634 Loss: 0.117800
2023-01-01 15:38: Train Epoch 8: 51/634 Loss: 0.144195
2023-01-01 15:38: Train Epoch 8: 55/634 Loss: 0.173660
2023-01-01 15:39: Train Epoch 8: 59/634 Loss: 0.159470
2023-01-01 15:39: Train Epoch 8: 63/634 Loss: 0.138656
2023-01-01 15:39: Train Epoch 8: 67/634 Loss: 0.135423
2023-01-01 15:39: Train Epoch 8: 71/634 Loss: 0.168907
2023-01-01 15:40: Train Epoch 8: 75/634 Loss: 0.138273
2023-01-01 15:40: Train Epoch 8: 79/634 Loss: 0.150980
2023-01-01 15:40: Train Epoch 8: 83/634 Loss: 0.155092
2023-01-01 15:40: Train Epoch 8: 87/634 Loss: 0.141653
2023-01-01 15:41: Train Epoch 8: 91/634 Loss: 0.141623
2023-01-01 15:41: Train Epoch 8: 95/634 Loss: 0.150834
2023-01-01 15:41: Train Epoch 8: 99/634 Loss: 0.165858
2023-01-01 15:41: Train Epoch 8: 103/634 Loss: 0.153676
2023-01-01 15:42: Train Epoch 8: 107/634 Loss: 0.151905
2023-01-01 15:42: Train Epoch 8: 111/634 Loss: 0.135601
2023-01-01 15:42: Train Epoch 8: 115/634 Loss: 0.153927
2023-01-01 15:42: Train Epoch 8: 119/634 Loss: 0.149883
2023-01-01 15:43: Train Epoch 8: 123/634 Loss: 0.145302
2023-01-01 15:43: Train Epoch 8: 127/634 Loss: 0.138573
2023-01-01 15:43: Train Epoch 8: 131/634 Loss: 0.158759
2023-01-01 15:43: Train Epoch 8: 135/634 Loss: 0.138752
2023-01-01 15:44: Train Epoch 8: 139/634 Loss: 0.161016
2023-01-01 15:44: Train Epoch 8: 143/634 Loss: 0.151640
2023-01-01 15:44: Train Epoch 8: 147/634 Loss: 0.152391
2023-01-01 15:44: Train Epoch 8: 151/634 Loss: 0.160633
2023-01-01 15:45: Train Epoch 8: 155/634 Loss: 0.125289
2023-01-01 15:45: Train Epoch 8: 159/634 Loss: 0.143721
2023-01-01 15:45: Train Epoch 8: 163/634 Loss: 0.199655
2023-01-01 15:45: Train Epoch 8: 167/634 Loss: 0.141589
2023-01-01 15:46: Train Epoch 8: 171/634 Loss: 0.152206
2023-01-01 15:46: Train Epoch 8: 175/634 Loss: 0.138328
2023-01-01 15:46: Train Epoch 8: 179/634 Loss: 0.144860
2023-01-01 15:46: Train Epoch 8: 183/634 Loss: 0.157423
2023-01-01 15:47: Train Epoch 8: 187/634 Loss: 0.165276
2023-01-01 15:47: Train Epoch 8: 191/634 Loss: 0.155773
2023-01-01 15:47: Train Epoch 8: 195/634 Loss: 0.135261
2023-01-01 15:47: Train Epoch 8: 199/634 Loss: 0.135485
2023-01-01 15:48: Train Epoch 8: 203/634 Loss: 0.163589
2023-01-01 15:48: Train Epoch 8: 207/634 Loss: 0.148086
2023-01-01 15:48: Train Epoch 8: 211/634 Loss: 0.163788
2023-01-01 15:48: Train Epoch 8: 215/634 Loss: 0.145590
2023-01-01 15:49: Train Epoch 8: 219/634 Loss: 0.140830
2023-01-01 15:49: Train Epoch 8: 223/634 Loss: 0.141479
2023-01-01 15:49: Train Epoch 8: 227/634 Loss: 0.189206
2023-01-01 15:49: Train Epoch 8: 231/634 Loss: 0.147044
2023-01-01 15:50: Train Epoch 8: 235/634 Loss: 0.149921
2023-01-01 15:50: Train Epoch 8: 239/634 Loss: 0.141063
2023-01-01 15:50: Train Epoch 8: 243/634 Loss: 0.129839
2023-01-01 15:50: Train Epoch 8: 247/634 Loss: 0.166206
2023-01-01 15:51: Train Epoch 8: 251/634 Loss: 0.151063
2023-01-01 15:51: Train Epoch 8: 255/634 Loss: 0.187504
2023-01-01 15:51: Train Epoch 8: 259/634 Loss: 0.142024
2023-01-01 15:51: Train Epoch 8: 263/634 Loss: 0.111260
2023-01-01 15:52: Train Epoch 8: 267/634 Loss: 0.147161
2023-01-01 15:52: Train Epoch 8: 271/634 Loss: 0.180036
2023-01-01 15:52: Train Epoch 8: 275/634 Loss: 0.147932
2023-01-01 15:52: Train Epoch 8: 279/634 Loss: 0.140821
2023-01-01 15:53: Train Epoch 8: 283/634 Loss: 0.162492
2023-01-01 15:53: Train Epoch 8: 287/634 Loss: 0.130238
2023-01-01 15:53: Train Epoch 8: 291/634 Loss: 0.145325
2023-01-01 15:53: Train Epoch 8: 295/634 Loss: 0.172376
2023-01-01 15:54: Train Epoch 8: 299/634 Loss: 0.168242
2023-01-01 15:54: Train Epoch 8: 303/634 Loss: 0.169048
2023-01-01 15:54: Train Epoch 8: 307/634 Loss: 0.155067
2023-01-01 15:54: Train Epoch 8: 311/634 Loss: 0.151573
2023-01-01 15:55: Train Epoch 8: 315/634 Loss: 0.157466
2023-01-01 15:55: Train Epoch 8: 319/634 Loss: 0.136922
2023-01-01 15:55: Train Epoch 8: 323/634 Loss: 0.146580
2023-01-01 15:55: Train Epoch 8: 327/634 Loss: 0.129704
2023-01-01 15:56: Train Epoch 8: 331/634 Loss: 0.162572
2023-01-01 15:56: Train Epoch 8: 335/634 Loss: 0.139696
2023-01-01 15:56: Train Epoch 8: 339/634 Loss: 0.139185
2023-01-01 15:56: Train Epoch 8: 343/634 Loss: 0.134866
2023-01-01 15:57: Train Epoch 8: 347/634 Loss: 0.151724
2023-01-01 15:57: Train Epoch 8: 351/634 Loss: 0.154701
2023-01-01 15:57: Train Epoch 8: 355/634 Loss: 0.138151
2023-01-01 15:57: Train Epoch 8: 359/634 Loss: 0.148024
2023-01-01 15:58: Train Epoch 8: 363/634 Loss: 0.145638
2023-01-01 15:58: Train Epoch 8: 367/634 Loss: 0.171759
2023-01-01 15:58: Train Epoch 8: 371/634 Loss: 0.146781
2023-01-01 15:58: Train Epoch 8: 375/634 Loss: 0.165723
2023-01-01 15:59: Train Epoch 8: 379/634 Loss: 0.179560
2023-01-01 15:59: Train Epoch 8: 383/634 Loss: 0.153827
2023-01-01 15:59: Train Epoch 8: 387/634 Loss: 0.144553
2023-01-01 15:59: Train Epoch 8: 391/634 Loss: 0.178363
2023-01-01 16:00: Train Epoch 8: 395/634 Loss: 0.136306
2023-01-01 16:00: Train Epoch 8: 399/634 Loss: 0.177430
2023-01-01 16:00: Train Epoch 8: 403/634 Loss: 0.155284
2023-01-01 16:00: Train Epoch 8: 407/634 Loss: 0.126099
2023-01-01 16:01: Train Epoch 8: 411/634 Loss: 0.170322
2023-01-01 16:01: Train Epoch 8: 415/634 Loss: 0.148302
2023-01-01 16:01: Train Epoch 8: 419/634 Loss: 0.158914
2023-01-01 16:01: Train Epoch 8: 423/634 Loss: 0.143868
2023-01-01 16:02: Train Epoch 8: 427/634 Loss: 0.210255
2023-01-01 16:02: Train Epoch 8: 431/634 Loss: 0.176331
2023-01-01 16:02: Train Epoch 8: 435/634 Loss: 0.130211
2023-01-01 16:02: Train Epoch 8: 439/634 Loss: 0.180743
2023-01-01 16:03: Train Epoch 8: 443/634 Loss: 0.160874
2023-01-01 16:03: Train Epoch 8: 447/634 Loss: 0.154809
2023-01-01 16:03: Train Epoch 8: 451/634 Loss: 0.148745
2023-01-01 16:03: Train Epoch 8: 455/634 Loss: 0.174078
2023-01-01 16:04: Train Epoch 8: 459/634 Loss: 0.166692
2023-01-01 16:04: Train Epoch 8: 463/634 Loss: 0.173203
2023-01-01 16:04: Train Epoch 8: 467/634 Loss: 0.192803
2023-01-01 16:04: Train Epoch 8: 471/634 Loss: 0.159450
2023-01-01 16:05: Train Epoch 8: 475/634 Loss: 0.182440
2023-01-01 16:05: Train Epoch 8: 479/634 Loss: 0.161676
2023-01-01 16:05: Train Epoch 8: 483/634 Loss: 0.144051
2023-01-01 16:05: Train Epoch 8: 487/634 Loss: 0.148307
2023-01-01 16:06: Train Epoch 8: 491/634 Loss: 0.173614
2023-01-01 16:06: Train Epoch 8: 495/634 Loss: 0.169325
2023-01-01 16:06: Train Epoch 8: 499/634 Loss: 0.188624
2023-01-01 16:06: Train Epoch 8: 503/634 Loss: 0.163497
2023-01-01 16:07: Train Epoch 8: 507/634 Loss: 0.153450
2023-01-01 16:07: Train Epoch 8: 511/634 Loss: 0.145725
2023-01-01 16:07: Train Epoch 8: 515/634 Loss: 0.225983
2023-01-01 16:07: Train Epoch 8: 519/634 Loss: 0.179202
2023-01-01 16:08: Train Epoch 8: 523/634 Loss: 0.124254
2023-01-01 16:08: Train Epoch 8: 527/634 Loss: 0.142773
2023-01-01 16:08: Train Epoch 8: 531/634 Loss: 0.167855
2023-01-01 16:08: Train Epoch 8: 535/634 Loss: 0.138806
2023-01-01 16:09: Train Epoch 8: 539/634 Loss: 0.159822
2023-01-01 16:09: Train Epoch 8: 543/634 Loss: 0.147230
2023-01-01 16:09: Train Epoch 8: 547/634 Loss: 0.151252
2023-01-01 16:09: Train Epoch 8: 551/634 Loss: 0.136348
2023-01-01 16:10: Train Epoch 8: 555/634 Loss: 0.126798
2023-01-01 16:10: Train Epoch 8: 559/634 Loss: 0.152439
2023-01-01 16:10: Train Epoch 8: 563/634 Loss: 0.140064
2023-01-01 16:10: Train Epoch 8: 567/634 Loss: 0.135724
2023-01-01 16:11: Train Epoch 8: 571/634 Loss: 0.148331
2023-01-01 16:11: Train Epoch 8: 575/634 Loss: 0.121432
2023-01-01 16:11: Train Epoch 8: 579/634 Loss: 0.140861
2023-01-01 16:11: Train Epoch 8: 583/634 Loss: 0.155071
2023-01-01 16:12: Train Epoch 8: 587/634 Loss: 0.157560
2023-01-01 16:12: Train Epoch 8: 591/634 Loss: 0.125474
2023-01-01 16:12: Train Epoch 8: 595/634 Loss: 0.164943
2023-01-01 16:12: Train Epoch 8: 599/634 Loss: 0.134082
2023-01-01 16:13: Train Epoch 8: 603/634 Loss: 0.145486
2023-01-01 16:13: Train Epoch 8: 607/634 Loss: 0.144999
2023-01-01 16:13: Train Epoch 8: 611/634 Loss: 0.160139
2023-01-01 16:13: Train Epoch 8: 615/634 Loss: 0.128273
2023-01-01 16:14: Train Epoch 8: 619/634 Loss: 0.185289
2023-01-01 16:14: Train Epoch 8: 623/634 Loss: 0.144021
2023-01-01 16:14: Train Epoch 8: 627/634 Loss: 0.163828
2023-01-01 16:14: Train Epoch 8: 631/634 Loss: 0.143567
2023-01-01 16:14: Train Epoch 8: 633/634 Loss: 0.048720
2023-01-01 16:14: **********Train Epoch 8: averaged Loss: 0.152817 
2023-01-01 16:14: 
Epoch time elapsed: 2381.4688391685486

2023-01-01 16:16: 
 metrics validation: {'precision': 0.8770053475935828, 'recall': 0.6307692307692307, 'f1-score': 0.7337807606263981, 'support': 1300, 'AUC': 0.933330177514793, 'AUCPR': 0.8734317255002215, 'TP': 820, 'FP': 115, 'TN': 2485, 'FN': 480} 

2023-01-01 16:16: **********Val Epoch 8: average Loss: 0.169623
2023-01-01 16:17: 
 Testing metrics {'precision': 0.808455565142364, 'recall': 0.7630293159609121, 'f1-score': 0.7850858818600753, 'support': 1228, 'AUC': 0.9259670527008244, 'AUCPR': 0.8803436726643092, 'TP': 937, 'FP': 222, 'TN': 2234, 'FN': 291} 

2023-01-01 16:21: 
 Testing metrics {'precision': 0.8795936013834846, 'recall': 0.9233038348082596, 'f1-score': 0.9009188530942102, 'support': 4407, 'AUC': 0.9789676715916347, 'AUCPR': 0.9615063895698949, 'TP': 4069, 'FP': 557, 'TN': 8257, 'FN': 338} 

2023-01-01 16:21: Train Epoch 9: 3/634 Loss: 0.150776
2023-01-01 16:21: Train Epoch 9: 7/634 Loss: 0.148947
2023-01-01 16:21: Train Epoch 9: 11/634 Loss: 0.153415
2023-01-01 16:22: Train Epoch 9: 15/634 Loss: 0.152428
2023-01-01 16:22: Train Epoch 9: 19/634 Loss: 0.155378
2023-01-01 16:22: Train Epoch 9: 23/634 Loss: 0.140263
2023-01-01 16:22: Train Epoch 9: 27/634 Loss: 0.158305
2023-01-01 16:23: Train Epoch 9: 31/634 Loss: 0.140787
2023-01-01 16:23: Train Epoch 9: 35/634 Loss: 0.168081
2023-01-01 16:23: Train Epoch 9: 39/634 Loss: 0.147075
2023-01-01 16:23: Train Epoch 9: 43/634 Loss: 0.170736
2023-01-01 16:24: Train Epoch 9: 47/634 Loss: 0.180581
2023-01-01 16:24: Train Epoch 9: 51/634 Loss: 0.142198
2023-01-01 16:24: Train Epoch 9: 55/634 Loss: 0.210341
2023-01-01 16:24: Train Epoch 9: 59/634 Loss: 0.173123
2023-01-01 16:25: Train Epoch 9: 63/634 Loss: 0.147969
2023-01-01 16:25: Train Epoch 9: 67/634 Loss: 0.161297
2023-01-01 16:25: Train Epoch 9: 71/634 Loss: 0.196021
2023-01-01 16:25: Train Epoch 9: 75/634 Loss: 0.148781
2023-01-01 16:26: Train Epoch 9: 79/634 Loss: 0.127258
2023-01-01 16:26: Train Epoch 9: 83/634 Loss: 0.163256
2023-01-01 16:26: Train Epoch 9: 87/634 Loss: 0.193533
2023-01-01 16:26: Train Epoch 9: 91/634 Loss: 0.133069
2023-01-01 16:27: Train Epoch 9: 95/634 Loss: 0.159180
2023-01-01 16:27: Train Epoch 9: 99/634 Loss: 0.167158
2023-01-01 16:27: Train Epoch 9: 103/634 Loss: 0.144027
2023-01-01 16:28: Train Epoch 9: 107/634 Loss: 0.154384
2023-01-01 16:28: Train Epoch 9: 111/634 Loss: 0.175919
2023-01-01 16:28: Train Epoch 9: 115/634 Loss: 0.151085
2023-01-01 16:28: Train Epoch 9: 119/634 Loss: 0.151625
2023-01-01 16:29: Train Epoch 9: 123/634 Loss: 0.137792
2023-01-01 16:29: Train Epoch 9: 127/634 Loss: 0.174453
2023-01-01 16:29: Train Epoch 9: 131/634 Loss: 0.163111
2023-01-01 16:29: Train Epoch 9: 135/634 Loss: 0.187537
2023-01-01 16:30: Train Epoch 9: 139/634 Loss: 0.151150
2023-01-01 16:30: Train Epoch 9: 143/634 Loss: 0.158469
2023-01-01 16:30: Train Epoch 9: 147/634 Loss: 0.141176
2023-01-01 16:31: Train Epoch 9: 151/634 Loss: 0.137778
2023-01-01 16:31: Train Epoch 9: 155/634 Loss: 0.150724
2023-01-01 16:31: Train Epoch 9: 159/634 Loss: 0.142463
2023-01-01 16:31: Train Epoch 9: 163/634 Loss: 0.174877
2023-01-01 16:32: Train Epoch 9: 167/634 Loss: 0.146482
2023-01-01 16:32: Train Epoch 9: 171/634 Loss: 0.170223
2023-01-01 16:32: Train Epoch 9: 175/634 Loss: 0.132279
2023-01-01 16:33: Train Epoch 9: 179/634 Loss: 0.156472
2023-01-01 16:33: Train Epoch 9: 183/634 Loss: 0.139858
2023-01-01 16:33: Train Epoch 9: 187/634 Loss: 0.151953
2023-01-01 16:33: Train Epoch 9: 191/634 Loss: 0.152910
2023-01-01 16:34: Train Epoch 9: 195/634 Loss: 0.142483
2023-01-01 16:34: Train Epoch 9: 199/634 Loss: 0.162905
2023-01-01 16:34: Train Epoch 9: 203/634 Loss: 0.140695
2023-01-01 16:34: Train Epoch 9: 207/634 Loss: 0.155816
2023-01-01 16:35: Train Epoch 9: 211/634 Loss: 0.143298
2023-01-01 16:35: Train Epoch 9: 215/634 Loss: 0.161722
2023-01-01 16:35: Train Epoch 9: 219/634 Loss: 0.152773
2023-01-01 16:35: Train Epoch 9: 223/634 Loss: 0.131793
2023-01-01 16:36: Train Epoch 9: 227/634 Loss: 0.147174
2023-01-01 16:36: Train Epoch 9: 231/634 Loss: 0.147871
2023-01-01 16:36: Train Epoch 9: 235/634 Loss: 0.136014
2023-01-01 16:36: Train Epoch 9: 239/634 Loss: 0.157312
2023-01-01 16:37: Train Epoch 9: 243/634 Loss: 0.149276
2023-01-01 16:37: Train Epoch 9: 247/634 Loss: 0.142872
2023-01-01 16:37: Train Epoch 9: 251/634 Loss: 0.133682
2023-01-01 16:37: Train Epoch 9: 255/634 Loss: 0.180960
2023-01-01 16:38: Train Epoch 9: 259/634 Loss: 0.128914
2023-01-01 16:38: Train Epoch 9: 263/634 Loss: 0.137554
2023-01-01 16:38: Train Epoch 9: 267/634 Loss: 0.148228
2023-01-01 16:38: Train Epoch 9: 271/634 Loss: 0.146075
2023-01-01 16:39: Train Epoch 9: 275/634 Loss: 0.146268
2023-01-01 16:39: Train Epoch 9: 279/634 Loss: 0.147645
2023-01-01 16:39: Train Epoch 9: 283/634 Loss: 0.143063
2023-01-01 16:39: Train Epoch 9: 287/634 Loss: 0.156573
2023-01-01 16:40: Train Epoch 9: 291/634 Loss: 0.144926
2023-01-01 16:40: Train Epoch 9: 295/634 Loss: 0.154415
2023-01-01 16:40: Train Epoch 9: 299/634 Loss: 0.148456
2023-01-01 16:40: Train Epoch 9: 303/634 Loss: 0.146919
2023-01-01 16:41: Train Epoch 9: 307/634 Loss: 0.174595
2023-01-01 16:41: Train Epoch 9: 311/634 Loss: 0.134949
2023-01-01 16:41: Train Epoch 9: 315/634 Loss: 0.173542
2023-01-01 16:41: Train Epoch 9: 319/634 Loss: 0.126351
2023-01-01 16:42: Train Epoch 9: 323/634 Loss: 0.158459
2023-01-01 16:42: Train Epoch 9: 327/634 Loss: 0.162047
2023-01-01 16:42: Train Epoch 9: 331/634 Loss: 0.159917
2023-01-01 16:42: Train Epoch 9: 335/634 Loss: 0.140621
2023-01-01 16:43: Train Epoch 9: 339/634 Loss: 0.136404
2023-01-01 16:43: Train Epoch 9: 343/634 Loss: 0.135117
2023-01-01 16:43: Train Epoch 9: 347/634 Loss: 0.128558
2023-01-01 16:43: Train Epoch 9: 351/634 Loss: 0.143449
2023-01-01 16:44: Train Epoch 9: 355/634 Loss: 0.168234
2023-01-01 16:44: Train Epoch 9: 359/634 Loss: 0.141994
2023-01-01 16:44: Train Epoch 9: 363/634 Loss: 0.127293
2023-01-01 16:44: Train Epoch 9: 367/634 Loss: 0.131919
2023-01-01 16:45: Train Epoch 9: 371/634 Loss: 0.168917
2023-01-01 16:45: Train Epoch 9: 375/634 Loss: 0.147144
2023-01-01 16:45: Train Epoch 9: 379/634 Loss: 0.129474
2023-01-01 16:45: Train Epoch 9: 383/634 Loss: 0.157321
2023-01-01 16:46: Train Epoch 9: 387/634 Loss: 0.158851
2023-01-01 16:46: Train Epoch 9: 391/634 Loss: 0.165919
2023-01-01 16:46: Train Epoch 9: 395/634 Loss: 0.140158
2023-01-01 16:46: Train Epoch 9: 399/634 Loss: 0.127226
2023-01-01 16:47: Train Epoch 9: 403/634 Loss: 0.167888
2023-01-01 16:47: Train Epoch 9: 407/634 Loss: 0.160473
2023-01-01 16:47: Train Epoch 9: 411/634 Loss: 0.148653
2023-01-01 16:47: Train Epoch 9: 415/634 Loss: 0.132497
2023-01-01 16:48: Train Epoch 9: 419/634 Loss: 0.147148
2023-01-01 16:48: Train Epoch 9: 423/634 Loss: 0.150085
2023-01-01 16:48: Train Epoch 9: 427/634 Loss: 0.141407
2023-01-01 16:48: Train Epoch 9: 431/634 Loss: 0.125947
2023-01-01 16:49: Train Epoch 9: 435/634 Loss: 0.157905
2023-01-01 16:49: Train Epoch 9: 439/634 Loss: 0.138578
2023-01-01 16:49: Train Epoch 9: 443/634 Loss: 0.137210
2023-01-01 16:49: Train Epoch 9: 447/634 Loss: 0.154523
2023-01-01 16:50: Train Epoch 9: 451/634 Loss: 0.141745
2023-01-01 16:50: Train Epoch 9: 455/634 Loss: 0.141390
2023-01-01 16:50: Train Epoch 9: 459/634 Loss: 0.148947
2023-01-01 16:50: Train Epoch 9: 463/634 Loss: 0.168752
2023-01-01 16:51: Train Epoch 9: 467/634 Loss: 0.149154
2023-01-01 16:51: Train Epoch 9: 471/634 Loss: 0.182930
2023-01-01 16:51: Train Epoch 9: 475/634 Loss: 0.208078
2023-01-01 16:51: Train Epoch 9: 479/634 Loss: 0.141187
2023-01-01 16:52: Train Epoch 9: 483/634 Loss: 0.183297
2023-01-01 16:52: Train Epoch 9: 487/634 Loss: 0.130067
2023-01-01 16:52: Train Epoch 9: 491/634 Loss: 0.152056
2023-01-01 16:52: Train Epoch 9: 495/634 Loss: 0.169146
2023-01-01 16:53: Train Epoch 9: 499/634 Loss: 0.143648
2023-01-01 16:53: Train Epoch 9: 503/634 Loss: 0.129686
2023-01-01 16:53: Train Epoch 9: 507/634 Loss: 0.205821
2023-01-01 16:53: Train Epoch 9: 511/634 Loss: 0.168870
2023-01-01 16:54: Train Epoch 9: 515/634 Loss: 0.165654
2023-01-01 16:54: Train Epoch 9: 519/634 Loss: 0.165216
2023-01-01 16:54: Train Epoch 9: 523/634 Loss: 0.157447
2023-01-01 16:54: Train Epoch 9: 527/634 Loss: 0.166420
2023-01-01 16:55: Train Epoch 9: 531/634 Loss: 0.164744
2023-01-01 16:55: Train Epoch 9: 535/634 Loss: 0.156918
2023-01-01 16:55: Train Epoch 9: 539/634 Loss: 0.161639
2023-01-01 16:55: Train Epoch 9: 543/634 Loss: 0.136991
2023-01-01 16:56: Train Epoch 9: 547/634 Loss: 0.165029
2023-01-01 16:56: Train Epoch 9: 551/634 Loss: 0.156297
2023-01-01 16:56: Train Epoch 9: 555/634 Loss: 0.161484
2023-01-01 16:56: Train Epoch 9: 559/634 Loss: 0.126332
2023-01-01 16:57: Train Epoch 9: 563/634 Loss: 0.132462
2023-01-01 16:57: Train Epoch 9: 567/634 Loss: 0.161037
2023-01-01 16:57: Train Epoch 9: 571/634 Loss: 0.141335
2023-01-01 16:57: Train Epoch 9: 575/634 Loss: 0.150209
2023-01-01 16:58: Train Epoch 9: 579/634 Loss: 0.152472
2023-01-01 16:58: Train Epoch 9: 583/634 Loss: 0.145462
2023-01-01 16:58: Train Epoch 9: 587/634 Loss: 0.141403
2023-01-01 16:58: Train Epoch 9: 591/634 Loss: 0.131802
2023-01-01 16:59: Train Epoch 9: 595/634 Loss: 0.166368
2023-01-01 16:59: Train Epoch 9: 599/634 Loss: 0.122551
2023-01-01 16:59: Train Epoch 9: 603/634 Loss: 0.152627
2023-01-01 16:59: Train Epoch 9: 607/634 Loss: 0.144741
2023-01-01 17:00: Train Epoch 9: 611/634 Loss: 0.153131
2023-01-01 17:00: Train Epoch 9: 615/634 Loss: 0.154943
2023-01-01 17:00: Train Epoch 9: 619/634 Loss: 0.128125
2023-01-01 17:00: Train Epoch 9: 623/634 Loss: 0.161921
2023-01-01 17:01: Train Epoch 9: 627/634 Loss: 0.171498
2023-01-01 17:01: Train Epoch 9: 631/634 Loss: 0.152038
2023-01-01 17:01: Train Epoch 9: 633/634 Loss: 0.080033
2023-01-01 17:01: **********Train Epoch 9: averaged Loss: 0.151989 
2023-01-01 17:01: 
Epoch time elapsed: 2428.190161705017

2023-01-01 17:02: 
 metrics validation: {'precision': 0.7854077253218884, 'recall': 0.8446153846153847, 'f1-score': 0.8139362490733877, 'support': 1300, 'AUC': 0.9388322485207099, 'AUCPR': 0.8821055950383623, 'TP': 1098, 'FP': 300, 'TN': 2300, 'FN': 202} 

2023-01-01 17:02: **********Val Epoch 9: average Loss: 0.143056
2023-01-01 17:02: *********************************Current best model saved!
2023-01-01 17:03: 
 Testing metrics {'precision': 0.8049403747870528, 'recall': 0.7695439739413681, 'f1-score': 0.7868442964196504, 'support': 1228, 'AUC': 0.9254514636760074, 'AUCPR': 0.8831107897948774, 'TP': 945, 'FP': 229, 'TN': 2227, 'FN': 283} 

2023-01-01 17:07: 
 Testing metrics {'precision': 0.8756710328537686, 'recall': 0.9253460403902882, 'f1-score': 0.8998234774933803, 'support': 4407, 'AUC': 0.9798364186274813, 'AUCPR': 0.9653462066051434, 'TP': 4078, 'FP': 579, 'TN': 8235, 'FN': 329} 

2023-01-01 17:07: Train Epoch 10: 3/634 Loss: 0.162217
2023-01-01 17:08: Train Epoch 10: 7/634 Loss: 0.130210
2023-01-01 17:08: Train Epoch 10: 11/634 Loss: 0.164947
2023-01-01 17:08: Train Epoch 10: 15/634 Loss: 0.161669
2023-01-01 17:08: Train Epoch 10: 19/634 Loss: 0.144897
2023-01-01 17:09: Train Epoch 10: 23/634 Loss: 0.160332
2023-01-01 17:09: Train Epoch 10: 27/634 Loss: 0.149080
2023-01-01 17:09: Train Epoch 10: 31/634 Loss: 0.161802
2023-01-01 17:09: Train Epoch 10: 35/634 Loss: 0.172479
2023-01-01 17:10: Train Epoch 10: 39/634 Loss: 0.171956
2023-01-01 17:10: Train Epoch 10: 43/634 Loss: 0.175364
2023-01-01 17:10: Train Epoch 10: 47/634 Loss: 0.125012
2023-01-01 17:10: Train Epoch 10: 51/634 Loss: 0.159655
2023-01-01 17:11: Train Epoch 10: 55/634 Loss: 0.186660
2023-01-01 17:11: Train Epoch 10: 59/634 Loss: 0.143842
2023-01-01 17:11: Train Epoch 10: 63/634 Loss: 0.136187
2023-01-01 17:11: Train Epoch 10: 67/634 Loss: 0.158656
2023-01-01 17:12: Train Epoch 10: 71/634 Loss: 0.119740
2023-01-01 17:12: Train Epoch 10: 75/634 Loss: 0.133169
2023-01-01 17:12: Train Epoch 10: 79/634 Loss: 0.137622
2023-01-01 17:12: Train Epoch 10: 83/634 Loss: 0.152649
2023-01-01 17:13: Train Epoch 10: 87/634 Loss: 0.143841
2023-01-01 17:13: Train Epoch 10: 91/634 Loss: 0.155693
2023-01-01 17:13: Train Epoch 10: 95/634 Loss: 0.129020
2023-01-01 17:13: Train Epoch 10: 99/634 Loss: 0.160806
2023-01-01 17:14: Train Epoch 10: 103/634 Loss: 0.178513
2023-01-01 17:14: Train Epoch 10: 107/634 Loss: 0.167659
2023-01-01 17:14: Train Epoch 10: 111/634 Loss: 0.140934
2023-01-01 17:14: Train Epoch 10: 115/634 Loss: 0.148756
2023-01-01 17:15: Train Epoch 10: 119/634 Loss: 0.155267
2023-01-01 17:15: Train Epoch 10: 123/634 Loss: 0.137307
2023-01-01 17:15: Train Epoch 10: 127/634 Loss: 0.167498
2023-01-01 17:15: Train Epoch 10: 131/634 Loss: 0.136454
2023-01-01 17:15: Train Epoch 10: 135/634 Loss: 0.156339
2023-01-01 17:16: Train Epoch 10: 139/634 Loss: 0.124244
2023-01-01 17:16: Train Epoch 10: 143/634 Loss: 0.163226
2023-01-01 17:16: Train Epoch 10: 147/634 Loss: 0.149789
2023-01-01 17:16: Train Epoch 10: 151/634 Loss: 0.154904
2023-01-01 17:17: Train Epoch 10: 155/634 Loss: 0.134365
2023-01-01 17:17: Train Epoch 10: 159/634 Loss: 0.167902
2023-01-01 17:17: Train Epoch 10: 163/634 Loss: 0.144885
2023-01-01 17:17: Train Epoch 10: 167/634 Loss: 0.137879
2023-01-01 17:18: Train Epoch 10: 171/634 Loss: 0.169646
2023-01-01 17:18: Train Epoch 10: 175/634 Loss: 0.143886
2023-01-01 17:18: Train Epoch 10: 179/634 Loss: 0.167319
2023-01-01 17:18: Train Epoch 10: 183/634 Loss: 0.159338
2023-01-01 17:19: Train Epoch 10: 187/634 Loss: 0.147174
2023-01-01 17:19: Train Epoch 10: 191/634 Loss: 0.151013
2023-01-01 17:19: Train Epoch 10: 195/634 Loss: 0.148734
2023-01-01 17:19: Train Epoch 10: 199/634 Loss: 0.156526
2023-01-01 17:20: Train Epoch 10: 203/634 Loss: 0.155036
2023-01-01 17:20: Train Epoch 10: 207/634 Loss: 0.153145
2023-01-01 17:20: Train Epoch 10: 211/634 Loss: 0.125377
2023-01-01 17:20: Train Epoch 10: 215/634 Loss: 0.147534
2023-01-01 17:21: Train Epoch 10: 219/634 Loss: 0.145040
2023-01-01 17:21: Train Epoch 10: 223/634 Loss: 0.165627
2023-01-01 17:21: Train Epoch 10: 227/634 Loss: 0.140183
2023-01-01 17:21: Train Epoch 10: 231/634 Loss: 0.151310
2023-01-01 17:22: Train Epoch 10: 235/634 Loss: 0.137153
2023-01-01 17:22: Train Epoch 10: 239/634 Loss: 0.136479
2023-01-01 17:22: Train Epoch 10: 243/634 Loss: 0.150248
2023-01-01 17:22: Train Epoch 10: 247/634 Loss: 0.129676
2023-01-01 17:23: Train Epoch 10: 251/634 Loss: 0.135463
2023-01-01 17:23: Train Epoch 10: 255/634 Loss: 0.123415
2023-01-01 17:23: Train Epoch 10: 259/634 Loss: 0.172763
2023-01-01 17:23: Train Epoch 10: 263/634 Loss: 0.150150
2023-01-01 17:24: Train Epoch 10: 267/634 Loss: 0.163952
2023-01-01 17:24: Train Epoch 10: 271/634 Loss: 0.142412
2023-01-01 17:24: Train Epoch 10: 275/634 Loss: 0.150987
2023-01-01 17:24: Train Epoch 10: 279/634 Loss: 0.129623
2023-01-01 17:25: Train Epoch 10: 283/634 Loss: 0.143964
2023-01-01 17:25: Train Epoch 10: 287/634 Loss: 0.131456
2023-01-01 17:25: Train Epoch 10: 291/634 Loss: 0.143989
2023-01-01 17:25: Train Epoch 10: 295/634 Loss: 0.177033
2023-01-01 17:26: Train Epoch 10: 299/634 Loss: 0.158955
2023-01-01 17:26: Train Epoch 10: 303/634 Loss: 0.162707
2023-01-01 17:26: Train Epoch 10: 307/634 Loss: 0.164660
2023-01-01 17:26: Train Epoch 10: 311/634 Loss: 0.175185
2023-01-01 17:27: Train Epoch 10: 315/634 Loss: 0.167354
2023-01-01 17:27: Train Epoch 10: 319/634 Loss: 0.150410
2023-01-01 17:27: Train Epoch 10: 323/634 Loss: 0.161602
2023-01-01 17:27: Train Epoch 10: 327/634 Loss: 0.153352
2023-01-01 17:28: Train Epoch 10: 331/634 Loss: 0.142036
2023-01-01 17:28: Train Epoch 10: 335/634 Loss: 0.192863
2023-01-01 17:28: Train Epoch 10: 339/634 Loss: 0.153374
2023-01-01 17:28: Train Epoch 10: 343/634 Loss: 0.166909
2023-01-01 17:29: Train Epoch 10: 347/634 Loss: 0.149134
2023-01-01 17:29: Train Epoch 10: 351/634 Loss: 0.154222
2023-01-01 17:29: Train Epoch 10: 355/634 Loss: 0.166691
2023-01-01 17:29: Train Epoch 10: 359/634 Loss: 0.170095
2023-01-01 17:30: Train Epoch 10: 363/634 Loss: 0.189146
2023-01-01 17:30: Train Epoch 10: 367/634 Loss: 0.208292
2023-01-01 17:30: Train Epoch 10: 371/634 Loss: 0.177124
2023-01-01 17:30: Train Epoch 10: 375/634 Loss: 0.207553
2023-01-01 17:31: Train Epoch 10: 379/634 Loss: 0.172301
2023-01-01 17:31: Train Epoch 10: 383/634 Loss: 0.154645
2023-01-01 17:31: Train Epoch 10: 387/634 Loss: 0.118738
2023-01-01 17:31: Train Epoch 10: 391/634 Loss: 0.156998
2023-01-01 17:32: Train Epoch 10: 395/634 Loss: 0.179510
2023-01-01 17:32: Train Epoch 10: 399/634 Loss: 0.157265
2023-01-01 17:32: Train Epoch 10: 403/634 Loss: 0.248102
2023-01-01 17:32: Train Epoch 10: 407/634 Loss: 0.143909
2023-01-01 17:33: Train Epoch 10: 411/634 Loss: 0.181418
2023-01-01 17:33: Train Epoch 10: 415/634 Loss: 0.161721
2023-01-01 17:33: Train Epoch 10: 419/634 Loss: 0.129731
2023-01-01 17:33: Train Epoch 10: 423/634 Loss: 0.155939
2023-01-01 17:33: Train Epoch 10: 427/634 Loss: 0.174618
2023-01-01 17:34: Train Epoch 10: 431/634 Loss: 0.153877
2023-01-01 17:34: Train Epoch 10: 435/634 Loss: 0.190695
2023-01-01 17:34: Train Epoch 10: 439/634 Loss: 0.162117
2023-01-01 17:34: Train Epoch 10: 443/634 Loss: 0.153884
2023-01-01 17:35: Train Epoch 10: 447/634 Loss: 0.141039
2023-01-01 17:35: Train Epoch 10: 451/634 Loss: 0.201638
2023-01-01 17:35: Train Epoch 10: 455/634 Loss: 0.198133
2023-01-01 17:35: Train Epoch 10: 459/634 Loss: 0.135548
2023-01-01 17:36: Train Epoch 10: 463/634 Loss: 0.157267
2023-01-01 17:36: Train Epoch 10: 467/634 Loss: 0.176576
2023-01-01 17:36: Train Epoch 10: 471/634 Loss: 0.168231
2023-01-01 17:36: Train Epoch 10: 475/634 Loss: 0.174927
2023-01-01 17:37: Train Epoch 10: 479/634 Loss: 0.153605
2023-01-01 17:37: Train Epoch 10: 483/634 Loss: 0.149254
2023-01-01 17:37: Train Epoch 10: 487/634 Loss: 0.126456
2023-01-01 17:37: Train Epoch 10: 491/634 Loss: 0.162747
2023-01-01 17:38: Train Epoch 10: 495/634 Loss: 0.166220
2023-01-01 17:38: Train Epoch 10: 499/634 Loss: 0.116771
2023-01-01 17:38: Train Epoch 10: 503/634 Loss: 0.116943
2023-01-01 17:38: Train Epoch 10: 507/634 Loss: 0.154073
2023-01-01 17:39: Train Epoch 10: 511/634 Loss: 0.178931
2023-01-01 17:39: Train Epoch 10: 515/634 Loss: 0.132968
2023-01-01 17:39: Train Epoch 10: 519/634 Loss: 0.151824
2023-01-01 17:39: Train Epoch 10: 523/634 Loss: 0.143282
2023-01-01 17:40: Train Epoch 10: 527/634 Loss: 0.130526
2023-01-01 17:40: Train Epoch 10: 531/634 Loss: 0.131278
2023-01-01 17:40: Train Epoch 10: 535/634 Loss: 0.158860
2023-01-01 17:41: Train Epoch 10: 539/634 Loss: 0.157791
2023-01-01 17:41: Train Epoch 10: 543/634 Loss: 0.125201
2023-01-01 17:41: Train Epoch 10: 547/634 Loss: 0.153476
2023-01-01 17:41: Train Epoch 10: 551/634 Loss: 0.145099
2023-01-01 17:42: Train Epoch 10: 555/634 Loss: 0.122172
2023-01-01 17:42: Train Epoch 10: 559/634 Loss: 0.151408
2023-01-01 17:42: Train Epoch 10: 563/634 Loss: 0.153160
2023-01-01 17:42: Train Epoch 10: 567/634 Loss: 0.149129
2023-01-01 17:43: Train Epoch 10: 571/634 Loss: 0.137909
2023-01-01 17:43: Train Epoch 10: 575/634 Loss: 0.165495
2023-01-01 17:43: Train Epoch 10: 579/634 Loss: 0.147642
2023-01-01 17:43: Train Epoch 10: 583/634 Loss: 0.159389
2023-01-01 17:43: Train Epoch 10: 587/634 Loss: 0.164019
2023-01-01 17:44: Train Epoch 10: 591/634 Loss: 0.175620
2023-01-01 17:44: Train Epoch 10: 595/634 Loss: 0.158302
2023-01-01 17:44: Train Epoch 10: 599/634 Loss: 0.136935
2023-01-01 17:44: Train Epoch 10: 603/634 Loss: 0.141247
2023-01-01 17:45: Train Epoch 10: 607/634 Loss: 0.126845
2023-01-01 17:45: Train Epoch 10: 611/634 Loss: 0.124536
2023-01-01 17:45: Train Epoch 10: 615/634 Loss: 0.151058
2023-01-01 17:45: Train Epoch 10: 619/634 Loss: 0.146298
2023-01-01 17:46: Train Epoch 10: 623/634 Loss: 0.146514
2023-01-01 17:46: Train Epoch 10: 627/634 Loss: 0.135495
2023-01-01 17:46: Train Epoch 10: 631/634 Loss: 0.137092
2023-01-01 17:46: Train Epoch 10: 633/634 Loss: 0.053010
2023-01-01 17:46: **********Train Epoch 10: averaged Loss: 0.153259 
2023-01-01 17:46: 
Epoch time elapsed: 2353.129013299942

2023-01-01 17:47: 
 metrics validation: {'precision': 0.8596171376481313, 'recall': 0.7253846153846154, 'f1-score': 0.786816854401335, 'support': 1300, 'AUC': 0.9365014792899409, 'AUCPR': 0.8800731806827828, 'TP': 943, 'FP': 154, 'TN': 2446, 'FN': 357} 

2023-01-01 17:47: **********Val Epoch 10: average Loss: 0.154501
2023-01-01 17:48: 
 Testing metrics {'precision': 0.8049403747870528, 'recall': 0.7695439739413681, 'f1-score': 0.7868442964196504, 'support': 1228, 'AUC': 0.9254514636760074, 'AUCPR': 0.8831107897948774, 'TP': 945, 'FP': 229, 'TN': 2227, 'FN': 283} 

2023-01-01 17:52: 
 Testing metrics {'precision': 0.8756710328537686, 'recall': 0.9253460403902882, 'f1-score': 0.8998234774933803, 'support': 4407, 'AUC': 0.9798364186274813, 'AUCPR': 0.9653462066051434, 'TP': 4078, 'FP': 579, 'TN': 8235, 'FN': 329} 

2023-01-01 17:53: Train Epoch 11: 3/634 Loss: 0.137961
2023-01-01 17:53: Train Epoch 11: 7/634 Loss: 0.136418
2023-01-01 17:53: Train Epoch 11: 11/634 Loss: 0.147312
2023-01-01 17:53: Train Epoch 11: 15/634 Loss: 0.157959
2023-01-01 17:54: Train Epoch 11: 19/634 Loss: 0.158934
2023-01-01 17:54: Train Epoch 11: 23/634 Loss: 0.158553
2023-01-01 17:54: Train Epoch 11: 27/634 Loss: 0.130373
2023-01-01 17:54: Train Epoch 11: 31/634 Loss: 0.154471
2023-01-01 17:55: Train Epoch 11: 35/634 Loss: 0.137957
2023-01-01 17:55: Train Epoch 11: 39/634 Loss: 0.148483
2023-01-01 17:55: Train Epoch 11: 43/634 Loss: 0.180077
2023-01-01 17:55: Train Epoch 11: 47/634 Loss: 0.141951
2023-01-01 17:56: Train Epoch 11: 51/634 Loss: 0.147871
2023-01-01 17:56: Train Epoch 11: 55/634 Loss: 0.156781
2023-01-01 17:56: Train Epoch 11: 59/634 Loss: 0.146258
2023-01-01 17:56: Train Epoch 11: 63/634 Loss: 0.158444
2023-01-01 17:57: Train Epoch 11: 67/634 Loss: 0.140319
2023-01-01 17:57: Train Epoch 11: 71/634 Loss: 0.130017
2023-01-01 17:57: Train Epoch 11: 75/634 Loss: 0.151614
2023-01-01 17:57: Train Epoch 11: 79/634 Loss: 0.160900
2023-01-01 17:58: Train Epoch 11: 83/634 Loss: 0.145065
2023-01-01 17:58: Train Epoch 11: 87/634 Loss: 0.128650
2023-01-01 17:58: Train Epoch 11: 91/634 Loss: 0.151597
2023-01-01 17:58: Train Epoch 11: 95/634 Loss: 0.163687
2023-01-01 17:59: Train Epoch 11: 99/634 Loss: 0.137690
2023-01-01 17:59: Train Epoch 11: 103/634 Loss: 0.143357
2023-01-01 17:59: Train Epoch 11: 107/634 Loss: 0.141976
2023-01-01 17:59: Train Epoch 11: 111/634 Loss: 0.148839
2023-01-01 18:00: Train Epoch 11: 115/634 Loss: 0.144636
2023-01-01 18:00: Train Epoch 11: 119/634 Loss: 0.159727
2023-01-01 18:00: Train Epoch 11: 123/634 Loss: 0.126678
2023-01-01 18:00: Train Epoch 11: 127/634 Loss: 0.148615
2023-01-01 18:01: Train Epoch 11: 131/634 Loss: 0.141694
2023-01-01 18:01: Train Epoch 11: 135/634 Loss: 0.142348
2023-01-01 18:01: Train Epoch 11: 139/634 Loss: 0.149340
2023-01-01 18:01: Train Epoch 11: 143/634 Loss: 0.153043
2023-01-01 18:02: Train Epoch 11: 147/634 Loss: 0.138738
2023-01-01 18:02: Train Epoch 11: 151/634 Loss: 0.151352
2023-01-01 18:02: Train Epoch 11: 155/634 Loss: 0.149984
2023-01-01 18:02: Train Epoch 11: 159/634 Loss: 0.155728
2023-01-01 18:03: Train Epoch 11: 163/634 Loss: 0.178636
2023-01-01 18:03: Train Epoch 11: 167/634 Loss: 0.137699
2023-01-01 18:03: Train Epoch 11: 171/634 Loss: 0.143595
2023-01-01 18:03: Train Epoch 11: 175/634 Loss: 0.145121
2023-01-01 18:04: Train Epoch 11: 179/634 Loss: 0.150109
2023-01-01 18:04: Train Epoch 11: 183/634 Loss: 0.156108
2023-01-01 18:04: Train Epoch 11: 187/634 Loss: 0.145696
2023-01-01 18:04: Train Epoch 11: 191/634 Loss: 0.135561
2023-01-01 18:05: Train Epoch 11: 195/634 Loss: 0.153308
2023-01-01 18:05: Train Epoch 11: 199/634 Loss: 0.144235
2023-01-01 18:05: Train Epoch 11: 203/634 Loss: 0.163918
2023-01-01 18:05: Train Epoch 11: 207/634 Loss: 0.147113
2023-01-01 18:06: Train Epoch 11: 211/634 Loss: 0.166787
2023-01-01 18:06: Train Epoch 11: 215/634 Loss: 0.157202
2023-01-01 18:06: Train Epoch 11: 219/634 Loss: 0.170598
2023-01-01 18:06: Train Epoch 11: 223/634 Loss: 0.142304
2023-01-01 18:07: Train Epoch 11: 227/634 Loss: 0.154417
2023-01-01 18:07: Train Epoch 11: 231/634 Loss: 0.138449
2023-01-01 18:07: Train Epoch 11: 235/634 Loss: 0.140804
2023-01-01 18:08: Train Epoch 11: 239/634 Loss: 0.137304
2023-01-01 18:08: Train Epoch 11: 243/634 Loss: 0.150464
2023-01-01 18:08: Train Epoch 11: 247/634 Loss: 0.150548
2023-01-01 18:08: Train Epoch 11: 251/634 Loss: 0.133630
2023-01-01 18:09: Train Epoch 11: 255/634 Loss: 0.157976
2023-01-01 18:09: Train Epoch 11: 259/634 Loss: 0.122523
2023-01-01 18:09: Train Epoch 11: 263/634 Loss: 0.140087
2023-01-01 18:09: Train Epoch 11: 267/634 Loss: 0.161459
2023-01-01 18:10: Train Epoch 11: 271/634 Loss: 0.136680
2023-01-01 18:10: Train Epoch 11: 275/634 Loss: 0.138486
2023-01-01 18:10: Train Epoch 11: 279/634 Loss: 0.157755
2023-01-01 18:11: Train Epoch 11: 283/634 Loss: 0.139752
2023-01-01 18:11: Train Epoch 11: 287/634 Loss: 0.134415
2023-01-01 18:11: Train Epoch 11: 291/634 Loss: 0.128882
2023-01-01 18:11: Train Epoch 11: 295/634 Loss: 0.145136
2023-01-01 18:12: Train Epoch 11: 299/634 Loss: 0.135900
2023-01-01 18:12: Train Epoch 11: 303/634 Loss: 0.159561
2023-01-01 18:12: Train Epoch 11: 307/634 Loss: 0.147166
2023-01-01 18:12: Train Epoch 11: 311/634 Loss: 0.139083
2023-01-01 18:13: Train Epoch 11: 315/634 Loss: 0.142958
2023-01-01 18:13: Train Epoch 11: 319/634 Loss: 0.131963
2023-01-01 18:13: Train Epoch 11: 323/634 Loss: 0.153921
2023-01-01 18:14: Train Epoch 11: 327/634 Loss: 0.141730
2023-01-01 18:14: Train Epoch 11: 331/634 Loss: 0.137400
2023-01-01 18:14: Train Epoch 11: 335/634 Loss: 0.141311
2023-01-01 18:14: Train Epoch 11: 339/634 Loss: 0.149493
2023-01-01 18:15: Train Epoch 11: 343/634 Loss: 0.183615
2023-01-01 18:15: Train Epoch 11: 347/634 Loss: 0.125916
2023-01-01 18:15: Train Epoch 11: 351/634 Loss: 0.170093
2023-01-01 18:15: Train Epoch 11: 355/634 Loss: 0.193573
2023-01-01 18:16: Train Epoch 11: 359/634 Loss: 0.145774
2023-01-01 18:16: Train Epoch 11: 363/634 Loss: 0.155552
2023-01-01 18:16: Train Epoch 11: 367/634 Loss: 0.177551
2023-01-01 18:16: Train Epoch 11: 371/634 Loss: 0.158151
2023-01-01 18:17: Train Epoch 11: 375/634 Loss: 0.123148
2023-01-01 18:17: Train Epoch 11: 379/634 Loss: 0.181389
2023-01-01 18:17: Train Epoch 11: 383/634 Loss: 0.153559
2023-01-01 18:17: Train Epoch 11: 387/634 Loss: 0.167963
2023-01-01 18:18: Train Epoch 11: 391/634 Loss: 0.143778
2023-01-01 18:18: Train Epoch 11: 395/634 Loss: 0.146532
2023-01-01 18:18: Train Epoch 11: 399/634 Loss: 0.139584
2023-01-01 18:18: Train Epoch 11: 403/634 Loss: 0.165161
2023-01-01 18:19: Train Epoch 11: 407/634 Loss: 0.130131
2023-01-01 18:19: Train Epoch 11: 411/634 Loss: 0.158776
2023-01-01 18:19: Train Epoch 11: 415/634 Loss: 0.141672
2023-01-01 18:19: Train Epoch 11: 419/634 Loss: 0.127694
2023-01-01 18:20: Train Epoch 11: 423/634 Loss: 0.164519
2023-01-01 18:20: Train Epoch 11: 427/634 Loss: 0.178386
2023-01-01 18:20: Train Epoch 11: 431/634 Loss: 0.138439
2023-01-01 18:20: Train Epoch 11: 435/634 Loss: 0.141638
2023-01-01 18:21: Train Epoch 11: 439/634 Loss: 0.140289
2023-01-01 18:21: Train Epoch 11: 443/634 Loss: 0.151610
2023-01-01 18:21: Train Epoch 11: 447/634 Loss: 0.148582
2023-01-01 18:21: Train Epoch 11: 451/634 Loss: 0.170839
2023-01-01 18:22: Train Epoch 11: 455/634 Loss: 0.150752
2023-01-01 18:22: Train Epoch 11: 459/634 Loss: 0.170552
2023-01-01 18:22: Train Epoch 11: 463/634 Loss: 0.157605
2023-01-01 18:22: Train Epoch 11: 467/634 Loss: 0.173003
2023-01-01 18:23: Train Epoch 11: 471/634 Loss: 0.143321
2023-01-01 18:23: Train Epoch 11: 475/634 Loss: 0.142802
2023-01-01 18:23: Train Epoch 11: 479/634 Loss: 0.145959
2023-01-01 18:23: Train Epoch 11: 483/634 Loss: 0.132618
2023-01-01 18:24: Train Epoch 11: 487/634 Loss: 0.131873
2023-01-01 18:24: Train Epoch 11: 491/634 Loss: 0.128462
2023-01-01 18:24: Train Epoch 11: 495/634 Loss: 0.157651
2023-01-01 18:24: Train Epoch 11: 499/634 Loss: 0.130314
2023-01-01 18:25: Train Epoch 11: 503/634 Loss: 0.116715
2023-01-01 18:25: Train Epoch 11: 507/634 Loss: 0.140214
2023-01-01 18:25: Train Epoch 11: 511/634 Loss: 0.145987
2023-01-01 18:25: Train Epoch 11: 515/634 Loss: 0.151998
2023-01-01 18:26: Train Epoch 11: 519/634 Loss: 0.147565
2023-01-01 18:26: Train Epoch 11: 523/634 Loss: 0.143560
2023-01-01 18:26: Train Epoch 11: 527/634 Loss: 0.161447
2023-01-01 18:26: Train Epoch 11: 531/634 Loss: 0.151865
2023-01-01 18:27: Train Epoch 11: 535/634 Loss: 0.143349
2023-01-01 18:27: Train Epoch 11: 539/634 Loss: 0.137809
2023-01-01 18:27: Train Epoch 11: 543/634 Loss: 0.143426
2023-01-01 18:27: Train Epoch 11: 547/634 Loss: 0.129438
2023-01-01 18:28: Train Epoch 11: 551/634 Loss: 0.141200
2023-01-01 18:28: Train Epoch 11: 555/634 Loss: 0.157830
2023-01-01 18:28: Train Epoch 11: 559/634 Loss: 0.148823
2023-01-01 18:28: Train Epoch 11: 563/634 Loss: 0.161414
2023-01-01 18:29: Train Epoch 11: 567/634 Loss: 0.143842
2023-01-01 18:29: Train Epoch 11: 571/634 Loss: 0.165350
2023-01-01 18:29: Train Epoch 11: 575/634 Loss: 0.147252
2023-01-01 18:29: Train Epoch 11: 579/634 Loss: 0.128859
2023-01-01 18:30: Train Epoch 11: 583/634 Loss: 0.146502
2023-01-01 18:30: Train Epoch 11: 587/634 Loss: 0.146253
2023-01-01 18:30: Train Epoch 11: 591/634 Loss: 0.139716
2023-01-01 18:30: Train Epoch 11: 595/634 Loss: 0.157467
2023-01-01 18:31: Train Epoch 11: 599/634 Loss: 0.135849
2023-01-01 18:31: Train Epoch 11: 603/634 Loss: 0.152756
2023-01-01 18:31: Train Epoch 11: 607/634 Loss: 0.142919
2023-01-01 18:31: Train Epoch 11: 611/634 Loss: 0.137421
2023-01-01 18:32: Train Epoch 11: 615/634 Loss: 0.140841
2023-01-01 18:32: Train Epoch 11: 619/634 Loss: 0.140790
2023-01-01 18:32: Train Epoch 11: 623/634 Loss: 0.142003
2023-01-01 18:32: Train Epoch 11: 627/634 Loss: 0.150634
2023-01-01 18:33: Train Epoch 11: 631/634 Loss: 0.152721
2023-01-01 18:33: Train Epoch 11: 633/634 Loss: 0.045869
2023-01-01 18:33: **********Train Epoch 11: averaged Loss: 0.147303 
2023-01-01 18:33: 
Epoch time elapsed: 2415.43794965744

2023-01-01 18:34: 
 metrics validation: {'precision': 0.8416013925152306, 'recall': 0.7438461538461538, 'f1-score': 0.7897100857492854, 'support': 1300, 'AUC': 0.9337893491124261, 'AUCPR': 0.8718708714549175, 'TP': 967, 'FP': 182, 'TN': 2418, 'FN': 333} 

2023-01-01 18:34: **********Val Epoch 11: average Loss: 0.158702
2023-01-01 18:35: 
 Testing metrics {'precision': 0.8049403747870528, 'recall': 0.7695439739413681, 'f1-score': 0.7868442964196504, 'support': 1228, 'AUC': 0.9254514636760074, 'AUCPR': 0.8831107897948774, 'TP': 945, 'FP': 229, 'TN': 2227, 'FN': 283} 

2023-01-01 18:39: 
 Testing metrics {'precision': 0.8756710328537686, 'recall': 0.9253460403902882, 'f1-score': 0.8998234774933803, 'support': 4407, 'AUC': 0.9798364186274813, 'AUCPR': 0.9653462066051434, 'TP': 4078, 'FP': 579, 'TN': 8235, 'FN': 329} 

2023-01-01 18:39: Train Epoch 12: 3/634 Loss: 0.173867
2023-01-01 18:39: Train Epoch 12: 7/634 Loss: 0.135745
2023-01-01 18:39: Train Epoch 12: 11/634 Loss: 0.181740
2023-01-01 18:40: Train Epoch 12: 15/634 Loss: 0.156024
2023-01-01 18:40: Train Epoch 12: 19/634 Loss: 0.156130
2023-01-01 18:40: Train Epoch 12: 23/634 Loss: 0.177772
2023-01-01 18:40: Train Epoch 12: 27/634 Loss: 0.177754
2023-01-01 18:41: Train Epoch 12: 31/634 Loss: 0.153847
2023-01-01 18:41: Train Epoch 12: 35/634 Loss: 0.160891
2023-01-01 18:41: Train Epoch 12: 39/634 Loss: 0.193142
2023-01-01 18:41: Train Epoch 12: 43/634 Loss: 0.146482
2023-01-01 18:42: Train Epoch 12: 47/634 Loss: 0.181297
2023-01-01 18:42: Train Epoch 12: 51/634 Loss: 0.173493
2023-01-01 18:42: Train Epoch 12: 55/634 Loss: 0.126006
2023-01-01 18:42: Train Epoch 12: 59/634 Loss: 0.150280
2023-01-01 18:43: Train Epoch 12: 63/634 Loss: 0.157606
2023-01-01 18:43: Train Epoch 12: 67/634 Loss: 0.143806
2023-01-01 18:43: Train Epoch 12: 71/634 Loss: 0.148713
2023-01-01 18:43: Train Epoch 12: 75/634 Loss: 0.164035
2023-01-01 18:44: Train Epoch 12: 79/634 Loss: 0.154340
2023-01-01 18:44: Train Epoch 12: 83/634 Loss: 0.145282
2023-01-01 18:44: Train Epoch 12: 87/634 Loss: 0.180597
2023-01-01 18:44: Train Epoch 12: 91/634 Loss: 0.149653
2023-01-01 18:45: Train Epoch 12: 95/634 Loss: 0.188359
2023-01-01 18:45: Train Epoch 12: 99/634 Loss: 0.164392
2023-01-01 18:45: Train Epoch 12: 103/634 Loss: 0.132746
2023-01-01 18:45: Train Epoch 12: 107/634 Loss: 0.135091
2023-01-01 18:46: Train Epoch 12: 111/634 Loss: 0.141563
2023-01-01 18:46: Train Epoch 12: 115/634 Loss: 0.135246
2023-01-01 18:46: Train Epoch 12: 119/634 Loss: 0.161254
2023-01-01 18:46: Train Epoch 12: 123/634 Loss: 0.127860
2023-01-01 18:47: Train Epoch 12: 127/634 Loss: 0.173469
2023-01-01 18:47: Train Epoch 12: 131/634 Loss: 0.151625
2023-01-01 18:47: Train Epoch 12: 135/634 Loss: 0.151128
2023-01-01 18:47: Train Epoch 12: 139/634 Loss: 0.152184
2023-01-01 18:48: Train Epoch 12: 143/634 Loss: 0.136299
2023-01-01 18:48: Train Epoch 12: 147/634 Loss: 0.145877
2023-01-01 18:48: Train Epoch 12: 151/634 Loss: 0.155566
2023-01-01 18:48: Train Epoch 12: 155/634 Loss: 0.126869
2023-01-01 18:49: Train Epoch 12: 159/634 Loss: 0.139279
2023-01-01 18:49: Train Epoch 12: 163/634 Loss: 0.152186
2023-01-01 18:49: Train Epoch 12: 167/634 Loss: 0.147378
2023-01-01 18:49: Train Epoch 12: 171/634 Loss: 0.141113
2023-01-01 18:50: Train Epoch 12: 175/634 Loss: 0.128696
2023-01-01 18:50: Train Epoch 12: 179/634 Loss: 0.177254
2023-01-01 18:50: Train Epoch 12: 183/634 Loss: 0.141777
2023-01-01 18:50: Train Epoch 12: 187/634 Loss: 0.138086
2023-01-01 18:51: Train Epoch 12: 191/634 Loss: 0.156156
2023-01-01 18:51: Train Epoch 12: 195/634 Loss: 0.149212
2023-01-01 18:51: Train Epoch 12: 199/634 Loss: 0.131817
2023-01-01 18:51: Train Epoch 12: 203/634 Loss: 0.147422
2023-01-01 18:52: Train Epoch 12: 207/634 Loss: 0.153460
2023-01-01 18:52: Train Epoch 12: 211/634 Loss: 0.141545
2023-01-01 18:52: Train Epoch 12: 215/634 Loss: 0.126215
2023-01-01 18:52: Train Epoch 12: 219/634 Loss: 0.150471
2023-01-01 18:53: Train Epoch 12: 223/634 Loss: 0.133091
2023-01-01 18:53: Train Epoch 12: 227/634 Loss: 0.142271
2023-01-01 18:53: Train Epoch 12: 231/634 Loss: 0.164269
2023-01-01 18:53: Train Epoch 12: 235/634 Loss: 0.157829
2023-01-01 18:54: Train Epoch 12: 239/634 Loss: 0.161610
2023-01-01 18:54: Train Epoch 12: 243/634 Loss: 0.149141
2023-01-01 18:54: Train Epoch 12: 247/634 Loss: 0.141221
2023-01-01 18:54: Train Epoch 12: 251/634 Loss: 0.151449
2023-01-01 18:55: Train Epoch 12: 255/634 Loss: 0.133299
2023-01-01 18:55: Train Epoch 12: 259/634 Loss: 0.138859
2023-01-01 18:55: Train Epoch 12: 263/634 Loss: 0.134830
2023-01-01 18:55: Train Epoch 12: 267/634 Loss: 0.172360
2023-01-01 18:56: Train Epoch 12: 271/634 Loss: 0.160190
2023-01-01 18:56: Train Epoch 12: 275/634 Loss: 0.134801
2023-01-01 18:56: Train Epoch 12: 279/634 Loss: 0.123080
2023-01-01 18:56: Train Epoch 12: 283/634 Loss: 0.165147
2023-01-01 18:56: Train Epoch 12: 287/634 Loss: 0.140672
2023-01-01 18:57: Train Epoch 12: 291/634 Loss: 0.118933
2023-01-01 18:57: Train Epoch 12: 295/634 Loss: 0.173907
2023-01-01 18:57: Train Epoch 12: 299/634 Loss: 0.148116
2023-01-01 18:57: Train Epoch 12: 303/634 Loss: 0.164249
2023-01-01 18:58: Train Epoch 12: 307/634 Loss: 0.149819
2023-01-01 18:58: Train Epoch 12: 311/634 Loss: 0.143310
2023-01-01 18:58: Train Epoch 12: 315/634 Loss: 0.164092
2023-01-01 18:58: Train Epoch 12: 319/634 Loss: 0.127534
2023-01-01 18:59: Train Epoch 12: 323/634 Loss: 0.138750
2023-01-01 18:59: Train Epoch 12: 327/634 Loss: 0.140336
2023-01-01 18:59: Train Epoch 12: 331/634 Loss: 0.161920
2023-01-01 18:59: Train Epoch 12: 335/634 Loss: 0.164800
2023-01-01 19:00: Train Epoch 12: 339/634 Loss: 0.125596
2023-01-01 19:00: Train Epoch 12: 343/634 Loss: 0.185220
2023-01-01 19:00: Train Epoch 12: 347/634 Loss: 0.131478
2023-01-01 19:00: Train Epoch 12: 351/634 Loss: 0.171907
2023-01-01 19:01: Train Epoch 12: 355/634 Loss: 0.140197
2023-01-01 19:01: Train Epoch 12: 359/634 Loss: 0.140621
2023-01-01 19:01: Train Epoch 12: 363/634 Loss: 0.112511
2023-01-01 19:01: Train Epoch 12: 367/634 Loss: 0.140223
2023-01-01 19:02: Train Epoch 12: 371/634 Loss: 0.150958
2023-01-01 19:02: Train Epoch 12: 375/634 Loss: 0.152485
2023-01-01 19:02: Train Epoch 12: 379/634 Loss: 0.131392
2023-01-01 19:02: Train Epoch 12: 383/634 Loss: 0.166140
2023-01-01 19:03: Train Epoch 12: 387/634 Loss: 0.146541
2023-01-01 19:03: Train Epoch 12: 391/634 Loss: 0.156087
2023-01-01 19:03: Train Epoch 12: 395/634 Loss: 0.135276
2023-01-01 19:03: Train Epoch 12: 399/634 Loss: 0.171657
2023-01-01 19:03: Train Epoch 12: 403/634 Loss: 0.139655
2023-01-01 19:04: Train Epoch 12: 407/634 Loss: 0.162803
2023-01-01 19:04: Train Epoch 12: 411/634 Loss: 0.113197
2023-01-01 19:04: Train Epoch 12: 415/634 Loss: 0.166777
2023-01-01 19:05: Train Epoch 12: 419/634 Loss: 0.126530
2023-01-01 19:05: Train Epoch 12: 423/634 Loss: 0.147554
2023-01-01 19:05: Train Epoch 12: 427/634 Loss: 0.147509
2023-01-01 19:05: Train Epoch 12: 431/634 Loss: 0.147666
2023-01-01 19:06: Train Epoch 12: 435/634 Loss: 0.175269
2023-01-01 19:06: Train Epoch 12: 439/634 Loss: 0.150234
2023-01-01 19:06: Train Epoch 12: 443/634 Loss: 0.140245
2023-01-01 19:06: Train Epoch 12: 447/634 Loss: 0.143731
2023-01-01 19:07: Train Epoch 12: 451/634 Loss: 0.141157
2023-01-01 19:07: Train Epoch 12: 455/634 Loss: 0.152411
2023-01-01 19:07: Train Epoch 12: 459/634 Loss: 0.175987
2023-01-01 19:07: Train Epoch 12: 463/634 Loss: 0.142797
2023-01-01 19:08: Train Epoch 12: 467/634 Loss: 0.177806
2023-01-01 19:08: Train Epoch 12: 471/634 Loss: 0.128871
2023-01-01 19:08: Train Epoch 12: 475/634 Loss: 0.124793
2023-01-01 19:08: Train Epoch 12: 479/634 Loss: 0.120824
2023-01-01 19:09: Train Epoch 12: 483/634 Loss: 0.154257
2023-01-01 19:09: Train Epoch 12: 487/634 Loss: 0.150162
2023-01-01 19:09: Train Epoch 12: 491/634 Loss: 0.130520
2023-01-01 19:09: Train Epoch 12: 495/634 Loss: 0.157532
2023-01-01 19:10: Train Epoch 12: 499/634 Loss: 0.153733
2023-01-01 19:10: Train Epoch 12: 503/634 Loss: 0.172946
2023-01-01 19:10: Train Epoch 12: 507/634 Loss: 0.158063
2023-01-01 19:10: Train Epoch 12: 511/634 Loss: 0.152641
2023-01-01 19:11: Train Epoch 12: 515/634 Loss: 0.145594
2023-01-01 19:11: Train Epoch 12: 519/634 Loss: 0.140208
2023-01-01 19:11: Train Epoch 12: 523/634 Loss: 0.162090
2023-01-01 19:11: Train Epoch 12: 527/634 Loss: 0.155245
2023-01-01 19:12: Train Epoch 12: 531/634 Loss: 0.152311
2023-01-01 19:12: Train Epoch 12: 535/634 Loss: 0.143058
2023-01-01 19:12: Train Epoch 12: 539/634 Loss: 0.177420
2023-01-01 19:12: Train Epoch 12: 543/634 Loss: 0.141818
2023-01-01 19:13: Train Epoch 12: 547/634 Loss: 0.137692
2023-01-01 19:13: Train Epoch 12: 551/634 Loss: 0.173243
2023-01-01 19:13: Train Epoch 12: 555/634 Loss: 0.123426
2023-01-01 19:13: Train Epoch 12: 559/634 Loss: 0.139856
2023-01-01 19:14: Train Epoch 12: 563/634 Loss: 0.119588
2023-01-01 19:14: Train Epoch 12: 567/634 Loss: 0.149671
2023-01-01 19:14: Train Epoch 12: 571/634 Loss: 0.146067
2023-01-01 19:14: Train Epoch 12: 575/634 Loss: 0.146694
2023-01-01 19:15: Train Epoch 12: 579/634 Loss: 0.172879
2023-01-01 19:15: Train Epoch 12: 583/634 Loss: 0.169556
2023-01-01 19:15: Train Epoch 12: 587/634 Loss: 0.134752
2023-01-01 19:15: Train Epoch 12: 591/634 Loss: 0.147367
2023-01-01 19:16: Train Epoch 12: 595/634 Loss: 0.169947
2023-01-01 19:16: Train Epoch 12: 599/634 Loss: 0.129625
2023-01-01 19:16: Train Epoch 12: 603/634 Loss: 0.137581
2023-01-01 19:16: Train Epoch 12: 607/634 Loss: 0.158506
2023-01-01 19:17: Train Epoch 12: 611/634 Loss: 0.137623
2023-01-01 19:17: Train Epoch 12: 615/634 Loss: 0.118024
2023-01-01 19:17: Train Epoch 12: 619/634 Loss: 0.144847
2023-01-01 19:17: Train Epoch 12: 623/634 Loss: 0.161275
2023-01-01 19:17: Train Epoch 12: 627/634 Loss: 0.223313
2023-01-01 19:18: Train Epoch 12: 631/634 Loss: 0.128005
2023-01-01 19:18: Train Epoch 12: 633/634 Loss: 0.065658
2023-01-01 19:18: **********Train Epoch 12: averaged Loss: 0.149414 
2023-01-01 19:18: 
Epoch time elapsed: 2353.7303450107574

2023-01-01 19:19: 
 metrics validation: {'precision': 0.6288343558282209, 'recall': 0.9461538461538461, 'f1-score': 0.7555282555282556, 'support': 1300, 'AUC': 0.9341304733727811, 'AUCPR': 0.8694843553629625, 'TP': 1230, 'FP': 726, 'TN': 1874, 'FN': 70} 

2023-01-01 19:19: **********Val Epoch 12: average Loss: 0.229674
2023-01-01 19:20: 
 Testing metrics {'precision': 0.8049403747870528, 'recall': 0.7695439739413681, 'f1-score': 0.7868442964196504, 'support': 1228, 'AUC': 0.9254514636760074, 'AUCPR': 0.8831107897948774, 'TP': 945, 'FP': 229, 'TN': 2227, 'FN': 283} 

2023-01-01 19:24: 
 Testing metrics {'precision': 0.8756710328537686, 'recall': 0.9253460403902882, 'f1-score': 0.8998234774933803, 'support': 4407, 'AUC': 0.9798364186274813, 'AUCPR': 0.9653462066051434, 'TP': 4078, 'FP': 579, 'TN': 8235, 'FN': 329} 

2023-01-01 19:24: Train Epoch 13: 3/634 Loss: 0.139990
2023-01-01 19:24: Train Epoch 13: 7/634 Loss: 0.155059
2023-01-01 19:25: Train Epoch 13: 11/634 Loss: 0.144043
2023-01-01 19:25: Train Epoch 13: 15/634 Loss: 0.184834
2023-01-01 19:25: Train Epoch 13: 19/634 Loss: 0.151994
2023-01-01 19:25: Train Epoch 13: 23/634 Loss: 0.162976
2023-01-01 19:26: Train Epoch 13: 27/634 Loss: 0.186358
2023-01-01 19:26: Train Epoch 13: 31/634 Loss: 0.145814
2023-01-01 19:26: Train Epoch 13: 35/634 Loss: 0.133193
2023-01-01 19:26: Train Epoch 13: 39/634 Loss: 0.135970
2023-01-01 19:27: Train Epoch 13: 43/634 Loss: 0.176199
2023-01-01 19:27: Train Epoch 13: 47/634 Loss: 0.172768
2023-01-01 19:27: Train Epoch 13: 51/634 Loss: 0.164988
2023-01-01 19:27: Train Epoch 13: 55/634 Loss: 0.172235
2023-01-01 19:28: Train Epoch 13: 59/634 Loss: 0.153023
2023-01-01 19:28: Train Epoch 13: 63/634 Loss: 0.146235
2023-01-01 19:28: Train Epoch 13: 67/634 Loss: 0.162094
2023-01-01 19:28: Train Epoch 13: 71/634 Loss: 0.122573
2023-01-01 19:28: Train Epoch 13: 75/634 Loss: 0.155701
2023-01-01 19:29: Train Epoch 13: 79/634 Loss: 0.156791
2023-01-01 19:29: Train Epoch 13: 83/634 Loss: 0.138713
2023-01-01 19:29: Train Epoch 13: 87/634 Loss: 0.220844
2023-01-01 19:29: Train Epoch 13: 91/634 Loss: 0.161457
2023-01-01 19:30: Train Epoch 13: 95/634 Loss: 0.167715
2023-01-01 19:30: Train Epoch 13: 99/634 Loss: 0.167133
2023-01-01 19:30: Train Epoch 13: 103/634 Loss: 0.142232
2023-01-01 19:30: Train Epoch 13: 107/634 Loss: 0.153157
2023-01-01 19:31: Train Epoch 13: 111/634 Loss: 0.165009
2023-01-01 19:31: Train Epoch 13: 115/634 Loss: 0.135181
2023-01-01 19:31: Train Epoch 13: 119/634 Loss: 0.168477
2023-01-01 19:31: Train Epoch 13: 123/634 Loss: 0.159539
2023-01-01 19:32: Train Epoch 13: 127/634 Loss: 0.152378
2023-01-01 19:32: Train Epoch 13: 131/634 Loss: 0.148033
2023-01-01 19:32: Train Epoch 13: 135/634 Loss: 0.141529
2023-01-01 19:32: Train Epoch 13: 139/634 Loss: 0.141250
2023-01-01 19:33: Train Epoch 13: 143/634 Loss: 0.167454
2023-01-01 19:33: Train Epoch 13: 147/634 Loss: 0.149176
2023-01-01 19:33: Train Epoch 13: 151/634 Loss: 0.153912
2023-01-01 19:33: Train Epoch 13: 155/634 Loss: 0.160268
2023-01-01 19:34: Train Epoch 13: 159/634 Loss: 0.141018
2023-01-01 19:34: Train Epoch 13: 163/634 Loss: 0.156873
2023-01-01 19:34: Train Epoch 13: 167/634 Loss: 0.155496
2023-01-01 19:34: Train Epoch 13: 171/634 Loss: 0.140174
2023-01-01 19:35: Train Epoch 13: 175/634 Loss: 0.162957
2023-01-01 19:35: Train Epoch 13: 179/634 Loss: 0.135120
2023-01-01 19:35: Train Epoch 13: 183/634 Loss: 0.131918
2023-01-01 19:35: Train Epoch 13: 187/634 Loss: 0.145189
2023-01-01 19:36: Train Epoch 13: 191/634 Loss: 0.152872
2023-01-01 19:36: Train Epoch 13: 195/634 Loss: 0.157164
2023-01-01 19:36: Train Epoch 13: 199/634 Loss: 0.145023
2023-01-01 19:36: Train Epoch 13: 203/634 Loss: 0.165978
2023-01-01 19:37: Train Epoch 13: 207/634 Loss: 0.129975
2023-01-01 19:37: Train Epoch 13: 211/634 Loss: 0.134769
2023-01-01 19:37: Train Epoch 13: 215/634 Loss: 0.188477
2023-01-01 19:37: Train Epoch 13: 219/634 Loss: 0.157334
2023-01-01 19:37: Train Epoch 13: 223/634 Loss: 0.170429
2023-01-01 19:38: Train Epoch 13: 227/634 Loss: 0.134246
2023-01-01 19:38: Train Epoch 13: 231/634 Loss: 0.150177
2023-01-01 19:38: Train Epoch 13: 235/634 Loss: 0.164433
2023-01-01 19:38: Train Epoch 13: 239/634 Loss: 0.160989
2023-01-01 19:39: Train Epoch 13: 243/634 Loss: 0.149239
2023-01-01 19:39: Train Epoch 13: 247/634 Loss: 0.136458
2023-01-01 19:39: Train Epoch 13: 251/634 Loss: 0.140746
2023-01-01 19:39: Train Epoch 13: 255/634 Loss: 0.125611
2023-01-01 19:40: Train Epoch 13: 259/634 Loss: 0.167245
2023-01-01 19:40: Train Epoch 13: 263/634 Loss: 0.133867
2023-01-01 19:40: Train Epoch 13: 267/634 Loss: 0.126101
2023-01-01 19:40: Train Epoch 13: 271/634 Loss: 0.152714
2023-01-01 19:41: Train Epoch 13: 275/634 Loss: 0.154549
2023-01-01 19:41: Train Epoch 13: 279/634 Loss: 0.124371
2023-01-01 19:41: Train Epoch 13: 283/634 Loss: 0.152383
2023-01-01 19:41: Train Epoch 13: 287/634 Loss: 0.154156
2023-01-01 19:42: Train Epoch 13: 291/634 Loss: 0.152246
2023-01-01 19:42: Train Epoch 13: 295/634 Loss: 0.130847
2023-01-01 19:42: Train Epoch 13: 299/634 Loss: 0.142235
2023-01-01 19:42: Train Epoch 13: 303/634 Loss: 0.143147
2023-01-01 19:42: Train Epoch 13: 307/634 Loss: 0.138602
2023-01-01 19:43: Train Epoch 13: 311/634 Loss: 0.138057
2023-01-01 19:43: Train Epoch 13: 315/634 Loss: 0.151083
2023-01-01 19:43: Train Epoch 13: 319/634 Loss: 0.136908
2023-01-01 19:43: Train Epoch 13: 323/634 Loss: 0.139718
2023-01-01 19:44: Train Epoch 13: 327/634 Loss: 0.143040
2023-01-01 19:44: Train Epoch 13: 331/634 Loss: 0.145298
2023-01-01 19:44: Train Epoch 13: 335/634 Loss: 0.136901
2023-01-01 19:44: Train Epoch 13: 339/634 Loss: 0.161916
2023-01-01 19:45: Train Epoch 13: 343/634 Loss: 0.154222
2023-01-01 19:45: Train Epoch 13: 347/634 Loss: 0.135886
2023-01-01 19:45: Train Epoch 13: 351/634 Loss: 0.127081
2023-01-01 19:45: Train Epoch 13: 355/634 Loss: 0.154410
2023-01-01 19:46: Train Epoch 13: 359/634 Loss: 0.149093
2023-01-01 19:46: Train Epoch 13: 363/634 Loss: 0.149358
2023-01-01 19:46: Train Epoch 13: 367/634 Loss: 0.137426
2023-01-01 19:46: Train Epoch 13: 371/634 Loss: 0.154709
2023-01-01 19:46: Train Epoch 13: 375/634 Loss: 0.130658
2023-01-01 19:47: Train Epoch 13: 379/634 Loss: 0.142230
2023-01-01 19:47: Train Epoch 13: 383/634 Loss: 0.143983
2023-01-01 19:47: Train Epoch 13: 387/634 Loss: 0.145453
2023-01-01 19:47: Train Epoch 13: 391/634 Loss: 0.166820
2023-01-01 19:48: Train Epoch 13: 395/634 Loss: 0.161495
2023-01-01 19:48: Train Epoch 13: 399/634 Loss: 0.165870
2023-01-01 19:48: Train Epoch 13: 403/634 Loss: 0.160227
2023-01-01 19:48: Train Epoch 13: 407/634 Loss: 0.143596
2023-01-01 19:49: Train Epoch 13: 411/634 Loss: 0.152204
2023-01-01 19:49: Train Epoch 13: 415/634 Loss: 0.141888
2023-01-01 19:49: Train Epoch 13: 419/634 Loss: 0.149486
2023-01-01 19:49: Train Epoch 13: 423/634 Loss: 0.162428
2023-01-01 19:50: Train Epoch 13: 427/634 Loss: 0.144622
2023-01-01 19:50: Train Epoch 13: 431/634 Loss: 0.143285
2023-01-01 19:50: Train Epoch 13: 435/634 Loss: 0.145757
2023-01-01 19:51: Train Epoch 13: 439/634 Loss: 0.149291
2023-01-01 19:51: Train Epoch 13: 443/634 Loss: 0.129694
2023-01-01 19:51: Train Epoch 13: 447/634 Loss: 0.141951
2023-01-01 19:51: Train Epoch 13: 451/634 Loss: 0.117351
2023-01-01 19:52: Train Epoch 13: 455/634 Loss: 0.159266
2023-01-01 19:52: Train Epoch 13: 459/634 Loss: 0.154199
2023-01-01 19:52: Train Epoch 13: 463/634 Loss: 0.143786
2023-01-01 19:52: Train Epoch 13: 467/634 Loss: 0.116460
2023-01-01 19:53: Train Epoch 13: 471/634 Loss: 0.146933
2023-01-01 19:53: Train Epoch 13: 475/634 Loss: 0.149828
2023-01-01 19:53: Train Epoch 13: 479/634 Loss: 0.135560
2023-01-01 19:53: Train Epoch 13: 483/634 Loss: 0.148459
2023-01-01 19:54: Train Epoch 13: 487/634 Loss: 0.139929
2023-01-01 19:54: Train Epoch 13: 491/634 Loss: 0.132706
2023-01-01 19:54: Train Epoch 13: 495/634 Loss: 0.142632
2023-01-01 19:54: Train Epoch 13: 499/634 Loss: 0.137715
2023-01-01 19:55: Train Epoch 13: 503/634 Loss: 0.126995
2023-01-01 19:55: Train Epoch 13: 507/634 Loss: 0.162788
2023-01-01 19:55: Train Epoch 13: 511/634 Loss: 0.142195
2023-01-01 19:56: Train Epoch 13: 515/634 Loss: 0.167103
2023-01-01 19:56: Train Epoch 13: 519/634 Loss: 0.136446
2023-01-01 19:56: Train Epoch 13: 523/634 Loss: 0.147605
2023-01-01 19:56: Train Epoch 13: 527/634 Loss: 0.139464
2023-01-01 19:57: Train Epoch 13: 531/634 Loss: 0.135122
2023-01-01 19:57: Train Epoch 13: 535/634 Loss: 0.161606
2023-01-01 19:57: Train Epoch 13: 539/634 Loss: 0.147320
2023-01-01 19:57: Train Epoch 13: 543/634 Loss: 0.134833
2023-01-01 19:58: Train Epoch 13: 547/634 Loss: 0.161205
2023-01-01 19:58: Train Epoch 13: 551/634 Loss: 0.181193
2023-01-01 19:58: Train Epoch 13: 555/634 Loss: 0.124521
2023-01-01 19:58: Train Epoch 13: 559/634 Loss: 0.125084
2023-01-01 19:59: Train Epoch 13: 563/634 Loss: 0.127818
2023-01-01 19:59: Train Epoch 13: 567/634 Loss: 0.143439
2023-01-01 19:59: Train Epoch 13: 571/634 Loss: 0.144650
2023-01-01 19:59: Train Epoch 13: 575/634 Loss: 0.158741
2023-01-01 20:00: Train Epoch 13: 579/634 Loss: 0.167543
2023-01-01 20:00: Train Epoch 13: 583/634 Loss: 0.148748
2023-01-01 20:00: Train Epoch 13: 587/634 Loss: 0.163720
2023-01-01 20:00: Train Epoch 13: 591/634 Loss: 0.165830
2023-01-01 20:01: Train Epoch 13: 595/634 Loss: 0.150643
2023-01-01 20:01: Train Epoch 13: 599/634 Loss: 0.162353
2023-01-01 20:01: Train Epoch 13: 603/634 Loss: 0.134826
2023-01-01 20:01: Train Epoch 13: 607/634 Loss: 0.145827
2023-01-01 20:02: Train Epoch 13: 611/634 Loss: 0.121479
2023-01-01 20:02: Train Epoch 13: 615/634 Loss: 0.156838
2023-01-01 20:02: Train Epoch 13: 619/634 Loss: 0.138691
2023-01-01 20:02: Train Epoch 13: 623/634 Loss: 0.136853
2023-01-01 20:03: Train Epoch 13: 627/634 Loss: 0.135165
2023-01-01 20:03: Train Epoch 13: 631/634 Loss: 0.143409
2023-01-01 20:03: Train Epoch 13: 633/634 Loss: 0.059850
2023-01-01 20:03: **********Train Epoch 13: averaged Loss: 0.148316 
2023-01-01 20:03: 
Epoch time elapsed: 2343.2935976982117

2023-01-01 20:04: 
 metrics validation: {'precision': 0.8614958448753463, 'recall': 0.7176923076923077, 'f1-score': 0.7830465799412506, 'support': 1300, 'AUC': 0.9380195266272191, 'AUCPR': 0.8801220022954118, 'TP': 933, 'FP': 150, 'TN': 2450, 'FN': 367} 

2023-01-01 20:04: **********Val Epoch 13: average Loss: 0.149232
2023-01-01 20:05: 
 Testing metrics {'precision': 0.8049403747870528, 'recall': 0.7695439739413681, 'f1-score': 0.7868442964196504, 'support': 1228, 'AUC': 0.9254514636760074, 'AUCPR': 0.8831107897948774, 'TP': 945, 'FP': 229, 'TN': 2227, 'FN': 283} 

2023-01-01 20:09: 
 Testing metrics {'precision': 0.8756710328537686, 'recall': 0.9253460403902882, 'f1-score': 0.8998234774933803, 'support': 4407, 'AUC': 0.9798364186274813, 'AUCPR': 0.9653462066051434, 'TP': 4078, 'FP': 579, 'TN': 8235, 'FN': 329} 

2023-01-01 20:09: Train Epoch 14: 3/634 Loss: 0.174366
2023-01-01 20:09: Train Epoch 14: 7/634 Loss: 0.133472
2023-01-01 20:10: Train Epoch 14: 11/634 Loss: 0.170262
2023-01-01 20:10: Train Epoch 14: 15/634 Loss: 0.147819
2023-01-01 20:10: Train Epoch 14: 19/634 Loss: 0.136938
2023-01-01 20:11: Train Epoch 14: 23/634 Loss: 0.160707
2023-01-01 20:11: Train Epoch 14: 27/634 Loss: 0.152792
2023-01-01 20:11: Train Epoch 14: 31/634 Loss: 0.139483
2023-01-01 20:11: Train Epoch 14: 35/634 Loss: 0.163896
2023-01-01 20:12: Train Epoch 14: 39/634 Loss: 0.155876
2023-01-01 20:12: Train Epoch 14: 43/634 Loss: 0.146918
2023-01-01 20:12: Train Epoch 14: 47/634 Loss: 0.147471
2023-01-01 20:12: Train Epoch 14: 51/634 Loss: 0.129746
2023-01-01 20:13: Train Epoch 14: 55/634 Loss: 0.142388
2023-01-01 20:13: Train Epoch 14: 59/634 Loss: 0.167817
2023-01-01 20:13: Train Epoch 14: 63/634 Loss: 0.135061
2023-01-01 20:13: Train Epoch 14: 67/634 Loss: 0.130487
2023-01-01 20:14: Train Epoch 14: 71/634 Loss: 0.140998
2023-01-01 20:14: Train Epoch 14: 75/634 Loss: 0.143744
2023-01-01 20:14: Train Epoch 14: 79/634 Loss: 0.174661
2023-01-01 20:14: Train Epoch 14: 83/634 Loss: 0.166682
2023-01-01 20:14: Train Epoch 14: 87/634 Loss: 0.152108
2023-01-01 20:15: Train Epoch 14: 91/634 Loss: 0.142690
2023-01-01 20:15: Train Epoch 14: 95/634 Loss: 0.167126
2023-01-01 20:15: Train Epoch 14: 99/634 Loss: 0.173237
2023-01-01 20:15: Train Epoch 14: 103/634 Loss: 0.138944
2023-01-01 20:16: Train Epoch 14: 107/634 Loss: 0.163348
2023-01-01 20:16: Train Epoch 14: 111/634 Loss: 0.170893
2023-01-01 20:16: Train Epoch 14: 115/634 Loss: 0.167547
2023-01-01 20:17: Train Epoch 14: 119/634 Loss: 0.142149
2023-01-01 20:17: Train Epoch 14: 123/634 Loss: 0.183819
2023-01-01 20:17: Train Epoch 14: 127/634 Loss: 0.146707
2023-01-01 20:17: Train Epoch 14: 131/634 Loss: 0.141006
2023-01-01 20:18: Train Epoch 14: 135/634 Loss: 0.135228
2023-01-01 20:18: Train Epoch 14: 139/634 Loss: 0.147461
2023-01-01 20:18: Train Epoch 14: 143/634 Loss: 0.144513
2023-01-01 20:18: Train Epoch 14: 147/634 Loss: 0.139745
2023-01-01 20:19: Train Epoch 14: 151/634 Loss: 0.137403
2023-01-01 20:19: Train Epoch 14: 155/634 Loss: 0.170159
2023-01-01 20:19: Train Epoch 14: 159/634 Loss: 0.145809
2023-01-01 20:19: Train Epoch 14: 163/634 Loss: 0.157271
2023-01-01 20:19: Train Epoch 14: 167/634 Loss: 0.160981
2023-01-01 20:20: Train Epoch 14: 171/634 Loss: 0.156619
2023-01-01 20:20: Train Epoch 14: 175/634 Loss: 0.133235
2023-01-01 20:20: Train Epoch 14: 179/634 Loss: 0.175532
2023-01-01 20:21: Train Epoch 14: 183/634 Loss: 0.169037
2023-01-01 20:21: Train Epoch 14: 187/634 Loss: 0.138825
2023-01-01 20:21: Train Epoch 14: 191/634 Loss: 0.152154
2023-01-01 20:21: Train Epoch 14: 195/634 Loss: 0.149630
2023-01-01 20:22: Train Epoch 14: 199/634 Loss: 0.173976
2023-01-01 20:22: Train Epoch 14: 203/634 Loss: 0.148271
2023-01-01 20:22: Train Epoch 14: 207/634 Loss: 0.130307
2023-01-01 20:22: Train Epoch 14: 211/634 Loss: 0.141633
2023-01-01 20:23: Train Epoch 14: 215/634 Loss: 0.162363
2023-01-01 20:23: Train Epoch 14: 219/634 Loss: 0.153106
2023-01-01 20:23: Train Epoch 14: 223/634 Loss: 0.146881
2023-01-01 20:23: Train Epoch 14: 227/634 Loss: 0.140562
2023-01-01 20:24: Train Epoch 14: 231/634 Loss: 0.135536
2023-01-01 20:24: Train Epoch 14: 235/634 Loss: 0.135723
2023-01-01 20:24: Train Epoch 14: 239/634 Loss: 0.157728
2023-01-01 20:24: Train Epoch 14: 243/634 Loss: 0.141181
2023-01-01 20:25: Train Epoch 14: 247/634 Loss: 0.146463
2023-01-01 20:25: Train Epoch 14: 251/634 Loss: 0.124179
2023-01-01 20:25: Train Epoch 14: 255/634 Loss: 0.142921
2023-01-01 20:25: Train Epoch 14: 259/634 Loss: 0.150209
2023-01-01 20:26: Train Epoch 14: 263/634 Loss: 0.143356
2023-01-01 20:26: Train Epoch 14: 267/634 Loss: 0.151183
2023-01-01 20:26: Train Epoch 14: 271/634 Loss: 0.158924
2023-01-01 20:26: Train Epoch 14: 275/634 Loss: 0.157340
2023-01-01 20:27: Train Epoch 14: 279/634 Loss: 0.190982
2023-01-01 20:27: Train Epoch 14: 283/634 Loss: 0.135035
2023-01-01 20:27: Train Epoch 14: 287/634 Loss: 0.136196
2023-01-01 20:27: Train Epoch 14: 291/634 Loss: 0.145561
2023-01-01 20:28: Train Epoch 14: 295/634 Loss: 0.169059
2023-01-01 20:28: Train Epoch 14: 299/634 Loss: 0.174617
2023-01-01 20:28: Train Epoch 14: 303/634 Loss: 0.166625
2023-01-01 20:28: Train Epoch 14: 307/634 Loss: 0.135268
2023-01-01 20:28: Train Epoch 14: 311/634 Loss: 0.146918
2023-01-01 20:29: Train Epoch 14: 315/634 Loss: 0.140023
2023-01-01 20:29: Train Epoch 14: 319/634 Loss: 0.167931
2023-01-01 20:29: Train Epoch 14: 323/634 Loss: 0.148225
2023-01-01 20:29: Train Epoch 14: 327/634 Loss: 0.173738
2023-01-01 20:30: Train Epoch 14: 331/634 Loss: 0.160490
2023-01-01 20:30: Train Epoch 14: 335/634 Loss: 0.139785
2023-01-01 20:30: Train Epoch 14: 339/634 Loss: 0.138029
2023-01-01 20:31: Train Epoch 14: 343/634 Loss: 0.138671
2023-01-01 20:31: Train Epoch 14: 347/634 Loss: 0.139949
2023-01-01 20:31: Train Epoch 14: 351/634 Loss: 0.132843
2023-01-01 20:31: Train Epoch 14: 355/634 Loss: 0.114912
2023-01-01 20:32: Train Epoch 14: 359/634 Loss: 0.149971
2023-01-01 20:32: Train Epoch 14: 363/634 Loss: 0.131178
2023-01-01 20:32: Train Epoch 14: 367/634 Loss: 0.111594
2023-01-01 20:32: Train Epoch 14: 371/634 Loss: 0.144435
2023-01-01 20:33: Train Epoch 14: 375/634 Loss: 0.171369
2023-01-01 20:33: Train Epoch 14: 379/634 Loss: 0.146810
2023-01-01 20:33: Train Epoch 14: 383/634 Loss: 0.155314
2023-01-01 20:33: Train Epoch 14: 387/634 Loss: 0.140706
2023-01-01 20:34: Train Epoch 14: 391/634 Loss: 0.138414
2023-01-01 20:34: Train Epoch 14: 395/634 Loss: 0.154423
2023-01-01 20:34: Train Epoch 14: 399/634 Loss: 0.146798
2023-01-01 20:34: Train Epoch 14: 403/634 Loss: 0.173422
2023-01-01 20:35: Train Epoch 14: 407/634 Loss: 0.145033
2023-01-01 20:35: Train Epoch 14: 411/634 Loss: 0.172817
2023-01-01 20:35: Train Epoch 14: 415/634 Loss: 0.131149
2023-01-01 20:35: Train Epoch 14: 419/634 Loss: 0.162825
2023-01-01 20:36: Train Epoch 14: 423/634 Loss: 0.134711
2023-01-01 20:36: Train Epoch 14: 427/634 Loss: 0.122045
2023-01-01 20:36: Train Epoch 14: 431/634 Loss: 0.157508
2023-01-01 20:36: Train Epoch 14: 435/634 Loss: 0.155841
2023-01-01 20:37: Train Epoch 14: 439/634 Loss: 0.158657
2023-01-01 20:37: Train Epoch 14: 443/634 Loss: 0.157187
2023-01-01 20:37: Train Epoch 14: 447/634 Loss: 0.148596
2023-01-01 20:37: Train Epoch 14: 451/634 Loss: 0.157207
2023-01-01 20:38: Train Epoch 14: 455/634 Loss: 0.185686
2023-01-01 20:38: Train Epoch 14: 459/634 Loss: 0.128427
2023-01-01 20:38: Train Epoch 14: 463/634 Loss: 0.154885
2023-01-01 20:38: Train Epoch 14: 467/634 Loss: 0.185666
2023-01-01 20:39: Train Epoch 14: 471/634 Loss: 0.143270
2023-01-01 20:39: Train Epoch 14: 475/634 Loss: 0.169486
2023-01-01 20:39: Train Epoch 14: 479/634 Loss: 0.184802
2023-01-01 20:39: Train Epoch 14: 483/634 Loss: 0.160727
2023-01-01 20:40: Train Epoch 14: 487/634 Loss: 0.140786
2023-01-01 20:40: Train Epoch 14: 491/634 Loss: 0.199793
2023-01-01 20:40: Train Epoch 14: 495/634 Loss: 0.170342
2023-01-01 20:40: Train Epoch 14: 499/634 Loss: 0.179330
2023-01-01 20:41: Train Epoch 14: 503/634 Loss: 0.145822
2023-01-01 20:41: Train Epoch 14: 507/634 Loss: 0.167808
2023-01-01 20:41: Train Epoch 14: 511/634 Loss: 0.153009
2023-01-01 20:41: Train Epoch 14: 515/634 Loss: 0.150975
2023-01-01 20:42: Train Epoch 14: 519/634 Loss: 0.168785
2023-01-01 20:42: Train Epoch 14: 523/634 Loss: 0.133014
2023-01-01 20:42: Train Epoch 14: 527/634 Loss: 0.163764
2023-01-01 20:42: Train Epoch 14: 531/634 Loss: 0.125832
2023-01-01 20:43: Train Epoch 14: 535/634 Loss: 0.165179
2023-01-01 20:43: Train Epoch 14: 539/634 Loss: 0.154234
2023-01-01 20:43: Train Epoch 14: 543/634 Loss: 0.176777
2023-01-01 20:43: Train Epoch 14: 547/634 Loss: 0.138434
2023-01-01 20:44: Train Epoch 14: 551/634 Loss: 0.163678
2023-01-01 20:44: Train Epoch 14: 555/634 Loss: 0.153607
2023-01-01 20:44: Train Epoch 14: 559/634 Loss: 0.168116
2023-01-01 20:44: Train Epoch 14: 563/634 Loss: 0.180993
2023-01-01 20:45: Train Epoch 14: 567/634 Loss: 0.157552
2023-01-01 20:45: Train Epoch 14: 571/634 Loss: 0.162899
2023-01-01 20:45: Train Epoch 14: 575/634 Loss: 0.156484
2023-01-01 20:45: Train Epoch 14: 579/634 Loss: 0.156805
2023-01-01 20:46: Train Epoch 14: 583/634 Loss: 0.194443
2023-01-01 20:46: Train Epoch 14: 587/634 Loss: 0.136926
2023-01-01 20:46: Train Epoch 14: 591/634 Loss: 0.193108
2023-01-01 20:46: Train Epoch 14: 595/634 Loss: 0.167721
2023-01-01 20:47: Train Epoch 14: 599/634 Loss: 0.203026
2023-01-01 20:47: Train Epoch 14: 603/634 Loss: 0.140541
2023-01-01 20:47: Train Epoch 14: 607/634 Loss: 0.177768
2023-01-01 20:47: Train Epoch 14: 611/634 Loss: 0.146070
2023-01-01 20:48: Train Epoch 14: 615/634 Loss: 0.144857
2023-01-01 20:48: Train Epoch 14: 619/634 Loss: 0.115198
2023-01-01 20:48: Train Epoch 14: 623/634 Loss: 0.171966
2023-01-01 20:48: Train Epoch 14: 627/634 Loss: 0.164193
2023-01-01 20:49: Train Epoch 14: 631/634 Loss: 0.165856
2023-01-01 20:49: Train Epoch 14: 633/634 Loss: 0.055000
2023-01-01 20:49: **********Train Epoch 14: averaged Loss: 0.152787 
2023-01-01 20:49: 
Epoch time elapsed: 2382.7426998615265

2023-01-01 20:50: 
 metrics validation: {'precision': 0.9198423127463863, 'recall': 0.5384615384615384, 'f1-score': 0.6792819019893255, 'support': 1300, 'AUC': 0.9461581360946745, 'AUCPR': 0.8988735735559151, 'TP': 700, 'FP': 61, 'TN': 2539, 'FN': 600} 

2023-01-01 20:50: **********Val Epoch 14: average Loss: 0.167962
2023-01-01 20:51: 
 Testing metrics {'precision': 0.8049403747870528, 'recall': 0.7695439739413681, 'f1-score': 0.7868442964196504, 'support': 1228, 'AUC': 0.9254514636760074, 'AUCPR': 0.8831107897948774, 'TP': 945, 'FP': 229, 'TN': 2227, 'FN': 283} 

2023-01-01 20:55: 
 Testing metrics {'precision': 0.8756710328537686, 'recall': 0.9253460403902882, 'f1-score': 0.8998234774933803, 'support': 4407, 'AUC': 0.9798364186274813, 'AUCPR': 0.9653462066051434, 'TP': 4078, 'FP': 579, 'TN': 8235, 'FN': 329} 

2023-01-01 20:55: Train Epoch 15: 3/634 Loss: 0.159229
2023-01-01 20:55: Train Epoch 15: 7/634 Loss: 0.158859
2023-01-01 20:56: Train Epoch 15: 11/634 Loss: 0.194967
2023-01-01 20:56: Train Epoch 15: 15/634 Loss: 0.137854
2023-01-01 20:56: Train Epoch 15: 19/634 Loss: 0.163879
2023-01-01 20:56: Train Epoch 15: 23/634 Loss: 0.169853
2023-01-01 20:57: Train Epoch 15: 27/634 Loss: 0.132464
2023-01-01 20:57: Train Epoch 15: 31/634 Loss: 0.139099
2023-01-01 20:57: Train Epoch 15: 35/634 Loss: 0.142410
2023-01-01 20:57: Train Epoch 15: 39/634 Loss: 0.144888
2023-01-01 20:57: Train Epoch 15: 43/634 Loss: 0.124193
2023-01-01 20:58: Train Epoch 15: 47/634 Loss: 0.155939
2023-01-01 20:58: Train Epoch 15: 51/634 Loss: 0.142952
2023-01-01 20:58: Train Epoch 15: 55/634 Loss: 0.173060
2023-01-01 20:58: Train Epoch 15: 59/634 Loss: 0.133573
2023-01-01 20:59: Train Epoch 15: 63/634 Loss: 0.120192
2023-01-01 20:59: Train Epoch 15: 67/634 Loss: 0.142531
2023-01-01 20:59: Train Epoch 15: 71/634 Loss: 0.157547
2023-01-01 20:59: Train Epoch 15: 75/634 Loss: 0.142118
2023-01-01 21:00: Train Epoch 15: 79/634 Loss: 0.138365
2023-01-01 21:00: Train Epoch 15: 83/634 Loss: 0.117261
2023-01-01 21:00: Train Epoch 15: 87/634 Loss: 0.141569
2023-01-01 21:00: Train Epoch 15: 91/634 Loss: 0.138408
2023-01-01 21:01: Train Epoch 15: 95/634 Loss: 0.159003
2023-01-01 21:01: Train Epoch 15: 99/634 Loss: 0.141364
2023-01-01 21:01: Train Epoch 15: 103/634 Loss: 0.150435
2023-01-01 21:01: Train Epoch 15: 107/634 Loss: 0.130531
2023-01-01 21:02: Train Epoch 15: 111/634 Loss: 0.166436
2023-01-01 21:02: Train Epoch 15: 115/634 Loss: 0.135133
2023-01-01 21:02: Train Epoch 15: 119/634 Loss: 0.143201
2023-01-01 21:02: Train Epoch 15: 123/634 Loss: 0.123055
2023-01-01 21:03: Train Epoch 15: 127/634 Loss: 0.168086
2023-01-01 21:03: Train Epoch 15: 131/634 Loss: 0.155431
2023-01-01 21:03: Train Epoch 15: 135/634 Loss: 0.135279
2023-01-01 21:03: Train Epoch 15: 139/634 Loss: 0.135315
2023-01-01 21:03: Train Epoch 15: 143/634 Loss: 0.157124
2023-01-01 21:04: Train Epoch 15: 147/634 Loss: 0.149055
2023-01-01 21:04: Train Epoch 15: 151/634 Loss: 0.178577
2023-01-01 21:04: Train Epoch 15: 155/634 Loss: 0.172264
2023-01-01 21:04: Train Epoch 15: 159/634 Loss: 0.141581
2023-01-01 21:05: Train Epoch 15: 163/634 Loss: 0.154614
2023-01-01 21:05: Train Epoch 15: 167/634 Loss: 0.156095
2023-01-01 21:05: Train Epoch 15: 171/634 Loss: 0.166033
2023-01-01 21:05: Train Epoch 15: 175/634 Loss: 0.154422
2023-01-01 21:06: Train Epoch 15: 179/634 Loss: 0.127943
2023-01-01 21:06: Train Epoch 15: 183/634 Loss: 0.149941
2023-01-01 21:06: Train Epoch 15: 187/634 Loss: 0.134198
2023-01-01 21:06: Train Epoch 15: 191/634 Loss: 0.141076
2023-01-01 21:07: Train Epoch 15: 195/634 Loss: 0.113334
2023-01-01 21:07: Train Epoch 15: 199/634 Loss: 0.146364
2023-01-01 21:07: Train Epoch 15: 203/634 Loss: 0.136937
2023-01-01 21:07: Train Epoch 15: 207/634 Loss: 0.119819
2023-01-01 21:08: Train Epoch 15: 211/634 Loss: 0.146026
2023-01-01 21:08: Train Epoch 15: 215/634 Loss: 0.129394
2023-01-01 21:08: Train Epoch 15: 219/634 Loss: 0.163141
2023-01-01 21:08: Train Epoch 15: 223/634 Loss: 0.140635
2023-01-01 21:09: Train Epoch 15: 227/634 Loss: 0.131485
2023-01-01 21:09: Train Epoch 15: 231/634 Loss: 0.136306
2023-01-01 21:09: Train Epoch 15: 235/634 Loss: 0.176332
2023-01-01 21:09: Train Epoch 15: 239/634 Loss: 0.162983
2023-01-01 21:10: Train Epoch 15: 243/634 Loss: 0.145864
2023-01-01 21:10: Train Epoch 15: 247/634 Loss: 0.133425
2023-01-01 21:10: Train Epoch 15: 251/634 Loss: 0.143948
2023-01-01 21:10: Train Epoch 15: 255/634 Loss: 0.171549
2023-01-01 21:11: Train Epoch 15: 259/634 Loss: 0.131789
2023-01-01 21:11: Train Epoch 15: 263/634 Loss: 0.142823
2023-01-01 21:11: Train Epoch 15: 267/634 Loss: 0.150749
2023-01-01 21:11: Train Epoch 15: 271/634 Loss: 0.155358
2023-01-01 21:12: Train Epoch 15: 275/634 Loss: 0.166339
2023-01-01 21:12: Train Epoch 15: 279/634 Loss: 0.167394
2023-01-01 21:12: Train Epoch 15: 283/634 Loss: 0.119616
2023-01-01 21:12: Train Epoch 15: 287/634 Loss: 0.171965
2023-01-01 21:13: Train Epoch 15: 291/634 Loss: 0.157762
2023-01-01 21:13: Train Epoch 15: 295/634 Loss: 0.154133
2023-01-01 21:13: Train Epoch 15: 299/634 Loss: 0.183724
2023-01-01 21:13: Train Epoch 15: 303/634 Loss: 0.159098
2023-01-01 21:14: Train Epoch 15: 307/634 Loss: 0.137092
2023-01-01 21:14: Train Epoch 15: 311/634 Loss: 0.144938
2023-01-01 21:14: Train Epoch 15: 315/634 Loss: 0.151569
2023-01-01 21:14: Train Epoch 15: 319/634 Loss: 0.166325
2023-01-01 21:15: Train Epoch 15: 323/634 Loss: 0.138833
2023-01-01 21:15: Train Epoch 15: 327/634 Loss: 0.131407
2023-01-01 21:15: Train Epoch 15: 331/634 Loss: 0.140176
2023-01-01 21:15: Train Epoch 15: 335/634 Loss: 0.144001
2023-01-01 21:16: Train Epoch 15: 339/634 Loss: 0.141047
2023-01-01 21:16: Train Epoch 15: 343/634 Loss: 0.136314
2023-01-01 21:16: Train Epoch 15: 347/634 Loss: 0.147848
2023-01-01 21:16: Train Epoch 15: 351/634 Loss: 0.143620
2023-01-01 21:17: Train Epoch 15: 355/634 Loss: 0.139162
2023-01-01 21:17: Train Epoch 15: 359/634 Loss: 0.161329
2023-01-01 21:17: Train Epoch 15: 363/634 Loss: 0.150039
2023-01-01 21:17: Train Epoch 15: 367/634 Loss: 0.171423
2023-01-01 21:17: Train Epoch 15: 371/634 Loss: 0.153475
2023-01-01 21:18: Train Epoch 15: 375/634 Loss: 0.137755
2023-01-01 21:18: Train Epoch 15: 379/634 Loss: 0.121025
2023-01-01 21:18: Train Epoch 15: 383/634 Loss: 0.143488
2023-01-01 21:18: Train Epoch 15: 387/634 Loss: 0.135347
2023-01-01 21:19: Train Epoch 15: 391/634 Loss: 0.154515
2023-01-01 21:19: Train Epoch 15: 395/634 Loss: 0.150960
2023-01-01 21:19: Train Epoch 15: 399/634 Loss: 0.152286
2023-01-01 21:19: Train Epoch 15: 403/634 Loss: 0.128438
2023-01-01 21:20: Train Epoch 15: 407/634 Loss: 0.135530
2023-01-01 21:20: Train Epoch 15: 411/634 Loss: 0.181095
2023-01-01 21:20: Train Epoch 15: 415/634 Loss: 0.171514
2023-01-01 21:20: Train Epoch 15: 419/634 Loss: 0.189742
2023-01-01 21:21: Train Epoch 15: 423/634 Loss: 0.165526
2023-01-01 21:21: Train Epoch 15: 427/634 Loss: 0.200825
2023-01-01 21:21: Train Epoch 15: 431/634 Loss: 0.163538
2023-01-01 21:21: Train Epoch 15: 435/634 Loss: 0.152888
2023-01-01 21:22: Train Epoch 15: 439/634 Loss: 0.195131
2023-01-01 21:22: Train Epoch 15: 443/634 Loss: 0.159760
2023-01-01 21:22: Train Epoch 15: 447/634 Loss: 0.153074
2023-01-01 21:22: Train Epoch 15: 451/634 Loss: 0.200407
2023-01-01 21:23: Train Epoch 15: 455/634 Loss: 0.146396
2023-01-01 21:23: Train Epoch 15: 459/634 Loss: 0.142868
2023-01-01 21:23: Train Epoch 15: 463/634 Loss: 0.185208
2023-01-01 21:23: Train Epoch 15: 467/634 Loss: 0.159200
2023-01-01 21:24: Train Epoch 15: 471/634 Loss: 0.152428
2023-01-01 21:24: Train Epoch 15: 475/634 Loss: 0.177664
2023-01-01 21:24: Train Epoch 15: 479/634 Loss: 0.153181
2023-01-01 21:24: Train Epoch 15: 483/634 Loss: 0.163257
2023-01-01 21:25: Train Epoch 15: 487/634 Loss: 0.175789
2023-01-01 21:25: Train Epoch 15: 491/634 Loss: 0.143332
2023-01-01 21:25: Train Epoch 15: 495/634 Loss: 0.122687
2023-01-01 21:25: Train Epoch 15: 499/634 Loss: 0.143649
2023-01-01 21:26: Train Epoch 15: 503/634 Loss: 0.177139
2023-01-01 21:26: Train Epoch 15: 507/634 Loss: 0.135946
2023-01-01 21:26: Train Epoch 15: 511/634 Loss: 0.176974
2023-01-01 21:26: Train Epoch 15: 515/634 Loss: 0.167893
2023-01-01 21:27: Train Epoch 15: 519/634 Loss: 0.142168
2023-01-01 21:27: Train Epoch 15: 523/634 Loss: 0.162670
2023-01-01 21:27: Train Epoch 15: 527/634 Loss: 0.190383
2023-01-01 21:27: Train Epoch 15: 531/634 Loss: 0.140110
2023-01-01 21:28: Train Epoch 15: 535/634 Loss: 0.184084
2023-01-01 21:28: Train Epoch 15: 539/634 Loss: 0.140652
2023-01-01 21:28: Train Epoch 15: 543/634 Loss: 0.124071
2023-01-01 21:28: Train Epoch 15: 547/634 Loss: 0.164024
2023-01-01 21:29: Train Epoch 15: 551/634 Loss: 0.154146
2023-01-01 21:29: Train Epoch 15: 555/634 Loss: 0.134223
2023-01-01 21:29: Train Epoch 15: 559/634 Loss: 0.155733
2023-01-01 21:29: Train Epoch 15: 563/634 Loss: 0.169642
2023-01-01 21:29: Train Epoch 15: 567/634 Loss: 0.136271
2023-01-01 21:30: Train Epoch 15: 571/634 Loss: 0.173491
2023-01-01 21:30: Train Epoch 15: 575/634 Loss: 0.154587
2023-01-01 21:30: Train Epoch 15: 579/634 Loss: 0.161332
2023-01-01 21:31: Train Epoch 15: 583/634 Loss: 0.188044
2023-01-01 21:31: Train Epoch 15: 587/634 Loss: 0.198272
2023-01-01 21:31: Train Epoch 15: 591/634 Loss: 0.144304
2023-01-01 21:31: Train Epoch 15: 595/634 Loss: 0.160402
2023-01-01 21:32: Train Epoch 15: 599/634 Loss: 0.145410
2023-01-01 21:32: Train Epoch 15: 603/634 Loss: 0.151392
2023-01-01 21:32: Train Epoch 15: 607/634 Loss: 0.167885
2023-01-01 21:32: Train Epoch 15: 611/634 Loss: 0.129020
2023-01-01 21:32: Train Epoch 15: 615/634 Loss: 0.154989
2023-01-01 21:33: Train Epoch 15: 619/634 Loss: 0.124047
2023-01-01 21:33: Train Epoch 15: 623/634 Loss: 0.157247
2023-01-01 21:33: Train Epoch 15: 627/634 Loss: 0.141841
2023-01-01 21:33: Train Epoch 15: 631/634 Loss: 0.161946
2023-01-01 21:34: Train Epoch 15: 633/634 Loss: 0.081307
2023-01-01 21:34: **********Train Epoch 15: averaged Loss: 0.151349 
2023-01-01 21:34: 
Epoch time elapsed: 2325.275179386139

2023-01-01 21:35: 
 metrics validation: {'precision': 0.8963337547408344, 'recall': 0.5453846153846154, 'f1-score': 0.6781444285031086, 'support': 1300, 'AUC': 0.9272218934911242, 'AUCPR': 0.8628531031977635, 'TP': 709, 'FP': 82, 'TN': 2518, 'FN': 591} 

2023-01-01 21:35: **********Val Epoch 15: average Loss: 0.218865
2023-01-01 21:36: 
 Testing metrics {'precision': 0.8049403747870528, 'recall': 0.7695439739413681, 'f1-score': 0.7868442964196504, 'support': 1228, 'AUC': 0.9254514636760074, 'AUCPR': 0.8831107897948774, 'TP': 945, 'FP': 229, 'TN': 2227, 'FN': 283} 

2023-01-01 21:40: 
 Testing metrics {'precision': 0.8756710328537686, 'recall': 0.9253460403902882, 'f1-score': 0.8998234774933803, 'support': 4407, 'AUC': 0.9798364186274813, 'AUCPR': 0.9653462066051434, 'TP': 4078, 'FP': 579, 'TN': 8235, 'FN': 329} 

2023-01-01 21:40: Train Epoch 16: 3/634 Loss: 0.169672
2023-01-01 21:41: Train Epoch 16: 7/634 Loss: 0.146885
2023-01-01 21:41: Train Epoch 16: 11/634 Loss: 0.153362
2023-01-01 21:41: Train Epoch 16: 15/634 Loss: 0.166835
2023-01-01 21:42: Train Epoch 16: 19/634 Loss: 0.143380
2023-01-01 21:42: Train Epoch 16: 23/634 Loss: 0.136544
2023-01-01 21:42: Train Epoch 16: 27/634 Loss: 0.143946
2023-01-01 21:42: Train Epoch 16: 31/634 Loss: 0.159267
2023-01-01 21:43: Train Epoch 16: 35/634 Loss: 0.143740
2023-01-01 21:43: Train Epoch 16: 39/634 Loss: 0.161040
2023-01-01 21:43: Train Epoch 16: 43/634 Loss: 0.120183
2023-01-01 21:43: Train Epoch 16: 47/634 Loss: 0.124150
2023-01-01 21:44: Train Epoch 16: 51/634 Loss: 0.160660
2023-01-01 21:44: Train Epoch 16: 55/634 Loss: 0.156936
2023-01-01 21:44: Train Epoch 16: 59/634 Loss: 0.159602
2023-01-01 21:44: Train Epoch 16: 63/634 Loss: 0.142331
2023-01-01 21:45: Train Epoch 16: 67/634 Loss: 0.139589
2023-01-01 21:45: Train Epoch 16: 71/634 Loss: 0.122432
2023-01-01 21:45: Train Epoch 16: 75/634 Loss: 0.163053
2023-01-01 21:45: Train Epoch 16: 79/634 Loss: 0.150110
2023-01-01 21:46: Train Epoch 16: 83/634 Loss: 0.156422
2023-01-01 21:46: Train Epoch 16: 87/634 Loss: 0.140025
2023-01-01 21:46: Train Epoch 16: 91/634 Loss: 0.133126
2023-01-01 21:46: Train Epoch 16: 95/634 Loss: 0.128636
2023-01-01 21:47: Train Epoch 16: 99/634 Loss: 0.145794
2023-01-01 21:47: Train Epoch 16: 103/634 Loss: 0.148578
2023-01-01 21:47: Train Epoch 16: 107/634 Loss: 0.141595
2023-01-01 21:48: Train Epoch 16: 111/634 Loss: 0.158616
2023-01-01 21:48: Train Epoch 16: 115/634 Loss: 0.118669
2023-01-01 21:48: Train Epoch 16: 119/634 Loss: 0.147766
2023-01-01 21:48: Train Epoch 16: 123/634 Loss: 0.128412
2023-01-01 21:48: Train Epoch 16: 127/634 Loss: 0.126595
2023-01-01 21:49: Train Epoch 16: 131/634 Loss: 0.153814
2023-01-01 21:49: Train Epoch 16: 135/634 Loss: 0.130628
2023-01-01 21:49: Train Epoch 16: 139/634 Loss: 0.152252
2023-01-01 21:49: Train Epoch 16: 143/634 Loss: 0.137357
2023-01-01 21:50: Train Epoch 16: 147/634 Loss: 0.140521
2023-01-01 21:50: Train Epoch 16: 151/634 Loss: 0.155029
2023-01-01 21:50: Train Epoch 16: 155/634 Loss: 0.115901
2023-01-01 21:51: Train Epoch 16: 159/634 Loss: 0.157991
2023-01-01 21:51: Train Epoch 16: 163/634 Loss: 0.142617
2023-01-01 21:51: Train Epoch 16: 167/634 Loss: 0.148849
2023-01-01 21:51: Train Epoch 16: 171/634 Loss: 0.140487
2023-01-01 21:52: Train Epoch 16: 175/634 Loss: 0.148615
2023-01-01 21:52: Train Epoch 16: 179/634 Loss: 0.140138
2023-01-01 21:52: Train Epoch 16: 183/634 Loss: 0.138889
2023-01-01 21:52: Train Epoch 16: 187/634 Loss: 0.135891
2023-01-01 21:53: Train Epoch 16: 191/634 Loss: 0.126881
2023-01-01 21:53: Train Epoch 16: 195/634 Loss: 0.121020
2023-01-01 21:53: Train Epoch 16: 199/634 Loss: 0.154074
2023-01-01 21:53: Train Epoch 16: 203/634 Loss: 0.151423
2023-01-01 21:54: Train Epoch 16: 207/634 Loss: 0.143995
2023-01-01 21:54: Train Epoch 16: 211/634 Loss: 0.135510
2023-01-01 21:54: Train Epoch 16: 215/634 Loss: 0.135716
2023-01-01 21:54: Train Epoch 16: 219/634 Loss: 0.129613
2023-01-01 21:55: Train Epoch 16: 223/634 Loss: 0.133709
2023-01-01 21:55: Train Epoch 16: 227/634 Loss: 0.129940
2023-01-01 21:55: Train Epoch 16: 231/634 Loss: 0.137879
2023-01-01 21:55: Train Epoch 16: 235/634 Loss: 0.115411
2023-01-01 21:55: Train Epoch 16: 239/634 Loss: 0.132139
2023-01-01 21:56: Train Epoch 16: 243/634 Loss: 0.117669
2023-01-01 21:56: Train Epoch 16: 247/634 Loss: 0.128273
2023-01-01 21:56: Train Epoch 16: 251/634 Loss: 0.115043
2023-01-01 21:56: Train Epoch 16: 255/634 Loss: 0.107162
2023-01-01 21:57: Train Epoch 16: 259/634 Loss: 0.162273
2023-01-01 21:57: Train Epoch 16: 263/634 Loss: 0.158964
2023-01-01 21:57: Train Epoch 16: 267/634 Loss: 0.139211
2023-01-01 21:57: Train Epoch 16: 271/634 Loss: 0.136081
2023-01-01 21:58: Train Epoch 16: 275/634 Loss: 0.118957
2023-01-01 21:58: Train Epoch 16: 279/634 Loss: 0.137640
2023-01-01 21:58: Train Epoch 16: 283/634 Loss: 0.132987
2023-01-01 21:58: Train Epoch 16: 287/634 Loss: 0.154478
2023-01-01 21:59: Train Epoch 16: 291/634 Loss: 0.148368
2023-01-01 21:59: Train Epoch 16: 295/634 Loss: 0.111517
2023-01-01 21:59: Train Epoch 16: 299/634 Loss: 0.121953
2023-01-01 21:59: Train Epoch 16: 303/634 Loss: 0.150149
2023-01-01 22:00: Train Epoch 16: 307/634 Loss: 0.144654
2023-01-01 22:00: Train Epoch 16: 311/634 Loss: 0.144998
2023-01-01 22:00: Train Epoch 16: 315/634 Loss: 0.142283
2023-01-01 22:00: Train Epoch 16: 319/634 Loss: 0.125763
2023-01-01 22:01: Train Epoch 16: 323/634 Loss: 0.133768
2023-01-01 22:01: Train Epoch 16: 327/634 Loss: 0.114469
2023-01-01 22:01: Train Epoch 16: 331/634 Loss: 0.131165
2023-01-01 22:01: Train Epoch 16: 335/634 Loss: 0.140062
2023-01-01 22:02: Train Epoch 16: 339/634 Loss: 0.155987
2023-01-01 22:02: Train Epoch 16: 343/634 Loss: 0.133061
2023-01-01 22:02: Train Epoch 16: 347/634 Loss: 0.138788
2023-01-01 22:02: Train Epoch 16: 351/634 Loss: 0.134897
2023-01-01 22:03: Train Epoch 16: 355/634 Loss: 0.136051
2023-01-01 22:03: Train Epoch 16: 359/634 Loss: 0.152240
2023-01-01 22:03: Train Epoch 16: 363/634 Loss: 0.139397
2023-01-01 22:03: Train Epoch 16: 367/634 Loss: 0.136364
2023-01-01 22:04: Train Epoch 16: 371/634 Loss: 0.131941
2023-01-01 22:04: Train Epoch 16: 375/634 Loss: 0.134049
2023-01-01 22:04: Train Epoch 16: 379/634 Loss: 0.139179
2023-01-01 22:04: Train Epoch 16: 383/634 Loss: 0.152928
2023-01-01 22:05: Train Epoch 16: 387/634 Loss: 0.145529
2023-01-01 22:05: Train Epoch 16: 391/634 Loss: 0.125768
2023-01-01 22:05: Train Epoch 16: 395/634 Loss: 0.135552
2023-01-01 22:05: Train Epoch 16: 399/634 Loss: 0.147840
2023-01-01 22:06: Train Epoch 16: 403/634 Loss: 0.113680
2023-01-01 22:06: Train Epoch 16: 407/634 Loss: 0.130822
2023-01-01 22:06: Train Epoch 16: 411/634 Loss: 0.114699
2023-01-01 22:06: Train Epoch 16: 415/634 Loss: 0.157422
2023-01-01 22:07: Train Epoch 16: 419/634 Loss: 0.138760
2023-01-01 22:07: Train Epoch 16: 423/634 Loss: 0.136732
2023-01-01 22:07: Train Epoch 16: 427/634 Loss: 0.156057
2023-01-01 22:07: Train Epoch 16: 431/634 Loss: 0.134438
2023-01-01 22:08: Train Epoch 16: 435/634 Loss: 0.149376
2023-01-01 22:08: Train Epoch 16: 439/634 Loss: 0.123870
2023-01-01 22:08: Train Epoch 16: 443/634 Loss: 0.143174
2023-01-01 22:08: Train Epoch 16: 447/634 Loss: 0.121622
2023-01-01 22:09: Train Epoch 16: 451/634 Loss: 0.158660
2023-01-01 22:09: Train Epoch 16: 455/634 Loss: 0.161384
2023-01-01 22:09: Train Epoch 16: 459/634 Loss: 0.148743
2023-01-01 22:09: Train Epoch 16: 463/634 Loss: 0.158514
2023-01-01 22:10: Train Epoch 16: 467/634 Loss: 0.127294
2023-01-01 22:10: Train Epoch 16: 471/634 Loss: 0.130398
2023-01-01 22:10: Train Epoch 16: 475/634 Loss: 0.137821
2023-01-01 22:10: Train Epoch 16: 479/634 Loss: 0.145410
2023-01-01 22:11: Train Epoch 16: 483/634 Loss: 0.137052
2023-01-01 22:11: Train Epoch 16: 487/634 Loss: 0.150856
2023-01-01 22:11: Train Epoch 16: 491/634 Loss: 0.158589
2023-01-01 22:11: Train Epoch 16: 495/634 Loss: 0.129174
2023-01-01 22:12: Train Epoch 16: 499/634 Loss: 0.124611
2023-01-01 22:12: Train Epoch 16: 503/634 Loss: 0.140773
2023-01-01 22:12: Train Epoch 16: 507/634 Loss: 0.151027
2023-01-01 22:12: Train Epoch 16: 511/634 Loss: 0.155604
2023-01-01 22:13: Train Epoch 16: 515/634 Loss: 0.130452
2023-01-01 22:13: Train Epoch 16: 519/634 Loss: 0.155979
2023-01-01 22:13: Train Epoch 16: 523/634 Loss: 0.140542
2023-01-01 22:13: Train Epoch 16: 527/634 Loss: 0.128707
2023-01-01 22:14: Train Epoch 16: 531/634 Loss: 0.146750
2023-01-01 22:14: Train Epoch 16: 535/634 Loss: 0.140917
2023-01-01 22:14: Train Epoch 16: 539/634 Loss: 0.147035
2023-01-01 22:14: Train Epoch 16: 543/634 Loss: 0.120659
2023-01-01 22:15: Train Epoch 16: 547/634 Loss: 0.147799
2023-01-01 22:15: Train Epoch 16: 551/634 Loss: 0.116509
2023-01-01 22:15: Train Epoch 16: 555/634 Loss: 0.138851
2023-01-01 22:15: Train Epoch 16: 559/634 Loss: 0.127775
2023-01-01 22:16: Train Epoch 16: 563/634 Loss: 0.131298
2023-01-01 22:16: Train Epoch 16: 567/634 Loss: 0.124452
2023-01-01 22:16: Train Epoch 16: 571/634 Loss: 0.114943
2023-01-01 22:16: Train Epoch 16: 575/634 Loss: 0.128749
2023-01-01 22:17: Train Epoch 16: 579/634 Loss: 0.128306
2023-01-01 22:17: Train Epoch 16: 583/634 Loss: 0.131621
2023-01-01 22:17: Train Epoch 16: 587/634 Loss: 0.135819
2023-01-01 22:17: Train Epoch 16: 591/634 Loss: 0.114461
2023-01-01 22:18: Train Epoch 16: 595/634 Loss: 0.142628
2023-01-01 22:18: Train Epoch 16: 599/634 Loss: 0.130669
2023-01-01 22:18: Train Epoch 16: 603/634 Loss: 0.134735
2023-01-01 22:18: Train Epoch 16: 607/634 Loss: 0.145205
2023-01-01 22:19: Train Epoch 16: 611/634 Loss: 0.140737
2023-01-01 22:19: Train Epoch 16: 615/634 Loss: 0.134048
2023-01-01 22:19: Train Epoch 16: 619/634 Loss: 0.142800
2023-01-01 22:19: Train Epoch 16: 623/634 Loss: 0.124101
2023-01-01 22:20: Train Epoch 16: 627/634 Loss: 0.131843
2023-01-01 22:20: Train Epoch 16: 631/634 Loss: 0.142884
2023-01-01 22:20: Train Epoch 16: 633/634 Loss: 0.075436
2023-01-01 22:20: **********Train Epoch 16: averaged Loss: 0.138459 
2023-01-01 22:20: 
Epoch time elapsed: 2394.863310813904

2023-01-01 22:21: 
 metrics validation: {'precision': 0.8650580875781948, 'recall': 0.7446153846153846, 'f1-score': 0.8003307151715585, 'support': 1300, 'AUC': 0.9393508875739645, 'AUCPR': 0.8864903966383145, 'TP': 968, 'FP': 151, 'TN': 2449, 'FN': 332} 

2023-01-01 22:21: **********Val Epoch 16: average Loss: 0.148821
2023-01-01 22:22: 
 Testing metrics {'precision': 0.8049403747870528, 'recall': 0.7695439739413681, 'f1-score': 0.7868442964196504, 'support': 1228, 'AUC': 0.9254514636760074, 'AUCPR': 0.8831107897948774, 'TP': 945, 'FP': 229, 'TN': 2227, 'FN': 283} 

2023-01-01 22:26: 
 Testing metrics {'precision': 0.8756710328537686, 'recall': 0.9253460403902882, 'f1-score': 0.8998234774933803, 'support': 4407, 'AUC': 0.9798364186274813, 'AUCPR': 0.9653462066051434, 'TP': 4078, 'FP': 579, 'TN': 8235, 'FN': 329} 

2023-01-01 22:26: Train Epoch 17: 3/634 Loss: 0.147300
2023-01-01 22:27: Train Epoch 17: 7/634 Loss: 0.154474
2023-01-01 22:27: Train Epoch 17: 11/634 Loss: 0.137754
2023-01-01 22:27: Train Epoch 17: 15/634 Loss: 0.111175
2023-01-01 22:27: Train Epoch 17: 19/634 Loss: 0.147803
2023-01-01 22:28: Train Epoch 17: 23/634 Loss: 0.114571
2023-01-01 22:28: Train Epoch 17: 27/634 Loss: 0.143286
2023-01-01 22:28: Train Epoch 17: 31/634 Loss: 0.122531
2023-01-01 22:28: Train Epoch 17: 35/634 Loss: 0.168873
2023-01-01 22:29: Train Epoch 17: 39/634 Loss: 0.176116
2023-01-01 22:29: Train Epoch 17: 43/634 Loss: 0.133630
2023-01-01 22:29: Train Epoch 17: 47/634 Loss: 0.135383
2023-01-01 22:29: Train Epoch 17: 51/634 Loss: 0.127391
2023-01-01 22:30: Train Epoch 17: 55/634 Loss: 0.160815
2023-01-01 22:30: Train Epoch 17: 59/634 Loss: 0.139316
2023-01-01 22:30: Train Epoch 17: 63/634 Loss: 0.170203
2023-01-01 22:30: Train Epoch 17: 67/634 Loss: 0.148217
2023-01-01 22:31: Train Epoch 17: 71/634 Loss: 0.135643
2023-01-01 22:31: Train Epoch 17: 75/634 Loss: 0.145607
2023-01-01 22:31: Train Epoch 17: 79/634 Loss: 0.131515
2023-01-01 22:31: Train Epoch 17: 83/634 Loss: 0.141273
2023-01-01 22:32: Train Epoch 17: 87/634 Loss: 0.140905
2023-01-01 22:32: Train Epoch 17: 91/634 Loss: 0.148908
2023-01-01 22:32: Train Epoch 17: 95/634 Loss: 0.166961
2023-01-01 22:32: Train Epoch 17: 99/634 Loss: 0.152826
2023-01-01 22:33: Train Epoch 17: 103/634 Loss: 0.162797
2023-01-01 22:33: Train Epoch 17: 107/634 Loss: 0.149207
2023-01-01 22:33: Train Epoch 17: 111/634 Loss: 0.168141
2023-01-01 22:33: Train Epoch 17: 115/634 Loss: 0.139322
2023-01-01 22:34: Train Epoch 17: 119/634 Loss: 0.130392
2023-01-01 22:34: Train Epoch 17: 123/634 Loss: 0.121651
2023-01-01 22:34: Train Epoch 17: 127/634 Loss: 0.151419
2023-01-01 22:34: Train Epoch 17: 131/634 Loss: 0.126749
2023-01-01 22:34: Train Epoch 17: 135/634 Loss: 0.127540
2023-01-01 22:35: Train Epoch 17: 139/634 Loss: 0.154257
2023-01-01 22:35: Train Epoch 17: 143/634 Loss: 0.106364
2023-01-01 22:35: Train Epoch 17: 147/634 Loss: 0.141160
2023-01-01 22:35: Train Epoch 17: 151/634 Loss: 0.129203
2023-01-01 22:36: Train Epoch 17: 155/634 Loss: 0.131044
2023-01-01 22:36: Train Epoch 17: 159/634 Loss: 0.119052
2023-01-01 22:36: Train Epoch 17: 163/634 Loss: 0.164526
2023-01-01 22:36: Train Epoch 17: 167/634 Loss: 0.128329
2023-01-01 22:37: Train Epoch 17: 171/634 Loss: 0.142604
2023-01-01 22:37: Train Epoch 17: 175/634 Loss: 0.154897
2023-01-01 22:37: Train Epoch 17: 179/634 Loss: 0.167273
2023-01-01 22:37: Train Epoch 17: 183/634 Loss: 0.153696
2023-01-01 22:38: Train Epoch 17: 187/634 Loss: 0.147631
2023-01-01 22:38: Train Epoch 17: 191/634 Loss: 0.156849
2023-01-01 22:38: Train Epoch 17: 195/634 Loss: 0.147948
2023-01-01 22:38: Train Epoch 17: 199/634 Loss: 0.124355
2023-01-01 22:39: Train Epoch 17: 203/634 Loss: 0.124140
2023-01-01 22:39: Train Epoch 17: 207/634 Loss: 0.130740
2023-01-01 22:39: Train Epoch 17: 211/634 Loss: 0.119911
2023-01-01 22:39: Train Epoch 17: 215/634 Loss: 0.149033
2023-01-01 22:40: Train Epoch 17: 219/634 Loss: 0.130683
2023-01-01 22:40: Train Epoch 17: 223/634 Loss: 0.165013
2023-01-01 22:40: Train Epoch 17: 227/634 Loss: 0.123469
2023-01-01 22:40: Train Epoch 17: 231/634 Loss: 0.131976
2023-01-01 22:41: Train Epoch 17: 235/634 Loss: 0.142097
2023-01-01 22:41: Train Epoch 17: 239/634 Loss: 0.155194
2023-01-01 22:41: Train Epoch 17: 243/634 Loss: 0.139938
2023-01-01 22:41: Train Epoch 17: 247/634 Loss: 0.139915
2023-01-01 22:42: Train Epoch 17: 251/634 Loss: 0.158364
2023-01-01 22:42: Train Epoch 17: 255/634 Loss: 0.156114
2023-01-01 22:42: Train Epoch 17: 259/634 Loss: 0.122071
2023-01-01 22:42: Train Epoch 17: 263/634 Loss: 0.129187
2023-01-01 22:43: Train Epoch 17: 267/634 Loss: 0.140631
2023-01-01 22:43: Train Epoch 17: 271/634 Loss: 0.151260
2023-01-01 22:43: Train Epoch 17: 275/634 Loss: 0.158338
2023-01-01 22:43: Train Epoch 17: 279/634 Loss: 0.129855
2023-01-01 22:44: Train Epoch 17: 283/634 Loss: 0.120274
2023-01-01 22:44: Train Epoch 17: 287/634 Loss: 0.129444
2023-01-01 22:44: Train Epoch 17: 291/634 Loss: 0.138597
2023-01-01 22:44: Train Epoch 17: 295/634 Loss: 0.142918
2023-01-01 22:45: Train Epoch 17: 299/634 Loss: 0.140717
2023-01-01 22:45: Train Epoch 17: 303/634 Loss: 0.152166
2023-01-01 22:45: Train Epoch 17: 307/634 Loss: 0.151506
2023-01-01 22:45: Train Epoch 17: 311/634 Loss: 0.142084
2023-01-01 22:46: Train Epoch 17: 315/634 Loss: 0.121962
2023-01-01 22:46: Train Epoch 17: 319/634 Loss: 0.127758
2023-01-01 22:46: Train Epoch 17: 323/634 Loss: 0.132861
2023-01-01 22:46: Train Epoch 17: 327/634 Loss: 0.136473
2023-01-01 22:47: Train Epoch 17: 331/634 Loss: 0.144290
2023-01-01 22:47: Train Epoch 17: 335/634 Loss: 0.133523
2023-01-01 22:47: Train Epoch 17: 339/634 Loss: 0.128459
2023-01-01 22:47: Train Epoch 17: 343/634 Loss: 0.137113
2023-01-01 22:47: Train Epoch 17: 347/634 Loss: 0.147099
2023-01-01 22:48: Train Epoch 17: 351/634 Loss: 0.131711
2023-01-01 22:48: Train Epoch 17: 355/634 Loss: 0.128472
2023-01-01 22:48: Train Epoch 17: 359/634 Loss: 0.135771
2023-01-01 22:48: Train Epoch 17: 363/634 Loss: 0.137648
2023-01-01 22:49: Train Epoch 17: 367/634 Loss: 0.156081
2023-01-01 22:49: Train Epoch 17: 371/634 Loss: 0.136260
2023-01-01 22:49: Train Epoch 17: 375/634 Loss: 0.128722
2023-01-01 22:49: Train Epoch 17: 379/634 Loss: 0.136802
2023-01-01 22:50: Train Epoch 17: 383/634 Loss: 0.140709
2023-01-01 22:50: Train Epoch 17: 387/634 Loss: 0.144877
2023-01-01 22:50: Train Epoch 17: 391/634 Loss: 0.126201
2023-01-01 22:51: Train Epoch 17: 395/634 Loss: 0.147367
2023-01-01 22:51: Train Epoch 17: 399/634 Loss: 0.153072
2023-01-01 22:51: Train Epoch 17: 403/634 Loss: 0.136408
2023-01-01 22:51: Train Epoch 17: 407/634 Loss: 0.127577
2023-01-01 22:51: Train Epoch 17: 411/634 Loss: 0.144752
2023-01-01 22:52: Train Epoch 17: 415/634 Loss: 0.156648
2023-01-01 22:52: Train Epoch 17: 419/634 Loss: 0.148441
2023-01-01 22:52: Train Epoch 17: 423/634 Loss: 0.123881
2023-01-01 22:52: Train Epoch 17: 427/634 Loss: 0.114281
2023-01-01 22:53: Train Epoch 17: 431/634 Loss: 0.129293
2023-01-01 22:53: Train Epoch 17: 435/634 Loss: 0.155850
2023-01-01 22:53: Train Epoch 17: 439/634 Loss: 0.135620
2023-01-01 22:53: Train Epoch 17: 443/634 Loss: 0.145021
2023-01-01 22:54: Train Epoch 17: 447/634 Loss: 0.128457
2023-01-01 22:54: Train Epoch 17: 451/634 Loss: 0.135826
2023-01-01 22:54: Train Epoch 17: 455/634 Loss: 0.146711
2023-01-01 22:54: Train Epoch 17: 459/634 Loss: 0.140442
2023-01-01 22:55: Train Epoch 17: 463/634 Loss: 0.140758
2023-01-01 22:55: Train Epoch 17: 467/634 Loss: 0.150776
2023-01-01 22:55: Train Epoch 17: 471/634 Loss: 0.136530
2023-01-01 22:55: Train Epoch 17: 475/634 Loss: 0.147533
2023-01-01 22:56: Train Epoch 17: 479/634 Loss: 0.114764
2023-01-01 22:56: Train Epoch 17: 483/634 Loss: 0.114356
2023-01-01 22:56: Train Epoch 17: 487/634 Loss: 0.134458
2023-01-01 22:56: Train Epoch 17: 491/634 Loss: 0.138160
2023-01-01 22:57: Train Epoch 17: 495/634 Loss: 0.127917
2023-01-01 22:57: Train Epoch 17: 499/634 Loss: 0.174350
2023-01-01 22:57: Train Epoch 17: 503/634 Loss: 0.139242
2023-01-01 22:57: Train Epoch 17: 507/634 Loss: 0.132493
2023-01-01 22:58: Train Epoch 17: 511/634 Loss: 0.125035
2023-01-01 22:58: Train Epoch 17: 515/634 Loss: 0.121112
2023-01-01 22:58: Train Epoch 17: 519/634 Loss: 0.136534
2023-01-01 22:58: Train Epoch 17: 523/634 Loss: 0.128156
2023-01-01 22:58: Train Epoch 17: 527/634 Loss: 0.120927
2023-01-01 22:59: Train Epoch 17: 531/634 Loss: 0.127067
2023-01-01 22:59: Train Epoch 17: 535/634 Loss: 0.131514
2023-01-01 22:59: Train Epoch 17: 539/634 Loss: 0.143032
2023-01-01 22:59: Train Epoch 17: 543/634 Loss: 0.138197
2023-01-01 23:00: Train Epoch 17: 547/634 Loss: 0.128352
2023-01-01 23:00: Train Epoch 17: 551/634 Loss: 0.126077
2023-01-01 23:00: Train Epoch 17: 555/634 Loss: 0.108364
2023-01-01 23:00: Train Epoch 17: 559/634 Loss: 0.144762
2023-01-01 23:01: Train Epoch 17: 563/634 Loss: 0.152936
2023-01-01 23:01: Train Epoch 17: 567/634 Loss: 0.131758
2023-01-01 23:01: Train Epoch 17: 571/634 Loss: 0.140450
2023-01-01 23:01: Train Epoch 17: 575/634 Loss: 0.128079
2023-01-01 23:02: Train Epoch 17: 579/634 Loss: 0.131164
2023-01-01 23:02: Train Epoch 17: 583/634 Loss: 0.144472
2023-01-01 23:02: Train Epoch 17: 587/634 Loss: 0.148464
2023-01-01 23:02: Train Epoch 17: 591/634 Loss: 0.130770
2023-01-01 23:03: Train Epoch 17: 595/634 Loss: 0.137715
2023-01-01 23:03: Train Epoch 17: 599/634 Loss: 0.124870
2023-01-01 23:03: Train Epoch 17: 603/634 Loss: 0.111958
2023-01-01 23:03: Train Epoch 17: 607/634 Loss: 0.135418
2023-01-01 23:04: Train Epoch 17: 611/634 Loss: 0.141903
2023-01-01 23:04: Train Epoch 17: 615/634 Loss: 0.136959
2023-01-01 23:04: Train Epoch 17: 619/634 Loss: 0.138029
2023-01-01 23:04: Train Epoch 17: 623/634 Loss: 0.141394
2023-01-01 23:05: Train Epoch 17: 627/634 Loss: 0.137242
2023-01-01 23:05: Train Epoch 17: 631/634 Loss: 0.118891
2023-01-01 23:05: Train Epoch 17: 633/634 Loss: 0.049901
2023-01-01 23:05: **********Train Epoch 17: averaged Loss: 0.138112 
2023-01-01 23:05: 
Epoch time elapsed: 2329.0065126419067

2023-01-01 23:06: 
 metrics validation: {'precision': 0.8958333333333334, 'recall': 0.6615384615384615, 'f1-score': 0.7610619469026548, 'support': 1300, 'AUC': 0.9395683431952664, 'AUCPR': 0.8857791786591743, 'TP': 860, 'FP': 100, 'TN': 2500, 'FN': 440} 

2023-01-01 23:06: **********Val Epoch 17: average Loss: 0.163009
2023-01-01 23:06: Validation performance didn't improve for 8 epochs. Training stops.
2023-01-01 23:06: Total training time: 770.1811min, best loss: 0.143056
2023-01-01 23:06: Saving current best model to /home/joel.chacon/tmp/WildFire_GCN/experiments/2020/2023010110162104625054013/best_model.pth
2023-01-01 23:07: 
 Testing metrics {'precision': 0.8049403747870528, 'recall': 0.7695439739413681, 'f1-score': 0.7868442964196504, 'support': 1228, 'AUC': 0.9254514636760074, 'AUCPR': 0.8831107897948774, 'TP': 945, 'FP': 229, 'TN': 2227, 'FN': 283} 

2023-01-01 23:11: 
 Testing metrics {'precision': 0.8756710328537686, 'recall': 0.9253460403902882, 'f1-score': 0.8998234774933803, 'support': 4407, 'AUC': 0.9798364186274813, 'AUCPR': 0.9653462066051434, 'TP': 4078, 'FP': 579, 'TN': 8235, 'FN': 329} 

